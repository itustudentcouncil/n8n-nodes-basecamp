// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/pubsub/v1/pubsub.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Duration } from "../../protobuf/duration.js";
import { Empty } from "../../protobuf/empty.js";
import { FieldMask } from "../../protobuf/field_mask.js";
import { Timestamp } from "../../protobuf/timestamp.js";
import { Encoding, encodingFromJSON, encodingToJSON } from "./schema.js";

export const protobufPackage = "google.pubsub.v1";

/** A policy constraining the storage of messages published to the topic. */
export interface MessageStoragePolicy {
  /**
   * Optional. A list of IDs of Google Cloud regions where messages that are
   * published to the topic may be persisted in storage. Messages published by
   * publishers running in non-allowed Google Cloud regions (or running outside
   * of Google Cloud altogether) are routed for storage in one of the allowed
   * regions. An empty list means that no regions are allowed, and is not a
   * valid configuration.
   */
  allowedPersistenceRegions: string[];
  /**
   * Optional. If true, `allowed_persistence_regions` is also used to enforce
   * in-transit guarantees for messages. That is, Pub/Sub will fail
   * Publish operations on this topic and subscribe operations
   * on any subscription attached to this topic in any region that is
   * not in `allowed_persistence_regions`.
   */
  enforceInTransit: boolean;
}

/** Settings for validating messages published against a schema. */
export interface SchemaSettings {
  /**
   * Required. The name of the schema that messages published should be
   * validated against. Format is `projects/{project}/schemas/{schema}`. The
   * value of this field will be `_deleted-schema_` if the schema has been
   * deleted.
   */
  schema: string;
  /** Optional. The encoding of messages validated against `schema`. */
  encoding: Encoding;
  /**
   * Optional. The minimum (inclusive) revision allowed for validating messages.
   * If empty or not present, allow any revision to be validated against
   * last_revision or any revision created before.
   */
  firstRevisionId: string;
  /**
   * Optional. The maximum (inclusive) revision allowed for validating messages.
   * If empty or not present, allow any revision to be validated against
   * first_revision or any revision created after.
   */
  lastRevisionId: string;
}

/** Settings for an ingestion data source on a topic. */
export interface IngestionDataSourceSettings {
  /** Optional. Amazon Kinesis Data Streams. */
  awsKinesis?:
    | IngestionDataSourceSettings_AwsKinesis
    | undefined;
  /** Optional. Cloud Storage. */
  cloudStorage?:
    | IngestionDataSourceSettings_CloudStorage
    | undefined;
  /**
   * Optional. Platform Logs settings. If unset, no Platform Logs will be
   * generated.
   */
  platformLogsSettings: PlatformLogsSettings | undefined;
}

/** Ingestion settings for Amazon Kinesis Data Streams. */
export interface IngestionDataSourceSettings_AwsKinesis {
  /**
   * Output only. An output-only field that indicates the state of the Kinesis
   * ingestion source.
   */
  state: IngestionDataSourceSettings_AwsKinesis_State;
  /** Required. The Kinesis stream ARN to ingest data from. */
  streamArn: string;
  /**
   * Required. The Kinesis consumer ARN to used for ingestion in Enhanced
   * Fan-Out mode. The consumer must be already created and ready to be used.
   */
  consumerArn: string;
  /**
   * Required. AWS role ARN to be used for Federated Identity authentication
   * with Kinesis. Check the Pub/Sub docs for how to set up this role and the
   * required permissions that need to be attached to it.
   */
  awsRoleArn: string;
  /**
   * Required. The GCP service account to be used for Federated Identity
   * authentication with Kinesis (via a `AssumeRoleWithWebIdentity` call for
   * the provided role). The `aws_role_arn` must be set up with
   * `accounts.google.com:sub` equals to this service account number.
   */
  gcpServiceAccount: string;
}

/** Possible states for ingestion from Amazon Kinesis Data Streams. */
export enum IngestionDataSourceSettings_AwsKinesis_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - Ingestion is active. */
  ACTIVE = 1,
  /**
   * KINESIS_PERMISSION_DENIED - Permission denied encountered while consuming data from Kinesis.
   * This can happen if:
   *   - The provided `aws_role_arn` does not exist or does not have the
   *     appropriate permissions attached.
   *   - The provided `aws_role_arn` is not set up properly for Identity
   *     Federation using `gcp_service_account`.
   *   - The Pub/Sub SA is not granted the
   *     `iam.serviceAccounts.getOpenIdToken` permission on
   *     `gcp_service_account`.
   */
  KINESIS_PERMISSION_DENIED = 2,
  /**
   * PUBLISH_PERMISSION_DENIED - Permission denied encountered while publishing to the topic. This can
   * happen if the Pub/Sub SA has not been granted the [appropriate publish
   * permissions](https://cloud.google.com/pubsub/docs/access-control#pubsub.publisher)
   */
  PUBLISH_PERMISSION_DENIED = 3,
  /** STREAM_NOT_FOUND - The Kinesis stream does not exist. */
  STREAM_NOT_FOUND = 4,
  /** CONSUMER_NOT_FOUND - The Kinesis consumer does not exist. */
  CONSUMER_NOT_FOUND = 5,
  UNRECOGNIZED = -1,
}

export function ingestionDataSourceSettings_AwsKinesis_StateFromJSON(
  object: any,
): IngestionDataSourceSettings_AwsKinesis_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return IngestionDataSourceSettings_AwsKinesis_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return IngestionDataSourceSettings_AwsKinesis_State.ACTIVE;
    case 2:
    case "KINESIS_PERMISSION_DENIED":
      return IngestionDataSourceSettings_AwsKinesis_State.KINESIS_PERMISSION_DENIED;
    case 3:
    case "PUBLISH_PERMISSION_DENIED":
      return IngestionDataSourceSettings_AwsKinesis_State.PUBLISH_PERMISSION_DENIED;
    case 4:
    case "STREAM_NOT_FOUND":
      return IngestionDataSourceSettings_AwsKinesis_State.STREAM_NOT_FOUND;
    case 5:
    case "CONSUMER_NOT_FOUND":
      return IngestionDataSourceSettings_AwsKinesis_State.CONSUMER_NOT_FOUND;
    case -1:
    case "UNRECOGNIZED":
    default:
      return IngestionDataSourceSettings_AwsKinesis_State.UNRECOGNIZED;
  }
}

export function ingestionDataSourceSettings_AwsKinesis_StateToJSON(
  object: IngestionDataSourceSettings_AwsKinesis_State,
): string {
  switch (object) {
    case IngestionDataSourceSettings_AwsKinesis_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case IngestionDataSourceSettings_AwsKinesis_State.ACTIVE:
      return "ACTIVE";
    case IngestionDataSourceSettings_AwsKinesis_State.KINESIS_PERMISSION_DENIED:
      return "KINESIS_PERMISSION_DENIED";
    case IngestionDataSourceSettings_AwsKinesis_State.PUBLISH_PERMISSION_DENIED:
      return "PUBLISH_PERMISSION_DENIED";
    case IngestionDataSourceSettings_AwsKinesis_State.STREAM_NOT_FOUND:
      return "STREAM_NOT_FOUND";
    case IngestionDataSourceSettings_AwsKinesis_State.CONSUMER_NOT_FOUND:
      return "CONSUMER_NOT_FOUND";
    case IngestionDataSourceSettings_AwsKinesis_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Ingestion settings for Cloud Storage. */
export interface IngestionDataSourceSettings_CloudStorage {
  /**
   * Output only. An output-only field that indicates the state of the Cloud
   * Storage ingestion source.
   */
  state: IngestionDataSourceSettings_CloudStorage_State;
  /**
   * Optional. Cloud Storage bucket. The bucket name must be without any
   * prefix like "gs://". See the [bucket naming requirements]
   * (https://cloud.google.com/storage/docs/buckets#naming).
   */
  bucket: string;
  /** Optional. Data from Cloud Storage will be interpreted as text. */
  textFormat?:
    | IngestionDataSourceSettings_CloudStorage_TextFormat
    | undefined;
  /** Optional. Data from Cloud Storage will be interpreted in Avro format. */
  avroFormat?:
    | IngestionDataSourceSettings_CloudStorage_AvroFormat
    | undefined;
  /**
   * Optional. It will be assumed data from Cloud Storage was written via
   * [Cloud Storage
   * subscriptions](https://cloud.google.com/pubsub/docs/cloudstorage).
   */
  pubsubAvroFormat?:
    | IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat
    | undefined;
  /**
   * Optional. Only objects with a larger or equal creation timestamp will be
   * ingested.
   */
  minimumObjectCreateTime:
    | Date
    | undefined;
  /**
   * Optional. Glob pattern used to match objects that will be ingested. If
   * unset, all objects will be ingested. See the [supported
   * patterns](https://cloud.google.com/storage/docs/json_api/v1/objects/list#list-objects-and-prefixes-using-glob).
   */
  matchGlob: string;
}

/** Possible states for ingestion from Cloud Storage. */
export enum IngestionDataSourceSettings_CloudStorage_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - Ingestion is active. */
  ACTIVE = 1,
  /**
   * CLOUD_STORAGE_PERMISSION_DENIED - Permission denied encountered while calling the Cloud Storage API. This
   * can happen if the Pub/Sub SA has not been granted the
   * [appropriate
   * permissions](https://cloud.google.com/storage/docs/access-control/iam-permissions):
   * - storage.objects.list: to list the objects in a bucket.
   * - storage.objects.get: to read the objects in a bucket.
   * - storage.buckets.get: to verify the bucket exists.
   */
  CLOUD_STORAGE_PERMISSION_DENIED = 2,
  /**
   * PUBLISH_PERMISSION_DENIED - Permission denied encountered while publishing to the topic. This can
   * happen if the Pub/Sub SA has not been granted the [appropriate publish
   * permissions](https://cloud.google.com/pubsub/docs/access-control#pubsub.publisher)
   */
  PUBLISH_PERMISSION_DENIED = 3,
  /** BUCKET_NOT_FOUND - The provided Cloud Storage bucket doesn't exist. */
  BUCKET_NOT_FOUND = 4,
  /**
   * TOO_MANY_OBJECTS - The Cloud Storage bucket has too many objects, ingestion will be
   * paused.
   */
  TOO_MANY_OBJECTS = 5,
  UNRECOGNIZED = -1,
}

export function ingestionDataSourceSettings_CloudStorage_StateFromJSON(
  object: any,
): IngestionDataSourceSettings_CloudStorage_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return IngestionDataSourceSettings_CloudStorage_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return IngestionDataSourceSettings_CloudStorage_State.ACTIVE;
    case 2:
    case "CLOUD_STORAGE_PERMISSION_DENIED":
      return IngestionDataSourceSettings_CloudStorage_State.CLOUD_STORAGE_PERMISSION_DENIED;
    case 3:
    case "PUBLISH_PERMISSION_DENIED":
      return IngestionDataSourceSettings_CloudStorage_State.PUBLISH_PERMISSION_DENIED;
    case 4:
    case "BUCKET_NOT_FOUND":
      return IngestionDataSourceSettings_CloudStorage_State.BUCKET_NOT_FOUND;
    case 5:
    case "TOO_MANY_OBJECTS":
      return IngestionDataSourceSettings_CloudStorage_State.TOO_MANY_OBJECTS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return IngestionDataSourceSettings_CloudStorage_State.UNRECOGNIZED;
  }
}

export function ingestionDataSourceSettings_CloudStorage_StateToJSON(
  object: IngestionDataSourceSettings_CloudStorage_State,
): string {
  switch (object) {
    case IngestionDataSourceSettings_CloudStorage_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case IngestionDataSourceSettings_CloudStorage_State.ACTIVE:
      return "ACTIVE";
    case IngestionDataSourceSettings_CloudStorage_State.CLOUD_STORAGE_PERMISSION_DENIED:
      return "CLOUD_STORAGE_PERMISSION_DENIED";
    case IngestionDataSourceSettings_CloudStorage_State.PUBLISH_PERMISSION_DENIED:
      return "PUBLISH_PERMISSION_DENIED";
    case IngestionDataSourceSettings_CloudStorage_State.BUCKET_NOT_FOUND:
      return "BUCKET_NOT_FOUND";
    case IngestionDataSourceSettings_CloudStorage_State.TOO_MANY_OBJECTS:
      return "TOO_MANY_OBJECTS";
    case IngestionDataSourceSettings_CloudStorage_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Configuration for reading Cloud Storage data in text format. Each line of
 * text as specified by the delimiter will be set to the `data` field of a
 * Pub/Sub message.
 */
export interface IngestionDataSourceSettings_CloudStorage_TextFormat {
  /** Optional. When unset, '\n' is used. */
  delimiter?: string | undefined;
}

/**
 * Configuration for reading Cloud Storage data in Avro binary format. The
 * bytes of each object will be set to the `data` field of a Pub/Sub
 * message.
 */
export interface IngestionDataSourceSettings_CloudStorage_AvroFormat {
}

/**
 * Configuration for reading Cloud Storage data written via [Cloud Storage
 * subscriptions](https://cloud.google.com/pubsub/docs/cloudstorage). The
 * data and attributes fields of the originally exported Pub/Sub message
 * will be restored when publishing.
 */
export interface IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat {
}

/** Settings for Platform Logs produced by Pub/Sub. */
export interface PlatformLogsSettings {
  /** Optional. The minimum severity level of Platform Logs that will be written. */
  severity: PlatformLogsSettings_Severity;
}

/** Severity levels of Platform Logs. */
export enum PlatformLogsSettings_Severity {
  /** SEVERITY_UNSPECIFIED - Default value. Logs level is unspecified. Logs will be disabled. */
  SEVERITY_UNSPECIFIED = 0,
  /** DISABLED - Logs will be disabled. */
  DISABLED = 1,
  /** DEBUG - Debug logs and higher-severity logs will be written. */
  DEBUG = 2,
  /** INFO - Info logs and higher-severity logs will be written. */
  INFO = 3,
  /** WARNING - Warning logs and higher-severity logs will be written. */
  WARNING = 4,
  /** ERROR - Only error logs will be written. */
  ERROR = 5,
  UNRECOGNIZED = -1,
}

export function platformLogsSettings_SeverityFromJSON(object: any): PlatformLogsSettings_Severity {
  switch (object) {
    case 0:
    case "SEVERITY_UNSPECIFIED":
      return PlatformLogsSettings_Severity.SEVERITY_UNSPECIFIED;
    case 1:
    case "DISABLED":
      return PlatformLogsSettings_Severity.DISABLED;
    case 2:
    case "DEBUG":
      return PlatformLogsSettings_Severity.DEBUG;
    case 3:
    case "INFO":
      return PlatformLogsSettings_Severity.INFO;
    case 4:
    case "WARNING":
      return PlatformLogsSettings_Severity.WARNING;
    case 5:
    case "ERROR":
      return PlatformLogsSettings_Severity.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PlatformLogsSettings_Severity.UNRECOGNIZED;
  }
}

export function platformLogsSettings_SeverityToJSON(object: PlatformLogsSettings_Severity): string {
  switch (object) {
    case PlatformLogsSettings_Severity.SEVERITY_UNSPECIFIED:
      return "SEVERITY_UNSPECIFIED";
    case PlatformLogsSettings_Severity.DISABLED:
      return "DISABLED";
    case PlatformLogsSettings_Severity.DEBUG:
      return "DEBUG";
    case PlatformLogsSettings_Severity.INFO:
      return "INFO";
    case PlatformLogsSettings_Severity.WARNING:
      return "WARNING";
    case PlatformLogsSettings_Severity.ERROR:
      return "ERROR";
    case PlatformLogsSettings_Severity.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A topic resource. */
export interface Topic {
  /**
   * Required. The name of the topic. It must have the format
   * `"projects/{project}/topics/{topic}"`. `{topic}` must start with a letter,
   * and contain only letters (`[A-Za-z]`), numbers (`[0-9]`), dashes (`-`),
   * underscores (`_`), periods (`.`), tildes (`~`), plus (`+`) or percent
   * signs (`%`). It must be between 3 and 255 characters in length, and it
   * must not start with `"goog"`.
   */
  name: string;
  /**
   * Optional. See [Creating and managing labels]
   * (https://cloud.google.com/pubsub/docs/labels).
   */
  labels: { [key: string]: string };
  /**
   * Optional. Policy constraining the set of Google Cloud Platform regions
   * where messages published to the topic may be stored. If not present, then
   * no constraints are in effect.
   */
  messageStoragePolicy:
    | MessageStoragePolicy
    | undefined;
  /**
   * Optional. The resource name of the Cloud KMS CryptoKey to be used to
   * protect access to messages published on this topic.
   *
   * The expected format is `projects/* /locations/* /keyRings/* /cryptoKeys/*`.
   */
  kmsKeyName: string;
  /** Optional. Settings for validating messages published against a schema. */
  schemaSettings:
    | SchemaSettings
    | undefined;
  /**
   * Optional. Reserved for future use. This field is set only in responses from
   * the server; it is ignored if it is set in any requests.
   */
  satisfiesPzs: boolean;
  /**
   * Optional. Indicates the minimum duration to retain a message after it is
   * published to the topic. If this field is set, messages published to the
   * topic in the last `message_retention_duration` are always available to
   * subscribers. For instance, it allows any attached subscription to [seek to
   * a
   * timestamp](https://cloud.google.com/pubsub/docs/replay-overview#seek_to_a_time)
   * that is up to `message_retention_duration` in the past. If this field is
   * not set, message retention is controlled by settings on individual
   * subscriptions. Cannot be more than 31 days or less than 10 minutes.
   */
  messageRetentionDuration:
    | Duration
    | undefined;
  /** Output only. An output-only field indicating the state of the topic. */
  state: Topic_State;
  /** Optional. Settings for ingestion from a data source into this topic. */
  ingestionDataSourceSettings: IngestionDataSourceSettings | undefined;
}

/** The state of the topic. */
export enum Topic_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The topic does not have any persistent errors. */
  ACTIVE = 1,
  /**
   * INGESTION_RESOURCE_ERROR - Ingestion from the data source has encountered a permanent error.
   * See the more detailed error state in the corresponding ingestion
   * source configuration.
   */
  INGESTION_RESOURCE_ERROR = 2,
  UNRECOGNIZED = -1,
}

export function topic_StateFromJSON(object: any): Topic_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Topic_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return Topic_State.ACTIVE;
    case 2:
    case "INGESTION_RESOURCE_ERROR":
      return Topic_State.INGESTION_RESOURCE_ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Topic_State.UNRECOGNIZED;
  }
}

export function topic_StateToJSON(object: Topic_State): string {
  switch (object) {
    case Topic_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Topic_State.ACTIVE:
      return "ACTIVE";
    case Topic_State.INGESTION_RESOURCE_ERROR:
      return "INGESTION_RESOURCE_ERROR";
    case Topic_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Topic_LabelsEntry {
  key: string;
  value: string;
}

/**
 * A message that is published by publishers and consumed by subscribers. The
 * message must contain either a non-empty data field or at least one attribute.
 * Note that client libraries represent this object differently
 * depending on the language. See the corresponding [client library
 * documentation](https://cloud.google.com/pubsub/docs/reference/libraries) for
 * more information. See [quotas and limits]
 * (https://cloud.google.com/pubsub/quotas) for more information about message
 * limits.
 */
export interface PubsubMessage {
  /**
   * Optional. The message data field. If this field is empty, the message must
   * contain at least one attribute.
   */
  data: Buffer;
  /**
   * Optional. Attributes for this message. If this field is empty, the message
   * must contain non-empty data. This can be used to filter messages on the
   * subscription.
   */
  attributes: { [key: string]: string };
  /**
   * ID of this message, assigned by the server when the message is published.
   * Guaranteed to be unique within the topic. This value may be read by a
   * subscriber that receives a `PubsubMessage` via a `Pull` call or a push
   * delivery. It must not be populated by the publisher in a `Publish` call.
   */
  messageId: string;
  /**
   * The time at which the message was published, populated by the server when
   * it receives the `Publish` call. It must not be populated by the
   * publisher in a `Publish` call.
   */
  publishTime:
    | Date
    | undefined;
  /**
   * Optional. If non-empty, identifies related messages for which publish order
   * should be respected. If a `Subscription` has `enable_message_ordering` set
   * to `true`, messages published with the same non-empty `ordering_key` value
   * will be delivered to subscribers in the order in which they are received by
   * the Pub/Sub system. All `PubsubMessage`s published in a given
   * `PublishRequest` must specify the same `ordering_key` value. For more
   * information, see [ordering
   * messages](https://cloud.google.com/pubsub/docs/ordering).
   */
  orderingKey: string;
}

export interface PubsubMessage_AttributesEntry {
  key: string;
  value: string;
}

/** Request for the GetTopic method. */
export interface GetTopicRequest {
  /**
   * Required. The name of the topic to get.
   * Format is `projects/{project}/topics/{topic}`.
   */
  topic: string;
}

/** Request for the UpdateTopic method. */
export interface UpdateTopicRequest {
  /** Required. The updated topic object. */
  topic:
    | Topic
    | undefined;
  /**
   * Required. Indicates which fields in the provided topic to update. Must be
   * specified and non-empty. Note that if `update_mask` contains
   * "message_storage_policy" but the `message_storage_policy` is not set in
   * the `topic` provided above, then the updated value is determined by the
   * policy configured at the project or organization level.
   */
  updateMask: string[] | undefined;
}

/** Request for the Publish method. */
export interface PublishRequest {
  /**
   * Required. The messages in the request will be published on this topic.
   * Format is `projects/{project}/topics/{topic}`.
   */
  topic: string;
  /** Required. The messages to publish. */
  messages: PubsubMessage[];
}

/** Response for the `Publish` method. */
export interface PublishResponse {
  /**
   * Optional. The server-assigned ID of each published message, in the same
   * order as the messages in the request. IDs are guaranteed to be unique
   * within the topic.
   */
  messageIds: string[];
}

/** Request for the `ListTopics` method. */
export interface ListTopicsRequest {
  /**
   * Required. The name of the project in which to list topics.
   * Format is `projects/{project-id}`.
   */
  project: string;
  /** Optional. Maximum number of topics to return. */
  pageSize: number;
  /**
   * Optional. The value returned by the last `ListTopicsResponse`; indicates
   * that this is a continuation of a prior `ListTopics` call, and that the
   * system should return the next page of data.
   */
  pageToken: string;
}

/** Response for the `ListTopics` method. */
export interface ListTopicsResponse {
  /** Optional. The resulting topics. */
  topics: Topic[];
  /**
   * Optional. If not empty, indicates that there may be more topics that match
   * the request; this value should be passed in a new `ListTopicsRequest`.
   */
  nextPageToken: string;
}

/** Request for the `ListTopicSubscriptions` method. */
export interface ListTopicSubscriptionsRequest {
  /**
   * Required. The name of the topic that subscriptions are attached to.
   * Format is `projects/{project}/topics/{topic}`.
   */
  topic: string;
  /** Optional. Maximum number of subscription names to return. */
  pageSize: number;
  /**
   * Optional. The value returned by the last `ListTopicSubscriptionsResponse`;
   * indicates that this is a continuation of a prior `ListTopicSubscriptions`
   * call, and that the system should return the next page of data.
   */
  pageToken: string;
}

/** Response for the `ListTopicSubscriptions` method. */
export interface ListTopicSubscriptionsResponse {
  /**
   * Optional. The names of subscriptions attached to the topic specified in the
   * request.
   */
  subscriptions: string[];
  /**
   * Optional. If not empty, indicates that there may be more subscriptions that
   * match the request; this value should be passed in a new
   * `ListTopicSubscriptionsRequest` to get more subscriptions.
   */
  nextPageToken: string;
}

/** Request for the `ListTopicSnapshots` method. */
export interface ListTopicSnapshotsRequest {
  /**
   * Required. The name of the topic that snapshots are attached to.
   * Format is `projects/{project}/topics/{topic}`.
   */
  topic: string;
  /** Optional. Maximum number of snapshot names to return. */
  pageSize: number;
  /**
   * Optional. The value returned by the last `ListTopicSnapshotsResponse`;
   * indicates that this is a continuation of a prior `ListTopicSnapshots` call,
   * and that the system should return the next page of data.
   */
  pageToken: string;
}

/** Response for the `ListTopicSnapshots` method. */
export interface ListTopicSnapshotsResponse {
  /** Optional. The names of the snapshots that match the request. */
  snapshots: string[];
  /**
   * Optional. If not empty, indicates that there may be more snapshots that
   * match the request; this value should be passed in a new
   * `ListTopicSnapshotsRequest` to get more snapshots.
   */
  nextPageToken: string;
}

/** Request for the `DeleteTopic` method. */
export interface DeleteTopicRequest {
  /**
   * Required. Name of the topic to delete.
   * Format is `projects/{project}/topics/{topic}`.
   */
  topic: string;
}

/** Request for the DetachSubscription method. */
export interface DetachSubscriptionRequest {
  /**
   * Required. The subscription to detach.
   * Format is `projects/{project}/subscriptions/{subscription}`.
   */
  subscription: string;
}

/**
 * Response for the DetachSubscription method.
 * Reserved for future use.
 */
export interface DetachSubscriptionResponse {
}

/**
 * A subscription resource. If none of `push_config`, `bigquery_config`, or
 * `cloud_storage_config` is set, then the subscriber will pull and ack messages
 * using API methods. At most one of these fields may be set.
 */
export interface Subscription {
  /**
   * Required. The name of the subscription. It must have the format
   * `"projects/{project}/subscriptions/{subscription}"`. `{subscription}` must
   * start with a letter, and contain only letters (`[A-Za-z]`), numbers
   * (`[0-9]`), dashes (`-`), underscores (`_`), periods (`.`), tildes (`~`),
   * plus (`+`) or percent signs (`%`). It must be between 3 and 255 characters
   * in length, and it must not start with `"goog"`.
   */
  name: string;
  /**
   * Required. The name of the topic from which this subscription is receiving
   * messages. Format is `projects/{project}/topics/{topic}`. The value of this
   * field will be `_deleted-topic_` if the topic has been deleted.
   */
  topic: string;
  /**
   * Optional. If push delivery is used with this subscription, this field is
   * used to configure it.
   */
  pushConfig:
    | PushConfig
    | undefined;
  /**
   * Optional. If delivery to BigQuery is used with this subscription, this
   * field is used to configure it.
   */
  bigqueryConfig:
    | BigQueryConfig
    | undefined;
  /**
   * Optional. If delivery to Google Cloud Storage is used with this
   * subscription, this field is used to configure it.
   */
  cloudStorageConfig:
    | CloudStorageConfig
    | undefined;
  /**
   * Optional. The approximate amount of time (on a best-effort basis) Pub/Sub
   * waits for the subscriber to acknowledge receipt before resending the
   * message. In the interval after the message is delivered and before it is
   * acknowledged, it is considered to be _outstanding_. During that time
   * period, the message will not be redelivered (on a best-effort basis).
   *
   * For pull subscriptions, this value is used as the initial value for the ack
   * deadline. To override this value for a given message, call
   * `ModifyAckDeadline` with the corresponding `ack_id` if using
   * non-streaming pull or send the `ack_id` in a
   * `StreamingModifyAckDeadlineRequest` if using streaming pull.
   * The minimum custom deadline you can specify is 10 seconds.
   * The maximum custom deadline you can specify is 600 seconds (10 minutes).
   * If this parameter is 0, a default value of 10 seconds is used.
   *
   * For push delivery, this value is also used to set the request timeout for
   * the call to the push endpoint.
   *
   * If the subscriber never acknowledges the message, the Pub/Sub
   * system will eventually redeliver the message.
   */
  ackDeadlineSeconds: number;
  /**
   * Optional. Indicates whether to retain acknowledged messages. If true, then
   * messages are not expunged from the subscription's backlog, even if they are
   * acknowledged, until they fall out of the `message_retention_duration`
   * window. This must be true if you would like to [`Seek` to a timestamp]
   * (https://cloud.google.com/pubsub/docs/replay-overview#seek_to_a_time) in
   * the past to replay previously-acknowledged messages.
   */
  retainAckedMessages: boolean;
  /**
   * Optional. How long to retain unacknowledged messages in the subscription's
   * backlog, from the moment a message is published. If `retain_acked_messages`
   * is true, then this also configures the retention of acknowledged messages,
   * and thus configures how far back in time a `Seek` can be done. Defaults to
   * 7 days. Cannot be more than 31 days or less than 10 minutes.
   */
  messageRetentionDuration:
    | Duration
    | undefined;
  /**
   * Optional. See [Creating and managing
   * labels](https://cloud.google.com/pubsub/docs/labels).
   */
  labels: { [key: string]: string };
  /**
   * Optional. If true, messages published with the same `ordering_key` in
   * `PubsubMessage` will be delivered to the subscribers in the order in which
   * they are received by the Pub/Sub system. Otherwise, they may be delivered
   * in any order.
   */
  enableMessageOrdering: boolean;
  /**
   * Optional. A policy that specifies the conditions for this subscription's
   * expiration. A subscription is considered active as long as any connected
   * subscriber is successfully consuming messages from the subscription or is
   * issuing operations on the subscription. If `expiration_policy` is not set,
   * a *default policy* with `ttl` of 31 days will be used. The minimum allowed
   * value for `expiration_policy.ttl` is 1 day. If `expiration_policy` is set,
   * but `expiration_policy.ttl` is not set, the subscription never expires.
   */
  expirationPolicy:
    | ExpirationPolicy
    | undefined;
  /**
   * Optional. An expression written in the Pub/Sub [filter
   * language](https://cloud.google.com/pubsub/docs/filtering). If non-empty,
   * then only `PubsubMessage`s whose `attributes` field matches the filter are
   * delivered on this subscription. If empty, then no messages are filtered
   * out.
   */
  filter: string;
  /**
   * Optional. A policy that specifies the conditions for dead lettering
   * messages in this subscription. If dead_letter_policy is not set, dead
   * lettering is disabled.
   *
   * The Pub/Sub service account associated with this subscriptions's
   * parent project (i.e.,
   * service-{project_number}@gcp-sa-pubsub.iam.gserviceaccount.com) must have
   * permission to Acknowledge() messages on this subscription.
   */
  deadLetterPolicy:
    | DeadLetterPolicy
    | undefined;
  /**
   * Optional. A policy that specifies how Pub/Sub retries message delivery for
   * this subscription.
   *
   * If not set, the default retry policy is applied. This generally implies
   * that messages will be retried as soon as possible for healthy subscribers.
   * RetryPolicy will be triggered on NACKs or acknowledgement deadline
   * exceeded events for a given message.
   */
  retryPolicy:
    | RetryPolicy
    | undefined;
  /**
   * Optional. Indicates whether the subscription is detached from its topic.
   * Detached subscriptions don't receive messages from their topic and don't
   * retain any backlog. `Pull` and `StreamingPull` requests will return
   * FAILED_PRECONDITION. If the subscription is a push subscription, pushes to
   * the endpoint will not be made.
   */
  detached: boolean;
  /**
   * Optional. If true, Pub/Sub provides the following guarantees for the
   * delivery of a message with a given value of `message_id` on this
   * subscription:
   *
   * * The message sent to a subscriber is guaranteed not to be resent
   * before the message's acknowledgement deadline expires.
   * * An acknowledged message will not be resent to a subscriber.
   *
   * Note that subscribers may still receive multiple copies of a message
   * when `enable_exactly_once_delivery` is true if the message was published
   * multiple times by a publisher client. These copies are  considered distinct
   * by Pub/Sub and have distinct `message_id` values.
   */
  enableExactlyOnceDelivery: boolean;
  /**
   * Output only. Indicates the minimum duration for which a message is retained
   * after it is published to the subscription's topic. If this field is set,
   * messages published to the subscription's topic in the last
   * `topic_message_retention_duration` are always available to subscribers. See
   * the `message_retention_duration` field in `Topic`. This field is set only
   * in responses from the server; it is ignored if it is set in any requests.
   */
  topicMessageRetentionDuration:
    | Duration
    | undefined;
  /**
   * Output only. An output-only field indicating whether or not the
   * subscription can receive messages.
   */
  state: Subscription_State;
  /**
   * Output only. Information about the associated Analytics Hub subscription.
   * Only set if the subscritpion is created by Analytics Hub.
   */
  analyticsHubSubscriptionInfo: Subscription_AnalyticsHubSubscriptionInfo | undefined;
}

/** Possible states for a subscription. */
export enum Subscription_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The subscription can actively receive messages */
  ACTIVE = 1,
  /**
   * RESOURCE_ERROR - The subscription cannot receive messages because of an error with the
   * resource to which it pushes messages. See the more detailed error state
   * in the corresponding configuration.
   */
  RESOURCE_ERROR = 2,
  UNRECOGNIZED = -1,
}

export function subscription_StateFromJSON(object: any): Subscription_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Subscription_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return Subscription_State.ACTIVE;
    case 2:
    case "RESOURCE_ERROR":
      return Subscription_State.RESOURCE_ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Subscription_State.UNRECOGNIZED;
  }
}

export function subscription_StateToJSON(object: Subscription_State): string {
  switch (object) {
    case Subscription_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Subscription_State.ACTIVE:
      return "ACTIVE";
    case Subscription_State.RESOURCE_ERROR:
      return "RESOURCE_ERROR";
    case Subscription_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Information about an associated Analytics Hub subscription
 * (https://cloud.google.com/bigquery/docs/analytics-hub-manage-subscriptions).
 */
export interface Subscription_AnalyticsHubSubscriptionInfo {
  /**
   * Optional. The name of the associated Analytics Hub listing resource.
   * Pattern:
   * "projects/{project}/locations/{location}/dataExchanges/{data_exchange}/listings/{listing}"
   */
  listing: string;
  /**
   * Optional. The name of the associated Analytics Hub subscription resource.
   * Pattern:
   * "projects/{project}/locations/{location}/subscriptions/{subscription}"
   */
  subscription: string;
}

export interface Subscription_LabelsEntry {
  key: string;
  value: string;
}

/**
 * A policy that specifies how Pub/Sub retries message delivery.
 *
 * Retry delay will be exponential based on provided minimum and maximum
 * backoffs. https://en.wikipedia.org/wiki/Exponential_backoff.
 *
 * RetryPolicy will be triggered on NACKs or acknowledgement deadline exceeded
 * events for a given message.
 *
 * Retry Policy is implemented on a best effort basis. At times, the delay
 * between consecutive deliveries may not match the configuration. That is,
 * delay can be more or less than configured backoff.
 */
export interface RetryPolicy {
  /**
   * Optional. The minimum delay between consecutive deliveries of a given
   * message. Value should be between 0 and 600 seconds. Defaults to 10 seconds.
   */
  minimumBackoff:
    | Duration
    | undefined;
  /**
   * Optional. The maximum delay between consecutive deliveries of a given
   * message. Value should be between 0 and 600 seconds. Defaults to 600
   * seconds.
   */
  maximumBackoff: Duration | undefined;
}

/**
 * Dead lettering is done on a best effort basis. The same message might be
 * dead lettered multiple times.
 *
 * If validation on any of the fields fails at subscription creation/updation,
 * the create/update subscription request will fail.
 */
export interface DeadLetterPolicy {
  /**
   * Optional. The name of the topic to which dead letter messages should be
   * published. Format is `projects/{project}/topics/{topic}`.The Pub/Sub
   * service account associated with the enclosing subscription's parent project
   * (i.e., service-{project_number}@gcp-sa-pubsub.iam.gserviceaccount.com) must
   * have permission to Publish() to this topic.
   *
   * The operation will fail if the topic does not exist.
   * Users should ensure that there is a subscription attached to this topic
   * since messages published to a topic with no subscriptions are lost.
   */
  deadLetterTopic: string;
  /**
   * Optional. The maximum number of delivery attempts for any message. The
   * value must be between 5 and 100.
   *
   * The number of delivery attempts is defined as 1 + (the sum of number of
   * NACKs and number of times the acknowledgement deadline has been exceeded
   * for the message).
   *
   * A NACK is any call to ModifyAckDeadline with a 0 deadline. Note that
   * client libraries may automatically extend ack_deadlines.
   *
   * This field will be honored on a best effort basis.
   *
   * If this parameter is 0, a default value of 5 is used.
   */
  maxDeliveryAttempts: number;
}

/**
 * A policy that specifies the conditions for resource expiration (i.e.,
 * automatic resource deletion).
 */
export interface ExpirationPolicy {
  /**
   * Optional. Specifies the "time-to-live" duration for an associated resource.
   * The resource expires if it is not active for a period of `ttl`. The
   * definition of "activity" depends on the type of the associated resource.
   * The minimum and maximum allowed values for `ttl` depend on the type of the
   * associated resource, as well. If `ttl` is not set, the associated resource
   * never expires.
   */
  ttl: Duration | undefined;
}

/** Configuration for a push delivery endpoint. */
export interface PushConfig {
  /**
   * Optional. A URL locating the endpoint to which messages should be pushed.
   * For example, a Webhook endpoint might use `https://example.com/push`.
   */
  pushEndpoint: string;
  /**
   * Optional. Endpoint configuration attributes that can be used to control
   * different aspects of the message delivery.
   *
   * The only currently supported attribute is `x-goog-version`, which you can
   * use to change the format of the pushed message. This attribute
   * indicates the version of the data expected by the endpoint. This
   * controls the shape of the pushed message (i.e., its fields and metadata).
   *
   * If not present during the `CreateSubscription` call, it will default to
   * the version of the Pub/Sub API used to make such call. If not present in a
   * `ModifyPushConfig` call, its value will not be changed. `GetSubscription`
   * calls will always return a valid version, even if the subscription was
   * created without this attribute.
   *
   * The only supported values for the `x-goog-version` attribute are:
   *
   * * `v1beta1`: uses the push format defined in the v1beta1 Pub/Sub API.
   * * `v1` or `v1beta2`: uses the push format defined in the v1 Pub/Sub API.
   *
   * For example:
   * `attributes { "x-goog-version": "v1" }`
   */
  attributes: { [key: string]: string };
  /**
   * Optional. If specified, Pub/Sub will generate and attach an OIDC JWT
   * token as an `Authorization` header in the HTTP request for every pushed
   * message.
   */
  oidcToken?:
    | PushConfig_OidcToken
    | undefined;
  /**
   * Optional. When set, the payload to the push endpoint is in the form of
   * the JSON representation of a PubsubMessage
   * (https://cloud.google.com/pubsub/docs/reference/rpc/google.pubsub.v1#pubsubmessage).
   */
  pubsubWrapper?:
    | PushConfig_PubsubWrapper
    | undefined;
  /** Optional. When set, the payload to the push endpoint is not wrapped. */
  noWrapper?: PushConfig_NoWrapper | undefined;
}

/**
 * Contains information needed for generating an
 * [OpenID Connect
 * token](https://developers.google.com/identity/protocols/OpenIDConnect).
 */
export interface PushConfig_OidcToken {
  /**
   * Optional. [Service account
   * email](https://cloud.google.com/iam/docs/service-accounts)
   * used for generating the OIDC token. For more information
   * on setting up authentication, see
   * [Push subscriptions](https://cloud.google.com/pubsub/docs/push).
   */
  serviceAccountEmail: string;
  /**
   * Optional. Audience to be used when generating OIDC token. The audience
   * claim identifies the recipients that the JWT is intended for. The
   * audience value is a single case-sensitive string. Having multiple values
   * (array) for the audience field is not supported. More info about the OIDC
   * JWT token audience here:
   * https://tools.ietf.org/html/rfc7519#section-4.1.3 Note: if not specified,
   * the Push endpoint URL will be used.
   */
  audience: string;
}

/**
 * The payload to the push endpoint is in the form of the JSON representation
 * of a PubsubMessage
 * (https://cloud.google.com/pubsub/docs/reference/rpc/google.pubsub.v1#pubsubmessage).
 */
export interface PushConfig_PubsubWrapper {
}

/** Sets the `data` field as the HTTP body for delivery. */
export interface PushConfig_NoWrapper {
  /**
   * Optional. When true, writes the Pub/Sub message metadata to
   * `x-goog-pubsub-<KEY>:<VAL>` headers of the HTTP request. Writes the
   * Pub/Sub message attributes to `<KEY>:<VAL>` headers of the HTTP request.
   */
  writeMetadata: boolean;
}

export interface PushConfig_AttributesEntry {
  key: string;
  value: string;
}

/** Configuration for a BigQuery subscription. */
export interface BigQueryConfig {
  /**
   * Optional. The name of the table to which to write data, of the form
   * {projectId}.{datasetId}.{tableId}
   */
  table: string;
  /**
   * Optional. When true, use the topic's schema as the columns to write to in
   * BigQuery, if it exists. `use_topic_schema` and `use_table_schema` cannot be
   * enabled at the same time.
   */
  useTopicSchema: boolean;
  /**
   * Optional. When true, write the subscription name, message_id, publish_time,
   * attributes, and ordering_key to additional columns in the table. The
   * subscription name, message_id, and publish_time fields are put in their own
   * columns while all other message properties (other than data) are written to
   * a JSON object in the attributes column.
   */
  writeMetadata: boolean;
  /**
   * Optional. When true and use_topic_schema is true, any fields that are a
   * part of the topic schema that are not part of the BigQuery table schema are
   * dropped when writing to BigQuery. Otherwise, the schemas must be kept in
   * sync and any messages with extra fields are not written and remain in the
   * subscription's backlog.
   */
  dropUnknownFields: boolean;
  /**
   * Output only. An output-only field that indicates whether or not the
   * subscription can receive messages.
   */
  state: BigQueryConfig_State;
  /**
   * Optional. When true, use the BigQuery table's schema as the columns to
   * write to in BigQuery. `use_table_schema` and `use_topic_schema` cannot be
   * enabled at the same time.
   */
  useTableSchema: boolean;
  /**
   * Optional. The service account to use to write to BigQuery. The subscription
   * creator or updater that specifies this field must have
   * `iam.serviceAccounts.actAs` permission on the service account. If not
   * specified, the Pub/Sub [service
   * agent](https://cloud.google.com/iam/docs/service-agents),
   * service-{project_number}@gcp-sa-pubsub.iam.gserviceaccount.com, is used.
   */
  serviceAccountEmail: string;
}

/** Possible states for a BigQuery subscription. */
export enum BigQueryConfig_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The subscription can actively send messages to BigQuery */
  ACTIVE = 1,
  /**
   * PERMISSION_DENIED - Cannot write to the BigQuery table because of permission denied errors.
   * This can happen if
   * - Pub/Sub SA has not been granted the [appropriate BigQuery IAM
   * permissions](https://cloud.google.com/pubsub/docs/create-subscription#assign_bigquery_service_account)
   * - bigquery.googleapis.com API is not enabled for the project
   * ([instructions](https://cloud.google.com/service-usage/docs/enable-disable))
   */
  PERMISSION_DENIED = 2,
  /** NOT_FOUND - Cannot write to the BigQuery table because it does not exist. */
  NOT_FOUND = 3,
  /** SCHEMA_MISMATCH - Cannot write to the BigQuery table due to a schema mismatch. */
  SCHEMA_MISMATCH = 4,
  /**
   * IN_TRANSIT_LOCATION_RESTRICTION - Cannot write to the destination because enforce_in_transit is set to true
   * and the destination locations are not in the allowed regions.
   */
  IN_TRANSIT_LOCATION_RESTRICTION = 5,
  UNRECOGNIZED = -1,
}

export function bigQueryConfig_StateFromJSON(object: any): BigQueryConfig_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return BigQueryConfig_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return BigQueryConfig_State.ACTIVE;
    case 2:
    case "PERMISSION_DENIED":
      return BigQueryConfig_State.PERMISSION_DENIED;
    case 3:
    case "NOT_FOUND":
      return BigQueryConfig_State.NOT_FOUND;
    case 4:
    case "SCHEMA_MISMATCH":
      return BigQueryConfig_State.SCHEMA_MISMATCH;
    case 5:
    case "IN_TRANSIT_LOCATION_RESTRICTION":
      return BigQueryConfig_State.IN_TRANSIT_LOCATION_RESTRICTION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigQueryConfig_State.UNRECOGNIZED;
  }
}

export function bigQueryConfig_StateToJSON(object: BigQueryConfig_State): string {
  switch (object) {
    case BigQueryConfig_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case BigQueryConfig_State.ACTIVE:
      return "ACTIVE";
    case BigQueryConfig_State.PERMISSION_DENIED:
      return "PERMISSION_DENIED";
    case BigQueryConfig_State.NOT_FOUND:
      return "NOT_FOUND";
    case BigQueryConfig_State.SCHEMA_MISMATCH:
      return "SCHEMA_MISMATCH";
    case BigQueryConfig_State.IN_TRANSIT_LOCATION_RESTRICTION:
      return "IN_TRANSIT_LOCATION_RESTRICTION";
    case BigQueryConfig_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Configuration for a Cloud Storage subscription. */
export interface CloudStorageConfig {
  /**
   * Required. User-provided name for the Cloud Storage bucket.
   * The bucket must be created by the user. The bucket name must be without
   * any prefix like "gs://". See the [bucket naming
   * requirements] (https://cloud.google.com/storage/docs/buckets#naming).
   */
  bucket: string;
  /**
   * Optional. User-provided prefix for Cloud Storage filename. See the [object
   * naming requirements](https://cloud.google.com/storage/docs/objects#naming).
   */
  filenamePrefix: string;
  /**
   * Optional. User-provided suffix for Cloud Storage filename. See the [object
   * naming requirements](https://cloud.google.com/storage/docs/objects#naming).
   * Must not end in "/".
   */
  filenameSuffix: string;
  /**
   * Optional. User-provided format string specifying how to represent datetimes
   * in Cloud Storage filenames. See the [datetime format
   * guidance](https://cloud.google.com/pubsub/docs/create-cloudstorage-subscription#file_names).
   */
  filenameDatetimeFormat: string;
  /**
   * Optional. If set, message data will be written to Cloud Storage in text
   * format.
   */
  textConfig?:
    | CloudStorageConfig_TextConfig
    | undefined;
  /**
   * Optional. If set, message data will be written to Cloud Storage in Avro
   * format.
   */
  avroConfig?:
    | CloudStorageConfig_AvroConfig
    | undefined;
  /**
   * Optional. The maximum duration that can elapse before a new Cloud Storage
   * file is created. Min 1 minute, max 10 minutes, default 5 minutes. May not
   * exceed the subscription's acknowledgement deadline.
   */
  maxDuration:
    | Duration
    | undefined;
  /**
   * Optional. The maximum bytes that can be written to a Cloud Storage file
   * before a new file is created. Min 1 KB, max 10 GiB. The max_bytes limit may
   * be exceeded in cases where messages are larger than the limit.
   */
  maxBytes: Long;
  /**
   * Optional. The maximum number of messages that can be written to a Cloud
   * Storage file before a new file is created. Min 1000 messages.
   */
  maxMessages: Long;
  /**
   * Output only. An output-only field that indicates whether or not the
   * subscription can receive messages.
   */
  state: CloudStorageConfig_State;
  /**
   * Optional. The service account to use to write to Cloud Storage. The
   * subscription creator or updater that specifies this field must have
   * `iam.serviceAccounts.actAs` permission on the service account. If not
   * specified, the Pub/Sub
   * [service agent](https://cloud.google.com/iam/docs/service-agents),
   * service-{project_number}@gcp-sa-pubsub.iam.gserviceaccount.com, is used.
   */
  serviceAccountEmail: string;
}

/** Possible states for a Cloud Storage subscription. */
export enum CloudStorageConfig_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - The subscription can actively send messages to Cloud Storage. */
  ACTIVE = 1,
  /**
   * PERMISSION_DENIED - Cannot write to the Cloud Storage bucket because of permission denied
   * errors.
   */
  PERMISSION_DENIED = 2,
  /** NOT_FOUND - Cannot write to the Cloud Storage bucket because it does not exist. */
  NOT_FOUND = 3,
  /**
   * IN_TRANSIT_LOCATION_RESTRICTION - Cannot write to the destination because enforce_in_transit is set to true
   * and the destination locations are not in the allowed regions.
   */
  IN_TRANSIT_LOCATION_RESTRICTION = 4,
  /**
   * SCHEMA_MISMATCH - Cannot write to the Cloud Storage bucket due to an incompatibility
   * between the topic schema and subscription settings.
   */
  SCHEMA_MISMATCH = 5,
  UNRECOGNIZED = -1,
}

export function cloudStorageConfig_StateFromJSON(object: any): CloudStorageConfig_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CloudStorageConfig_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return CloudStorageConfig_State.ACTIVE;
    case 2:
    case "PERMISSION_DENIED":
      return CloudStorageConfig_State.PERMISSION_DENIED;
    case 3:
    case "NOT_FOUND":
      return CloudStorageConfig_State.NOT_FOUND;
    case 4:
    case "IN_TRANSIT_LOCATION_RESTRICTION":
      return CloudStorageConfig_State.IN_TRANSIT_LOCATION_RESTRICTION;
    case 5:
    case "SCHEMA_MISMATCH":
      return CloudStorageConfig_State.SCHEMA_MISMATCH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudStorageConfig_State.UNRECOGNIZED;
  }
}

export function cloudStorageConfig_StateToJSON(object: CloudStorageConfig_State): string {
  switch (object) {
    case CloudStorageConfig_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CloudStorageConfig_State.ACTIVE:
      return "ACTIVE";
    case CloudStorageConfig_State.PERMISSION_DENIED:
      return "PERMISSION_DENIED";
    case CloudStorageConfig_State.NOT_FOUND:
      return "NOT_FOUND";
    case CloudStorageConfig_State.IN_TRANSIT_LOCATION_RESTRICTION:
      return "IN_TRANSIT_LOCATION_RESTRICTION";
    case CloudStorageConfig_State.SCHEMA_MISMATCH:
      return "SCHEMA_MISMATCH";
    case CloudStorageConfig_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Configuration for writing message data in text format.
 * Message payloads will be written to files as raw text, separated by a
 * newline.
 */
export interface CloudStorageConfig_TextConfig {
}

/**
 * Configuration for writing message data in Avro format.
 * Message payloads and metadata will be written to files as an Avro binary.
 */
export interface CloudStorageConfig_AvroConfig {
  /**
   * Optional. When true, write the subscription name, message_id,
   * publish_time, attributes, and ordering_key as additional fields in the
   * output. The subscription name, message_id, and publish_time fields are
   * put in their own fields while all other message properties other than
   * data (for example, an ordering_key, if present) are added as entries in
   * the attributes map.
   */
  writeMetadata: boolean;
  /**
   * Optional. When true, the output Cloud Storage file will be serialized
   * using the topic schema, if it exists.
   */
  useTopicSchema: boolean;
}

/** A message and its corresponding acknowledgment ID. */
export interface ReceivedMessage {
  /** Optional. This ID can be used to acknowledge the received message. */
  ackId: string;
  /** Optional. The message. */
  message:
    | PubsubMessage
    | undefined;
  /**
   * Optional. The approximate number of times that Pub/Sub has attempted to
   * deliver the associated message to a subscriber.
   *
   * More precisely, this is 1 + (number of NACKs) +
   * (number of ack_deadline exceeds) for this message.
   *
   * A NACK is any call to ModifyAckDeadline with a 0 deadline. An ack_deadline
   * exceeds event is whenever a message is not acknowledged within
   * ack_deadline. Note that ack_deadline is initially
   * Subscription.ackDeadlineSeconds, but may get extended automatically by
   * the client library.
   *
   * Upon the first delivery of a given message, `delivery_attempt` will have a
   * value of 1. The value is calculated at best effort and is approximate.
   *
   * If a DeadLetterPolicy is not set on the subscription, this will be 0.
   */
  deliveryAttempt: number;
}

/** Request for the GetSubscription method. */
export interface GetSubscriptionRequest {
  /**
   * Required. The name of the subscription to get.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
}

/** Request for the UpdateSubscription method. */
export interface UpdateSubscriptionRequest {
  /** Required. The updated subscription object. */
  subscription:
    | Subscription
    | undefined;
  /**
   * Required. Indicates which fields in the provided subscription to update.
   * Must be specified and non-empty.
   */
  updateMask: string[] | undefined;
}

/** Request for the `ListSubscriptions` method. */
export interface ListSubscriptionsRequest {
  /**
   * Required. The name of the project in which to list subscriptions.
   * Format is `projects/{project-id}`.
   */
  project: string;
  /** Optional. Maximum number of subscriptions to return. */
  pageSize: number;
  /**
   * Optional. The value returned by the last `ListSubscriptionsResponse`;
   * indicates that this is a continuation of a prior `ListSubscriptions` call,
   * and that the system should return the next page of data.
   */
  pageToken: string;
}

/** Response for the `ListSubscriptions` method. */
export interface ListSubscriptionsResponse {
  /** Optional. The subscriptions that match the request. */
  subscriptions: Subscription[];
  /**
   * Optional. If not empty, indicates that there may be more subscriptions that
   * match the request; this value should be passed in a new
   * `ListSubscriptionsRequest` to get more subscriptions.
   */
  nextPageToken: string;
}

/** Request for the DeleteSubscription method. */
export interface DeleteSubscriptionRequest {
  /**
   * Required. The subscription to delete.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
}

/** Request for the ModifyPushConfig method. */
export interface ModifyPushConfigRequest {
  /**
   * Required. The name of the subscription.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
  /**
   * Required. The push configuration for future deliveries.
   *
   * An empty `pushConfig` indicates that the Pub/Sub system should
   * stop pushing messages from the given subscription and allow
   * messages to be pulled and acknowledged - effectively pausing
   * the subscription if `Pull` or `StreamingPull` is not called.
   */
  pushConfig: PushConfig | undefined;
}

/** Request for the `Pull` method. */
export interface PullRequest {
  /**
   * Required. The subscription from which messages should be pulled.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
  /**
   * Optional. If this field set to true, the system will respond immediately
   * even if it there are no messages available to return in the `Pull`
   * response. Otherwise, the system may wait (for a bounded amount of time)
   * until at least one message is available, rather than returning no messages.
   * Warning: setting this field to `true` is discouraged because it adversely
   * impacts the performance of `Pull` operations. We recommend that users do
   * not set this field.
   *
   * @deprecated
   */
  returnImmediately: boolean;
  /**
   * Required. The maximum number of messages to return for this request. Must
   * be a positive integer. The Pub/Sub system may return fewer than the number
   * specified.
   */
  maxMessages: number;
}

/** Response for the `Pull` method. */
export interface PullResponse {
  /**
   * Optional. Received Pub/Sub messages. The list will be empty if there are no
   * more messages available in the backlog, or if no messages could be returned
   * before the request timeout. For JSON, the response can be entirely
   * empty. The Pub/Sub system may return fewer than the `maxMessages` requested
   * even if there are more messages available in the backlog.
   */
  receivedMessages: ReceivedMessage[];
}

/** Request for the ModifyAckDeadline method. */
export interface ModifyAckDeadlineRequest {
  /**
   * Required. The name of the subscription.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
  /** Required. List of acknowledgment IDs. */
  ackIds: string[];
  /**
   * Required. The new ack deadline with respect to the time this request was
   * sent to the Pub/Sub system. For example, if the value is 10, the new ack
   * deadline will expire 10 seconds after the `ModifyAckDeadline` call was
   * made. Specifying zero might immediately make the message available for
   * delivery to another subscriber client. This typically results in an
   * increase in the rate of message redeliveries (that is, duplicates).
   * The minimum deadline you can specify is 0 seconds.
   * The maximum deadline you can specify in a single request is 600 seconds
   * (10 minutes).
   */
  ackDeadlineSeconds: number;
}

/** Request for the Acknowledge method. */
export interface AcknowledgeRequest {
  /**
   * Required. The subscription whose message is being acknowledged.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
  /**
   * Required. The acknowledgment ID for the messages being acknowledged that
   * was returned by the Pub/Sub system in the `Pull` response. Must not be
   * empty.
   */
  ackIds: string[];
}

/**
 * Request for the `StreamingPull` streaming RPC method. This request is used to
 * establish the initial stream as well as to stream acknowledgements and ack
 * deadline modifications from the client to the server.
 */
export interface StreamingPullRequest {
  /**
   * Required. The subscription for which to initialize the new stream. This
   * must be provided in the first request on the stream, and must not be set in
   * subsequent requests from client to server.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
  /**
   * Optional. List of acknowledgement IDs for acknowledging previously received
   * messages (received on this stream or a different stream). If an ack ID has
   * expired, the corresponding message may be redelivered later. Acknowledging
   * a message more than once will not result in an error. If the
   * acknowledgement ID is malformed, the stream will be aborted with status
   * `INVALID_ARGUMENT`.
   */
  ackIds: string[];
  /**
   * Optional. The list of new ack deadlines for the IDs listed in
   * `modify_deadline_ack_ids`. The size of this list must be the same as the
   * size of `modify_deadline_ack_ids`. If it differs the stream will be aborted
   * with `INVALID_ARGUMENT`. Each element in this list is applied to the
   * element in the same position in `modify_deadline_ack_ids`. The new ack
   * deadline is with respect to the time this request was sent to the Pub/Sub
   * system. Must be >= 0. For example, if the value is 10, the new ack deadline
   * will expire 10 seconds after this request is received. If the value is 0,
   * the message is immediately made available for another streaming or
   * non-streaming pull request. If the value is < 0 (an error), the stream will
   * be aborted with status `INVALID_ARGUMENT`.
   */
  modifyDeadlineSeconds: number[];
  /**
   * Optional. List of acknowledgement IDs whose deadline will be modified based
   * on the corresponding element in `modify_deadline_seconds`. This field can
   * be used to indicate that more time is needed to process a message by the
   * subscriber, or to make the message available for redelivery if the
   * processing was interrupted.
   */
  modifyDeadlineAckIds: string[];
  /**
   * Required. The ack deadline to use for the stream. This must be provided in
   * the first request on the stream, but it can also be updated on subsequent
   * requests from client to server. The minimum deadline you can specify is 10
   * seconds. The maximum deadline you can specify is 600 seconds (10 minutes).
   */
  streamAckDeadlineSeconds: number;
  /**
   * Optional. A unique identifier that is used to distinguish client instances
   * from each other. Only needs to be provided on the initial request. When a
   * stream disconnects and reconnects for the same stream, the client_id should
   * be set to the same value so that state associated with the old stream can
   * be transferred to the new stream. The same client_id should not be used for
   * different client instances.
   */
  clientId: string;
  /**
   * Optional. Flow control settings for the maximum number of outstanding
   * messages. When there are `max_outstanding_messages` currently sent to the
   * streaming pull client that have not yet been acked or nacked, the server
   * stops sending more messages. The sending of messages resumes once the
   * number of outstanding messages is less than this value. If the value is
   * <= 0, there is no limit to the number of outstanding messages. This
   * property can only be set on the initial StreamingPullRequest. If it is set
   * on a subsequent request, the stream will be aborted with status
   * `INVALID_ARGUMENT`.
   */
  maxOutstandingMessages: Long;
  /**
   * Optional. Flow control settings for the maximum number of outstanding
   * bytes. When there are `max_outstanding_bytes` or more worth of messages
   * currently sent to the streaming pull client that have not yet been acked or
   * nacked, the server will stop sending more messages. The sending of messages
   * resumes once the number of outstanding bytes is less than this value. If
   * the value is <= 0, there is no limit to the number of outstanding bytes.
   * This property can only be set on the initial StreamingPullRequest. If it is
   * set on a subsequent request, the stream will be aborted with status
   * `INVALID_ARGUMENT`.
   */
  maxOutstandingBytes: Long;
}

/**
 * Response for the `StreamingPull` method. This response is used to stream
 * messages from the server to the client.
 */
export interface StreamingPullResponse {
  /** Optional. Received Pub/Sub messages. This will not be empty. */
  receivedMessages: ReceivedMessage[];
  /**
   * Optional. This field will only be set if `enable_exactly_once_delivery` is
   * set to `true`.
   */
  acknowledgeConfirmation:
    | StreamingPullResponse_AcknowledgeConfirmation
    | undefined;
  /**
   * Optional. This field will only be set if `enable_exactly_once_delivery` is
   * set to `true`.
   */
  modifyAckDeadlineConfirmation:
    | StreamingPullResponse_ModifyAckDeadlineConfirmation
    | undefined;
  /** Optional. Properties associated with this subscription. */
  subscriptionProperties: StreamingPullResponse_SubscriptionProperties | undefined;
}

/**
 * Acknowledgement IDs sent in one or more previous requests to acknowledge a
 * previously received message.
 */
export interface StreamingPullResponse_AcknowledgeConfirmation {
  /** Optional. Successfully processed acknowledgement IDs. */
  ackIds: string[];
  /**
   * Optional. List of acknowledgement IDs that were malformed or whose
   * acknowledgement deadline has expired.
   */
  invalidAckIds: string[];
  /** Optional. List of acknowledgement IDs that were out of order. */
  unorderedAckIds: string[];
  /**
   * Optional. List of acknowledgement IDs that failed processing with
   * temporary issues.
   */
  temporaryFailedAckIds: string[];
}

/**
 * Acknowledgement IDs sent in one or more previous requests to modify the
 * deadline for a specific message.
 */
export interface StreamingPullResponse_ModifyAckDeadlineConfirmation {
  /** Optional. Successfully processed acknowledgement IDs. */
  ackIds: string[];
  /**
   * Optional. List of acknowledgement IDs that were malformed or whose
   * acknowledgement deadline has expired.
   */
  invalidAckIds: string[];
  /**
   * Optional. List of acknowledgement IDs that failed processing with
   * temporary issues.
   */
  temporaryFailedAckIds: string[];
}

/** Subscription properties sent as part of the response. */
export interface StreamingPullResponse_SubscriptionProperties {
  /**
   * Optional. True iff exactly once delivery is enabled for this
   * subscription.
   */
  exactlyOnceDeliveryEnabled: boolean;
  /** Optional. True iff message ordering is enabled for this subscription. */
  messageOrderingEnabled: boolean;
}

/** Request for the `CreateSnapshot` method. */
export interface CreateSnapshotRequest {
  /**
   * Required. User-provided name for this snapshot. If the name is not provided
   * in the request, the server will assign a random name for this snapshot on
   * the same project as the subscription. Note that for REST API requests, you
   * must specify a name.  See the [resource name
   * rules](https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
   * Format is `projects/{project}/snapshots/{snap}`.
   */
  name: string;
  /**
   * Required. The subscription whose backlog the snapshot retains.
   * Specifically, the created snapshot is guaranteed to retain:
   *  (a) The existing backlog on the subscription. More precisely, this is
   *      defined as the messages in the subscription's backlog that are
   *      unacknowledged upon the successful completion of the
   *      `CreateSnapshot` request; as well as:
   *  (b) Any messages published to the subscription's topic following the
   *      successful completion of the CreateSnapshot request.
   * Format is `projects/{project}/subscriptions/{sub}`.
   */
  subscription: string;
  /**
   * Optional. See [Creating and managing
   * labels](https://cloud.google.com/pubsub/docs/labels).
   */
  labels: { [key: string]: string };
}

export interface CreateSnapshotRequest_LabelsEntry {
  key: string;
  value: string;
}

/** Request for the UpdateSnapshot method. */
export interface UpdateSnapshotRequest {
  /** Required. The updated snapshot object. */
  snapshot:
    | Snapshot
    | undefined;
  /**
   * Required. Indicates which fields in the provided snapshot to update.
   * Must be specified and non-empty.
   */
  updateMask: string[] | undefined;
}

/**
 * A snapshot resource. Snapshots are used in
 * [Seek](https://cloud.google.com/pubsub/docs/replay-overview)
 * operations, which allow you to manage message acknowledgments in bulk. That
 * is, you can set the acknowledgment state of messages in an existing
 * subscription to the state captured by a snapshot.
 */
export interface Snapshot {
  /** Optional. The name of the snapshot. */
  name: string;
  /**
   * Optional. The name of the topic from which this snapshot is retaining
   * messages.
   */
  topic: string;
  /**
   * Optional. The snapshot is guaranteed to exist up until this time.
   * A newly-created snapshot expires no later than 7 days from the time of its
   * creation. Its exact lifetime is determined at creation by the existing
   * backlog in the source subscription. Specifically, the lifetime of the
   * snapshot is `7 days - (age of oldest unacked message in the subscription)`.
   * For example, consider a subscription whose oldest unacked message is 3 days
   * old. If a snapshot is created from this subscription, the snapshot -- which
   * will always capture this 3-day-old backlog as long as the snapshot
   * exists -- will expire in 4 days. The service will refuse to create a
   * snapshot that would expire in less than 1 hour after creation.
   */
  expireTime:
    | Date
    | undefined;
  /**
   * Optional. See [Creating and managing labels]
   * (https://cloud.google.com/pubsub/docs/labels).
   */
  labels: { [key: string]: string };
}

export interface Snapshot_LabelsEntry {
  key: string;
  value: string;
}

/** Request for the GetSnapshot method. */
export interface GetSnapshotRequest {
  /**
   * Required. The name of the snapshot to get.
   * Format is `projects/{project}/snapshots/{snap}`.
   */
  snapshot: string;
}

/** Request for the `ListSnapshots` method. */
export interface ListSnapshotsRequest {
  /**
   * Required. The name of the project in which to list snapshots.
   * Format is `projects/{project-id}`.
   */
  project: string;
  /** Optional. Maximum number of snapshots to return. */
  pageSize: number;
  /**
   * Optional. The value returned by the last `ListSnapshotsResponse`; indicates
   * that this is a continuation of a prior `ListSnapshots` call, and that the
   * system should return the next page of data.
   */
  pageToken: string;
}

/** Response for the `ListSnapshots` method. */
export interface ListSnapshotsResponse {
  /** Optional. The resulting snapshots. */
  snapshots: Snapshot[];
  /**
   * Optional. If not empty, indicates that there may be more snapshot that
   * match the request; this value should be passed in a new
   * `ListSnapshotsRequest`.
   */
  nextPageToken: string;
}

/** Request for the `DeleteSnapshot` method. */
export interface DeleteSnapshotRequest {
  /**
   * Required. The name of the snapshot to delete.
   * Format is `projects/{project}/snapshots/{snap}`.
   */
  snapshot: string;
}

/** Request for the `Seek` method. */
export interface SeekRequest {
  /** Required. The subscription to affect. */
  subscription: string;
  /**
   * Optional. The time to seek to.
   * Messages retained in the subscription that were published before this
   * time are marked as acknowledged, and messages retained in the
   * subscription that were published after this time are marked as
   * unacknowledged. Note that this operation affects only those messages
   * retained in the subscription (configured by the combination of
   * `message_retention_duration` and `retain_acked_messages`). For example,
   * if `time` corresponds to a point before the message retention
   * window (or to a point before the system's notion of the subscription
   * creation time), only retained messages will be marked as unacknowledged,
   * and already-expunged messages will not be restored.
   */
  time?:
    | Date
    | undefined;
  /**
   * Optional. The snapshot to seek to. The snapshot's topic must be the same
   * as that of the provided subscription. Format is
   * `projects/{project}/snapshots/{snap}`.
   */
  snapshot?: string | undefined;
}

/** Response for the `Seek` method (this response is empty). */
export interface SeekResponse {
}

function createBaseMessageStoragePolicy(): MessageStoragePolicy {
  return { allowedPersistenceRegions: [], enforceInTransit: false };
}

export const MessageStoragePolicy: MessageFns<MessageStoragePolicy> = {
  encode(message: MessageStoragePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.allowedPersistenceRegions) {
      writer.uint32(10).string(v!);
    }
    if (message.enforceInTransit !== false) {
      writer.uint32(16).bool(message.enforceInTransit);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MessageStoragePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMessageStoragePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.allowedPersistenceRegions.push(reader.string());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.enforceInTransit = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MessageStoragePolicy {
    return {
      allowedPersistenceRegions: globalThis.Array.isArray(object?.allowedPersistenceRegions)
        ? object.allowedPersistenceRegions.map((e: any) => globalThis.String(e))
        : [],
      enforceInTransit: isSet(object.enforceInTransit) ? globalThis.Boolean(object.enforceInTransit) : false,
    };
  },

  toJSON(message: MessageStoragePolicy): unknown {
    const obj: any = {};
    if (message.allowedPersistenceRegions?.length) {
      obj.allowedPersistenceRegions = message.allowedPersistenceRegions;
    }
    if (message.enforceInTransit !== false) {
      obj.enforceInTransit = message.enforceInTransit;
    }
    return obj;
  },

  create(base?: DeepPartial<MessageStoragePolicy>): MessageStoragePolicy {
    return MessageStoragePolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MessageStoragePolicy>): MessageStoragePolicy {
    const message = createBaseMessageStoragePolicy();
    message.allowedPersistenceRegions = object.allowedPersistenceRegions?.map((e) => e) || [];
    message.enforceInTransit = object.enforceInTransit ?? false;
    return message;
  },
};

function createBaseSchemaSettings(): SchemaSettings {
  return { schema: "", encoding: 0, firstRevisionId: "", lastRevisionId: "" };
}

export const SchemaSettings: MessageFns<SchemaSettings> = {
  encode(message: SchemaSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schema !== "") {
      writer.uint32(10).string(message.schema);
    }
    if (message.encoding !== 0) {
      writer.uint32(16).int32(message.encoding);
    }
    if (message.firstRevisionId !== "") {
      writer.uint32(26).string(message.firstRevisionId);
    }
    if (message.lastRevisionId !== "") {
      writer.uint32(34).string(message.lastRevisionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SchemaSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchemaSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schema = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encoding = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.firstRevisionId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lastRevisionId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SchemaSettings {
    return {
      schema: isSet(object.schema) ? globalThis.String(object.schema) : "",
      encoding: isSet(object.encoding) ? encodingFromJSON(object.encoding) : 0,
      firstRevisionId: isSet(object.firstRevisionId) ? globalThis.String(object.firstRevisionId) : "",
      lastRevisionId: isSet(object.lastRevisionId) ? globalThis.String(object.lastRevisionId) : "",
    };
  },

  toJSON(message: SchemaSettings): unknown {
    const obj: any = {};
    if (message.schema !== "") {
      obj.schema = message.schema;
    }
    if (message.encoding !== 0) {
      obj.encoding = encodingToJSON(message.encoding);
    }
    if (message.firstRevisionId !== "") {
      obj.firstRevisionId = message.firstRevisionId;
    }
    if (message.lastRevisionId !== "") {
      obj.lastRevisionId = message.lastRevisionId;
    }
    return obj;
  },

  create(base?: DeepPartial<SchemaSettings>): SchemaSettings {
    return SchemaSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SchemaSettings>): SchemaSettings {
    const message = createBaseSchemaSettings();
    message.schema = object.schema ?? "";
    message.encoding = object.encoding ?? 0;
    message.firstRevisionId = object.firstRevisionId ?? "";
    message.lastRevisionId = object.lastRevisionId ?? "";
    return message;
  },
};

function createBaseIngestionDataSourceSettings(): IngestionDataSourceSettings {
  return { awsKinesis: undefined, cloudStorage: undefined, platformLogsSettings: undefined };
}

export const IngestionDataSourceSettings: MessageFns<IngestionDataSourceSettings> = {
  encode(message: IngestionDataSourceSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.awsKinesis !== undefined) {
      IngestionDataSourceSettings_AwsKinesis.encode(message.awsKinesis, writer.uint32(10).fork()).join();
    }
    if (message.cloudStorage !== undefined) {
      IngestionDataSourceSettings_CloudStorage.encode(message.cloudStorage, writer.uint32(18).fork()).join();
    }
    if (message.platformLogsSettings !== undefined) {
      PlatformLogsSettings.encode(message.platformLogsSettings, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionDataSourceSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionDataSourceSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.awsKinesis = IngestionDataSourceSettings_AwsKinesis.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cloudStorage = IngestionDataSourceSettings_CloudStorage.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.platformLogsSettings = PlatformLogsSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionDataSourceSettings {
    return {
      awsKinesis: isSet(object.awsKinesis)
        ? IngestionDataSourceSettings_AwsKinesis.fromJSON(object.awsKinesis)
        : undefined,
      cloudStorage: isSet(object.cloudStorage)
        ? IngestionDataSourceSettings_CloudStorage.fromJSON(object.cloudStorage)
        : undefined,
      platformLogsSettings: isSet(object.platformLogsSettings)
        ? PlatformLogsSettings.fromJSON(object.platformLogsSettings)
        : undefined,
    };
  },

  toJSON(message: IngestionDataSourceSettings): unknown {
    const obj: any = {};
    if (message.awsKinesis !== undefined) {
      obj.awsKinesis = IngestionDataSourceSettings_AwsKinesis.toJSON(message.awsKinesis);
    }
    if (message.cloudStorage !== undefined) {
      obj.cloudStorage = IngestionDataSourceSettings_CloudStorage.toJSON(message.cloudStorage);
    }
    if (message.platformLogsSettings !== undefined) {
      obj.platformLogsSettings = PlatformLogsSettings.toJSON(message.platformLogsSettings);
    }
    return obj;
  },

  create(base?: DeepPartial<IngestionDataSourceSettings>): IngestionDataSourceSettings {
    return IngestionDataSourceSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IngestionDataSourceSettings>): IngestionDataSourceSettings {
    const message = createBaseIngestionDataSourceSettings();
    message.awsKinesis = (object.awsKinesis !== undefined && object.awsKinesis !== null)
      ? IngestionDataSourceSettings_AwsKinesis.fromPartial(object.awsKinesis)
      : undefined;
    message.cloudStorage = (object.cloudStorage !== undefined && object.cloudStorage !== null)
      ? IngestionDataSourceSettings_CloudStorage.fromPartial(object.cloudStorage)
      : undefined;
    message.platformLogsSettings = (object.platformLogsSettings !== undefined && object.platformLogsSettings !== null)
      ? PlatformLogsSettings.fromPartial(object.platformLogsSettings)
      : undefined;
    return message;
  },
};

function createBaseIngestionDataSourceSettings_AwsKinesis(): IngestionDataSourceSettings_AwsKinesis {
  return { state: 0, streamArn: "", consumerArn: "", awsRoleArn: "", gcpServiceAccount: "" };
}

export const IngestionDataSourceSettings_AwsKinesis: MessageFns<IngestionDataSourceSettings_AwsKinesis> = {
  encode(message: IngestionDataSourceSettings_AwsKinesis, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.streamArn !== "") {
      writer.uint32(18).string(message.streamArn);
    }
    if (message.consumerArn !== "") {
      writer.uint32(26).string(message.consumerArn);
    }
    if (message.awsRoleArn !== "") {
      writer.uint32(34).string(message.awsRoleArn);
    }
    if (message.gcpServiceAccount !== "") {
      writer.uint32(42).string(message.gcpServiceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionDataSourceSettings_AwsKinesis {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionDataSourceSettings_AwsKinesis();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.streamArn = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.consumerArn = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.awsRoleArn = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.gcpServiceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionDataSourceSettings_AwsKinesis {
    return {
      state: isSet(object.state) ? ingestionDataSourceSettings_AwsKinesis_StateFromJSON(object.state) : 0,
      streamArn: isSet(object.streamArn) ? globalThis.String(object.streamArn) : "",
      consumerArn: isSet(object.consumerArn) ? globalThis.String(object.consumerArn) : "",
      awsRoleArn: isSet(object.awsRoleArn) ? globalThis.String(object.awsRoleArn) : "",
      gcpServiceAccount: isSet(object.gcpServiceAccount) ? globalThis.String(object.gcpServiceAccount) : "",
    };
  },

  toJSON(message: IngestionDataSourceSettings_AwsKinesis): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = ingestionDataSourceSettings_AwsKinesis_StateToJSON(message.state);
    }
    if (message.streamArn !== "") {
      obj.streamArn = message.streamArn;
    }
    if (message.consumerArn !== "") {
      obj.consumerArn = message.consumerArn;
    }
    if (message.awsRoleArn !== "") {
      obj.awsRoleArn = message.awsRoleArn;
    }
    if (message.gcpServiceAccount !== "") {
      obj.gcpServiceAccount = message.gcpServiceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<IngestionDataSourceSettings_AwsKinesis>): IngestionDataSourceSettings_AwsKinesis {
    return IngestionDataSourceSettings_AwsKinesis.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IngestionDataSourceSettings_AwsKinesis>): IngestionDataSourceSettings_AwsKinesis {
    const message = createBaseIngestionDataSourceSettings_AwsKinesis();
    message.state = object.state ?? 0;
    message.streamArn = object.streamArn ?? "";
    message.consumerArn = object.consumerArn ?? "";
    message.awsRoleArn = object.awsRoleArn ?? "";
    message.gcpServiceAccount = object.gcpServiceAccount ?? "";
    return message;
  },
};

function createBaseIngestionDataSourceSettings_CloudStorage(): IngestionDataSourceSettings_CloudStorage {
  return {
    state: 0,
    bucket: "",
    textFormat: undefined,
    avroFormat: undefined,
    pubsubAvroFormat: undefined,
    minimumObjectCreateTime: undefined,
    matchGlob: "",
  };
}

export const IngestionDataSourceSettings_CloudStorage: MessageFns<IngestionDataSourceSettings_CloudStorage> = {
  encode(message: IngestionDataSourceSettings_CloudStorage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.bucket !== "") {
      writer.uint32(18).string(message.bucket);
    }
    if (message.textFormat !== undefined) {
      IngestionDataSourceSettings_CloudStorage_TextFormat.encode(message.textFormat, writer.uint32(26).fork()).join();
    }
    if (message.avroFormat !== undefined) {
      IngestionDataSourceSettings_CloudStorage_AvroFormat.encode(message.avroFormat, writer.uint32(34).fork()).join();
    }
    if (message.pubsubAvroFormat !== undefined) {
      IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat.encode(
        message.pubsubAvroFormat,
        writer.uint32(42).fork(),
      ).join();
    }
    if (message.minimumObjectCreateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.minimumObjectCreateTime), writer.uint32(50).fork()).join();
    }
    if (message.matchGlob !== "") {
      writer.uint32(74).string(message.matchGlob);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionDataSourceSettings_CloudStorage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionDataSourceSettings_CloudStorage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.textFormat = IngestionDataSourceSettings_CloudStorage_TextFormat.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.avroFormat = IngestionDataSourceSettings_CloudStorage_AvroFormat.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pubsubAvroFormat = IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.minimumObjectCreateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.matchGlob = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionDataSourceSettings_CloudStorage {
    return {
      state: isSet(object.state) ? ingestionDataSourceSettings_CloudStorage_StateFromJSON(object.state) : 0,
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      textFormat: isSet(object.textFormat)
        ? IngestionDataSourceSettings_CloudStorage_TextFormat.fromJSON(object.textFormat)
        : undefined,
      avroFormat: isSet(object.avroFormat)
        ? IngestionDataSourceSettings_CloudStorage_AvroFormat.fromJSON(object.avroFormat)
        : undefined,
      pubsubAvroFormat: isSet(object.pubsubAvroFormat)
        ? IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat.fromJSON(object.pubsubAvroFormat)
        : undefined,
      minimumObjectCreateTime: isSet(object.minimumObjectCreateTime)
        ? fromJsonTimestamp(object.minimumObjectCreateTime)
        : undefined,
      matchGlob: isSet(object.matchGlob) ? globalThis.String(object.matchGlob) : "",
    };
  },

  toJSON(message: IngestionDataSourceSettings_CloudStorage): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = ingestionDataSourceSettings_CloudStorage_StateToJSON(message.state);
    }
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.textFormat !== undefined) {
      obj.textFormat = IngestionDataSourceSettings_CloudStorage_TextFormat.toJSON(message.textFormat);
    }
    if (message.avroFormat !== undefined) {
      obj.avroFormat = IngestionDataSourceSettings_CloudStorage_AvroFormat.toJSON(message.avroFormat);
    }
    if (message.pubsubAvroFormat !== undefined) {
      obj.pubsubAvroFormat = IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat.toJSON(message.pubsubAvroFormat);
    }
    if (message.minimumObjectCreateTime !== undefined) {
      obj.minimumObjectCreateTime = message.minimumObjectCreateTime.toISOString();
    }
    if (message.matchGlob !== "") {
      obj.matchGlob = message.matchGlob;
    }
    return obj;
  },

  create(base?: DeepPartial<IngestionDataSourceSettings_CloudStorage>): IngestionDataSourceSettings_CloudStorage {
    return IngestionDataSourceSettings_CloudStorage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IngestionDataSourceSettings_CloudStorage>): IngestionDataSourceSettings_CloudStorage {
    const message = createBaseIngestionDataSourceSettings_CloudStorage();
    message.state = object.state ?? 0;
    message.bucket = object.bucket ?? "";
    message.textFormat = (object.textFormat !== undefined && object.textFormat !== null)
      ? IngestionDataSourceSettings_CloudStorage_TextFormat.fromPartial(object.textFormat)
      : undefined;
    message.avroFormat = (object.avroFormat !== undefined && object.avroFormat !== null)
      ? IngestionDataSourceSettings_CloudStorage_AvroFormat.fromPartial(object.avroFormat)
      : undefined;
    message.pubsubAvroFormat = (object.pubsubAvroFormat !== undefined && object.pubsubAvroFormat !== null)
      ? IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat.fromPartial(object.pubsubAvroFormat)
      : undefined;
    message.minimumObjectCreateTime = object.minimumObjectCreateTime ?? undefined;
    message.matchGlob = object.matchGlob ?? "";
    return message;
  },
};

function createBaseIngestionDataSourceSettings_CloudStorage_TextFormat(): IngestionDataSourceSettings_CloudStorage_TextFormat {
  return { delimiter: undefined };
}

export const IngestionDataSourceSettings_CloudStorage_TextFormat: MessageFns<
  IngestionDataSourceSettings_CloudStorage_TextFormat
> = {
  encode(
    message: IngestionDataSourceSettings_CloudStorage_TextFormat,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.delimiter !== undefined) {
      writer.uint32(10).string(message.delimiter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionDataSourceSettings_CloudStorage_TextFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionDataSourceSettings_CloudStorage_TextFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.delimiter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionDataSourceSettings_CloudStorage_TextFormat {
    return { delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : undefined };
  },

  toJSON(message: IngestionDataSourceSettings_CloudStorage_TextFormat): unknown {
    const obj: any = {};
    if (message.delimiter !== undefined) {
      obj.delimiter = message.delimiter;
    }
    return obj;
  },

  create(
    base?: DeepPartial<IngestionDataSourceSettings_CloudStorage_TextFormat>,
  ): IngestionDataSourceSettings_CloudStorage_TextFormat {
    return IngestionDataSourceSettings_CloudStorage_TextFormat.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<IngestionDataSourceSettings_CloudStorage_TextFormat>,
  ): IngestionDataSourceSettings_CloudStorage_TextFormat {
    const message = createBaseIngestionDataSourceSettings_CloudStorage_TextFormat();
    message.delimiter = object.delimiter ?? undefined;
    return message;
  },
};

function createBaseIngestionDataSourceSettings_CloudStorage_AvroFormat(): IngestionDataSourceSettings_CloudStorage_AvroFormat {
  return {};
}

export const IngestionDataSourceSettings_CloudStorage_AvroFormat: MessageFns<
  IngestionDataSourceSettings_CloudStorage_AvroFormat
> = {
  encode(
    _: IngestionDataSourceSettings_CloudStorage_AvroFormat,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionDataSourceSettings_CloudStorage_AvroFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionDataSourceSettings_CloudStorage_AvroFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): IngestionDataSourceSettings_CloudStorage_AvroFormat {
    return {};
  },

  toJSON(_: IngestionDataSourceSettings_CloudStorage_AvroFormat): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<IngestionDataSourceSettings_CloudStorage_AvroFormat>,
  ): IngestionDataSourceSettings_CloudStorage_AvroFormat {
    return IngestionDataSourceSettings_CloudStorage_AvroFormat.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<IngestionDataSourceSettings_CloudStorage_AvroFormat>,
  ): IngestionDataSourceSettings_CloudStorage_AvroFormat {
    const message = createBaseIngestionDataSourceSettings_CloudStorage_AvroFormat();
    return message;
  },
};

function createBaseIngestionDataSourceSettings_CloudStorage_PubSubAvroFormat(): IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat {
  return {};
}

export const IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat: MessageFns<
  IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat
> = {
  encode(
    _: IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionDataSourceSettings_CloudStorage_PubSubAvroFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat {
    return {};
  },

  toJSON(_: IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat>,
  ): IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat {
    return IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat>,
  ): IngestionDataSourceSettings_CloudStorage_PubSubAvroFormat {
    const message = createBaseIngestionDataSourceSettings_CloudStorage_PubSubAvroFormat();
    return message;
  },
};

function createBasePlatformLogsSettings(): PlatformLogsSettings {
  return { severity: 0 };
}

export const PlatformLogsSettings: MessageFns<PlatformLogsSettings> = {
  encode(message: PlatformLogsSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.severity !== 0) {
      writer.uint32(8).int32(message.severity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PlatformLogsSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePlatformLogsSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.severity = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PlatformLogsSettings {
    return { severity: isSet(object.severity) ? platformLogsSettings_SeverityFromJSON(object.severity) : 0 };
  },

  toJSON(message: PlatformLogsSettings): unknown {
    const obj: any = {};
    if (message.severity !== 0) {
      obj.severity = platformLogsSettings_SeverityToJSON(message.severity);
    }
    return obj;
  },

  create(base?: DeepPartial<PlatformLogsSettings>): PlatformLogsSettings {
    return PlatformLogsSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PlatformLogsSettings>): PlatformLogsSettings {
    const message = createBasePlatformLogsSettings();
    message.severity = object.severity ?? 0;
    return message;
  },
};

function createBaseTopic(): Topic {
  return {
    name: "",
    labels: {},
    messageStoragePolicy: undefined,
    kmsKeyName: "",
    schemaSettings: undefined,
    satisfiesPzs: false,
    messageRetentionDuration: undefined,
    state: 0,
    ingestionDataSourceSettings: undefined,
  };
}

export const Topic: MessageFns<Topic> = {
  encode(message: Topic, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Topic_LabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.messageStoragePolicy !== undefined) {
      MessageStoragePolicy.encode(message.messageStoragePolicy, writer.uint32(26).fork()).join();
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(42).string(message.kmsKeyName);
    }
    if (message.schemaSettings !== undefined) {
      SchemaSettings.encode(message.schemaSettings, writer.uint32(50).fork()).join();
    }
    if (message.satisfiesPzs !== false) {
      writer.uint32(56).bool(message.satisfiesPzs);
    }
    if (message.messageRetentionDuration !== undefined) {
      Duration.encode(message.messageRetentionDuration, writer.uint32(66).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(72).int32(message.state);
    }
    if (message.ingestionDataSourceSettings !== undefined) {
      IngestionDataSourceSettings.encode(message.ingestionDataSourceSettings, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Topic {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTopic();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = Topic_LabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.labels[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.messageStoragePolicy = MessageStoragePolicy.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.schemaSettings = SchemaSettings.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.messageRetentionDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.ingestionDataSourceSettings = IngestionDataSourceSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Topic {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      messageStoragePolicy: isSet(object.messageStoragePolicy)
        ? MessageStoragePolicy.fromJSON(object.messageStoragePolicy)
        : undefined,
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      schemaSettings: isSet(object.schemaSettings) ? SchemaSettings.fromJSON(object.schemaSettings) : undefined,
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : false,
      messageRetentionDuration: isSet(object.messageRetentionDuration)
        ? Duration.fromJSON(object.messageRetentionDuration)
        : undefined,
      state: isSet(object.state) ? topic_StateFromJSON(object.state) : 0,
      ingestionDataSourceSettings: isSet(object.ingestionDataSourceSettings)
        ? IngestionDataSourceSettings.fromJSON(object.ingestionDataSourceSettings)
        : undefined,
    };
  },

  toJSON(message: Topic): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.messageStoragePolicy !== undefined) {
      obj.messageStoragePolicy = MessageStoragePolicy.toJSON(message.messageStoragePolicy);
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.schemaSettings !== undefined) {
      obj.schemaSettings = SchemaSettings.toJSON(message.schemaSettings);
    }
    if (message.satisfiesPzs !== false) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.messageRetentionDuration !== undefined) {
      obj.messageRetentionDuration = Duration.toJSON(message.messageRetentionDuration);
    }
    if (message.state !== 0) {
      obj.state = topic_StateToJSON(message.state);
    }
    if (message.ingestionDataSourceSettings !== undefined) {
      obj.ingestionDataSourceSettings = IngestionDataSourceSettings.toJSON(message.ingestionDataSourceSettings);
    }
    return obj;
  },

  create(base?: DeepPartial<Topic>): Topic {
    return Topic.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Topic>): Topic {
    const message = createBaseTopic();
    message.name = object.name ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.messageStoragePolicy = (object.messageStoragePolicy !== undefined && object.messageStoragePolicy !== null)
      ? MessageStoragePolicy.fromPartial(object.messageStoragePolicy)
      : undefined;
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.schemaSettings = (object.schemaSettings !== undefined && object.schemaSettings !== null)
      ? SchemaSettings.fromPartial(object.schemaSettings)
      : undefined;
    message.satisfiesPzs = object.satisfiesPzs ?? false;
    message.messageRetentionDuration =
      (object.messageRetentionDuration !== undefined && object.messageRetentionDuration !== null)
        ? Duration.fromPartial(object.messageRetentionDuration)
        : undefined;
    message.state = object.state ?? 0;
    message.ingestionDataSourceSettings =
      (object.ingestionDataSourceSettings !== undefined && object.ingestionDataSourceSettings !== null)
        ? IngestionDataSourceSettings.fromPartial(object.ingestionDataSourceSettings)
        : undefined;
    return message;
  },
};

function createBaseTopic_LabelsEntry(): Topic_LabelsEntry {
  return { key: "", value: "" };
}

export const Topic_LabelsEntry: MessageFns<Topic_LabelsEntry> = {
  encode(message: Topic_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Topic_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTopic_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Topic_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Topic_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Topic_LabelsEntry>): Topic_LabelsEntry {
    return Topic_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Topic_LabelsEntry>): Topic_LabelsEntry {
    const message = createBaseTopic_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePubsubMessage(): PubsubMessage {
  return { data: Buffer.alloc(0), attributes: {}, messageId: "", publishTime: undefined, orderingKey: "" };
}

export const PubsubMessage: MessageFns<PubsubMessage> = {
  encode(message: PubsubMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.data.length !== 0) {
      writer.uint32(10).bytes(message.data);
    }
    Object.entries(message.attributes).forEach(([key, value]) => {
      PubsubMessage_AttributesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.messageId !== "") {
      writer.uint32(26).string(message.messageId);
    }
    if (message.publishTime !== undefined) {
      Timestamp.encode(toTimestamp(message.publishTime), writer.uint32(34).fork()).join();
    }
    if (message.orderingKey !== "") {
      writer.uint32(42).string(message.orderingKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PubsubMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePubsubMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.data = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = PubsubMessage_AttributesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.attributes[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.messageId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.publishTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderingKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PubsubMessage {
    return {
      data: isSet(object.data) ? Buffer.from(bytesFromBase64(object.data)) : Buffer.alloc(0),
      attributes: isObject(object.attributes)
        ? Object.entries(object.attributes).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      messageId: isSet(object.messageId) ? globalThis.String(object.messageId) : "",
      publishTime: isSet(object.publishTime) ? fromJsonTimestamp(object.publishTime) : undefined,
      orderingKey: isSet(object.orderingKey) ? globalThis.String(object.orderingKey) : "",
    };
  },

  toJSON(message: PubsubMessage): unknown {
    const obj: any = {};
    if (message.data.length !== 0) {
      obj.data = base64FromBytes(message.data);
    }
    if (message.attributes) {
      const entries = Object.entries(message.attributes);
      if (entries.length > 0) {
        obj.attributes = {};
        entries.forEach(([k, v]) => {
          obj.attributes[k] = v;
        });
      }
    }
    if (message.messageId !== "") {
      obj.messageId = message.messageId;
    }
    if (message.publishTime !== undefined) {
      obj.publishTime = message.publishTime.toISOString();
    }
    if (message.orderingKey !== "") {
      obj.orderingKey = message.orderingKey;
    }
    return obj;
  },

  create(base?: DeepPartial<PubsubMessage>): PubsubMessage {
    return PubsubMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PubsubMessage>): PubsubMessage {
    const message = createBasePubsubMessage();
    message.data = object.data ?? Buffer.alloc(0);
    message.attributes = Object.entries(object.attributes ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.messageId = object.messageId ?? "";
    message.publishTime = object.publishTime ?? undefined;
    message.orderingKey = object.orderingKey ?? "";
    return message;
  },
};

function createBasePubsubMessage_AttributesEntry(): PubsubMessage_AttributesEntry {
  return { key: "", value: "" };
}

export const PubsubMessage_AttributesEntry: MessageFns<PubsubMessage_AttributesEntry> = {
  encode(message: PubsubMessage_AttributesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PubsubMessage_AttributesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePubsubMessage_AttributesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PubsubMessage_AttributesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PubsubMessage_AttributesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<PubsubMessage_AttributesEntry>): PubsubMessage_AttributesEntry {
    return PubsubMessage_AttributesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PubsubMessage_AttributesEntry>): PubsubMessage_AttributesEntry {
    const message = createBasePubsubMessage_AttributesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseGetTopicRequest(): GetTopicRequest {
  return { topic: "" };
}

export const GetTopicRequest: MessageFns<GetTopicRequest> = {
  encode(message: GetTopicRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTopicRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTopicRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetTopicRequest {
    return { topic: isSet(object.topic) ? globalThis.String(object.topic) : "" };
  },

  toJSON(message: GetTopicRequest): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    return obj;
  },

  create(base?: DeepPartial<GetTopicRequest>): GetTopicRequest {
    return GetTopicRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetTopicRequest>): GetTopicRequest {
    const message = createBaseGetTopicRequest();
    message.topic = object.topic ?? "";
    return message;
  },
};

function createBaseUpdateTopicRequest(): UpdateTopicRequest {
  return { topic: undefined, updateMask: undefined };
}

export const UpdateTopicRequest: MessageFns<UpdateTopicRequest> = {
  encode(message: UpdateTopicRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== undefined) {
      Topic.encode(message.topic, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateTopicRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateTopicRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = Topic.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateTopicRequest {
    return {
      topic: isSet(object.topic) ? Topic.fromJSON(object.topic) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateTopicRequest): unknown {
    const obj: any = {};
    if (message.topic !== undefined) {
      obj.topic = Topic.toJSON(message.topic);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateTopicRequest>): UpdateTopicRequest {
    return UpdateTopicRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateTopicRequest>): UpdateTopicRequest {
    const message = createBaseUpdateTopicRequest();
    message.topic = (object.topic !== undefined && object.topic !== null) ? Topic.fromPartial(object.topic) : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBasePublishRequest(): PublishRequest {
  return { topic: "", messages: [] };
}

export const PublishRequest: MessageFns<PublishRequest> = {
  encode(message: PublishRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    for (const v of message.messages) {
      PubsubMessage.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PublishRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePublishRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.messages.push(PubsubMessage.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PublishRequest {
    return {
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      messages: globalThis.Array.isArray(object?.messages)
        ? object.messages.map((e: any) => PubsubMessage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PublishRequest): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.messages?.length) {
      obj.messages = message.messages.map((e) => PubsubMessage.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PublishRequest>): PublishRequest {
    return PublishRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PublishRequest>): PublishRequest {
    const message = createBasePublishRequest();
    message.topic = object.topic ?? "";
    message.messages = object.messages?.map((e) => PubsubMessage.fromPartial(e)) || [];
    return message;
  },
};

function createBasePublishResponse(): PublishResponse {
  return { messageIds: [] };
}

export const PublishResponse: MessageFns<PublishResponse> = {
  encode(message: PublishResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.messageIds) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PublishResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePublishResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.messageIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PublishResponse {
    return {
      messageIds: globalThis.Array.isArray(object?.messageIds)
        ? object.messageIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: PublishResponse): unknown {
    const obj: any = {};
    if (message.messageIds?.length) {
      obj.messageIds = message.messageIds;
    }
    return obj;
  },

  create(base?: DeepPartial<PublishResponse>): PublishResponse {
    return PublishResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PublishResponse>): PublishResponse {
    const message = createBasePublishResponse();
    message.messageIds = object.messageIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseListTopicsRequest(): ListTopicsRequest {
  return { project: "", pageSize: 0, pageToken: "" };
}

export const ListTopicsRequest: MessageFns<ListTopicsRequest> = {
  encode(message: ListTopicsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTopicsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTopicsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTopicsRequest {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListTopicsRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTopicsRequest>): ListTopicsRequest {
    return ListTopicsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTopicsRequest>): ListTopicsRequest {
    const message = createBaseListTopicsRequest();
    message.project = object.project ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListTopicsResponse(): ListTopicsResponse {
  return { topics: [], nextPageToken: "" };
}

export const ListTopicsResponse: MessageFns<ListTopicsResponse> = {
  encode(message: ListTopicsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.topics) {
      Topic.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTopicsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTopicsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topics.push(Topic.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTopicsResponse {
    return {
      topics: globalThis.Array.isArray(object?.topics) ? object.topics.map((e: any) => Topic.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTopicsResponse): unknown {
    const obj: any = {};
    if (message.topics?.length) {
      obj.topics = message.topics.map((e) => Topic.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTopicsResponse>): ListTopicsResponse {
    return ListTopicsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTopicsResponse>): ListTopicsResponse {
    const message = createBaseListTopicsResponse();
    message.topics = object.topics?.map((e) => Topic.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseListTopicSubscriptionsRequest(): ListTopicSubscriptionsRequest {
  return { topic: "", pageSize: 0, pageToken: "" };
}

export const ListTopicSubscriptionsRequest: MessageFns<ListTopicSubscriptionsRequest> = {
  encode(message: ListTopicSubscriptionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTopicSubscriptionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTopicSubscriptionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTopicSubscriptionsRequest {
    return {
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListTopicSubscriptionsRequest): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTopicSubscriptionsRequest>): ListTopicSubscriptionsRequest {
    return ListTopicSubscriptionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTopicSubscriptionsRequest>): ListTopicSubscriptionsRequest {
    const message = createBaseListTopicSubscriptionsRequest();
    message.topic = object.topic ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListTopicSubscriptionsResponse(): ListTopicSubscriptionsResponse {
  return { subscriptions: [], nextPageToken: "" };
}

export const ListTopicSubscriptionsResponse: MessageFns<ListTopicSubscriptionsResponse> = {
  encode(message: ListTopicSubscriptionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.subscriptions) {
      writer.uint32(10).string(v!);
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTopicSubscriptionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTopicSubscriptionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscriptions.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTopicSubscriptionsResponse {
    return {
      subscriptions: globalThis.Array.isArray(object?.subscriptions)
        ? object.subscriptions.map((e: any) => globalThis.String(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTopicSubscriptionsResponse): unknown {
    const obj: any = {};
    if (message.subscriptions?.length) {
      obj.subscriptions = message.subscriptions;
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTopicSubscriptionsResponse>): ListTopicSubscriptionsResponse {
    return ListTopicSubscriptionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTopicSubscriptionsResponse>): ListTopicSubscriptionsResponse {
    const message = createBaseListTopicSubscriptionsResponse();
    message.subscriptions = object.subscriptions?.map((e) => e) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseListTopicSnapshotsRequest(): ListTopicSnapshotsRequest {
  return { topic: "", pageSize: 0, pageToken: "" };
}

export const ListTopicSnapshotsRequest: MessageFns<ListTopicSnapshotsRequest> = {
  encode(message: ListTopicSnapshotsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTopicSnapshotsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTopicSnapshotsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTopicSnapshotsRequest {
    return {
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListTopicSnapshotsRequest): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTopicSnapshotsRequest>): ListTopicSnapshotsRequest {
    return ListTopicSnapshotsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTopicSnapshotsRequest>): ListTopicSnapshotsRequest {
    const message = createBaseListTopicSnapshotsRequest();
    message.topic = object.topic ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListTopicSnapshotsResponse(): ListTopicSnapshotsResponse {
  return { snapshots: [], nextPageToken: "" };
}

export const ListTopicSnapshotsResponse: MessageFns<ListTopicSnapshotsResponse> = {
  encode(message: ListTopicSnapshotsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.snapshots) {
      writer.uint32(10).string(v!);
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTopicSnapshotsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTopicSnapshotsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshots.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTopicSnapshotsResponse {
    return {
      snapshots: globalThis.Array.isArray(object?.snapshots)
        ? object.snapshots.map((e: any) => globalThis.String(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTopicSnapshotsResponse): unknown {
    const obj: any = {};
    if (message.snapshots?.length) {
      obj.snapshots = message.snapshots;
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTopicSnapshotsResponse>): ListTopicSnapshotsResponse {
    return ListTopicSnapshotsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTopicSnapshotsResponse>): ListTopicSnapshotsResponse {
    const message = createBaseListTopicSnapshotsResponse();
    message.snapshots = object.snapshots?.map((e) => e) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteTopicRequest(): DeleteTopicRequest {
  return { topic: "" };
}

export const DeleteTopicRequest: MessageFns<DeleteTopicRequest> = {
  encode(message: DeleteTopicRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteTopicRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteTopicRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteTopicRequest {
    return { topic: isSet(object.topic) ? globalThis.String(object.topic) : "" };
  },

  toJSON(message: DeleteTopicRequest): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteTopicRequest>): DeleteTopicRequest {
    return DeleteTopicRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteTopicRequest>): DeleteTopicRequest {
    const message = createBaseDeleteTopicRequest();
    message.topic = object.topic ?? "";
    return message;
  },
};

function createBaseDetachSubscriptionRequest(): DetachSubscriptionRequest {
  return { subscription: "" };
}

export const DetachSubscriptionRequest: MessageFns<DetachSubscriptionRequest> = {
  encode(message: DetachSubscriptionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DetachSubscriptionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDetachSubscriptionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DetachSubscriptionRequest {
    return { subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "" };
  },

  toJSON(message: DetachSubscriptionRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    return obj;
  },

  create(base?: DeepPartial<DetachSubscriptionRequest>): DetachSubscriptionRequest {
    return DetachSubscriptionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DetachSubscriptionRequest>): DetachSubscriptionRequest {
    const message = createBaseDetachSubscriptionRequest();
    message.subscription = object.subscription ?? "";
    return message;
  },
};

function createBaseDetachSubscriptionResponse(): DetachSubscriptionResponse {
  return {};
}

export const DetachSubscriptionResponse: MessageFns<DetachSubscriptionResponse> = {
  encode(_: DetachSubscriptionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DetachSubscriptionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDetachSubscriptionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DetachSubscriptionResponse {
    return {};
  },

  toJSON(_: DetachSubscriptionResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DetachSubscriptionResponse>): DetachSubscriptionResponse {
    return DetachSubscriptionResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DetachSubscriptionResponse>): DetachSubscriptionResponse {
    const message = createBaseDetachSubscriptionResponse();
    return message;
  },
};

function createBaseSubscription(): Subscription {
  return {
    name: "",
    topic: "",
    pushConfig: undefined,
    bigqueryConfig: undefined,
    cloudStorageConfig: undefined,
    ackDeadlineSeconds: 0,
    retainAckedMessages: false,
    messageRetentionDuration: undefined,
    labels: {},
    enableMessageOrdering: false,
    expirationPolicy: undefined,
    filter: "",
    deadLetterPolicy: undefined,
    retryPolicy: undefined,
    detached: false,
    enableExactlyOnceDelivery: false,
    topicMessageRetentionDuration: undefined,
    state: 0,
    analyticsHubSubscriptionInfo: undefined,
  };
}

export const Subscription: MessageFns<Subscription> = {
  encode(message: Subscription, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.topic !== "") {
      writer.uint32(18).string(message.topic);
    }
    if (message.pushConfig !== undefined) {
      PushConfig.encode(message.pushConfig, writer.uint32(34).fork()).join();
    }
    if (message.bigqueryConfig !== undefined) {
      BigQueryConfig.encode(message.bigqueryConfig, writer.uint32(146).fork()).join();
    }
    if (message.cloudStorageConfig !== undefined) {
      CloudStorageConfig.encode(message.cloudStorageConfig, writer.uint32(178).fork()).join();
    }
    if (message.ackDeadlineSeconds !== 0) {
      writer.uint32(40).int32(message.ackDeadlineSeconds);
    }
    if (message.retainAckedMessages !== false) {
      writer.uint32(56).bool(message.retainAckedMessages);
    }
    if (message.messageRetentionDuration !== undefined) {
      Duration.encode(message.messageRetentionDuration, writer.uint32(66).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Subscription_LabelsEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    if (message.enableMessageOrdering !== false) {
      writer.uint32(80).bool(message.enableMessageOrdering);
    }
    if (message.expirationPolicy !== undefined) {
      ExpirationPolicy.encode(message.expirationPolicy, writer.uint32(90).fork()).join();
    }
    if (message.filter !== "") {
      writer.uint32(98).string(message.filter);
    }
    if (message.deadLetterPolicy !== undefined) {
      DeadLetterPolicy.encode(message.deadLetterPolicy, writer.uint32(106).fork()).join();
    }
    if (message.retryPolicy !== undefined) {
      RetryPolicy.encode(message.retryPolicy, writer.uint32(114).fork()).join();
    }
    if (message.detached !== false) {
      writer.uint32(120).bool(message.detached);
    }
    if (message.enableExactlyOnceDelivery !== false) {
      writer.uint32(128).bool(message.enableExactlyOnceDelivery);
    }
    if (message.topicMessageRetentionDuration !== undefined) {
      Duration.encode(message.topicMessageRetentionDuration, writer.uint32(138).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(152).int32(message.state);
    }
    if (message.analyticsHubSubscriptionInfo !== undefined) {
      Subscription_AnalyticsHubSubscriptionInfo.encode(message.analyticsHubSubscriptionInfo, writer.uint32(186).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Subscription {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSubscription();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pushConfig = PushConfig.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.bigqueryConfig = BigQueryConfig.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.cloudStorageConfig = CloudStorageConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ackDeadlineSeconds = reader.int32();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.retainAckedMessages = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.messageRetentionDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          const entry9 = Subscription_LabelsEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.labels[entry9.key] = entry9.value;
          }
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.enableMessageOrdering = reader.bool();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.expirationPolicy = ExpirationPolicy.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.deadLetterPolicy = DeadLetterPolicy.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.retryPolicy = RetryPolicy.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.detached = reader.bool();
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.enableExactlyOnceDelivery = reader.bool();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.topicMessageRetentionDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 152) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.analyticsHubSubscriptionInfo = Subscription_AnalyticsHubSubscriptionInfo.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Subscription {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      pushConfig: isSet(object.pushConfig) ? PushConfig.fromJSON(object.pushConfig) : undefined,
      bigqueryConfig: isSet(object.bigqueryConfig) ? BigQueryConfig.fromJSON(object.bigqueryConfig) : undefined,
      cloudStorageConfig: isSet(object.cloudStorageConfig)
        ? CloudStorageConfig.fromJSON(object.cloudStorageConfig)
        : undefined,
      ackDeadlineSeconds: isSet(object.ackDeadlineSeconds) ? globalThis.Number(object.ackDeadlineSeconds) : 0,
      retainAckedMessages: isSet(object.retainAckedMessages) ? globalThis.Boolean(object.retainAckedMessages) : false,
      messageRetentionDuration: isSet(object.messageRetentionDuration)
        ? Duration.fromJSON(object.messageRetentionDuration)
        : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      enableMessageOrdering: isSet(object.enableMessageOrdering)
        ? globalThis.Boolean(object.enableMessageOrdering)
        : false,
      expirationPolicy: isSet(object.expirationPolicy) ? ExpirationPolicy.fromJSON(object.expirationPolicy) : undefined,
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      deadLetterPolicy: isSet(object.deadLetterPolicy) ? DeadLetterPolicy.fromJSON(object.deadLetterPolicy) : undefined,
      retryPolicy: isSet(object.retryPolicy) ? RetryPolicy.fromJSON(object.retryPolicy) : undefined,
      detached: isSet(object.detached) ? globalThis.Boolean(object.detached) : false,
      enableExactlyOnceDelivery: isSet(object.enableExactlyOnceDelivery)
        ? globalThis.Boolean(object.enableExactlyOnceDelivery)
        : false,
      topicMessageRetentionDuration: isSet(object.topicMessageRetentionDuration)
        ? Duration.fromJSON(object.topicMessageRetentionDuration)
        : undefined,
      state: isSet(object.state) ? subscription_StateFromJSON(object.state) : 0,
      analyticsHubSubscriptionInfo: isSet(object.analyticsHubSubscriptionInfo)
        ? Subscription_AnalyticsHubSubscriptionInfo.fromJSON(object.analyticsHubSubscriptionInfo)
        : undefined,
    };
  },

  toJSON(message: Subscription): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.pushConfig !== undefined) {
      obj.pushConfig = PushConfig.toJSON(message.pushConfig);
    }
    if (message.bigqueryConfig !== undefined) {
      obj.bigqueryConfig = BigQueryConfig.toJSON(message.bigqueryConfig);
    }
    if (message.cloudStorageConfig !== undefined) {
      obj.cloudStorageConfig = CloudStorageConfig.toJSON(message.cloudStorageConfig);
    }
    if (message.ackDeadlineSeconds !== 0) {
      obj.ackDeadlineSeconds = Math.round(message.ackDeadlineSeconds);
    }
    if (message.retainAckedMessages !== false) {
      obj.retainAckedMessages = message.retainAckedMessages;
    }
    if (message.messageRetentionDuration !== undefined) {
      obj.messageRetentionDuration = Duration.toJSON(message.messageRetentionDuration);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.enableMessageOrdering !== false) {
      obj.enableMessageOrdering = message.enableMessageOrdering;
    }
    if (message.expirationPolicy !== undefined) {
      obj.expirationPolicy = ExpirationPolicy.toJSON(message.expirationPolicy);
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.deadLetterPolicy !== undefined) {
      obj.deadLetterPolicy = DeadLetterPolicy.toJSON(message.deadLetterPolicy);
    }
    if (message.retryPolicy !== undefined) {
      obj.retryPolicy = RetryPolicy.toJSON(message.retryPolicy);
    }
    if (message.detached !== false) {
      obj.detached = message.detached;
    }
    if (message.enableExactlyOnceDelivery !== false) {
      obj.enableExactlyOnceDelivery = message.enableExactlyOnceDelivery;
    }
    if (message.topicMessageRetentionDuration !== undefined) {
      obj.topicMessageRetentionDuration = Duration.toJSON(message.topicMessageRetentionDuration);
    }
    if (message.state !== 0) {
      obj.state = subscription_StateToJSON(message.state);
    }
    if (message.analyticsHubSubscriptionInfo !== undefined) {
      obj.analyticsHubSubscriptionInfo = Subscription_AnalyticsHubSubscriptionInfo.toJSON(
        message.analyticsHubSubscriptionInfo,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<Subscription>): Subscription {
    return Subscription.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Subscription>): Subscription {
    const message = createBaseSubscription();
    message.name = object.name ?? "";
    message.topic = object.topic ?? "";
    message.pushConfig = (object.pushConfig !== undefined && object.pushConfig !== null)
      ? PushConfig.fromPartial(object.pushConfig)
      : undefined;
    message.bigqueryConfig = (object.bigqueryConfig !== undefined && object.bigqueryConfig !== null)
      ? BigQueryConfig.fromPartial(object.bigqueryConfig)
      : undefined;
    message.cloudStorageConfig = (object.cloudStorageConfig !== undefined && object.cloudStorageConfig !== null)
      ? CloudStorageConfig.fromPartial(object.cloudStorageConfig)
      : undefined;
    message.ackDeadlineSeconds = object.ackDeadlineSeconds ?? 0;
    message.retainAckedMessages = object.retainAckedMessages ?? false;
    message.messageRetentionDuration =
      (object.messageRetentionDuration !== undefined && object.messageRetentionDuration !== null)
        ? Duration.fromPartial(object.messageRetentionDuration)
        : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.enableMessageOrdering = object.enableMessageOrdering ?? false;
    message.expirationPolicy = (object.expirationPolicy !== undefined && object.expirationPolicy !== null)
      ? ExpirationPolicy.fromPartial(object.expirationPolicy)
      : undefined;
    message.filter = object.filter ?? "";
    message.deadLetterPolicy = (object.deadLetterPolicy !== undefined && object.deadLetterPolicy !== null)
      ? DeadLetterPolicy.fromPartial(object.deadLetterPolicy)
      : undefined;
    message.retryPolicy = (object.retryPolicy !== undefined && object.retryPolicy !== null)
      ? RetryPolicy.fromPartial(object.retryPolicy)
      : undefined;
    message.detached = object.detached ?? false;
    message.enableExactlyOnceDelivery = object.enableExactlyOnceDelivery ?? false;
    message.topicMessageRetentionDuration =
      (object.topicMessageRetentionDuration !== undefined && object.topicMessageRetentionDuration !== null)
        ? Duration.fromPartial(object.topicMessageRetentionDuration)
        : undefined;
    message.state = object.state ?? 0;
    message.analyticsHubSubscriptionInfo =
      (object.analyticsHubSubscriptionInfo !== undefined && object.analyticsHubSubscriptionInfo !== null)
        ? Subscription_AnalyticsHubSubscriptionInfo.fromPartial(object.analyticsHubSubscriptionInfo)
        : undefined;
    return message;
  },
};

function createBaseSubscription_AnalyticsHubSubscriptionInfo(): Subscription_AnalyticsHubSubscriptionInfo {
  return { listing: "", subscription: "" };
}

export const Subscription_AnalyticsHubSubscriptionInfo: MessageFns<Subscription_AnalyticsHubSubscriptionInfo> = {
  encode(message: Subscription_AnalyticsHubSubscriptionInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.listing !== "") {
      writer.uint32(10).string(message.listing);
    }
    if (message.subscription !== "") {
      writer.uint32(18).string(message.subscription);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Subscription_AnalyticsHubSubscriptionInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSubscription_AnalyticsHubSubscriptionInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.listing = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subscription = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Subscription_AnalyticsHubSubscriptionInfo {
    return {
      listing: isSet(object.listing) ? globalThis.String(object.listing) : "",
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
    };
  },

  toJSON(message: Subscription_AnalyticsHubSubscriptionInfo): unknown {
    const obj: any = {};
    if (message.listing !== "") {
      obj.listing = message.listing;
    }
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    return obj;
  },

  create(base?: DeepPartial<Subscription_AnalyticsHubSubscriptionInfo>): Subscription_AnalyticsHubSubscriptionInfo {
    return Subscription_AnalyticsHubSubscriptionInfo.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Subscription_AnalyticsHubSubscriptionInfo>,
  ): Subscription_AnalyticsHubSubscriptionInfo {
    const message = createBaseSubscription_AnalyticsHubSubscriptionInfo();
    message.listing = object.listing ?? "";
    message.subscription = object.subscription ?? "";
    return message;
  },
};

function createBaseSubscription_LabelsEntry(): Subscription_LabelsEntry {
  return { key: "", value: "" };
}

export const Subscription_LabelsEntry: MessageFns<Subscription_LabelsEntry> = {
  encode(message: Subscription_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Subscription_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSubscription_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Subscription_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Subscription_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Subscription_LabelsEntry>): Subscription_LabelsEntry {
    return Subscription_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Subscription_LabelsEntry>): Subscription_LabelsEntry {
    const message = createBaseSubscription_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRetryPolicy(): RetryPolicy {
  return { minimumBackoff: undefined, maximumBackoff: undefined };
}

export const RetryPolicy: MessageFns<RetryPolicy> = {
  encode(message: RetryPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minimumBackoff !== undefined) {
      Duration.encode(message.minimumBackoff, writer.uint32(10).fork()).join();
    }
    if (message.maximumBackoff !== undefined) {
      Duration.encode(message.maximumBackoff, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RetryPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRetryPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.minimumBackoff = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.maximumBackoff = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RetryPolicy {
    return {
      minimumBackoff: isSet(object.minimumBackoff) ? Duration.fromJSON(object.minimumBackoff) : undefined,
      maximumBackoff: isSet(object.maximumBackoff) ? Duration.fromJSON(object.maximumBackoff) : undefined,
    };
  },

  toJSON(message: RetryPolicy): unknown {
    const obj: any = {};
    if (message.minimumBackoff !== undefined) {
      obj.minimumBackoff = Duration.toJSON(message.minimumBackoff);
    }
    if (message.maximumBackoff !== undefined) {
      obj.maximumBackoff = Duration.toJSON(message.maximumBackoff);
    }
    return obj;
  },

  create(base?: DeepPartial<RetryPolicy>): RetryPolicy {
    return RetryPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RetryPolicy>): RetryPolicy {
    const message = createBaseRetryPolicy();
    message.minimumBackoff = (object.minimumBackoff !== undefined && object.minimumBackoff !== null)
      ? Duration.fromPartial(object.minimumBackoff)
      : undefined;
    message.maximumBackoff = (object.maximumBackoff !== undefined && object.maximumBackoff !== null)
      ? Duration.fromPartial(object.maximumBackoff)
      : undefined;
    return message;
  },
};

function createBaseDeadLetterPolicy(): DeadLetterPolicy {
  return { deadLetterTopic: "", maxDeliveryAttempts: 0 };
}

export const DeadLetterPolicy: MessageFns<DeadLetterPolicy> = {
  encode(message: DeadLetterPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deadLetterTopic !== "") {
      writer.uint32(10).string(message.deadLetterTopic);
    }
    if (message.maxDeliveryAttempts !== 0) {
      writer.uint32(16).int32(message.maxDeliveryAttempts);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeadLetterPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeadLetterPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.deadLetterTopic = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxDeliveryAttempts = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeadLetterPolicy {
    return {
      deadLetterTopic: isSet(object.deadLetterTopic) ? globalThis.String(object.deadLetterTopic) : "",
      maxDeliveryAttempts: isSet(object.maxDeliveryAttempts) ? globalThis.Number(object.maxDeliveryAttempts) : 0,
    };
  },

  toJSON(message: DeadLetterPolicy): unknown {
    const obj: any = {};
    if (message.deadLetterTopic !== "") {
      obj.deadLetterTopic = message.deadLetterTopic;
    }
    if (message.maxDeliveryAttempts !== 0) {
      obj.maxDeliveryAttempts = Math.round(message.maxDeliveryAttempts);
    }
    return obj;
  },

  create(base?: DeepPartial<DeadLetterPolicy>): DeadLetterPolicy {
    return DeadLetterPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeadLetterPolicy>): DeadLetterPolicy {
    const message = createBaseDeadLetterPolicy();
    message.deadLetterTopic = object.deadLetterTopic ?? "";
    message.maxDeliveryAttempts = object.maxDeliveryAttempts ?? 0;
    return message;
  },
};

function createBaseExpirationPolicy(): ExpirationPolicy {
  return { ttl: undefined };
}

export const ExpirationPolicy: MessageFns<ExpirationPolicy> = {
  encode(message: ExpirationPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.ttl !== undefined) {
      Duration.encode(message.ttl, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExpirationPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExpirationPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ttl = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExpirationPolicy {
    return { ttl: isSet(object.ttl) ? Duration.fromJSON(object.ttl) : undefined };
  },

  toJSON(message: ExpirationPolicy): unknown {
    const obj: any = {};
    if (message.ttl !== undefined) {
      obj.ttl = Duration.toJSON(message.ttl);
    }
    return obj;
  },

  create(base?: DeepPartial<ExpirationPolicy>): ExpirationPolicy {
    return ExpirationPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExpirationPolicy>): ExpirationPolicy {
    const message = createBaseExpirationPolicy();
    message.ttl = (object.ttl !== undefined && object.ttl !== null) ? Duration.fromPartial(object.ttl) : undefined;
    return message;
  },
};

function createBasePushConfig(): PushConfig {
  return { pushEndpoint: "", attributes: {}, oidcToken: undefined, pubsubWrapper: undefined, noWrapper: undefined };
}

export const PushConfig: MessageFns<PushConfig> = {
  encode(message: PushConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pushEndpoint !== "") {
      writer.uint32(10).string(message.pushEndpoint);
    }
    Object.entries(message.attributes).forEach(([key, value]) => {
      PushConfig_AttributesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.oidcToken !== undefined) {
      PushConfig_OidcToken.encode(message.oidcToken, writer.uint32(26).fork()).join();
    }
    if (message.pubsubWrapper !== undefined) {
      PushConfig_PubsubWrapper.encode(message.pubsubWrapper, writer.uint32(34).fork()).join();
    }
    if (message.noWrapper !== undefined) {
      PushConfig_NoWrapper.encode(message.noWrapper, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pushEndpoint = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = PushConfig_AttributesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.attributes[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.oidcToken = PushConfig_OidcToken.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pubsubWrapper = PushConfig_PubsubWrapper.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.noWrapper = PushConfig_NoWrapper.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PushConfig {
    return {
      pushEndpoint: isSet(object.pushEndpoint) ? globalThis.String(object.pushEndpoint) : "",
      attributes: isObject(object.attributes)
        ? Object.entries(object.attributes).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      oidcToken: isSet(object.oidcToken) ? PushConfig_OidcToken.fromJSON(object.oidcToken) : undefined,
      pubsubWrapper: isSet(object.pubsubWrapper) ? PushConfig_PubsubWrapper.fromJSON(object.pubsubWrapper) : undefined,
      noWrapper: isSet(object.noWrapper) ? PushConfig_NoWrapper.fromJSON(object.noWrapper) : undefined,
    };
  },

  toJSON(message: PushConfig): unknown {
    const obj: any = {};
    if (message.pushEndpoint !== "") {
      obj.pushEndpoint = message.pushEndpoint;
    }
    if (message.attributes) {
      const entries = Object.entries(message.attributes);
      if (entries.length > 0) {
        obj.attributes = {};
        entries.forEach(([k, v]) => {
          obj.attributes[k] = v;
        });
      }
    }
    if (message.oidcToken !== undefined) {
      obj.oidcToken = PushConfig_OidcToken.toJSON(message.oidcToken);
    }
    if (message.pubsubWrapper !== undefined) {
      obj.pubsubWrapper = PushConfig_PubsubWrapper.toJSON(message.pubsubWrapper);
    }
    if (message.noWrapper !== undefined) {
      obj.noWrapper = PushConfig_NoWrapper.toJSON(message.noWrapper);
    }
    return obj;
  },

  create(base?: DeepPartial<PushConfig>): PushConfig {
    return PushConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PushConfig>): PushConfig {
    const message = createBasePushConfig();
    message.pushEndpoint = object.pushEndpoint ?? "";
    message.attributes = Object.entries(object.attributes ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.oidcToken = (object.oidcToken !== undefined && object.oidcToken !== null)
      ? PushConfig_OidcToken.fromPartial(object.oidcToken)
      : undefined;
    message.pubsubWrapper = (object.pubsubWrapper !== undefined && object.pubsubWrapper !== null)
      ? PushConfig_PubsubWrapper.fromPartial(object.pubsubWrapper)
      : undefined;
    message.noWrapper = (object.noWrapper !== undefined && object.noWrapper !== null)
      ? PushConfig_NoWrapper.fromPartial(object.noWrapper)
      : undefined;
    return message;
  },
};

function createBasePushConfig_OidcToken(): PushConfig_OidcToken {
  return { serviceAccountEmail: "", audience: "" };
}

export const PushConfig_OidcToken: MessageFns<PushConfig_OidcToken> = {
  encode(message: PushConfig_OidcToken, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serviceAccountEmail !== "") {
      writer.uint32(10).string(message.serviceAccountEmail);
    }
    if (message.audience !== "") {
      writer.uint32(18).string(message.audience);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushConfig_OidcToken {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushConfig_OidcToken();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.audience = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PushConfig_OidcToken {
    return {
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      audience: isSet(object.audience) ? globalThis.String(object.audience) : "",
    };
  },

  toJSON(message: PushConfig_OidcToken): unknown {
    const obj: any = {};
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.audience !== "") {
      obj.audience = message.audience;
    }
    return obj;
  },

  create(base?: DeepPartial<PushConfig_OidcToken>): PushConfig_OidcToken {
    return PushConfig_OidcToken.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PushConfig_OidcToken>): PushConfig_OidcToken {
    const message = createBasePushConfig_OidcToken();
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.audience = object.audience ?? "";
    return message;
  },
};

function createBasePushConfig_PubsubWrapper(): PushConfig_PubsubWrapper {
  return {};
}

export const PushConfig_PubsubWrapper: MessageFns<PushConfig_PubsubWrapper> = {
  encode(_: PushConfig_PubsubWrapper, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushConfig_PubsubWrapper {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushConfig_PubsubWrapper();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): PushConfig_PubsubWrapper {
    return {};
  },

  toJSON(_: PushConfig_PubsubWrapper): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<PushConfig_PubsubWrapper>): PushConfig_PubsubWrapper {
    return PushConfig_PubsubWrapper.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<PushConfig_PubsubWrapper>): PushConfig_PubsubWrapper {
    const message = createBasePushConfig_PubsubWrapper();
    return message;
  },
};

function createBasePushConfig_NoWrapper(): PushConfig_NoWrapper {
  return { writeMetadata: false };
}

export const PushConfig_NoWrapper: MessageFns<PushConfig_NoWrapper> = {
  encode(message: PushConfig_NoWrapper, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.writeMetadata !== false) {
      writer.uint32(8).bool(message.writeMetadata);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushConfig_NoWrapper {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushConfig_NoWrapper();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.writeMetadata = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PushConfig_NoWrapper {
    return { writeMetadata: isSet(object.writeMetadata) ? globalThis.Boolean(object.writeMetadata) : false };
  },

  toJSON(message: PushConfig_NoWrapper): unknown {
    const obj: any = {};
    if (message.writeMetadata !== false) {
      obj.writeMetadata = message.writeMetadata;
    }
    return obj;
  },

  create(base?: DeepPartial<PushConfig_NoWrapper>): PushConfig_NoWrapper {
    return PushConfig_NoWrapper.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PushConfig_NoWrapper>): PushConfig_NoWrapper {
    const message = createBasePushConfig_NoWrapper();
    message.writeMetadata = object.writeMetadata ?? false;
    return message;
  },
};

function createBasePushConfig_AttributesEntry(): PushConfig_AttributesEntry {
  return { key: "", value: "" };
}

export const PushConfig_AttributesEntry: MessageFns<PushConfig_AttributesEntry> = {
  encode(message: PushConfig_AttributesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushConfig_AttributesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushConfig_AttributesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PushConfig_AttributesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PushConfig_AttributesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<PushConfig_AttributesEntry>): PushConfig_AttributesEntry {
    return PushConfig_AttributesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PushConfig_AttributesEntry>): PushConfig_AttributesEntry {
    const message = createBasePushConfig_AttributesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBigQueryConfig(): BigQueryConfig {
  return {
    table: "",
    useTopicSchema: false,
    writeMetadata: false,
    dropUnknownFields: false,
    state: 0,
    useTableSchema: false,
    serviceAccountEmail: "",
  };
}

export const BigQueryConfig: MessageFns<BigQueryConfig> = {
  encode(message: BigQueryConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== "") {
      writer.uint32(10).string(message.table);
    }
    if (message.useTopicSchema !== false) {
      writer.uint32(16).bool(message.useTopicSchema);
    }
    if (message.writeMetadata !== false) {
      writer.uint32(24).bool(message.writeMetadata);
    }
    if (message.dropUnknownFields !== false) {
      writer.uint32(32).bool(message.dropUnknownFields);
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.useTableSchema !== false) {
      writer.uint32(48).bool(message.useTableSchema);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(58).string(message.serviceAccountEmail);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.useTopicSchema = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.writeMetadata = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.dropUnknownFields = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.useTableSchema = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryConfig {
    return {
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      useTopicSchema: isSet(object.useTopicSchema) ? globalThis.Boolean(object.useTopicSchema) : false,
      writeMetadata: isSet(object.writeMetadata) ? globalThis.Boolean(object.writeMetadata) : false,
      dropUnknownFields: isSet(object.dropUnknownFields) ? globalThis.Boolean(object.dropUnknownFields) : false,
      state: isSet(object.state) ? bigQueryConfig_StateFromJSON(object.state) : 0,
      useTableSchema: isSet(object.useTableSchema) ? globalThis.Boolean(object.useTableSchema) : false,
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
    };
  },

  toJSON(message: BigQueryConfig): unknown {
    const obj: any = {};
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.useTopicSchema !== false) {
      obj.useTopicSchema = message.useTopicSchema;
    }
    if (message.writeMetadata !== false) {
      obj.writeMetadata = message.writeMetadata;
    }
    if (message.dropUnknownFields !== false) {
      obj.dropUnknownFields = message.dropUnknownFields;
    }
    if (message.state !== 0) {
      obj.state = bigQueryConfig_StateToJSON(message.state);
    }
    if (message.useTableSchema !== false) {
      obj.useTableSchema = message.useTableSchema;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryConfig>): BigQueryConfig {
    return BigQueryConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryConfig>): BigQueryConfig {
    const message = createBaseBigQueryConfig();
    message.table = object.table ?? "";
    message.useTopicSchema = object.useTopicSchema ?? false;
    message.writeMetadata = object.writeMetadata ?? false;
    message.dropUnknownFields = object.dropUnknownFields ?? false;
    message.state = object.state ?? 0;
    message.useTableSchema = object.useTableSchema ?? false;
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    return message;
  },
};

function createBaseCloudStorageConfig(): CloudStorageConfig {
  return {
    bucket: "",
    filenamePrefix: "",
    filenameSuffix: "",
    filenameDatetimeFormat: "",
    textConfig: undefined,
    avroConfig: undefined,
    maxDuration: undefined,
    maxBytes: Long.ZERO,
    maxMessages: Long.ZERO,
    state: 0,
    serviceAccountEmail: "",
  };
}

export const CloudStorageConfig: MessageFns<CloudStorageConfig> = {
  encode(message: CloudStorageConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.filenamePrefix !== "") {
      writer.uint32(18).string(message.filenamePrefix);
    }
    if (message.filenameSuffix !== "") {
      writer.uint32(26).string(message.filenameSuffix);
    }
    if (message.filenameDatetimeFormat !== "") {
      writer.uint32(82).string(message.filenameDatetimeFormat);
    }
    if (message.textConfig !== undefined) {
      CloudStorageConfig_TextConfig.encode(message.textConfig, writer.uint32(34).fork()).join();
    }
    if (message.avroConfig !== undefined) {
      CloudStorageConfig_AvroConfig.encode(message.avroConfig, writer.uint32(42).fork()).join();
    }
    if (message.maxDuration !== undefined) {
      Duration.encode(message.maxDuration, writer.uint32(50).fork()).join();
    }
    if (!message.maxBytes.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.maxBytes.toString());
    }
    if (!message.maxMessages.equals(Long.ZERO)) {
      writer.uint32(64).int64(message.maxMessages.toString());
    }
    if (message.state !== 0) {
      writer.uint32(72).int32(message.state);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(90).string(message.serviceAccountEmail);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filenamePrefix = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.filenameSuffix = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.filenameDatetimeFormat = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.textConfig = CloudStorageConfig_TextConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.avroConfig = CloudStorageConfig_AvroConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.maxDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.maxBytes = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.maxMessages = Long.fromString(reader.int64().toString());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudStorageConfig {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      filenamePrefix: isSet(object.filenamePrefix) ? globalThis.String(object.filenamePrefix) : "",
      filenameSuffix: isSet(object.filenameSuffix) ? globalThis.String(object.filenameSuffix) : "",
      filenameDatetimeFormat: isSet(object.filenameDatetimeFormat)
        ? globalThis.String(object.filenameDatetimeFormat)
        : "",
      textConfig: isSet(object.textConfig) ? CloudStorageConfig_TextConfig.fromJSON(object.textConfig) : undefined,
      avroConfig: isSet(object.avroConfig) ? CloudStorageConfig_AvroConfig.fromJSON(object.avroConfig) : undefined,
      maxDuration: isSet(object.maxDuration) ? Duration.fromJSON(object.maxDuration) : undefined,
      maxBytes: isSet(object.maxBytes) ? Long.fromValue(object.maxBytes) : Long.ZERO,
      maxMessages: isSet(object.maxMessages) ? Long.fromValue(object.maxMessages) : Long.ZERO,
      state: isSet(object.state) ? cloudStorageConfig_StateFromJSON(object.state) : 0,
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
    };
  },

  toJSON(message: CloudStorageConfig): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.filenamePrefix !== "") {
      obj.filenamePrefix = message.filenamePrefix;
    }
    if (message.filenameSuffix !== "") {
      obj.filenameSuffix = message.filenameSuffix;
    }
    if (message.filenameDatetimeFormat !== "") {
      obj.filenameDatetimeFormat = message.filenameDatetimeFormat;
    }
    if (message.textConfig !== undefined) {
      obj.textConfig = CloudStorageConfig_TextConfig.toJSON(message.textConfig);
    }
    if (message.avroConfig !== undefined) {
      obj.avroConfig = CloudStorageConfig_AvroConfig.toJSON(message.avroConfig);
    }
    if (message.maxDuration !== undefined) {
      obj.maxDuration = Duration.toJSON(message.maxDuration);
    }
    if (!message.maxBytes.equals(Long.ZERO)) {
      obj.maxBytes = (message.maxBytes || Long.ZERO).toString();
    }
    if (!message.maxMessages.equals(Long.ZERO)) {
      obj.maxMessages = (message.maxMessages || Long.ZERO).toString();
    }
    if (message.state !== 0) {
      obj.state = cloudStorageConfig_StateToJSON(message.state);
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudStorageConfig>): CloudStorageConfig {
    return CloudStorageConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudStorageConfig>): CloudStorageConfig {
    const message = createBaseCloudStorageConfig();
    message.bucket = object.bucket ?? "";
    message.filenamePrefix = object.filenamePrefix ?? "";
    message.filenameSuffix = object.filenameSuffix ?? "";
    message.filenameDatetimeFormat = object.filenameDatetimeFormat ?? "";
    message.textConfig = (object.textConfig !== undefined && object.textConfig !== null)
      ? CloudStorageConfig_TextConfig.fromPartial(object.textConfig)
      : undefined;
    message.avroConfig = (object.avroConfig !== undefined && object.avroConfig !== null)
      ? CloudStorageConfig_AvroConfig.fromPartial(object.avroConfig)
      : undefined;
    message.maxDuration = (object.maxDuration !== undefined && object.maxDuration !== null)
      ? Duration.fromPartial(object.maxDuration)
      : undefined;
    message.maxBytes = (object.maxBytes !== undefined && object.maxBytes !== null)
      ? Long.fromValue(object.maxBytes)
      : Long.ZERO;
    message.maxMessages = (object.maxMessages !== undefined && object.maxMessages !== null)
      ? Long.fromValue(object.maxMessages)
      : Long.ZERO;
    message.state = object.state ?? 0;
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    return message;
  },
};

function createBaseCloudStorageConfig_TextConfig(): CloudStorageConfig_TextConfig {
  return {};
}

export const CloudStorageConfig_TextConfig: MessageFns<CloudStorageConfig_TextConfig> = {
  encode(_: CloudStorageConfig_TextConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageConfig_TextConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageConfig_TextConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CloudStorageConfig_TextConfig {
    return {};
  },

  toJSON(_: CloudStorageConfig_TextConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<CloudStorageConfig_TextConfig>): CloudStorageConfig_TextConfig {
    return CloudStorageConfig_TextConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<CloudStorageConfig_TextConfig>): CloudStorageConfig_TextConfig {
    const message = createBaseCloudStorageConfig_TextConfig();
    return message;
  },
};

function createBaseCloudStorageConfig_AvroConfig(): CloudStorageConfig_AvroConfig {
  return { writeMetadata: false, useTopicSchema: false };
}

export const CloudStorageConfig_AvroConfig: MessageFns<CloudStorageConfig_AvroConfig> = {
  encode(message: CloudStorageConfig_AvroConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.writeMetadata !== false) {
      writer.uint32(8).bool(message.writeMetadata);
    }
    if (message.useTopicSchema !== false) {
      writer.uint32(16).bool(message.useTopicSchema);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageConfig_AvroConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageConfig_AvroConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.writeMetadata = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.useTopicSchema = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudStorageConfig_AvroConfig {
    return {
      writeMetadata: isSet(object.writeMetadata) ? globalThis.Boolean(object.writeMetadata) : false,
      useTopicSchema: isSet(object.useTopicSchema) ? globalThis.Boolean(object.useTopicSchema) : false,
    };
  },

  toJSON(message: CloudStorageConfig_AvroConfig): unknown {
    const obj: any = {};
    if (message.writeMetadata !== false) {
      obj.writeMetadata = message.writeMetadata;
    }
    if (message.useTopicSchema !== false) {
      obj.useTopicSchema = message.useTopicSchema;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudStorageConfig_AvroConfig>): CloudStorageConfig_AvroConfig {
    return CloudStorageConfig_AvroConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudStorageConfig_AvroConfig>): CloudStorageConfig_AvroConfig {
    const message = createBaseCloudStorageConfig_AvroConfig();
    message.writeMetadata = object.writeMetadata ?? false;
    message.useTopicSchema = object.useTopicSchema ?? false;
    return message;
  },
};

function createBaseReceivedMessage(): ReceivedMessage {
  return { ackId: "", message: undefined, deliveryAttempt: 0 };
}

export const ReceivedMessage: MessageFns<ReceivedMessage> = {
  encode(message: ReceivedMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.ackId !== "") {
      writer.uint32(10).string(message.ackId);
    }
    if (message.message !== undefined) {
      PubsubMessage.encode(message.message, writer.uint32(18).fork()).join();
    }
    if (message.deliveryAttempt !== 0) {
      writer.uint32(24).int32(message.deliveryAttempt);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReceivedMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReceivedMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ackId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.message = PubsubMessage.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.deliveryAttempt = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReceivedMessage {
    return {
      ackId: isSet(object.ackId) ? globalThis.String(object.ackId) : "",
      message: isSet(object.message) ? PubsubMessage.fromJSON(object.message) : undefined,
      deliveryAttempt: isSet(object.deliveryAttempt) ? globalThis.Number(object.deliveryAttempt) : 0,
    };
  },

  toJSON(message: ReceivedMessage): unknown {
    const obj: any = {};
    if (message.ackId !== "") {
      obj.ackId = message.ackId;
    }
    if (message.message !== undefined) {
      obj.message = PubsubMessage.toJSON(message.message);
    }
    if (message.deliveryAttempt !== 0) {
      obj.deliveryAttempt = Math.round(message.deliveryAttempt);
    }
    return obj;
  },

  create(base?: DeepPartial<ReceivedMessage>): ReceivedMessage {
    return ReceivedMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReceivedMessage>): ReceivedMessage {
    const message = createBaseReceivedMessage();
    message.ackId = object.ackId ?? "";
    message.message = (object.message !== undefined && object.message !== null)
      ? PubsubMessage.fromPartial(object.message)
      : undefined;
    message.deliveryAttempt = object.deliveryAttempt ?? 0;
    return message;
  },
};

function createBaseGetSubscriptionRequest(): GetSubscriptionRequest {
  return { subscription: "" };
}

export const GetSubscriptionRequest: MessageFns<GetSubscriptionRequest> = {
  encode(message: GetSubscriptionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetSubscriptionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetSubscriptionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetSubscriptionRequest {
    return { subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "" };
  },

  toJSON(message: GetSubscriptionRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    return obj;
  },

  create(base?: DeepPartial<GetSubscriptionRequest>): GetSubscriptionRequest {
    return GetSubscriptionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetSubscriptionRequest>): GetSubscriptionRequest {
    const message = createBaseGetSubscriptionRequest();
    message.subscription = object.subscription ?? "";
    return message;
  },
};

function createBaseUpdateSubscriptionRequest(): UpdateSubscriptionRequest {
  return { subscription: undefined, updateMask: undefined };
}

export const UpdateSubscriptionRequest: MessageFns<UpdateSubscriptionRequest> = {
  encode(message: UpdateSubscriptionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== undefined) {
      Subscription.encode(message.subscription, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateSubscriptionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateSubscriptionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = Subscription.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateSubscriptionRequest {
    return {
      subscription: isSet(object.subscription) ? Subscription.fromJSON(object.subscription) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateSubscriptionRequest): unknown {
    const obj: any = {};
    if (message.subscription !== undefined) {
      obj.subscription = Subscription.toJSON(message.subscription);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateSubscriptionRequest>): UpdateSubscriptionRequest {
    return UpdateSubscriptionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateSubscriptionRequest>): UpdateSubscriptionRequest {
    const message = createBaseUpdateSubscriptionRequest();
    message.subscription = (object.subscription !== undefined && object.subscription !== null)
      ? Subscription.fromPartial(object.subscription)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseListSubscriptionsRequest(): ListSubscriptionsRequest {
  return { project: "", pageSize: 0, pageToken: "" };
}

export const ListSubscriptionsRequest: MessageFns<ListSubscriptionsRequest> = {
  encode(message: ListSubscriptionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSubscriptionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSubscriptionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSubscriptionsRequest {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListSubscriptionsRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSubscriptionsRequest>): ListSubscriptionsRequest {
    return ListSubscriptionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSubscriptionsRequest>): ListSubscriptionsRequest {
    const message = createBaseListSubscriptionsRequest();
    message.project = object.project ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListSubscriptionsResponse(): ListSubscriptionsResponse {
  return { subscriptions: [], nextPageToken: "" };
}

export const ListSubscriptionsResponse: MessageFns<ListSubscriptionsResponse> = {
  encode(message: ListSubscriptionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.subscriptions) {
      Subscription.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSubscriptionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSubscriptionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscriptions.push(Subscription.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSubscriptionsResponse {
    return {
      subscriptions: globalThis.Array.isArray(object?.subscriptions)
        ? object.subscriptions.map((e: any) => Subscription.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListSubscriptionsResponse): unknown {
    const obj: any = {};
    if (message.subscriptions?.length) {
      obj.subscriptions = message.subscriptions.map((e) => Subscription.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSubscriptionsResponse>): ListSubscriptionsResponse {
    return ListSubscriptionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSubscriptionsResponse>): ListSubscriptionsResponse {
    const message = createBaseListSubscriptionsResponse();
    message.subscriptions = object.subscriptions?.map((e) => Subscription.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteSubscriptionRequest(): DeleteSubscriptionRequest {
  return { subscription: "" };
}

export const DeleteSubscriptionRequest: MessageFns<DeleteSubscriptionRequest> = {
  encode(message: DeleteSubscriptionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteSubscriptionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteSubscriptionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteSubscriptionRequest {
    return { subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "" };
  },

  toJSON(message: DeleteSubscriptionRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteSubscriptionRequest>): DeleteSubscriptionRequest {
    return DeleteSubscriptionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteSubscriptionRequest>): DeleteSubscriptionRequest {
    const message = createBaseDeleteSubscriptionRequest();
    message.subscription = object.subscription ?? "";
    return message;
  },
};

function createBaseModifyPushConfigRequest(): ModifyPushConfigRequest {
  return { subscription: "", pushConfig: undefined };
}

export const ModifyPushConfigRequest: MessageFns<ModifyPushConfigRequest> = {
  encode(message: ModifyPushConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    if (message.pushConfig !== undefined) {
      PushConfig.encode(message.pushConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModifyPushConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModifyPushConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pushConfig = PushConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModifyPushConfigRequest {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      pushConfig: isSet(object.pushConfig) ? PushConfig.fromJSON(object.pushConfig) : undefined,
    };
  },

  toJSON(message: ModifyPushConfigRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.pushConfig !== undefined) {
      obj.pushConfig = PushConfig.toJSON(message.pushConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<ModifyPushConfigRequest>): ModifyPushConfigRequest {
    return ModifyPushConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModifyPushConfigRequest>): ModifyPushConfigRequest {
    const message = createBaseModifyPushConfigRequest();
    message.subscription = object.subscription ?? "";
    message.pushConfig = (object.pushConfig !== undefined && object.pushConfig !== null)
      ? PushConfig.fromPartial(object.pushConfig)
      : undefined;
    return message;
  },
};

function createBasePullRequest(): PullRequest {
  return { subscription: "", returnImmediately: false, maxMessages: 0 };
}

export const PullRequest: MessageFns<PullRequest> = {
  encode(message: PullRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    if (message.returnImmediately !== false) {
      writer.uint32(16).bool(message.returnImmediately);
    }
    if (message.maxMessages !== 0) {
      writer.uint32(24).int32(message.maxMessages);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PullRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePullRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.returnImmediately = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.maxMessages = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PullRequest {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      returnImmediately: isSet(object.returnImmediately) ? globalThis.Boolean(object.returnImmediately) : false,
      maxMessages: isSet(object.maxMessages) ? globalThis.Number(object.maxMessages) : 0,
    };
  },

  toJSON(message: PullRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.returnImmediately !== false) {
      obj.returnImmediately = message.returnImmediately;
    }
    if (message.maxMessages !== 0) {
      obj.maxMessages = Math.round(message.maxMessages);
    }
    return obj;
  },

  create(base?: DeepPartial<PullRequest>): PullRequest {
    return PullRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PullRequest>): PullRequest {
    const message = createBasePullRequest();
    message.subscription = object.subscription ?? "";
    message.returnImmediately = object.returnImmediately ?? false;
    message.maxMessages = object.maxMessages ?? 0;
    return message;
  },
};

function createBasePullResponse(): PullResponse {
  return { receivedMessages: [] };
}

export const PullResponse: MessageFns<PullResponse> = {
  encode(message: PullResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.receivedMessages) {
      ReceivedMessage.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PullResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePullResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.receivedMessages.push(ReceivedMessage.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PullResponse {
    return {
      receivedMessages: globalThis.Array.isArray(object?.receivedMessages)
        ? object.receivedMessages.map((e: any) => ReceivedMessage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PullResponse): unknown {
    const obj: any = {};
    if (message.receivedMessages?.length) {
      obj.receivedMessages = message.receivedMessages.map((e) => ReceivedMessage.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PullResponse>): PullResponse {
    return PullResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PullResponse>): PullResponse {
    const message = createBasePullResponse();
    message.receivedMessages = object.receivedMessages?.map((e) => ReceivedMessage.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModifyAckDeadlineRequest(): ModifyAckDeadlineRequest {
  return { subscription: "", ackIds: [], ackDeadlineSeconds: 0 };
}

export const ModifyAckDeadlineRequest: MessageFns<ModifyAckDeadlineRequest> = {
  encode(message: ModifyAckDeadlineRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    for (const v of message.ackIds) {
      writer.uint32(34).string(v!);
    }
    if (message.ackDeadlineSeconds !== 0) {
      writer.uint32(24).int32(message.ackDeadlineSeconds);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModifyAckDeadlineRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModifyAckDeadlineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.ackIds.push(reader.string());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ackDeadlineSeconds = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModifyAckDeadlineRequest {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      ackIds: globalThis.Array.isArray(object?.ackIds) ? object.ackIds.map((e: any) => globalThis.String(e)) : [],
      ackDeadlineSeconds: isSet(object.ackDeadlineSeconds) ? globalThis.Number(object.ackDeadlineSeconds) : 0,
    };
  },

  toJSON(message: ModifyAckDeadlineRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.ackIds?.length) {
      obj.ackIds = message.ackIds;
    }
    if (message.ackDeadlineSeconds !== 0) {
      obj.ackDeadlineSeconds = Math.round(message.ackDeadlineSeconds);
    }
    return obj;
  },

  create(base?: DeepPartial<ModifyAckDeadlineRequest>): ModifyAckDeadlineRequest {
    return ModifyAckDeadlineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModifyAckDeadlineRequest>): ModifyAckDeadlineRequest {
    const message = createBaseModifyAckDeadlineRequest();
    message.subscription = object.subscription ?? "";
    message.ackIds = object.ackIds?.map((e) => e) || [];
    message.ackDeadlineSeconds = object.ackDeadlineSeconds ?? 0;
    return message;
  },
};

function createBaseAcknowledgeRequest(): AcknowledgeRequest {
  return { subscription: "", ackIds: [] };
}

export const AcknowledgeRequest: MessageFns<AcknowledgeRequest> = {
  encode(message: AcknowledgeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    for (const v of message.ackIds) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AcknowledgeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAcknowledgeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.ackIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AcknowledgeRequest {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      ackIds: globalThis.Array.isArray(object?.ackIds) ? object.ackIds.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: AcknowledgeRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.ackIds?.length) {
      obj.ackIds = message.ackIds;
    }
    return obj;
  },

  create(base?: DeepPartial<AcknowledgeRequest>): AcknowledgeRequest {
    return AcknowledgeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AcknowledgeRequest>): AcknowledgeRequest {
    const message = createBaseAcknowledgeRequest();
    message.subscription = object.subscription ?? "";
    message.ackIds = object.ackIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseStreamingPullRequest(): StreamingPullRequest {
  return {
    subscription: "",
    ackIds: [],
    modifyDeadlineSeconds: [],
    modifyDeadlineAckIds: [],
    streamAckDeadlineSeconds: 0,
    clientId: "",
    maxOutstandingMessages: Long.ZERO,
    maxOutstandingBytes: Long.ZERO,
  };
}

export const StreamingPullRequest: MessageFns<StreamingPullRequest> = {
  encode(message: StreamingPullRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    for (const v of message.ackIds) {
      writer.uint32(18).string(v!);
    }
    writer.uint32(26).fork();
    for (const v of message.modifyDeadlineSeconds) {
      writer.int32(v);
    }
    writer.join();
    for (const v of message.modifyDeadlineAckIds) {
      writer.uint32(34).string(v!);
    }
    if (message.streamAckDeadlineSeconds !== 0) {
      writer.uint32(40).int32(message.streamAckDeadlineSeconds);
    }
    if (message.clientId !== "") {
      writer.uint32(50).string(message.clientId);
    }
    if (!message.maxOutstandingMessages.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.maxOutstandingMessages.toString());
    }
    if (!message.maxOutstandingBytes.equals(Long.ZERO)) {
      writer.uint32(64).int64(message.maxOutstandingBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingPullRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingPullRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.ackIds.push(reader.string());
          continue;
        case 3:
          if (tag === 24) {
            message.modifyDeadlineSeconds.push(reader.int32());

            continue;
          }

          if (tag === 26) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.modifyDeadlineSeconds.push(reader.int32());
            }

            continue;
          }

          break;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.modifyDeadlineAckIds.push(reader.string());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.streamAckDeadlineSeconds = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.clientId = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.maxOutstandingMessages = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.maxOutstandingBytes = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingPullRequest {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      ackIds: globalThis.Array.isArray(object?.ackIds) ? object.ackIds.map((e: any) => globalThis.String(e)) : [],
      modifyDeadlineSeconds: globalThis.Array.isArray(object?.modifyDeadlineSeconds)
        ? object.modifyDeadlineSeconds.map((e: any) => globalThis.Number(e))
        : [],
      modifyDeadlineAckIds: globalThis.Array.isArray(object?.modifyDeadlineAckIds)
        ? object.modifyDeadlineAckIds.map((e: any) => globalThis.String(e))
        : [],
      streamAckDeadlineSeconds: isSet(object.streamAckDeadlineSeconds)
        ? globalThis.Number(object.streamAckDeadlineSeconds)
        : 0,
      clientId: isSet(object.clientId) ? globalThis.String(object.clientId) : "",
      maxOutstandingMessages: isSet(object.maxOutstandingMessages)
        ? Long.fromValue(object.maxOutstandingMessages)
        : Long.ZERO,
      maxOutstandingBytes: isSet(object.maxOutstandingBytes) ? Long.fromValue(object.maxOutstandingBytes) : Long.ZERO,
    };
  },

  toJSON(message: StreamingPullRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.ackIds?.length) {
      obj.ackIds = message.ackIds;
    }
    if (message.modifyDeadlineSeconds?.length) {
      obj.modifyDeadlineSeconds = message.modifyDeadlineSeconds.map((e) => Math.round(e));
    }
    if (message.modifyDeadlineAckIds?.length) {
      obj.modifyDeadlineAckIds = message.modifyDeadlineAckIds;
    }
    if (message.streamAckDeadlineSeconds !== 0) {
      obj.streamAckDeadlineSeconds = Math.round(message.streamAckDeadlineSeconds);
    }
    if (message.clientId !== "") {
      obj.clientId = message.clientId;
    }
    if (!message.maxOutstandingMessages.equals(Long.ZERO)) {
      obj.maxOutstandingMessages = (message.maxOutstandingMessages || Long.ZERO).toString();
    }
    if (!message.maxOutstandingBytes.equals(Long.ZERO)) {
      obj.maxOutstandingBytes = (message.maxOutstandingBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingPullRequest>): StreamingPullRequest {
    return StreamingPullRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingPullRequest>): StreamingPullRequest {
    const message = createBaseStreamingPullRequest();
    message.subscription = object.subscription ?? "";
    message.ackIds = object.ackIds?.map((e) => e) || [];
    message.modifyDeadlineSeconds = object.modifyDeadlineSeconds?.map((e) => e) || [];
    message.modifyDeadlineAckIds = object.modifyDeadlineAckIds?.map((e) => e) || [];
    message.streamAckDeadlineSeconds = object.streamAckDeadlineSeconds ?? 0;
    message.clientId = object.clientId ?? "";
    message.maxOutstandingMessages =
      (object.maxOutstandingMessages !== undefined && object.maxOutstandingMessages !== null)
        ? Long.fromValue(object.maxOutstandingMessages)
        : Long.ZERO;
    message.maxOutstandingBytes = (object.maxOutstandingBytes !== undefined && object.maxOutstandingBytes !== null)
      ? Long.fromValue(object.maxOutstandingBytes)
      : Long.ZERO;
    return message;
  },
};

function createBaseStreamingPullResponse(): StreamingPullResponse {
  return {
    receivedMessages: [],
    acknowledgeConfirmation: undefined,
    modifyAckDeadlineConfirmation: undefined,
    subscriptionProperties: undefined,
  };
}

export const StreamingPullResponse: MessageFns<StreamingPullResponse> = {
  encode(message: StreamingPullResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.receivedMessages) {
      ReceivedMessage.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.acknowledgeConfirmation !== undefined) {
      StreamingPullResponse_AcknowledgeConfirmation.encode(message.acknowledgeConfirmation, writer.uint32(42).fork())
        .join();
    }
    if (message.modifyAckDeadlineConfirmation !== undefined) {
      StreamingPullResponse_ModifyAckDeadlineConfirmation.encode(
        message.modifyAckDeadlineConfirmation,
        writer.uint32(26).fork(),
      ).join();
    }
    if (message.subscriptionProperties !== undefined) {
      StreamingPullResponse_SubscriptionProperties.encode(message.subscriptionProperties, writer.uint32(34).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingPullResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingPullResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.receivedMessages.push(ReceivedMessage.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.acknowledgeConfirmation = StreamingPullResponse_AcknowledgeConfirmation.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.modifyAckDeadlineConfirmation = StreamingPullResponse_ModifyAckDeadlineConfirmation.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.subscriptionProperties = StreamingPullResponse_SubscriptionProperties.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingPullResponse {
    return {
      receivedMessages: globalThis.Array.isArray(object?.receivedMessages)
        ? object.receivedMessages.map((e: any) => ReceivedMessage.fromJSON(e))
        : [],
      acknowledgeConfirmation: isSet(object.acknowledgeConfirmation)
        ? StreamingPullResponse_AcknowledgeConfirmation.fromJSON(object.acknowledgeConfirmation)
        : undefined,
      modifyAckDeadlineConfirmation: isSet(object.modifyAckDeadlineConfirmation)
        ? StreamingPullResponse_ModifyAckDeadlineConfirmation.fromJSON(object.modifyAckDeadlineConfirmation)
        : undefined,
      subscriptionProperties: isSet(object.subscriptionProperties)
        ? StreamingPullResponse_SubscriptionProperties.fromJSON(object.subscriptionProperties)
        : undefined,
    };
  },

  toJSON(message: StreamingPullResponse): unknown {
    const obj: any = {};
    if (message.receivedMessages?.length) {
      obj.receivedMessages = message.receivedMessages.map((e) => ReceivedMessage.toJSON(e));
    }
    if (message.acknowledgeConfirmation !== undefined) {
      obj.acknowledgeConfirmation = StreamingPullResponse_AcknowledgeConfirmation.toJSON(
        message.acknowledgeConfirmation,
      );
    }
    if (message.modifyAckDeadlineConfirmation !== undefined) {
      obj.modifyAckDeadlineConfirmation = StreamingPullResponse_ModifyAckDeadlineConfirmation.toJSON(
        message.modifyAckDeadlineConfirmation,
      );
    }
    if (message.subscriptionProperties !== undefined) {
      obj.subscriptionProperties = StreamingPullResponse_SubscriptionProperties.toJSON(message.subscriptionProperties);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingPullResponse>): StreamingPullResponse {
    return StreamingPullResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingPullResponse>): StreamingPullResponse {
    const message = createBaseStreamingPullResponse();
    message.receivedMessages = object.receivedMessages?.map((e) => ReceivedMessage.fromPartial(e)) || [];
    message.acknowledgeConfirmation =
      (object.acknowledgeConfirmation !== undefined && object.acknowledgeConfirmation !== null)
        ? StreamingPullResponse_AcknowledgeConfirmation.fromPartial(object.acknowledgeConfirmation)
        : undefined;
    message.modifyAckDeadlineConfirmation =
      (object.modifyAckDeadlineConfirmation !== undefined && object.modifyAckDeadlineConfirmation !== null)
        ? StreamingPullResponse_ModifyAckDeadlineConfirmation.fromPartial(object.modifyAckDeadlineConfirmation)
        : undefined;
    message.subscriptionProperties =
      (object.subscriptionProperties !== undefined && object.subscriptionProperties !== null)
        ? StreamingPullResponse_SubscriptionProperties.fromPartial(object.subscriptionProperties)
        : undefined;
    return message;
  },
};

function createBaseStreamingPullResponse_AcknowledgeConfirmation(): StreamingPullResponse_AcknowledgeConfirmation {
  return { ackIds: [], invalidAckIds: [], unorderedAckIds: [], temporaryFailedAckIds: [] };
}

export const StreamingPullResponse_AcknowledgeConfirmation: MessageFns<StreamingPullResponse_AcknowledgeConfirmation> =
  {
    encode(
      message: StreamingPullResponse_AcknowledgeConfirmation,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.ackIds) {
        writer.uint32(10).string(v!);
      }
      for (const v of message.invalidAckIds) {
        writer.uint32(18).string(v!);
      }
      for (const v of message.unorderedAckIds) {
        writer.uint32(26).string(v!);
      }
      for (const v of message.temporaryFailedAckIds) {
        writer.uint32(34).string(v!);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): StreamingPullResponse_AcknowledgeConfirmation {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseStreamingPullResponse_AcknowledgeConfirmation();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.ackIds.push(reader.string());
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.invalidAckIds.push(reader.string());
            continue;
          case 3:
            if (tag !== 26) {
              break;
            }

            message.unorderedAckIds.push(reader.string());
            continue;
          case 4:
            if (tag !== 34) {
              break;
            }

            message.temporaryFailedAckIds.push(reader.string());
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): StreamingPullResponse_AcknowledgeConfirmation {
      return {
        ackIds: globalThis.Array.isArray(object?.ackIds) ? object.ackIds.map((e: any) => globalThis.String(e)) : [],
        invalidAckIds: globalThis.Array.isArray(object?.invalidAckIds)
          ? object.invalidAckIds.map((e: any) => globalThis.String(e))
          : [],
        unorderedAckIds: globalThis.Array.isArray(object?.unorderedAckIds)
          ? object.unorderedAckIds.map((e: any) => globalThis.String(e))
          : [],
        temporaryFailedAckIds: globalThis.Array.isArray(object?.temporaryFailedAckIds)
          ? object.temporaryFailedAckIds.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: StreamingPullResponse_AcknowledgeConfirmation): unknown {
      const obj: any = {};
      if (message.ackIds?.length) {
        obj.ackIds = message.ackIds;
      }
      if (message.invalidAckIds?.length) {
        obj.invalidAckIds = message.invalidAckIds;
      }
      if (message.unorderedAckIds?.length) {
        obj.unorderedAckIds = message.unorderedAckIds;
      }
      if (message.temporaryFailedAckIds?.length) {
        obj.temporaryFailedAckIds = message.temporaryFailedAckIds;
      }
      return obj;
    },

    create(
      base?: DeepPartial<StreamingPullResponse_AcknowledgeConfirmation>,
    ): StreamingPullResponse_AcknowledgeConfirmation {
      return StreamingPullResponse_AcknowledgeConfirmation.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<StreamingPullResponse_AcknowledgeConfirmation>,
    ): StreamingPullResponse_AcknowledgeConfirmation {
      const message = createBaseStreamingPullResponse_AcknowledgeConfirmation();
      message.ackIds = object.ackIds?.map((e) => e) || [];
      message.invalidAckIds = object.invalidAckIds?.map((e) => e) || [];
      message.unorderedAckIds = object.unorderedAckIds?.map((e) => e) || [];
      message.temporaryFailedAckIds = object.temporaryFailedAckIds?.map((e) => e) || [];
      return message;
    },
  };

function createBaseStreamingPullResponse_ModifyAckDeadlineConfirmation(): StreamingPullResponse_ModifyAckDeadlineConfirmation {
  return { ackIds: [], invalidAckIds: [], temporaryFailedAckIds: [] };
}

export const StreamingPullResponse_ModifyAckDeadlineConfirmation: MessageFns<
  StreamingPullResponse_ModifyAckDeadlineConfirmation
> = {
  encode(
    message: StreamingPullResponse_ModifyAckDeadlineConfirmation,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.ackIds) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.invalidAckIds) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.temporaryFailedAckIds) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingPullResponse_ModifyAckDeadlineConfirmation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingPullResponse_ModifyAckDeadlineConfirmation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ackIds.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.invalidAckIds.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.temporaryFailedAckIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingPullResponse_ModifyAckDeadlineConfirmation {
    return {
      ackIds: globalThis.Array.isArray(object?.ackIds) ? object.ackIds.map((e: any) => globalThis.String(e)) : [],
      invalidAckIds: globalThis.Array.isArray(object?.invalidAckIds)
        ? object.invalidAckIds.map((e: any) => globalThis.String(e))
        : [],
      temporaryFailedAckIds: globalThis.Array.isArray(object?.temporaryFailedAckIds)
        ? object.temporaryFailedAckIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: StreamingPullResponse_ModifyAckDeadlineConfirmation): unknown {
    const obj: any = {};
    if (message.ackIds?.length) {
      obj.ackIds = message.ackIds;
    }
    if (message.invalidAckIds?.length) {
      obj.invalidAckIds = message.invalidAckIds;
    }
    if (message.temporaryFailedAckIds?.length) {
      obj.temporaryFailedAckIds = message.temporaryFailedAckIds;
    }
    return obj;
  },

  create(
    base?: DeepPartial<StreamingPullResponse_ModifyAckDeadlineConfirmation>,
  ): StreamingPullResponse_ModifyAckDeadlineConfirmation {
    return StreamingPullResponse_ModifyAckDeadlineConfirmation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<StreamingPullResponse_ModifyAckDeadlineConfirmation>,
  ): StreamingPullResponse_ModifyAckDeadlineConfirmation {
    const message = createBaseStreamingPullResponse_ModifyAckDeadlineConfirmation();
    message.ackIds = object.ackIds?.map((e) => e) || [];
    message.invalidAckIds = object.invalidAckIds?.map((e) => e) || [];
    message.temporaryFailedAckIds = object.temporaryFailedAckIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseStreamingPullResponse_SubscriptionProperties(): StreamingPullResponse_SubscriptionProperties {
  return { exactlyOnceDeliveryEnabled: false, messageOrderingEnabled: false };
}

export const StreamingPullResponse_SubscriptionProperties: MessageFns<StreamingPullResponse_SubscriptionProperties> = {
  encode(
    message: StreamingPullResponse_SubscriptionProperties,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.exactlyOnceDeliveryEnabled !== false) {
      writer.uint32(8).bool(message.exactlyOnceDeliveryEnabled);
    }
    if (message.messageOrderingEnabled !== false) {
      writer.uint32(16).bool(message.messageOrderingEnabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingPullResponse_SubscriptionProperties {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingPullResponse_SubscriptionProperties();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.exactlyOnceDeliveryEnabled = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.messageOrderingEnabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingPullResponse_SubscriptionProperties {
    return {
      exactlyOnceDeliveryEnabled: isSet(object.exactlyOnceDeliveryEnabled)
        ? globalThis.Boolean(object.exactlyOnceDeliveryEnabled)
        : false,
      messageOrderingEnabled: isSet(object.messageOrderingEnabled)
        ? globalThis.Boolean(object.messageOrderingEnabled)
        : false,
    };
  },

  toJSON(message: StreamingPullResponse_SubscriptionProperties): unknown {
    const obj: any = {};
    if (message.exactlyOnceDeliveryEnabled !== false) {
      obj.exactlyOnceDeliveryEnabled = message.exactlyOnceDeliveryEnabled;
    }
    if (message.messageOrderingEnabled !== false) {
      obj.messageOrderingEnabled = message.messageOrderingEnabled;
    }
    return obj;
  },

  create(
    base?: DeepPartial<StreamingPullResponse_SubscriptionProperties>,
  ): StreamingPullResponse_SubscriptionProperties {
    return StreamingPullResponse_SubscriptionProperties.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<StreamingPullResponse_SubscriptionProperties>,
  ): StreamingPullResponse_SubscriptionProperties {
    const message = createBaseStreamingPullResponse_SubscriptionProperties();
    message.exactlyOnceDeliveryEnabled = object.exactlyOnceDeliveryEnabled ?? false;
    message.messageOrderingEnabled = object.messageOrderingEnabled ?? false;
    return message;
  },
};

function createBaseCreateSnapshotRequest(): CreateSnapshotRequest {
  return { name: "", subscription: "", labels: {} };
}

export const CreateSnapshotRequest: MessageFns<CreateSnapshotRequest> = {
  encode(message: CreateSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.subscription !== "") {
      writer.uint32(18).string(message.subscription);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      CreateSnapshotRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = CreateSnapshotRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateSnapshotRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: CreateSnapshotRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<CreateSnapshotRequest>): CreateSnapshotRequest {
    return CreateSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateSnapshotRequest>): CreateSnapshotRequest {
    const message = createBaseCreateSnapshotRequest();
    message.name = object.name ?? "";
    message.subscription = object.subscription ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseCreateSnapshotRequest_LabelsEntry(): CreateSnapshotRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const CreateSnapshotRequest_LabelsEntry: MessageFns<CreateSnapshotRequest_LabelsEntry> = {
  encode(message: CreateSnapshotRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateSnapshotRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateSnapshotRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateSnapshotRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CreateSnapshotRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateSnapshotRequest_LabelsEntry>): CreateSnapshotRequest_LabelsEntry {
    return CreateSnapshotRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateSnapshotRequest_LabelsEntry>): CreateSnapshotRequest_LabelsEntry {
    const message = createBaseCreateSnapshotRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseUpdateSnapshotRequest(): UpdateSnapshotRequest {
  return { snapshot: undefined, updateMask: undefined };
}

export const UpdateSnapshotRequest: MessageFns<UpdateSnapshotRequest> = {
  encode(message: UpdateSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshot !== undefined) {
      Snapshot.encode(message.snapshot, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshot = Snapshot.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateSnapshotRequest {
    return {
      snapshot: isSet(object.snapshot) ? Snapshot.fromJSON(object.snapshot) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateSnapshotRequest): unknown {
    const obj: any = {};
    if (message.snapshot !== undefined) {
      obj.snapshot = Snapshot.toJSON(message.snapshot);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateSnapshotRequest>): UpdateSnapshotRequest {
    return UpdateSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateSnapshotRequest>): UpdateSnapshotRequest {
    const message = createBaseUpdateSnapshotRequest();
    message.snapshot = (object.snapshot !== undefined && object.snapshot !== null)
      ? Snapshot.fromPartial(object.snapshot)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseSnapshot(): Snapshot {
  return { name: "", topic: "", expireTime: undefined, labels: {} };
}

export const Snapshot: MessageFns<Snapshot> = {
  encode(message: Snapshot, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.topic !== "") {
      writer.uint32(18).string(message.topic);
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Snapshot_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Snapshot {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSnapshot();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = Snapshot_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Snapshot {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Snapshot): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<Snapshot>): Snapshot {
    return Snapshot.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Snapshot>): Snapshot {
    const message = createBaseSnapshot();
    message.name = object.name ?? "";
    message.topic = object.topic ?? "";
    message.expireTime = object.expireTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseSnapshot_LabelsEntry(): Snapshot_LabelsEntry {
  return { key: "", value: "" };
}

export const Snapshot_LabelsEntry: MessageFns<Snapshot_LabelsEntry> = {
  encode(message: Snapshot_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Snapshot_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSnapshot_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Snapshot_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Snapshot_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Snapshot_LabelsEntry>): Snapshot_LabelsEntry {
    return Snapshot_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Snapshot_LabelsEntry>): Snapshot_LabelsEntry {
    const message = createBaseSnapshot_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseGetSnapshotRequest(): GetSnapshotRequest {
  return { snapshot: "" };
}

export const GetSnapshotRequest: MessageFns<GetSnapshotRequest> = {
  encode(message: GetSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshot !== "") {
      writer.uint32(10).string(message.snapshot);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshot = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetSnapshotRequest {
    return { snapshot: isSet(object.snapshot) ? globalThis.String(object.snapshot) : "" };
  },

  toJSON(message: GetSnapshotRequest): unknown {
    const obj: any = {};
    if (message.snapshot !== "") {
      obj.snapshot = message.snapshot;
    }
    return obj;
  },

  create(base?: DeepPartial<GetSnapshotRequest>): GetSnapshotRequest {
    return GetSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetSnapshotRequest>): GetSnapshotRequest {
    const message = createBaseGetSnapshotRequest();
    message.snapshot = object.snapshot ?? "";
    return message;
  },
};

function createBaseListSnapshotsRequest(): ListSnapshotsRequest {
  return { project: "", pageSize: 0, pageToken: "" };
}

export const ListSnapshotsRequest: MessageFns<ListSnapshotsRequest> = {
  encode(message: ListSnapshotsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSnapshotsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSnapshotsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSnapshotsRequest {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListSnapshotsRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSnapshotsRequest>): ListSnapshotsRequest {
    return ListSnapshotsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSnapshotsRequest>): ListSnapshotsRequest {
    const message = createBaseListSnapshotsRequest();
    message.project = object.project ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListSnapshotsResponse(): ListSnapshotsResponse {
  return { snapshots: [], nextPageToken: "" };
}

export const ListSnapshotsResponse: MessageFns<ListSnapshotsResponse> = {
  encode(message: ListSnapshotsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.snapshots) {
      Snapshot.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSnapshotsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSnapshotsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshots.push(Snapshot.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSnapshotsResponse {
    return {
      snapshots: globalThis.Array.isArray(object?.snapshots)
        ? object.snapshots.map((e: any) => Snapshot.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListSnapshotsResponse): unknown {
    const obj: any = {};
    if (message.snapshots?.length) {
      obj.snapshots = message.snapshots.map((e) => Snapshot.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSnapshotsResponse>): ListSnapshotsResponse {
    return ListSnapshotsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSnapshotsResponse>): ListSnapshotsResponse {
    const message = createBaseListSnapshotsResponse();
    message.snapshots = object.snapshots?.map((e) => Snapshot.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteSnapshotRequest(): DeleteSnapshotRequest {
  return { snapshot: "" };
}

export const DeleteSnapshotRequest: MessageFns<DeleteSnapshotRequest> = {
  encode(message: DeleteSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshot !== "") {
      writer.uint32(10).string(message.snapshot);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshot = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteSnapshotRequest {
    return { snapshot: isSet(object.snapshot) ? globalThis.String(object.snapshot) : "" };
  },

  toJSON(message: DeleteSnapshotRequest): unknown {
    const obj: any = {};
    if (message.snapshot !== "") {
      obj.snapshot = message.snapshot;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteSnapshotRequest>): DeleteSnapshotRequest {
    return DeleteSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteSnapshotRequest>): DeleteSnapshotRequest {
    const message = createBaseDeleteSnapshotRequest();
    message.snapshot = object.snapshot ?? "";
    return message;
  },
};

function createBaseSeekRequest(): SeekRequest {
  return { subscription: "", time: undefined, snapshot: undefined };
}

export const SeekRequest: MessageFns<SeekRequest> = {
  encode(message: SeekRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    if (message.time !== undefined) {
      Timestamp.encode(toTimestamp(message.time), writer.uint32(18).fork()).join();
    }
    if (message.snapshot !== undefined) {
      writer.uint32(26).string(message.snapshot);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SeekRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSeekRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.time = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.snapshot = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SeekRequest {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      time: isSet(object.time) ? fromJsonTimestamp(object.time) : undefined,
      snapshot: isSet(object.snapshot) ? globalThis.String(object.snapshot) : undefined,
    };
  },

  toJSON(message: SeekRequest): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.time !== undefined) {
      obj.time = message.time.toISOString();
    }
    if (message.snapshot !== undefined) {
      obj.snapshot = message.snapshot;
    }
    return obj;
  },

  create(base?: DeepPartial<SeekRequest>): SeekRequest {
    return SeekRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SeekRequest>): SeekRequest {
    const message = createBaseSeekRequest();
    message.subscription = object.subscription ?? "";
    message.time = object.time ?? undefined;
    message.snapshot = object.snapshot ?? undefined;
    return message;
  },
};

function createBaseSeekResponse(): SeekResponse {
  return {};
}

export const SeekResponse: MessageFns<SeekResponse> = {
  encode(_: SeekResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SeekResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSeekResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): SeekResponse {
    return {};
  },

  toJSON(_: SeekResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<SeekResponse>): SeekResponse {
    return SeekResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<SeekResponse>): SeekResponse {
    const message = createBaseSeekResponse();
    return message;
  },
};

/**
 * The service that an application uses to manipulate topics, and to send
 * messages to a topic.
 */
export type PublisherDefinition = typeof PublisherDefinition;
export const PublisherDefinition = {
  name: "Publisher",
  fullName: "google.pubsub.v1.Publisher",
  methods: {
    /**
     * Creates the given topic with the given name. See the [resource name rules]
     * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
     */
    createTopic: {
      name: "CreateTopic",
      requestType: Topic,
      requestStream: false,
      responseType: Topic,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              35,
              58,
              1,
              42,
              26,
              30,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates an existing topic by updating the fields specified in the update
     * mask. Note that certain properties of a topic are not modifiable.
     */
    updateTopic: {
      name: "UpdateTopic",
      requestType: UpdateTopicRequest,
      requestStream: false,
      responseType: Topic,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([17, 116, 111, 112, 105, 99, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365826: [
            Buffer.from([
              41,
              58,
              1,
              42,
              50,
              36,
              47,
              118,
              49,
              47,
              123,
              116,
              111,
              112,
              105,
              99,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Adds one or more messages to the topic. Returns `NOT_FOUND` if the topic
     * does not exist.
     */
    publish: {
      name: "Publish",
      requestType: PublishRequest,
      requestStream: false,
      responseType: PublishResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([14, 116, 111, 112, 105, 99, 44, 109, 101, 115, 115, 97, 103, 101, 115])],
          578365826: [
            Buffer.from([
              44,
              58,
              1,
              42,
              34,
              39,
              47,
              118,
              49,
              47,
              123,
              116,
              111,
              112,
              105,
              99,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
              58,
              112,
              117,
              98,
              108,
              105,
              115,
              104,
            ]),
          ],
        },
      },
    },
    /** Gets the configuration of a topic. */
    getTopic: {
      name: "GetTopic",
      requestType: GetTopicRequest,
      requestStream: false,
      responseType: Topic,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([5, 116, 111, 112, 105, 99])],
          578365826: [
            Buffer.from([
              33,
              18,
              31,
              47,
              118,
              49,
              47,
              123,
              116,
              111,
              112,
              105,
              99,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists matching topics. */
    listTopics: {
      name: "ListTopics",
      requestType: ListTopicsRequest,
      requestStream: false,
      responseType: ListTopicsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([7, 112, 114, 111, 106, 101, 99, 116])],
          578365826: [
            Buffer.from([
              33,
              18,
              31,
              47,
              118,
              49,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists the names of the attached subscriptions on this topic. */
    listTopicSubscriptions: {
      name: "ListTopicSubscriptions",
      requestType: ListTopicSubscriptionsRequest,
      requestStream: false,
      responseType: ListTopicSubscriptionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([5, 116, 111, 112, 105, 99])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              116,
              111,
              112,
              105,
              99,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Lists the names of the snapshots on this topic. Snapshots are used in
     * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
     * which allow you to manage message acknowledgments in bulk. That is, you can
     * set the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot.
     */
    listTopicSnapshots: {
      name: "ListTopicSnapshots",
      requestType: ListTopicSnapshotsRequest,
      requestStream: false,
      responseType: ListTopicSnapshotsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([5, 116, 111, 112, 105, 99])],
          578365826: [
            Buffer.from([
              43,
              18,
              41,
              47,
              118,
              49,
              47,
              123,
              116,
              111,
              112,
              105,
              99,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes the topic with the given name. Returns `NOT_FOUND` if the topic
     * does not exist. After a topic is deleted, a new topic may be created with
     * the same name; this is an entirely new topic with none of the old
     * configuration or subscriptions. Existing subscriptions to this topic are
     * not deleted, but their `topic` field is set to `_deleted-topic_`.
     */
    deleteTopic: {
      name: "DeleteTopic",
      requestType: DeleteTopicRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([5, 116, 111, 112, 105, 99])],
          578365826: [
            Buffer.from([
              33,
              42,
              31,
              47,
              118,
              49,
              47,
              123,
              116,
              111,
              112,
              105,
              99,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              116,
              111,
              112,
              105,
              99,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Detaches a subscription from this topic. All messages retained in the
     * subscription are dropped. Subsequent `Pull` and `StreamingPull` requests
     * will return FAILED_PRECONDITION. If the subscription is a push
     * subscription, pushes to the endpoint will stop.
     */
    detachSubscription: {
      name: "DetachSubscription",
      requestType: DetachSubscriptionRequest,
      requestStream: false,
      responseType: DetachSubscriptionResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              54,
              34,
              52,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              116,
              97,
              99,
              104,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface PublisherServiceImplementation<CallContextExt = {}> {
  /**
   * Creates the given topic with the given name. See the [resource name rules]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
   */
  createTopic(request: Topic, context: CallContext & CallContextExt): Promise<DeepPartial<Topic>>;
  /**
   * Updates an existing topic by updating the fields specified in the update
   * mask. Note that certain properties of a topic are not modifiable.
   */
  updateTopic(request: UpdateTopicRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Topic>>;
  /**
   * Adds one or more messages to the topic. Returns `NOT_FOUND` if the topic
   * does not exist.
   */
  publish(request: PublishRequest, context: CallContext & CallContextExt): Promise<DeepPartial<PublishResponse>>;
  /** Gets the configuration of a topic. */
  getTopic(request: GetTopicRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Topic>>;
  /** Lists matching topics. */
  listTopics(
    request: ListTopicsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTopicsResponse>>;
  /** Lists the names of the attached subscriptions on this topic. */
  listTopicSubscriptions(
    request: ListTopicSubscriptionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTopicSubscriptionsResponse>>;
  /**
   * Lists the names of the snapshots on this topic. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  listTopicSnapshots(
    request: ListTopicSnapshotsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTopicSnapshotsResponse>>;
  /**
   * Deletes the topic with the given name. Returns `NOT_FOUND` if the topic
   * does not exist. After a topic is deleted, a new topic may be created with
   * the same name; this is an entirely new topic with none of the old
   * configuration or subscriptions. Existing subscriptions to this topic are
   * not deleted, but their `topic` field is set to `_deleted-topic_`.
   */
  deleteTopic(request: DeleteTopicRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Detaches a subscription from this topic. All messages retained in the
   * subscription are dropped. Subsequent `Pull` and `StreamingPull` requests
   * will return FAILED_PRECONDITION. If the subscription is a push
   * subscription, pushes to the endpoint will stop.
   */
  detachSubscription(
    request: DetachSubscriptionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DetachSubscriptionResponse>>;
}

export interface PublisherClient<CallOptionsExt = {}> {
  /**
   * Creates the given topic with the given name. See the [resource name rules]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
   */
  createTopic(request: DeepPartial<Topic>, options?: CallOptions & CallOptionsExt): Promise<Topic>;
  /**
   * Updates an existing topic by updating the fields specified in the update
   * mask. Note that certain properties of a topic are not modifiable.
   */
  updateTopic(request: DeepPartial<UpdateTopicRequest>, options?: CallOptions & CallOptionsExt): Promise<Topic>;
  /**
   * Adds one or more messages to the topic. Returns `NOT_FOUND` if the topic
   * does not exist.
   */
  publish(request: DeepPartial<PublishRequest>, options?: CallOptions & CallOptionsExt): Promise<PublishResponse>;
  /** Gets the configuration of a topic. */
  getTopic(request: DeepPartial<GetTopicRequest>, options?: CallOptions & CallOptionsExt): Promise<Topic>;
  /** Lists matching topics. */
  listTopics(
    request: DeepPartial<ListTopicsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTopicsResponse>;
  /** Lists the names of the attached subscriptions on this topic. */
  listTopicSubscriptions(
    request: DeepPartial<ListTopicSubscriptionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTopicSubscriptionsResponse>;
  /**
   * Lists the names of the snapshots on this topic. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  listTopicSnapshots(
    request: DeepPartial<ListTopicSnapshotsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTopicSnapshotsResponse>;
  /**
   * Deletes the topic with the given name. Returns `NOT_FOUND` if the topic
   * does not exist. After a topic is deleted, a new topic may be created with
   * the same name; this is an entirely new topic with none of the old
   * configuration or subscriptions. Existing subscriptions to this topic are
   * not deleted, but their `topic` field is set to `_deleted-topic_`.
   */
  deleteTopic(request: DeepPartial<DeleteTopicRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Detaches a subscription from this topic. All messages retained in the
   * subscription are dropped. Subsequent `Pull` and `StreamingPull` requests
   * will return FAILED_PRECONDITION. If the subscription is a push
   * subscription, pushes to the endpoint will stop.
   */
  detachSubscription(
    request: DeepPartial<DetachSubscriptionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DetachSubscriptionResponse>;
}

/**
 * The service that an application uses to manipulate subscriptions and to
 * consume messages from a subscription via the `Pull` method or by
 * establishing a bi-directional stream using the `StreamingPull` method.
 */
export type SubscriberDefinition = typeof SubscriberDefinition;
export const SubscriberDefinition = {
  name: "Subscriber",
  fullName: "google.pubsub.v1.Subscriber",
  methods: {
    /**
     * Creates a subscription to a given topic. See the [resource name rules]
     * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
     * If the subscription already exists, returns `ALREADY_EXISTS`.
     * If the corresponding topic doesn't exist, returns `NOT_FOUND`.
     *
     * If the name is not provided in the request, the server will assign a random
     * name for this subscription on the same project as the topic, conforming
     * to the [resource name format]
     * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names). The
     * generated name is populated in the returned Subscription object. Note that
     * for REST API requests, you must specify a name in the request.
     */
    createSubscription: {
      name: "CreateSubscription",
      requestType: Subscription,
      requestStream: false,
      responseType: Subscription,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              43,
              110,
              97,
              109,
              101,
              44,
              116,
              111,
              112,
              105,
              99,
              44,
              112,
              117,
              115,
              104,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              97,
              99,
              107,
              95,
              100,
              101,
              97,
              100,
              108,
              105,
              110,
              101,
              95,
              115,
              101,
              99,
              111,
              110,
              100,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              42,
              58,
              1,
              42,
              26,
              37,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets the configuration details of a subscription. */
    getSubscription: {
      name: "GetSubscription",
      requestType: GetSubscriptionRequest,
      requestStream: false,
      responseType: Subscription,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([12, 115, 117, 98, 115, 99, 114, 105, 112, 116, 105, 111, 110])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates an existing subscription by updating the fields specified in the
     * update mask. Note that certain properties of a subscription, such as its
     * topic, are not modifiable.
     */
    updateSubscription: {
      name: "UpdateSubscription",
      requestType: UpdateSubscriptionRequest,
      requestStream: false,
      responseType: Subscription,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              24,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              55,
              58,
              1,
              42,
              50,
              50,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists matching subscriptions. */
    listSubscriptions: {
      name: "ListSubscriptions",
      requestType: ListSubscriptionsRequest,
      requestStream: false,
      responseType: ListSubscriptionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([7, 112, 114, 111, 106, 101, 99, 116])],
          578365826: [
            Buffer.from([
              40,
              18,
              38,
              47,
              118,
              49,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes an existing subscription. All messages retained in the subscription
     * are immediately dropped. Calls to `Pull` after deletion will return
     * `NOT_FOUND`. After a subscription is deleted, a new one may be created with
     * the same name, but the new one has no association with the old
     * subscription or its topic unless the same topic is specified.
     */
    deleteSubscription: {
      name: "DeleteSubscription",
      requestType: DeleteSubscriptionRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([12, 115, 117, 98, 115, 99, 114, 105, 112, 116, 105, 111, 110])],
          578365826: [
            Buffer.from([
              47,
              42,
              45,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Modifies the ack deadline for a specific message. This method is useful
     * to indicate that more time is needed to process a message by the
     * subscriber, or to make the message available for redelivery if the
     * processing was interrupted. Note that this does not modify the
     * subscription-level `ackDeadlineSeconds` used for subsequent messages.
     */
    modifyAckDeadline: {
      name: "ModifyAckDeadline",
      requestType: ModifyAckDeadlineRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              41,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              44,
              97,
              99,
              107,
              95,
              105,
              100,
              115,
              44,
              97,
              99,
              107,
              95,
              100,
              101,
              97,
              100,
              108,
              105,
              110,
              101,
              95,
              115,
              101,
              99,
              111,
              110,
              100,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              109,
              111,
              100,
              105,
              102,
              121,
              65,
              99,
              107,
              68,
              101,
              97,
              100,
              108,
              105,
              110,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Acknowledges the messages associated with the `ack_ids` in the
     * `AcknowledgeRequest`. The Pub/Sub system can remove the relevant messages
     * from the subscription.
     *
     * Acknowledging a message whose ack deadline has expired may succeed,
     * but such a message may be redelivered later. Acknowledging a message more
     * than once will not result in an error.
     */
    acknowledge: {
      name: "Acknowledge",
      requestType: AcknowledgeRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              44,
              97,
              99,
              107,
              95,
              105,
              100,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              62,
              58,
              1,
              42,
              34,
              57,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              97,
              99,
              107,
              110,
              111,
              119,
              108,
              101,
              100,
              103,
              101,
            ]),
          ],
        },
      },
    },
    /** Pulls messages from the server. */
    pull: {
      name: "Pull",
      requestType: PullRequest,
      requestStream: false,
      responseType: PullResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              44,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              44,
              114,
              101,
              116,
              117,
              114,
              110,
              95,
              105,
              109,
              109,
              101,
              100,
              105,
              97,
              116,
              101,
              108,
              121,
              44,
              109,
              97,
              120,
              95,
              109,
              101,
              115,
              115,
              97,
              103,
              101,
              115,
            ]),
            Buffer.from([
              25,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              44,
              109,
              97,
              120,
              95,
              109,
              101,
              115,
              115,
              97,
              103,
              101,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              112,
              117,
              108,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Establishes a stream with the server, which sends messages down to the
     * client. The client streams acknowledgements and ack deadline modifications
     * back to the server. The server will close the stream and return the status
     * on any error. The server may close the stream with status `UNAVAILABLE` to
     * reassign server-side resources, in which case, the client should
     * re-establish the stream. Flow control can be achieved by configuring the
     * underlying RPC channel.
     */
    streamingPull: {
      name: "StreamingPull",
      requestType: StreamingPullRequest,
      requestStream: true,
      responseType: StreamingPullResponse,
      responseStream: true,
      options: {},
    },
    /**
     * Modifies the `PushConfig` for a specified subscription.
     *
     * This may be used to change a push subscription to a pull one (signified by
     * an empty `PushConfig`) or vice versa, or change the endpoint URL and other
     * attributes of a push subscription. Messages will accumulate for delivery
     * continuously through the call regardless of changes to the `PushConfig`.
     */
    modifyPushConfig: {
      name: "ModifyPushConfig",
      requestType: ModifyPushConfigRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              24,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              44,
              112,
              117,
              115,
              104,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
            ]),
          ],
          578365826: [
            Buffer.from([
              67,
              58,
              1,
              42,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              109,
              111,
              100,
              105,
              102,
              121,
              80,
              117,
              115,
              104,
              67,
              111,
              110,
              102,
              105,
              103,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the configuration details of a snapshot. Snapshots are used in
     * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
     * which allow you to manage message acknowledgments in bulk. That is, you can
     * set the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot.
     */
    getSnapshot: {
      name: "GetSnapshot",
      requestType: GetSnapshotRequest,
      requestStream: false,
      responseType: Snapshot,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 115, 110, 97, 112, 115, 104, 111, 116])],
          578365826: [
            Buffer.from([
              39,
              18,
              37,
              47,
              118,
              49,
              47,
              123,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists the existing snapshots. Snapshots are used in [Seek](
     * https://cloud.google.com/pubsub/docs/replay-overview) operations, which
     * allow you to manage message acknowledgments in bulk. That is, you can set
     * the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot.
     */
    listSnapshots: {
      name: "ListSnapshots",
      requestType: ListSnapshotsRequest,
      requestStream: false,
      responseType: ListSnapshotsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([7, 112, 114, 111, 106, 101, 99, 116])],
          578365826: [
            Buffer.from([
              36,
              18,
              34,
              47,
              118,
              49,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a snapshot from the requested subscription. Snapshots are used in
     * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
     * which allow you to manage message acknowledgments in bulk. That is, you can
     * set the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot.
     * If the snapshot already exists, returns `ALREADY_EXISTS`.
     * If the requested subscription doesn't exist, returns `NOT_FOUND`.
     * If the backlog in the subscription is too old -- and the resulting snapshot
     * would expire in less than 1 hour -- then `FAILED_PRECONDITION` is returned.
     * See also the `Snapshot.expire_time` field. If the name is not provided in
     * the request, the server will assign a random
     * name for this snapshot on the same project as the subscription, conforming
     * to the [resource name format]
     * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names). The
     * generated name is populated in the returned Snapshot object. Note that for
     * REST API requests, you must specify a name in the request.
     */
    createSnapshot: {
      name: "CreateSnapshot",
      requestType: CreateSnapshotRequest,
      requestStream: false,
      responseType: Snapshot,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([17, 110, 97, 109, 101, 44, 115, 117, 98, 115, 99, 114, 105, 112, 116, 105, 111, 110])],
          578365826: [
            Buffer.from([
              38,
              58,
              1,
              42,
              26,
              33,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates an existing snapshot by updating the fields specified in the update
     * mask. Snapshots are used in
     * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
     * which allow you to manage message acknowledgments in bulk. That is, you can
     * set the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot.
     */
    updateSnapshot: {
      name: "UpdateSnapshot",
      requestType: UpdateSnapshotRequest,
      requestStream: false,
      responseType: Snapshot,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              47,
              58,
              1,
              42,
              50,
              42,
              47,
              118,
              49,
              47,
              123,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Removes an existing snapshot. Snapshots are used in [Seek]
     * (https://cloud.google.com/pubsub/docs/replay-overview) operations, which
     * allow you to manage message acknowledgments in bulk. That is, you can set
     * the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot.
     * When the snapshot is deleted, all messages retained in the snapshot
     * are immediately dropped. After a snapshot is deleted, a new one may be
     * created with the same name, but the new one has no association with the old
     * snapshot or its subscription, unless the same subscription is specified.
     */
    deleteSnapshot: {
      name: "DeleteSnapshot",
      requestType: DeleteSnapshotRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 115, 110, 97, 112, 115, 104, 111, 116])],
          578365826: [
            Buffer.from([
              39,
              42,
              37,
              47,
              118,
              49,
              47,
              123,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Seeks an existing subscription to a point in time or to a given snapshot,
     * whichever is provided in the request. Snapshots are used in [Seek]
     * (https://cloud.google.com/pubsub/docs/replay-overview) operations, which
     * allow you to manage message acknowledgments in bulk. That is, you can set
     * the acknowledgment state of messages in an existing subscription to the
     * state captured by a snapshot. Note that both the subscription and the
     * snapshot must be on the same topic.
     */
    seek: {
      name: "Seek",
      requestType: SeekRequest,
      requestStream: false,
      responseType: SeekResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              49,
              47,
              123,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              117,
              98,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              101,
              107,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface SubscriberServiceImplementation<CallContextExt = {}> {
  /**
   * Creates a subscription to a given topic. See the [resource name rules]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
   * If the subscription already exists, returns `ALREADY_EXISTS`.
   * If the corresponding topic doesn't exist, returns `NOT_FOUND`.
   *
   * If the name is not provided in the request, the server will assign a random
   * name for this subscription on the same project as the topic, conforming
   * to the [resource name format]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names). The
   * generated name is populated in the returned Subscription object. Note that
   * for REST API requests, you must specify a name in the request.
   */
  createSubscription(request: Subscription, context: CallContext & CallContextExt): Promise<DeepPartial<Subscription>>;
  /** Gets the configuration details of a subscription. */
  getSubscription(
    request: GetSubscriptionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Subscription>>;
  /**
   * Updates an existing subscription by updating the fields specified in the
   * update mask. Note that certain properties of a subscription, such as its
   * topic, are not modifiable.
   */
  updateSubscription(
    request: UpdateSubscriptionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Subscription>>;
  /** Lists matching subscriptions. */
  listSubscriptions(
    request: ListSubscriptionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListSubscriptionsResponse>>;
  /**
   * Deletes an existing subscription. All messages retained in the subscription
   * are immediately dropped. Calls to `Pull` after deletion will return
   * `NOT_FOUND`. After a subscription is deleted, a new one may be created with
   * the same name, but the new one has no association with the old
   * subscription or its topic unless the same topic is specified.
   */
  deleteSubscription(
    request: DeleteSubscriptionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Modifies the ack deadline for a specific message. This method is useful
   * to indicate that more time is needed to process a message by the
   * subscriber, or to make the message available for redelivery if the
   * processing was interrupted. Note that this does not modify the
   * subscription-level `ackDeadlineSeconds` used for subsequent messages.
   */
  modifyAckDeadline(
    request: ModifyAckDeadlineRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Acknowledges the messages associated with the `ack_ids` in the
   * `AcknowledgeRequest`. The Pub/Sub system can remove the relevant messages
   * from the subscription.
   *
   * Acknowledging a message whose ack deadline has expired may succeed,
   * but such a message may be redelivered later. Acknowledging a message more
   * than once will not result in an error.
   */
  acknowledge(request: AcknowledgeRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Pulls messages from the server. */
  pull(request: PullRequest, context: CallContext & CallContextExt): Promise<DeepPartial<PullResponse>>;
  /**
   * Establishes a stream with the server, which sends messages down to the
   * client. The client streams acknowledgements and ack deadline modifications
   * back to the server. The server will close the stream and return the status
   * on any error. The server may close the stream with status `UNAVAILABLE` to
   * reassign server-side resources, in which case, the client should
   * re-establish the stream. Flow control can be achieved by configuring the
   * underlying RPC channel.
   */
  streamingPull(
    request: AsyncIterable<StreamingPullRequest>,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<StreamingPullResponse>>;
  /**
   * Modifies the `PushConfig` for a specified subscription.
   *
   * This may be used to change a push subscription to a pull one (signified by
   * an empty `PushConfig`) or vice versa, or change the endpoint URL and other
   * attributes of a push subscription. Messages will accumulate for delivery
   * continuously through the call regardless of changes to the `PushConfig`.
   */
  modifyPushConfig(
    request: ModifyPushConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Gets the configuration details of a snapshot. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  getSnapshot(request: GetSnapshotRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Snapshot>>;
  /**
   * Lists the existing snapshots. Snapshots are used in [Seek](
   * https://cloud.google.com/pubsub/docs/replay-overview) operations, which
   * allow you to manage message acknowledgments in bulk. That is, you can set
   * the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  listSnapshots(
    request: ListSnapshotsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListSnapshotsResponse>>;
  /**
   * Creates a snapshot from the requested subscription. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   * If the snapshot already exists, returns `ALREADY_EXISTS`.
   * If the requested subscription doesn't exist, returns `NOT_FOUND`.
   * If the backlog in the subscription is too old -- and the resulting snapshot
   * would expire in less than 1 hour -- then `FAILED_PRECONDITION` is returned.
   * See also the `Snapshot.expire_time` field. If the name is not provided in
   * the request, the server will assign a random
   * name for this snapshot on the same project as the subscription, conforming
   * to the [resource name format]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names). The
   * generated name is populated in the returned Snapshot object. Note that for
   * REST API requests, you must specify a name in the request.
   */
  createSnapshot(request: CreateSnapshotRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Snapshot>>;
  /**
   * Updates an existing snapshot by updating the fields specified in the update
   * mask. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  updateSnapshot(request: UpdateSnapshotRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Snapshot>>;
  /**
   * Removes an existing snapshot. Snapshots are used in [Seek]
   * (https://cloud.google.com/pubsub/docs/replay-overview) operations, which
   * allow you to manage message acknowledgments in bulk. That is, you can set
   * the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   * When the snapshot is deleted, all messages retained in the snapshot
   * are immediately dropped. After a snapshot is deleted, a new one may be
   * created with the same name, but the new one has no association with the old
   * snapshot or its subscription, unless the same subscription is specified.
   */
  deleteSnapshot(request: DeleteSnapshotRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Seeks an existing subscription to a point in time or to a given snapshot,
   * whichever is provided in the request. Snapshots are used in [Seek]
   * (https://cloud.google.com/pubsub/docs/replay-overview) operations, which
   * allow you to manage message acknowledgments in bulk. That is, you can set
   * the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot. Note that both the subscription and the
   * snapshot must be on the same topic.
   */
  seek(request: SeekRequest, context: CallContext & CallContextExt): Promise<DeepPartial<SeekResponse>>;
}

export interface SubscriberClient<CallOptionsExt = {}> {
  /**
   * Creates a subscription to a given topic. See the [resource name rules]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names).
   * If the subscription already exists, returns `ALREADY_EXISTS`.
   * If the corresponding topic doesn't exist, returns `NOT_FOUND`.
   *
   * If the name is not provided in the request, the server will assign a random
   * name for this subscription on the same project as the topic, conforming
   * to the [resource name format]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names). The
   * generated name is populated in the returned Subscription object. Note that
   * for REST API requests, you must specify a name in the request.
   */
  createSubscription(request: DeepPartial<Subscription>, options?: CallOptions & CallOptionsExt): Promise<Subscription>;
  /** Gets the configuration details of a subscription. */
  getSubscription(
    request: DeepPartial<GetSubscriptionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Subscription>;
  /**
   * Updates an existing subscription by updating the fields specified in the
   * update mask. Note that certain properties of a subscription, such as its
   * topic, are not modifiable.
   */
  updateSubscription(
    request: DeepPartial<UpdateSubscriptionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Subscription>;
  /** Lists matching subscriptions. */
  listSubscriptions(
    request: DeepPartial<ListSubscriptionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListSubscriptionsResponse>;
  /**
   * Deletes an existing subscription. All messages retained in the subscription
   * are immediately dropped. Calls to `Pull` after deletion will return
   * `NOT_FOUND`. After a subscription is deleted, a new one may be created with
   * the same name, but the new one has no association with the old
   * subscription or its topic unless the same topic is specified.
   */
  deleteSubscription(
    request: DeepPartial<DeleteSubscriptionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Modifies the ack deadline for a specific message. This method is useful
   * to indicate that more time is needed to process a message by the
   * subscriber, or to make the message available for redelivery if the
   * processing was interrupted. Note that this does not modify the
   * subscription-level `ackDeadlineSeconds` used for subsequent messages.
   */
  modifyAckDeadline(
    request: DeepPartial<ModifyAckDeadlineRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Acknowledges the messages associated with the `ack_ids` in the
   * `AcknowledgeRequest`. The Pub/Sub system can remove the relevant messages
   * from the subscription.
   *
   * Acknowledging a message whose ack deadline has expired may succeed,
   * but such a message may be redelivered later. Acknowledging a message more
   * than once will not result in an error.
   */
  acknowledge(request: DeepPartial<AcknowledgeRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Pulls messages from the server. */
  pull(request: DeepPartial<PullRequest>, options?: CallOptions & CallOptionsExt): Promise<PullResponse>;
  /**
   * Establishes a stream with the server, which sends messages down to the
   * client. The client streams acknowledgements and ack deadline modifications
   * back to the server. The server will close the stream and return the status
   * on any error. The server may close the stream with status `UNAVAILABLE` to
   * reassign server-side resources, in which case, the client should
   * re-establish the stream. Flow control can be achieved by configuring the
   * underlying RPC channel.
   */
  streamingPull(
    request: AsyncIterable<DeepPartial<StreamingPullRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<StreamingPullResponse>;
  /**
   * Modifies the `PushConfig` for a specified subscription.
   *
   * This may be used to change a push subscription to a pull one (signified by
   * an empty `PushConfig`) or vice versa, or change the endpoint URL and other
   * attributes of a push subscription. Messages will accumulate for delivery
   * continuously through the call regardless of changes to the `PushConfig`.
   */
  modifyPushConfig(
    request: DeepPartial<ModifyPushConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Gets the configuration details of a snapshot. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  getSnapshot(request: DeepPartial<GetSnapshotRequest>, options?: CallOptions & CallOptionsExt): Promise<Snapshot>;
  /**
   * Lists the existing snapshots. Snapshots are used in [Seek](
   * https://cloud.google.com/pubsub/docs/replay-overview) operations, which
   * allow you to manage message acknowledgments in bulk. That is, you can set
   * the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  listSnapshots(
    request: DeepPartial<ListSnapshotsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListSnapshotsResponse>;
  /**
   * Creates a snapshot from the requested subscription. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   * If the snapshot already exists, returns `ALREADY_EXISTS`.
   * If the requested subscription doesn't exist, returns `NOT_FOUND`.
   * If the backlog in the subscription is too old -- and the resulting snapshot
   * would expire in less than 1 hour -- then `FAILED_PRECONDITION` is returned.
   * See also the `Snapshot.expire_time` field. If the name is not provided in
   * the request, the server will assign a random
   * name for this snapshot on the same project as the subscription, conforming
   * to the [resource name format]
   * (https://cloud.google.com/pubsub/docs/pubsub-basics#resource_names). The
   * generated name is populated in the returned Snapshot object. Note that for
   * REST API requests, you must specify a name in the request.
   */
  createSnapshot(
    request: DeepPartial<CreateSnapshotRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Snapshot>;
  /**
   * Updates an existing snapshot by updating the fields specified in the update
   * mask. Snapshots are used in
   * [Seek](https://cloud.google.com/pubsub/docs/replay-overview) operations,
   * which allow you to manage message acknowledgments in bulk. That is, you can
   * set the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   */
  updateSnapshot(
    request: DeepPartial<UpdateSnapshotRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Snapshot>;
  /**
   * Removes an existing snapshot. Snapshots are used in [Seek]
   * (https://cloud.google.com/pubsub/docs/replay-overview) operations, which
   * allow you to manage message acknowledgments in bulk. That is, you can set
   * the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot.
   * When the snapshot is deleted, all messages retained in the snapshot
   * are immediately dropped. After a snapshot is deleted, a new one may be
   * created with the same name, but the new one has no association with the old
   * snapshot or its subscription, unless the same subscription is specified.
   */
  deleteSnapshot(request: DeepPartial<DeleteSnapshotRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Seeks an existing subscription to a point in time or to a given snapshot,
   * whichever is provided in the request. Snapshots are used in [Seek]
   * (https://cloud.google.com/pubsub/docs/replay-overview) operations, which
   * allow you to manage message acknowledgments in bulk. That is, you can set
   * the acknowledgment state of messages in an existing subscription to the
   * state captured by a snapshot. Note that both the subscription and the
   * snapshot must be on the same topic.
   */
  seek(request: DeepPartial<SeekRequest>, options?: CallOptions & CallOptionsExt): Promise<SeekResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export type ServerStreamingMethodResult<Response> = { [Symbol.asyncIterator](): AsyncIterator<Response, void> };

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
