// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/genomics/v1/readgroupset.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { ListValue } from "../../protobuf/struct.js";
import { ReadGroup } from "./readgroup.js";

export const protobufPackage = "google.genomics.v1";

/**
 * A read group set is a logical collection of read groups, which are
 * collections of reads produced by a sequencer. A read group set typically
 * models reads corresponding to one sample, sequenced one way, and aligned one
 * way.
 *
 * * A read group set belongs to one dataset.
 * * A read group belongs to one read group set.
 * * A read belongs to one read group.
 *
 * For more genomics resource definitions, see [Fundamentals of Google
 * Genomics](https://cloud.google.com/genomics/fundamentals-of-google-genomics)
 */
export interface ReadGroupSet {
  /** The server-generated read group set ID, unique for all read group sets. */
  id: string;
  /** The dataset to which this read group set belongs. */
  datasetId: string;
  /** The reference set to which the reads in this read group set are aligned. */
  referenceSetId: string;
  /**
   * The read group set name. By default this will be initialized to the sample
   * name of the sequenced data contained in this set.
   */
  name: string;
  /** The filename of the original source file for this read group set, if any. */
  filename: string;
  /**
   * The read groups in this set. There are typically 1-10 read groups in a read
   * group set.
   */
  readGroups: ReadGroup[];
  /** A map of additional read group set information. */
  info: { [key: string]: Array<any> | undefined };
}

export interface ReadGroupSet_InfoEntry {
  key: string;
  value: Array<any> | undefined;
}

function createBaseReadGroupSet(): ReadGroupSet {
  return { id: "", datasetId: "", referenceSetId: "", name: "", filename: "", readGroups: [], info: {} };
}

export const ReadGroupSet: MessageFns<ReadGroupSet> = {
  encode(message: ReadGroupSet, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    if (message.referenceSetId !== "") {
      writer.uint32(26).string(message.referenceSetId);
    }
    if (message.name !== "") {
      writer.uint32(34).string(message.name);
    }
    if (message.filename !== "") {
      writer.uint32(42).string(message.filename);
    }
    for (const v of message.readGroups) {
      ReadGroup.encode(v!, writer.uint32(50).fork()).join();
    }
    Object.entries(message.info).forEach(([key, value]) => {
      if (value !== undefined) {
        ReadGroupSet_InfoEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
      }
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadGroupSet {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadGroupSet();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.referenceSetId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.name = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filename = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.readGroups.push(ReadGroup.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = ReadGroupSet_InfoEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.info[entry7.key] = entry7.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadGroupSet {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      referenceSetId: isSet(object.referenceSetId) ? globalThis.String(object.referenceSetId) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      filename: isSet(object.filename) ? globalThis.String(object.filename) : "",
      readGroups: globalThis.Array.isArray(object?.readGroups)
        ? object.readGroups.map((e: any) => ReadGroup.fromJSON(e))
        : [],
      info: isObject(object.info)
        ? Object.entries(object.info).reduce<{ [key: string]: Array<any> | undefined }>((acc, [key, value]) => {
          acc[key] = value as Array<any> | undefined;
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: ReadGroupSet): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.referenceSetId !== "") {
      obj.referenceSetId = message.referenceSetId;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.filename !== "") {
      obj.filename = message.filename;
    }
    if (message.readGroups?.length) {
      obj.readGroups = message.readGroups.map((e) => ReadGroup.toJSON(e));
    }
    if (message.info) {
      const entries = Object.entries(message.info);
      if (entries.length > 0) {
        obj.info = {};
        entries.forEach(([k, v]) => {
          obj.info[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ReadGroupSet>): ReadGroupSet {
    return ReadGroupSet.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadGroupSet>): ReadGroupSet {
    const message = createBaseReadGroupSet();
    message.id = object.id ?? "";
    message.datasetId = object.datasetId ?? "";
    message.referenceSetId = object.referenceSetId ?? "";
    message.name = object.name ?? "";
    message.filename = object.filename ?? "";
    message.readGroups = object.readGroups?.map((e) => ReadGroup.fromPartial(e)) || [];
    message.info = Object.entries(object.info ?? {}).reduce<{ [key: string]: Array<any> | undefined }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = value;
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseReadGroupSet_InfoEntry(): ReadGroupSet_InfoEntry {
  return { key: "", value: undefined };
}

export const ReadGroupSet_InfoEntry: MessageFns<ReadGroupSet_InfoEntry> = {
  encode(message: ReadGroupSet_InfoEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      ListValue.encode(ListValue.wrap(message.value), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadGroupSet_InfoEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadGroupSet_InfoEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = ListValue.unwrap(ListValue.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadGroupSet_InfoEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: globalThis.Array.isArray(object.value) ? [...object.value] : undefined,
    };
  },

  toJSON(message: ReadGroupSet_InfoEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ReadGroupSet_InfoEntry>): ReadGroupSet_InfoEntry {
    return ReadGroupSet_InfoEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadGroupSet_InfoEntry>): ReadGroupSet_InfoEntry {
    const message = createBaseReadGroupSet_InfoEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
