// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/firestore/admin/v1beta1/firestore_admin.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Empty } from "../../../protobuf/empty.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Index } from "./index.js";

export const protobufPackage = "google.firestore.admin.v1beta1";

/** The various possible states for an ongoing Operation. */
export enum OperationState {
  /** STATE_UNSPECIFIED - Unspecified. */
  STATE_UNSPECIFIED = 0,
  /** INITIALIZING - Request is being prepared for processing. */
  INITIALIZING = 1,
  /** PROCESSING - Request is actively being processed. */
  PROCESSING = 2,
  /**
   * CANCELLING - Request is in the process of being cancelled after user called
   * google.longrunning.Operations.CancelOperation on the operation.
   */
  CANCELLING = 3,
  /** FINALIZING - Request has been processed and is in its finalization stage. */
  FINALIZING = 4,
  /** SUCCESSFUL - Request has completed successfully. */
  SUCCESSFUL = 5,
  /** FAILED - Request has finished being processed, but encountered an error. */
  FAILED = 6,
  /**
   * CANCELLED - Request has finished being cancelled after user called
   * google.longrunning.Operations.CancelOperation.
   */
  CANCELLED = 7,
  UNRECOGNIZED = -1,
}

export function operationStateFromJSON(object: any): OperationState {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return OperationState.STATE_UNSPECIFIED;
    case 1:
    case "INITIALIZING":
      return OperationState.INITIALIZING;
    case 2:
    case "PROCESSING":
      return OperationState.PROCESSING;
    case 3:
    case "CANCELLING":
      return OperationState.CANCELLING;
    case 4:
    case "FINALIZING":
      return OperationState.FINALIZING;
    case 5:
    case "SUCCESSFUL":
      return OperationState.SUCCESSFUL;
    case 6:
    case "FAILED":
      return OperationState.FAILED;
    case 7:
    case "CANCELLED":
      return OperationState.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OperationState.UNRECOGNIZED;
  }
}

export function operationStateToJSON(object: OperationState): string {
  switch (object) {
    case OperationState.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case OperationState.INITIALIZING:
      return "INITIALIZING";
    case OperationState.PROCESSING:
      return "PROCESSING";
    case OperationState.CANCELLING:
      return "CANCELLING";
    case OperationState.FINALIZING:
      return "FINALIZING";
    case OperationState.SUCCESSFUL:
      return "SUCCESSFUL";
    case OperationState.FAILED:
      return "FAILED";
    case OperationState.CANCELLED:
      return "CANCELLED";
    case OperationState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Metadata for index operations. This metadata populates
 * the metadata field of [google.longrunning.Operation][google.longrunning.Operation].
 */
export interface IndexOperationMetadata {
  /** The time that work began on the operation. */
  startTime:
    | Date
    | undefined;
  /**
   * The time the operation ended, either successfully or otherwise. Unset if
   * the operation is still active.
   */
  endTime:
    | Date
    | undefined;
  /**
   * The index resource that this operation is acting on. For example:
   * `projects/{project_id}/databases/{database_id}/indexes/{index_id}`
   */
  index: string;
  /** The type of index operation. */
  operationType: IndexOperationMetadata_OperationType;
  /**
   * True if the [google.longrunning.Operation] was cancelled. If the
   * cancellation is in progress, cancelled will be true but
   * [google.longrunning.Operation.done][google.longrunning.Operation.done] will be false.
   */
  cancelled: boolean;
  /** Progress of the existing operation, measured in number of documents. */
  documentProgress: Progress | undefined;
}

/** The type of index operation. */
export enum IndexOperationMetadata_OperationType {
  /** OPERATION_TYPE_UNSPECIFIED - Unspecified. Never set by server. */
  OPERATION_TYPE_UNSPECIFIED = 0,
  /** CREATING_INDEX - The operation is creating the index. Initiated by a `CreateIndex` call. */
  CREATING_INDEX = 1,
  UNRECOGNIZED = -1,
}

export function indexOperationMetadata_OperationTypeFromJSON(object: any): IndexOperationMetadata_OperationType {
  switch (object) {
    case 0:
    case "OPERATION_TYPE_UNSPECIFIED":
      return IndexOperationMetadata_OperationType.OPERATION_TYPE_UNSPECIFIED;
    case 1:
    case "CREATING_INDEX":
      return IndexOperationMetadata_OperationType.CREATING_INDEX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return IndexOperationMetadata_OperationType.UNRECOGNIZED;
  }
}

export function indexOperationMetadata_OperationTypeToJSON(object: IndexOperationMetadata_OperationType): string {
  switch (object) {
    case IndexOperationMetadata_OperationType.OPERATION_TYPE_UNSPECIFIED:
      return "OPERATION_TYPE_UNSPECIFIED";
    case IndexOperationMetadata_OperationType.CREATING_INDEX:
      return "CREATING_INDEX";
    case IndexOperationMetadata_OperationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Measures the progress of a particular metric. */
export interface Progress {
  /**
   * An estimate of how much work has been completed. Note that this may be
   * greater than `work_estimated`.
   */
  workCompleted: Long;
  /**
   * An estimate of how much work needs to be performed. Zero if the
   * work estimate is unavailable. May change as work progresses.
   */
  workEstimated: Long;
}

/** The request for [FirestoreAdmin.CreateIndex][google.firestore.admin.v1beta1.FirestoreAdmin.CreateIndex]. */
export interface CreateIndexRequest {
  /**
   * The name of the database this index will apply to. For example:
   * `projects/{project_id}/databases/{database_id}`
   */
  parent: string;
  /**
   * The index to create. The name and state fields are output only and will be
   * ignored. Certain single field indexes cannot be created or deleted.
   */
  index: Index | undefined;
}

/** The request for [FirestoreAdmin.GetIndex][google.firestore.admin.v1beta1.FirestoreAdmin.GetIndex]. */
export interface GetIndexRequest {
  /**
   * The name of the index. For example:
   * `projects/{project_id}/databases/{database_id}/indexes/{index_id}`
   */
  name: string;
}

/** The request for [FirestoreAdmin.ListIndexes][google.firestore.admin.v1beta1.FirestoreAdmin.ListIndexes]. */
export interface ListIndexesRequest {
  /**
   * The database name. For example:
   * `projects/{project_id}/databases/{database_id}`
   */
  parent: string;
  filter: string;
  /** The standard List page size. */
  pageSize: number;
  /** The standard List page token. */
  pageToken: string;
}

/** The request for [FirestoreAdmin.DeleteIndex][google.firestore.admin.v1beta1.FirestoreAdmin.DeleteIndex]. */
export interface DeleteIndexRequest {
  /**
   * The index name. For example:
   * `projects/{project_id}/databases/{database_id}/indexes/{index_id}`
   */
  name: string;
}

/** The response for [FirestoreAdmin.ListIndexes][google.firestore.admin.v1beta1.FirestoreAdmin.ListIndexes]. */
export interface ListIndexesResponse {
  /** The indexes. */
  indexes: Index[];
  /** The standard List next-page token. */
  nextPageToken: string;
}

/** The request for [FirestoreAdmin.ExportDocuments][google.firestore.admin.v1beta1.FirestoreAdmin.ExportDocuments]. */
export interface ExportDocumentsRequest {
  /**
   * Database to export. Should be of the form:
   * `projects/{project_id}/databases/{database_id}`.
   */
  name: string;
  /** Which collection ids to export. Unspecified means all collections. */
  collectionIds: string[];
  /**
   * The output URI. Currently only supports Google Cloud Storage URIs of the
   * form: `gs://BUCKET_NAME[/NAMESPACE_PATH]`, where `BUCKET_NAME` is the name
   * of the Google Cloud Storage bucket and `NAMESPACE_PATH` is an optional
   * Google Cloud Storage namespace path. When
   * choosing a name, be sure to consider Google Cloud Storage naming
   * guidelines: https://cloud.google.com/storage/docs/naming.
   * If the URI is a bucket (without a namespace path), a prefix will be
   * generated based on the start time.
   */
  outputUriPrefix: string;
}

/** The request for [FirestoreAdmin.ImportDocuments][google.firestore.admin.v1beta1.FirestoreAdmin.ImportDocuments]. */
export interface ImportDocumentsRequest {
  /**
   * Database to import into. Should be of the form:
   * `projects/{project_id}/databases/{database_id}`.
   */
  name: string;
  /**
   * Which collection ids to import. Unspecified means all collections included
   * in the import.
   */
  collectionIds: string[];
  /**
   * Location of the exported files.
   * This must match the output_uri_prefix of an ExportDocumentsResponse from
   * an export that has completed successfully.
   * See:
   * [google.firestore.admin.v1beta1.ExportDocumentsResponse.output_uri_prefix][google.firestore.admin.v1beta1.ExportDocumentsResponse.output_uri_prefix].
   */
  inputUriPrefix: string;
}

/** Returned in the [google.longrunning.Operation][google.longrunning.Operation] response field. */
export interface ExportDocumentsResponse {
  /**
   * Location of the output files. This can be used to begin an import
   * into Cloud Firestore (this project or another project) after the operation
   * completes successfully.
   */
  outputUriPrefix: string;
}

/** Metadata for ExportDocuments operations. */
export interface ExportDocumentsMetadata {
  /** The time that work began on the operation. */
  startTime:
    | Date
    | undefined;
  /**
   * The time the operation ended, either successfully or otherwise. Unset if
   * the operation is still active.
   */
  endTime:
    | Date
    | undefined;
  /** The state of the export operation. */
  operationState: OperationState;
  /** An estimate of the number of documents processed. */
  progressDocuments:
    | Progress
    | undefined;
  /** An estimate of the number of bytes processed. */
  progressBytes:
    | Progress
    | undefined;
  /** Which collection ids are being exported. */
  collectionIds: string[];
  /** Where the entities are being exported to. */
  outputUriPrefix: string;
}

/** Metadata for ImportDocuments operations. */
export interface ImportDocumentsMetadata {
  /** The time that work began on the operation. */
  startTime:
    | Date
    | undefined;
  /**
   * The time the operation ended, either successfully or otherwise. Unset if
   * the operation is still active.
   */
  endTime:
    | Date
    | undefined;
  /** The state of the import operation. */
  operationState: OperationState;
  /** An estimate of the number of documents processed. */
  progressDocuments:
    | Progress
    | undefined;
  /** An estimate of the number of bytes processed. */
  progressBytes:
    | Progress
    | undefined;
  /** Which collection ids are being imported. */
  collectionIds: string[];
  /** The location of the documents being imported. */
  inputUriPrefix: string;
}

function createBaseIndexOperationMetadata(): IndexOperationMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    index: "",
    operationType: 0,
    cancelled: false,
    documentProgress: undefined,
  };
}

export const IndexOperationMetadata: MessageFns<IndexOperationMetadata> = {
  encode(message: IndexOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.index !== "") {
      writer.uint32(26).string(message.index);
    }
    if (message.operationType !== 0) {
      writer.uint32(32).int32(message.operationType);
    }
    if (message.cancelled !== false) {
      writer.uint32(40).bool(message.cancelled);
    }
    if (message.documentProgress !== undefined) {
      Progress.encode(message.documentProgress, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IndexOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIndexOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.index = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.operationType = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.cancelled = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.documentProgress = Progress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IndexOperationMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      index: isSet(object.index) ? globalThis.String(object.index) : "",
      operationType: isSet(object.operationType)
        ? indexOperationMetadata_OperationTypeFromJSON(object.operationType)
        : 0,
      cancelled: isSet(object.cancelled) ? globalThis.Boolean(object.cancelled) : false,
      documentProgress: isSet(object.documentProgress) ? Progress.fromJSON(object.documentProgress) : undefined,
    };
  },

  toJSON(message: IndexOperationMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.index !== "") {
      obj.index = message.index;
    }
    if (message.operationType !== 0) {
      obj.operationType = indexOperationMetadata_OperationTypeToJSON(message.operationType);
    }
    if (message.cancelled !== false) {
      obj.cancelled = message.cancelled;
    }
    if (message.documentProgress !== undefined) {
      obj.documentProgress = Progress.toJSON(message.documentProgress);
    }
    return obj;
  },

  create(base?: DeepPartial<IndexOperationMetadata>): IndexOperationMetadata {
    return IndexOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IndexOperationMetadata>): IndexOperationMetadata {
    const message = createBaseIndexOperationMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.index = object.index ?? "";
    message.operationType = object.operationType ?? 0;
    message.cancelled = object.cancelled ?? false;
    message.documentProgress = (object.documentProgress !== undefined && object.documentProgress !== null)
      ? Progress.fromPartial(object.documentProgress)
      : undefined;
    return message;
  },
};

function createBaseProgress(): Progress {
  return { workCompleted: Long.ZERO, workEstimated: Long.ZERO };
}

export const Progress: MessageFns<Progress> = {
  encode(message: Progress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.workCompleted.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.workCompleted.toString());
    }
    if (!message.workEstimated.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.workEstimated.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Progress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProgress();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.workCompleted = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.workEstimated = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Progress {
    return {
      workCompleted: isSet(object.workCompleted) ? Long.fromValue(object.workCompleted) : Long.ZERO,
      workEstimated: isSet(object.workEstimated) ? Long.fromValue(object.workEstimated) : Long.ZERO,
    };
  },

  toJSON(message: Progress): unknown {
    const obj: any = {};
    if (!message.workCompleted.equals(Long.ZERO)) {
      obj.workCompleted = (message.workCompleted || Long.ZERO).toString();
    }
    if (!message.workEstimated.equals(Long.ZERO)) {
      obj.workEstimated = (message.workEstimated || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Progress>): Progress {
    return Progress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Progress>): Progress {
    const message = createBaseProgress();
    message.workCompleted = (object.workCompleted !== undefined && object.workCompleted !== null)
      ? Long.fromValue(object.workCompleted)
      : Long.ZERO;
    message.workEstimated = (object.workEstimated !== undefined && object.workEstimated !== null)
      ? Long.fromValue(object.workEstimated)
      : Long.ZERO;
    return message;
  },
};

function createBaseCreateIndexRequest(): CreateIndexRequest {
  return { parent: "", index: undefined };
}

export const CreateIndexRequest: MessageFns<CreateIndexRequest> = {
  encode(message: CreateIndexRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.index !== undefined) {
      Index.encode(message.index, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateIndexRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateIndexRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.index = Index.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateIndexRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      index: isSet(object.index) ? Index.fromJSON(object.index) : undefined,
    };
  },

  toJSON(message: CreateIndexRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.index !== undefined) {
      obj.index = Index.toJSON(message.index);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateIndexRequest>): CreateIndexRequest {
    return CreateIndexRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateIndexRequest>): CreateIndexRequest {
    const message = createBaseCreateIndexRequest();
    message.parent = object.parent ?? "";
    message.index = (object.index !== undefined && object.index !== null) ? Index.fromPartial(object.index) : undefined;
    return message;
  },
};

function createBaseGetIndexRequest(): GetIndexRequest {
  return { name: "" };
}

export const GetIndexRequest: MessageFns<GetIndexRequest> = {
  encode(message: GetIndexRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetIndexRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetIndexRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetIndexRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetIndexRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetIndexRequest>): GetIndexRequest {
    return GetIndexRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetIndexRequest>): GetIndexRequest {
    const message = createBaseGetIndexRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListIndexesRequest(): ListIndexesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "" };
}

export const ListIndexesRequest: MessageFns<ListIndexesRequest> = {
  encode(message: ListIndexesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListIndexesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListIndexesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListIndexesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListIndexesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListIndexesRequest>): ListIndexesRequest {
    return ListIndexesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListIndexesRequest>): ListIndexesRequest {
    const message = createBaseListIndexesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseDeleteIndexRequest(): DeleteIndexRequest {
  return { name: "" };
}

export const DeleteIndexRequest: MessageFns<DeleteIndexRequest> = {
  encode(message: DeleteIndexRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteIndexRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteIndexRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteIndexRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteIndexRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteIndexRequest>): DeleteIndexRequest {
    return DeleteIndexRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteIndexRequest>): DeleteIndexRequest {
    const message = createBaseDeleteIndexRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListIndexesResponse(): ListIndexesResponse {
  return { indexes: [], nextPageToken: "" };
}

export const ListIndexesResponse: MessageFns<ListIndexesResponse> = {
  encode(message: ListIndexesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.indexes) {
      Index.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListIndexesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListIndexesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.indexes.push(Index.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListIndexesResponse {
    return {
      indexes: globalThis.Array.isArray(object?.indexes) ? object.indexes.map((e: any) => Index.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListIndexesResponse): unknown {
    const obj: any = {};
    if (message.indexes?.length) {
      obj.indexes = message.indexes.map((e) => Index.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListIndexesResponse>): ListIndexesResponse {
    return ListIndexesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListIndexesResponse>): ListIndexesResponse {
    const message = createBaseListIndexesResponse();
    message.indexes = object.indexes?.map((e) => Index.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseExportDocumentsRequest(): ExportDocumentsRequest {
  return { name: "", collectionIds: [], outputUriPrefix: "" };
}

export const ExportDocumentsRequest: MessageFns<ExportDocumentsRequest> = {
  encode(message: ExportDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.collectionIds) {
      writer.uint32(26).string(v!);
    }
    if (message.outputUriPrefix !== "") {
      writer.uint32(34).string(message.outputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDocumentsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "",
    };
  },

  toJSON(message: ExportDocumentsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDocumentsRequest>): ExportDocumentsRequest {
    return ExportDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDocumentsRequest>): ExportDocumentsRequest {
    const message = createBaseExportDocumentsRequest();
    message.name = object.name ?? "";
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    return message;
  },
};

function createBaseImportDocumentsRequest(): ImportDocumentsRequest {
  return { name: "", collectionIds: [], inputUriPrefix: "" };
}

export const ImportDocumentsRequest: MessageFns<ImportDocumentsRequest> = {
  encode(message: ImportDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.collectionIds) {
      writer.uint32(26).string(v!);
    }
    if (message.inputUriPrefix !== "") {
      writer.uint32(34).string(message.inputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.inputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportDocumentsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      inputUriPrefix: isSet(object.inputUriPrefix) ? globalThis.String(object.inputUriPrefix) : "",
    };
  },

  toJSON(message: ImportDocumentsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.inputUriPrefix !== "") {
      obj.inputUriPrefix = message.inputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportDocumentsRequest>): ImportDocumentsRequest {
    return ImportDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportDocumentsRequest>): ImportDocumentsRequest {
    const message = createBaseImportDocumentsRequest();
    message.name = object.name ?? "";
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.inputUriPrefix = object.inputUriPrefix ?? "";
    return message;
  },
};

function createBaseExportDocumentsResponse(): ExportDocumentsResponse {
  return { outputUriPrefix: "" };
}

export const ExportDocumentsResponse: MessageFns<ExportDocumentsResponse> = {
  encode(message: ExportDocumentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputUriPrefix !== "") {
      writer.uint32(10).string(message.outputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDocumentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDocumentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDocumentsResponse {
    return { outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "" };
  },

  toJSON(message: ExportDocumentsResponse): unknown {
    const obj: any = {};
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDocumentsResponse>): ExportDocumentsResponse {
    return ExportDocumentsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDocumentsResponse>): ExportDocumentsResponse {
    const message = createBaseExportDocumentsResponse();
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    return message;
  },
};

function createBaseExportDocumentsMetadata(): ExportDocumentsMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    operationState: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
    collectionIds: [],
    outputUriPrefix: "",
  };
}

export const ExportDocumentsMetadata: MessageFns<ExportDocumentsMetadata> = {
  encode(message: ExportDocumentsMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationState !== 0) {
      writer.uint32(24).int32(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(34).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(42).fork()).join();
    }
    for (const v of message.collectionIds) {
      writer.uint32(50).string(v!);
    }
    if (message.outputUriPrefix !== "") {
      writer.uint32(58).string(message.outputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDocumentsMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDocumentsMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationState = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDocumentsMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationState: isSet(object.operationState) ? operationStateFromJSON(object.operationState) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "",
    };
  },

  toJSON(message: ExportDocumentsMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationState !== 0) {
      obj.operationState = operationStateToJSON(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDocumentsMetadata>): ExportDocumentsMetadata {
    return ExportDocumentsMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDocumentsMetadata>): ExportDocumentsMetadata {
    const message = createBaseExportDocumentsMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationState = object.operationState ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    return message;
  },
};

function createBaseImportDocumentsMetadata(): ImportDocumentsMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    operationState: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
    collectionIds: [],
    inputUriPrefix: "",
  };
}

export const ImportDocumentsMetadata: MessageFns<ImportDocumentsMetadata> = {
  encode(message: ImportDocumentsMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationState !== 0) {
      writer.uint32(24).int32(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(34).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(42).fork()).join();
    }
    for (const v of message.collectionIds) {
      writer.uint32(50).string(v!);
    }
    if (message.inputUriPrefix !== "") {
      writer.uint32(58).string(message.inputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDocumentsMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDocumentsMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationState = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.inputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportDocumentsMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationState: isSet(object.operationState) ? operationStateFromJSON(object.operationState) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      inputUriPrefix: isSet(object.inputUriPrefix) ? globalThis.String(object.inputUriPrefix) : "",
    };
  },

  toJSON(message: ImportDocumentsMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationState !== 0) {
      obj.operationState = operationStateToJSON(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.inputUriPrefix !== "") {
      obj.inputUriPrefix = message.inputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportDocumentsMetadata>): ImportDocumentsMetadata {
    return ImportDocumentsMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportDocumentsMetadata>): ImportDocumentsMetadata {
    const message = createBaseImportDocumentsMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationState = object.operationState ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.inputUriPrefix = object.inputUriPrefix ?? "";
    return message;
  },
};

/**
 * The Cloud Firestore Admin API.
 *
 * This API provides several administrative services for Cloud Firestore.
 *
 * # Concepts
 *
 * Project, Database, Namespace, Collection, and Document are used as defined in
 * the Google Cloud Firestore API.
 *
 * Operation: An Operation represents work being performed in the background.
 *
 * # Services
 *
 * ## Index
 *
 * The index service manages Cloud Firestore indexes.
 *
 * Index creation is performed asynchronously.
 * An Operation resource is created for each such asynchronous operation.
 * The state of the operation (including any errors encountered)
 * may be queried via the Operation resource.
 *
 * ## Metadata
 *
 * Provides metadata and statistical information about data in Cloud Firestore.
 * The data provided as part of this API may be stale.
 *
 * ## Operation
 *
 * The Operations collection provides a record of actions performed for the
 * specified Project (including any Operations in progress). Operations are not
 * created directly but through calls on other collections or resources.
 *
 * An Operation that is not yet done may be cancelled. The request to cancel is
 * asynchronous and the Operation may continue to run for some time after the
 * request to cancel is made.
 *
 * An Operation that is done may be deleted so that it is no longer listed as
 * part of the Operation collection.
 *
 * Operations are created by service `FirestoreAdmin`, but are accessed via
 * service `google.longrunning.Operations`.
 */
export type FirestoreAdminDefinition = typeof FirestoreAdminDefinition;
export const FirestoreAdminDefinition = {
  name: "FirestoreAdmin",
  fullName: "google.firestore.admin.v1beta1.FirestoreAdmin",
  methods: {
    /**
     * Creates the specified index.
     * A newly created index's initial state is `CREATING`. On completion of the
     * returned [google.longrunning.Operation][google.longrunning.Operation], the state will be `READY`.
     * If the index already exists, the call will return an `ALREADY_EXISTS`
     * status.
     *
     * During creation, the process could result in an error, in which case the
     * index will move to the `ERROR` state. The process can be recovered by
     * fixing the data that caused the error, removing the index with
     * [delete][google.firestore.admin.v1beta1.FirestoreAdmin.DeleteIndex], then re-creating the index with
     * [create][google.firestore.admin.v1beta1.FirestoreAdmin.CreateIndex].
     *
     * Indexes with a single field cannot be created.
     */
    createIndex: {
      name: "CreateIndex",
      requestType: CreateIndexRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              57,
              58,
              5,
              105,
              110,
              100,
              101,
              120,
              34,
              48,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists the indexes that match the specified filters. */
    listIndexes: {
      name: "ListIndexes",
      requestType: ListIndexesRequest,
      requestStream: false,
      responseType: ListIndexesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              50,
              18,
              48,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets an index. */
    getIndex: {
      name: "GetIndex",
      requestType: GetIndexRequest,
      requestStream: false,
      responseType: Index,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              50,
              18,
              48,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes an index. */
    deleteIndex: {
      name: "DeleteIndex",
      requestType: DeleteIndexRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              50,
              42,
              48,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Exports a copy of all or a subset of documents from Google Cloud Firestore
     * to another storage system, such as Google Cloud Storage. Recent updates to
     * documents may not be reflected in the export. The export occurs in the
     * background and its progress can be monitored and managed via the
     * Operation resource that is created. The output of an export may only be
     * used once the associated operation is done. If an export operation is
     * cancelled before completion it may leave partial data behind in Google
     * Cloud Storage.
     */
    exportDocuments: {
      name: "ExportDocuments",
      requestType: ExportDocumentsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Imports documents into Google Cloud Firestore. Existing documents with the
     * same name are overwritten. The import occurs in the background and its
     * progress can be monitored and managed via the Operation resource that is
     * created. If an ImportDocuments operation is cancelled, it is possible
     * that a subset of the data has already been imported to Cloud Firestore.
     */
    importDocuments: {
      name: "ImportDocuments",
      requestType: ImportDocumentsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface FirestoreAdminServiceImplementation<CallContextExt = {}> {
  /**
   * Creates the specified index.
   * A newly created index's initial state is `CREATING`. On completion of the
   * returned [google.longrunning.Operation][google.longrunning.Operation], the state will be `READY`.
   * If the index already exists, the call will return an `ALREADY_EXISTS`
   * status.
   *
   * During creation, the process could result in an error, in which case the
   * index will move to the `ERROR` state. The process can be recovered by
   * fixing the data that caused the error, removing the index with
   * [delete][google.firestore.admin.v1beta1.FirestoreAdmin.DeleteIndex], then re-creating the index with
   * [create][google.firestore.admin.v1beta1.FirestoreAdmin.CreateIndex].
   *
   * Indexes with a single field cannot be created.
   */
  createIndex(request: CreateIndexRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Lists the indexes that match the specified filters. */
  listIndexes(
    request: ListIndexesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListIndexesResponse>>;
  /** Gets an index. */
  getIndex(request: GetIndexRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Index>>;
  /** Deletes an index. */
  deleteIndex(request: DeleteIndexRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Exports a copy of all or a subset of documents from Google Cloud Firestore
   * to another storage system, such as Google Cloud Storage. Recent updates to
   * documents may not be reflected in the export. The export occurs in the
   * background and its progress can be monitored and managed via the
   * Operation resource that is created. The output of an export may only be
   * used once the associated operation is done. If an export operation is
   * cancelled before completion it may leave partial data behind in Google
   * Cloud Storage.
   */
  exportDocuments(
    request: ExportDocumentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Imports documents into Google Cloud Firestore. Existing documents with the
   * same name are overwritten. The import occurs in the background and its
   * progress can be monitored and managed via the Operation resource that is
   * created. If an ImportDocuments operation is cancelled, it is possible
   * that a subset of the data has already been imported to Cloud Firestore.
   */
  importDocuments(
    request: ImportDocumentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface FirestoreAdminClient<CallOptionsExt = {}> {
  /**
   * Creates the specified index.
   * A newly created index's initial state is `CREATING`. On completion of the
   * returned [google.longrunning.Operation][google.longrunning.Operation], the state will be `READY`.
   * If the index already exists, the call will return an `ALREADY_EXISTS`
   * status.
   *
   * During creation, the process could result in an error, in which case the
   * index will move to the `ERROR` state. The process can be recovered by
   * fixing the data that caused the error, removing the index with
   * [delete][google.firestore.admin.v1beta1.FirestoreAdmin.DeleteIndex], then re-creating the index with
   * [create][google.firestore.admin.v1beta1.FirestoreAdmin.CreateIndex].
   *
   * Indexes with a single field cannot be created.
   */
  createIndex(request: DeepPartial<CreateIndexRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Lists the indexes that match the specified filters. */
  listIndexes(
    request: DeepPartial<ListIndexesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListIndexesResponse>;
  /** Gets an index. */
  getIndex(request: DeepPartial<GetIndexRequest>, options?: CallOptions & CallOptionsExt): Promise<Index>;
  /** Deletes an index. */
  deleteIndex(request: DeepPartial<DeleteIndexRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Exports a copy of all or a subset of documents from Google Cloud Firestore
   * to another storage system, such as Google Cloud Storage. Recent updates to
   * documents may not be reflected in the export. The export occurs in the
   * background and its progress can be monitored and managed via the
   * Operation resource that is created. The output of an export may only be
   * used once the associated operation is done. If an export operation is
   * cancelled before completion it may leave partial data behind in Google
   * Cloud Storage.
   */
  exportDocuments(
    request: DeepPartial<ExportDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Imports documents into Google Cloud Firestore. Existing documents with the
   * same name are overwritten. The import occurs in the background and its
   * progress can be monitored and managed via the Operation resource that is
   * created. If an ImportDocuments operation is cancelled, it is possible
   * that a subset of the data has already been imported to Cloud Firestore.
   */
  importDocuments(
    request: DeepPartial<ImportDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
