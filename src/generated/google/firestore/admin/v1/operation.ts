// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/firestore/admin/v1/operation.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Index } from "./index.js";

export const protobufPackage = "google.firestore.admin.v1";

/** Describes the state of the operation. */
export enum OperationState {
  /** OPERATION_STATE_UNSPECIFIED - Unspecified. */
  OPERATION_STATE_UNSPECIFIED = 0,
  /** INITIALIZING - Request is being prepared for processing. */
  INITIALIZING = 1,
  /** PROCESSING - Request is actively being processed. */
  PROCESSING = 2,
  /**
   * CANCELLING - Request is in the process of being cancelled after user called
   * google.longrunning.Operations.CancelOperation on the operation.
   */
  CANCELLING = 3,
  /** FINALIZING - Request has been processed and is in its finalization stage. */
  FINALIZING = 4,
  /** SUCCESSFUL - Request has completed successfully. */
  SUCCESSFUL = 5,
  /** FAILED - Request has finished being processed, but encountered an error. */
  FAILED = 6,
  /**
   * CANCELLED - Request has finished being cancelled after user called
   * google.longrunning.Operations.CancelOperation.
   */
  CANCELLED = 7,
  UNRECOGNIZED = -1,
}

export function operationStateFromJSON(object: any): OperationState {
  switch (object) {
    case 0:
    case "OPERATION_STATE_UNSPECIFIED":
      return OperationState.OPERATION_STATE_UNSPECIFIED;
    case 1:
    case "INITIALIZING":
      return OperationState.INITIALIZING;
    case 2:
    case "PROCESSING":
      return OperationState.PROCESSING;
    case 3:
    case "CANCELLING":
      return OperationState.CANCELLING;
    case 4:
    case "FINALIZING":
      return OperationState.FINALIZING;
    case 5:
    case "SUCCESSFUL":
      return OperationState.SUCCESSFUL;
    case 6:
    case "FAILED":
      return OperationState.FAILED;
    case 7:
    case "CANCELLED":
      return OperationState.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OperationState.UNRECOGNIZED;
  }
}

export function operationStateToJSON(object: OperationState): string {
  switch (object) {
    case OperationState.OPERATION_STATE_UNSPECIFIED:
      return "OPERATION_STATE_UNSPECIFIED";
    case OperationState.INITIALIZING:
      return "INITIALIZING";
    case OperationState.PROCESSING:
      return "PROCESSING";
    case OperationState.CANCELLING:
      return "CANCELLING";
    case OperationState.FINALIZING:
      return "FINALIZING";
    case OperationState.SUCCESSFUL:
      return "SUCCESSFUL";
    case OperationState.FAILED:
      return "FAILED";
    case OperationState.CANCELLED:
      return "CANCELLED";
    case OperationState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Metadata for [google.longrunning.Operation][google.longrunning.Operation]
 * results from
 * [FirestoreAdmin.CreateIndex][google.firestore.admin.v1.FirestoreAdmin.CreateIndex].
 */
export interface IndexOperationMetadata {
  /** The time this operation started. */
  startTime:
    | Date
    | undefined;
  /**
   * The time this operation completed. Will be unset if operation still in
   * progress.
   */
  endTime:
    | Date
    | undefined;
  /**
   * The index resource that this operation is acting on. For example:
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}/indexes/{index_id}`
   */
  index: string;
  /** The state of the operation. */
  state: OperationState;
  /** The progress, in documents, of this operation. */
  progressDocuments:
    | Progress
    | undefined;
  /** The progress, in bytes, of this operation. */
  progressBytes: Progress | undefined;
}

/**
 * Metadata for [google.longrunning.Operation][google.longrunning.Operation]
 * results from
 * [FirestoreAdmin.UpdateField][google.firestore.admin.v1.FirestoreAdmin.UpdateField].
 */
export interface FieldOperationMetadata {
  /** The time this operation started. */
  startTime:
    | Date
    | undefined;
  /**
   * The time this operation completed. Will be unset if operation still in
   * progress.
   */
  endTime:
    | Date
    | undefined;
  /**
   * The field resource that this operation is acting on. For example:
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}/fields/{field_path}`
   */
  field: string;
  /**
   * A list of
   * [IndexConfigDelta][google.firestore.admin.v1.FieldOperationMetadata.IndexConfigDelta],
   * which describe the intent of this operation.
   */
  indexConfigDeltas: FieldOperationMetadata_IndexConfigDelta[];
  /** The state of the operation. */
  state: OperationState;
  /** The progress, in documents, of this operation. */
  progressDocuments:
    | Progress
    | undefined;
  /** The progress, in bytes, of this operation. */
  progressBytes:
    | Progress
    | undefined;
  /** Describes the deltas of TTL configuration. */
  ttlConfigDelta: FieldOperationMetadata_TtlConfigDelta | undefined;
}

/** Information about an index configuration change. */
export interface FieldOperationMetadata_IndexConfigDelta {
  /** Specifies how the index is changing. */
  changeType: FieldOperationMetadata_IndexConfigDelta_ChangeType;
  /** The index being changed. */
  index: Index | undefined;
}

/** Specifies how the index is changing. */
export enum FieldOperationMetadata_IndexConfigDelta_ChangeType {
  /** CHANGE_TYPE_UNSPECIFIED - The type of change is not specified or known. */
  CHANGE_TYPE_UNSPECIFIED = 0,
  /** ADD - The single field index is being added. */
  ADD = 1,
  /** REMOVE - The single field index is being removed. */
  REMOVE = 2,
  UNRECOGNIZED = -1,
}

export function fieldOperationMetadata_IndexConfigDelta_ChangeTypeFromJSON(
  object: any,
): FieldOperationMetadata_IndexConfigDelta_ChangeType {
  switch (object) {
    case 0:
    case "CHANGE_TYPE_UNSPECIFIED":
      return FieldOperationMetadata_IndexConfigDelta_ChangeType.CHANGE_TYPE_UNSPECIFIED;
    case 1:
    case "ADD":
      return FieldOperationMetadata_IndexConfigDelta_ChangeType.ADD;
    case 2:
    case "REMOVE":
      return FieldOperationMetadata_IndexConfigDelta_ChangeType.REMOVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FieldOperationMetadata_IndexConfigDelta_ChangeType.UNRECOGNIZED;
  }
}

export function fieldOperationMetadata_IndexConfigDelta_ChangeTypeToJSON(
  object: FieldOperationMetadata_IndexConfigDelta_ChangeType,
): string {
  switch (object) {
    case FieldOperationMetadata_IndexConfigDelta_ChangeType.CHANGE_TYPE_UNSPECIFIED:
      return "CHANGE_TYPE_UNSPECIFIED";
    case FieldOperationMetadata_IndexConfigDelta_ChangeType.ADD:
      return "ADD";
    case FieldOperationMetadata_IndexConfigDelta_ChangeType.REMOVE:
      return "REMOVE";
    case FieldOperationMetadata_IndexConfigDelta_ChangeType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about a TTL configuration change. */
export interface FieldOperationMetadata_TtlConfigDelta {
  /** Specifies how the TTL configuration is changing. */
  changeType: FieldOperationMetadata_TtlConfigDelta_ChangeType;
}

/** Specifies how the TTL config is changing. */
export enum FieldOperationMetadata_TtlConfigDelta_ChangeType {
  /** CHANGE_TYPE_UNSPECIFIED - The type of change is not specified or known. */
  CHANGE_TYPE_UNSPECIFIED = 0,
  /** ADD - The TTL config is being added. */
  ADD = 1,
  /** REMOVE - The TTL config is being removed. */
  REMOVE = 2,
  UNRECOGNIZED = -1,
}

export function fieldOperationMetadata_TtlConfigDelta_ChangeTypeFromJSON(
  object: any,
): FieldOperationMetadata_TtlConfigDelta_ChangeType {
  switch (object) {
    case 0:
    case "CHANGE_TYPE_UNSPECIFIED":
      return FieldOperationMetadata_TtlConfigDelta_ChangeType.CHANGE_TYPE_UNSPECIFIED;
    case 1:
    case "ADD":
      return FieldOperationMetadata_TtlConfigDelta_ChangeType.ADD;
    case 2:
    case "REMOVE":
      return FieldOperationMetadata_TtlConfigDelta_ChangeType.REMOVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FieldOperationMetadata_TtlConfigDelta_ChangeType.UNRECOGNIZED;
  }
}

export function fieldOperationMetadata_TtlConfigDelta_ChangeTypeToJSON(
  object: FieldOperationMetadata_TtlConfigDelta_ChangeType,
): string {
  switch (object) {
    case FieldOperationMetadata_TtlConfigDelta_ChangeType.CHANGE_TYPE_UNSPECIFIED:
      return "CHANGE_TYPE_UNSPECIFIED";
    case FieldOperationMetadata_TtlConfigDelta_ChangeType.ADD:
      return "ADD";
    case FieldOperationMetadata_TtlConfigDelta_ChangeType.REMOVE:
      return "REMOVE";
    case FieldOperationMetadata_TtlConfigDelta_ChangeType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Metadata for [google.longrunning.Operation][google.longrunning.Operation]
 * results from
 * [FirestoreAdmin.ExportDocuments][google.firestore.admin.v1.FirestoreAdmin.ExportDocuments].
 */
export interface ExportDocumentsMetadata {
  /** The time this operation started. */
  startTime:
    | Date
    | undefined;
  /**
   * The time this operation completed. Will be unset if operation still in
   * progress.
   */
  endTime:
    | Date
    | undefined;
  /** The state of the export operation. */
  operationState: OperationState;
  /** The progress, in documents, of this operation. */
  progressDocuments:
    | Progress
    | undefined;
  /** The progress, in bytes, of this operation. */
  progressBytes:
    | Progress
    | undefined;
  /** Which collection IDs are being exported. */
  collectionIds: string[];
  /** Where the documents are being exported to. */
  outputUriPrefix: string;
  /** Which namespace IDs are being exported. */
  namespaceIds: string[];
  /**
   * The timestamp that corresponds to the version of the database that is being
   * exported. If unspecified, there are no guarantees about the consistency of
   * the documents being exported.
   */
  snapshotTime: Date | undefined;
}

/**
 * Metadata for [google.longrunning.Operation][google.longrunning.Operation]
 * results from
 * [FirestoreAdmin.ImportDocuments][google.firestore.admin.v1.FirestoreAdmin.ImportDocuments].
 */
export interface ImportDocumentsMetadata {
  /** The time this operation started. */
  startTime:
    | Date
    | undefined;
  /**
   * The time this operation completed. Will be unset if operation still in
   * progress.
   */
  endTime:
    | Date
    | undefined;
  /** The state of the import operation. */
  operationState: OperationState;
  /** The progress, in documents, of this operation. */
  progressDocuments:
    | Progress
    | undefined;
  /** The progress, in bytes, of this operation. */
  progressBytes:
    | Progress
    | undefined;
  /** Which collection IDs are being imported. */
  collectionIds: string[];
  /** The location of the documents being imported. */
  inputUriPrefix: string;
  /** Which namespace IDs are being imported. */
  namespaceIds: string[];
}

/**
 * Metadata for [google.longrunning.Operation][google.longrunning.Operation]
 * results from
 * [FirestoreAdmin.BulkDeleteDocuments][google.firestore.admin.v1.FirestoreAdmin.BulkDeleteDocuments].
 */
export interface BulkDeleteDocumentsMetadata {
  /** The time this operation started. */
  startTime:
    | Date
    | undefined;
  /**
   * The time this operation completed. Will be unset if operation still in
   * progress.
   */
  endTime:
    | Date
    | undefined;
  /** The state of the operation. */
  operationState: OperationState;
  /** The progress, in documents, of this operation. */
  progressDocuments:
    | Progress
    | undefined;
  /** The progress, in bytes, of this operation. */
  progressBytes:
    | Progress
    | undefined;
  /** The IDs of the collection groups that are being deleted. */
  collectionIds: string[];
  /** Which namespace IDs are being deleted. */
  namespaceIds: string[];
  /**
   * The timestamp that corresponds to the version of the database that is being
   * read to get the list of documents to delete. This time can also be used as
   * the timestamp of PITR in case of disaster recovery (subject to PITR window
   * limit).
   */
  snapshotTime: Date | undefined;
}

/**
 * Returned in the [google.longrunning.Operation][google.longrunning.Operation]
 * response field.
 */
export interface ExportDocumentsResponse {
  /**
   * Location of the output files. This can be used to begin an import
   * into Cloud Firestore (this project or another project) after the operation
   * completes successfully.
   */
  outputUriPrefix: string;
}

/**
 * Metadata for the [long-running operation][google.longrunning.Operation] from
 * the [RestoreDatabase][google.firestore.admin.v1.RestoreDatabase] request.
 */
export interface RestoreDatabaseMetadata {
  /** The time the restore was started. */
  startTime:
    | Date
    | undefined;
  /** The time the restore finished, unset for ongoing restores. */
  endTime:
    | Date
    | undefined;
  /** The operation state of the restore. */
  operationState: OperationState;
  /** The name of the database being restored to. */
  database: string;
  /** The name of the backup restoring from. */
  backup: string;
  /** How far along the restore is as an estimated percentage of remaining time. */
  progressPercentage: Progress | undefined;
}

/**
 * Describes the progress of the operation.
 * Unit of work is generic and must be interpreted based on where
 * [Progress][google.firestore.admin.v1.Progress] is used.
 */
export interface Progress {
  /** The amount of work estimated. */
  estimatedWork: Long;
  /** The amount of work completed. */
  completedWork: Long;
}

function createBaseIndexOperationMetadata(): IndexOperationMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    index: "",
    state: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
  };
}

export const IndexOperationMetadata: MessageFns<IndexOperationMetadata> = {
  encode(message: IndexOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.index !== "") {
      writer.uint32(26).string(message.index);
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(42).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IndexOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIndexOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.index = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IndexOperationMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      index: isSet(object.index) ? globalThis.String(object.index) : "",
      state: isSet(object.state) ? operationStateFromJSON(object.state) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
    };
  },

  toJSON(message: IndexOperationMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.index !== "") {
      obj.index = message.index;
    }
    if (message.state !== 0) {
      obj.state = operationStateToJSON(message.state);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    return obj;
  },

  create(base?: DeepPartial<IndexOperationMetadata>): IndexOperationMetadata {
    return IndexOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IndexOperationMetadata>): IndexOperationMetadata {
    const message = createBaseIndexOperationMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.index = object.index ?? "";
    message.state = object.state ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    return message;
  },
};

function createBaseFieldOperationMetadata(): FieldOperationMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    field: "",
    indexConfigDeltas: [],
    state: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
    ttlConfigDelta: undefined,
  };
}

export const FieldOperationMetadata: MessageFns<FieldOperationMetadata> = {
  encode(message: FieldOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.field !== "") {
      writer.uint32(26).string(message.field);
    }
    for (const v of message.indexConfigDeltas) {
      FieldOperationMetadata_IndexConfigDelta.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(50).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(58).fork()).join();
    }
    if (message.ttlConfigDelta !== undefined) {
      FieldOperationMetadata_TtlConfigDelta.encode(message.ttlConfigDelta, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FieldOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFieldOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.field = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.indexConfigDeltas.push(FieldOperationMetadata_IndexConfigDelta.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.ttlConfigDelta = FieldOperationMetadata_TtlConfigDelta.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FieldOperationMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      field: isSet(object.field) ? globalThis.String(object.field) : "",
      indexConfigDeltas: globalThis.Array.isArray(object?.indexConfigDeltas)
        ? object.indexConfigDeltas.map((e: any) => FieldOperationMetadata_IndexConfigDelta.fromJSON(e))
        : [],
      state: isSet(object.state) ? operationStateFromJSON(object.state) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      ttlConfigDelta: isSet(object.ttlConfigDelta)
        ? FieldOperationMetadata_TtlConfigDelta.fromJSON(object.ttlConfigDelta)
        : undefined,
    };
  },

  toJSON(message: FieldOperationMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.field !== "") {
      obj.field = message.field;
    }
    if (message.indexConfigDeltas?.length) {
      obj.indexConfigDeltas = message.indexConfigDeltas.map((e) => FieldOperationMetadata_IndexConfigDelta.toJSON(e));
    }
    if (message.state !== 0) {
      obj.state = operationStateToJSON(message.state);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.ttlConfigDelta !== undefined) {
      obj.ttlConfigDelta = FieldOperationMetadata_TtlConfigDelta.toJSON(message.ttlConfigDelta);
    }
    return obj;
  },

  create(base?: DeepPartial<FieldOperationMetadata>): FieldOperationMetadata {
    return FieldOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FieldOperationMetadata>): FieldOperationMetadata {
    const message = createBaseFieldOperationMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.field = object.field ?? "";
    message.indexConfigDeltas =
      object.indexConfigDeltas?.map((e) => FieldOperationMetadata_IndexConfigDelta.fromPartial(e)) || [];
    message.state = object.state ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.ttlConfigDelta = (object.ttlConfigDelta !== undefined && object.ttlConfigDelta !== null)
      ? FieldOperationMetadata_TtlConfigDelta.fromPartial(object.ttlConfigDelta)
      : undefined;
    return message;
  },
};

function createBaseFieldOperationMetadata_IndexConfigDelta(): FieldOperationMetadata_IndexConfigDelta {
  return { changeType: 0, index: undefined };
}

export const FieldOperationMetadata_IndexConfigDelta: MessageFns<FieldOperationMetadata_IndexConfigDelta> = {
  encode(message: FieldOperationMetadata_IndexConfigDelta, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.changeType !== 0) {
      writer.uint32(8).int32(message.changeType);
    }
    if (message.index !== undefined) {
      Index.encode(message.index, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FieldOperationMetadata_IndexConfigDelta {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFieldOperationMetadata_IndexConfigDelta();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.changeType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.index = Index.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FieldOperationMetadata_IndexConfigDelta {
    return {
      changeType: isSet(object.changeType)
        ? fieldOperationMetadata_IndexConfigDelta_ChangeTypeFromJSON(object.changeType)
        : 0,
      index: isSet(object.index) ? Index.fromJSON(object.index) : undefined,
    };
  },

  toJSON(message: FieldOperationMetadata_IndexConfigDelta): unknown {
    const obj: any = {};
    if (message.changeType !== 0) {
      obj.changeType = fieldOperationMetadata_IndexConfigDelta_ChangeTypeToJSON(message.changeType);
    }
    if (message.index !== undefined) {
      obj.index = Index.toJSON(message.index);
    }
    return obj;
  },

  create(base?: DeepPartial<FieldOperationMetadata_IndexConfigDelta>): FieldOperationMetadata_IndexConfigDelta {
    return FieldOperationMetadata_IndexConfigDelta.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FieldOperationMetadata_IndexConfigDelta>): FieldOperationMetadata_IndexConfigDelta {
    const message = createBaseFieldOperationMetadata_IndexConfigDelta();
    message.changeType = object.changeType ?? 0;
    message.index = (object.index !== undefined && object.index !== null) ? Index.fromPartial(object.index) : undefined;
    return message;
  },
};

function createBaseFieldOperationMetadata_TtlConfigDelta(): FieldOperationMetadata_TtlConfigDelta {
  return { changeType: 0 };
}

export const FieldOperationMetadata_TtlConfigDelta: MessageFns<FieldOperationMetadata_TtlConfigDelta> = {
  encode(message: FieldOperationMetadata_TtlConfigDelta, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.changeType !== 0) {
      writer.uint32(8).int32(message.changeType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FieldOperationMetadata_TtlConfigDelta {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFieldOperationMetadata_TtlConfigDelta();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.changeType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FieldOperationMetadata_TtlConfigDelta {
    return {
      changeType: isSet(object.changeType)
        ? fieldOperationMetadata_TtlConfigDelta_ChangeTypeFromJSON(object.changeType)
        : 0,
    };
  },

  toJSON(message: FieldOperationMetadata_TtlConfigDelta): unknown {
    const obj: any = {};
    if (message.changeType !== 0) {
      obj.changeType = fieldOperationMetadata_TtlConfigDelta_ChangeTypeToJSON(message.changeType);
    }
    return obj;
  },

  create(base?: DeepPartial<FieldOperationMetadata_TtlConfigDelta>): FieldOperationMetadata_TtlConfigDelta {
    return FieldOperationMetadata_TtlConfigDelta.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FieldOperationMetadata_TtlConfigDelta>): FieldOperationMetadata_TtlConfigDelta {
    const message = createBaseFieldOperationMetadata_TtlConfigDelta();
    message.changeType = object.changeType ?? 0;
    return message;
  },
};

function createBaseExportDocumentsMetadata(): ExportDocumentsMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    operationState: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
    collectionIds: [],
    outputUriPrefix: "",
    namespaceIds: [],
    snapshotTime: undefined,
  };
}

export const ExportDocumentsMetadata: MessageFns<ExportDocumentsMetadata> = {
  encode(message: ExportDocumentsMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationState !== 0) {
      writer.uint32(24).int32(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(34).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(42).fork()).join();
    }
    for (const v of message.collectionIds) {
      writer.uint32(50).string(v!);
    }
    if (message.outputUriPrefix !== "") {
      writer.uint32(58).string(message.outputUriPrefix);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(66).string(v!);
    }
    if (message.snapshotTime !== undefined) {
      Timestamp.encode(toTimestamp(message.snapshotTime), writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDocumentsMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDocumentsMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationState = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.snapshotTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDocumentsMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationState: isSet(object.operationState) ? operationStateFromJSON(object.operationState) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "",
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
      snapshotTime: isSet(object.snapshotTime) ? fromJsonTimestamp(object.snapshotTime) : undefined,
    };
  },

  toJSON(message: ExportDocumentsMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationState !== 0) {
      obj.operationState = operationStateToJSON(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    if (message.snapshotTime !== undefined) {
      obj.snapshotTime = message.snapshotTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDocumentsMetadata>): ExportDocumentsMetadata {
    return ExportDocumentsMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDocumentsMetadata>): ExportDocumentsMetadata {
    const message = createBaseExportDocumentsMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationState = object.operationState ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    message.snapshotTime = object.snapshotTime ?? undefined;
    return message;
  },
};

function createBaseImportDocumentsMetadata(): ImportDocumentsMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    operationState: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
    collectionIds: [],
    inputUriPrefix: "",
    namespaceIds: [],
  };
}

export const ImportDocumentsMetadata: MessageFns<ImportDocumentsMetadata> = {
  encode(message: ImportDocumentsMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationState !== 0) {
      writer.uint32(24).int32(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(34).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(42).fork()).join();
    }
    for (const v of message.collectionIds) {
      writer.uint32(50).string(v!);
    }
    if (message.inputUriPrefix !== "") {
      writer.uint32(58).string(message.inputUriPrefix);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(66).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDocumentsMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDocumentsMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationState = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.inputUriPrefix = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportDocumentsMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationState: isSet(object.operationState) ? operationStateFromJSON(object.operationState) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      inputUriPrefix: isSet(object.inputUriPrefix) ? globalThis.String(object.inputUriPrefix) : "",
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ImportDocumentsMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationState !== 0) {
      obj.operationState = operationStateToJSON(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.inputUriPrefix !== "") {
      obj.inputUriPrefix = message.inputUriPrefix;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportDocumentsMetadata>): ImportDocumentsMetadata {
    return ImportDocumentsMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportDocumentsMetadata>): ImportDocumentsMetadata {
    const message = createBaseImportDocumentsMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationState = object.operationState ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.inputUriPrefix = object.inputUriPrefix ?? "";
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseBulkDeleteDocumentsMetadata(): BulkDeleteDocumentsMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    operationState: 0,
    progressDocuments: undefined,
    progressBytes: undefined,
    collectionIds: [],
    namespaceIds: [],
    snapshotTime: undefined,
  };
}

export const BulkDeleteDocumentsMetadata: MessageFns<BulkDeleteDocumentsMetadata> = {
  encode(message: BulkDeleteDocumentsMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationState !== 0) {
      writer.uint32(24).int32(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      Progress.encode(message.progressDocuments, writer.uint32(34).fork()).join();
    }
    if (message.progressBytes !== undefined) {
      Progress.encode(message.progressBytes, writer.uint32(42).fork()).join();
    }
    for (const v of message.collectionIds) {
      writer.uint32(50).string(v!);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(58).string(v!);
    }
    if (message.snapshotTime !== undefined) {
      Timestamp.encode(toTimestamp(message.snapshotTime), writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BulkDeleteDocumentsMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBulkDeleteDocumentsMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationState = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.progressDocuments = Progress.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progressBytes = Progress.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.snapshotTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BulkDeleteDocumentsMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationState: isSet(object.operationState) ? operationStateFromJSON(object.operationState) : 0,
      progressDocuments: isSet(object.progressDocuments) ? Progress.fromJSON(object.progressDocuments) : undefined,
      progressBytes: isSet(object.progressBytes) ? Progress.fromJSON(object.progressBytes) : undefined,
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
      snapshotTime: isSet(object.snapshotTime) ? fromJsonTimestamp(object.snapshotTime) : undefined,
    };
  },

  toJSON(message: BulkDeleteDocumentsMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationState !== 0) {
      obj.operationState = operationStateToJSON(message.operationState);
    }
    if (message.progressDocuments !== undefined) {
      obj.progressDocuments = Progress.toJSON(message.progressDocuments);
    }
    if (message.progressBytes !== undefined) {
      obj.progressBytes = Progress.toJSON(message.progressBytes);
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    if (message.snapshotTime !== undefined) {
      obj.snapshotTime = message.snapshotTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<BulkDeleteDocumentsMetadata>): BulkDeleteDocumentsMetadata {
    return BulkDeleteDocumentsMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BulkDeleteDocumentsMetadata>): BulkDeleteDocumentsMetadata {
    const message = createBaseBulkDeleteDocumentsMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationState = object.operationState ?? 0;
    message.progressDocuments = (object.progressDocuments !== undefined && object.progressDocuments !== null)
      ? Progress.fromPartial(object.progressDocuments)
      : undefined;
    message.progressBytes = (object.progressBytes !== undefined && object.progressBytes !== null)
      ? Progress.fromPartial(object.progressBytes)
      : undefined;
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    message.snapshotTime = object.snapshotTime ?? undefined;
    return message;
  },
};

function createBaseExportDocumentsResponse(): ExportDocumentsResponse {
  return { outputUriPrefix: "" };
}

export const ExportDocumentsResponse: MessageFns<ExportDocumentsResponse> = {
  encode(message: ExportDocumentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputUriPrefix !== "") {
      writer.uint32(10).string(message.outputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDocumentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDocumentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDocumentsResponse {
    return { outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "" };
  },

  toJSON(message: ExportDocumentsResponse): unknown {
    const obj: any = {};
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDocumentsResponse>): ExportDocumentsResponse {
    return ExportDocumentsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDocumentsResponse>): ExportDocumentsResponse {
    const message = createBaseExportDocumentsResponse();
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    return message;
  },
};

function createBaseRestoreDatabaseMetadata(): RestoreDatabaseMetadata {
  return {
    startTime: undefined,
    endTime: undefined,
    operationState: 0,
    database: "",
    backup: "",
    progressPercentage: undefined,
  };
}

export const RestoreDatabaseMetadata: MessageFns<RestoreDatabaseMetadata> = {
  encode(message: RestoreDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.operationState !== 0) {
      writer.uint32(24).int32(message.operationState);
    }
    if (message.database !== "") {
      writer.uint32(34).string(message.database);
    }
    if (message.backup !== "") {
      writer.uint32(42).string(message.backup);
    }
    if (message.progressPercentage !== undefined) {
      Progress.encode(message.progressPercentage, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operationState = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.database = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.backup = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.progressPercentage = Progress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreDatabaseMetadata {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      operationState: isSet(object.operationState) ? operationStateFromJSON(object.operationState) : 0,
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      backup: isSet(object.backup) ? globalThis.String(object.backup) : "",
      progressPercentage: isSet(object.progressPercentage) ? Progress.fromJSON(object.progressPercentage) : undefined,
    };
  },

  toJSON(message: RestoreDatabaseMetadata): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.operationState !== 0) {
      obj.operationState = operationStateToJSON(message.operationState);
    }
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.backup !== "") {
      obj.backup = message.backup;
    }
    if (message.progressPercentage !== undefined) {
      obj.progressPercentage = Progress.toJSON(message.progressPercentage);
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreDatabaseMetadata>): RestoreDatabaseMetadata {
    return RestoreDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreDatabaseMetadata>): RestoreDatabaseMetadata {
    const message = createBaseRestoreDatabaseMetadata();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.operationState = object.operationState ?? 0;
    message.database = object.database ?? "";
    message.backup = object.backup ?? "";
    message.progressPercentage = (object.progressPercentage !== undefined && object.progressPercentage !== null)
      ? Progress.fromPartial(object.progressPercentage)
      : undefined;
    return message;
  },
};

function createBaseProgress(): Progress {
  return { estimatedWork: Long.ZERO, completedWork: Long.ZERO };
}

export const Progress: MessageFns<Progress> = {
  encode(message: Progress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.estimatedWork.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.estimatedWork.toString());
    }
    if (!message.completedWork.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.completedWork.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Progress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProgress();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.estimatedWork = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.completedWork = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Progress {
    return {
      estimatedWork: isSet(object.estimatedWork) ? Long.fromValue(object.estimatedWork) : Long.ZERO,
      completedWork: isSet(object.completedWork) ? Long.fromValue(object.completedWork) : Long.ZERO,
    };
  },

  toJSON(message: Progress): unknown {
    const obj: any = {};
    if (!message.estimatedWork.equals(Long.ZERO)) {
      obj.estimatedWork = (message.estimatedWork || Long.ZERO).toString();
    }
    if (!message.completedWork.equals(Long.ZERO)) {
      obj.completedWork = (message.completedWork || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Progress>): Progress {
    return Progress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Progress>): Progress {
    const message = createBaseProgress();
    message.estimatedWork = (object.estimatedWork !== undefined && object.estimatedWork !== null)
      ? Long.fromValue(object.estimatedWork)
      : Long.ZERO;
    message.completedWork = (object.completedWork !== undefined && object.completedWork !== null)
      ? Long.fromValue(object.completedWork)
      : Long.ZERO;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
