// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/firestore/v1beta1/firestore.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Empty } from "../../protobuf/empty.js";
import { Timestamp } from "../../protobuf/timestamp.js";
import { Status } from "../../rpc/status.js";
import { DocumentMask, Precondition, TransactionOptions } from "./common.js";
import { Document } from "./document.js";
import { Cursor, StructuredQuery } from "./query.js";
import { DocumentChange, DocumentDelete, DocumentRemove, ExistenceFilter, Write, WriteResult } from "./write.js";

export const protobufPackage = "google.firestore.v1beta1";

/** The request for [Firestore.GetDocument][google.firestore.v1beta1.Firestore.GetDocument]. */
export interface GetDocumentRequest {
  /**
   * Required. The resource name of the Document to get. In the format:
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   */
  name: string;
  /**
   * The fields to return. If not set, returns all fields.
   *
   * If the document has a field that is not present in this mask, that field
   * will not be returned in the response.
   */
  mask:
    | DocumentMask
    | undefined;
  /** Reads the document in a transaction. */
  transaction?:
    | Buffer
    | undefined;
  /**
   * Reads the version of the document at the given time.
   * This may not be older than 270 seconds.
   */
  readTime?: Date | undefined;
}

/** The request for [Firestore.ListDocuments][google.firestore.v1beta1.Firestore.ListDocuments]. */
export interface ListDocumentsRequest {
  /**
   * Required. The parent resource name. In the format:
   * `projects/{project_id}/databases/{database_id}/documents` or
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   * For example:
   * `projects/my-project/databases/my-database/documents` or
   * `projects/my-project/databases/my-database/documents/chatrooms/my-chatroom`
   */
  parent: string;
  /**
   * Required. The collection ID, relative to `parent`, to list. For example: `chatrooms`
   * or `messages`.
   */
  collectionId: string;
  /** The maximum number of documents to return. */
  pageSize: number;
  /** The `next_page_token` value returned from a previous List request, if any. */
  pageToken: string;
  /** The order to sort results by. For example: `priority desc, name`. */
  orderBy: string;
  /**
   * The fields to return. If not set, returns all fields.
   *
   * If a document has a field that is not present in this mask, that field
   * will not be returned in the response.
   */
  mask:
    | DocumentMask
    | undefined;
  /** Reads documents in a transaction. */
  transaction?:
    | Buffer
    | undefined;
  /**
   * Reads documents as they were at the given time.
   * This may not be older than 270 seconds.
   */
  readTime?:
    | Date
    | undefined;
  /**
   * If the list should show missing documents. A missing document is a
   * document that does not exist but has sub-documents. These documents will
   * be returned with a key but will not have fields, [Document.create_time][google.firestore.v1beta1.Document.create_time],
   * or [Document.update_time][google.firestore.v1beta1.Document.update_time] set.
   *
   * Requests with `show_missing` may not specify `where` or
   * `order_by`.
   */
  showMissing: boolean;
}

/** The response for [Firestore.ListDocuments][google.firestore.v1beta1.Firestore.ListDocuments]. */
export interface ListDocumentsResponse {
  /** The Documents found. */
  documents: Document[];
  /** The next page token. */
  nextPageToken: string;
}

/** The request for [Firestore.CreateDocument][google.firestore.v1beta1.Firestore.CreateDocument]. */
export interface CreateDocumentRequest {
  /**
   * Required. The parent resource. For example:
   * `projects/{project_id}/databases/{database_id}/documents` or
   * `projects/{project_id}/databases/{database_id}/documents/chatrooms/{chatroom_id}`
   */
  parent: string;
  /** Required. The collection ID, relative to `parent`, to list. For example: `chatrooms`. */
  collectionId: string;
  /**
   * The client-assigned document ID to use for this document.
   *
   * Optional. If not specified, an ID will be assigned by the service.
   */
  documentId: string;
  /** Required. The document to create. `name` must not be set. */
  document:
    | Document
    | undefined;
  /**
   * The fields to return. If not set, returns all fields.
   *
   * If the document has a field that is not present in this mask, that field
   * will not be returned in the response.
   */
  mask: DocumentMask | undefined;
}

/** The request for [Firestore.UpdateDocument][google.firestore.v1beta1.Firestore.UpdateDocument]. */
export interface UpdateDocumentRequest {
  /**
   * Required. The updated document.
   * Creates the document if it does not already exist.
   */
  document:
    | Document
    | undefined;
  /**
   * The fields to update.
   * None of the field paths in the mask may contain a reserved name.
   *
   * If the document exists on the server and has fields not referenced in the
   * mask, they are left unchanged.
   * Fields referenced in the mask, but not present in the input document, are
   * deleted from the document on the server.
   */
  updateMask:
    | DocumentMask
    | undefined;
  /**
   * The fields to return. If not set, returns all fields.
   *
   * If the document has a field that is not present in this mask, that field
   * will not be returned in the response.
   */
  mask:
    | DocumentMask
    | undefined;
  /**
   * An optional precondition on the document.
   * The request will fail if this is set and not met by the target document.
   */
  currentDocument: Precondition | undefined;
}

/** The request for [Firestore.DeleteDocument][google.firestore.v1beta1.Firestore.DeleteDocument]. */
export interface DeleteDocumentRequest {
  /**
   * Required. The resource name of the Document to delete. In the format:
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   */
  name: string;
  /**
   * An optional precondition on the document.
   * The request will fail if this is set and not met by the target document.
   */
  currentDocument: Precondition | undefined;
}

/** The request for [Firestore.BatchGetDocuments][google.firestore.v1beta1.Firestore.BatchGetDocuments]. */
export interface BatchGetDocumentsRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   */
  database: string;
  /**
   * The names of the documents to retrieve. In the format:
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   * The request will fail if any of the document is not a child resource of the
   * given `database`. Duplicate names will be elided.
   */
  documents: string[];
  /**
   * The fields to return. If not set, returns all fields.
   *
   * If a document has a field that is not present in this mask, that field will
   * not be returned in the response.
   */
  mask:
    | DocumentMask
    | undefined;
  /** Reads documents in a transaction. */
  transaction?:
    | Buffer
    | undefined;
  /**
   * Starts a new transaction and reads the documents.
   * Defaults to a read-only transaction.
   * The new transaction ID will be returned as the first response in the
   * stream.
   */
  newTransaction?:
    | TransactionOptions
    | undefined;
  /**
   * Reads documents as they were at the given time.
   * This may not be older than 270 seconds.
   */
  readTime?: Date | undefined;
}

/** The streamed response for [Firestore.BatchGetDocuments][google.firestore.v1beta1.Firestore.BatchGetDocuments]. */
export interface BatchGetDocumentsResponse {
  /** A document that was requested. */
  found?:
    | Document
    | undefined;
  /**
   * A document name that was requested but does not exist. In the format:
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   */
  missing?:
    | string
    | undefined;
  /**
   * The transaction that was started as part of this request.
   * Will only be set in the first response, and only if
   * [BatchGetDocumentsRequest.new_transaction][google.firestore.v1beta1.BatchGetDocumentsRequest.new_transaction] was set in the request.
   */
  transaction: Buffer;
  /**
   * The time at which the document was read.
   * This may be monotically increasing, in this case the previous documents in
   * the result stream are guaranteed not to have changed between their
   * read_time and this one.
   */
  readTime: Date | undefined;
}

/** The request for [Firestore.BeginTransaction][google.firestore.v1beta1.Firestore.BeginTransaction]. */
export interface BeginTransactionRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   */
  database: string;
  /**
   * The options for the transaction.
   * Defaults to a read-write transaction.
   */
  options: TransactionOptions | undefined;
}

/** The response for [Firestore.BeginTransaction][google.firestore.v1beta1.Firestore.BeginTransaction]. */
export interface BeginTransactionResponse {
  /** The transaction that was started. */
  transaction: Buffer;
}

/** The request for [Firestore.Commit][google.firestore.v1beta1.Firestore.Commit]. */
export interface CommitRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   */
  database: string;
  /**
   * The writes to apply.
   *
   * Always executed atomically and in order.
   */
  writes: Write[];
  /** If set, applies all writes in this transaction, and commits it. */
  transaction: Buffer;
}

/** The response for [Firestore.Commit][google.firestore.v1beta1.Firestore.Commit]. */
export interface CommitResponse {
  /**
   * The result of applying the writes.
   *
   * This i-th write result corresponds to the i-th write in the
   * request.
   */
  writeResults: WriteResult[];
  /**
   * The time at which the commit occurred. Any read with an equal or greater
   * `read_time` is guaranteed to see the effects of the commit.
   */
  commitTime: Date | undefined;
}

/** The request for [Firestore.Rollback][google.firestore.v1beta1.Firestore.Rollback]. */
export interface RollbackRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   */
  database: string;
  /** Required. The transaction to roll back. */
  transaction: Buffer;
}

/** The request for [Firestore.RunQuery][google.firestore.v1beta1.Firestore.RunQuery]. */
export interface RunQueryRequest {
  /**
   * Required. The parent resource name. In the format:
   * `projects/{project_id}/databases/{database_id}/documents` or
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   * For example:
   * `projects/my-project/databases/my-database/documents` or
   * `projects/my-project/databases/my-database/documents/chatrooms/my-chatroom`
   */
  parent: string;
  /** A structured query. */
  structuredQuery?:
    | StructuredQuery
    | undefined;
  /** Reads documents in a transaction. */
  transaction?:
    | Buffer
    | undefined;
  /**
   * Starts a new transaction and reads the documents.
   * Defaults to a read-only transaction.
   * The new transaction ID will be returned as the first response in the
   * stream.
   */
  newTransaction?:
    | TransactionOptions
    | undefined;
  /**
   * Reads documents as they were at the given time.
   * This may not be older than 270 seconds.
   */
  readTime?: Date | undefined;
}

/** The response for [Firestore.RunQuery][google.firestore.v1beta1.Firestore.RunQuery]. */
export interface RunQueryResponse {
  /**
   * The transaction that was started as part of this request.
   * Can only be set in the first response, and only if
   * [RunQueryRequest.new_transaction][google.firestore.v1beta1.RunQueryRequest.new_transaction] was set in the request.
   * If set, no other fields will be set in this response.
   */
  transaction: Buffer;
  /**
   * A query result.
   * Not set when reporting partial progress.
   */
  document:
    | Document
    | undefined;
  /**
   * The time at which the document was read. This may be monotonically
   * increasing; in this case, the previous documents in the result stream are
   * guaranteed not to have changed between their `read_time` and this one.
   *
   * If the query returns no results, a response with `read_time` and no
   * `document` will be sent, and this represents the time at which the query
   * was run.
   */
  readTime:
    | Date
    | undefined;
  /**
   * The number of results that have been skipped due to an offset between
   * the last response and the current response.
   */
  skippedResults: number;
}

/** The request for [Firestore.PartitionQuery][google.firestore.v1beta1.Firestore.PartitionQuery]. */
export interface PartitionQueryRequest {
  /**
   * Required. The parent resource name. In the format:
   * `projects/{project_id}/databases/{database_id}/documents`.
   * Document resource names are not supported; only database resource names
   * can be specified.
   */
  parent: string;
  /**
   * A structured query.
   * Query must specify collection with all descendants and be ordered by name
   * ascending. Other filters, order bys, limits, offsets, and start/end
   * cursors are not supported.
   */
  structuredQuery?:
    | StructuredQuery
    | undefined;
  /**
   * The desired maximum number of partition points.
   * The partitions may be returned across multiple pages of results.
   * The number must be positive. The actual number of partitions
   * returned may be fewer.
   *
   * For example, this may be set to one fewer than the number of parallel
   * queries to be run, or in running a data pipeline job, one fewer than the
   * number of workers or compute instances available.
   */
  partitionCount: Long;
  /**
   * The `next_page_token` value returned from a previous call to
   * PartitionQuery that may be used to get an additional set of results.
   * There are no ordering guarantees between sets of results. Thus, using
   * multiple sets of results will require merging the different result sets.
   *
   * For example, two subsequent calls using a page_token may return:
   *
   *  * cursor B, cursor M, cursor Q
   *  * cursor A, cursor U, cursor W
   *
   * To obtain a complete result set ordered with respect to the results of the
   * query supplied to PartitionQuery, the results sets should be merged:
   * cursor A, cursor B, cursor M, cursor Q, cursor U, cursor W
   */
  pageToken: string;
  /**
   * The maximum number of partitions to return in this call, subject to
   * `partition_count`.
   *
   * For example, if `partition_count` = 10 and `page_size` = 8, the first call
   * to PartitionQuery will return up to 8 partitions and a `next_page_token`
   * if more results exist. A second call to PartitionQuery will return up to
   * 2 partitions, to complete the total of 10 specified in `partition_count`.
   */
  pageSize: number;
}

/** The response for [Firestore.PartitionQuery][google.firestore.v1beta1.Firestore.PartitionQuery]. */
export interface PartitionQueryResponse {
  /**
   * Partition results.
   * Each partition is a split point that can be used by RunQuery as a starting
   * or end point for the query results. The RunQuery requests must be made with
   * the same query supplied to this PartitionQuery request. The partition
   * cursors will be ordered according to same ordering as the results of the
   * query supplied to PartitionQuery.
   *
   * For example, if a PartitionQuery request returns partition cursors A and B,
   * running the following three queries will return the entire result set of
   * the original query:
   *
   *  * query, end_at A
   *  * query, start_at A, end_at B
   *  * query, start_at B
   *
   * An empty result may indicate that the query has too few results to be
   * partitioned.
   */
  partitions: Cursor[];
  /**
   * A page token that may be used to request an additional set of results, up
   * to the number specified by `partition_count` in the PartitionQuery request.
   * If blank, there are no more results.
   */
  nextPageToken: string;
}

/**
 * The request for [Firestore.Write][google.firestore.v1beta1.Firestore.Write].
 *
 * The first request creates a stream, or resumes an existing one from a token.
 *
 * When creating a new stream, the server replies with a response containing
 * only an ID and a token, to use in the next request.
 *
 * When resuming a stream, the server first streams any responses later than the
 * given token, then a response containing only an up-to-date token, to use in
 * the next request.
 */
export interface WriteRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   * This is only required in the first message.
   */
  database: string;
  /**
   * The ID of the write stream to resume.
   * This may only be set in the first message. When left empty, a new write
   * stream will be created.
   */
  streamId: string;
  /**
   * The writes to apply.
   *
   * Always executed atomically and in order.
   * This must be empty on the first request.
   * This may be empty on the last request.
   * This must not be empty on all other requests.
   */
  writes: Write[];
  /**
   * A stream token that was previously sent by the server.
   *
   * The client should set this field to the token from the most recent
   * [WriteResponse][google.firestore.v1beta1.WriteResponse] it has received. This acknowledges that the client has
   * received responses up to this token. After sending this token, earlier
   * tokens may not be used anymore.
   *
   * The server may close the stream if there are too many unacknowledged
   * responses.
   *
   * Leave this field unset when creating a new stream. To resume a stream at
   * a specific point, set this field and the `stream_id` field.
   *
   * Leave this field unset when creating a new stream.
   */
  streamToken: Buffer;
  /** Labels associated with this write request. */
  labels: { [key: string]: string };
}

export interface WriteRequest_LabelsEntry {
  key: string;
  value: string;
}

/** The response for [Firestore.Write][google.firestore.v1beta1.Firestore.Write]. */
export interface WriteResponse {
  /**
   * The ID of the stream.
   * Only set on the first message, when a new stream was created.
   */
  streamId: string;
  /**
   * A token that represents the position of this response in the stream.
   * This can be used by a client to resume the stream at this point.
   *
   * This field is always set.
   */
  streamToken: Buffer;
  /**
   * The result of applying the writes.
   *
   * This i-th write result corresponds to the i-th write in the
   * request.
   */
  writeResults: WriteResult[];
  /**
   * The time at which the commit occurred. Any read with an equal or greater
   * `read_time` is guaranteed to see the effects of the write.
   */
  commitTime: Date | undefined;
}

/** A request for [Firestore.Listen][google.firestore.v1beta1.Firestore.Listen] */
export interface ListenRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   */
  database: string;
  /** A target to add to this stream. */
  addTarget?:
    | Target
    | undefined;
  /** The ID of a target to remove from this stream. */
  removeTarget?:
    | number
    | undefined;
  /** Labels associated with this target change. */
  labels: { [key: string]: string };
}

export interface ListenRequest_LabelsEntry {
  key: string;
  value: string;
}

/** The response for [Firestore.Listen][google.firestore.v1beta1.Firestore.Listen]. */
export interface ListenResponse {
  /** Targets have changed. */
  targetChange?:
    | TargetChange
    | undefined;
  /** A [Document][google.firestore.v1beta1.Document] has changed. */
  documentChange?:
    | DocumentChange
    | undefined;
  /** A [Document][google.firestore.v1beta1.Document] has been deleted. */
  documentDelete?:
    | DocumentDelete
    | undefined;
  /**
   * A [Document][google.firestore.v1beta1.Document] has been removed from a target (because it is no longer
   * relevant to that target).
   */
  documentRemove?:
    | DocumentRemove
    | undefined;
  /**
   * A filter to apply to the set of documents previously returned for the
   * given target.
   *
   * Returned when documents may have been removed from the given target, but
   * the exact documents are unknown.
   */
  filter?: ExistenceFilter | undefined;
}

/** A specification of a set of documents to listen to. */
export interface Target {
  /** A target specified by a query. */
  query?:
    | Target_QueryTarget
    | undefined;
  /** A target specified by a set of document names. */
  documents?:
    | Target_DocumentsTarget
    | undefined;
  /**
   * A resume token from a prior [TargetChange][google.firestore.v1beta1.TargetChange] for an identical target.
   *
   * Using a resume token with a different target is unsupported and may fail.
   */
  resumeToken?:
    | Buffer
    | undefined;
  /**
   * Start listening after a specific `read_time`.
   *
   * The client must know the state of matching documents at this time.
   */
  readTime?:
    | Date
    | undefined;
  /**
   * The target ID that identifies the target on the stream. Must be a positive
   * number and non-zero.
   */
  targetId: number;
  /** If the target should be removed once it is current and consistent. */
  once: boolean;
}

/** A target specified by a set of documents names. */
export interface Target_DocumentsTarget {
  /**
   * The names of the documents to retrieve. In the format:
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   * The request will fail if any of the document is not a child resource of
   * the given `database`. Duplicate names will be elided.
   */
  documents: string[];
}

/** A target specified by a query. */
export interface Target_QueryTarget {
  /**
   * The parent resource name. In the format:
   * `projects/{project_id}/databases/{database_id}/documents` or
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   * For example:
   * `projects/my-project/databases/my-database/documents` or
   * `projects/my-project/databases/my-database/documents/chatrooms/my-chatroom`
   */
  parent: string;
  /** A structured query. */
  structuredQuery?: StructuredQuery | undefined;
}

/** Targets being watched have changed. */
export interface TargetChange {
  /** The type of change that occurred. */
  targetChangeType: TargetChange_TargetChangeType;
  /**
   * The target IDs of targets that have changed.
   *
   * If empty, the change applies to all targets.
   *
   * The order of the target IDs is not defined.
   */
  targetIds: number[];
  /** The error that resulted in this change, if applicable. */
  cause:
    | Status
    | undefined;
  /**
   * A token that can be used to resume the stream for the given `target_ids`,
   * or all targets if `target_ids` is empty.
   *
   * Not set on every target change.
   */
  resumeToken: Buffer;
  /**
   * The consistent `read_time` for the given `target_ids` (omitted when the
   * target_ids are not at a consistent snapshot).
   *
   * The stream is guaranteed to send a `read_time` with `target_ids` empty
   * whenever the entire stream reaches a new consistent snapshot. ADD,
   * CURRENT, and RESET messages are guaranteed to (eventually) result in a
   * new consistent snapshot (while NO_CHANGE and REMOVE messages are not).
   *
   * For a given stream, `read_time` is guaranteed to be monotonically
   * increasing.
   */
  readTime: Date | undefined;
}

/** The type of change. */
export enum TargetChange_TargetChangeType {
  /** NO_CHANGE - No change has occurred. Used only to send an updated `resume_token`. */
  NO_CHANGE = 0,
  /** ADD - The targets have been added. */
  ADD = 1,
  /** REMOVE - The targets have been removed. */
  REMOVE = 2,
  /**
   * CURRENT - The targets reflect all changes committed before the targets were added
   * to the stream.
   *
   * This will be sent after or with a `read_time` that is greater than or
   * equal to the time at which the targets were added.
   *
   * Listeners can wait for this change if read-after-write semantics
   * are desired.
   */
  CURRENT = 3,
  /**
   * RESET - The targets have been reset, and a new initial state for the targets
   * will be returned in subsequent changes.
   *
   * After the initial state is complete, `CURRENT` will be returned even
   * if the target was previously indicated to be `CURRENT`.
   */
  RESET = 4,
  UNRECOGNIZED = -1,
}

export function targetChange_TargetChangeTypeFromJSON(object: any): TargetChange_TargetChangeType {
  switch (object) {
    case 0:
    case "NO_CHANGE":
      return TargetChange_TargetChangeType.NO_CHANGE;
    case 1:
    case "ADD":
      return TargetChange_TargetChangeType.ADD;
    case 2:
    case "REMOVE":
      return TargetChange_TargetChangeType.REMOVE;
    case 3:
    case "CURRENT":
      return TargetChange_TargetChangeType.CURRENT;
    case 4:
    case "RESET":
      return TargetChange_TargetChangeType.RESET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TargetChange_TargetChangeType.UNRECOGNIZED;
  }
}

export function targetChange_TargetChangeTypeToJSON(object: TargetChange_TargetChangeType): string {
  switch (object) {
    case TargetChange_TargetChangeType.NO_CHANGE:
      return "NO_CHANGE";
    case TargetChange_TargetChangeType.ADD:
      return "ADD";
    case TargetChange_TargetChangeType.REMOVE:
      return "REMOVE";
    case TargetChange_TargetChangeType.CURRENT:
      return "CURRENT";
    case TargetChange_TargetChangeType.RESET:
      return "RESET";
    case TargetChange_TargetChangeType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The request for [Firestore.ListCollectionIds][google.firestore.v1beta1.Firestore.ListCollectionIds]. */
export interface ListCollectionIdsRequest {
  /**
   * Required. The parent document. In the format:
   * `projects/{project_id}/databases/{database_id}/documents/{document_path}`.
   * For example:
   * `projects/my-project/databases/my-database/documents/chatrooms/my-chatroom`
   */
  parent: string;
  /** The maximum number of results to return. */
  pageSize: number;
  /**
   * A page token. Must be a value from
   * [ListCollectionIdsResponse][google.firestore.v1beta1.ListCollectionIdsResponse].
   */
  pageToken: string;
}

/** The response from [Firestore.ListCollectionIds][google.firestore.v1beta1.Firestore.ListCollectionIds]. */
export interface ListCollectionIdsResponse {
  /** The collection ids. */
  collectionIds: string[];
  /** A page token that may be used to continue the list. */
  nextPageToken: string;
}

/** The request for [Firestore.BatchWrite][google.firestore.v1beta1.Firestore.BatchWrite]. */
export interface BatchWriteRequest {
  /**
   * Required. The database name. In the format:
   * `projects/{project_id}/databases/{database_id}`.
   */
  database: string;
  /**
   * The writes to apply.
   *
   * Method does not apply writes atomically and does not guarantee ordering.
   * Each write succeeds or fails independently. You cannot write to the same
   * document more than once per request.
   */
  writes: Write[];
  /** Labels associated with this batch write. */
  labels: { [key: string]: string };
}

export interface BatchWriteRequest_LabelsEntry {
  key: string;
  value: string;
}

/** The response from [Firestore.BatchWrite][google.firestore.v1beta1.Firestore.BatchWrite]. */
export interface BatchWriteResponse {
  /**
   * The result of applying the writes.
   *
   * This i-th write result corresponds to the i-th write in the
   * request.
   */
  writeResults: WriteResult[];
  /**
   * The status of applying the writes.
   *
   * This i-th write status corresponds to the i-th write in the
   * request.
   */
  status: Status[];
}

function createBaseGetDocumentRequest(): GetDocumentRequest {
  return { name: "", mask: undefined, transaction: undefined, readTime: undefined };
}

export const GetDocumentRequest: MessageFns<GetDocumentRequest> = {
  encode(message: GetDocumentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.mask !== undefined) {
      DocumentMask.encode(message.mask, writer.uint32(18).fork()).join();
    }
    if (message.transaction !== undefined) {
      writer.uint32(26).bytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDocumentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDocumentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mask = DocumentMask.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDocumentRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      mask: isSet(object.mask) ? DocumentMask.fromJSON(object.mask) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: GetDocumentRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.mask !== undefined) {
      obj.mask = DocumentMask.toJSON(message.mask);
    }
    if (message.transaction !== undefined) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<GetDocumentRequest>): GetDocumentRequest {
    return GetDocumentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDocumentRequest>): GetDocumentRequest {
    const message = createBaseGetDocumentRequest();
    message.name = object.name ?? "";
    message.mask = (object.mask !== undefined && object.mask !== null)
      ? DocumentMask.fromPartial(object.mask)
      : undefined;
    message.transaction = object.transaction ?? undefined;
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseListDocumentsRequest(): ListDocumentsRequest {
  return {
    parent: "",
    collectionId: "",
    pageSize: 0,
    pageToken: "",
    orderBy: "",
    mask: undefined,
    transaction: undefined,
    readTime: undefined,
    showMissing: false,
  };
}

export const ListDocumentsRequest: MessageFns<ListDocumentsRequest> = {
  encode(message: ListDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.collectionId !== "") {
      writer.uint32(18).string(message.collectionId);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(50).string(message.orderBy);
    }
    if (message.mask !== undefined) {
      DocumentMask.encode(message.mask, writer.uint32(58).fork()).join();
    }
    if (message.transaction !== undefined) {
      writer.uint32(66).bytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(82).fork()).join();
    }
    if (message.showMissing !== false) {
      writer.uint32(96).bool(message.showMissing);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.collectionId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.mask = DocumentMask.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.showMissing = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDocumentsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      collectionId: isSet(object.collectionId) ? globalThis.String(object.collectionId) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      mask: isSet(object.mask) ? DocumentMask.fromJSON(object.mask) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      showMissing: isSet(object.showMissing) ? globalThis.Boolean(object.showMissing) : false,
    };
  },

  toJSON(message: ListDocumentsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.collectionId !== "") {
      obj.collectionId = message.collectionId;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.mask !== undefined) {
      obj.mask = DocumentMask.toJSON(message.mask);
    }
    if (message.transaction !== undefined) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.showMissing !== false) {
      obj.showMissing = message.showMissing;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDocumentsRequest>): ListDocumentsRequest {
    return ListDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDocumentsRequest>): ListDocumentsRequest {
    const message = createBaseListDocumentsRequest();
    message.parent = object.parent ?? "";
    message.collectionId = object.collectionId ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.mask = (object.mask !== undefined && object.mask !== null)
      ? DocumentMask.fromPartial(object.mask)
      : undefined;
    message.transaction = object.transaction ?? undefined;
    message.readTime = object.readTime ?? undefined;
    message.showMissing = object.showMissing ?? false;
    return message;
  },
};

function createBaseListDocumentsResponse(): ListDocumentsResponse {
  return { documents: [], nextPageToken: "" };
}

export const ListDocumentsResponse: MessageFns<ListDocumentsResponse> = {
  encode(message: ListDocumentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.documents) {
      Document.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDocumentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDocumentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.documents.push(Document.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDocumentsResponse {
    return {
      documents: globalThis.Array.isArray(object?.documents)
        ? object.documents.map((e: any) => Document.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDocumentsResponse): unknown {
    const obj: any = {};
    if (message.documents?.length) {
      obj.documents = message.documents.map((e) => Document.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDocumentsResponse>): ListDocumentsResponse {
    return ListDocumentsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDocumentsResponse>): ListDocumentsResponse {
    const message = createBaseListDocumentsResponse();
    message.documents = object.documents?.map((e) => Document.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCreateDocumentRequest(): CreateDocumentRequest {
  return { parent: "", collectionId: "", documentId: "", document: undefined, mask: undefined };
}

export const CreateDocumentRequest: MessageFns<CreateDocumentRequest> = {
  encode(message: CreateDocumentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.collectionId !== "") {
      writer.uint32(18).string(message.collectionId);
    }
    if (message.documentId !== "") {
      writer.uint32(26).string(message.documentId);
    }
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(34).fork()).join();
    }
    if (message.mask !== undefined) {
      DocumentMask.encode(message.mask, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDocumentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDocumentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.collectionId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.documentId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.mask = DocumentMask.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDocumentRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      collectionId: isSet(object.collectionId) ? globalThis.String(object.collectionId) : "",
      documentId: isSet(object.documentId) ? globalThis.String(object.documentId) : "",
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      mask: isSet(object.mask) ? DocumentMask.fromJSON(object.mask) : undefined,
    };
  },

  toJSON(message: CreateDocumentRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.collectionId !== "") {
      obj.collectionId = message.collectionId;
    }
    if (message.documentId !== "") {
      obj.documentId = message.documentId;
    }
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.mask !== undefined) {
      obj.mask = DocumentMask.toJSON(message.mask);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDocumentRequest>): CreateDocumentRequest {
    return CreateDocumentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDocumentRequest>): CreateDocumentRequest {
    const message = createBaseCreateDocumentRequest();
    message.parent = object.parent ?? "";
    message.collectionId = object.collectionId ?? "";
    message.documentId = object.documentId ?? "";
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.mask = (object.mask !== undefined && object.mask !== null)
      ? DocumentMask.fromPartial(object.mask)
      : undefined;
    return message;
  },
};

function createBaseUpdateDocumentRequest(): UpdateDocumentRequest {
  return { document: undefined, updateMask: undefined, mask: undefined, currentDocument: undefined };
}

export const UpdateDocumentRequest: MessageFns<UpdateDocumentRequest> = {
  encode(message: UpdateDocumentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      DocumentMask.encode(message.updateMask, writer.uint32(18).fork()).join();
    }
    if (message.mask !== undefined) {
      DocumentMask.encode(message.mask, writer.uint32(26).fork()).join();
    }
    if (message.currentDocument !== undefined) {
      Precondition.encode(message.currentDocument, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDocumentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDocumentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = DocumentMask.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mask = DocumentMask.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.currentDocument = Precondition.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDocumentRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      updateMask: isSet(object.updateMask) ? DocumentMask.fromJSON(object.updateMask) : undefined,
      mask: isSet(object.mask) ? DocumentMask.fromJSON(object.mask) : undefined,
      currentDocument: isSet(object.currentDocument) ? Precondition.fromJSON(object.currentDocument) : undefined,
    };
  },

  toJSON(message: UpdateDocumentRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = DocumentMask.toJSON(message.updateMask);
    }
    if (message.mask !== undefined) {
      obj.mask = DocumentMask.toJSON(message.mask);
    }
    if (message.currentDocument !== undefined) {
      obj.currentDocument = Precondition.toJSON(message.currentDocument);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDocumentRequest>): UpdateDocumentRequest {
    return UpdateDocumentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDocumentRequest>): UpdateDocumentRequest {
    const message = createBaseUpdateDocumentRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.updateMask = (object.updateMask !== undefined && object.updateMask !== null)
      ? DocumentMask.fromPartial(object.updateMask)
      : undefined;
    message.mask = (object.mask !== undefined && object.mask !== null)
      ? DocumentMask.fromPartial(object.mask)
      : undefined;
    message.currentDocument = (object.currentDocument !== undefined && object.currentDocument !== null)
      ? Precondition.fromPartial(object.currentDocument)
      : undefined;
    return message;
  },
};

function createBaseDeleteDocumentRequest(): DeleteDocumentRequest {
  return { name: "", currentDocument: undefined };
}

export const DeleteDocumentRequest: MessageFns<DeleteDocumentRequest> = {
  encode(message: DeleteDocumentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.currentDocument !== undefined) {
      Precondition.encode(message.currentDocument, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteDocumentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteDocumentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.currentDocument = Precondition.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteDocumentRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      currentDocument: isSet(object.currentDocument) ? Precondition.fromJSON(object.currentDocument) : undefined,
    };
  },

  toJSON(message: DeleteDocumentRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.currentDocument !== undefined) {
      obj.currentDocument = Precondition.toJSON(message.currentDocument);
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteDocumentRequest>): DeleteDocumentRequest {
    return DeleteDocumentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteDocumentRequest>): DeleteDocumentRequest {
    const message = createBaseDeleteDocumentRequest();
    message.name = object.name ?? "";
    message.currentDocument = (object.currentDocument !== undefined && object.currentDocument !== null)
      ? Precondition.fromPartial(object.currentDocument)
      : undefined;
    return message;
  },
};

function createBaseBatchGetDocumentsRequest(): BatchGetDocumentsRequest {
  return {
    database: "",
    documents: [],
    mask: undefined,
    transaction: undefined,
    newTransaction: undefined,
    readTime: undefined,
  };
}

export const BatchGetDocumentsRequest: MessageFns<BatchGetDocumentsRequest> = {
  encode(message: BatchGetDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    for (const v of message.documents) {
      writer.uint32(18).string(v!);
    }
    if (message.mask !== undefined) {
      DocumentMask.encode(message.mask, writer.uint32(26).fork()).join();
    }
    if (message.transaction !== undefined) {
      writer.uint32(34).bytes(message.transaction);
    }
    if (message.newTransaction !== undefined) {
      TransactionOptions.encode(message.newTransaction, writer.uint32(42).fork()).join();
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.documents.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mask = DocumentMask.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.newTransaction = TransactionOptions.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetDocumentsRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      documents: globalThis.Array.isArray(object?.documents)
        ? object.documents.map((e: any) => globalThis.String(e))
        : [],
      mask: isSet(object.mask) ? DocumentMask.fromJSON(object.mask) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : undefined,
      newTransaction: isSet(object.newTransaction) ? TransactionOptions.fromJSON(object.newTransaction) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: BatchGetDocumentsRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.documents?.length) {
      obj.documents = message.documents;
    }
    if (message.mask !== undefined) {
      obj.mask = DocumentMask.toJSON(message.mask);
    }
    if (message.transaction !== undefined) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.newTransaction !== undefined) {
      obj.newTransaction = TransactionOptions.toJSON(message.newTransaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetDocumentsRequest>): BatchGetDocumentsRequest {
    return BatchGetDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetDocumentsRequest>): BatchGetDocumentsRequest {
    const message = createBaseBatchGetDocumentsRequest();
    message.database = object.database ?? "";
    message.documents = object.documents?.map((e) => e) || [];
    message.mask = (object.mask !== undefined && object.mask !== null)
      ? DocumentMask.fromPartial(object.mask)
      : undefined;
    message.transaction = object.transaction ?? undefined;
    message.newTransaction = (object.newTransaction !== undefined && object.newTransaction !== null)
      ? TransactionOptions.fromPartial(object.newTransaction)
      : undefined;
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseBatchGetDocumentsResponse(): BatchGetDocumentsResponse {
  return { found: undefined, missing: undefined, transaction: Buffer.alloc(0), readTime: undefined };
}

export const BatchGetDocumentsResponse: MessageFns<BatchGetDocumentsResponse> = {
  encode(message: BatchGetDocumentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.found !== undefined) {
      Document.encode(message.found, writer.uint32(10).fork()).join();
    }
    if (message.missing !== undefined) {
      writer.uint32(18).string(message.missing);
    }
    if (message.transaction.length !== 0) {
      writer.uint32(26).bytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetDocumentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetDocumentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.found = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.missing = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetDocumentsResponse {
    return {
      found: isSet(object.found) ? Document.fromJSON(object.found) : undefined,
      missing: isSet(object.missing) ? globalThis.String(object.missing) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: BatchGetDocumentsResponse): unknown {
    const obj: any = {};
    if (message.found !== undefined) {
      obj.found = Document.toJSON(message.found);
    }
    if (message.missing !== undefined) {
      obj.missing = message.missing;
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetDocumentsResponse>): BatchGetDocumentsResponse {
    return BatchGetDocumentsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetDocumentsResponse>): BatchGetDocumentsResponse {
    const message = createBaseBatchGetDocumentsResponse();
    message.found = (object.found !== undefined && object.found !== null)
      ? Document.fromPartial(object.found)
      : undefined;
    message.missing = object.missing ?? undefined;
    message.transaction = object.transaction ?? Buffer.alloc(0);
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseBeginTransactionRequest(): BeginTransactionRequest {
  return { database: "", options: undefined };
}

export const BeginTransactionRequest: MessageFns<BeginTransactionRequest> = {
  encode(message: BeginTransactionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    if (message.options !== undefined) {
      TransactionOptions.encode(message.options, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BeginTransactionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBeginTransactionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.options = TransactionOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BeginTransactionRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      options: isSet(object.options) ? TransactionOptions.fromJSON(object.options) : undefined,
    };
  },

  toJSON(message: BeginTransactionRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.options !== undefined) {
      obj.options = TransactionOptions.toJSON(message.options);
    }
    return obj;
  },

  create(base?: DeepPartial<BeginTransactionRequest>): BeginTransactionRequest {
    return BeginTransactionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BeginTransactionRequest>): BeginTransactionRequest {
    const message = createBaseBeginTransactionRequest();
    message.database = object.database ?? "";
    message.options = (object.options !== undefined && object.options !== null)
      ? TransactionOptions.fromPartial(object.options)
      : undefined;
    return message;
  },
};

function createBaseBeginTransactionResponse(): BeginTransactionResponse {
  return { transaction: Buffer.alloc(0) };
}

export const BeginTransactionResponse: MessageFns<BeginTransactionResponse> = {
  encode(message: BeginTransactionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transaction.length !== 0) {
      writer.uint32(10).bytes(message.transaction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BeginTransactionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBeginTransactionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BeginTransactionResponse {
    return {
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
    };
  },

  toJSON(message: BeginTransactionResponse): unknown {
    const obj: any = {};
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    return obj;
  },

  create(base?: DeepPartial<BeginTransactionResponse>): BeginTransactionResponse {
    return BeginTransactionResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BeginTransactionResponse>): BeginTransactionResponse {
    const message = createBaseBeginTransactionResponse();
    message.transaction = object.transaction ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCommitRequest(): CommitRequest {
  return { database: "", writes: [], transaction: Buffer.alloc(0) };
}

export const CommitRequest: MessageFns<CommitRequest> = {
  encode(message: CommitRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    for (const v of message.writes) {
      Write.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.transaction.length !== 0) {
      writer.uint32(26).bytes(message.transaction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.writes.push(Write.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      writes: globalThis.Array.isArray(object?.writes) ? object.writes.map((e: any) => Write.fromJSON(e)) : [],
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
    };
  },

  toJSON(message: CommitRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.writes?.length) {
      obj.writes = message.writes.map((e) => Write.toJSON(e));
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    return obj;
  },

  create(base?: DeepPartial<CommitRequest>): CommitRequest {
    return CommitRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitRequest>): CommitRequest {
    const message = createBaseCommitRequest();
    message.database = object.database ?? "";
    message.writes = object.writes?.map((e) => Write.fromPartial(e)) || [];
    message.transaction = object.transaction ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCommitResponse(): CommitResponse {
  return { writeResults: [], commitTime: undefined };
}

export const CommitResponse: MessageFns<CommitResponse> = {
  encode(message: CommitResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.writeResults) {
      WriteResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.commitTime !== undefined) {
      Timestamp.encode(toTimestamp(message.commitTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.writeResults.push(WriteResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitResponse {
    return {
      writeResults: globalThis.Array.isArray(object?.writeResults)
        ? object.writeResults.map((e: any) => WriteResult.fromJSON(e))
        : [],
      commitTime: isSet(object.commitTime) ? fromJsonTimestamp(object.commitTime) : undefined,
    };
  },

  toJSON(message: CommitResponse): unknown {
    const obj: any = {};
    if (message.writeResults?.length) {
      obj.writeResults = message.writeResults.map((e) => WriteResult.toJSON(e));
    }
    if (message.commitTime !== undefined) {
      obj.commitTime = message.commitTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CommitResponse>): CommitResponse {
    return CommitResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitResponse>): CommitResponse {
    const message = createBaseCommitResponse();
    message.writeResults = object.writeResults?.map((e) => WriteResult.fromPartial(e)) || [];
    message.commitTime = object.commitTime ?? undefined;
    return message;
  },
};

function createBaseRollbackRequest(): RollbackRequest {
  return { database: "", transaction: Buffer.alloc(0) };
}

export const RollbackRequest: MessageFns<RollbackRequest> = {
  encode(message: RollbackRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    if (message.transaction.length !== 0) {
      writer.uint32(18).bytes(message.transaction);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RollbackRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollbackRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RollbackRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
    };
  },

  toJSON(message: RollbackRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    return obj;
  },

  create(base?: DeepPartial<RollbackRequest>): RollbackRequest {
    return RollbackRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RollbackRequest>): RollbackRequest {
    const message = createBaseRollbackRequest();
    message.database = object.database ?? "";
    message.transaction = object.transaction ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseRunQueryRequest(): RunQueryRequest {
  return {
    parent: "",
    structuredQuery: undefined,
    transaction: undefined,
    newTransaction: undefined,
    readTime: undefined,
  };
}

export const RunQueryRequest: MessageFns<RunQueryRequest> = {
  encode(message: RunQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.structuredQuery !== undefined) {
      StructuredQuery.encode(message.structuredQuery, writer.uint32(18).fork()).join();
    }
    if (message.transaction !== undefined) {
      writer.uint32(42).bytes(message.transaction);
    }
    if (message.newTransaction !== undefined) {
      TransactionOptions.encode(message.newTransaction, writer.uint32(50).fork()).join();
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.structuredQuery = StructuredQuery.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.newTransaction = TransactionOptions.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunQueryRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      structuredQuery: isSet(object.structuredQuery) ? StructuredQuery.fromJSON(object.structuredQuery) : undefined,
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : undefined,
      newTransaction: isSet(object.newTransaction) ? TransactionOptions.fromJSON(object.newTransaction) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: RunQueryRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.structuredQuery !== undefined) {
      obj.structuredQuery = StructuredQuery.toJSON(message.structuredQuery);
    }
    if (message.transaction !== undefined) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.newTransaction !== undefined) {
      obj.newTransaction = TransactionOptions.toJSON(message.newTransaction);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<RunQueryRequest>): RunQueryRequest {
    return RunQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunQueryRequest>): RunQueryRequest {
    const message = createBaseRunQueryRequest();
    message.parent = object.parent ?? "";
    message.structuredQuery = (object.structuredQuery !== undefined && object.structuredQuery !== null)
      ? StructuredQuery.fromPartial(object.structuredQuery)
      : undefined;
    message.transaction = object.transaction ?? undefined;
    message.newTransaction = (object.newTransaction !== undefined && object.newTransaction !== null)
      ? TransactionOptions.fromPartial(object.newTransaction)
      : undefined;
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseRunQueryResponse(): RunQueryResponse {
  return { transaction: Buffer.alloc(0), document: undefined, readTime: undefined, skippedResults: 0 };
}

export const RunQueryResponse: MessageFns<RunQueryResponse> = {
  encode(message: RunQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transaction.length !== 0) {
      writer.uint32(18).bytes(message.transaction);
    }
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(26).fork()).join();
    }
    if (message.skippedResults !== 0) {
      writer.uint32(32).int32(message.skippedResults);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transaction = Buffer.from(reader.bytes());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.skippedResults = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunQueryResponse {
    return {
      transaction: isSet(object.transaction) ? Buffer.from(bytesFromBase64(object.transaction)) : Buffer.alloc(0),
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      skippedResults: isSet(object.skippedResults) ? globalThis.Number(object.skippedResults) : 0,
    };
  },

  toJSON(message: RunQueryResponse): unknown {
    const obj: any = {};
    if (message.transaction.length !== 0) {
      obj.transaction = base64FromBytes(message.transaction);
    }
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.skippedResults !== 0) {
      obj.skippedResults = Math.round(message.skippedResults);
    }
    return obj;
  },

  create(base?: DeepPartial<RunQueryResponse>): RunQueryResponse {
    return RunQueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunQueryResponse>): RunQueryResponse {
    const message = createBaseRunQueryResponse();
    message.transaction = object.transaction ?? Buffer.alloc(0);
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.readTime = object.readTime ?? undefined;
    message.skippedResults = object.skippedResults ?? 0;
    return message;
  },
};

function createBasePartitionQueryRequest(): PartitionQueryRequest {
  return { parent: "", structuredQuery: undefined, partitionCount: Long.ZERO, pageToken: "", pageSize: 0 };
}

export const PartitionQueryRequest: MessageFns<PartitionQueryRequest> = {
  encode(message: PartitionQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.structuredQuery !== undefined) {
      StructuredQuery.encode(message.structuredQuery, writer.uint32(18).fork()).join();
    }
    if (!message.partitionCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.partitionCount.toString());
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(40).int32(message.pageSize);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PartitionQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartitionQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.structuredQuery = StructuredQuery.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.partitionCount = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PartitionQueryRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      structuredQuery: isSet(object.structuredQuery) ? StructuredQuery.fromJSON(object.structuredQuery) : undefined,
      partitionCount: isSet(object.partitionCount) ? Long.fromValue(object.partitionCount) : Long.ZERO,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
    };
  },

  toJSON(message: PartitionQueryRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.structuredQuery !== undefined) {
      obj.structuredQuery = StructuredQuery.toJSON(message.structuredQuery);
    }
    if (!message.partitionCount.equals(Long.ZERO)) {
      obj.partitionCount = (message.partitionCount || Long.ZERO).toString();
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    return obj;
  },

  create(base?: DeepPartial<PartitionQueryRequest>): PartitionQueryRequest {
    return PartitionQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PartitionQueryRequest>): PartitionQueryRequest {
    const message = createBasePartitionQueryRequest();
    message.parent = object.parent ?? "";
    message.structuredQuery = (object.structuredQuery !== undefined && object.structuredQuery !== null)
      ? StructuredQuery.fromPartial(object.structuredQuery)
      : undefined;
    message.partitionCount = (object.partitionCount !== undefined && object.partitionCount !== null)
      ? Long.fromValue(object.partitionCount)
      : Long.ZERO;
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    return message;
  },
};

function createBasePartitionQueryResponse(): PartitionQueryResponse {
  return { partitions: [], nextPageToken: "" };
}

export const PartitionQueryResponse: MessageFns<PartitionQueryResponse> = {
  encode(message: PartitionQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.partitions) {
      Cursor.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PartitionQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartitionQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.partitions.push(Cursor.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PartitionQueryResponse {
    return {
      partitions: globalThis.Array.isArray(object?.partitions)
        ? object.partitions.map((e: any) => Cursor.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: PartitionQueryResponse): unknown {
    const obj: any = {};
    if (message.partitions?.length) {
      obj.partitions = message.partitions.map((e) => Cursor.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<PartitionQueryResponse>): PartitionQueryResponse {
    return PartitionQueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PartitionQueryResponse>): PartitionQueryResponse {
    const message = createBasePartitionQueryResponse();
    message.partitions = object.partitions?.map((e) => Cursor.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseWriteRequest(): WriteRequest {
  return { database: "", streamId: "", writes: [], streamToken: Buffer.alloc(0), labels: {} };
}

export const WriteRequest: MessageFns<WriteRequest> = {
  encode(message: WriteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    if (message.streamId !== "") {
      writer.uint32(18).string(message.streamId);
    }
    for (const v of message.writes) {
      Write.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.streamToken.length !== 0) {
      writer.uint32(34).bytes(message.streamToken);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      WriteRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.streamId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.writes.push(Write.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.streamToken = Buffer.from(reader.bytes());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = WriteRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      streamId: isSet(object.streamId) ? globalThis.String(object.streamId) : "",
      writes: globalThis.Array.isArray(object?.writes) ? object.writes.map((e: any) => Write.fromJSON(e)) : [],
      streamToken: isSet(object.streamToken) ? Buffer.from(bytesFromBase64(object.streamToken)) : Buffer.alloc(0),
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: WriteRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.streamId !== "") {
      obj.streamId = message.streamId;
    }
    if (message.writes?.length) {
      obj.writes = message.writes.map((e) => Write.toJSON(e));
    }
    if (message.streamToken.length !== 0) {
      obj.streamToken = base64FromBytes(message.streamToken);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<WriteRequest>): WriteRequest {
    return WriteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteRequest>): WriteRequest {
    const message = createBaseWriteRequest();
    message.database = object.database ?? "";
    message.streamId = object.streamId ?? "";
    message.writes = object.writes?.map((e) => Write.fromPartial(e)) || [];
    message.streamToken = object.streamToken ?? Buffer.alloc(0);
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseWriteRequest_LabelsEntry(): WriteRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const WriteRequest_LabelsEntry: MessageFns<WriteRequest_LabelsEntry> = {
  encode(message: WriteRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: WriteRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<WriteRequest_LabelsEntry>): WriteRequest_LabelsEntry {
    return WriteRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteRequest_LabelsEntry>): WriteRequest_LabelsEntry {
    const message = createBaseWriteRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseWriteResponse(): WriteResponse {
  return { streamId: "", streamToken: Buffer.alloc(0), writeResults: [], commitTime: undefined };
}

export const WriteResponse: MessageFns<WriteResponse> = {
  encode(message: WriteResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.streamId !== "") {
      writer.uint32(10).string(message.streamId);
    }
    if (message.streamToken.length !== 0) {
      writer.uint32(18).bytes(message.streamToken);
    }
    for (const v of message.writeResults) {
      WriteResult.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.commitTime !== undefined) {
      Timestamp.encode(toTimestamp(message.commitTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.streamId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.streamToken = Buffer.from(reader.bytes());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.writeResults.push(WriteResult.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.commitTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteResponse {
    return {
      streamId: isSet(object.streamId) ? globalThis.String(object.streamId) : "",
      streamToken: isSet(object.streamToken) ? Buffer.from(bytesFromBase64(object.streamToken)) : Buffer.alloc(0),
      writeResults: globalThis.Array.isArray(object?.writeResults)
        ? object.writeResults.map((e: any) => WriteResult.fromJSON(e))
        : [],
      commitTime: isSet(object.commitTime) ? fromJsonTimestamp(object.commitTime) : undefined,
    };
  },

  toJSON(message: WriteResponse): unknown {
    const obj: any = {};
    if (message.streamId !== "") {
      obj.streamId = message.streamId;
    }
    if (message.streamToken.length !== 0) {
      obj.streamToken = base64FromBytes(message.streamToken);
    }
    if (message.writeResults?.length) {
      obj.writeResults = message.writeResults.map((e) => WriteResult.toJSON(e));
    }
    if (message.commitTime !== undefined) {
      obj.commitTime = message.commitTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<WriteResponse>): WriteResponse {
    return WriteResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteResponse>): WriteResponse {
    const message = createBaseWriteResponse();
    message.streamId = object.streamId ?? "";
    message.streamToken = object.streamToken ?? Buffer.alloc(0);
    message.writeResults = object.writeResults?.map((e) => WriteResult.fromPartial(e)) || [];
    message.commitTime = object.commitTime ?? undefined;
    return message;
  },
};

function createBaseListenRequest(): ListenRequest {
  return { database: "", addTarget: undefined, removeTarget: undefined, labels: {} };
}

export const ListenRequest: MessageFns<ListenRequest> = {
  encode(message: ListenRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    if (message.addTarget !== undefined) {
      Target.encode(message.addTarget, writer.uint32(18).fork()).join();
    }
    if (message.removeTarget !== undefined) {
      writer.uint32(24).int32(message.removeTarget);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ListenRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListenRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListenRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.addTarget = Target.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.removeTarget = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = ListenRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListenRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      addTarget: isSet(object.addTarget) ? Target.fromJSON(object.addTarget) : undefined,
      removeTarget: isSet(object.removeTarget) ? globalThis.Number(object.removeTarget) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: ListenRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.addTarget !== undefined) {
      obj.addTarget = Target.toJSON(message.addTarget);
    }
    if (message.removeTarget !== undefined) {
      obj.removeTarget = Math.round(message.removeTarget);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ListenRequest>): ListenRequest {
    return ListenRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListenRequest>): ListenRequest {
    const message = createBaseListenRequest();
    message.database = object.database ?? "";
    message.addTarget = (object.addTarget !== undefined && object.addTarget !== null)
      ? Target.fromPartial(object.addTarget)
      : undefined;
    message.removeTarget = object.removeTarget ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseListenRequest_LabelsEntry(): ListenRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const ListenRequest_LabelsEntry: MessageFns<ListenRequest_LabelsEntry> = {
  encode(message: ListenRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListenRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListenRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListenRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ListenRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ListenRequest_LabelsEntry>): ListenRequest_LabelsEntry {
    return ListenRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListenRequest_LabelsEntry>): ListenRequest_LabelsEntry {
    const message = createBaseListenRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseListenResponse(): ListenResponse {
  return {
    targetChange: undefined,
    documentChange: undefined,
    documentDelete: undefined,
    documentRemove: undefined,
    filter: undefined,
  };
}

export const ListenResponse: MessageFns<ListenResponse> = {
  encode(message: ListenResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.targetChange !== undefined) {
      TargetChange.encode(message.targetChange, writer.uint32(18).fork()).join();
    }
    if (message.documentChange !== undefined) {
      DocumentChange.encode(message.documentChange, writer.uint32(26).fork()).join();
    }
    if (message.documentDelete !== undefined) {
      DocumentDelete.encode(message.documentDelete, writer.uint32(34).fork()).join();
    }
    if (message.documentRemove !== undefined) {
      DocumentRemove.encode(message.documentRemove, writer.uint32(50).fork()).join();
    }
    if (message.filter !== undefined) {
      ExistenceFilter.encode(message.filter, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListenResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListenResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.targetChange = TargetChange.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.documentChange = DocumentChange.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.documentDelete = DocumentDelete.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.documentRemove = DocumentRemove.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = ExistenceFilter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListenResponse {
    return {
      targetChange: isSet(object.targetChange) ? TargetChange.fromJSON(object.targetChange) : undefined,
      documentChange: isSet(object.documentChange) ? DocumentChange.fromJSON(object.documentChange) : undefined,
      documentDelete: isSet(object.documentDelete) ? DocumentDelete.fromJSON(object.documentDelete) : undefined,
      documentRemove: isSet(object.documentRemove) ? DocumentRemove.fromJSON(object.documentRemove) : undefined,
      filter: isSet(object.filter) ? ExistenceFilter.fromJSON(object.filter) : undefined,
    };
  },

  toJSON(message: ListenResponse): unknown {
    const obj: any = {};
    if (message.targetChange !== undefined) {
      obj.targetChange = TargetChange.toJSON(message.targetChange);
    }
    if (message.documentChange !== undefined) {
      obj.documentChange = DocumentChange.toJSON(message.documentChange);
    }
    if (message.documentDelete !== undefined) {
      obj.documentDelete = DocumentDelete.toJSON(message.documentDelete);
    }
    if (message.documentRemove !== undefined) {
      obj.documentRemove = DocumentRemove.toJSON(message.documentRemove);
    }
    if (message.filter !== undefined) {
      obj.filter = ExistenceFilter.toJSON(message.filter);
    }
    return obj;
  },

  create(base?: DeepPartial<ListenResponse>): ListenResponse {
    return ListenResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListenResponse>): ListenResponse {
    const message = createBaseListenResponse();
    message.targetChange = (object.targetChange !== undefined && object.targetChange !== null)
      ? TargetChange.fromPartial(object.targetChange)
      : undefined;
    message.documentChange = (object.documentChange !== undefined && object.documentChange !== null)
      ? DocumentChange.fromPartial(object.documentChange)
      : undefined;
    message.documentDelete = (object.documentDelete !== undefined && object.documentDelete !== null)
      ? DocumentDelete.fromPartial(object.documentDelete)
      : undefined;
    message.documentRemove = (object.documentRemove !== undefined && object.documentRemove !== null)
      ? DocumentRemove.fromPartial(object.documentRemove)
      : undefined;
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? ExistenceFilter.fromPartial(object.filter)
      : undefined;
    return message;
  },
};

function createBaseTarget(): Target {
  return {
    query: undefined,
    documents: undefined,
    resumeToken: undefined,
    readTime: undefined,
    targetId: 0,
    once: false,
  };
}

export const Target: MessageFns<Target> = {
  encode(message: Target, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== undefined) {
      Target_QueryTarget.encode(message.query, writer.uint32(18).fork()).join();
    }
    if (message.documents !== undefined) {
      Target_DocumentsTarget.encode(message.documents, writer.uint32(26).fork()).join();
    }
    if (message.resumeToken !== undefined) {
      writer.uint32(34).bytes(message.resumeToken);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(90).fork()).join();
    }
    if (message.targetId !== 0) {
      writer.uint32(40).int32(message.targetId);
    }
    if (message.once !== false) {
      writer.uint32(48).bool(message.once);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.query = Target_QueryTarget.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.documents = Target_DocumentsTarget.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.resumeToken = Buffer.from(reader.bytes());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.targetId = reader.int32();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.once = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target {
    return {
      query: isSet(object.query) ? Target_QueryTarget.fromJSON(object.query) : undefined,
      documents: isSet(object.documents) ? Target_DocumentsTarget.fromJSON(object.documents) : undefined,
      resumeToken: isSet(object.resumeToken) ? Buffer.from(bytesFromBase64(object.resumeToken)) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      targetId: isSet(object.targetId) ? globalThis.Number(object.targetId) : 0,
      once: isSet(object.once) ? globalThis.Boolean(object.once) : false,
    };
  },

  toJSON(message: Target): unknown {
    const obj: any = {};
    if (message.query !== undefined) {
      obj.query = Target_QueryTarget.toJSON(message.query);
    }
    if (message.documents !== undefined) {
      obj.documents = Target_DocumentsTarget.toJSON(message.documents);
    }
    if (message.resumeToken !== undefined) {
      obj.resumeToken = base64FromBytes(message.resumeToken);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.targetId !== 0) {
      obj.targetId = Math.round(message.targetId);
    }
    if (message.once !== false) {
      obj.once = message.once;
    }
    return obj;
  },

  create(base?: DeepPartial<Target>): Target {
    return Target.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Target>): Target {
    const message = createBaseTarget();
    message.query = (object.query !== undefined && object.query !== null)
      ? Target_QueryTarget.fromPartial(object.query)
      : undefined;
    message.documents = (object.documents !== undefined && object.documents !== null)
      ? Target_DocumentsTarget.fromPartial(object.documents)
      : undefined;
    message.resumeToken = object.resumeToken ?? undefined;
    message.readTime = object.readTime ?? undefined;
    message.targetId = object.targetId ?? 0;
    message.once = object.once ?? false;
    return message;
  },
};

function createBaseTarget_DocumentsTarget(): Target_DocumentsTarget {
  return { documents: [] };
}

export const Target_DocumentsTarget: MessageFns<Target_DocumentsTarget> = {
  encode(message: Target_DocumentsTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.documents) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target_DocumentsTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget_DocumentsTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.documents.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target_DocumentsTarget {
    return {
      documents: globalThis.Array.isArray(object?.documents)
        ? object.documents.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Target_DocumentsTarget): unknown {
    const obj: any = {};
    if (message.documents?.length) {
      obj.documents = message.documents;
    }
    return obj;
  },

  create(base?: DeepPartial<Target_DocumentsTarget>): Target_DocumentsTarget {
    return Target_DocumentsTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Target_DocumentsTarget>): Target_DocumentsTarget {
    const message = createBaseTarget_DocumentsTarget();
    message.documents = object.documents?.map((e) => e) || [];
    return message;
  },
};

function createBaseTarget_QueryTarget(): Target_QueryTarget {
  return { parent: "", structuredQuery: undefined };
}

export const Target_QueryTarget: MessageFns<Target_QueryTarget> = {
  encode(message: Target_QueryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.structuredQuery !== undefined) {
      StructuredQuery.encode(message.structuredQuery, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target_QueryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget_QueryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.structuredQuery = StructuredQuery.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target_QueryTarget {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      structuredQuery: isSet(object.structuredQuery) ? StructuredQuery.fromJSON(object.structuredQuery) : undefined,
    };
  },

  toJSON(message: Target_QueryTarget): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.structuredQuery !== undefined) {
      obj.structuredQuery = StructuredQuery.toJSON(message.structuredQuery);
    }
    return obj;
  },

  create(base?: DeepPartial<Target_QueryTarget>): Target_QueryTarget {
    return Target_QueryTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Target_QueryTarget>): Target_QueryTarget {
    const message = createBaseTarget_QueryTarget();
    message.parent = object.parent ?? "";
    message.structuredQuery = (object.structuredQuery !== undefined && object.structuredQuery !== null)
      ? StructuredQuery.fromPartial(object.structuredQuery)
      : undefined;
    return message;
  },
};

function createBaseTargetChange(): TargetChange {
  return { targetChangeType: 0, targetIds: [], cause: undefined, resumeToken: Buffer.alloc(0), readTime: undefined };
}

export const TargetChange: MessageFns<TargetChange> = {
  encode(message: TargetChange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.targetChangeType !== 0) {
      writer.uint32(8).int32(message.targetChangeType);
    }
    writer.uint32(18).fork();
    for (const v of message.targetIds) {
      writer.int32(v);
    }
    writer.join();
    if (message.cause !== undefined) {
      Status.encode(message.cause, writer.uint32(26).fork()).join();
    }
    if (message.resumeToken.length !== 0) {
      writer.uint32(34).bytes(message.resumeToken);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetChange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetChange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.targetChangeType = reader.int32() as any;
          continue;
        case 2:
          if (tag === 16) {
            message.targetIds.push(reader.int32());

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.targetIds.push(reader.int32());
            }

            continue;
          }

          break;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cause = Status.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.resumeToken = Buffer.from(reader.bytes());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetChange {
    return {
      targetChangeType: isSet(object.targetChangeType)
        ? targetChange_TargetChangeTypeFromJSON(object.targetChangeType)
        : 0,
      targetIds: globalThis.Array.isArray(object?.targetIds)
        ? object.targetIds.map((e: any) => globalThis.Number(e))
        : [],
      cause: isSet(object.cause) ? Status.fromJSON(object.cause) : undefined,
      resumeToken: isSet(object.resumeToken) ? Buffer.from(bytesFromBase64(object.resumeToken)) : Buffer.alloc(0),
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
    };
  },

  toJSON(message: TargetChange): unknown {
    const obj: any = {};
    if (message.targetChangeType !== 0) {
      obj.targetChangeType = targetChange_TargetChangeTypeToJSON(message.targetChangeType);
    }
    if (message.targetIds?.length) {
      obj.targetIds = message.targetIds.map((e) => Math.round(e));
    }
    if (message.cause !== undefined) {
      obj.cause = Status.toJSON(message.cause);
    }
    if (message.resumeToken.length !== 0) {
      obj.resumeToken = base64FromBytes(message.resumeToken);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<TargetChange>): TargetChange {
    return TargetChange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TargetChange>): TargetChange {
    const message = createBaseTargetChange();
    message.targetChangeType = object.targetChangeType ?? 0;
    message.targetIds = object.targetIds?.map((e) => e) || [];
    message.cause = (object.cause !== undefined && object.cause !== null)
      ? Status.fromPartial(object.cause)
      : undefined;
    message.resumeToken = object.resumeToken ?? Buffer.alloc(0);
    message.readTime = object.readTime ?? undefined;
    return message;
  },
};

function createBaseListCollectionIdsRequest(): ListCollectionIdsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListCollectionIdsRequest: MessageFns<ListCollectionIdsRequest> = {
  encode(message: ListCollectionIdsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListCollectionIdsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListCollectionIdsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListCollectionIdsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListCollectionIdsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListCollectionIdsRequest>): ListCollectionIdsRequest {
    return ListCollectionIdsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListCollectionIdsRequest>): ListCollectionIdsRequest {
    const message = createBaseListCollectionIdsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListCollectionIdsResponse(): ListCollectionIdsResponse {
  return { collectionIds: [], nextPageToken: "" };
}

export const ListCollectionIdsResponse: MessageFns<ListCollectionIdsResponse> = {
  encode(message: ListCollectionIdsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.collectionIds) {
      writer.uint32(10).string(v!);
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListCollectionIdsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListCollectionIdsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListCollectionIdsResponse {
    return {
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListCollectionIdsResponse): unknown {
    const obj: any = {};
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListCollectionIdsResponse>): ListCollectionIdsResponse {
    return ListCollectionIdsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListCollectionIdsResponse>): ListCollectionIdsResponse {
    const message = createBaseListCollectionIdsResponse();
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseBatchWriteRequest(): BatchWriteRequest {
  return { database: "", writes: [], labels: {} };
}

export const BatchWriteRequest: MessageFns<BatchWriteRequest> = {
  encode(message: BatchWriteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    for (const v of message.writes) {
      Write.encode(v!, writer.uint32(18).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      BatchWriteRequest_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchWriteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchWriteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.writes.push(Write.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = BatchWriteRequest_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchWriteRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      writes: globalThis.Array.isArray(object?.writes) ? object.writes.map((e: any) => Write.fromJSON(e)) : [],
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: BatchWriteRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.writes?.length) {
      obj.writes = message.writes.map((e) => Write.toJSON(e));
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<BatchWriteRequest>): BatchWriteRequest {
    return BatchWriteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchWriteRequest>): BatchWriteRequest {
    const message = createBaseBatchWriteRequest();
    message.database = object.database ?? "";
    message.writes = object.writes?.map((e) => Write.fromPartial(e)) || [];
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseBatchWriteRequest_LabelsEntry(): BatchWriteRequest_LabelsEntry {
  return { key: "", value: "" };
}

export const BatchWriteRequest_LabelsEntry: MessageFns<BatchWriteRequest_LabelsEntry> = {
  encode(message: BatchWriteRequest_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchWriteRequest_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchWriteRequest_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchWriteRequest_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: BatchWriteRequest_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchWriteRequest_LabelsEntry>): BatchWriteRequest_LabelsEntry {
    return BatchWriteRequest_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchWriteRequest_LabelsEntry>): BatchWriteRequest_LabelsEntry {
    const message = createBaseBatchWriteRequest_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBatchWriteResponse(): BatchWriteResponse {
  return { writeResults: [], status: [] };
}

export const BatchWriteResponse: MessageFns<BatchWriteResponse> = {
  encode(message: BatchWriteResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.writeResults) {
      WriteResult.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.status) {
      Status.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchWriteResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchWriteResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.writeResults.push(WriteResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.status.push(Status.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchWriteResponse {
    return {
      writeResults: globalThis.Array.isArray(object?.writeResults)
        ? object.writeResults.map((e: any) => WriteResult.fromJSON(e))
        : [],
      status: globalThis.Array.isArray(object?.status) ? object.status.map((e: any) => Status.fromJSON(e)) : [],
    };
  },

  toJSON(message: BatchWriteResponse): unknown {
    const obj: any = {};
    if (message.writeResults?.length) {
      obj.writeResults = message.writeResults.map((e) => WriteResult.toJSON(e));
    }
    if (message.status?.length) {
      obj.status = message.status.map((e) => Status.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchWriteResponse>): BatchWriteResponse {
    return BatchWriteResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchWriteResponse>): BatchWriteResponse {
    const message = createBaseBatchWriteResponse();
    message.writeResults = object.writeResults?.map((e) => WriteResult.fromPartial(e)) || [];
    message.status = object.status?.map((e) => Status.fromPartial(e)) || [];
    return message;
  },
};

/**
 * The Cloud Firestore service.
 *
 * Cloud Firestore is a fast, fully managed, serverless, cloud-native NoSQL
 * document database that simplifies storing, syncing, and querying data for
 * your mobile, web, and IoT apps at global scale. Its client libraries provide
 * live synchronization and offline support, while its security features and
 * integrations with Firebase and Google Cloud Platform (GCP) accelerate
 * building truly serverless apps.
 */
export type FirestoreDefinition = typeof FirestoreDefinition;
export const FirestoreDefinition = {
  name: "Firestore",
  fullName: "google.firestore.v1beta1.Firestore",
  methods: {
    /** Gets a single document. */
    getDocument: {
      name: "GetDocument",
      requestType: GetDocumentRequest,
      requestStream: false,
      responseType: Document,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              55,
              18,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists documents. */
    listDocuments: {
      name: "ListDocuments",
      requestType: ListDocumentsRequest,
      requestStream: false,
      responseType: ListDocumentsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              73,
              18,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
              47,
              123,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              95,
              105,
              100,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates or inserts a document. */
    updateDocument: {
      name: "UpdateDocument",
      requestType: UpdateDocumentRequest,
      requestStream: false,
      responseType: Document,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              74,
              58,
              8,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              50,
              62,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a document. */
    deleteDocument: {
      name: "DeleteDocument",
      requestType: DeleteDocumentRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              55,
              42,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Gets multiple documents.
     *
     * Documents returned by this method are not guaranteed to be returned in the
     * same order that they were requested.
     */
    batchGetDocuments: {
      name: "BatchGetDocuments",
      requestType: BatchGetDocumentsRequest,
      requestStream: false,
      responseType: BatchGetDocumentsResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              71,
              101,
              116,
            ]),
          ],
        },
      },
    },
    /** Starts a new transaction. */
    beginTransaction: {
      name: "BeginTransaction",
      requestType: BeginTransactionRequest,
      requestStream: false,
      responseType: BeginTransactionResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 97, 116, 97, 98, 97, 115, 101])],
          578365826: [
            Buffer.from([
              74,
              58,
              1,
              42,
              34,
              69,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              98,
              101,
              103,
              105,
              110,
              84,
              114,
              97,
              110,
              115,
              97,
              99,
              116,
              105,
              111,
              110,
            ]),
          ],
        },
      },
    },
    /** Commits a transaction, while optionally updating documents. */
    commit: {
      name: "Commit",
      requestType: CommitRequest,
      requestStream: false,
      responseType: CommitResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 100, 97, 116, 97, 98, 97, 115, 101, 44, 119, 114, 105, 116, 101, 115])],
          578365826: [
            Buffer.from([
              64,
              58,
              1,
              42,
              34,
              59,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              99,
              111,
              109,
              109,
              105,
              116,
            ]),
          ],
        },
      },
    },
    /** Rolls back a transaction. */
    rollback: {
      name: "Rollback",
      requestType: RollbackRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              44,
              116,
              114,
              97,
              110,
              115,
              97,
              99,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              114,
              111,
              108,
              108,
              98,
              97,
              99,
              107,
            ]),
          ],
        },
      },
    },
    /** Runs a query. */
    runQuery: {
      name: "RunQuery",
      requestType: RunQueryRequest,
      requestStream: false,
      responseType: RunQueryResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              135,
              1,
              58,
              1,
              42,
              90,
              69,
              58,
              1,
              42,
              34,
              64,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
              58,
              114,
              117,
              110,
              81,
              117,
              101,
              114,
              121,
              34,
              59,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              125,
              58,
              114,
              117,
              110,
              81,
              117,
              101,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Partitions a query by returning partition cursors that can be used to run
     * the query in parallel. The returned partition cursors are split points that
     * can be used by RunQuery as starting/end points for the query results.
     */
    partitionQuery: {
      name: "PartitionQuery",
      requestType: PartitionQueryRequest,
      requestStream: false,
      responseType: PartitionQueryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              147,
              1,
              58,
              1,
              42,
              90,
              75,
              58,
              1,
              42,
              34,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
              58,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              81,
              117,
              101,
              114,
              121,
              34,
              65,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              125,
              58,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              81,
              117,
              101,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /** Streams batches of document updates and deletes, in order. */
    write: {
      name: "Write",
      requestType: WriteRequest,
      requestStream: true,
      responseType: WriteResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              63,
              58,
              1,
              42,
              34,
              58,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              119,
              114,
              105,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /** Listens to changes. */
    listen: {
      name: "Listen",
      requestType: ListenRequest,
      requestStream: true,
      responseType: ListenResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              64,
              58,
              1,
              42,
              34,
              59,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              108,
              105,
              115,
              116,
              101,
              110,
            ]),
          ],
        },
      },
    },
    /** Lists all the collection IDs underneath a document. */
    listCollectionIds: {
      name: "ListCollectionIds",
      requestType: ListCollectionIdsRequest,
      requestStream: false,
      responseType: ListCollectionIdsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              153,
              1,
              58,
              1,
              42,
              90,
              78,
              58,
              1,
              42,
              34,
              73,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              42,
              42,
              125,
              58,
              108,
              105,
              115,
              116,
              67,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              73,
              100,
              115,
              34,
              68,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              125,
              58,
              108,
              105,
              115,
              116,
              67,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              73,
              100,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Applies a batch of write operations.
     *
     * The BatchWrite method does not apply the write operations atomically
     * and can apply them out of order. Method does not allow more than one write
     * per document. Each write succeeds or fails independently. See the
     * [BatchWriteResponse][google.firestore.v1beta1.BatchWriteResponse] for the success status of each write.
     *
     * If you require an atomically applied set of writes, use
     * [Commit][google.firestore.v1beta1.Firestore.Commit] instead.
     */
    batchWrite: {
      name: "BatchWrite",
      requestType: BatchWriteRequest,
      requestStream: false,
      responseType: BatchWriteResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              87,
              114,
              105,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /** Creates a new document. */
    createDocument: {
      name: "CreateDocument",
      requestType: CreateDocumentRequest,
      requestStream: false,
      responseType: Document,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              81,
              58,
              8,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              34,
              69,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              42,
              125,
              47,
              123,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              95,
              105,
              100,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface FirestoreServiceImplementation<CallContextExt = {}> {
  /** Gets a single document. */
  getDocument(request: GetDocumentRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Document>>;
  /** Lists documents. */
  listDocuments(
    request: ListDocumentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDocumentsResponse>>;
  /** Updates or inserts a document. */
  updateDocument(request: UpdateDocumentRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Document>>;
  /** Deletes a document. */
  deleteDocument(request: DeleteDocumentRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Gets multiple documents.
   *
   * Documents returned by this method are not guaranteed to be returned in the
   * same order that they were requested.
   */
  batchGetDocuments(
    request: BatchGetDocumentsRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<BatchGetDocumentsResponse>>;
  /** Starts a new transaction. */
  beginTransaction(
    request: BeginTransactionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BeginTransactionResponse>>;
  /** Commits a transaction, while optionally updating documents. */
  commit(request: CommitRequest, context: CallContext & CallContextExt): Promise<DeepPartial<CommitResponse>>;
  /** Rolls back a transaction. */
  rollback(request: RollbackRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Runs a query. */
  runQuery(
    request: RunQueryRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<RunQueryResponse>>;
  /**
   * Partitions a query by returning partition cursors that can be used to run
   * the query in parallel. The returned partition cursors are split points that
   * can be used by RunQuery as starting/end points for the query results.
   */
  partitionQuery(
    request: PartitionQueryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<PartitionQueryResponse>>;
  /** Streams batches of document updates and deletes, in order. */
  write(
    request: AsyncIterable<WriteRequest>,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<WriteResponse>>;
  /** Listens to changes. */
  listen(
    request: AsyncIterable<ListenRequest>,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<ListenResponse>>;
  /** Lists all the collection IDs underneath a document. */
  listCollectionIds(
    request: ListCollectionIdsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListCollectionIdsResponse>>;
  /**
   * Applies a batch of write operations.
   *
   * The BatchWrite method does not apply the write operations atomically
   * and can apply them out of order. Method does not allow more than one write
   * per document. Each write succeeds or fails independently. See the
   * [BatchWriteResponse][google.firestore.v1beta1.BatchWriteResponse] for the success status of each write.
   *
   * If you require an atomically applied set of writes, use
   * [Commit][google.firestore.v1beta1.Firestore.Commit] instead.
   */
  batchWrite(
    request: BatchWriteRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BatchWriteResponse>>;
  /** Creates a new document. */
  createDocument(request: CreateDocumentRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Document>>;
}

export interface FirestoreClient<CallOptionsExt = {}> {
  /** Gets a single document. */
  getDocument(request: DeepPartial<GetDocumentRequest>, options?: CallOptions & CallOptionsExt): Promise<Document>;
  /** Lists documents. */
  listDocuments(
    request: DeepPartial<ListDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDocumentsResponse>;
  /** Updates or inserts a document. */
  updateDocument(
    request: DeepPartial<UpdateDocumentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Document>;
  /** Deletes a document. */
  deleteDocument(request: DeepPartial<DeleteDocumentRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Gets multiple documents.
   *
   * Documents returned by this method are not guaranteed to be returned in the
   * same order that they were requested.
   */
  batchGetDocuments(
    request: DeepPartial<BatchGetDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<BatchGetDocumentsResponse>;
  /** Starts a new transaction. */
  beginTransaction(
    request: DeepPartial<BeginTransactionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BeginTransactionResponse>;
  /** Commits a transaction, while optionally updating documents. */
  commit(request: DeepPartial<CommitRequest>, options?: CallOptions & CallOptionsExt): Promise<CommitResponse>;
  /** Rolls back a transaction. */
  rollback(request: DeepPartial<RollbackRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Runs a query. */
  runQuery(
    request: DeepPartial<RunQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<RunQueryResponse>;
  /**
   * Partitions a query by returning partition cursors that can be used to run
   * the query in parallel. The returned partition cursors are split points that
   * can be used by RunQuery as starting/end points for the query results.
   */
  partitionQuery(
    request: DeepPartial<PartitionQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<PartitionQueryResponse>;
  /** Streams batches of document updates and deletes, in order. */
  write(
    request: AsyncIterable<DeepPartial<WriteRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<WriteResponse>;
  /** Listens to changes. */
  listen(
    request: AsyncIterable<DeepPartial<ListenRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<ListenResponse>;
  /** Lists all the collection IDs underneath a document. */
  listCollectionIds(
    request: DeepPartial<ListCollectionIdsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListCollectionIdsResponse>;
  /**
   * Applies a batch of write operations.
   *
   * The BatchWrite method does not apply the write operations atomically
   * and can apply them out of order. Method does not allow more than one write
   * per document. Each write succeeds or fails independently. See the
   * [BatchWriteResponse][google.firestore.v1beta1.BatchWriteResponse] for the success status of each write.
   *
   * If you require an atomically applied set of writes, use
   * [Commit][google.firestore.v1beta1.Firestore.Commit] instead.
   */
  batchWrite(
    request: DeepPartial<BatchWriteRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BatchWriteResponse>;
  /** Creates a new document. */
  createDocument(
    request: DeepPartial<CreateDocumentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Document>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export type ServerStreamingMethodResult<Response> = { [Symbol.asyncIterator](): AsyncIterator<Response, void> };

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
