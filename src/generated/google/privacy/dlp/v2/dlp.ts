// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/privacy/dlp/v2/dlp.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Duration } from "../../../protobuf/duration.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { DateMessage } from "../../../type/date.js";
import { DayOfWeek, dayOfWeekFromJSON, dayOfWeekToJSON } from "../../../type/dayofweek.js";
import { TimeOfDay } from "../../../type/timeofday.js";
import {
  BigQueryField,
  BigQueryTable,
  CloudStorageFileSet,
  CloudStoragePath,
  CustomInfoType,
  CustomInfoType_DetectionRule_HotwordRule,
  CustomInfoType_DetectionRule_Proximity,
  CustomInfoType_Dictionary,
  CustomInfoType_Dictionary_WordList,
  CustomInfoType_Regex,
  EntityId,
  FieldId,
  FileType,
  fileTypeFromJSON,
  fileTypeToJSON,
  InfoType,
  Likelihood,
  likelihoodFromJSON,
  likelihoodToJSON,
  RecordKey,
  SensitivityScore,
  StorageConfig,
  TableOptions,
  TableReference,
} from "./storage.js";

export const protobufPackage = "google.privacy.dlp.v2";

/**
 * Enum of possible outcomes of transformations. SUCCESS if transformation and
 * storing of transformation was successful, otherwise, reason for not
 * transforming.
 */
export enum TransformationResultStatusType {
  /** STATE_TYPE_UNSPECIFIED - Unused. */
  STATE_TYPE_UNSPECIFIED = 0,
  /**
   * INVALID_TRANSFORM - This will be set when a finding could not be transformed (i.e. outside user
   * set bucket range).
   */
  INVALID_TRANSFORM = 1,
  /**
   * BIGQUERY_MAX_ROW_SIZE_EXCEEDED - This will be set when a BigQuery transformation was successful but could
   * not be stored back in BigQuery because the transformed row exceeds
   * BigQuery's max row size.
   */
  BIGQUERY_MAX_ROW_SIZE_EXCEEDED = 2,
  /**
   * METADATA_UNRETRIEVABLE - This will be set when there is a finding in the custom metadata of a file,
   * but at the write time of the transformed file, this key / value pair is
   * unretrievable.
   */
  METADATA_UNRETRIEVABLE = 3,
  /** SUCCESS - This will be set when the transformation and storing of it is successful. */
  SUCCESS = 4,
  UNRECOGNIZED = -1,
}

export function transformationResultStatusTypeFromJSON(object: any): TransformationResultStatusType {
  switch (object) {
    case 0:
    case "STATE_TYPE_UNSPECIFIED":
      return TransformationResultStatusType.STATE_TYPE_UNSPECIFIED;
    case 1:
    case "INVALID_TRANSFORM":
      return TransformationResultStatusType.INVALID_TRANSFORM;
    case 2:
    case "BIGQUERY_MAX_ROW_SIZE_EXCEEDED":
      return TransformationResultStatusType.BIGQUERY_MAX_ROW_SIZE_EXCEEDED;
    case 3:
    case "METADATA_UNRETRIEVABLE":
      return TransformationResultStatusType.METADATA_UNRETRIEVABLE;
    case 4:
    case "SUCCESS":
      return TransformationResultStatusType.SUCCESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TransformationResultStatusType.UNRECOGNIZED;
  }
}

export function transformationResultStatusTypeToJSON(object: TransformationResultStatusType): string {
  switch (object) {
    case TransformationResultStatusType.STATE_TYPE_UNSPECIFIED:
      return "STATE_TYPE_UNSPECIFIED";
    case TransformationResultStatusType.INVALID_TRANSFORM:
      return "INVALID_TRANSFORM";
    case TransformationResultStatusType.BIGQUERY_MAX_ROW_SIZE_EXCEEDED:
      return "BIGQUERY_MAX_ROW_SIZE_EXCEEDED";
    case TransformationResultStatusType.METADATA_UNRETRIEVABLE:
      return "METADATA_UNRETRIEVABLE";
    case TransformationResultStatusType.SUCCESS:
      return "SUCCESS";
    case TransformationResultStatusType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Describes functionality of a given container in its original format. */
export enum TransformationContainerType {
  /** TRANSFORM_UNKNOWN_CONTAINER - Unused. */
  TRANSFORM_UNKNOWN_CONTAINER = 0,
  /** TRANSFORM_BODY - Body of a file. */
  TRANSFORM_BODY = 1,
  /** TRANSFORM_METADATA - Metadata for a file. */
  TRANSFORM_METADATA = 2,
  /** TRANSFORM_TABLE - A table. */
  TRANSFORM_TABLE = 3,
  UNRECOGNIZED = -1,
}

export function transformationContainerTypeFromJSON(object: any): TransformationContainerType {
  switch (object) {
    case 0:
    case "TRANSFORM_UNKNOWN_CONTAINER":
      return TransformationContainerType.TRANSFORM_UNKNOWN_CONTAINER;
    case 1:
    case "TRANSFORM_BODY":
      return TransformationContainerType.TRANSFORM_BODY;
    case 2:
    case "TRANSFORM_METADATA":
      return TransformationContainerType.TRANSFORM_METADATA;
    case 3:
    case "TRANSFORM_TABLE":
      return TransformationContainerType.TRANSFORM_TABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TransformationContainerType.UNRECOGNIZED;
  }
}

export function transformationContainerTypeToJSON(object: TransformationContainerType): string {
  switch (object) {
    case TransformationContainerType.TRANSFORM_UNKNOWN_CONTAINER:
      return "TRANSFORM_UNKNOWN_CONTAINER";
    case TransformationContainerType.TRANSFORM_BODY:
      return "TRANSFORM_BODY";
    case TransformationContainerType.TRANSFORM_METADATA:
      return "TRANSFORM_METADATA";
    case TransformationContainerType.TRANSFORM_TABLE:
      return "TRANSFORM_TABLE";
    case TransformationContainerType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * An enum of rules that can be used to transform a value. Can be a
 * record suppression, or one of the transformation rules specified under
 * `PrimitiveTransformation`.
 */
export enum TransformationType {
  /** TRANSFORMATION_TYPE_UNSPECIFIED - Unused */
  TRANSFORMATION_TYPE_UNSPECIFIED = 0,
  /** RECORD_SUPPRESSION - Record suppression */
  RECORD_SUPPRESSION = 1,
  /** REPLACE_VALUE - Replace value */
  REPLACE_VALUE = 2,
  /** REPLACE_DICTIONARY - Replace value using a dictionary. */
  REPLACE_DICTIONARY = 15,
  /** REDACT - Redact */
  REDACT = 3,
  /** CHARACTER_MASK - Character mask */
  CHARACTER_MASK = 4,
  /** CRYPTO_REPLACE_FFX_FPE - FFX-FPE */
  CRYPTO_REPLACE_FFX_FPE = 5,
  /** FIXED_SIZE_BUCKETING - Fixed size bucketing */
  FIXED_SIZE_BUCKETING = 6,
  /** BUCKETING - Bucketing */
  BUCKETING = 7,
  /** REPLACE_WITH_INFO_TYPE - Replace with info type */
  REPLACE_WITH_INFO_TYPE = 8,
  /** TIME_PART - Time part */
  TIME_PART = 9,
  /** CRYPTO_HASH - Crypto hash */
  CRYPTO_HASH = 10,
  /** DATE_SHIFT - Date shift */
  DATE_SHIFT = 12,
  /** CRYPTO_DETERMINISTIC_CONFIG - Deterministic crypto */
  CRYPTO_DETERMINISTIC_CONFIG = 13,
  /** REDACT_IMAGE - Redact image */
  REDACT_IMAGE = 14,
  UNRECOGNIZED = -1,
}

export function transformationTypeFromJSON(object: any): TransformationType {
  switch (object) {
    case 0:
    case "TRANSFORMATION_TYPE_UNSPECIFIED":
      return TransformationType.TRANSFORMATION_TYPE_UNSPECIFIED;
    case 1:
    case "RECORD_SUPPRESSION":
      return TransformationType.RECORD_SUPPRESSION;
    case 2:
    case "REPLACE_VALUE":
      return TransformationType.REPLACE_VALUE;
    case 15:
    case "REPLACE_DICTIONARY":
      return TransformationType.REPLACE_DICTIONARY;
    case 3:
    case "REDACT":
      return TransformationType.REDACT;
    case 4:
    case "CHARACTER_MASK":
      return TransformationType.CHARACTER_MASK;
    case 5:
    case "CRYPTO_REPLACE_FFX_FPE":
      return TransformationType.CRYPTO_REPLACE_FFX_FPE;
    case 6:
    case "FIXED_SIZE_BUCKETING":
      return TransformationType.FIXED_SIZE_BUCKETING;
    case 7:
    case "BUCKETING":
      return TransformationType.BUCKETING;
    case 8:
    case "REPLACE_WITH_INFO_TYPE":
      return TransformationType.REPLACE_WITH_INFO_TYPE;
    case 9:
    case "TIME_PART":
      return TransformationType.TIME_PART;
    case 10:
    case "CRYPTO_HASH":
      return TransformationType.CRYPTO_HASH;
    case 12:
    case "DATE_SHIFT":
      return TransformationType.DATE_SHIFT;
    case 13:
    case "CRYPTO_DETERMINISTIC_CONFIG":
      return TransformationType.CRYPTO_DETERMINISTIC_CONFIG;
    case 14:
    case "REDACT_IMAGE":
      return TransformationType.REDACT_IMAGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TransformationType.UNRECOGNIZED;
  }
}

export function transformationTypeToJSON(object: TransformationType): string {
  switch (object) {
    case TransformationType.TRANSFORMATION_TYPE_UNSPECIFIED:
      return "TRANSFORMATION_TYPE_UNSPECIFIED";
    case TransformationType.RECORD_SUPPRESSION:
      return "RECORD_SUPPRESSION";
    case TransformationType.REPLACE_VALUE:
      return "REPLACE_VALUE";
    case TransformationType.REPLACE_DICTIONARY:
      return "REPLACE_DICTIONARY";
    case TransformationType.REDACT:
      return "REDACT";
    case TransformationType.CHARACTER_MASK:
      return "CHARACTER_MASK";
    case TransformationType.CRYPTO_REPLACE_FFX_FPE:
      return "CRYPTO_REPLACE_FFX_FPE";
    case TransformationType.FIXED_SIZE_BUCKETING:
      return "FIXED_SIZE_BUCKETING";
    case TransformationType.BUCKETING:
      return "BUCKETING";
    case TransformationType.REPLACE_WITH_INFO_TYPE:
      return "REPLACE_WITH_INFO_TYPE";
    case TransformationType.TIME_PART:
      return "TIME_PART";
    case TransformationType.CRYPTO_HASH:
      return "CRYPTO_HASH";
    case TransformationType.DATE_SHIFT:
      return "DATE_SHIFT";
    case TransformationType.CRYPTO_DETERMINISTIC_CONFIG:
      return "CRYPTO_DETERMINISTIC_CONFIG";
    case TransformationType.REDACT_IMAGE:
      return "REDACT_IMAGE";
    case TransformationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Whether a profile being created is the first generation or an update. */
export enum ProfileGeneration {
  /** PROFILE_GENERATION_UNSPECIFIED - Unused. */
  PROFILE_GENERATION_UNSPECIFIED = 0,
  /** PROFILE_GENERATION_NEW - The profile is the first profile for the resource. */
  PROFILE_GENERATION_NEW = 1,
  /** PROFILE_GENERATION_UPDATE - The profile is an update to a previous profile. */
  PROFILE_GENERATION_UPDATE = 2,
  UNRECOGNIZED = -1,
}

export function profileGenerationFromJSON(object: any): ProfileGeneration {
  switch (object) {
    case 0:
    case "PROFILE_GENERATION_UNSPECIFIED":
      return ProfileGeneration.PROFILE_GENERATION_UNSPECIFIED;
    case 1:
    case "PROFILE_GENERATION_NEW":
      return ProfileGeneration.PROFILE_GENERATION_NEW;
    case 2:
    case "PROFILE_GENERATION_UPDATE":
      return ProfileGeneration.PROFILE_GENERATION_UPDATE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ProfileGeneration.UNRECOGNIZED;
  }
}

export function profileGenerationToJSON(object: ProfileGeneration): string {
  switch (object) {
    case ProfileGeneration.PROFILE_GENERATION_UNSPECIFIED:
      return "PROFILE_GENERATION_UNSPECIFIED";
    case ProfileGeneration.PROFILE_GENERATION_NEW:
      return "PROFILE_GENERATION_NEW";
    case ProfileGeneration.PROFILE_GENERATION_UPDATE:
      return "PROFILE_GENERATION_UPDATE";
    case ProfileGeneration.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Over time new types may be added. Currently VIEW, MATERIALIZED_VIEW,
 * and SNAPSHOT are not supported.
 */
export enum BigQueryTableTypeCollection {
  /** BIG_QUERY_COLLECTION_UNSPECIFIED - Unused. */
  BIG_QUERY_COLLECTION_UNSPECIFIED = 0,
  /**
   * BIG_QUERY_COLLECTION_ALL_TYPES - Automatically generate profiles for all tables, even if the table type is
   * not yet fully supported for analysis. Profiles for unsupported tables will
   * be generated with errors to indicate their partial support. When full
   * support is added, the tables will automatically be profiled during the next
   * scheduled run.
   */
  BIG_QUERY_COLLECTION_ALL_TYPES = 1,
  /**
   * BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES - Only those types fully supported will be profiled. Will expand
   * automatically as Cloud DLP adds support for new table types. Unsupported
   * table types will not have partial profiles generated.
   */
  BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES = 2,
  UNRECOGNIZED = -1,
}

export function bigQueryTableTypeCollectionFromJSON(object: any): BigQueryTableTypeCollection {
  switch (object) {
    case 0:
    case "BIG_QUERY_COLLECTION_UNSPECIFIED":
      return BigQueryTableTypeCollection.BIG_QUERY_COLLECTION_UNSPECIFIED;
    case 1:
    case "BIG_QUERY_COLLECTION_ALL_TYPES":
      return BigQueryTableTypeCollection.BIG_QUERY_COLLECTION_ALL_TYPES;
    case 2:
    case "BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES":
      return BigQueryTableTypeCollection.BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigQueryTableTypeCollection.UNRECOGNIZED;
  }
}

export function bigQueryTableTypeCollectionToJSON(object: BigQueryTableTypeCollection): string {
  switch (object) {
    case BigQueryTableTypeCollection.BIG_QUERY_COLLECTION_UNSPECIFIED:
      return "BIG_QUERY_COLLECTION_UNSPECIFIED";
    case BigQueryTableTypeCollection.BIG_QUERY_COLLECTION_ALL_TYPES:
      return "BIG_QUERY_COLLECTION_ALL_TYPES";
    case BigQueryTableTypeCollection.BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES:
      return "BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES";
    case BigQueryTableTypeCollection.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Over time new types may be added. Currently VIEW, MATERIALIZED_VIEW,
 * SNAPSHOT, and non-BigLake external tables are not supported.
 */
export enum BigQueryTableType {
  /** BIG_QUERY_TABLE_TYPE_UNSPECIFIED - Unused. */
  BIG_QUERY_TABLE_TYPE_UNSPECIFIED = 0,
  /** BIG_QUERY_TABLE_TYPE_TABLE - A normal BigQuery table. */
  BIG_QUERY_TABLE_TYPE_TABLE = 1,
  /** BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE - A table that references data stored in Cloud Storage. */
  BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE = 2,
  UNRECOGNIZED = -1,
}

export function bigQueryTableTypeFromJSON(object: any): BigQueryTableType {
  switch (object) {
    case 0:
    case "BIG_QUERY_TABLE_TYPE_UNSPECIFIED":
      return BigQueryTableType.BIG_QUERY_TABLE_TYPE_UNSPECIFIED;
    case 1:
    case "BIG_QUERY_TABLE_TYPE_TABLE":
      return BigQueryTableType.BIG_QUERY_TABLE_TYPE_TABLE;
    case 2:
    case "BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE":
      return BigQueryTableType.BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigQueryTableType.UNRECOGNIZED;
  }
}

export function bigQueryTableTypeToJSON(object: BigQueryTableType): string {
  switch (object) {
    case BigQueryTableType.BIG_QUERY_TABLE_TYPE_UNSPECIFIED:
      return "BIG_QUERY_TABLE_TYPE_UNSPECIFIED";
    case BigQueryTableType.BIG_QUERY_TABLE_TYPE_TABLE:
      return "BIG_QUERY_TABLE_TYPE_TABLE";
    case BigQueryTableType.BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE:
      return "BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE";
    case BigQueryTableType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * How frequently data profiles can be updated. New options can be added at a
 * later time.
 */
export enum DataProfileUpdateFrequency {
  /** UPDATE_FREQUENCY_UNSPECIFIED - Unspecified. */
  UPDATE_FREQUENCY_UNSPECIFIED = 0,
  /** UPDATE_FREQUENCY_NEVER - After the data profile is created, it will never be updated. */
  UPDATE_FREQUENCY_NEVER = 1,
  /** UPDATE_FREQUENCY_DAILY - The data profile can be updated up to once every 24 hours. */
  UPDATE_FREQUENCY_DAILY = 2,
  /** UPDATE_FREQUENCY_MONTHLY - The data profile can be updated up to once every 30 days. Default. */
  UPDATE_FREQUENCY_MONTHLY = 4,
  UNRECOGNIZED = -1,
}

export function dataProfileUpdateFrequencyFromJSON(object: any): DataProfileUpdateFrequency {
  switch (object) {
    case 0:
    case "UPDATE_FREQUENCY_UNSPECIFIED":
      return DataProfileUpdateFrequency.UPDATE_FREQUENCY_UNSPECIFIED;
    case 1:
    case "UPDATE_FREQUENCY_NEVER":
      return DataProfileUpdateFrequency.UPDATE_FREQUENCY_NEVER;
    case 2:
    case "UPDATE_FREQUENCY_DAILY":
      return DataProfileUpdateFrequency.UPDATE_FREQUENCY_DAILY;
    case 4:
    case "UPDATE_FREQUENCY_MONTHLY":
      return DataProfileUpdateFrequency.UPDATE_FREQUENCY_MONTHLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataProfileUpdateFrequency.UNRECOGNIZED;
  }
}

export function dataProfileUpdateFrequencyToJSON(object: DataProfileUpdateFrequency): string {
  switch (object) {
    case DataProfileUpdateFrequency.UPDATE_FREQUENCY_UNSPECIFIED:
      return "UPDATE_FREQUENCY_UNSPECIFIED";
    case DataProfileUpdateFrequency.UPDATE_FREQUENCY_NEVER:
      return "UPDATE_FREQUENCY_NEVER";
    case DataProfileUpdateFrequency.UPDATE_FREQUENCY_DAILY:
      return "UPDATE_FREQUENCY_DAILY";
    case DataProfileUpdateFrequency.UPDATE_FREQUENCY_MONTHLY:
      return "UPDATE_FREQUENCY_MONTHLY";
    case DataProfileUpdateFrequency.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Attributes evaluated to determine if a table has been modified. New values
 * may be added at a later time.
 */
export enum BigQueryTableModification {
  /** TABLE_MODIFICATION_UNSPECIFIED - Unused. */
  TABLE_MODIFICATION_UNSPECIFIED = 0,
  /**
   * TABLE_MODIFIED_TIMESTAMP - A table will be considered modified when the last_modified_time from
   * BigQuery has been updated.
   */
  TABLE_MODIFIED_TIMESTAMP = 1,
  UNRECOGNIZED = -1,
}

export function bigQueryTableModificationFromJSON(object: any): BigQueryTableModification {
  switch (object) {
    case 0:
    case "TABLE_MODIFICATION_UNSPECIFIED":
      return BigQueryTableModification.TABLE_MODIFICATION_UNSPECIFIED;
    case 1:
    case "TABLE_MODIFIED_TIMESTAMP":
      return BigQueryTableModification.TABLE_MODIFIED_TIMESTAMP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigQueryTableModification.UNRECOGNIZED;
  }
}

export function bigQueryTableModificationToJSON(object: BigQueryTableModification): string {
  switch (object) {
    case BigQueryTableModification.TABLE_MODIFICATION_UNSPECIFIED:
      return "TABLE_MODIFICATION_UNSPECIFIED";
    case BigQueryTableModification.TABLE_MODIFIED_TIMESTAMP:
      return "TABLE_MODIFIED_TIMESTAMP";
    case BigQueryTableModification.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Attributes evaluated to determine if a schema has been modified. New values
 * may be added at a later time.
 */
export enum BigQuerySchemaModification {
  /** SCHEMA_MODIFICATION_UNSPECIFIED - Unused */
  SCHEMA_MODIFICATION_UNSPECIFIED = 0,
  /**
   * SCHEMA_NEW_COLUMNS - Profiles should be regenerated when new columns are added to the table.
   * Default.
   */
  SCHEMA_NEW_COLUMNS = 1,
  /** SCHEMA_REMOVED_COLUMNS - Profiles should be regenerated when columns are removed from the table. */
  SCHEMA_REMOVED_COLUMNS = 2,
  UNRECOGNIZED = -1,
}

export function bigQuerySchemaModificationFromJSON(object: any): BigQuerySchemaModification {
  switch (object) {
    case 0:
    case "SCHEMA_MODIFICATION_UNSPECIFIED":
      return BigQuerySchemaModification.SCHEMA_MODIFICATION_UNSPECIFIED;
    case 1:
    case "SCHEMA_NEW_COLUMNS":
      return BigQuerySchemaModification.SCHEMA_NEW_COLUMNS;
    case 2:
    case "SCHEMA_REMOVED_COLUMNS":
      return BigQuerySchemaModification.SCHEMA_REMOVED_COLUMNS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigQuerySchemaModification.UNRECOGNIZED;
  }
}

export function bigQuerySchemaModificationToJSON(object: BigQuerySchemaModification): string {
  switch (object) {
    case BigQuerySchemaModification.SCHEMA_MODIFICATION_UNSPECIFIED:
      return "SCHEMA_MODIFICATION_UNSPECIFIED";
    case BigQuerySchemaModification.SCHEMA_NEW_COLUMNS:
      return "SCHEMA_NEW_COLUMNS";
    case BigQuerySchemaModification.SCHEMA_REMOVED_COLUMNS:
      return "SCHEMA_REMOVED_COLUMNS";
    case BigQuerySchemaModification.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Operators available for comparing the value of fields. */
export enum RelationalOperator {
  /** RELATIONAL_OPERATOR_UNSPECIFIED - Unused */
  RELATIONAL_OPERATOR_UNSPECIFIED = 0,
  /** EQUAL_TO - Equal. Attempts to match even with incompatible types. */
  EQUAL_TO = 1,
  /** NOT_EQUAL_TO - Not equal to. Attempts to match even with incompatible types. */
  NOT_EQUAL_TO = 2,
  /** GREATER_THAN - Greater than. */
  GREATER_THAN = 3,
  /** LESS_THAN - Less than. */
  LESS_THAN = 4,
  /** GREATER_THAN_OR_EQUALS - Greater than or equals. */
  GREATER_THAN_OR_EQUALS = 5,
  /** LESS_THAN_OR_EQUALS - Less than or equals. */
  LESS_THAN_OR_EQUALS = 6,
  /** EXISTS - Exists */
  EXISTS = 7,
  UNRECOGNIZED = -1,
}

export function relationalOperatorFromJSON(object: any): RelationalOperator {
  switch (object) {
    case 0:
    case "RELATIONAL_OPERATOR_UNSPECIFIED":
      return RelationalOperator.RELATIONAL_OPERATOR_UNSPECIFIED;
    case 1:
    case "EQUAL_TO":
      return RelationalOperator.EQUAL_TO;
    case 2:
    case "NOT_EQUAL_TO":
      return RelationalOperator.NOT_EQUAL_TO;
    case 3:
    case "GREATER_THAN":
      return RelationalOperator.GREATER_THAN;
    case 4:
    case "LESS_THAN":
      return RelationalOperator.LESS_THAN;
    case 5:
    case "GREATER_THAN_OR_EQUALS":
      return RelationalOperator.GREATER_THAN_OR_EQUALS;
    case 6:
    case "LESS_THAN_OR_EQUALS":
      return RelationalOperator.LESS_THAN_OR_EQUALS;
    case 7:
    case "EXISTS":
      return RelationalOperator.EXISTS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RelationalOperator.UNRECOGNIZED;
  }
}

export function relationalOperatorToJSON(object: RelationalOperator): string {
  switch (object) {
    case RelationalOperator.RELATIONAL_OPERATOR_UNSPECIFIED:
      return "RELATIONAL_OPERATOR_UNSPECIFIED";
    case RelationalOperator.EQUAL_TO:
      return "EQUAL_TO";
    case RelationalOperator.NOT_EQUAL_TO:
      return "NOT_EQUAL_TO";
    case RelationalOperator.GREATER_THAN:
      return "GREATER_THAN";
    case RelationalOperator.LESS_THAN:
      return "LESS_THAN";
    case RelationalOperator.GREATER_THAN_OR_EQUALS:
      return "GREATER_THAN_OR_EQUALS";
    case RelationalOperator.LESS_THAN_OR_EQUALS:
      return "LESS_THAN_OR_EQUALS";
    case RelationalOperator.EXISTS:
      return "EXISTS";
    case RelationalOperator.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Type of the match which can be applied to different ways of matching, like
 * Dictionary, regular expression and intersecting with findings of another
 * info type.
 */
export enum MatchingType {
  /** MATCHING_TYPE_UNSPECIFIED - Invalid. */
  MATCHING_TYPE_UNSPECIFIED = 0,
  /**
   * MATCHING_TYPE_FULL_MATCH - Full match.
   *
   * - Dictionary: join of Dictionary results matched complete finding quote
   * - Regex: all regex matches fill a finding quote start to end
   * - Exclude info type: completely inside affecting info types findings
   */
  MATCHING_TYPE_FULL_MATCH = 1,
  /**
   * MATCHING_TYPE_PARTIAL_MATCH - Partial match.
   *
   * - Dictionary: at least one of the tokens in the finding matches
   * - Regex: substring of the finding matches
   * - Exclude info type: intersects with affecting info types findings
   */
  MATCHING_TYPE_PARTIAL_MATCH = 2,
  /**
   * MATCHING_TYPE_INVERSE_MATCH - Inverse match.
   *
   * - Dictionary: no tokens in the finding match the dictionary
   * - Regex: finding doesn't match the regex
   * - Exclude info type: no intersection with affecting info types findings
   */
  MATCHING_TYPE_INVERSE_MATCH = 3,
  UNRECOGNIZED = -1,
}

export function matchingTypeFromJSON(object: any): MatchingType {
  switch (object) {
    case 0:
    case "MATCHING_TYPE_UNSPECIFIED":
      return MatchingType.MATCHING_TYPE_UNSPECIFIED;
    case 1:
    case "MATCHING_TYPE_FULL_MATCH":
      return MatchingType.MATCHING_TYPE_FULL_MATCH;
    case 2:
    case "MATCHING_TYPE_PARTIAL_MATCH":
      return MatchingType.MATCHING_TYPE_PARTIAL_MATCH;
    case 3:
    case "MATCHING_TYPE_INVERSE_MATCH":
      return MatchingType.MATCHING_TYPE_INVERSE_MATCH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MatchingType.UNRECOGNIZED;
  }
}

export function matchingTypeToJSON(object: MatchingType): string {
  switch (object) {
    case MatchingType.MATCHING_TYPE_UNSPECIFIED:
      return "MATCHING_TYPE_UNSPECIFIED";
    case MatchingType.MATCHING_TYPE_FULL_MATCH:
      return "MATCHING_TYPE_FULL_MATCH";
    case MatchingType.MATCHING_TYPE_PARTIAL_MATCH:
      return "MATCHING_TYPE_PARTIAL_MATCH";
    case MatchingType.MATCHING_TYPE_INVERSE_MATCH:
      return "MATCHING_TYPE_INVERSE_MATCH";
    case MatchingType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Deprecated and unused. */
export enum ContentOption {
  /** CONTENT_UNSPECIFIED - Includes entire content of a file or a data stream. */
  CONTENT_UNSPECIFIED = 0,
  /** CONTENT_TEXT - Text content within the data, excluding any metadata. */
  CONTENT_TEXT = 1,
  /** CONTENT_IMAGE - Images found in the data. */
  CONTENT_IMAGE = 2,
  UNRECOGNIZED = -1,
}

export function contentOptionFromJSON(object: any): ContentOption {
  switch (object) {
    case 0:
    case "CONTENT_UNSPECIFIED":
      return ContentOption.CONTENT_UNSPECIFIED;
    case 1:
    case "CONTENT_TEXT":
      return ContentOption.CONTENT_TEXT;
    case 2:
    case "CONTENT_IMAGE":
      return ContentOption.CONTENT_IMAGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ContentOption.UNRECOGNIZED;
  }
}

export function contentOptionToJSON(object: ContentOption): string {
  switch (object) {
    case ContentOption.CONTENT_UNSPECIFIED:
      return "CONTENT_UNSPECIFIED";
    case ContentOption.CONTENT_TEXT:
      return "CONTENT_TEXT";
    case ContentOption.CONTENT_IMAGE:
      return "CONTENT_IMAGE";
    case ContentOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Type of metadata containing the finding. */
export enum MetadataType {
  /** METADATATYPE_UNSPECIFIED - Unused */
  METADATATYPE_UNSPECIFIED = 0,
  /** STORAGE_METADATA - General file metadata provided by Cloud Storage. */
  STORAGE_METADATA = 2,
  UNRECOGNIZED = -1,
}

export function metadataTypeFromJSON(object: any): MetadataType {
  switch (object) {
    case 0:
    case "METADATATYPE_UNSPECIFIED":
      return MetadataType.METADATATYPE_UNSPECIFIED;
    case 2:
    case "STORAGE_METADATA":
      return MetadataType.STORAGE_METADATA;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataType.UNRECOGNIZED;
  }
}

export function metadataTypeToJSON(object: MetadataType): string {
  switch (object) {
    case MetadataType.METADATATYPE_UNSPECIFIED:
      return "METADATATYPE_UNSPECIFIED";
    case MetadataType.STORAGE_METADATA:
      return "STORAGE_METADATA";
    case MetadataType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Parts of the APIs which use certain infoTypes. */
export enum InfoTypeSupportedBy {
  /** ENUM_TYPE_UNSPECIFIED - Unused. */
  ENUM_TYPE_UNSPECIFIED = 0,
  /** INSPECT - Supported by the inspect operations. */
  INSPECT = 1,
  /** RISK_ANALYSIS - Supported by the risk analysis operations. */
  RISK_ANALYSIS = 2,
  UNRECOGNIZED = -1,
}

export function infoTypeSupportedByFromJSON(object: any): InfoTypeSupportedBy {
  switch (object) {
    case 0:
    case "ENUM_TYPE_UNSPECIFIED":
      return InfoTypeSupportedBy.ENUM_TYPE_UNSPECIFIED;
    case 1:
    case "INSPECT":
      return InfoTypeSupportedBy.INSPECT;
    case 2:
    case "RISK_ANALYSIS":
      return InfoTypeSupportedBy.RISK_ANALYSIS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return InfoTypeSupportedBy.UNRECOGNIZED;
  }
}

export function infoTypeSupportedByToJSON(object: InfoTypeSupportedBy): string {
  switch (object) {
    case InfoTypeSupportedBy.ENUM_TYPE_UNSPECIFIED:
      return "ENUM_TYPE_UNSPECIFIED";
    case InfoTypeSupportedBy.INSPECT:
      return "INSPECT";
    case InfoTypeSupportedBy.RISK_ANALYSIS:
      return "RISK_ANALYSIS";
    case InfoTypeSupportedBy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** An enum to represent the various types of DLP jobs. */
export enum DlpJobType {
  /** DLP_JOB_TYPE_UNSPECIFIED - Defaults to INSPECT_JOB. */
  DLP_JOB_TYPE_UNSPECIFIED = 0,
  /** INSPECT_JOB - The job inspected Google Cloud for sensitive data. */
  INSPECT_JOB = 1,
  /** RISK_ANALYSIS_JOB - The job executed a Risk Analysis computation. */
  RISK_ANALYSIS_JOB = 2,
  UNRECOGNIZED = -1,
}

export function dlpJobTypeFromJSON(object: any): DlpJobType {
  switch (object) {
    case 0:
    case "DLP_JOB_TYPE_UNSPECIFIED":
      return DlpJobType.DLP_JOB_TYPE_UNSPECIFIED;
    case 1:
    case "INSPECT_JOB":
      return DlpJobType.INSPECT_JOB;
    case 2:
    case "RISK_ANALYSIS_JOB":
      return DlpJobType.RISK_ANALYSIS_JOB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DlpJobType.UNRECOGNIZED;
  }
}

export function dlpJobTypeToJSON(object: DlpJobType): string {
  switch (object) {
    case DlpJobType.DLP_JOB_TYPE_UNSPECIFIED:
      return "DLP_JOB_TYPE_UNSPECIFIED";
    case DlpJobType.INSPECT_JOB:
      return "INSPECT_JOB";
    case DlpJobType.RISK_ANALYSIS_JOB:
      return "RISK_ANALYSIS_JOB";
    case DlpJobType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** State of a StoredInfoType version. */
export enum StoredInfoTypeState {
  /** STORED_INFO_TYPE_STATE_UNSPECIFIED - Unused */
  STORED_INFO_TYPE_STATE_UNSPECIFIED = 0,
  /** PENDING - StoredInfoType version is being created. */
  PENDING = 1,
  /** READY - StoredInfoType version is ready for use. */
  READY = 2,
  /**
   * FAILED - StoredInfoType creation failed. All relevant error messages are returned in
   * the `StoredInfoTypeVersion` message.
   */
  FAILED = 3,
  /**
   * INVALID - StoredInfoType is no longer valid because artifacts stored in
   * user-controlled storage were modified. To fix an invalid StoredInfoType,
   * use the `UpdateStoredInfoType` method to create a new version.
   */
  INVALID = 4,
  UNRECOGNIZED = -1,
}

export function storedInfoTypeStateFromJSON(object: any): StoredInfoTypeState {
  switch (object) {
    case 0:
    case "STORED_INFO_TYPE_STATE_UNSPECIFIED":
      return StoredInfoTypeState.STORED_INFO_TYPE_STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return StoredInfoTypeState.PENDING;
    case 2:
    case "READY":
      return StoredInfoTypeState.READY;
    case 3:
    case "FAILED":
      return StoredInfoTypeState.FAILED;
    case 4:
    case "INVALID":
      return StoredInfoTypeState.INVALID;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StoredInfoTypeState.UNRECOGNIZED;
  }
}

export function storedInfoTypeStateToJSON(object: StoredInfoTypeState): string {
  switch (object) {
    case StoredInfoTypeState.STORED_INFO_TYPE_STATE_UNSPECIFIED:
      return "STORED_INFO_TYPE_STATE_UNSPECIFIED";
    case StoredInfoTypeState.PENDING:
      return "PENDING";
    case StoredInfoTypeState.READY:
      return "READY";
    case StoredInfoTypeState.FAILED:
      return "FAILED";
    case StoredInfoTypeState.INVALID:
      return "INVALID";
    case StoredInfoTypeState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * How broadly the data in the resource has been shared. New items may be added
 * over time. A higher number means more restricted.
 */
export enum ResourceVisibility {
  /** RESOURCE_VISIBILITY_UNSPECIFIED - Unused. */
  RESOURCE_VISIBILITY_UNSPECIFIED = 0,
  /** RESOURCE_VISIBILITY_PUBLIC - Visible to any user. */
  RESOURCE_VISIBILITY_PUBLIC = 10,
  /**
   * RESOURCE_VISIBILITY_INCONCLUSIVE - May contain public items.
   * For example, if a Cloud Storage bucket has uniform bucket level access
   * disabled, some objects inside it may be public, but none are known yet.
   */
  RESOURCE_VISIBILITY_INCONCLUSIVE = 15,
  /** RESOURCE_VISIBILITY_RESTRICTED - Visible only to specific users. */
  RESOURCE_VISIBILITY_RESTRICTED = 20,
  UNRECOGNIZED = -1,
}

export function resourceVisibilityFromJSON(object: any): ResourceVisibility {
  switch (object) {
    case 0:
    case "RESOURCE_VISIBILITY_UNSPECIFIED":
      return ResourceVisibility.RESOURCE_VISIBILITY_UNSPECIFIED;
    case 10:
    case "RESOURCE_VISIBILITY_PUBLIC":
      return ResourceVisibility.RESOURCE_VISIBILITY_PUBLIC;
    case 15:
    case "RESOURCE_VISIBILITY_INCONCLUSIVE":
      return ResourceVisibility.RESOURCE_VISIBILITY_INCONCLUSIVE;
    case 20:
    case "RESOURCE_VISIBILITY_RESTRICTED":
      return ResourceVisibility.RESOURCE_VISIBILITY_RESTRICTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ResourceVisibility.UNRECOGNIZED;
  }
}

export function resourceVisibilityToJSON(object: ResourceVisibility): string {
  switch (object) {
    case ResourceVisibility.RESOURCE_VISIBILITY_UNSPECIFIED:
      return "RESOURCE_VISIBILITY_UNSPECIFIED";
    case ResourceVisibility.RESOURCE_VISIBILITY_PUBLIC:
      return "RESOURCE_VISIBILITY_PUBLIC";
    case ResourceVisibility.RESOURCE_VISIBILITY_INCONCLUSIVE:
      return "RESOURCE_VISIBILITY_INCONCLUSIVE";
    case ResourceVisibility.RESOURCE_VISIBILITY_RESTRICTED:
      return "RESOURCE_VISIBILITY_RESTRICTED";
    case ResourceVisibility.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** How a resource is encrypted. */
export enum EncryptionStatus {
  /** ENCRYPTION_STATUS_UNSPECIFIED - Unused. */
  ENCRYPTION_STATUS_UNSPECIFIED = 0,
  /** ENCRYPTION_GOOGLE_MANAGED - Google manages server-side encryption keys on your behalf. */
  ENCRYPTION_GOOGLE_MANAGED = 1,
  /** ENCRYPTION_CUSTOMER_MANAGED - Customer provides the key. */
  ENCRYPTION_CUSTOMER_MANAGED = 2,
  UNRECOGNIZED = -1,
}

export function encryptionStatusFromJSON(object: any): EncryptionStatus {
  switch (object) {
    case 0:
    case "ENCRYPTION_STATUS_UNSPECIFIED":
      return EncryptionStatus.ENCRYPTION_STATUS_UNSPECIFIED;
    case 1:
    case "ENCRYPTION_GOOGLE_MANAGED":
      return EncryptionStatus.ENCRYPTION_GOOGLE_MANAGED;
    case 2:
    case "ENCRYPTION_CUSTOMER_MANAGED":
      return EncryptionStatus.ENCRYPTION_CUSTOMER_MANAGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EncryptionStatus.UNRECOGNIZED;
  }
}

export function encryptionStatusToJSON(object: EncryptionStatus): string {
  switch (object) {
    case EncryptionStatus.ENCRYPTION_STATUS_UNSPECIFIED:
      return "ENCRYPTION_STATUS_UNSPECIFIED";
    case EncryptionStatus.ENCRYPTION_GOOGLE_MANAGED:
      return "ENCRYPTION_GOOGLE_MANAGED";
    case EncryptionStatus.ENCRYPTION_CUSTOMER_MANAGED:
      return "ENCRYPTION_CUSTOMER_MANAGED";
    case EncryptionStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Bucketized nullness percentage levels. A higher level means a higher
 * percentage of the column is null.
 */
export enum NullPercentageLevel {
  /** NULL_PERCENTAGE_LEVEL_UNSPECIFIED - Unused. */
  NULL_PERCENTAGE_LEVEL_UNSPECIFIED = 0,
  /** NULL_PERCENTAGE_VERY_LOW - Very few null entries. */
  NULL_PERCENTAGE_VERY_LOW = 1,
  /** NULL_PERCENTAGE_LOW - Some null entries. */
  NULL_PERCENTAGE_LOW = 2,
  /** NULL_PERCENTAGE_MEDIUM - A few null entries. */
  NULL_PERCENTAGE_MEDIUM = 3,
  /** NULL_PERCENTAGE_HIGH - A lot of null entries. */
  NULL_PERCENTAGE_HIGH = 4,
  UNRECOGNIZED = -1,
}

export function nullPercentageLevelFromJSON(object: any): NullPercentageLevel {
  switch (object) {
    case 0:
    case "NULL_PERCENTAGE_LEVEL_UNSPECIFIED":
      return NullPercentageLevel.NULL_PERCENTAGE_LEVEL_UNSPECIFIED;
    case 1:
    case "NULL_PERCENTAGE_VERY_LOW":
      return NullPercentageLevel.NULL_PERCENTAGE_VERY_LOW;
    case 2:
    case "NULL_PERCENTAGE_LOW":
      return NullPercentageLevel.NULL_PERCENTAGE_LOW;
    case 3:
    case "NULL_PERCENTAGE_MEDIUM":
      return NullPercentageLevel.NULL_PERCENTAGE_MEDIUM;
    case 4:
    case "NULL_PERCENTAGE_HIGH":
      return NullPercentageLevel.NULL_PERCENTAGE_HIGH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return NullPercentageLevel.UNRECOGNIZED;
  }
}

export function nullPercentageLevelToJSON(object: NullPercentageLevel): string {
  switch (object) {
    case NullPercentageLevel.NULL_PERCENTAGE_LEVEL_UNSPECIFIED:
      return "NULL_PERCENTAGE_LEVEL_UNSPECIFIED";
    case NullPercentageLevel.NULL_PERCENTAGE_VERY_LOW:
      return "NULL_PERCENTAGE_VERY_LOW";
    case NullPercentageLevel.NULL_PERCENTAGE_LOW:
      return "NULL_PERCENTAGE_LOW";
    case NullPercentageLevel.NULL_PERCENTAGE_MEDIUM:
      return "NULL_PERCENTAGE_MEDIUM";
    case NullPercentageLevel.NULL_PERCENTAGE_HIGH:
      return "NULL_PERCENTAGE_HIGH";
    case NullPercentageLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Bucketized uniqueness score levels. A higher uniqueness score is a strong
 * signal that the column may contain a unique identifier like user id. A low
 * value indicates that the column contains few unique values like booleans or
 * other classifiers.
 */
export enum UniquenessScoreLevel {
  /**
   * UNIQUENESS_SCORE_LEVEL_UNSPECIFIED - Some columns do not have estimated uniqueness. Possible reasons include
   * having too few values.
   */
  UNIQUENESS_SCORE_LEVEL_UNSPECIFIED = 0,
  /** UNIQUENESS_SCORE_LOW - Low uniqueness, possibly a boolean, enum or similiarly typed column. */
  UNIQUENESS_SCORE_LOW = 1,
  /** UNIQUENESS_SCORE_MEDIUM - Medium uniqueness. */
  UNIQUENESS_SCORE_MEDIUM = 2,
  /** UNIQUENESS_SCORE_HIGH - High uniqueness, possibly a column of free text or unique identifiers. */
  UNIQUENESS_SCORE_HIGH = 3,
  UNRECOGNIZED = -1,
}

export function uniquenessScoreLevelFromJSON(object: any): UniquenessScoreLevel {
  switch (object) {
    case 0:
    case "UNIQUENESS_SCORE_LEVEL_UNSPECIFIED":
      return UniquenessScoreLevel.UNIQUENESS_SCORE_LEVEL_UNSPECIFIED;
    case 1:
    case "UNIQUENESS_SCORE_LOW":
      return UniquenessScoreLevel.UNIQUENESS_SCORE_LOW;
    case 2:
    case "UNIQUENESS_SCORE_MEDIUM":
      return UniquenessScoreLevel.UNIQUENESS_SCORE_MEDIUM;
    case 3:
    case "UNIQUENESS_SCORE_HIGH":
      return UniquenessScoreLevel.UNIQUENESS_SCORE_HIGH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return UniquenessScoreLevel.UNRECOGNIZED;
  }
}

export function uniquenessScoreLevelToJSON(object: UniquenessScoreLevel): string {
  switch (object) {
    case UniquenessScoreLevel.UNIQUENESS_SCORE_LEVEL_UNSPECIFIED:
      return "UNIQUENESS_SCORE_LEVEL_UNSPECIFIED";
    case UniquenessScoreLevel.UNIQUENESS_SCORE_LOW:
      return "UNIQUENESS_SCORE_LOW";
    case UniquenessScoreLevel.UNIQUENESS_SCORE_MEDIUM:
      return "UNIQUENESS_SCORE_MEDIUM";
    case UniquenessScoreLevel.UNIQUENESS_SCORE_HIGH:
      return "UNIQUENESS_SCORE_HIGH";
    case UniquenessScoreLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * State of the connection.
 * New values may be added over time.
 */
export enum ConnectionState {
  /** CONNECTION_STATE_UNSPECIFIED - Unused */
  CONNECTION_STATE_UNSPECIFIED = 0,
  /**
   * MISSING_CREDENTIALS - DLP automatically created this connection during an initial scan, and it is
   * awaiting full configuration by a user.
   */
  MISSING_CREDENTIALS = 1,
  /** AVAILABLE - A configured connection that has not encountered any errors. */
  AVAILABLE = 2,
  /**
   * ERROR - A configured connection that encountered errors during its last use. It
   * will not be used again until it is set to AVAILABLE.
   *
   * If the resolution requires external action, then the client must send a
   * request to set the status to AVAILABLE when the connection is ready for
   * use. If the resolution doesn't require external action, then any changes to
   * the connection properties will automatically mark it as AVAILABLE.
   */
  ERROR = 3,
  UNRECOGNIZED = -1,
}

export function connectionStateFromJSON(object: any): ConnectionState {
  switch (object) {
    case 0:
    case "CONNECTION_STATE_UNSPECIFIED":
      return ConnectionState.CONNECTION_STATE_UNSPECIFIED;
    case 1:
    case "MISSING_CREDENTIALS":
      return ConnectionState.MISSING_CREDENTIALS;
    case 2:
    case "AVAILABLE":
      return ConnectionState.AVAILABLE;
    case 3:
    case "ERROR":
      return ConnectionState.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ConnectionState.UNRECOGNIZED;
  }
}

export function connectionStateToJSON(object: ConnectionState): string {
  switch (object) {
    case ConnectionState.CONNECTION_STATE_UNSPECIFIED:
      return "CONNECTION_STATE_UNSPECIFIED";
    case ConnectionState.MISSING_CREDENTIALS:
      return "MISSING_CREDENTIALS";
    case ConnectionState.AVAILABLE:
      return "AVAILABLE";
    case ConnectionState.ERROR:
      return "ERROR";
    case ConnectionState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** List of excluded infoTypes. */
export interface ExcludeInfoTypes {
  /**
   * InfoType list in ExclusionRule rule drops a finding when it overlaps or
   * contained within with a finding of an infoType from this list. For
   * example, for `InspectionRuleSet.info_types` containing "PHONE_NUMBER"` and
   * `exclusion_rule` containing `exclude_info_types.info_types` with
   * "EMAIL_ADDRESS" the phone number findings are dropped if they overlap
   * with EMAIL_ADDRESS finding.
   * That leads to "555-222-2222@example.org" to generate only a single
   * finding, namely email address.
   */
  infoTypes: InfoType[];
}

/**
 * The rule to exclude findings based on a hotword. For record inspection of
 * tables, column names are considered hotwords. An example of this is to
 * exclude a finding if it belongs to a BigQuery column that matches a specific
 * pattern.
 */
export interface ExcludeByHotword {
  /** Regular expression pattern defining what qualifies as a hotword. */
  hotwordRegex:
    | CustomInfoType_Regex
    | undefined;
  /**
   * Range of characters within which the entire hotword must reside.
   * The total length of the window cannot exceed 1000 characters.
   * The windowBefore property in proximity should be set to 1 if the hotword
   * needs to be included in a column header.
   */
  proximity: CustomInfoType_DetectionRule_Proximity | undefined;
}

/**
 * The rule that specifies conditions when findings of infoTypes specified in
 * `InspectionRuleSet` are removed from results.
 */
export interface ExclusionRule {
  /** Dictionary which defines the rule. */
  dictionary?:
    | CustomInfoType_Dictionary
    | undefined;
  /** Regular expression which defines the rule. */
  regex?:
    | CustomInfoType_Regex
    | undefined;
  /** Set of infoTypes for which findings would affect this rule. */
  excludeInfoTypes?:
    | ExcludeInfoTypes
    | undefined;
  /**
   * Drop if the hotword rule is contained in the proximate context. For
   * tabular data, the context includes the column name.
   */
  excludeByHotword?:
    | ExcludeByHotword
    | undefined;
  /** How the rule is applied, see MatchingType documentation for details. */
  matchingType: MatchingType;
}

/**
 * A single inspection rule to be applied to infoTypes, specified in
 * `InspectionRuleSet`.
 */
export interface InspectionRule {
  /** Hotword-based detection rule. */
  hotwordRule?:
    | CustomInfoType_DetectionRule_HotwordRule
    | undefined;
  /** Exclusion rule. */
  exclusionRule?: ExclusionRule | undefined;
}

/**
 * Rule set for modifying a set of infoTypes to alter behavior under certain
 * circumstances, depending on the specific details of the rules within the set.
 */
export interface InspectionRuleSet {
  /** List of infoTypes this rule set is applied to. */
  infoTypes: InfoType[];
  /** Set of rules to be applied to infoTypes. The rules are applied in order. */
  rules: InspectionRule[];
}

/**
 * Configuration description of the scanning process.
 * When used with redactContent only info_types and min_likelihood are currently
 * used.
 */
export interface InspectConfig {
  /**
   * Restricts what info_types to look for. The values must correspond to
   * InfoType values returned by ListInfoTypes or listed at
   * https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference.
   *
   * When no InfoTypes or CustomInfoTypes are specified in a request, the
   * system may automatically choose a default list of detectors to run, which
   * may change over time.
   *
   * If you need precise control and predictability as to what detectors are
   * run you should specify specific InfoTypes listed in the reference,
   * otherwise a default list will be used, which may change over time.
   */
  infoTypes: InfoType[];
  /**
   * Only returns findings equal to or above this threshold. The default is
   * POSSIBLE.
   *
   * In general, the highest likelihood setting yields the fewest findings in
   * results and the lowest chance of a false positive. For more information,
   * see [Match
   * likelihood](https://cloud.google.com/sensitive-data-protection/docs/likelihood).
   */
  minLikelihood: Likelihood;
  /**
   * Minimum likelihood per infotype. For each infotype, a user can specify a
   * minimum likelihood. The system only returns a finding if its likelihood is
   * above this threshold. If this field is not set, the system uses the
   * InspectConfig min_likelihood.
   */
  minLikelihoodPerInfoType: InspectConfig_InfoTypeLikelihood[];
  /**
   * Configuration to control the number of findings returned.
   * This is not used for data profiling.
   *
   * When redacting sensitive data from images, finding limits don't apply. They
   * can cause unexpected or inconsistent results, where only some data is
   * redacted. Don't include finding limits in
   * [RedactImage][google.privacy.dlp.v2.DlpService.RedactImage]
   * requests. Otherwise, Cloud DLP returns an error.
   *
   * When set within an
   * [InspectJobConfig][google.privacy.dlp.v2.InspectJobConfig], the specified
   * maximum values aren't hard limits. If an inspection job reaches these
   * limits, the job ends gradually, not abruptly. Therefore, the actual number
   * of findings that Cloud DLP returns can be multiple times higher than these
   * maximum values.
   */
  limits:
    | InspectConfig_FindingLimits
    | undefined;
  /**
   * When true, a contextual quote from the data that triggered a finding is
   * included in the response; see
   * [Finding.quote][google.privacy.dlp.v2.Finding.quote]. This is not used for
   * data profiling.
   */
  includeQuote: boolean;
  /**
   * When true, excludes type information of the findings.
   * This is not used for data profiling.
   */
  excludeInfoTypes: boolean;
  /**
   * CustomInfoTypes provided by the user. See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-custom-infotypes
   * to learn more.
   */
  customInfoTypes: CustomInfoType[];
  /** Deprecated and unused. */
  contentOptions: ContentOption[];
  /**
   * Set of rules to apply to the findings for this InspectConfig.
   * Exclusion rules, contained in the set are executed in the end, other
   * rules are executed in the order they are specified for each info type.
   */
  ruleSet: InspectionRuleSet[];
}

/**
 * Configuration for setting a minimum likelihood per infotype. Used to
 * customize the minimum likelihood level for specific infotypes in the
 * request. For example, use this if you want to lower the precision for
 * PERSON_NAME without lowering the precision for the other infotypes in the
 * request.
 */
export interface InspectConfig_InfoTypeLikelihood {
  /**
   * Type of information the likelihood threshold applies to. Only one
   * likelihood per info_type should be provided. If InfoTypeLikelihood does
   * not have an info_type, the configuration fails.
   */
  infoType:
    | InfoType
    | undefined;
  /**
   * Only returns findings equal to or above this threshold. This field is
   * required or else the configuration fails.
   */
  minLikelihood: Likelihood;
}

/**
 * Configuration to control the number of findings returned for inspection.
 * This is not used for de-identification or data profiling.
 *
 * When redacting sensitive data from images, finding limits don't apply. They
 * can cause unexpected or inconsistent results, where only some data is
 * redacted. Don't include finding limits in
 * [RedactImage][google.privacy.dlp.v2.DlpService.RedactImage]
 * requests. Otherwise, Cloud DLP returns an error.
 */
export interface InspectConfig_FindingLimits {
  /**
   * Max number of findings that are returned for each item scanned.
   *
   * When set within an
   * [InspectContentRequest][google.privacy.dlp.v2.InspectContentRequest],
   * this field is ignored.
   *
   * This value isn't a hard limit. If the number of findings for an item
   * reaches this limit, the inspection of that item ends gradually, not
   * abruptly. Therefore, the actual number of findings that Cloud DLP returns
   * for the item can be multiple times higher than this value.
   */
  maxFindingsPerItem: number;
  /**
   * Max number of findings that are returned per request or job.
   *
   * If you set this field in an
   * [InspectContentRequest][google.privacy.dlp.v2.InspectContentRequest], the
   * resulting maximum value is the value that you set or 3,000, whichever is
   * lower.
   *
   * This value isn't a hard limit. If an inspection reaches this limit, the
   * inspection ends gradually, not abruptly. Therefore, the actual number of
   * findings that Cloud DLP returns can be multiple times higher than this
   * value.
   */
  maxFindingsPerRequest: number;
  /** Configuration of findings limit given for specified infoTypes. */
  maxFindingsPerInfoType: InspectConfig_FindingLimits_InfoTypeLimit[];
}

/**
 * Max findings configuration per infoType, per content item or long
 * running DlpJob.
 */
export interface InspectConfig_FindingLimits_InfoTypeLimit {
  /**
   * Type of information the findings limit applies to. Only one limit per
   * info_type should be provided. If InfoTypeLimit does not have an
   * info_type, the DLP API applies the limit against all info_types that
   * are found but not specified in another InfoTypeLimit.
   */
  infoType:
    | InfoType
    | undefined;
  /** Max findings limit for the given infoType. */
  maxFindings: number;
}

/** Container for bytes to inspect or redact. */
export interface ByteContentItem {
  /** The type of data stored in the bytes string. Default will be TEXT_UTF8. */
  type: ByteContentItem_BytesType;
  /** Content data to inspect or redact. */
  data: Buffer;
}

/**
 * The type of data being sent for inspection. To learn more, see
 * [Supported file
 * types](https://cloud.google.com/sensitive-data-protection/docs/supported-file-types).
 */
export enum ByteContentItem_BytesType {
  /** BYTES_TYPE_UNSPECIFIED - Unused */
  BYTES_TYPE_UNSPECIFIED = 0,
  /** IMAGE - Any image type. */
  IMAGE = 6,
  /** IMAGE_JPEG - jpeg */
  IMAGE_JPEG = 1,
  /** IMAGE_BMP - bmp */
  IMAGE_BMP = 2,
  /** IMAGE_PNG - png */
  IMAGE_PNG = 3,
  /** IMAGE_SVG - svg */
  IMAGE_SVG = 4,
  /** TEXT_UTF8 - plain text */
  TEXT_UTF8 = 5,
  /** WORD_DOCUMENT - docx, docm, dotx, dotm */
  WORD_DOCUMENT = 7,
  /** PDF - pdf */
  PDF = 8,
  /** POWERPOINT_DOCUMENT - pptx, pptm, potx, potm, pot */
  POWERPOINT_DOCUMENT = 9,
  /** EXCEL_DOCUMENT - xlsx, xlsm, xltx, xltm */
  EXCEL_DOCUMENT = 10,
  /** AVRO - avro */
  AVRO = 11,
  /** CSV - csv */
  CSV = 12,
  /** TSV - tsv */
  TSV = 13,
  /** AUDIO - Audio file types. Only used for profiling. */
  AUDIO = 15,
  /** VIDEO - Video file types. Only used for profiling. */
  VIDEO = 16,
  /** EXECUTABLE - Executable file types. Only used for profiling. */
  EXECUTABLE = 17,
  UNRECOGNIZED = -1,
}

export function byteContentItem_BytesTypeFromJSON(object: any): ByteContentItem_BytesType {
  switch (object) {
    case 0:
    case "BYTES_TYPE_UNSPECIFIED":
      return ByteContentItem_BytesType.BYTES_TYPE_UNSPECIFIED;
    case 6:
    case "IMAGE":
      return ByteContentItem_BytesType.IMAGE;
    case 1:
    case "IMAGE_JPEG":
      return ByteContentItem_BytesType.IMAGE_JPEG;
    case 2:
    case "IMAGE_BMP":
      return ByteContentItem_BytesType.IMAGE_BMP;
    case 3:
    case "IMAGE_PNG":
      return ByteContentItem_BytesType.IMAGE_PNG;
    case 4:
    case "IMAGE_SVG":
      return ByteContentItem_BytesType.IMAGE_SVG;
    case 5:
    case "TEXT_UTF8":
      return ByteContentItem_BytesType.TEXT_UTF8;
    case 7:
    case "WORD_DOCUMENT":
      return ByteContentItem_BytesType.WORD_DOCUMENT;
    case 8:
    case "PDF":
      return ByteContentItem_BytesType.PDF;
    case 9:
    case "POWERPOINT_DOCUMENT":
      return ByteContentItem_BytesType.POWERPOINT_DOCUMENT;
    case 10:
    case "EXCEL_DOCUMENT":
      return ByteContentItem_BytesType.EXCEL_DOCUMENT;
    case 11:
    case "AVRO":
      return ByteContentItem_BytesType.AVRO;
    case 12:
    case "CSV":
      return ByteContentItem_BytesType.CSV;
    case 13:
    case "TSV":
      return ByteContentItem_BytesType.TSV;
    case 15:
    case "AUDIO":
      return ByteContentItem_BytesType.AUDIO;
    case 16:
    case "VIDEO":
      return ByteContentItem_BytesType.VIDEO;
    case 17:
    case "EXECUTABLE":
      return ByteContentItem_BytesType.EXECUTABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ByteContentItem_BytesType.UNRECOGNIZED;
  }
}

export function byteContentItem_BytesTypeToJSON(object: ByteContentItem_BytesType): string {
  switch (object) {
    case ByteContentItem_BytesType.BYTES_TYPE_UNSPECIFIED:
      return "BYTES_TYPE_UNSPECIFIED";
    case ByteContentItem_BytesType.IMAGE:
      return "IMAGE";
    case ByteContentItem_BytesType.IMAGE_JPEG:
      return "IMAGE_JPEG";
    case ByteContentItem_BytesType.IMAGE_BMP:
      return "IMAGE_BMP";
    case ByteContentItem_BytesType.IMAGE_PNG:
      return "IMAGE_PNG";
    case ByteContentItem_BytesType.IMAGE_SVG:
      return "IMAGE_SVG";
    case ByteContentItem_BytesType.TEXT_UTF8:
      return "TEXT_UTF8";
    case ByteContentItem_BytesType.WORD_DOCUMENT:
      return "WORD_DOCUMENT";
    case ByteContentItem_BytesType.PDF:
      return "PDF";
    case ByteContentItem_BytesType.POWERPOINT_DOCUMENT:
      return "POWERPOINT_DOCUMENT";
    case ByteContentItem_BytesType.EXCEL_DOCUMENT:
      return "EXCEL_DOCUMENT";
    case ByteContentItem_BytesType.AVRO:
      return "AVRO";
    case ByteContentItem_BytesType.CSV:
      return "CSV";
    case ByteContentItem_BytesType.TSV:
      return "TSV";
    case ByteContentItem_BytesType.AUDIO:
      return "AUDIO";
    case ByteContentItem_BytesType.VIDEO:
      return "VIDEO";
    case ByteContentItem_BytesType.EXECUTABLE:
      return "EXECUTABLE";
    case ByteContentItem_BytesType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Type of content to inspect. */
export interface ContentItem {
  /** String data to inspect or redact. */
  value?:
    | string
    | undefined;
  /**
   * Structured content for inspection. See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-text#inspecting_a_table
   * to learn more.
   */
  table?:
    | Table
    | undefined;
  /** Content data to inspect or redact. Replaces `type` and `data`. */
  byteItem?: ByteContentItem | undefined;
}

/**
 * Structured content to inspect. Up to 50,000 `Value`s per request allowed. See
 * https://cloud.google.com/sensitive-data-protection/docs/inspecting-structured-text#inspecting_a_table
 * to learn more.
 */
export interface Table {
  /** Headers of the table. */
  headers: FieldId[];
  /** Rows of the table. */
  rows: Table_Row[];
}

/** Values of the row. */
export interface Table_Row {
  /** Individual cells. */
  values: Value[];
}

/** All the findings for a single scanned item. */
export interface InspectResult {
  /** List of findings for an item. */
  findings: Finding[];
  /**
   * If true, then this item might have more findings than were returned,
   * and the findings returned are an arbitrary subset of all findings.
   * The findings list might be truncated because the input items were too
   * large, or because the server reached the maximum amount of resources
   * allowed for a single API call. For best results, divide the input into
   * smaller batches.
   */
  findingsTruncated: boolean;
}

/** Represents a piece of potentially sensitive content. */
export interface Finding {
  /**
   * Resource name in format
   * projects/{project}/locations/{location}/findings/{finding} Populated only
   * when viewing persisted findings.
   */
  name: string;
  /**
   * The content that was found. Even if the content is not textual, it
   * may be converted to a textual representation here.
   * Provided if `include_quote` is true and the finding is
   * less than or equal to 4096 bytes long. If the finding exceeds 4096 bytes
   * in length, the quote may be omitted.
   */
  quote: string;
  /**
   * The type of content that might have been found.
   * Provided if `excluded_types` is false.
   */
  infoType:
    | InfoType
    | undefined;
  /** Confidence of how likely it is that the `info_type` is correct. */
  likelihood: Likelihood;
  /** Where the content was found. */
  location:
    | Location
    | undefined;
  /** Timestamp when finding was detected. */
  createTime:
    | Date
    | undefined;
  /**
   * Contains data parsed from quotes. Only populated if include_quote was set
   * to true and a supported infoType was requested. Currently supported
   * infoTypes: DATE, DATE_OF_BIRTH and TIME.
   */
  quoteInfo:
    | QuoteInfo
    | undefined;
  /** The job that stored the finding. */
  resourceName: string;
  /** Job trigger name, if applicable, for this finding. */
  triggerName: string;
  /**
   * The labels associated with this `Finding`.
   *
   * Label keys must be between 1 and 63 characters long and must conform
   * to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`.
   *
   * Label values must be between 0 and 63 characters long and must conform
   * to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`.
   *
   * No more than 10 labels can be associated with a given finding.
   *
   * Examples:
   *
   * * `"environment" : "production"`
   * * `"pipeline" : "etl"`
   */
  labels: { [key: string]: string };
  /** Time the job started that produced this finding. */
  jobCreateTime:
    | Date
    | undefined;
  /** The job that stored the finding. */
  jobName: string;
  /** The unique finding id. */
  findingId: string;
}

export interface Finding_LabelsEntry {
  key: string;
  value: string;
}

/** Specifies the location of the finding. */
export interface Location {
  /**
   * Zero-based byte offsets delimiting the finding.
   * These are relative to the finding's containing element.
   * Note that when the content is not textual, this references
   * the UTF-8 encoded textual representation of the content.
   * Omitted if content is an image.
   */
  byteRange:
    | Range
    | undefined;
  /**
   * Unicode character offsets delimiting the finding.
   * These are relative to the finding's containing element.
   * Provided when the content is text.
   */
  codepointRange:
    | Range
    | undefined;
  /**
   * List of nested objects pointing to the precise location of the finding
   * within the file or record.
   */
  contentLocations: ContentLocation[];
  /** Information about the container where this finding occurred, if available. */
  container: Container | undefined;
}

/**
 * Precise location of the finding within a document, record, image, or metadata
 * container.
 */
export interface ContentLocation {
  /**
   * Name of the container where the finding is located.
   * The top level name is the source file name or table name. Names of some
   * common storage containers are formatted as follows:
   *
   * * BigQuery tables:  `{project_id}:{dataset_id}.{table_id}`
   * * Cloud Storage files: `gs://{bucket}/{path}`
   * * Datastore namespace: {namespace}
   *
   * Nested names could be absent if the embedded object has no string
   * identifier (for example, an image contained within a document).
   */
  containerName: string;
  /** Location within a row or record of a database table. */
  recordLocation?:
    | RecordLocation
    | undefined;
  /** Location within an image's pixels. */
  imageLocation?:
    | ImageLocation
    | undefined;
  /** Location data for document files. */
  documentLocation?:
    | DocumentLocation
    | undefined;
  /** Location within the metadata for inspected content. */
  metadataLocation?:
    | MetadataLocation
    | undefined;
  /**
   * Finding container modification timestamp, if applicable. For Cloud Storage,
   * this field contains the last file modification timestamp. For a BigQuery
   * table, this field contains the last_modified_time property. For Datastore,
   * this field isn't populated.
   */
  containerTimestamp:
    | Date
    | undefined;
  /**
   * Finding container version, if available
   * ("generation" for Cloud Storage).
   */
  containerVersion: string;
}

/** Metadata Location */
export interface MetadataLocation {
  /** Type of metadata containing the finding. */
  type: MetadataType;
  /** Storage metadata. */
  storageLabel?: StorageMetadataLabel | undefined;
}

/** Storage metadata label to indicate which metadata entry contains findings. */
export interface StorageMetadataLabel {
  /** Label name. */
  key: string;
}

/** Location of a finding within a document. */
export interface DocumentLocation {
  /**
   * Offset of the line, from the beginning of the file, where the finding
   * is located.
   */
  fileOffset: Long;
}

/** Location of a finding within a row or record. */
export interface RecordLocation {
  /** Key of the finding. */
  recordKey:
    | RecordKey
    | undefined;
  /** Field id of the field containing the finding. */
  fieldId:
    | FieldId
    | undefined;
  /** Location within a `ContentItem.Table`. */
  tableLocation: TableLocation | undefined;
}

/** Location of a finding within a table. */
export interface TableLocation {
  /**
   * The zero-based index of the row where the finding is located. Only
   * populated for resources that have a natural ordering, not BigQuery. In
   * BigQuery, to identify the row a finding came from, populate
   * BigQueryOptions.identifying_fields with your primary key column names and
   * when you store the findings the value of those columns will be stored
   * inside of Finding.
   */
  rowIndex: Long;
}

/**
 * Represents a container that may contain DLP findings.
 * Examples of a container include a file, table, or database record.
 */
export interface Container {
  /** Container type, for example BigQuery or Cloud Storage. */
  type: string;
  /**
   * Project where the finding was found.
   * Can be different from the project that owns the finding.
   */
  projectId: string;
  /**
   * A string representation of the full container name.
   * Examples:
   * - BigQuery: 'Project:DataSetId.TableId'
   * - Cloud Storage: 'gs://Bucket/folders/filename.txt'
   */
  fullPath: string;
  /**
   * The root of the container.
   * Examples:
   *
   * - For BigQuery table `project_id:dataset_id.table_id`, the root is
   *  `dataset_id`
   * - For Cloud Storage file `gs://bucket/folder/filename.txt`, the root
   *  is `gs://bucket`
   */
  rootPath: string;
  /**
   * The rest of the path after the root.
   * Examples:
   *
   * - For BigQuery table `project_id:dataset_id.table_id`, the relative path is
   *  `table_id`
   * - For Cloud Storage file `gs://bucket/folder/filename.txt`, the relative
   *  path is `folder/filename.txt`
   */
  relativePath: string;
  /**
   * Findings container modification timestamp, if applicable. For Cloud
   * Storage, this field contains the last file modification timestamp. For a
   * BigQuery table, this field contains the last_modified_time property. For
   * Datastore, this field isn't populated.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * Findings container version, if available
   * ("generation" for Cloud Storage).
   */
  version: string;
}

/** Generic half-open interval [start, end) */
export interface Range {
  /** Index of the first character of the range (inclusive). */
  start: Long;
  /** Index of the last character of the range (exclusive). */
  end: Long;
}

/** Location of the finding within an image. */
export interface ImageLocation {
  /** Bounding boxes locating the pixels within the image containing the finding. */
  boundingBoxes: BoundingBox[];
}

/** Bounding box encompassing detected text within an image. */
export interface BoundingBox {
  /** Top coordinate of the bounding box. (0,0) is upper left. */
  top: number;
  /** Left coordinate of the bounding box. (0,0) is upper left. */
  left: number;
  /** Width of the bounding box in pixels. */
  width: number;
  /** Height of the bounding box in pixels. */
  height: number;
}

/**
 * Request to search for potentially sensitive info in an image and redact it
 * by covering it with a colored rectangle.
 */
export interface RedactImageRequest {
  /**
   * Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
  /** Configuration for the inspector. */
  inspectConfig:
    | InspectConfig
    | undefined;
  /** The configuration for specifying what content to redact from images. */
  imageRedactionConfigs: RedactImageRequest_ImageRedactionConfig[];
  /**
   * Whether the response should include findings along with the redacted
   * image.
   */
  includeFindings: boolean;
  /** The content must be PNG, JPEG, SVG or BMP. */
  byteItem: ByteContentItem | undefined;
}

/** Configuration for determining how redaction of images should occur. */
export interface RedactImageRequest_ImageRedactionConfig {
  /**
   * Only one per info_type should be provided per request. If not
   * specified, and redact_all_text is false, the DLP API will redact all
   * text that it matches against all info_types that are found, but not
   * specified in another ImageRedactionConfig.
   */
  infoType?:
    | InfoType
    | undefined;
  /**
   * If true, all text found in the image, regardless whether it matches an
   * info_type, is redacted. Only one should be provided.
   */
  redactAllText?:
    | boolean
    | undefined;
  /**
   * The color to use when redacting content from an image. If not specified,
   * the default is black.
   */
  redactionColor: Color | undefined;
}

/** Represents a color in the RGB color space. */
export interface Color {
  /** The amount of red in the color as a value in the interval [0, 1]. */
  red: number;
  /** The amount of green in the color as a value in the interval [0, 1]. */
  green: number;
  /** The amount of blue in the color as a value in the interval [0, 1]. */
  blue: number;
}

/** Results of redacting an image. */
export interface RedactImageResponse {
  /** The redacted image. The type will be the same as the original image. */
  redactedImage: Buffer;
  /**
   * If an image was being inspected and the InspectConfig's include_quote was
   * set to true, then this field will include all text, if any, that was found
   * in the image.
   */
  extractedText: string;
  /** The findings. Populated when include_findings in the request is true. */
  inspectResult: InspectResult | undefined;
}

/** Request to de-identify a ContentItem. */
export interface DeidentifyContentRequest {
  /**
   * Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Configuration for the de-identification of the content item.
   * Items specified here will override the template referenced by the
   * deidentify_template_name argument.
   */
  deidentifyConfig:
    | DeidentifyConfig
    | undefined;
  /**
   * Configuration for the inspector.
   * Items specified here will override the template referenced by the
   * inspect_template_name argument.
   */
  inspectConfig:
    | InspectConfig
    | undefined;
  /**
   * The item to de-identify. Will be treated as text.
   *
   * This value must be of type
   * [Table][google.privacy.dlp.v2.Table] if your
   * [deidentify_config][google.privacy.dlp.v2.DeidentifyContentRequest.deidentify_config]
   * is a
   * [RecordTransformations][google.privacy.dlp.v2.RecordTransformations]
   * object.
   */
  item:
    | ContentItem
    | undefined;
  /**
   * Template to use. Any configuration directly specified in
   * inspect_config will override those set in the template. Singular fields
   * that are set in this request will replace their corresponding fields in the
   * template. Repeated fields are appended. Singular sub-messages and groups
   * are recursively merged.
   */
  inspectTemplateName: string;
  /**
   * Template to use. Any configuration directly specified in
   * deidentify_config will override those set in the template. Singular fields
   * that are set in this request will replace their corresponding fields in the
   * template. Repeated fields are appended. Singular sub-messages and groups
   * are recursively merged.
   */
  deidentifyTemplateName: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Results of de-identifying a ContentItem. */
export interface DeidentifyContentResponse {
  /** The de-identified item. */
  item:
    | ContentItem
    | undefined;
  /** An overview of the changes that were made on the `item`. */
  overview: TransformationOverview | undefined;
}

/** Request to re-identify an item. */
export interface ReidentifyContentRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Configuration for the re-identification of the content item.
   * This field shares the same proto message type that is used for
   * de-identification, however its usage here is for the reversal of the
   * previous de-identification. Re-identification is performed by examining
   * the transformations used to de-identify the items and executing the
   * reverse. This requires that only reversible transformations
   * be provided here. The reversible transformations are:
   *
   *  - `CryptoDeterministicConfig`
   *  - `CryptoReplaceFfxFpeConfig`
   */
  reidentifyConfig:
    | DeidentifyConfig
    | undefined;
  /** Configuration for the inspector. */
  inspectConfig:
    | InspectConfig
    | undefined;
  /** The item to re-identify. Will be treated as text. */
  item:
    | ContentItem
    | undefined;
  /**
   * Template to use. Any configuration directly specified in
   * `inspect_config` will override those set in the template. Singular fields
   * that are set in this request will replace their corresponding fields in the
   * template. Repeated fields are appended. Singular sub-messages and groups
   * are recursively merged.
   */
  inspectTemplateName: string;
  /**
   * Template to use. References an instance of `DeidentifyTemplate`.
   * Any configuration directly specified in `reidentify_config` or
   * `inspect_config` will override those set in the template. The
   * `DeidentifyTemplate` used must include only reversible transformations.
   * Singular fields that are set in this request will replace their
   * corresponding fields in the template. Repeated fields are appended.
   * Singular sub-messages and groups are recursively merged.
   */
  reidentifyTemplateName: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Results of re-identifying an item. */
export interface ReidentifyContentResponse {
  /** The re-identified item. */
  item:
    | ContentItem
    | undefined;
  /** An overview of the changes that were made to the `item`. */
  overview: TransformationOverview | undefined;
}

/** Request to search for potentially sensitive info in a ContentItem. */
export interface InspectContentRequest {
  /**
   * Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Configuration for the inspector. What specified here will override
   * the template referenced by the inspect_template_name argument.
   */
  inspectConfig:
    | InspectConfig
    | undefined;
  /** The item to inspect. */
  item:
    | ContentItem
    | undefined;
  /**
   * Template to use. Any configuration directly specified in
   * inspect_config will override those set in the template. Singular fields
   * that are set in this request will replace their corresponding fields in the
   * template. Repeated fields are appended. Singular sub-messages and groups
   * are recursively merged.
   */
  inspectTemplateName: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Results of inspecting an item. */
export interface InspectContentResponse {
  /** The findings. */
  result: InspectResult | undefined;
}

/** Cloud repository for storing output. */
export interface OutputStorageConfig {
  /**
   * Store findings in an existing table or a new table in an existing
   * dataset. If table_id is not set a new one will be generated
   * for you with the following format:
   * dlp_googleapis_yyyy_mm_dd_[dlp_job_id]. Pacific time zone will be used
   * for generating the date details.
   *
   * For Inspect, each column in an existing output table must have the same
   * name, type, and mode of a field in the `Finding` object.
   *
   * For Risk, an existing output table should be the output of a previous
   * Risk analysis job run on the same source table, with the same privacy
   * metric and quasi-identifiers. Risk jobs that analyze the same table but
   * compute a different privacy metric, or use different sets of
   * quasi-identifiers, cannot store their results in the same table.
   */
  table?:
    | BigQueryTable
    | undefined;
  /**
   * Schema used for writing the findings for Inspect jobs. This field is only
   * used for Inspect and must be unspecified for Risk jobs. Columns are derived
   * from the `Finding` object. If appending to an existing table, any columns
   * from the predefined schema that are missing will be added. No columns in
   * the existing table will be deleted.
   *
   * If unspecified, then all available columns will be used for a new table or
   * an (existing) table with no schema, and no changes will be made to an
   * existing table that has a schema.
   * Only for use with external storage.
   */
  outputSchema: OutputStorageConfig_OutputSchema;
}

/**
 * Predefined schemas for storing findings.
 * Only for use with external storage.
 */
export enum OutputStorageConfig_OutputSchema {
  /** OUTPUT_SCHEMA_UNSPECIFIED - Unused. */
  OUTPUT_SCHEMA_UNSPECIFIED = 0,
  /**
   * BASIC_COLUMNS - Basic schema including only `info_type`, `quote`, `certainty`, and
   * `timestamp`.
   */
  BASIC_COLUMNS = 1,
  /** GCS_COLUMNS - Schema tailored to findings from scanning Cloud Storage. */
  GCS_COLUMNS = 2,
  /** DATASTORE_COLUMNS - Schema tailored to findings from scanning Google Datastore. */
  DATASTORE_COLUMNS = 3,
  /** BIG_QUERY_COLUMNS - Schema tailored to findings from scanning Google BigQuery. */
  BIG_QUERY_COLUMNS = 4,
  /** ALL_COLUMNS - Schema containing all columns. */
  ALL_COLUMNS = 5,
  UNRECOGNIZED = -1,
}

export function outputStorageConfig_OutputSchemaFromJSON(object: any): OutputStorageConfig_OutputSchema {
  switch (object) {
    case 0:
    case "OUTPUT_SCHEMA_UNSPECIFIED":
      return OutputStorageConfig_OutputSchema.OUTPUT_SCHEMA_UNSPECIFIED;
    case 1:
    case "BASIC_COLUMNS":
      return OutputStorageConfig_OutputSchema.BASIC_COLUMNS;
    case 2:
    case "GCS_COLUMNS":
      return OutputStorageConfig_OutputSchema.GCS_COLUMNS;
    case 3:
    case "DATASTORE_COLUMNS":
      return OutputStorageConfig_OutputSchema.DATASTORE_COLUMNS;
    case 4:
    case "BIG_QUERY_COLUMNS":
      return OutputStorageConfig_OutputSchema.BIG_QUERY_COLUMNS;
    case 5:
    case "ALL_COLUMNS":
      return OutputStorageConfig_OutputSchema.ALL_COLUMNS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OutputStorageConfig_OutputSchema.UNRECOGNIZED;
  }
}

export function outputStorageConfig_OutputSchemaToJSON(object: OutputStorageConfig_OutputSchema): string {
  switch (object) {
    case OutputStorageConfig_OutputSchema.OUTPUT_SCHEMA_UNSPECIFIED:
      return "OUTPUT_SCHEMA_UNSPECIFIED";
    case OutputStorageConfig_OutputSchema.BASIC_COLUMNS:
      return "BASIC_COLUMNS";
    case OutputStorageConfig_OutputSchema.GCS_COLUMNS:
      return "GCS_COLUMNS";
    case OutputStorageConfig_OutputSchema.DATASTORE_COLUMNS:
      return "DATASTORE_COLUMNS";
    case OutputStorageConfig_OutputSchema.BIG_QUERY_COLUMNS:
      return "BIG_QUERY_COLUMNS";
    case OutputStorageConfig_OutputSchema.ALL_COLUMNS:
      return "ALL_COLUMNS";
    case OutputStorageConfig_OutputSchema.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Statistics regarding a specific InfoType. */
export interface InfoTypeStats {
  /** The type of finding this stat is for. */
  infoType:
    | InfoType
    | undefined;
  /** Number of findings for this infoType. */
  count: Long;
}

/** The results of an inspect DataSource job. */
export interface InspectDataSourceDetails {
  /** The configuration used for this job. */
  requestedOptions:
    | InspectDataSourceDetails_RequestedOptions
    | undefined;
  /** A summary of the outcome of this inspection job. */
  result: InspectDataSourceDetails_Result | undefined;
}

/** Snapshot of the inspection configuration. */
export interface InspectDataSourceDetails_RequestedOptions {
  /**
   * If run with an InspectTemplate, a snapshot of its state at the time of
   * this run.
   */
  snapshotInspectTemplate:
    | InspectTemplate
    | undefined;
  /** Inspect config. */
  jobConfig: InspectJobConfig | undefined;
}

/** All result fields mentioned below are updated while the job is processing. */
export interface InspectDataSourceDetails_Result {
  /** Total size in bytes that were processed. */
  processedBytes: Long;
  /** Estimate of the number of bytes to process. */
  totalEstimatedBytes: Long;
  /**
   * Statistics of how many instances of each info type were found during
   * inspect job.
   */
  infoTypeStats: InfoTypeStats[];
  /**
   * Number of rows scanned after sampling and time filtering (applicable for
   * row based stores such as BigQuery).
   */
  numRowsProcessed: Long;
  /** Statistics related to the processing of hybrid inspect. */
  hybridStats: HybridInspectStatistics | undefined;
}

/**
 * The schema of data to be saved to the BigQuery table when the
 * `DataProfileAction` is enabled.
 */
export interface DataProfileBigQueryRowSchema {
  /** Table data profile column */
  tableProfile?:
    | TableDataProfile
    | undefined;
  /** Column data profile column */
  columnProfile?:
    | ColumnDataProfile
    | undefined;
  /** File store data profile column. */
  fileStoreProfile?: FileStoreDataProfile | undefined;
}

/** Statistics related to processing hybrid inspect requests. */
export interface HybridInspectStatistics {
  /** The number of hybrid inspection requests processed within this job. */
  processedCount: Long;
  /**
   * The number of hybrid inspection requests aborted because the job ran
   * out of quota or was ended before they could be processed.
   */
  abortedCount: Long;
  /**
   * The number of hybrid requests currently being processed. Only populated
   * when called via method `getDlpJob`.
   * A burst of traffic may cause hybrid inspect requests to be enqueued.
   * Processing will take place as quickly as possible, but resource limitations
   * may impact how long a request is enqueued for.
   */
  pendingCount: Long;
}

/** The results of an [Action][google.privacy.dlp.v2.Action]. */
export interface ActionDetails {
  /** Outcome of a de-identification action. */
  deidentifyDetails?: DeidentifyDataSourceDetails | undefined;
}

/** Summary of what was modified during a transformation. */
export interface DeidentifyDataSourceStats {
  /** Total size in bytes that were transformed in some way. */
  transformedBytes: Long;
  /** Number of successfully applied transformations. */
  transformationCount: Long;
  /** Number of errors encountered while trying to apply transformations. */
  transformationErrorCount: Long;
}

/**
 * The results of a [Deidentify][google.privacy.dlp.v2.Action.Deidentify] action
 * from an inspect job.
 */
export interface DeidentifyDataSourceDetails {
  /** De-identification config used for the request. */
  requestedOptions:
    | DeidentifyDataSourceDetails_RequestedDeidentifyOptions
    | undefined;
  /** Stats about the de-identification operation. */
  deidentifyStats: DeidentifyDataSourceStats | undefined;
}

/** De-identification options. */
export interface DeidentifyDataSourceDetails_RequestedDeidentifyOptions {
  /**
   * Snapshot of the state of the `DeidentifyTemplate` from the
   * [Deidentify][google.privacy.dlp.v2.Action.Deidentify] action at the time
   * this job was run.
   */
  snapshotDeidentifyTemplate:
    | DeidentifyTemplate
    | undefined;
  /**
   * Snapshot of the state of the structured `DeidentifyTemplate` from the
   * `Deidentify` action at the time this job was run.
   */
  snapshotStructuredDeidentifyTemplate:
    | DeidentifyTemplate
    | undefined;
  /**
   * Snapshot of the state of the image transformation `DeidentifyTemplate`
   * from the `Deidentify` action at the time this job was run.
   */
  snapshotImageRedactTemplate: DeidentifyTemplate | undefined;
}

/** InfoType description. */
export interface InfoTypeDescription {
  /** Internal name of the infoType. */
  name: string;
  /** Human readable form of the infoType name. */
  displayName: string;
  /** Which parts of the API supports this InfoType. */
  supportedBy: InfoTypeSupportedBy[];
  /**
   * Description of the infotype. Translated when language is provided in the
   * request.
   */
  description: string;
  /** A list of available versions for the infotype. */
  versions: VersionDescription[];
  /** The category of the infoType. */
  categories: InfoTypeCategory[];
  /** The default sensitivity of the infoType. */
  sensitivityScore: SensitivityScore | undefined;
}

/**
 * Classification of infoTypes to organize them according to geographic
 * location, industry, and data type.
 */
export interface InfoTypeCategory {
  /**
   * The region or country that issued the ID or document represented by the
   * infoType.
   */
  locationCategory?:
    | InfoTypeCategory_LocationCategory
    | undefined;
  /** The group of relevant businesses where this infoType is commonly used */
  industryCategory?:
    | InfoTypeCategory_IndustryCategory
    | undefined;
  /** The class of identifiers where this infoType belongs */
  typeCategory?: InfoTypeCategory_TypeCategory | undefined;
}

/**
 * Enum of the current locations.
 * We might add more locations in the future.
 */
export enum InfoTypeCategory_LocationCategory {
  /** LOCATION_UNSPECIFIED - Unused location */
  LOCATION_UNSPECIFIED = 0,
  /**
   * GLOBAL - The infoType is not issued by or tied to a specific region, but is used
   * almost everywhere.
   */
  GLOBAL = 1,
  /** ARGENTINA - The infoType is typically used in Argentina. */
  ARGENTINA = 2,
  /** ARMENIA - The infoType is typically used in Armenia. */
  ARMENIA = 51,
  /** AUSTRALIA - The infoType is typically used in Australia. */
  AUSTRALIA = 3,
  /** AZERBAIJAN - The infoType is typically used in Azerbaijan. */
  AZERBAIJAN = 48,
  /** BELARUS - The infoType is typically used in Belarus. */
  BELARUS = 50,
  /** BELGIUM - The infoType is typically used in Belgium. */
  BELGIUM = 4,
  /** BRAZIL - The infoType is typically used in Brazil. */
  BRAZIL = 5,
  /** CANADA - The infoType is typically used in Canada. */
  CANADA = 6,
  /** CHILE - The infoType is typically used in Chile. */
  CHILE = 7,
  /** CHINA - The infoType is typically used in China. */
  CHINA = 8,
  /** COLOMBIA - The infoType is typically used in Colombia. */
  COLOMBIA = 9,
  /** CROATIA - The infoType is typically used in Croatia. */
  CROATIA = 42,
  /** DENMARK - The infoType is typically used in Denmark. */
  DENMARK = 10,
  /** FRANCE - The infoType is typically used in France. */
  FRANCE = 11,
  /** FINLAND - The infoType is typically used in Finland. */
  FINLAND = 12,
  /** GERMANY - The infoType is typically used in Germany. */
  GERMANY = 13,
  /** HONG_KONG - The infoType is typically used in Hong Kong. */
  HONG_KONG = 14,
  /** INDIA - The infoType is typically used in India. */
  INDIA = 15,
  /** INDONESIA - The infoType is typically used in Indonesia. */
  INDONESIA = 16,
  /** IRELAND - The infoType is typically used in Ireland. */
  IRELAND = 17,
  /** ISRAEL - The infoType is typically used in Israel. */
  ISRAEL = 18,
  /** ITALY - The infoType is typically used in Italy. */
  ITALY = 19,
  /** JAPAN - The infoType is typically used in Japan. */
  JAPAN = 20,
  /** KAZAKHSTAN - The infoType is typically used in Kazakhstan. */
  KAZAKHSTAN = 47,
  /** KOREA - The infoType is typically used in Korea. */
  KOREA = 21,
  /** MEXICO - The infoType is typically used in Mexico. */
  MEXICO = 22,
  /** THE_NETHERLANDS - The infoType is typically used in the Netherlands. */
  THE_NETHERLANDS = 23,
  /** NEW_ZEALAND - The infoType is typically used in New Zealand. */
  NEW_ZEALAND = 41,
  /** NORWAY - The infoType is typically used in Norway. */
  NORWAY = 24,
  /** PARAGUAY - The infoType is typically used in Paraguay. */
  PARAGUAY = 25,
  /** PERU - The infoType is typically used in Peru. */
  PERU = 26,
  /** POLAND - The infoType is typically used in Poland. */
  POLAND = 27,
  /** PORTUGAL - The infoType is typically used in Portugal. */
  PORTUGAL = 28,
  /** RUSSIA - The infoType is typically used in Russia. */
  RUSSIA = 44,
  /** SINGAPORE - The infoType is typically used in Singapore. */
  SINGAPORE = 29,
  /** SOUTH_AFRICA - The infoType is typically used in South Africa. */
  SOUTH_AFRICA = 30,
  /** SPAIN - The infoType is typically used in Spain. */
  SPAIN = 31,
  /** SWEDEN - The infoType is typically used in Sweden. */
  SWEDEN = 32,
  /** SWITZERLAND - The infoType is typically used in Switzerland. */
  SWITZERLAND = 43,
  /** TAIWAN - The infoType is typically used in Taiwan. */
  TAIWAN = 33,
  /** THAILAND - The infoType is typically used in Thailand. */
  THAILAND = 34,
  /** TURKEY - The infoType is typically used in Turkey. */
  TURKEY = 35,
  /** UKRAINE - The infoType is typically used in Ukraine. */
  UKRAINE = 45,
  /** UNITED_KINGDOM - The infoType is typically used in the United Kingdom. */
  UNITED_KINGDOM = 36,
  /** UNITED_STATES - The infoType is typically used in the United States. */
  UNITED_STATES = 37,
  /** URUGUAY - The infoType is typically used in Uruguay. */
  URUGUAY = 38,
  /** UZBEKISTAN - The infoType is typically used in Uzbekistan. */
  UZBEKISTAN = 46,
  /** VENEZUELA - The infoType is typically used in Venezuela. */
  VENEZUELA = 39,
  /** INTERNAL - The infoType is typically used in Google internally. */
  INTERNAL = 40,
  UNRECOGNIZED = -1,
}

export function infoTypeCategory_LocationCategoryFromJSON(object: any): InfoTypeCategory_LocationCategory {
  switch (object) {
    case 0:
    case "LOCATION_UNSPECIFIED":
      return InfoTypeCategory_LocationCategory.LOCATION_UNSPECIFIED;
    case 1:
    case "GLOBAL":
      return InfoTypeCategory_LocationCategory.GLOBAL;
    case 2:
    case "ARGENTINA":
      return InfoTypeCategory_LocationCategory.ARGENTINA;
    case 51:
    case "ARMENIA":
      return InfoTypeCategory_LocationCategory.ARMENIA;
    case 3:
    case "AUSTRALIA":
      return InfoTypeCategory_LocationCategory.AUSTRALIA;
    case 48:
    case "AZERBAIJAN":
      return InfoTypeCategory_LocationCategory.AZERBAIJAN;
    case 50:
    case "BELARUS":
      return InfoTypeCategory_LocationCategory.BELARUS;
    case 4:
    case "BELGIUM":
      return InfoTypeCategory_LocationCategory.BELGIUM;
    case 5:
    case "BRAZIL":
      return InfoTypeCategory_LocationCategory.BRAZIL;
    case 6:
    case "CANADA":
      return InfoTypeCategory_LocationCategory.CANADA;
    case 7:
    case "CHILE":
      return InfoTypeCategory_LocationCategory.CHILE;
    case 8:
    case "CHINA":
      return InfoTypeCategory_LocationCategory.CHINA;
    case 9:
    case "COLOMBIA":
      return InfoTypeCategory_LocationCategory.COLOMBIA;
    case 42:
    case "CROATIA":
      return InfoTypeCategory_LocationCategory.CROATIA;
    case 10:
    case "DENMARK":
      return InfoTypeCategory_LocationCategory.DENMARK;
    case 11:
    case "FRANCE":
      return InfoTypeCategory_LocationCategory.FRANCE;
    case 12:
    case "FINLAND":
      return InfoTypeCategory_LocationCategory.FINLAND;
    case 13:
    case "GERMANY":
      return InfoTypeCategory_LocationCategory.GERMANY;
    case 14:
    case "HONG_KONG":
      return InfoTypeCategory_LocationCategory.HONG_KONG;
    case 15:
    case "INDIA":
      return InfoTypeCategory_LocationCategory.INDIA;
    case 16:
    case "INDONESIA":
      return InfoTypeCategory_LocationCategory.INDONESIA;
    case 17:
    case "IRELAND":
      return InfoTypeCategory_LocationCategory.IRELAND;
    case 18:
    case "ISRAEL":
      return InfoTypeCategory_LocationCategory.ISRAEL;
    case 19:
    case "ITALY":
      return InfoTypeCategory_LocationCategory.ITALY;
    case 20:
    case "JAPAN":
      return InfoTypeCategory_LocationCategory.JAPAN;
    case 47:
    case "KAZAKHSTAN":
      return InfoTypeCategory_LocationCategory.KAZAKHSTAN;
    case 21:
    case "KOREA":
      return InfoTypeCategory_LocationCategory.KOREA;
    case 22:
    case "MEXICO":
      return InfoTypeCategory_LocationCategory.MEXICO;
    case 23:
    case "THE_NETHERLANDS":
      return InfoTypeCategory_LocationCategory.THE_NETHERLANDS;
    case 41:
    case "NEW_ZEALAND":
      return InfoTypeCategory_LocationCategory.NEW_ZEALAND;
    case 24:
    case "NORWAY":
      return InfoTypeCategory_LocationCategory.NORWAY;
    case 25:
    case "PARAGUAY":
      return InfoTypeCategory_LocationCategory.PARAGUAY;
    case 26:
    case "PERU":
      return InfoTypeCategory_LocationCategory.PERU;
    case 27:
    case "POLAND":
      return InfoTypeCategory_LocationCategory.POLAND;
    case 28:
    case "PORTUGAL":
      return InfoTypeCategory_LocationCategory.PORTUGAL;
    case 44:
    case "RUSSIA":
      return InfoTypeCategory_LocationCategory.RUSSIA;
    case 29:
    case "SINGAPORE":
      return InfoTypeCategory_LocationCategory.SINGAPORE;
    case 30:
    case "SOUTH_AFRICA":
      return InfoTypeCategory_LocationCategory.SOUTH_AFRICA;
    case 31:
    case "SPAIN":
      return InfoTypeCategory_LocationCategory.SPAIN;
    case 32:
    case "SWEDEN":
      return InfoTypeCategory_LocationCategory.SWEDEN;
    case 43:
    case "SWITZERLAND":
      return InfoTypeCategory_LocationCategory.SWITZERLAND;
    case 33:
    case "TAIWAN":
      return InfoTypeCategory_LocationCategory.TAIWAN;
    case 34:
    case "THAILAND":
      return InfoTypeCategory_LocationCategory.THAILAND;
    case 35:
    case "TURKEY":
      return InfoTypeCategory_LocationCategory.TURKEY;
    case 45:
    case "UKRAINE":
      return InfoTypeCategory_LocationCategory.UKRAINE;
    case 36:
    case "UNITED_KINGDOM":
      return InfoTypeCategory_LocationCategory.UNITED_KINGDOM;
    case 37:
    case "UNITED_STATES":
      return InfoTypeCategory_LocationCategory.UNITED_STATES;
    case 38:
    case "URUGUAY":
      return InfoTypeCategory_LocationCategory.URUGUAY;
    case 46:
    case "UZBEKISTAN":
      return InfoTypeCategory_LocationCategory.UZBEKISTAN;
    case 39:
    case "VENEZUELA":
      return InfoTypeCategory_LocationCategory.VENEZUELA;
    case 40:
    case "INTERNAL":
      return InfoTypeCategory_LocationCategory.INTERNAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return InfoTypeCategory_LocationCategory.UNRECOGNIZED;
  }
}

export function infoTypeCategory_LocationCategoryToJSON(object: InfoTypeCategory_LocationCategory): string {
  switch (object) {
    case InfoTypeCategory_LocationCategory.LOCATION_UNSPECIFIED:
      return "LOCATION_UNSPECIFIED";
    case InfoTypeCategory_LocationCategory.GLOBAL:
      return "GLOBAL";
    case InfoTypeCategory_LocationCategory.ARGENTINA:
      return "ARGENTINA";
    case InfoTypeCategory_LocationCategory.ARMENIA:
      return "ARMENIA";
    case InfoTypeCategory_LocationCategory.AUSTRALIA:
      return "AUSTRALIA";
    case InfoTypeCategory_LocationCategory.AZERBAIJAN:
      return "AZERBAIJAN";
    case InfoTypeCategory_LocationCategory.BELARUS:
      return "BELARUS";
    case InfoTypeCategory_LocationCategory.BELGIUM:
      return "BELGIUM";
    case InfoTypeCategory_LocationCategory.BRAZIL:
      return "BRAZIL";
    case InfoTypeCategory_LocationCategory.CANADA:
      return "CANADA";
    case InfoTypeCategory_LocationCategory.CHILE:
      return "CHILE";
    case InfoTypeCategory_LocationCategory.CHINA:
      return "CHINA";
    case InfoTypeCategory_LocationCategory.COLOMBIA:
      return "COLOMBIA";
    case InfoTypeCategory_LocationCategory.CROATIA:
      return "CROATIA";
    case InfoTypeCategory_LocationCategory.DENMARK:
      return "DENMARK";
    case InfoTypeCategory_LocationCategory.FRANCE:
      return "FRANCE";
    case InfoTypeCategory_LocationCategory.FINLAND:
      return "FINLAND";
    case InfoTypeCategory_LocationCategory.GERMANY:
      return "GERMANY";
    case InfoTypeCategory_LocationCategory.HONG_KONG:
      return "HONG_KONG";
    case InfoTypeCategory_LocationCategory.INDIA:
      return "INDIA";
    case InfoTypeCategory_LocationCategory.INDONESIA:
      return "INDONESIA";
    case InfoTypeCategory_LocationCategory.IRELAND:
      return "IRELAND";
    case InfoTypeCategory_LocationCategory.ISRAEL:
      return "ISRAEL";
    case InfoTypeCategory_LocationCategory.ITALY:
      return "ITALY";
    case InfoTypeCategory_LocationCategory.JAPAN:
      return "JAPAN";
    case InfoTypeCategory_LocationCategory.KAZAKHSTAN:
      return "KAZAKHSTAN";
    case InfoTypeCategory_LocationCategory.KOREA:
      return "KOREA";
    case InfoTypeCategory_LocationCategory.MEXICO:
      return "MEXICO";
    case InfoTypeCategory_LocationCategory.THE_NETHERLANDS:
      return "THE_NETHERLANDS";
    case InfoTypeCategory_LocationCategory.NEW_ZEALAND:
      return "NEW_ZEALAND";
    case InfoTypeCategory_LocationCategory.NORWAY:
      return "NORWAY";
    case InfoTypeCategory_LocationCategory.PARAGUAY:
      return "PARAGUAY";
    case InfoTypeCategory_LocationCategory.PERU:
      return "PERU";
    case InfoTypeCategory_LocationCategory.POLAND:
      return "POLAND";
    case InfoTypeCategory_LocationCategory.PORTUGAL:
      return "PORTUGAL";
    case InfoTypeCategory_LocationCategory.RUSSIA:
      return "RUSSIA";
    case InfoTypeCategory_LocationCategory.SINGAPORE:
      return "SINGAPORE";
    case InfoTypeCategory_LocationCategory.SOUTH_AFRICA:
      return "SOUTH_AFRICA";
    case InfoTypeCategory_LocationCategory.SPAIN:
      return "SPAIN";
    case InfoTypeCategory_LocationCategory.SWEDEN:
      return "SWEDEN";
    case InfoTypeCategory_LocationCategory.SWITZERLAND:
      return "SWITZERLAND";
    case InfoTypeCategory_LocationCategory.TAIWAN:
      return "TAIWAN";
    case InfoTypeCategory_LocationCategory.THAILAND:
      return "THAILAND";
    case InfoTypeCategory_LocationCategory.TURKEY:
      return "TURKEY";
    case InfoTypeCategory_LocationCategory.UKRAINE:
      return "UKRAINE";
    case InfoTypeCategory_LocationCategory.UNITED_KINGDOM:
      return "UNITED_KINGDOM";
    case InfoTypeCategory_LocationCategory.UNITED_STATES:
      return "UNITED_STATES";
    case InfoTypeCategory_LocationCategory.URUGUAY:
      return "URUGUAY";
    case InfoTypeCategory_LocationCategory.UZBEKISTAN:
      return "UZBEKISTAN";
    case InfoTypeCategory_LocationCategory.VENEZUELA:
      return "VENEZUELA";
    case InfoTypeCategory_LocationCategory.INTERNAL:
      return "INTERNAL";
    case InfoTypeCategory_LocationCategory.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Enum of the current industries in the category.
 * We might add more industries in the future.
 */
export enum InfoTypeCategory_IndustryCategory {
  /** INDUSTRY_UNSPECIFIED - Unused industry */
  INDUSTRY_UNSPECIFIED = 0,
  /** FINANCE - The infoType is typically used in the finance industry. */
  FINANCE = 1,
  /** HEALTH - The infoType is typically used in the health industry. */
  HEALTH = 2,
  /** TELECOMMUNICATIONS - The infoType is typically used in the telecommunications industry. */
  TELECOMMUNICATIONS = 3,
  UNRECOGNIZED = -1,
}

export function infoTypeCategory_IndustryCategoryFromJSON(object: any): InfoTypeCategory_IndustryCategory {
  switch (object) {
    case 0:
    case "INDUSTRY_UNSPECIFIED":
      return InfoTypeCategory_IndustryCategory.INDUSTRY_UNSPECIFIED;
    case 1:
    case "FINANCE":
      return InfoTypeCategory_IndustryCategory.FINANCE;
    case 2:
    case "HEALTH":
      return InfoTypeCategory_IndustryCategory.HEALTH;
    case 3:
    case "TELECOMMUNICATIONS":
      return InfoTypeCategory_IndustryCategory.TELECOMMUNICATIONS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return InfoTypeCategory_IndustryCategory.UNRECOGNIZED;
  }
}

export function infoTypeCategory_IndustryCategoryToJSON(object: InfoTypeCategory_IndustryCategory): string {
  switch (object) {
    case InfoTypeCategory_IndustryCategory.INDUSTRY_UNSPECIFIED:
      return "INDUSTRY_UNSPECIFIED";
    case InfoTypeCategory_IndustryCategory.FINANCE:
      return "FINANCE";
    case InfoTypeCategory_IndustryCategory.HEALTH:
      return "HEALTH";
    case InfoTypeCategory_IndustryCategory.TELECOMMUNICATIONS:
      return "TELECOMMUNICATIONS";
    case InfoTypeCategory_IndustryCategory.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Enum of the current types in the category.
 * We might add more types in the future.
 */
export enum InfoTypeCategory_TypeCategory {
  /** TYPE_UNSPECIFIED - Unused type */
  TYPE_UNSPECIFIED = 0,
  /**
   * PII - Personally identifiable information, for example, a
   * name or phone number
   */
  PII = 1,
  /**
   * SPII - Personally identifiable information that is especially sensitive, for
   * example, a passport number.
   */
  SPII = 2,
  /**
   * DEMOGRAPHIC - Attributes that can partially identify someone, especially in
   * combination with other attributes, like age, height, and gender.
   */
  DEMOGRAPHIC = 3,
  /** CREDENTIAL - Confidential or secret information, for example, a password. */
  CREDENTIAL = 4,
  /** GOVERNMENT_ID - An identification document issued by a government. */
  GOVERNMENT_ID = 5,
  /** DOCUMENT - A document, for example, a resume or source code. */
  DOCUMENT = 6,
  /**
   * CONTEXTUAL_INFORMATION - Information that is not sensitive on its own, but provides details about
   * the circumstances surrounding an entity or an event.
   */
  CONTEXTUAL_INFORMATION = 7,
  UNRECOGNIZED = -1,
}

export function infoTypeCategory_TypeCategoryFromJSON(object: any): InfoTypeCategory_TypeCategory {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return InfoTypeCategory_TypeCategory.TYPE_UNSPECIFIED;
    case 1:
    case "PII":
      return InfoTypeCategory_TypeCategory.PII;
    case 2:
    case "SPII":
      return InfoTypeCategory_TypeCategory.SPII;
    case 3:
    case "DEMOGRAPHIC":
      return InfoTypeCategory_TypeCategory.DEMOGRAPHIC;
    case 4:
    case "CREDENTIAL":
      return InfoTypeCategory_TypeCategory.CREDENTIAL;
    case 5:
    case "GOVERNMENT_ID":
      return InfoTypeCategory_TypeCategory.GOVERNMENT_ID;
    case 6:
    case "DOCUMENT":
      return InfoTypeCategory_TypeCategory.DOCUMENT;
    case 7:
    case "CONTEXTUAL_INFORMATION":
      return InfoTypeCategory_TypeCategory.CONTEXTUAL_INFORMATION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return InfoTypeCategory_TypeCategory.UNRECOGNIZED;
  }
}

export function infoTypeCategory_TypeCategoryToJSON(object: InfoTypeCategory_TypeCategory): string {
  switch (object) {
    case InfoTypeCategory_TypeCategory.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case InfoTypeCategory_TypeCategory.PII:
      return "PII";
    case InfoTypeCategory_TypeCategory.SPII:
      return "SPII";
    case InfoTypeCategory_TypeCategory.DEMOGRAPHIC:
      return "DEMOGRAPHIC";
    case InfoTypeCategory_TypeCategory.CREDENTIAL:
      return "CREDENTIAL";
    case InfoTypeCategory_TypeCategory.GOVERNMENT_ID:
      return "GOVERNMENT_ID";
    case InfoTypeCategory_TypeCategory.DOCUMENT:
      return "DOCUMENT";
    case InfoTypeCategory_TypeCategory.CONTEXTUAL_INFORMATION:
      return "CONTEXTUAL_INFORMATION";
    case InfoTypeCategory_TypeCategory.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Details about each available version for an infotype. */
export interface VersionDescription {
  /** Name of the version */
  version: string;
  /** Description of the version. */
  description: string;
}

/** Request for the list of infoTypes. */
export interface ListInfoTypesRequest {
  /**
   * The parent resource name.
   *
   * The format of this value is as follows:
   *
   *     `locations/{location_id}`
   */
  parent: string;
  /**
   * BCP-47 language code for localized infoType friendly
   * names. If omitted, or if localized strings are not available,
   * en-US strings will be returned.
   */
  languageCode: string;
  /**
   * filter to only return infoTypes supported by certain parts of the
   * API. Defaults to supported_by=INSPECT.
   */
  filter: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Response to the ListInfoTypes request. */
export interface ListInfoTypesResponse {
  /** Set of sensitive infoTypes. */
  infoTypes: InfoTypeDescription[];
}

/**
 * Configuration for a risk analysis job. See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-risk-analysis
 * to learn more.
 */
export interface RiskAnalysisJobConfig {
  /** Privacy metric to compute. */
  privacyMetric:
    | PrivacyMetric
    | undefined;
  /** Input dataset to compute metrics over. */
  sourceTable:
    | BigQueryTable
    | undefined;
  /**
   * Actions to execute at the completion of the job. Are executed in the order
   * provided.
   */
  actions: Action[];
}

/** A column with a semantic tag attached. */
export interface QuasiId {
  /** Required. Identifies the column. */
  field:
    | FieldId
    | undefined;
  /**
   * A column can be tagged with a InfoType to use the relevant public
   * dataset as a statistical model of population, if available. We
   * currently support US ZIP codes, region codes, ages and genders.
   * To programmatically obtain the list of supported InfoTypes, use
   * ListInfoTypes with the supported_by=RISK_ANALYSIS filter.
   */
  infoType?:
    | InfoType
    | undefined;
  /**
   * A column can be tagged with a custom tag. In this case, the user must
   * indicate an auxiliary table that contains statistical information on
   * the possible values of this column (below).
   */
  customTag?:
    | string
    | undefined;
  /**
   * If no semantic tag is indicated, we infer the statistical model from
   * the distribution of values in the input data
   */
  inferred?: Empty | undefined;
}

/**
 * An auxiliary table containing statistical information on the relative
 * frequency of different quasi-identifiers values. It has one or several
 * quasi-identifiers columns, and one column that indicates the relative
 * frequency of each quasi-identifier tuple.
 * If a tuple is present in the data but not in the auxiliary table, the
 * corresponding relative frequency is assumed to be zero (and thus, the
 * tuple is highly reidentifiable).
 */
export interface StatisticalTable {
  /** Required. Auxiliary table location. */
  table:
    | BigQueryTable
    | undefined;
  /** Required. Quasi-identifier columns. */
  quasiIds: StatisticalTable_QuasiIdentifierField[];
  /**
   * Required. The relative frequency column must contain a floating-point
   * number between 0 and 1 (inclusive). Null values are assumed to be zero.
   */
  relativeFrequency: FieldId | undefined;
}

/**
 * A quasi-identifier column has a custom_tag, used to know which column
 * in the data corresponds to which column in the statistical model.
 */
export interface StatisticalTable_QuasiIdentifierField {
  /** Identifies the column. */
  field:
    | FieldId
    | undefined;
  /**
   * A column can be tagged with a custom tag. In this case, the user must
   * indicate an auxiliary table that contains statistical information on
   * the possible values of this column (below).
   */
  customTag: string;
}

/** Privacy metric to compute for reidentification risk analysis. */
export interface PrivacyMetric {
  /** Numerical stats */
  numericalStatsConfig?:
    | PrivacyMetric_NumericalStatsConfig
    | undefined;
  /** Categorical stats */
  categoricalStatsConfig?:
    | PrivacyMetric_CategoricalStatsConfig
    | undefined;
  /** K-anonymity */
  kAnonymityConfig?:
    | PrivacyMetric_KAnonymityConfig
    | undefined;
  /** l-diversity */
  lDiversityConfig?:
    | PrivacyMetric_LDiversityConfig
    | undefined;
  /** k-map */
  kMapEstimationConfig?:
    | PrivacyMetric_KMapEstimationConfig
    | undefined;
  /** delta-presence */
  deltaPresenceEstimationConfig?: PrivacyMetric_DeltaPresenceEstimationConfig | undefined;
}

/**
 * Compute numerical stats over an individual column, including
 * min, max, and quantiles.
 */
export interface PrivacyMetric_NumericalStatsConfig {
  /**
   * Field to compute numerical stats on. Supported types are
   * integer, float, date, datetime, timestamp, time.
   */
  field: FieldId | undefined;
}

/**
 * Compute numerical stats over an individual column, including
 * number of distinct values and value count distribution.
 */
export interface PrivacyMetric_CategoricalStatsConfig {
  /**
   * Field to compute categorical stats on. All column types are
   * supported except for arrays and structs. However, it may be more
   * informative to use NumericalStats when the field type is supported,
   * depending on the data.
   */
  field: FieldId | undefined;
}

/** k-anonymity metric, used for analysis of reidentification risk. */
export interface PrivacyMetric_KAnonymityConfig {
  /**
   * Set of fields to compute k-anonymity over. When multiple fields are
   * specified, they are considered a single composite key. Structs and
   * repeated data types are not supported; however, nested fields are
   * supported so long as they are not structs themselves or nested within
   * a repeated field.
   */
  quasiIds: FieldId[];
  /**
   * Message indicating that multiple rows might be associated to a
   * single individual. If the same entity_id is associated to multiple
   * quasi-identifier tuples over distinct rows, we consider the entire
   * collection of tuples as the composite quasi-identifier. This collection
   * is a multiset: the order in which the different tuples appear in the
   * dataset is ignored, but their frequency is taken into account.
   *
   * Important note: a maximum of 1000 rows can be associated to a single
   * entity ID. If more rows are associated with the same entity ID, some
   * might be ignored.
   */
  entityId: EntityId | undefined;
}

/** l-diversity metric, used for analysis of reidentification risk. */
export interface PrivacyMetric_LDiversityConfig {
  /**
   * Set of quasi-identifiers indicating how equivalence classes are
   * defined for the l-diversity computation. When multiple fields are
   * specified, they are considered a single composite key.
   */
  quasiIds: FieldId[];
  /** Sensitive field for computing the l-value. */
  sensitiveAttribute: FieldId | undefined;
}

/**
 * Reidentifiability metric. This corresponds to a risk model similar to what
 * is called "journalist risk" in the literature, except the attack dataset is
 * statistically modeled instead of being perfectly known. This can be done
 * using publicly available data (like the US Census), or using a custom
 * statistical model (indicated as one or several BigQuery tables), or by
 * extrapolating from the distribution of values in the input dataset.
 */
export interface PrivacyMetric_KMapEstimationConfig {
  /**
   * Required. Fields considered to be quasi-identifiers. No two columns can
   * have the same tag.
   */
  quasiIds: PrivacyMetric_KMapEstimationConfig_TaggedField[];
  /**
   * ISO 3166-1 alpha-2 region code to use in the statistical modeling.
   * Set if no column is tagged with a region-specific InfoType (like
   * US_ZIP_5) or a region code.
   */
  regionCode: string;
  /**
   * Several auxiliary tables can be used in the analysis. Each custom_tag
   * used to tag a quasi-identifiers column must appear in exactly one column
   * of one auxiliary table.
   */
  auxiliaryTables: PrivacyMetric_KMapEstimationConfig_AuxiliaryTable[];
}

/** A column with a semantic tag attached. */
export interface PrivacyMetric_KMapEstimationConfig_TaggedField {
  /** Required. Identifies the column. */
  field:
    | FieldId
    | undefined;
  /**
   * A column can be tagged with a InfoType to use the relevant public
   * dataset as a statistical model of population, if available. We
   * currently support US ZIP codes, region codes, ages and genders.
   * To programmatically obtain the list of supported InfoTypes, use
   * ListInfoTypes with the supported_by=RISK_ANALYSIS filter.
   */
  infoType?:
    | InfoType
    | undefined;
  /**
   * A column can be tagged with a custom tag. In this case, the user must
   * indicate an auxiliary table that contains statistical information on
   * the possible values of this column (below).
   */
  customTag?:
    | string
    | undefined;
  /**
   * If no semantic tag is indicated, we infer the statistical model from
   * the distribution of values in the input data
   */
  inferred?: Empty | undefined;
}

/**
 * An auxiliary table contains statistical information on the relative
 * frequency of different quasi-identifiers values. It has one or several
 * quasi-identifiers columns, and one column that indicates the relative
 * frequency of each quasi-identifier tuple.
 * If a tuple is present in the data but not in the auxiliary table, the
 * corresponding relative frequency is assumed to be zero (and thus, the
 * tuple is highly reidentifiable).
 */
export interface PrivacyMetric_KMapEstimationConfig_AuxiliaryTable {
  /** Required. Auxiliary table location. */
  table:
    | BigQueryTable
    | undefined;
  /** Required. Quasi-identifier columns. */
  quasiIds: PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField[];
  /**
   * Required. The relative frequency column must contain a floating-point
   * number between 0 and 1 (inclusive). Null values are assumed to be zero.
   */
  relativeFrequency: FieldId | undefined;
}

/**
 * A quasi-identifier column has a custom_tag, used to know which column
 * in the data corresponds to which column in the statistical model.
 */
export interface PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField {
  /** Identifies the column. */
  field:
    | FieldId
    | undefined;
  /** A auxiliary field. */
  customTag: string;
}

/**
 * -presence metric, used to estimate how likely it is for an attacker to
 * figure out that one given individual appears in a de-identified dataset.
 * Similarly to the k-map metric, we cannot compute -presence exactly without
 * knowing the attack dataset, so we use a statistical model instead.
 */
export interface PrivacyMetric_DeltaPresenceEstimationConfig {
  /**
   * Required. Fields considered to be quasi-identifiers. No two fields can
   * have the same tag.
   */
  quasiIds: QuasiId[];
  /**
   * ISO 3166-1 alpha-2 region code to use in the statistical modeling.
   * Set if no column is tagged with a region-specific InfoType (like
   * US_ZIP_5) or a region code.
   */
  regionCode: string;
  /**
   * Several auxiliary tables can be used in the analysis. Each custom_tag
   * used to tag a quasi-identifiers field must appear in exactly one
   * field of one auxiliary table.
   */
  auxiliaryTables: StatisticalTable[];
}

/** Result of a risk analysis operation request. */
export interface AnalyzeDataSourceRiskDetails {
  /** Privacy metric to compute. */
  requestedPrivacyMetric:
    | PrivacyMetric
    | undefined;
  /** Input dataset to compute metrics over. */
  requestedSourceTable:
    | BigQueryTable
    | undefined;
  /** Numerical stats result */
  numericalStatsResult?:
    | AnalyzeDataSourceRiskDetails_NumericalStatsResult
    | undefined;
  /** Categorical stats result */
  categoricalStatsResult?:
    | AnalyzeDataSourceRiskDetails_CategoricalStatsResult
    | undefined;
  /** K-anonymity result */
  kAnonymityResult?:
    | AnalyzeDataSourceRiskDetails_KAnonymityResult
    | undefined;
  /** L-divesity result */
  lDiversityResult?:
    | AnalyzeDataSourceRiskDetails_LDiversityResult
    | undefined;
  /** K-map result */
  kMapEstimationResult?:
    | AnalyzeDataSourceRiskDetails_KMapEstimationResult
    | undefined;
  /** Delta-presence result */
  deltaPresenceEstimationResult?:
    | AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult
    | undefined;
  /** The configuration used for this job. */
  requestedOptions: AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions | undefined;
}

/** Result of the numerical stats computation. */
export interface AnalyzeDataSourceRiskDetails_NumericalStatsResult {
  /** Minimum value appearing in the column. */
  minValue:
    | Value
    | undefined;
  /** Maximum value appearing in the column. */
  maxValue:
    | Value
    | undefined;
  /**
   * List of 99 values that partition the set of field values into 100 equal
   * sized buckets.
   */
  quantileValues: Value[];
}

/** Result of the categorical stats computation. */
export interface AnalyzeDataSourceRiskDetails_CategoricalStatsResult {
  /** Histogram of value frequencies in the column. */
  valueFrequencyHistogramBuckets: AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket[];
}

/** Histogram of value frequencies in the column. */
export interface AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket {
  /** Lower bound on the value frequency of the values in this bucket. */
  valueFrequencyLowerBound: Long;
  /** Upper bound on the value frequency of the values in this bucket. */
  valueFrequencyUpperBound: Long;
  /** Total number of values in this bucket. */
  bucketSize: Long;
  /**
   * Sample of value frequencies in this bucket. The total number of
   * values returned per bucket is capped at 20.
   */
  bucketValues: ValueFrequency[];
  /** Total number of distinct values in this bucket. */
  bucketValueCount: Long;
}

/** Result of the k-anonymity computation. */
export interface AnalyzeDataSourceRiskDetails_KAnonymityResult {
  /** Histogram of k-anonymity equivalence classes. */
  equivalenceClassHistogramBuckets: AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket[];
}

/** The set of columns' values that share the same ldiversity value */
export interface AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass {
  /**
   * Set of values defining the equivalence class. One value per
   * quasi-identifier column in the original KAnonymity metric message.
   * The order is always the same as the original request.
   */
  quasiIdsValues: Value[];
  /**
   * Size of the equivalence class, for example number of rows with the
   * above set of values.
   */
  equivalenceClassSize: Long;
}

/** Histogram of k-anonymity equivalence classes. */
export interface AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket {
  /** Lower bound on the size of the equivalence classes in this bucket. */
  equivalenceClassSizeLowerBound: Long;
  /** Upper bound on the size of the equivalence classes in this bucket. */
  equivalenceClassSizeUpperBound: Long;
  /** Total number of equivalence classes in this bucket. */
  bucketSize: Long;
  /**
   * Sample of equivalence classes in this bucket. The total number of
   * classes returned per bucket is capped at 20.
   */
  bucketValues: AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass[];
  /** Total number of distinct equivalence classes in this bucket. */
  bucketValueCount: Long;
}

/** Result of the l-diversity computation. */
export interface AnalyzeDataSourceRiskDetails_LDiversityResult {
  /** Histogram of l-diversity equivalence class sensitive value frequencies. */
  sensitiveValueFrequencyHistogramBuckets: AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket[];
}

/** The set of columns' values that share the same ldiversity value. */
export interface AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass {
  /**
   * Quasi-identifier values defining the k-anonymity equivalence
   * class. The order is always the same as the original request.
   */
  quasiIdsValues: Value[];
  /** Size of the k-anonymity equivalence class. */
  equivalenceClassSize: Long;
  /** Number of distinct sensitive values in this equivalence class. */
  numDistinctSensitiveValues: Long;
  /** Estimated frequencies of top sensitive values. */
  topSensitiveValues: ValueFrequency[];
}

/** Histogram of l-diversity equivalence class sensitive value frequencies. */
export interface AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket {
  /**
   * Lower bound on the sensitive value frequencies of the equivalence
   * classes in this bucket.
   */
  sensitiveValueFrequencyLowerBound: Long;
  /**
   * Upper bound on the sensitive value frequencies of the equivalence
   * classes in this bucket.
   */
  sensitiveValueFrequencyUpperBound: Long;
  /** Total number of equivalence classes in this bucket. */
  bucketSize: Long;
  /**
   * Sample of equivalence classes in this bucket. The total number of
   * classes returned per bucket is capped at 20.
   */
  bucketValues: AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass[];
  /** Total number of distinct equivalence classes in this bucket. */
  bucketValueCount: Long;
}

/**
 * Result of the reidentifiability analysis. Note that these results are an
 * estimation, not exact values.
 */
export interface AnalyzeDataSourceRiskDetails_KMapEstimationResult {
  /**
   * The intervals [min_anonymity, max_anonymity] do not overlap. If a value
   * doesn't correspond to any such interval, the associated frequency is
   * zero. For example, the following records:
   *   {min_anonymity: 1, max_anonymity: 1, frequency: 17}
   *   {min_anonymity: 2, max_anonymity: 3, frequency: 42}
   *   {min_anonymity: 5, max_anonymity: 10, frequency: 99}
   * mean that there are no record with an estimated anonymity of 4, 5, or
   * larger than 10.
   */
  kMapEstimationHistogram: AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket[];
}

/** A tuple of values for the quasi-identifier columns. */
export interface AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues {
  /** The quasi-identifier values. */
  quasiIdsValues: Value[];
  /** The estimated anonymity for these quasi-identifier values. */
  estimatedAnonymity: Long;
}

/**
 * A KMapEstimationHistogramBucket message with the following values:
 *   min_anonymity: 3
 *   max_anonymity: 5
 *   frequency: 42
 * means that there are 42 records whose quasi-identifier values correspond
 * to 3, 4 or 5 people in the overlying population. An important particular
 * case is when min_anonymity = max_anonymity = 1: the frequency field then
 * corresponds to the number of uniquely identifiable records.
 */
export interface AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket {
  /** Always positive. */
  minAnonymity: Long;
  /** Always greater than or equal to min_anonymity. */
  maxAnonymity: Long;
  /** Number of records within these anonymity bounds. */
  bucketSize: Long;
  /**
   * Sample of quasi-identifier tuple values in this bucket. The total
   * number of classes returned per bucket is capped at 20.
   */
  bucketValues: AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues[];
  /** Total number of distinct quasi-identifier tuple values in this bucket. */
  bucketValueCount: Long;
}

/**
 * Result of the -presence computation. Note that these results are an
 * estimation, not exact values.
 */
export interface AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult {
  /**
   * The intervals [min_probability, max_probability) do not overlap. If a
   * value doesn't correspond to any such interval, the associated frequency
   * is zero. For example, the following records:
   *   {min_probability: 0, max_probability: 0.1, frequency: 17}
   *   {min_probability: 0.2, max_probability: 0.3, frequency: 42}
   *   {min_probability: 0.3, max_probability: 0.4, frequency: 99}
   * mean that there are no record with an estimated probability in [0.1, 0.2)
   * nor larger or equal to 0.4.
   */
  deltaPresenceEstimationHistogram:
    AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket[];
}

/** A tuple of values for the quasi-identifier columns. */
export interface AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues {
  /** The quasi-identifier values. */
  quasiIdsValues: Value[];
  /**
   * The estimated probability that a given individual sharing these
   * quasi-identifier values is in the dataset. This value, typically
   * called , is the ratio between the number of records in the dataset
   * with these quasi-identifier values, and the total number of individuals
   * (inside *and* outside the dataset) with these quasi-identifier values.
   * For example, if there are 15 individuals in the dataset who share the
   * same quasi-identifier values, and an estimated 100 people in the entire
   * population with these values, then  is 0.15.
   */
  estimatedProbability: number;
}

/**
 * A DeltaPresenceEstimationHistogramBucket message with the following
 * values:
 *   min_probability: 0.1
 *   max_probability: 0.2
 *   frequency: 42
 * means that there are 42 records for which  is in [0.1, 0.2). An
 * important particular case is when min_probability = max_probability = 1:
 * then, every individual who shares this quasi-identifier combination is in
 * the dataset.
 */
export interface AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket {
  /** Between 0 and 1. */
  minProbability: number;
  /** Always greater than or equal to min_probability. */
  maxProbability: number;
  /** Number of records within these probability bounds. */
  bucketSize: Long;
  /**
   * Sample of quasi-identifier tuple values in this bucket. The total
   * number of classes returned per bucket is capped at 20.
   */
  bucketValues: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues[];
  /** Total number of distinct quasi-identifier tuple values in this bucket. */
  bucketValueCount: Long;
}

/** Risk analysis options. */
export interface AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions {
  /** The job config for the risk job. */
  jobConfig: RiskAnalysisJobConfig | undefined;
}

/** A value of a field, including its frequency. */
export interface ValueFrequency {
  /** A value contained in the field in question. */
  value:
    | Value
    | undefined;
  /** How many times the value is contained in the field. */
  count: Long;
}

/**
 * Set of primitive values supported by the system.
 * Note that for the purposes of inspection or transformation, the number
 * of bytes considered to comprise a 'Value' is based on its representation
 * as a UTF-8 encoded string. For example, if 'integer_value' is set to
 * 123456789, the number of bytes would be counted as 9, even though an
 * int64 only holds up to 8 bytes of data.
 */
export interface Value {
  /** integer */
  integerValue?:
    | Long
    | undefined;
  /** float */
  floatValue?:
    | number
    | undefined;
  /** string */
  stringValue?:
    | string
    | undefined;
  /** boolean */
  booleanValue?:
    | boolean
    | undefined;
  /** timestamp */
  timestampValue?:
    | Date
    | undefined;
  /** time of day */
  timeValue?:
    | TimeOfDay
    | undefined;
  /** date */
  dateValue?:
    | DateMessage
    | undefined;
  /** day of week */
  dayOfWeekValue?: DayOfWeek | undefined;
}

/** Message for infoType-dependent details parsed from quote. */
export interface QuoteInfo {
  /** The date time indicated by the quote. */
  dateTime?: DateTime | undefined;
}

/**
 * Message for a date time object.
 * e.g. 2018-01-01, 5th August.
 */
export interface DateTime {
  /**
   * One or more of the following must be set.
   * Must be a valid date or time value.
   */
  date:
    | DateMessage
    | undefined;
  /** Day of week */
  dayOfWeek: DayOfWeek;
  /** Time of day */
  time:
    | TimeOfDay
    | undefined;
  /** Time zone */
  timeZone: DateTime_TimeZone | undefined;
}

/** Time zone of the date time object. */
export interface DateTime_TimeZone {
  /**
   * Set only if the offset can be determined. Positive for time ahead of UTC.
   * E.g. For "UTC-9", this value is -540.
   */
  offsetMinutes: number;
}

/** The configuration that controls how the data will change. */
export interface DeidentifyConfig {
  /**
   * Treat the dataset as free-form text and apply the same free text
   * transformation everywhere.
   */
  infoTypeTransformations?:
    | InfoTypeTransformations
    | undefined;
  /**
   * Treat the dataset as structured. Transformations can be applied to
   * specific locations within structured datasets, such as transforming
   * a column within a table.
   */
  recordTransformations?:
    | RecordTransformations
    | undefined;
  /** Treat the dataset as an image and redact. */
  imageTransformations?:
    | ImageTransformations
    | undefined;
  /**
   * Mode for handling transformation errors. If left unspecified, the default
   * mode is `TransformationErrorHandling.ThrowError`.
   */
  transformationErrorHandling: TransformationErrorHandling | undefined;
}

/** A type of transformation that is applied over images. */
export interface ImageTransformations {
  /** List of transforms to make. */
  transforms: ImageTransformations_ImageTransformation[];
}

/** Configuration for determining how redaction of images should occur. */
export interface ImageTransformations_ImageTransformation {
  /** Apply transformation to the selected info_types. */
  selectedInfoTypes?:
    | ImageTransformations_ImageTransformation_SelectedInfoTypes
    | undefined;
  /**
   * Apply transformation to all findings not specified in other
   * ImageTransformation's selected_info_types. Only one instance is allowed
   * within the ImageTransformations message.
   */
  allInfoTypes?:
    | ImageTransformations_ImageTransformation_AllInfoTypes
    | undefined;
  /**
   * Apply transformation to all text that doesn't match an infoType. Only
   * one instance is allowed within the ImageTransformations message.
   */
  allText?:
    | ImageTransformations_ImageTransformation_AllText
    | undefined;
  /**
   * The color to use when redacting content from an image. If not
   * specified, the default is black.
   */
  redactionColor: Color | undefined;
}

/** Apply transformation to the selected info_types. */
export interface ImageTransformations_ImageTransformation_SelectedInfoTypes {
  /**
   * Required. InfoTypes to apply the transformation to. Required. Provided
   * InfoType must be unique within the ImageTransformations message.
   */
  infoTypes: InfoType[];
}

/** Apply transformation to all findings. */
export interface ImageTransformations_ImageTransformation_AllInfoTypes {
}

/** Apply to all text. */
export interface ImageTransformations_ImageTransformation_AllText {
}

/**
 * How to handle transformation errors during de-identification. A
 * transformation error occurs when the requested transformation is incompatible
 * with the data. For example, trying to de-identify an IP address using a
 * `DateShift` transformation would result in a transformation error, since date
 * info cannot be extracted from an IP address.
 * Information about any incompatible transformations, and how they were
 * handled, is returned in the response as part of the
 * `TransformationOverviews`.
 */
export interface TransformationErrorHandling {
  /** Throw an error */
  throwError?:
    | TransformationErrorHandling_ThrowError
    | undefined;
  /** Ignore errors */
  leaveUntransformed?: TransformationErrorHandling_LeaveUntransformed | undefined;
}

/** Throw an error and fail the request when a transformation error occurs. */
export interface TransformationErrorHandling_ThrowError {
}

/**
 * Skips the data without modifying it if the requested transformation would
 * cause an error. For example, if a `DateShift` transformation were applied
 * an an IP address, this mode would leave the IP address unchanged in the
 * response.
 */
export interface TransformationErrorHandling_LeaveUntransformed {
}

/** A rule for transforming a value. */
export interface PrimitiveTransformation {
  /** Replace with a specified value. */
  replaceConfig?:
    | ReplaceValueConfig
    | undefined;
  /** Redact */
  redactConfig?:
    | RedactConfig
    | undefined;
  /** Mask */
  characterMaskConfig?:
    | CharacterMaskConfig
    | undefined;
  /** Ffx-Fpe */
  cryptoReplaceFfxFpeConfig?:
    | CryptoReplaceFfxFpeConfig
    | undefined;
  /** Fixed size bucketing */
  fixedSizeBucketingConfig?:
    | FixedSizeBucketingConfig
    | undefined;
  /** Bucketing */
  bucketingConfig?:
    | BucketingConfig
    | undefined;
  /** Replace with infotype */
  replaceWithInfoTypeConfig?:
    | ReplaceWithInfoTypeConfig
    | undefined;
  /** Time extraction */
  timePartConfig?:
    | TimePartConfig
    | undefined;
  /** Crypto */
  cryptoHashConfig?:
    | CryptoHashConfig
    | undefined;
  /** Date Shift */
  dateShiftConfig?:
    | DateShiftConfig
    | undefined;
  /** Deterministic Crypto */
  cryptoDeterministicConfig?:
    | CryptoDeterministicConfig
    | undefined;
  /** Replace with a value randomly drawn (with replacement) from a dictionary. */
  replaceDictionaryConfig?: ReplaceDictionaryConfig | undefined;
}

/**
 * For use with `Date`, `Timestamp`, and `TimeOfDay`, extract or preserve a
 * portion of the value.
 */
export interface TimePartConfig {
  /** The part of the time to keep. */
  partToExtract: TimePartConfig_TimePart;
}

/** Components that make up time. */
export enum TimePartConfig_TimePart {
  /** TIME_PART_UNSPECIFIED - Unused */
  TIME_PART_UNSPECIFIED = 0,
  /** YEAR - [0-9999] */
  YEAR = 1,
  /** MONTH - [1-12] */
  MONTH = 2,
  /** DAY_OF_MONTH - [1-31] */
  DAY_OF_MONTH = 3,
  /** DAY_OF_WEEK - [1-7] */
  DAY_OF_WEEK = 4,
  /** WEEK_OF_YEAR - [1-53] */
  WEEK_OF_YEAR = 5,
  /** HOUR_OF_DAY - [0-23] */
  HOUR_OF_DAY = 6,
  UNRECOGNIZED = -1,
}

export function timePartConfig_TimePartFromJSON(object: any): TimePartConfig_TimePart {
  switch (object) {
    case 0:
    case "TIME_PART_UNSPECIFIED":
      return TimePartConfig_TimePart.TIME_PART_UNSPECIFIED;
    case 1:
    case "YEAR":
      return TimePartConfig_TimePart.YEAR;
    case 2:
    case "MONTH":
      return TimePartConfig_TimePart.MONTH;
    case 3:
    case "DAY_OF_MONTH":
      return TimePartConfig_TimePart.DAY_OF_MONTH;
    case 4:
    case "DAY_OF_WEEK":
      return TimePartConfig_TimePart.DAY_OF_WEEK;
    case 5:
    case "WEEK_OF_YEAR":
      return TimePartConfig_TimePart.WEEK_OF_YEAR;
    case 6:
    case "HOUR_OF_DAY":
      return TimePartConfig_TimePart.HOUR_OF_DAY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TimePartConfig_TimePart.UNRECOGNIZED;
  }
}

export function timePartConfig_TimePartToJSON(object: TimePartConfig_TimePart): string {
  switch (object) {
    case TimePartConfig_TimePart.TIME_PART_UNSPECIFIED:
      return "TIME_PART_UNSPECIFIED";
    case TimePartConfig_TimePart.YEAR:
      return "YEAR";
    case TimePartConfig_TimePart.MONTH:
      return "MONTH";
    case TimePartConfig_TimePart.DAY_OF_MONTH:
      return "DAY_OF_MONTH";
    case TimePartConfig_TimePart.DAY_OF_WEEK:
      return "DAY_OF_WEEK";
    case TimePartConfig_TimePart.WEEK_OF_YEAR:
      return "WEEK_OF_YEAR";
    case TimePartConfig_TimePart.HOUR_OF_DAY:
      return "HOUR_OF_DAY";
    case TimePartConfig_TimePart.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Pseudonymization method that generates surrogates via cryptographic hashing.
 * Uses SHA-256.
 * The key size must be either 32 or 64 bytes.
 * Outputs a base64 encoded representation of the hashed output
 * (for example, L7k0BHmF1ha5U3NfGykjro4xWi1MPVQPjhMAZbSV9mM=).
 * Currently, only string and integer values can be hashed.
 * See https://cloud.google.com/sensitive-data-protection/docs/pseudonymization
 * to learn more.
 */
export interface CryptoHashConfig {
  /** The key used by the hash function. */
  cryptoKey: CryptoKey | undefined;
}

/**
 * Pseudonymization method that generates deterministic encryption for the given
 * input. Outputs a base64 encoded representation of the encrypted output.
 * Uses AES-SIV based on the RFC https://tools.ietf.org/html/rfc5297.
 */
export interface CryptoDeterministicConfig {
  /**
   * The key used by the encryption function. For deterministic encryption
   * using AES-SIV, the provided key is internally expanded to 64 bytes prior to
   * use.
   */
  cryptoKey:
    | CryptoKey
    | undefined;
  /**
   * The custom info type to annotate the surrogate with.
   * This annotation will be applied to the surrogate by prefixing it with
   * the name of the custom info type followed by the number of
   * characters comprising the surrogate. The following scheme defines the
   * format: {info type name}({surrogate character count}):{surrogate}
   *
   * For example, if the name of custom info type is 'MY_TOKEN_INFO_TYPE' and
   * the surrogate is 'abc', the full replacement value
   * will be: 'MY_TOKEN_INFO_TYPE(3):abc'
   *
   * This annotation identifies the surrogate when inspecting content using the
   * custom info type 'Surrogate'. This facilitates reversal of the
   * surrogate when it occurs in free text.
   *
   * Note: For record transformations where the entire cell in a table is being
   * transformed, surrogates are not mandatory. Surrogates are used to denote
   * the location of the token and are necessary for re-identification in free
   * form text.
   *
   * In order for inspection to work properly, the name of this info type must
   * not occur naturally anywhere in your data; otherwise, inspection may either
   *
   * - reverse a surrogate that does not correspond to an actual identifier
   * - be unable to parse the surrogate and result in an error
   *
   * Therefore, choose your custom info type name carefully after considering
   * what your data looks like. One way to select a name that has a high chance
   * of yielding reliable detection is to include one or more unicode characters
   * that are highly improbable to exist in your data.
   * For example, assuming your data is entered from a regular ASCII keyboard,
   * the symbol with the hex code point 29DD might be used like so:
   * MY_TOKEN_TYPE.
   */
  surrogateInfoType:
    | InfoType
    | undefined;
  /**
   * A context may be used for higher security and maintaining
   * referential integrity such that the same identifier in two different
   * contexts will be given a distinct surrogate. The context is appended to
   * plaintext value being encrypted. On decryption the provided context is
   * validated against the value used during encryption. If a context was
   * provided during encryption, same context must be provided during decryption
   * as well.
   *
   * If the context is not set, plaintext would be used as is for encryption.
   * If the context is set but:
   *
   * 1. there is no record present when transforming a given value or
   * 2. the field is not present when transforming a given value,
   *
   * plaintext would be used as is for encryption.
   *
   * Note that case (1) is expected when an `InfoTypeTransformation` is
   * applied to both structured and unstructured `ContentItem`s.
   */
  context: FieldId | undefined;
}

/** Replace each input value with a given `Value`. */
export interface ReplaceValueConfig {
  /** Value to replace it with. */
  newValue: Value | undefined;
}

/** Replace each input value with a value randomly selected from the dictionary. */
export interface ReplaceDictionaryConfig {
  /**
   * A list of words to select from for random replacement. The
   * [limits](https://cloud.google.com/sensitive-data-protection/limits) page
   * contains details about the size limits of dictionaries.
   */
  wordList?: CustomInfoType_Dictionary_WordList | undefined;
}

/** Replace each matching finding with the name of the info_type. */
export interface ReplaceWithInfoTypeConfig {
}

/**
 * Redact a given value. For example, if used with an `InfoTypeTransformation`
 * transforming PHONE_NUMBER, and input 'My phone number is 206-555-0123', the
 * output would be 'My phone number is '.
 */
export interface RedactConfig {
}

/**
 * Characters to skip when doing deidentification of a value. These will be left
 * alone and skipped.
 */
export interface CharsToIgnore {
  /** Characters to not transform when masking. */
  charactersToSkip?:
    | string
    | undefined;
  /**
   * Common characters to not transform when masking. Useful to avoid removing
   * punctuation.
   */
  commonCharactersToIgnore?: CharsToIgnore_CommonCharsToIgnore | undefined;
}

/** Convenience enum for indicating common characters to not transform. */
export enum CharsToIgnore_CommonCharsToIgnore {
  /** COMMON_CHARS_TO_IGNORE_UNSPECIFIED - Unused. */
  COMMON_CHARS_TO_IGNORE_UNSPECIFIED = 0,
  /** NUMERIC - 0-9 */
  NUMERIC = 1,
  /** ALPHA_UPPER_CASE - A-Z */
  ALPHA_UPPER_CASE = 2,
  /** ALPHA_LOWER_CASE - a-z */
  ALPHA_LOWER_CASE = 3,
  /** PUNCTUATION - US Punctuation, one of !"#$%&'()*+,-./:;<=>?@[\]^_`{|}~ */
  PUNCTUATION = 4,
  /** WHITESPACE - Whitespace character, one of [ \t\n\x0B\f\r] */
  WHITESPACE = 5,
  UNRECOGNIZED = -1,
}

export function charsToIgnore_CommonCharsToIgnoreFromJSON(object: any): CharsToIgnore_CommonCharsToIgnore {
  switch (object) {
    case 0:
    case "COMMON_CHARS_TO_IGNORE_UNSPECIFIED":
      return CharsToIgnore_CommonCharsToIgnore.COMMON_CHARS_TO_IGNORE_UNSPECIFIED;
    case 1:
    case "NUMERIC":
      return CharsToIgnore_CommonCharsToIgnore.NUMERIC;
    case 2:
    case "ALPHA_UPPER_CASE":
      return CharsToIgnore_CommonCharsToIgnore.ALPHA_UPPER_CASE;
    case 3:
    case "ALPHA_LOWER_CASE":
      return CharsToIgnore_CommonCharsToIgnore.ALPHA_LOWER_CASE;
    case 4:
    case "PUNCTUATION":
      return CharsToIgnore_CommonCharsToIgnore.PUNCTUATION;
    case 5:
    case "WHITESPACE":
      return CharsToIgnore_CommonCharsToIgnore.WHITESPACE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CharsToIgnore_CommonCharsToIgnore.UNRECOGNIZED;
  }
}

export function charsToIgnore_CommonCharsToIgnoreToJSON(object: CharsToIgnore_CommonCharsToIgnore): string {
  switch (object) {
    case CharsToIgnore_CommonCharsToIgnore.COMMON_CHARS_TO_IGNORE_UNSPECIFIED:
      return "COMMON_CHARS_TO_IGNORE_UNSPECIFIED";
    case CharsToIgnore_CommonCharsToIgnore.NUMERIC:
      return "NUMERIC";
    case CharsToIgnore_CommonCharsToIgnore.ALPHA_UPPER_CASE:
      return "ALPHA_UPPER_CASE";
    case CharsToIgnore_CommonCharsToIgnore.ALPHA_LOWER_CASE:
      return "ALPHA_LOWER_CASE";
    case CharsToIgnore_CommonCharsToIgnore.PUNCTUATION:
      return "PUNCTUATION";
    case CharsToIgnore_CommonCharsToIgnore.WHITESPACE:
      return "WHITESPACE";
    case CharsToIgnore_CommonCharsToIgnore.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Partially mask a string by replacing a given number of characters with a
 * fixed character. Masking can start from the beginning or end of the string.
 * This can be used on data of any type (numbers, longs, and so on) and when
 * de-identifying structured data we'll attempt to preserve the original data's
 * type. (This allows you to take a long like 123 and modify it to a string like
 * **3.
 */
export interface CharacterMaskConfig {
  /**
   * Character to use to mask the sensitive values&mdash;for example, `*` for an
   * alphabetic string such as a name, or `0` for a numeric string such as ZIP
   * code or credit card number. This string must have a length of 1. If not
   * supplied, this value defaults to `*` for strings, and `0` for digits.
   */
  maskingCharacter: string;
  /**
   * Number of characters to mask. If not set, all matching chars will be
   * masked. Skipped characters do not count towards this tally.
   *
   * If `number_to_mask` is negative, this denotes inverse masking. Cloud DLP
   * masks all but a number of characters.
   * For example, suppose you have the following values:
   *
   * - `masking_character` is `*`
   * - `number_to_mask` is `-4`
   * - `reverse_order` is `false`
   * - `CharsToIgnore` includes `-`
   * - Input string is `1234-5678-9012-3456`
   *
   * The resulting de-identified string is
   * `****-****-****-3456`. Cloud DLP masks all but the last four characters.
   * If `reverse_order` is `true`, all but the first four characters are masked
   * as `1234-****-****-****`.
   */
  numberToMask: number;
  /**
   * Mask characters in reverse order. For example, if `masking_character` is
   * `0`, `number_to_mask` is `14`, and `reverse_order` is `false`, then the
   * input string `1234-5678-9012-3456` is masked as `00000000000000-3456`.
   * If `masking_character` is `*`, `number_to_mask` is `3`, and `reverse_order`
   * is `true`, then the string `12345` is masked as `12***`.
   */
  reverseOrder: boolean;
  /**
   * When masking a string, items in this list will be skipped when replacing
   * characters. For example, if the input string is `555-555-5555` and you
   * instruct Cloud DLP to skip `-` and mask 5 characters with `*`, Cloud DLP
   * returns `***-**5-5555`.
   */
  charactersToIgnore: CharsToIgnore[];
}

/**
 * Buckets values based on fixed size ranges. The
 * Bucketing transformation can provide all of this functionality,
 * but requires more configuration. This message is provided as a convenience to
 * the user for simple bucketing strategies.
 *
 * The transformed value will be a hyphenated string of
 * {lower_bound}-{upper_bound}. For example, if lower_bound = 10 and upper_bound
 * = 20, all values that are within this bucket will be replaced with "10-20".
 *
 * This can be used on data of type: double, long.
 *
 * If the bound Value type differs from the type of data
 * being transformed, we will first attempt converting the type of the data to
 * be transformed to match the type of the bound before comparing.
 *
 * See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-bucketing to
 * learn more.
 */
export interface FixedSizeBucketingConfig {
  /**
   * Required. Lower bound value of buckets. All values less than `lower_bound`
   * are grouped together into a single bucket; for example if `lower_bound` =
   * 10, then all values less than 10 are replaced with the value "-10".
   */
  lowerBound:
    | Value
    | undefined;
  /**
   * Required. Upper bound value of buckets. All values greater than upper_bound
   * are grouped together into a single bucket; for example if `upper_bound` =
   * 89, then all values greater than 89 are replaced with the value "89+".
   */
  upperBound:
    | Value
    | undefined;
  /**
   * Required. Size of each bucket (except for minimum and maximum buckets). So
   * if `lower_bound` = 10, `upper_bound` = 89, and `bucket_size` = 10, then the
   * following buckets would be used: -10, 10-20, 20-30, 30-40, 40-50, 50-60,
   * 60-70, 70-80, 80-89, 89+. Precision up to 2 decimals works.
   */
  bucketSize: number;
}

/**
 * Generalization function that buckets values based on ranges. The ranges and
 * replacement values are dynamically provided by the user for custom behavior,
 * such as 1-30 -> LOW, 31-65 -> MEDIUM, 66-100 -> HIGH.
 *
 * This can be used on data of type: number, long, string, timestamp.
 *
 * If the bound `Value` type differs from the type of data being transformed, we
 * will first attempt converting the type of the data to be transformed to match
 * the type of the bound before comparing.
 * See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-bucketing to
 * learn more.
 */
export interface BucketingConfig {
  /** Set of buckets. Ranges must be non-overlapping. */
  buckets: BucketingConfig_Bucket[];
}

/** Bucket is represented as a range, along with replacement values. */
export interface BucketingConfig_Bucket {
  /**
   * Lower bound of the range, inclusive. Type should be the same as max if
   * used.
   */
  min:
    | Value
    | undefined;
  /** Upper bound of the range, exclusive; type must match min. */
  max:
    | Value
    | undefined;
  /** Required. Replacement value for this bucket. */
  replacementValue: Value | undefined;
}

/**
 * Replaces an identifier with a surrogate using Format Preserving Encryption
 * (FPE) with the FFX mode of operation; however when used in the
 * `ReidentifyContent` API method, it serves the opposite function by reversing
 * the surrogate back into the original identifier. The identifier must be
 * encoded as ASCII. For a given crypto key and context, the same identifier
 * will be replaced with the same surrogate. Identifiers must be at least two
 * characters long. In the case that the identifier is the empty string, it will
 * be skipped. See
 * https://cloud.google.com/sensitive-data-protection/docs/pseudonymization to
 * learn more.
 *
 * Note: We recommend using  CryptoDeterministicConfig for all use cases which
 * do not require preserving the input alphabet space and size, plus warrant
 * referential integrity.
 */
export interface CryptoReplaceFfxFpeConfig {
  /** Required. The key used by the encryption algorithm. */
  cryptoKey:
    | CryptoKey
    | undefined;
  /**
   * The 'tweak', a context may be used for higher security since the same
   * identifier in two different contexts won't be given the same surrogate. If
   * the context is not set, a default tweak will be used.
   *
   * If the context is set but:
   *
   * 1. there is no record present when transforming a given value or
   * 1. the field is not present when transforming a given value,
   *
   * a default tweak will be used.
   *
   * Note that case (1) is expected when an `InfoTypeTransformation` is
   * applied to both structured and unstructured `ContentItem`s.
   * Currently, the referenced field may be of value type integer or string.
   *
   * The tweak is constructed as a sequence of bytes in big endian byte order
   * such that:
   *
   * - a 64 bit integer is encoded followed by a single byte of value 1
   * - a string is encoded in UTF-8 format followed by a single byte of value 2
   */
  context:
    | FieldId
    | undefined;
  /** Common alphabets. */
  commonAlphabet?:
    | CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet
    | undefined;
  /**
   * This is supported by mapping these to the alphanumeric characters
   * that the FFX mode natively supports. This happens before/after
   * encryption/decryption.
   * Each character listed must appear only once.
   * Number of characters must be in the range [2, 95].
   * This must be encoded as ASCII.
   * The order of characters does not matter.
   * The full list of allowed characters is:
   * ``0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz~`!@#$%^&*()_-+={[}]|\:;"'<,>.?/``
   */
  customAlphabet?:
    | string
    | undefined;
  /** The native way to select the alphabet. Must be in the range [2, 95]. */
  radix?:
    | number
    | undefined;
  /**
   * The custom infoType to annotate the surrogate with.
   * This annotation will be applied to the surrogate by prefixing it with
   * the name of the custom infoType followed by the number of
   * characters comprising the surrogate. The following scheme defines the
   * format: info_type_name(surrogate_character_count):surrogate
   *
   * For example, if the name of custom infoType is 'MY_TOKEN_INFO_TYPE' and
   * the surrogate is 'abc', the full replacement value
   * will be: 'MY_TOKEN_INFO_TYPE(3):abc'
   *
   * This annotation identifies the surrogate when inspecting content using the
   * custom infoType
   * [`SurrogateType`](https://cloud.google.com/sensitive-data-protection/docs/reference/rest/v2/InspectConfig#surrogatetype).
   * This facilitates reversal of the surrogate when it occurs in free text.
   *
   * In order for inspection to work properly, the name of this infoType must
   * not occur naturally anywhere in your data; otherwise, inspection may
   * find a surrogate that does not correspond to an actual identifier.
   * Therefore, choose your custom infoType name carefully after considering
   * what your data looks like. One way to select a name that has a high chance
   * of yielding reliable detection is to include one or more unicode characters
   * that are highly improbable to exist in your data.
   * For example, assuming your data is entered from a regular ASCII keyboard,
   * the symbol with the hex code point 29DD might be used like so:
   * MY_TOKEN_TYPE
   */
  surrogateInfoType: InfoType | undefined;
}

/**
 * These are commonly used subsets of the alphabet that the FFX mode
 * natively supports. In the algorithm, the alphabet is selected using
 * the "radix". Therefore each corresponds to a particular radix.
 */
export enum CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet {
  /** FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED - Unused. */
  FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED = 0,
  /** NUMERIC - `[0-9]` (radix of 10) */
  NUMERIC = 1,
  /** HEXADECIMAL - `[0-9A-F]` (radix of 16) */
  HEXADECIMAL = 2,
  /** UPPER_CASE_ALPHA_NUMERIC - `[0-9A-Z]` (radix of 36) */
  UPPER_CASE_ALPHA_NUMERIC = 3,
  /** ALPHA_NUMERIC - `[0-9A-Za-z]` (radix of 62) */
  ALPHA_NUMERIC = 4,
  UNRECOGNIZED = -1,
}

export function cryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabetFromJSON(
  object: any,
): CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet {
  switch (object) {
    case 0:
    case "FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED":
      return CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED;
    case 1:
    case "NUMERIC":
      return CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.NUMERIC;
    case 2:
    case "HEXADECIMAL":
      return CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.HEXADECIMAL;
    case 3:
    case "UPPER_CASE_ALPHA_NUMERIC":
      return CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.UPPER_CASE_ALPHA_NUMERIC;
    case 4:
    case "ALPHA_NUMERIC":
      return CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.ALPHA_NUMERIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.UNRECOGNIZED;
  }
}

export function cryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabetToJSON(
  object: CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet,
): string {
  switch (object) {
    case CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED:
      return "FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED";
    case CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.NUMERIC:
      return "NUMERIC";
    case CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.HEXADECIMAL:
      return "HEXADECIMAL";
    case CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.UPPER_CASE_ALPHA_NUMERIC:
      return "UPPER_CASE_ALPHA_NUMERIC";
    case CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.ALPHA_NUMERIC:
      return "ALPHA_NUMERIC";
    case CryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabet.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * This is a data encryption key (DEK) (as opposed to
 * a key encryption key (KEK) stored by Cloud Key Management Service
 * (Cloud KMS).
 * When using Cloud KMS to wrap or unwrap a DEK, be sure to set an appropriate
 * IAM policy on the KEK to ensure an attacker cannot
 * unwrap the DEK.
 */
export interface CryptoKey {
  /** Transient crypto key */
  transient?:
    | TransientCryptoKey
    | undefined;
  /** Unwrapped crypto key */
  unwrapped?:
    | UnwrappedCryptoKey
    | undefined;
  /** Key wrapped using Cloud KMS */
  kmsWrapped?: KmsWrappedCryptoKey | undefined;
}

/**
 * Use this to have a random data crypto key generated.
 * It will be discarded after the request finishes.
 */
export interface TransientCryptoKey {
  /**
   * Required. Name of the key.
   * This is an arbitrary string used to differentiate different keys.
   * A unique key is generated per name: two separate `TransientCryptoKey`
   * protos share the same generated key if their names are the same.
   * When the data crypto key is generated, this name is not used in any way
   * (repeating the api call will result in a different key being generated).
   */
  name: string;
}

/**
 * Using raw keys is prone to security risks due to accidentally
 * leaking the key. Choose another type of key if possible.
 */
export interface UnwrappedCryptoKey {
  /** Required. A 128/192/256 bit key. */
  key: Buffer;
}

/**
 * Include to use an existing data crypto key wrapped by KMS.
 * The wrapped key must be a 128-, 192-, or 256-bit key.
 * Authorization requires the following IAM permissions when sending a request
 * to perform a crypto transformation using a KMS-wrapped crypto key:
 * dlp.kms.encrypt
 *
 * For more information, see [Creating a wrapped key]
 * (https://cloud.google.com/sensitive-data-protection/docs/create-wrapped-key).
 *
 * Note: When you use Cloud KMS for cryptographic operations,
 * [charges apply](https://cloud.google.com/kms/pricing).
 */
export interface KmsWrappedCryptoKey {
  /** Required. The wrapped data crypto key. */
  wrappedKey: Buffer;
  /** Required. The resource name of the KMS CryptoKey to use for unwrapping. */
  cryptoKeyName: string;
}

/**
 * Shifts dates by random number of days, with option to be consistent for the
 * same context. See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-date-shifting
 * to learn more.
 */
export interface DateShiftConfig {
  /**
   * Required. Range of shift in days. Actual shift will be selected at random
   * within this range (inclusive ends). Negative means shift to earlier in
   * time. Must not be more than 365250 days (1000 years) each direction.
   *
   * For example, 3 means shift date to at most 3 days into the future.
   */
  upperBoundDays: number;
  /**
   * Required. For example, -5 means shift date to at most 5 days back in the
   * past.
   */
  lowerBoundDays: number;
  /**
   * Points to the field that contains the context, for example, an entity id.
   * If set, must also set cryptoKey. If set, shift will be consistent for the
   * given context.
   */
  context:
    | FieldId
    | undefined;
  /**
   * Causes the shift to be computed based on this key and the context. This
   * results in the same shift for the same context and crypto_key. If
   * set, must also set context. Can only be applied to table items.
   */
  cryptoKey?: CryptoKey | undefined;
}

/**
 * A type of transformation that will scan unstructured text and
 * apply various `PrimitiveTransformation`s to each finding, where the
 * transformation is applied to only values that were identified as a specific
 * info_type.
 */
export interface InfoTypeTransformations {
  /**
   * Required. Transformation for each infoType. Cannot specify more than one
   * for a given infoType.
   */
  transformations: InfoTypeTransformations_InfoTypeTransformation[];
}

/**
 * A transformation to apply to text that is identified as a specific
 * info_type.
 */
export interface InfoTypeTransformations_InfoTypeTransformation {
  /**
   * InfoTypes to apply the transformation to. An empty list will cause
   * this transformation to apply to all findings that correspond to
   * infoTypes that were requested in `InspectConfig`.
   */
  infoTypes: InfoType[];
  /** Required. Primitive transformation to apply to the infoType. */
  primitiveTransformation: PrimitiveTransformation | undefined;
}

/** The transformation to apply to the field. */
export interface FieldTransformation {
  /**
   * Required. Input field(s) to apply the transformation to.
   * When you have columns that reference their position within a list,
   * omit the index from the FieldId. FieldId name matching ignores the index.
   * For example, instead of "contact.nums[0].type", use "contact.nums.type".
   */
  fields: FieldId[];
  /**
   * Only apply the transformation if the condition evaluates to true for the
   * given `RecordCondition`. The conditions are allowed to reference fields
   * that are not used in the actual transformation.
   *
   * Example Use Cases:
   *
   * - Apply a different bucket transformation to an age column if the zip code
   * column for the same record is within a specific range.
   * - Redact a field if the date of birth field is greater than 85.
   */
  condition:
    | RecordCondition
    | undefined;
  /** Apply the transformation to the entire field. */
  primitiveTransformation?:
    | PrimitiveTransformation
    | undefined;
  /**
   * Treat the contents of the field as free text, and selectively
   * transform content that matches an `InfoType`.
   */
  infoTypeTransformations?: InfoTypeTransformations | undefined;
}

/**
 * A type of transformation that is applied over structured data such as a
 * table.
 */
export interface RecordTransformations {
  /** Transform the record by applying various field transformations. */
  fieldTransformations: FieldTransformation[];
  /**
   * Configuration defining which records get suppressed entirely. Records that
   * match any suppression rule are omitted from the output.
   */
  recordSuppressions: RecordSuppression[];
}

/**
 * Configuration to suppress records whose suppression conditions evaluate to
 * true.
 */
export interface RecordSuppression {
  /**
   * A condition that when it evaluates to true will result in the record being
   * evaluated to be suppressed from the transformed content.
   */
  condition: RecordCondition | undefined;
}

/**
 * A condition for determining whether a transformation should be applied to
 * a field.
 */
export interface RecordCondition {
  /** An expression. */
  expressions: RecordCondition_Expressions | undefined;
}

/**
 * The field type of `value` and `field` do not need to match to be
 * considered equal, but not all comparisons are possible.
 * EQUAL_TO and NOT_EQUAL_TO attempt to compare even with incompatible types,
 * but all other comparisons are invalid with incompatible types.
 * A `value` of type:
 *
 * - `string` can be compared against all other types
 * - `boolean` can only be compared against other booleans
 * - `integer` can be compared against doubles or a string if the string value
 * can be parsed as an integer.
 * - `double` can be compared against integers or a string if the string can
 * be parsed as a double.
 * - `Timestamp` can be compared against strings in RFC 3339 date string
 * format.
 * - `TimeOfDay` can be compared against timestamps and strings in the format
 * of 'HH:mm:ss'.
 *
 * If we fail to compare do to type mismatch, a warning will be given and
 * the condition will evaluate to false.
 */
export interface RecordCondition_Condition {
  /** Required. Field within the record this condition is evaluated against. */
  field:
    | FieldId
    | undefined;
  /** Required. Operator used to compare the field or infoType to the value. */
  operator: RelationalOperator;
  /** Value to compare against. [Mandatory, except for `EXISTS` tests.] */
  value: Value | undefined;
}

/** A collection of conditions. */
export interface RecordCondition_Conditions {
  /** A collection of conditions. */
  conditions: RecordCondition_Condition[];
}

/** An expression, consisting of an operator and conditions. */
export interface RecordCondition_Expressions {
  /**
   * The operator to apply to the result of conditions. Default and currently
   * only supported value is `AND`.
   */
  logicalOperator: RecordCondition_Expressions_LogicalOperator;
  /** Conditions to apply to the expression. */
  conditions?: RecordCondition_Conditions | undefined;
}

/** Logical operators for conditional checks. */
export enum RecordCondition_Expressions_LogicalOperator {
  /** LOGICAL_OPERATOR_UNSPECIFIED - Unused */
  LOGICAL_OPERATOR_UNSPECIFIED = 0,
  /** AND - Conditional AND */
  AND = 1,
  UNRECOGNIZED = -1,
}

export function recordCondition_Expressions_LogicalOperatorFromJSON(
  object: any,
): RecordCondition_Expressions_LogicalOperator {
  switch (object) {
    case 0:
    case "LOGICAL_OPERATOR_UNSPECIFIED":
      return RecordCondition_Expressions_LogicalOperator.LOGICAL_OPERATOR_UNSPECIFIED;
    case 1:
    case "AND":
      return RecordCondition_Expressions_LogicalOperator.AND;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RecordCondition_Expressions_LogicalOperator.UNRECOGNIZED;
  }
}

export function recordCondition_Expressions_LogicalOperatorToJSON(
  object: RecordCondition_Expressions_LogicalOperator,
): string {
  switch (object) {
    case RecordCondition_Expressions_LogicalOperator.LOGICAL_OPERATOR_UNSPECIFIED:
      return "LOGICAL_OPERATOR_UNSPECIFIED";
    case RecordCondition_Expressions_LogicalOperator.AND:
      return "AND";
    case RecordCondition_Expressions_LogicalOperator.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Overview of the modifications that occurred. */
export interface TransformationOverview {
  /** Total size in bytes that were transformed in some way. */
  transformedBytes: Long;
  /** Transformations applied to the dataset. */
  transformationSummaries: TransformationSummary[];
}

/**
 * Summary of a single transformation.
 * Only one of 'transformation', 'field_transformation', or 'record_suppress'
 * will be set.
 */
export interface TransformationSummary {
  /** Set if the transformation was limited to a specific InfoType. */
  infoType:
    | InfoType
    | undefined;
  /** Set if the transformation was limited to a specific FieldId. */
  field:
    | FieldId
    | undefined;
  /** The specific transformation these stats apply to. */
  transformation:
    | PrimitiveTransformation
    | undefined;
  /**
   * The field transformation that was applied.
   * If multiple field transformations are requested for a single field,
   * this list will contain all of them; otherwise, only one is supplied.
   */
  fieldTransformations: FieldTransformation[];
  /** The specific suppression option these stats apply to. */
  recordSuppress:
    | RecordSuppression
    | undefined;
  /** Collection of all transformations that took place or had an error. */
  results: TransformationSummary_SummaryResult[];
  /** Total size in bytes that were transformed in some way. */
  transformedBytes: Long;
}

/** Possible outcomes of transformations. */
export enum TransformationSummary_TransformationResultCode {
  /** TRANSFORMATION_RESULT_CODE_UNSPECIFIED - Unused */
  TRANSFORMATION_RESULT_CODE_UNSPECIFIED = 0,
  /** SUCCESS - Transformation completed without an error. */
  SUCCESS = 1,
  /** ERROR - Transformation had an error. */
  ERROR = 2,
  UNRECOGNIZED = -1,
}

export function transformationSummary_TransformationResultCodeFromJSON(
  object: any,
): TransformationSummary_TransformationResultCode {
  switch (object) {
    case 0:
    case "TRANSFORMATION_RESULT_CODE_UNSPECIFIED":
      return TransformationSummary_TransformationResultCode.TRANSFORMATION_RESULT_CODE_UNSPECIFIED;
    case 1:
    case "SUCCESS":
      return TransformationSummary_TransformationResultCode.SUCCESS;
    case 2:
    case "ERROR":
      return TransformationSummary_TransformationResultCode.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TransformationSummary_TransformationResultCode.UNRECOGNIZED;
  }
}

export function transformationSummary_TransformationResultCodeToJSON(
  object: TransformationSummary_TransformationResultCode,
): string {
  switch (object) {
    case TransformationSummary_TransformationResultCode.TRANSFORMATION_RESULT_CODE_UNSPECIFIED:
      return "TRANSFORMATION_RESULT_CODE_UNSPECIFIED";
    case TransformationSummary_TransformationResultCode.SUCCESS:
      return "SUCCESS";
    case TransformationSummary_TransformationResultCode.ERROR:
      return "ERROR";
    case TransformationSummary_TransformationResultCode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A collection that informs the user the number of times a particular
 * `TransformationResultCode` and error details occurred.
 */
export interface TransformationSummary_SummaryResult {
  /** Number of transformations counted by this result. */
  count: Long;
  /** Outcome of the transformation. */
  code: TransformationSummary_TransformationResultCode;
  /**
   * A place for warnings or errors to show up if a transformation didn't
   * work as expected.
   */
  details: string;
}

/**
 * A flattened description of a `PrimitiveTransformation` or
 * `RecordSuppression`.
 */
export interface TransformationDescription {
  /** The transformation type. */
  type: TransformationType;
  /**
   * A description of the transformation. This is empty for a
   * RECORD_SUPPRESSION, or is the output of calling toString() on the
   * `PrimitiveTransformation` protocol buffer message for any other type of
   * transformation.
   */
  description: string;
  /**
   * A human-readable string representation of the `RecordCondition`
   * corresponding to this transformation. Set if a `RecordCondition` was used
   * to determine whether or not to apply this transformation.
   *
   * Examples:
   *     * (age_field > 85)
   *     * (age_field <= 18)
   *     * (zip_field exists)
   *     * (zip_field == 01234) && (city_field != "Springville")
   *     * (zip_field == 01234) && (age_field <= 18) && (city_field exists)
   */
  condition: string;
  /** Set if the transformation was limited to a specific `InfoType`. */
  infoType: InfoType | undefined;
}

/**
 * Details about a single transformation. This object contains a description of
 * the transformation, information about whether the transformation was
 * successfully applied, and the precise location where the transformation
 * occurred. These details are stored in a user-specified BigQuery table.
 */
export interface TransformationDetails {
  /** The name of the job that completed the transformation. */
  resourceName: string;
  /**
   * The top level name of the container where the transformation is located
   * (this will be the source file name or table name).
   */
  containerName: string;
  /**
   * Description of transformation. This would only contain more than one
   * element if there were multiple matching transformations and which one to
   * apply was ambiguous. Not set for states that contain no transformation,
   * currently only state that contains no transformation is
   * TransformationResultStateType.METADATA_UNRETRIEVABLE.
   */
  transformation: TransformationDescription[];
  /**
   * Status of the transformation, if transformation was not successful, this
   * will specify what caused it to fail, otherwise it will show that the
   * transformation was successful.
   */
  statusDetails:
    | TransformationResultStatus
    | undefined;
  /**
   * The number of bytes that were transformed. If transformation was
   * unsuccessful or did not take place because there was no content to
   * transform, this will be zero.
   */
  transformedBytes: Long;
  /** The precise location of the transformed content in the original container. */
  transformationLocation: TransformationLocation | undefined;
}

/** Specifies the location of a transformation. */
export interface TransformationLocation {
  /**
   * For infotype transformations, link to the corresponding findings ID so
   * that location information does not need to be duplicated. Each findings
   * ID correlates to an entry in the findings output table, this table only
   * gets created when users specify to save findings (add the save findings
   * action to the request).
   */
  findingId?:
    | string
    | undefined;
  /** For record transformations, provide a field and container information. */
  recordTransformation?:
    | RecordTransformation
    | undefined;
  /**
   * Information about the functionality of the container where this finding
   * occurred, if available.
   */
  containerType: TransformationContainerType;
}

/** The field in a record to transform. */
export interface RecordTransformation {
  /** For record transformations, provide a field. */
  fieldId:
    | FieldId
    | undefined;
  /** Findings container modification timestamp, if applicable. */
  containerTimestamp:
    | Date
    | undefined;
  /** Container version, if available ("generation" for Cloud Storage). */
  containerVersion: string;
}

/** The outcome of a transformation. */
export interface TransformationResultStatus {
  /**
   * Transformation result status type, this will be either SUCCESS, or it will
   * be the reason for why the transformation was not completely successful.
   */
  resultStatusType: TransformationResultStatusType;
  /** Detailed error codes and messages */
  details: Status | undefined;
}

/** Config for storing transformation details. */
export interface TransformationDetailsStorageConfig {
  /**
   * The BigQuery table in which to store the output. This may be an existing
   * table or in a new table in an existing dataset.
   * If table_id is not set a new one will be generated for you with the
   * following format:
   * dlp_googleapis_transformation_details_yyyy_mm_dd_[dlp_job_id]. Pacific
   * time zone will be used for generating the date details.
   */
  table?: BigQueryTable | undefined;
}

/** Schedule for inspect job triggers. */
export interface Schedule {
  /**
   * With this option a job is started on a regular periodic basis. For
   * example: every day (86400 seconds).
   *
   * A scheduled start time will be skipped if the previous
   * execution has not ended when its scheduled time occurs.
   *
   * This value must be set to a time duration greater than or equal
   * to 1 day and can be no longer than 60 days.
   */
  recurrencePeriodDuration?: Duration | undefined;
}

/**
 * Job trigger option for hybrid jobs. Jobs must be manually created
 * and finished.
 */
export interface Manual {
}

/**
 * The inspectTemplate contains a configuration (set of types of sensitive data
 * to be detected) to be used anywhere you otherwise would normally specify
 * InspectConfig. See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-templates to
 * learn more.
 */
export interface InspectTemplate {
  /**
   * Output only. The template name.
   *
   * The template will have one of the following formats:
   * `projects/PROJECT_ID/inspectTemplates/TEMPLATE_ID` OR
   * `organizations/ORGANIZATION_ID/inspectTemplates/TEMPLATE_ID`;
   */
  name: string;
  /** Display name (max 256 chars). */
  displayName: string;
  /** Short description (max 256 chars). */
  description: string;
  /** Output only. The creation timestamp of an inspectTemplate. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update timestamp of an inspectTemplate. */
  updateTime:
    | Date
    | undefined;
  /** The core content of the template. Configuration of the scanning process. */
  inspectConfig: InspectConfig | undefined;
}

/**
 * DeidentifyTemplates contains instructions on how to de-identify content.
 * See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-templates to
 * learn more.
 */
export interface DeidentifyTemplate {
  /**
   * Output only. The template name.
   *
   * The template will have one of the following formats:
   * `projects/PROJECT_ID/deidentifyTemplates/TEMPLATE_ID` OR
   * `organizations/ORGANIZATION_ID/deidentifyTemplates/TEMPLATE_ID`
   */
  name: string;
  /** Display name (max 256 chars). */
  displayName: string;
  /** Short description (max 256 chars). */
  description: string;
  /** Output only. The creation timestamp of an inspectTemplate. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update timestamp of an inspectTemplate. */
  updateTime:
    | Date
    | undefined;
  /** The core content of the template. */
  deidentifyConfig: DeidentifyConfig | undefined;
}

/**
 * Details information about an error encountered during job execution or
 * the results of an unsuccessful activation of the JobTrigger.
 */
export interface Error {
  /** Detailed error codes and messages. */
  details:
    | Status
    | undefined;
  /**
   * The times the error occurred. List includes the oldest timestamp and the
   * last 9 timestamps.
   */
  timestamps: Date[];
  /** Additional information about the error. */
  extraInfo: Error_ErrorExtraInfo;
}

/** Additional information about the error. */
export enum Error_ErrorExtraInfo {
  /** ERROR_INFO_UNSPECIFIED - Unused. */
  ERROR_INFO_UNSPECIFIED = 0,
  /** IMAGE_SCAN_UNAVAILABLE_IN_REGION - Image scan is not available in the region. */
  IMAGE_SCAN_UNAVAILABLE_IN_REGION = 1,
  /** FILE_STORE_CLUSTER_UNSUPPORTED - File store cluster is not supported for profile generation. */
  FILE_STORE_CLUSTER_UNSUPPORTED = 2,
  UNRECOGNIZED = -1,
}

export function error_ErrorExtraInfoFromJSON(object: any): Error_ErrorExtraInfo {
  switch (object) {
    case 0:
    case "ERROR_INFO_UNSPECIFIED":
      return Error_ErrorExtraInfo.ERROR_INFO_UNSPECIFIED;
    case 1:
    case "IMAGE_SCAN_UNAVAILABLE_IN_REGION":
      return Error_ErrorExtraInfo.IMAGE_SCAN_UNAVAILABLE_IN_REGION;
    case 2:
    case "FILE_STORE_CLUSTER_UNSUPPORTED":
      return Error_ErrorExtraInfo.FILE_STORE_CLUSTER_UNSUPPORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Error_ErrorExtraInfo.UNRECOGNIZED;
  }
}

export function error_ErrorExtraInfoToJSON(object: Error_ErrorExtraInfo): string {
  switch (object) {
    case Error_ErrorExtraInfo.ERROR_INFO_UNSPECIFIED:
      return "ERROR_INFO_UNSPECIFIED";
    case Error_ErrorExtraInfo.IMAGE_SCAN_UNAVAILABLE_IN_REGION:
      return "IMAGE_SCAN_UNAVAILABLE_IN_REGION";
    case Error_ErrorExtraInfo.FILE_STORE_CLUSTER_UNSUPPORTED:
      return "FILE_STORE_CLUSTER_UNSUPPORTED";
    case Error_ErrorExtraInfo.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Contains a configuration to make API calls on a repeating basis.
 * See
 * https://cloud.google.com/sensitive-data-protection/docs/concepts-job-triggers
 * to learn more.
 */
export interface JobTrigger {
  /**
   * Unique resource name for the triggeredJob, assigned by the service when the
   * triggeredJob is created, for example
   * `projects/dlp-test-project/jobTriggers/53234423`.
   */
  name: string;
  /** Display name (max 100 chars) */
  displayName: string;
  /** User provided description (max 256 chars) */
  description: string;
  /** For inspect jobs, a snapshot of the configuration. */
  inspectJob?:
    | InspectJobConfig
    | undefined;
  /**
   * A list of triggers which will be OR'ed together. Only one in the list
   * needs to trigger for a job to be started. The list may contain only
   * a single Schedule trigger and must have at least one object.
   */
  triggers: JobTrigger_Trigger[];
  /**
   * Output only. A stream of errors encountered when the trigger was activated.
   * Repeated errors may result in the JobTrigger automatically being paused.
   * Will return the last 100 errors. Whenever the JobTrigger is modified
   * this list will be cleared.
   */
  errors: Error[];
  /** Output only. The creation timestamp of a triggeredJob. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update timestamp of a triggeredJob. */
  updateTime:
    | Date
    | undefined;
  /** Output only. The timestamp of the last time this trigger executed. */
  lastRunTime:
    | Date
    | undefined;
  /** Required. A status for this trigger. */
  status: JobTrigger_Status;
}

/**
 * Whether the trigger is currently active. If PAUSED or CANCELLED, no jobs
 * will be created with this configuration. The service may automatically
 * pause triggers experiencing frequent errors. To restart a job, set the
 * status to HEALTHY after correcting user errors.
 */
export enum JobTrigger_Status {
  /** STATUS_UNSPECIFIED - Unused. */
  STATUS_UNSPECIFIED = 0,
  /** HEALTHY - Trigger is healthy. */
  HEALTHY = 1,
  /** PAUSED - Trigger is temporarily paused. */
  PAUSED = 2,
  /** CANCELLED - Trigger is cancelled and can not be resumed. */
  CANCELLED = 3,
  UNRECOGNIZED = -1,
}

export function jobTrigger_StatusFromJSON(object: any): JobTrigger_Status {
  switch (object) {
    case 0:
    case "STATUS_UNSPECIFIED":
      return JobTrigger_Status.STATUS_UNSPECIFIED;
    case 1:
    case "HEALTHY":
      return JobTrigger_Status.HEALTHY;
    case 2:
    case "PAUSED":
      return JobTrigger_Status.PAUSED;
    case 3:
    case "CANCELLED":
      return JobTrigger_Status.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobTrigger_Status.UNRECOGNIZED;
  }
}

export function jobTrigger_StatusToJSON(object: JobTrigger_Status): string {
  switch (object) {
    case JobTrigger_Status.STATUS_UNSPECIFIED:
      return "STATUS_UNSPECIFIED";
    case JobTrigger_Status.HEALTHY:
      return "HEALTHY";
    case JobTrigger_Status.PAUSED:
      return "PAUSED";
    case JobTrigger_Status.CANCELLED:
      return "CANCELLED";
    case JobTrigger_Status.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** What event needs to occur for a new job to be started. */
export interface JobTrigger_Trigger {
  /** Create a job on a repeating basis based on the elapse of time. */
  schedule?:
    | Schedule
    | undefined;
  /** For use with hybrid jobs. Jobs must be manually created and finished. */
  manual?: Manual | undefined;
}

/**
 * A task to execute on the completion of a job.
 * See https://cloud.google.com/sensitive-data-protection/docs/concepts-actions
 * to learn more.
 */
export interface Action {
  /** Save resulting findings in a provided location. */
  saveFindings?:
    | Action_SaveFindings
    | undefined;
  /** Publish a notification to a Pub/Sub topic. */
  pubSub?:
    | Action_PublishToPubSub
    | undefined;
  /** Publish summary to Cloud Security Command Center (Alpha). */
  publishSummaryToCscc?:
    | Action_PublishSummaryToCscc
    | undefined;
  /** Publish findings to Cloud Datahub. */
  publishFindingsToCloudDataCatalog?:
    | Action_PublishFindingsToCloudDataCatalog
    | undefined;
  /** Create a de-identified copy of the input data. */
  deidentify?:
    | Action_Deidentify
    | undefined;
  /**
   * Sends an email when the job completes. The email goes to IAM project
   * owners and technical [Essential
   * Contacts](https://cloud.google.com/resource-manager/docs/managing-notification-contacts).
   */
  jobNotificationEmails?:
    | Action_JobNotificationEmails
    | undefined;
  /** Enable Stackdriver metric dlp.googleapis.com/finding_count. */
  publishToStackdriver?: Action_PublishToStackdriver | undefined;
}

/**
 * If set, the detailed findings will be persisted to the specified
 * OutputStorageConfig. Only a single instance of this action can be
 * specified.
 * Compatible with: Inspect, Risk
 */
export interface Action_SaveFindings {
  /** Location to store findings outside of DLP. */
  outputConfig: OutputStorageConfig | undefined;
}

/**
 * Publish a message into a given Pub/Sub topic when DlpJob has completed. The
 * message contains a single field, `DlpJobName`, which is equal to the
 * finished job's
 * [`DlpJob.name`](https://cloud.google.com/sensitive-data-protection/docs/reference/rest/v2/projects.dlpJobs#DlpJob).
 * Compatible with: Inspect, Risk
 */
export interface Action_PublishToPubSub {
  /**
   * Cloud Pub/Sub topic to send notifications to. The topic must have given
   * publishing access rights to the DLP API service account executing
   * the long running DlpJob sending the notifications.
   * Format is projects/{project}/topics/{topic}.
   */
  topic: string;
}

/**
 * Publish the result summary of a DlpJob to [Security Command
 * Center](https://cloud.google.com/security-command-center). This action is
 * available for only projects that belong to an organization. This action
 * publishes the count of finding instances and their infoTypes. The summary
 * of findings are persisted in Security Command Center and are governed by
 * [service-specific policies for Security Command
 * Center](https://cloud.google.com/terms/service-terms). Only a single
 * instance of this action can be specified. Compatible with: Inspect
 */
export interface Action_PublishSummaryToCscc {
}

/**
 * Publish findings of a DlpJob to Data Catalog. In Data Catalog, tag
 * templates are applied to the resource that Cloud DLP scanned. Data
 * Catalog tag templates are stored in the same project and region where the
 * BigQuery table exists. For Cloud DLP to create and apply the tag template,
 * the Cloud DLP service agent must have the
 * `roles/datacatalog.tagTemplateOwner` permission on the project. The tag
 * template contains fields summarizing the results of the DlpJob. Any field
 * values previously written by another DlpJob are deleted. [InfoType naming
 * patterns][google.privacy.dlp.v2.InfoType] are strictly enforced when using
 * this feature.
 *
 * Findings are persisted in Data Catalog storage and are governed by
 * service-specific policies for Data Catalog. For more information, see
 * [Service Specific Terms](https://cloud.google.com/terms/service-terms).
 *
 * Only a single instance of this action can be specified. This action is
 * allowed only if all resources being scanned are BigQuery tables.
 * Compatible with: Inspect
 */
export interface Action_PublishFindingsToCloudDataCatalog {
}

/**
 * Create a de-identified copy of the requested table or files.
 *
 * A TransformationDetail will be created for each transformation.
 *
 * If any rows in BigQuery are skipped during de-identification
 * (transformation errors or row size exceeds BigQuery insert API limits) they
 * are placed in the failure output table. If the original row exceeds
 * the BigQuery insert API limit it will be truncated when written to the
 * failure output table. The failure output table can be set in the
 * action.deidentify.output.big_query_output.deidentified_failure_output_table
 * field, if no table is set, a table will be automatically created in the
 * same project and dataset as the original table.
 *
 * Compatible with: Inspect
 */
export interface Action_Deidentify {
  /**
   * User specified deidentify templates and configs for structured,
   * unstructured, and image files.
   */
  transformationConfig:
    | TransformationConfig
    | undefined;
  /**
   * Config for storing transformation details. This is separate from the
   * de-identified content, and contains metadata about the successful
   * transformations and/or failures that occurred while de-identifying. This
   * needs to be set in order for users to access information about the status
   * of each transformation (see
   * [TransformationDetails][google.privacy.dlp.v2.TransformationDetails]
   * message for more information about what is noted).
   */
  transformationDetailsStorageConfig:
    | TransformationDetailsStorageConfig
    | undefined;
  /**
   * Required. User settable Cloud Storage bucket and folders to store
   * de-identified files. This field must be set for Cloud Storage
   * deidentification. The output Cloud Storage bucket must be different
   * from the input bucket. De-identified files will overwrite files in the
   * output path.
   *
   * Form of: gs://bucket/folder/ or gs://bucket
   */
  cloudStorageOutput?:
    | string
    | undefined;
  /**
   * List of user-specified file type groups to transform. If specified, only
   * the files with these file types will be transformed. If empty, all
   * supported files will be transformed. Supported types may be automatically
   * added over time. If a file type is set in this field that isn't supported
   * by the Deidentify action then the job will fail and will not be
   * successfully created/started. Currently the only file types supported
   * are: IMAGES, TEXT_FILES, CSV, TSV.
   */
  fileTypesToTransform: FileType[];
}

/**
 * Sends an email when the job completes. The email goes to IAM project owners
 * and technical [Essential
 * Contacts](https://cloud.google.com/resource-manager/docs/managing-notification-contacts).
 */
export interface Action_JobNotificationEmails {
}

/**
 * Enable Stackdriver metric dlp.googleapis.com/finding_count. This
 * will publish a metric to stack driver on each infotype requested and
 * how many findings were found for it. CustomDetectors will be bucketed
 * as 'Custom' under the Stackdriver label 'info_type'.
 */
export interface Action_PublishToStackdriver {
}

/**
 * User specified templates and configs for how to deidentify structured,
 * unstructures, and image files. User must provide either a unstructured
 * deidentify template or at least one redact image config.
 */
export interface TransformationConfig {
  /**
   * De-identify template.
   * If this template is specified, it will serve as the default de-identify
   * template. This template cannot contain `record_transformations` since it
   * can be used for unstructured content such as free-form text files. If this
   * template is not set, a default `ReplaceWithInfoTypeConfig` will be used to
   * de-identify unstructured content.
   */
  deidentifyTemplate: string;
  /**
   * Structured de-identify template.
   * If this template is specified, it will serve as the de-identify template
   * for structured content such as delimited files and tables. If this template
   * is not set but the `deidentify_template` is set, then `deidentify_template`
   * will also apply to the structured content. If neither template is set, a
   * default `ReplaceWithInfoTypeConfig` will be used to de-identify structured
   * content.
   */
  structuredDeidentifyTemplate: string;
  /**
   * Image redact template.
   * If this template is specified, it will serve as the de-identify template
   * for images. If this template is not set, all findings in the image will be
   * redacted with a black box.
   */
  imageRedactTemplate: string;
}

/** Request message for CreateInspectTemplate. */
export interface CreateInspectTemplateRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization) and whether you have [specified a processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   * + Organizations scope, location specified:
   *   `organizations/{org_id}/locations/{location_id}`
   * + Organizations scope, no location specified (defaults to global):
   *   `organizations/{org_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** Required. The InspectTemplate to create. */
  inspectTemplate:
    | InspectTemplate
    | undefined;
  /**
   * The template id can contain uppercase and lowercase letters,
   * numbers, and hyphens; that is, it must match the regular
   * expression: `[a-zA-Z\d-_]+`. The maximum length is 100
   * characters. Can be empty to allow the system to generate one.
   */
  templateId: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Request message for UpdateInspectTemplate. */
export interface UpdateInspectTemplateRequest {
  /**
   * Required. Resource name of organization and inspectTemplate to be updated,
   * for example `organizations/433245324/inspectTemplates/432452342` or
   * projects/project-id/inspectTemplates/432452342.
   */
  name: string;
  /** New InspectTemplate value. */
  inspectTemplate:
    | InspectTemplate
    | undefined;
  /** Mask to control which fields get updated. */
  updateMask: string[] | undefined;
}

/** Request message for GetInspectTemplate. */
export interface GetInspectTemplateRequest {
  /**
   * Required. Resource name of the organization and inspectTemplate to be read,
   * for example `organizations/433245324/inspectTemplates/432452342` or
   * projects/project-id/inspectTemplates/432452342.
   */
  name: string;
}

/** Request message for ListInspectTemplates. */
export interface ListInspectTemplatesRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization) and whether you have [specified a processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   * + Organizations scope, location specified:
   *   `organizations/{org_id}/locations/{location_id}`
   * + Organizations scope, no location specified (defaults to global):
   *   `organizations/{org_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Page token to continue retrieval. Comes from the previous call
   * to `ListInspectTemplates`.
   */
  pageToken: string;
  /**
   * Size of the page. This value can be limited by the server. If zero server
   * returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Comma-separated list of fields to order by,
   * followed by `asc` or `desc` postfix. This list is case insensitive. The
   * default sorting order is ascending. Redundant space characters are
   * insignificant.
   *
   * Example: `name asc,update_time, create_time desc`
   *
   * Supported fields are:
   *
   * - `create_time`: corresponds to the time the template was created.
   * - `update_time`: corresponds to the time the template was last updated.
   * - `name`: corresponds to the template's name.
   * - `display_name`: corresponds to the template's display name.
   */
  orderBy: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Response message for ListInspectTemplates. */
export interface ListInspectTemplatesResponse {
  /** List of inspectTemplates, up to page_size in ListInspectTemplatesRequest. */
  inspectTemplates: InspectTemplate[];
  /**
   * If the next page is available then the next page token to be used in the
   * following ListInspectTemplates request.
   */
  nextPageToken: string;
}

/** Request message for DeleteInspectTemplate. */
export interface DeleteInspectTemplateRequest {
  /**
   * Required. Resource name of the organization and inspectTemplate to be
   * deleted, for example `organizations/433245324/inspectTemplates/432452342`
   * or projects/project-id/inspectTemplates/432452342.
   */
  name: string;
}

/** Request message for CreateJobTrigger. */
export interface CreateJobTriggerRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** Required. The JobTrigger to create. */
  jobTrigger:
    | JobTrigger
    | undefined;
  /**
   * The trigger id can contain uppercase and lowercase letters,
   * numbers, and hyphens; that is, it must match the regular
   * expression: `[a-zA-Z\d-_]+`. The maximum length is 100
   * characters. Can be empty to allow the system to generate one.
   */
  triggerId: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Request message for ActivateJobTrigger. */
export interface ActivateJobTriggerRequest {
  /**
   * Required. Resource name of the trigger to activate, for example
   * `projects/dlp-test-project/jobTriggers/53234423`.
   */
  name: string;
}

/** Request message for UpdateJobTrigger. */
export interface UpdateJobTriggerRequest {
  /**
   * Required. Resource name of the project and the triggeredJob, for example
   * `projects/dlp-test-project/jobTriggers/53234423`.
   */
  name: string;
  /** New JobTrigger value. */
  jobTrigger:
    | JobTrigger
    | undefined;
  /** Mask to control which fields get updated. */
  updateMask: string[] | undefined;
}

/** Request message for GetJobTrigger. */
export interface GetJobTriggerRequest {
  /**
   * Required. Resource name of the project and the triggeredJob, for example
   * `projects/dlp-test-project/jobTriggers/53234423`.
   */
  name: string;
}

/** Request message for CreateDiscoveryConfig. */
export interface CreateDiscoveryConfigRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization):
   *
   * + Projects scope:
   *   `projects/{project_id}/locations/{location_id}`
   * + Organizations scope:
   *   `organizations/{org_id}/locations/{location_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** Required. The DiscoveryConfig to create. */
  discoveryConfig:
    | DiscoveryConfig
    | undefined;
  /**
   * The config ID can contain uppercase and lowercase letters,
   * numbers, and hyphens; that is, it must match the regular
   * expression: `[a-zA-Z\d-_]+`. The maximum length is 100
   * characters. Can be empty to allow the system to generate one.
   */
  configId: string;
}

/** Request message for UpdateDiscoveryConfig. */
export interface UpdateDiscoveryConfigRequest {
  /**
   * Required. Resource name of the project and the configuration, for example
   * `projects/dlp-test-project/discoveryConfigs/53234423`.
   */
  name: string;
  /** Required. New DiscoveryConfig value. */
  discoveryConfig:
    | DiscoveryConfig
    | undefined;
  /** Mask to control which fields get updated. */
  updateMask: string[] | undefined;
}

/** Request message for GetDiscoveryConfig. */
export interface GetDiscoveryConfigRequest {
  /**
   * Required. Resource name of the project and the configuration, for example
   * `projects/dlp-test-project/discoveryConfigs/53234423`.
   */
  name: string;
}

/** Request message for ListDiscoveryConfigs. */
export interface ListDiscoveryConfigsRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value is as follows:
   * `projects/{project_id}/locations/{location_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Page token to continue retrieval. Comes from the previous call
   * to ListDiscoveryConfigs. `order_by` field must not
   * change for subsequent calls.
   */
  pageToken: string;
  /** Size of the page. This value can be limited by a server. */
  pageSize: number;
  /**
   * Comma-separated list of config fields to order by,
   * followed by `asc` or `desc` postfix. This list is case insensitive. The
   * default sorting order is ascending. Redundant space characters are
   * insignificant.
   *
   * Example: `name asc,update_time, create_time desc`
   *
   * Supported fields are:
   *
   * - `last_run_time`: corresponds to the last time the DiscoveryConfig ran.
   * - `name`: corresponds to the DiscoveryConfig's name.
   * - `status`: corresponds to DiscoveryConfig's status.
   */
  orderBy: string;
}

/** Response message for ListDiscoveryConfigs. */
export interface ListDiscoveryConfigsResponse {
  /** List of configs, up to page_size in ListDiscoveryConfigsRequest. */
  discoveryConfigs: DiscoveryConfig[];
  /**
   * If the next page is available then this value is the next page token to be
   * used in the following ListDiscoveryConfigs request.
   */
  nextPageToken: string;
}

/** Request message for DeleteDiscoveryConfig. */
export interface DeleteDiscoveryConfigRequest {
  /**
   * Required. Resource name of the project and the config, for example
   * `projects/dlp-test-project/discoveryConfigs/53234423`.
   */
  name: string;
}

/**
 * Request message for CreateDlpJobRequest. Used to initiate long running
 * jobs such as calculating risk metrics or inspecting Google Cloud
 * Storage.
 */
export interface CreateDlpJobRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** An inspection job scans a storage repository for InfoTypes. */
  inspectJob?:
    | InspectJobConfig
    | undefined;
  /**
   * A risk analysis job calculates re-identification risk metrics for a
   * BigQuery table.
   */
  riskJob?:
    | RiskAnalysisJobConfig
    | undefined;
  /**
   * The job id can contain uppercase and lowercase letters,
   * numbers, and hyphens; that is, it must match the regular
   * expression: `[a-zA-Z\d-_]+`. The maximum length is 100
   * characters. Can be empty to allow the system to generate one.
   */
  jobId: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Request message for ListJobTriggers. */
export interface ListJobTriggersRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Page token to continue retrieval. Comes from the previous call
   * to ListJobTriggers. `order_by` field must not
   * change for subsequent calls.
   */
  pageToken: string;
  /** Size of the page. This value can be limited by a server. */
  pageSize: number;
  /**
   * Comma-separated list of triggeredJob fields to order by,
   * followed by `asc` or `desc` postfix. This list is case insensitive. The
   * default sorting order is ascending. Redundant space characters are
   * insignificant.
   *
   * Example: `name asc,update_time, create_time desc`
   *
   * Supported fields are:
   *
   * - `create_time`: corresponds to the time the JobTrigger was created.
   * - `update_time`: corresponds to the time the JobTrigger was last updated.
   * - `last_run_time`: corresponds to the last time the JobTrigger ran.
   * - `name`: corresponds to the JobTrigger's name.
   * - `display_name`: corresponds to the JobTrigger's display name.
   * - `status`: corresponds to JobTrigger's status.
   */
  orderBy: string;
  /**
   * Allows filtering.
   *
   * Supported syntax:
   *
   * * Filter expressions are made up of one or more restrictions.
   * * Restrictions can be combined by `AND` or `OR` logical operators. A
   * sequence of restrictions implicitly uses `AND`.
   * * A restriction has the form of `{field} {operator} {value}`.
   * * Supported fields/values for inspect triggers:
   *     - `status` - HEALTHY|PAUSED|CANCELLED
   *     - `inspected_storage` - DATASTORE|CLOUD_STORAGE|BIGQUERY
   *     - 'last_run_time` - RFC 3339 formatted timestamp, surrounded by
   *     quotation marks. Nanoseconds are ignored.
   *     - 'error_count' - Number of errors that have occurred while running.
   * * The operator must be `=` or `!=` for status and inspected_storage.
   *
   * Examples:
   *
   * * inspected_storage = cloud_storage AND status = HEALTHY
   * * inspected_storage = cloud_storage OR inspected_storage = bigquery
   * * inspected_storage = cloud_storage AND (state = PAUSED OR state = HEALTHY)
   * * last_run_time > \"2017-12-12T00:00:00+00:00\"
   *
   * The length of this field should be no more than 500 characters.
   */
  filter: string;
  /** The type of jobs. Will use `DlpJobType.INSPECT` if not set. */
  type: DlpJobType;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Response message for ListJobTriggers. */
export interface ListJobTriggersResponse {
  /** List of triggeredJobs, up to page_size in ListJobTriggersRequest. */
  jobTriggers: JobTrigger[];
  /**
   * If the next page is available then this value is the next page token to be
   * used in the following ListJobTriggers request.
   */
  nextPageToken: string;
}

/** Request message for DeleteJobTrigger. */
export interface DeleteJobTriggerRequest {
  /**
   * Required. Resource name of the project and the triggeredJob, for example
   * `projects/dlp-test-project/jobTriggers/53234423`.
   */
  name: string;
}

/** Controls what and how to inspect for findings. */
export interface InspectJobConfig {
  /** The data to scan. */
  storageConfig:
    | StorageConfig
    | undefined;
  /** How and what to scan for. */
  inspectConfig:
    | InspectConfig
    | undefined;
  /**
   * If provided, will be used as the default for all values in InspectConfig.
   * `inspect_config` will be merged into the values persisted as part of the
   * template.
   */
  inspectTemplateName: string;
  /** Actions to execute at the completion of the job. */
  actions: Action[];
}

/** A task to execute when a data profile has been generated. */
export interface DataProfileAction {
  /** Export data profiles into a provided location. */
  exportData?:
    | DataProfileAction_Export
    | undefined;
  /** Publish a message into the Pub/Sub topic. */
  pubSubNotification?:
    | DataProfileAction_PubSubNotification
    | undefined;
  /**
   * Publishes generated data profiles to Google Security Operations.
   * For more information, see [Use Sensitive Data Protection data in
   * context-aware
   * analytics](https://cloud.google.com/chronicle/docs/detection/usecase-dlp-high-risk-user-download).
   */
  publishToChronicle?:
    | DataProfileAction_PublishToChronicle
    | undefined;
  /** Publishes findings to SCC for each data profile. */
  publishToScc?:
    | DataProfileAction_PublishToSecurityCommandCenter
    | undefined;
  /** Tags the profiled resources with the specified tag values. */
  tagResources?: DataProfileAction_TagResources | undefined;
}

/** Types of event that can trigger an action. */
export enum DataProfileAction_EventType {
  /** EVENT_TYPE_UNSPECIFIED - Unused. */
  EVENT_TYPE_UNSPECIFIED = 0,
  /** NEW_PROFILE - New profile (not a re-profile). */
  NEW_PROFILE = 1,
  /**
   * CHANGED_PROFILE - One of the following profile metrics changed: Data risk score,
   * Sensitivity score, Resource visibility, Encryption type, Predicted
   * infoTypes, Other infoTypes
   */
  CHANGED_PROFILE = 2,
  /** SCORE_INCREASED - Table data risk score or sensitivity score increased. */
  SCORE_INCREASED = 3,
  /** ERROR_CHANGED - A user (non-internal) error occurred. */
  ERROR_CHANGED = 4,
  UNRECOGNIZED = -1,
}

export function dataProfileAction_EventTypeFromJSON(object: any): DataProfileAction_EventType {
  switch (object) {
    case 0:
    case "EVENT_TYPE_UNSPECIFIED":
      return DataProfileAction_EventType.EVENT_TYPE_UNSPECIFIED;
    case 1:
    case "NEW_PROFILE":
      return DataProfileAction_EventType.NEW_PROFILE;
    case 2:
    case "CHANGED_PROFILE":
      return DataProfileAction_EventType.CHANGED_PROFILE;
    case 3:
    case "SCORE_INCREASED":
      return DataProfileAction_EventType.SCORE_INCREASED;
    case 4:
    case "ERROR_CHANGED":
      return DataProfileAction_EventType.ERROR_CHANGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataProfileAction_EventType.UNRECOGNIZED;
  }
}

export function dataProfileAction_EventTypeToJSON(object: DataProfileAction_EventType): string {
  switch (object) {
    case DataProfileAction_EventType.EVENT_TYPE_UNSPECIFIED:
      return "EVENT_TYPE_UNSPECIFIED";
    case DataProfileAction_EventType.NEW_PROFILE:
      return "NEW_PROFILE";
    case DataProfileAction_EventType.CHANGED_PROFILE:
      return "CHANGED_PROFILE";
    case DataProfileAction_EventType.SCORE_INCREASED:
      return "SCORE_INCREASED";
    case DataProfileAction_EventType.ERROR_CHANGED:
      return "ERROR_CHANGED";
    case DataProfileAction_EventType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * If set, the detailed data profiles will be persisted to the location
 * of your choice whenever updated.
 */
export interface DataProfileAction_Export {
  /**
   * Store all table and column profiles in an existing table or a new table
   * in an existing dataset. Each re-generation will result in new rows in
   * BigQuery. Data is inserted using [streaming
   * insert](https://cloud.google.com/blog/products/bigquery/life-of-a-bigquery-streaming-insert)
   * and so data may be in the buffer for a period of time after the profile
   * has finished. The Pub/Sub notification is sent before the streaming
   * buffer is guaranteed to be written, so data may not be instantly
   * visible to queries by the time your topic receives the Pub/Sub
   * notification.
   */
  profileTable: BigQueryTable | undefined;
}

/**
 * Send a Pub/Sub message into the given Pub/Sub topic to connect other
 * systems to data profile generation. The message payload data will
 * be the byte serialization of `DataProfilePubSubMessage`.
 */
export interface DataProfileAction_PubSubNotification {
  /**
   * Cloud Pub/Sub topic to send notifications to.
   * Format is projects/{project}/topics/{topic}.
   */
  topic: string;
  /**
   * The type of event that triggers a Pub/Sub. At most one
   * `PubSubNotification` per EventType is permitted.
   */
  event: DataProfileAction_EventType;
  /**
   * Conditions (e.g., data risk or sensitivity level) for triggering a
   * Pub/Sub.
   */
  pubsubCondition:
    | DataProfilePubSubCondition
    | undefined;
  /**
   * How much data to include in the Pub/Sub message. If the user wishes to
   * limit the size of the message, they can use resource_name and fetch the
   * profile fields they wish to. Per table profile (not per column).
   */
  detailOfMessage: DataProfileAction_PubSubNotification_DetailLevel;
}

/** The levels of detail that can be included in the Pub/Sub message. */
export enum DataProfileAction_PubSubNotification_DetailLevel {
  /** DETAIL_LEVEL_UNSPECIFIED - Unused. */
  DETAIL_LEVEL_UNSPECIFIED = 0,
  /** TABLE_PROFILE - The full table data profile. */
  TABLE_PROFILE = 1,
  /** RESOURCE_NAME - The name of the profiled resource. */
  RESOURCE_NAME = 2,
  /** FILE_STORE_PROFILE - The full file store data profile. */
  FILE_STORE_PROFILE = 3,
  UNRECOGNIZED = -1,
}

export function dataProfileAction_PubSubNotification_DetailLevelFromJSON(
  object: any,
): DataProfileAction_PubSubNotification_DetailLevel {
  switch (object) {
    case 0:
    case "DETAIL_LEVEL_UNSPECIFIED":
      return DataProfileAction_PubSubNotification_DetailLevel.DETAIL_LEVEL_UNSPECIFIED;
    case 1:
    case "TABLE_PROFILE":
      return DataProfileAction_PubSubNotification_DetailLevel.TABLE_PROFILE;
    case 2:
    case "RESOURCE_NAME":
      return DataProfileAction_PubSubNotification_DetailLevel.RESOURCE_NAME;
    case 3:
    case "FILE_STORE_PROFILE":
      return DataProfileAction_PubSubNotification_DetailLevel.FILE_STORE_PROFILE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataProfileAction_PubSubNotification_DetailLevel.UNRECOGNIZED;
  }
}

export function dataProfileAction_PubSubNotification_DetailLevelToJSON(
  object: DataProfileAction_PubSubNotification_DetailLevel,
): string {
  switch (object) {
    case DataProfileAction_PubSubNotification_DetailLevel.DETAIL_LEVEL_UNSPECIFIED:
      return "DETAIL_LEVEL_UNSPECIFIED";
    case DataProfileAction_PubSubNotification_DetailLevel.TABLE_PROFILE:
      return "TABLE_PROFILE";
    case DataProfileAction_PubSubNotification_DetailLevel.RESOURCE_NAME:
      return "RESOURCE_NAME";
    case DataProfileAction_PubSubNotification_DetailLevel.FILE_STORE_PROFILE:
      return "FILE_STORE_PROFILE";
    case DataProfileAction_PubSubNotification_DetailLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Message expressing intention to publish to Google Security Operations. */
export interface DataProfileAction_PublishToChronicle {
}

/** If set, a summary finding will be created/updated in SCC for each profile. */
export interface DataProfileAction_PublishToSecurityCommandCenter {
}

/**
 * If set, attaches the [tags]
 * (https://cloud.google.com/resource-manager/docs/tags/tags-overview)
 * provided to profiled resources. Tags support [access
 * control](https://cloud.google.com/iam/docs/tags-access-control). You can
 * conditionally grant or deny access to a resource based on whether the
 * resource has a specific tag.
 */
export interface DataProfileAction_TagResources {
  /** The tags to associate with different conditions. */
  tagConditions: DataProfileAction_TagResources_TagCondition[];
  /**
   * The profile generations for which the tag should be attached to
   * resources. If you attach a tag to only new profiles, then if the
   * sensitivity score of a profile subsequently changes, its tag doesn't
   * change. By default, this field includes only new profiles. To include
   * both new and updated profiles for tagging, this field should explicitly
   * include both `PROFILE_GENERATION_NEW` and `PROFILE_GENERATION_UPDATE`.
   */
  profileGenerationsToTag: ProfileGeneration[];
  /**
   * Whether applying a tag to a resource should lower the risk of the profile
   * for that resource. For example, in conjunction with an [IAM deny
   * policy](https://cloud.google.com/iam/docs/deny-overview), you can deny
   * all principals a permission if a tag value is present, mitigating the
   * risk of the resource. This also lowers the data risk of resources at the
   * lower levels of the resource hierarchy. For example, reducing the data
   * risk of a table data profile also reduces the data risk of the
   * constituent column data profiles.
   */
  lowerDataRiskToLow: boolean;
}

/**
 * The tag to attach to profiles matching the condition. At most one
 * `TagCondition` can be specified per sensitivity level.
 */
export interface DataProfileAction_TagResources_TagCondition {
  /** The tag value to attach to resources. */
  tag:
    | DataProfileAction_TagResources_TagValue
    | undefined;
  /**
   * Conditions attaching the tag to a resource on its profile having this
   * sensitivity score.
   */
  sensitivityScore?: SensitivityScore | undefined;
}

/** A value of a tag. */
export interface DataProfileAction_TagResources_TagValue {
  /**
   * The namespaced name for the tag value to attach to resources. Must be
   * in the format `{parent_id}/{tag_key_short_name}/{short_name}`, for
   * example, "123456/environment/prod".
   */
  namespacedValue?: string | undefined;
}

/**
 * Configuration for setting up a job to scan resources for profile generation.
 * Only one data profile configuration may exist per organization, folder,
 * or project.
 *
 * The generated data profiles are retained according to the
 * [data retention policy]
 * (https://cloud.google.com/sensitive-data-protection/docs/data-profiles#retention).
 */
export interface DataProfileJobConfig {
  /** The data to scan. */
  location:
    | DataProfileLocation
    | undefined;
  /**
   * The project that will run the scan. The DLP service
   * account that exists within this project must have access to all resources
   * that are profiled, and the Cloud DLP API must be enabled.
   */
  projectId: string;
  /** Must be set only when scanning other clouds. */
  otherCloudStartingLocation:
    | OtherCloudDiscoveryStartingLocation
    | undefined;
  /**
   * Detection logic for profile generation.
   *
   * Not all template features are used by profiles. FindingLimits,
   * include_quote and exclude_info_types have no impact on
   * data profiling.
   *
   * Multiple templates may be provided if there is data in multiple regions.
   * At most one template must be specified per-region (including "global").
   * Each region is scanned using the applicable template. If no region-specific
   * template is specified, but a "global" template is specified, it will be
   * copied to that region and used instead. If no global or region-specific
   * template is provided for a region with data, that region's data will not be
   * scanned.
   *
   * For more information, see
   * https://cloud.google.com/sensitive-data-protection/docs/data-profiles#data-residency.
   */
  inspectTemplates: string[];
  /** Actions to execute at the completion of the job. */
  dataProfileActions: DataProfileAction[];
}

/**
 * A pattern to match against one or more tables, datasets, or projects that
 * contain BigQuery tables. At least one pattern must be specified.
 * Regular expressions use RE2
 * [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found
 * under the google/re2 repository on GitHub.
 */
export interface BigQueryRegex {
  /**
   * For organizations, if unset, will match all projects. Has no effect
   * for data profile configurations created within a project.
   */
  projectIdRegex: string;
  /** If unset, this property matches all datasets. */
  datasetIdRegex: string;
  /** If unset, this property matches all tables. */
  tableIdRegex: string;
}

/**
 * A collection of regular expressions to determine what tables to match
 * against.
 */
export interface BigQueryRegexes {
  /**
   * A single BigQuery regular expression pattern to match against one or more
   * tables, datasets, or projects that contain BigQuery tables.
   */
  patterns: BigQueryRegex[];
}

/** The types of BigQuery tables supported by Cloud DLP. */
export interface BigQueryTableTypes {
  /** A set of BigQuery table types. */
  types: BigQueryTableType[];
}

/** Do not profile the tables. */
export interface Disabled {
}

/** The data that will be profiled. */
export interface DataProfileLocation {
  /** The ID of an organization to scan. */
  organizationId?:
    | Long
    | undefined;
  /** The ID of the folder within an organization to scan. */
  folderId?: Long | undefined;
}

/**
 * Configuration for discovery to scan resources for profile generation.
 * Only one discovery configuration may exist per organization, folder,
 * or project.
 *
 * The generated data profiles are retained according to the
 * [data retention policy]
 * (https://cloud.google.com/sensitive-data-protection/docs/data-profiles#retention).
 */
export interface DiscoveryConfig {
  /**
   * Unique resource name for the DiscoveryConfig, assigned by the service when
   * the DiscoveryConfig is created, for example
   * `projects/dlp-test-project/locations/global/discoveryConfigs/53234423`.
   */
  name: string;
  /** Display name (max 100 chars) */
  displayName: string;
  /** Only set when the parent is an org. */
  orgConfig:
    | DiscoveryConfig_OrgConfig
    | undefined;
  /** Must be set only when scanning other clouds. */
  otherCloudStartingLocation:
    | OtherCloudDiscoveryStartingLocation
    | undefined;
  /**
   * Detection logic for profile generation.
   *
   * Not all template features are used by Discovery. FindingLimits,
   * include_quote and exclude_info_types have no impact on
   * Discovery.
   *
   * Multiple templates may be provided if there is data in multiple regions.
   * At most one template must be specified per-region (including "global").
   * Each region is scanned using the applicable template. If no region-specific
   * template is specified, but a "global" template is specified, it will be
   * copied to that region and used instead. If no global or region-specific
   * template is provided for a region with data, that region's data will not be
   * scanned.
   *
   * For more information, see
   * https://cloud.google.com/sensitive-data-protection/docs/data-profiles#data-residency.
   */
  inspectTemplates: string[];
  /** Actions to execute at the completion of scanning. */
  actions: DataProfileAction[];
  /** Target to match against for determining what to scan and how frequently. */
  targets: DiscoveryTarget[];
  /**
   * Output only. A stream of errors encountered when the config was activated.
   * Repeated errors may result in the config automatically being paused. Output
   * only field. Will return the last 100 errors. Whenever the config is
   * modified this list will be cleared.
   */
  errors: Error[];
  /** Output only. The creation timestamp of a DiscoveryConfig. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update timestamp of a DiscoveryConfig. */
  updateTime:
    | Date
    | undefined;
  /** Output only. The timestamp of the last time this config was executed. */
  lastRunTime:
    | Date
    | undefined;
  /** Required. A status for this configuration. */
  status: DiscoveryConfig_Status;
}

/**
 * Whether the discovery config is currently active. New options may be added
 * at a later time.
 */
export enum DiscoveryConfig_Status {
  /** STATUS_UNSPECIFIED - Unused */
  STATUS_UNSPECIFIED = 0,
  /** RUNNING - The discovery config is currently active. */
  RUNNING = 1,
  /** PAUSED - The discovery config is paused temporarily. */
  PAUSED = 2,
  UNRECOGNIZED = -1,
}

export function discoveryConfig_StatusFromJSON(object: any): DiscoveryConfig_Status {
  switch (object) {
    case 0:
    case "STATUS_UNSPECIFIED":
      return DiscoveryConfig_Status.STATUS_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return DiscoveryConfig_Status.RUNNING;
    case 2:
    case "PAUSED":
      return DiscoveryConfig_Status.PAUSED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryConfig_Status.UNRECOGNIZED;
  }
}

export function discoveryConfig_StatusToJSON(object: DiscoveryConfig_Status): string {
  switch (object) {
    case DiscoveryConfig_Status.STATUS_UNSPECIFIED:
      return "STATUS_UNSPECIFIED";
    case DiscoveryConfig_Status.RUNNING:
      return "RUNNING";
    case DiscoveryConfig_Status.PAUSED:
      return "PAUSED";
    case DiscoveryConfig_Status.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Project and scan location information. Only set when the parent is an org. */
export interface DiscoveryConfig_OrgConfig {
  /** The data to scan: folder, org, or project */
  location:
    | DiscoveryStartingLocation
    | undefined;
  /**
   * The project that will run the scan. The DLP service
   * account that exists within this project must have access to all resources
   * that are profiled, and the Cloud DLP API must be enabled.
   */
  projectId: string;
}

/** Target used to match against for Discovery. */
export interface DiscoveryTarget {
  /**
   * BigQuery target for Discovery. The first target to match a table will be
   * the one applied.
   */
  bigQueryTarget?:
    | BigQueryDiscoveryTarget
    | undefined;
  /**
   * Cloud SQL target for Discovery. The first target to match a table will be
   * the one applied.
   */
  cloudSqlTarget?:
    | CloudSqlDiscoveryTarget
    | undefined;
  /**
   * Discovery target that looks for credentials and secrets stored in cloud
   * resource metadata and reports them as vulnerabilities to Security Command
   * Center. Only one target of this type is allowed.
   */
  secretsTarget?:
    | SecretsDiscoveryTarget
    | undefined;
  /**
   * Cloud Storage target for Discovery. The first target to match a table
   * will be the one applied.
   */
  cloudStorageTarget?:
    | CloudStorageDiscoveryTarget
    | undefined;
  /**
   * Other clouds target for discovery. The first target to match a resource
   * will be the one applied.
   */
  otherCloudTarget?: OtherCloudDiscoveryTarget | undefined;
}

/** Target used to match against for discovery with BigQuery tables */
export interface BigQueryDiscoveryTarget {
  /**
   * Required. The tables the discovery cadence applies to. The first target
   * with a matching filter will be the one to apply to a table.
   */
  filter:
    | DiscoveryBigQueryFilter
    | undefined;
  /**
   * In addition to matching the filter, these conditions must be true
   * before a profile is generated.
   */
  conditions:
    | DiscoveryBigQueryConditions
    | undefined;
  /**
   * How often and when to update profiles. New tables that match both the
   * filter and conditions are scanned as quickly as possible depending on
   * system capacity.
   */
  cadence?:
    | DiscoveryGenerationCadence
    | undefined;
  /** Tables that match this filter will not have profiles created. */
  disabled?: Disabled | undefined;
}

/**
 * Determines what tables will have profiles generated within an organization
 * or project. Includes the ability to filter by regular expression patterns
 * on project ID, dataset ID, and table ID.
 */
export interface DiscoveryBigQueryFilter {
  /**
   * A specific set of tables for this filter to apply to. A table collection
   * must be specified in only one filter per config.
   * If a table id or dataset is empty, Cloud DLP assumes all tables in that
   * collection must be profiled. Must specify a project ID.
   */
  tables?:
    | BigQueryTableCollection
    | undefined;
  /**
   * Catch-all. This should always be the last filter in the list because
   * anything above it will apply first. Should only appear once in a
   * configuration. If none is specified, a default one will be added
   * automatically.
   */
  otherTables?:
    | DiscoveryBigQueryFilter_AllOtherBigQueryTables
    | undefined;
  /**
   * The table to scan. Discovery configurations including this can only
   * include one DiscoveryTarget (the DiscoveryTarget with this
   * TableReference).
   */
  tableReference?: TableReference | undefined;
}

/**
 * Catch-all for all other tables not specified by other filters. Should
 * always be last, except for single-table configurations, which will only
 * have a TableReference target.
 */
export interface DiscoveryBigQueryFilter_AllOtherBigQueryTables {
}

/** Specifies a collection of BigQuery tables. Used for Discovery. */
export interface BigQueryTableCollection {
  /** A collection of regular expressions to match a BigQuery table against. */
  includeRegexes?: BigQueryRegexes | undefined;
}

/**
 * Requirements that must be true before a table is scanned in discovery for the
 * first time. There is an AND relationship between the top-level attributes.
 * Additionally, minimum conditions with an OR relationship that must be met
 * before Cloud DLP scans a table can be set (like a minimum row count or a
 * minimum table age).
 */
export interface DiscoveryBigQueryConditions {
  /**
   * BigQuery table must have been created after this date. Used to avoid
   * backfilling.
   */
  createdAfter:
    | Date
    | undefined;
  /** Restrict discovery to specific table types. */
  types?:
    | BigQueryTableTypes
    | undefined;
  /** Restrict discovery to categories of table types. */
  typeCollection?:
    | BigQueryTableTypeCollection
    | undefined;
  /** At least one of the conditions must be true for a table to be scanned. */
  orConditions: DiscoveryBigQueryConditions_OrConditions | undefined;
}

/**
 * There is an OR relationship between these attributes. They are used to
 * determine if a table should be scanned or not in Discovery.
 */
export interface DiscoveryBigQueryConditions_OrConditions {
  /**
   * Minimum number of rows that should be present before Cloud DLP
   * profiles a table
   */
  minRowCount: number;
  /**
   * Minimum age a table must have before Cloud DLP can profile it. Value must
   * be 1 hour or greater.
   */
  minAge: Duration | undefined;
}

/**
 * What must take place for a profile to be updated and how
 * frequently it should occur.
 * New tables are scanned as quickly as possible depending on system
 * capacity.
 */
export interface DiscoveryGenerationCadence {
  /** Governs when to update data profiles when a schema is modified. */
  schemaModifiedCadence:
    | DiscoverySchemaModifiedCadence
    | undefined;
  /** Governs when to update data profiles when a table is modified. */
  tableModifiedCadence:
    | DiscoveryTableModifiedCadence
    | undefined;
  /**
   * Governs when to update data profiles when the inspection rules
   * defined by the `InspectTemplate` change.
   * If not set, changing the template will not cause a data profile to update.
   */
  inspectTemplateModifiedCadence:
    | DiscoveryInspectTemplateModifiedCadence
    | undefined;
  /**
   * Frequency at which profiles should be updated, regardless of whether the
   * underlying resource has changed. Defaults to never.
   */
  refreshFrequency: DataProfileUpdateFrequency;
}

/** The cadence at which to update data profiles when a table is modified. */
export interface DiscoveryTableModifiedCadence {
  /**
   * The type of events to consider when deciding if the table has been
   * modified and should have the profile updated. Defaults to
   * MODIFIED_TIMESTAMP.
   */
  types: BigQueryTableModification[];
  /**
   * How frequently data profiles can be updated when tables are modified.
   * Defaults to never.
   */
  frequency: DataProfileUpdateFrequency;
}

/** The cadence at which to update data profiles when a schema is modified. */
export interface DiscoverySchemaModifiedCadence {
  /**
   * The type of events to consider when deciding if the table's schema
   * has been modified and should have the profile updated. Defaults to
   * NEW_COLUMNS.
   */
  types: BigQuerySchemaModification[];
  /**
   * How frequently profiles may be updated when schemas are
   * modified. Defaults to monthly.
   */
  frequency: DataProfileUpdateFrequency;
}

/**
 * The cadence at which to update data profiles when the inspection rules
 * defined by the `InspectTemplate` change.
 */
export interface DiscoveryInspectTemplateModifiedCadence {
  /**
   * How frequently data profiles can be updated when the template is modified.
   * Defaults to never.
   */
  frequency: DataProfileUpdateFrequency;
}

/** Target used to match against for discovery with Cloud SQL tables. */
export interface CloudSqlDiscoveryTarget {
  /**
   * Required. The tables the discovery cadence applies to. The first target
   * with a matching filter will be the one to apply to a table.
   */
  filter:
    | DiscoveryCloudSqlFilter
    | undefined;
  /**
   * In addition to matching the filter, these conditions must be true
   * before a profile is generated.
   */
  conditions:
    | DiscoveryCloudSqlConditions
    | undefined;
  /**
   * How often and when to update profiles. New tables that match both the
   * filter and conditions are scanned as quickly as possible depending on
   * system capacity.
   */
  generationCadence?:
    | DiscoveryCloudSqlGenerationCadence
    | undefined;
  /** Disable profiling for database resources that match this filter. */
  disabled?: Disabled | undefined;
}

/**
 * Determines what tables will have profiles generated within an organization
 * or project. Includes the ability to filter by regular expression patterns
 * on project ID, location, instance, database, and database resource name.
 */
export interface DiscoveryCloudSqlFilter {
  /** A specific set of database resources for this filter to apply to. */
  collection?:
    | DatabaseResourceCollection
    | undefined;
  /**
   * Catch-all. This should always be the last target in the list because
   * anything above it will apply first. Should only appear once in a
   * configuration. If none is specified, a default one will be added
   * automatically.
   */
  others?:
    | AllOtherDatabaseResources
    | undefined;
  /**
   * The database resource to scan. Targets including this can only include
   * one target (the target with this database resource reference).
   */
  databaseResourceReference?: DatabaseResourceReference | undefined;
}

/**
 * Match database resources using regex filters. Examples of database
 * resources are tables, views, and stored procedures.
 */
export interface DatabaseResourceCollection {
  /** A collection of regular expressions to match a database resource against. */
  includeRegexes?: DatabaseResourceRegexes | undefined;
}

/**
 * A collection of regular expressions to determine what database resources to
 * match against.
 */
export interface DatabaseResourceRegexes {
  /**
   * A group of regular expression patterns to match against one or more
   * database resources.
   * Maximum of 100 entries. The sum of all regular expression's length can't
   * exceed 10 KiB.
   */
  patterns: DatabaseResourceRegex[];
}

/**
 * A pattern to match against one or more database resources. At least one
 * pattern must be specified. Regular expressions use RE2
 * [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found
 * under the google/re2 repository on GitHub.
 */
export interface DatabaseResourceRegex {
  /**
   * For organizations, if unset, will match all projects. Has no effect
   * for configurations created within a project.
   */
  projectIdRegex: string;
  /** Regex to test the instance name against. If empty, all instances match. */
  instanceRegex: string;
  /** Regex to test the database name against. If empty, all databases match. */
  databaseRegex: string;
  /**
   * Regex to test the database resource's name against. An example of a
   * database resource name is a table's name. Other database resource names
   * like view names could be included in the future. If empty, all database
   * resources match.
   */
  databaseResourceNameRegex: string;
}

/** Match database resources not covered by any other filter. */
export interface AllOtherDatabaseResources {
}

/** Identifies a single database resource, like a table within a database. */
export interface DatabaseResourceReference {
  /**
   * Required. If within a project-level config, then this must match the
   * config's project ID.
   */
  projectId: string;
  /**
   * Required. The instance where this resource is located. For example: Cloud
   * SQL instance ID.
   */
  instance: string;
  /** Required. Name of a database within the instance. */
  database: string;
  /**
   * Required. Name of a database resource, for example, a table within the
   * database.
   */
  databaseResource: string;
}

/**
 * Requirements that must be true before a table is profiled for the
 * first time.
 */
export interface DiscoveryCloudSqlConditions {
  /**
   * Optional. Database engines that should be profiled.
   * Optional. Defaults to ALL_SUPPORTED_DATABASE_ENGINES if unspecified.
   */
  databaseEngines: DiscoveryCloudSqlConditions_DatabaseEngine[];
  /**
   * Data profiles will only be generated for the database resource types
   * specified in this field.
   * If not specified, defaults to [DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES].
   */
  types: DiscoveryCloudSqlConditions_DatabaseResourceType[];
}

/** The database engines that should be profiled. */
export enum DiscoveryCloudSqlConditions_DatabaseEngine {
  /** DATABASE_ENGINE_UNSPECIFIED - Unused. */
  DATABASE_ENGINE_UNSPECIFIED = 0,
  /** ALL_SUPPORTED_DATABASE_ENGINES - Include all supported database engines. */
  ALL_SUPPORTED_DATABASE_ENGINES = 1,
  /** MYSQL - MySQL database. */
  MYSQL = 2,
  /** POSTGRES - PostgreSQL database. */
  POSTGRES = 3,
  UNRECOGNIZED = -1,
}

export function discoveryCloudSqlConditions_DatabaseEngineFromJSON(
  object: any,
): DiscoveryCloudSqlConditions_DatabaseEngine {
  switch (object) {
    case 0:
    case "DATABASE_ENGINE_UNSPECIFIED":
      return DiscoveryCloudSqlConditions_DatabaseEngine.DATABASE_ENGINE_UNSPECIFIED;
    case 1:
    case "ALL_SUPPORTED_DATABASE_ENGINES":
      return DiscoveryCloudSqlConditions_DatabaseEngine.ALL_SUPPORTED_DATABASE_ENGINES;
    case 2:
    case "MYSQL":
      return DiscoveryCloudSqlConditions_DatabaseEngine.MYSQL;
    case 3:
    case "POSTGRES":
      return DiscoveryCloudSqlConditions_DatabaseEngine.POSTGRES;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryCloudSqlConditions_DatabaseEngine.UNRECOGNIZED;
  }
}

export function discoveryCloudSqlConditions_DatabaseEngineToJSON(
  object: DiscoveryCloudSqlConditions_DatabaseEngine,
): string {
  switch (object) {
    case DiscoveryCloudSqlConditions_DatabaseEngine.DATABASE_ENGINE_UNSPECIFIED:
      return "DATABASE_ENGINE_UNSPECIFIED";
    case DiscoveryCloudSqlConditions_DatabaseEngine.ALL_SUPPORTED_DATABASE_ENGINES:
      return "ALL_SUPPORTED_DATABASE_ENGINES";
    case DiscoveryCloudSqlConditions_DatabaseEngine.MYSQL:
      return "MYSQL";
    case DiscoveryCloudSqlConditions_DatabaseEngine.POSTGRES:
      return "POSTGRES";
    case DiscoveryCloudSqlConditions_DatabaseEngine.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Cloud SQL database resource types. New values can be added at a later time. */
export enum DiscoveryCloudSqlConditions_DatabaseResourceType {
  /** DATABASE_RESOURCE_TYPE_UNSPECIFIED - Unused. */
  DATABASE_RESOURCE_TYPE_UNSPECIFIED = 0,
  /** DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES - Includes database resource types that become supported at a later time. */
  DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES = 1,
  /** DATABASE_RESOURCE_TYPE_TABLE - Tables. */
  DATABASE_RESOURCE_TYPE_TABLE = 2,
  UNRECOGNIZED = -1,
}

export function discoveryCloudSqlConditions_DatabaseResourceTypeFromJSON(
  object: any,
): DiscoveryCloudSqlConditions_DatabaseResourceType {
  switch (object) {
    case 0:
    case "DATABASE_RESOURCE_TYPE_UNSPECIFIED":
      return DiscoveryCloudSqlConditions_DatabaseResourceType.DATABASE_RESOURCE_TYPE_UNSPECIFIED;
    case 1:
    case "DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES":
      return DiscoveryCloudSqlConditions_DatabaseResourceType.DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES;
    case 2:
    case "DATABASE_RESOURCE_TYPE_TABLE":
      return DiscoveryCloudSqlConditions_DatabaseResourceType.DATABASE_RESOURCE_TYPE_TABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryCloudSqlConditions_DatabaseResourceType.UNRECOGNIZED;
  }
}

export function discoveryCloudSqlConditions_DatabaseResourceTypeToJSON(
  object: DiscoveryCloudSqlConditions_DatabaseResourceType,
): string {
  switch (object) {
    case DiscoveryCloudSqlConditions_DatabaseResourceType.DATABASE_RESOURCE_TYPE_UNSPECIFIED:
      return "DATABASE_RESOURCE_TYPE_UNSPECIFIED";
    case DiscoveryCloudSqlConditions_DatabaseResourceType.DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES:
      return "DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES";
    case DiscoveryCloudSqlConditions_DatabaseResourceType.DATABASE_RESOURCE_TYPE_TABLE:
      return "DATABASE_RESOURCE_TYPE_TABLE";
    case DiscoveryCloudSqlConditions_DatabaseResourceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * How often existing tables should have their profiles refreshed.
 * New tables are scanned as quickly as possible depending on system
 * capacity.
 */
export interface DiscoveryCloudSqlGenerationCadence {
  /** When to reprofile if the schema has changed. */
  schemaModifiedCadence:
    | DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence
    | undefined;
  /**
   * Data changes (non-schema changes) in Cloud SQL tables can't trigger
   * reprofiling. If you set this field, profiles are refreshed at this
   * frequency regardless of whether the underlying tables have changed.
   * Defaults to never.
   */
  refreshFrequency: DataProfileUpdateFrequency;
  /**
   * Governs when to update data profiles when the inspection rules
   * defined by the `InspectTemplate` change.
   * If not set, changing the template will not cause a data profile to update.
   */
  inspectTemplateModifiedCadence: DiscoveryInspectTemplateModifiedCadence | undefined;
}

/** How frequently to modify the profile when the table's schema is modified. */
export interface DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence {
  /**
   * The types of schema modifications to consider.
   * Defaults to NEW_COLUMNS.
   */
  types: DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification[];
  /**
   * Frequency to regenerate data profiles when the schema is modified.
   * Defaults to monthly.
   */
  frequency: DataProfileUpdateFrequency;
}

/** The type of modification that causes a profile update. */
export enum DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification {
  /** SQL_SCHEMA_MODIFICATION_UNSPECIFIED - Unused. */
  SQL_SCHEMA_MODIFICATION_UNSPECIFIED = 0,
  /** NEW_COLUMNS - New columns have appeared. */
  NEW_COLUMNS = 1,
  /** REMOVED_COLUMNS - Columns have been removed from the table. */
  REMOVED_COLUMNS = 2,
  UNRECOGNIZED = -1,
}

export function discoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModificationFromJSON(
  object: any,
): DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification {
  switch (object) {
    case 0:
    case "SQL_SCHEMA_MODIFICATION_UNSPECIFIED":
      return DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification
        .SQL_SCHEMA_MODIFICATION_UNSPECIFIED;
    case 1:
    case "NEW_COLUMNS":
      return DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification.NEW_COLUMNS;
    case 2:
    case "REMOVED_COLUMNS":
      return DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification.REMOVED_COLUMNS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification.UNRECOGNIZED;
  }
}

export function discoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModificationToJSON(
  object: DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification,
): string {
  switch (object) {
    case DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification
      .SQL_SCHEMA_MODIFICATION_UNSPECIFIED:
      return "SQL_SCHEMA_MODIFICATION_UNSPECIFIED";
    case DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification.NEW_COLUMNS:
      return "NEW_COLUMNS";
    case DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification.REMOVED_COLUMNS:
      return "REMOVED_COLUMNS";
    case DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModification.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Discovery target for credentials and secrets in cloud resource metadata.
 *
 * This target does not include any filtering or frequency controls. Cloud
 * DLP will scan cloud resource metadata for secrets daily.
 *
 * No inspect template should be included in the discovery config for a
 * security benchmarks scan. Instead, the built-in list of secrets and
 * credentials infoTypes will be used (see
 * https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference#credentials_and_secrets).
 *
 * Credentials and secrets discovered will be reported as vulnerabilities to
 * Security Command Center.
 */
export interface SecretsDiscoveryTarget {
}

/** Target used to match against for discovery with Cloud Storage buckets. */
export interface CloudStorageDiscoveryTarget {
  /**
   * Required. The buckets the generation_cadence applies to. The first target
   * with a matching filter will be the one to apply to a bucket.
   */
  filter:
    | DiscoveryCloudStorageFilter
    | undefined;
  /**
   * Optional. In addition to matching the filter, these conditions must be true
   * before a profile is generated.
   */
  conditions:
    | DiscoveryFileStoreConditions
    | undefined;
  /**
   * Optional. How often and when to update profiles. New buckets that match
   * both the filter and conditions are scanned as quickly as possible
   * depending on system capacity.
   */
  generationCadence?:
    | DiscoveryCloudStorageGenerationCadence
    | undefined;
  /** Optional. Disable profiling for buckets that match this filter. */
  disabled?: Disabled | undefined;
}

/**
 * Determines which buckets will have profiles generated within an organization
 * or project. Includes the ability to filter by regular expression patterns
 * on project ID and bucket name.
 */
export interface DiscoveryCloudStorageFilter {
  /** Optional. A specific set of buckets for this filter to apply to. */
  collection?:
    | FileStoreCollection
    | undefined;
  /**
   * Optional. The bucket to scan. Targets including this can only include one
   * target (the target with this bucket). This enables profiling the contents
   * of a single bucket, while the other options allow for easy profiling of
   * many bucets within a project or an organization.
   */
  cloudStorageResourceReference?:
    | CloudStorageResourceReference
    | undefined;
  /**
   * Optional. Catch-all. This should always be the last target in the list
   * because anything above it will apply first. Should only appear once in a
   * configuration. If none is specified, a default one will be added
   * automatically.
   */
  others?: AllOtherResources | undefined;
}

/** Match file stores (e.g. buckets) using regex filters. */
export interface FileStoreCollection {
  /**
   * Optional. A collection of regular expressions to match a file store
   * against.
   */
  includeRegexes?: FileStoreRegexes | undefined;
}

/**
 * A collection of regular expressions to determine what file store to match
 * against.
 */
export interface FileStoreRegexes {
  /**
   * Required. The group of regular expression patterns to match against one or
   * more file stores. Maximum of 100 entries. The sum of all regular
   * expression's length can't exceed 10 KiB.
   */
  patterns: FileStoreRegex[];
}

/** A pattern to match against one or more file stores. */
export interface FileStoreRegex {
  /** Optional. Regex for Cloud Storage. */
  cloudStorageRegex?: CloudStorageRegex | undefined;
}

/**
 * A pattern to match against one or more file stores. At least one
 * pattern must be specified. Regular expressions use RE2
 * [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found
 * under the google/re2 repository on GitHub.
 */
export interface CloudStorageRegex {
  /** Optional. For organizations, if unset, will match all projects. */
  projectIdRegex: string;
  /**
   * Optional. Regex to test the bucket name against. If empty, all buckets
   * match. Example: "marketing2021" or "(marketing)\d{4}" will both match the
   * bucket gs://marketing2021
   */
  bucketNameRegex: string;
}

/** Identifies a single Cloud Storage bucket. */
export interface CloudStorageResourceReference {
  /** Required. The bucket to scan. */
  bucketName: string;
  /**
   * Required. If within a project-level config, then this must match the
   * config's project id.
   */
  projectId: string;
}

/**
 * How often existing buckets should have their profiles refreshed.
 * New buckets are scanned as quickly as possible depending on system
 * capacity.
 */
export interface DiscoveryCloudStorageGenerationCadence {
  /**
   * Optional. Data changes in Cloud Storage can't trigger reprofiling. If you
   * set this field, profiles are refreshed at this frequency regardless of
   * whether the underlying buckets have changed. Defaults to never.
   */
  refreshFrequency: DataProfileUpdateFrequency;
  /**
   * Optional. Governs when to update data profiles when the inspection rules
   * defined by the `InspectTemplate` change.
   * If not set, changing the template will not cause a data profile to update.
   */
  inspectTemplateModifiedCadence: DiscoveryInspectTemplateModifiedCadence | undefined;
}

/**
 * Requirements that must be true before a Cloud Storage bucket or object is
 * scanned in discovery for the first time. There is an AND relationship between
 * the top-level attributes.
 */
export interface DiscoveryCloudStorageConditions {
  /**
   * Required. Only objects with the specified attributes will be scanned. If an
   * object has one of the specified attributes but is inside an excluded
   * bucket, it will not be scanned. Defaults to [ALL_SUPPORTED_OBJECTS]. A
   * profile will be created even if no objects match the
   * included_object_attributes.
   */
  includedObjectAttributes: DiscoveryCloudStorageConditions_CloudStorageObjectAttribute[];
  /**
   * Required. Only objects with the specified attributes will be scanned.
   * Defaults to [ALL_SUPPORTED_BUCKETS] if unset.
   */
  includedBucketAttributes: DiscoveryCloudStorageConditions_CloudStorageBucketAttribute[];
}

/**
 * The attribute of an object. See
 * https://cloud.google.com/storage/docs/storage-classes for more information
 * on storage classes.
 */
export enum DiscoveryCloudStorageConditions_CloudStorageObjectAttribute {
  /** CLOUD_STORAGE_OBJECT_ATTRIBUTE_UNSPECIFIED - Unused. */
  CLOUD_STORAGE_OBJECT_ATTRIBUTE_UNSPECIFIED = 0,
  /** ALL_SUPPORTED_OBJECTS - Scan objects regardless of the attribute. */
  ALL_SUPPORTED_OBJECTS = 1,
  /** STANDARD - Scan objects with the standard storage class. */
  STANDARD = 2,
  /**
   * NEARLINE - Scan objects with the nearline storage class. This will incur retrieval
   * fees.
   */
  NEARLINE = 3,
  /**
   * COLDLINE - Scan objects with the coldline storage class. This will incur retrieval
   * fees.
   */
  COLDLINE = 4,
  /**
   * ARCHIVE - Scan objects with the archive storage class. This will incur retrieval
   * fees.
   */
  ARCHIVE = 5,
  /** REGIONAL - Scan objects with the regional storage class. */
  REGIONAL = 6,
  /** MULTI_REGIONAL - Scan objects with the multi-regional storage class. */
  MULTI_REGIONAL = 7,
  /**
   * DURABLE_REDUCED_AVAILABILITY - Scan objects with the dual-regional storage class. This will incur
   * retrieval fees.
   */
  DURABLE_REDUCED_AVAILABILITY = 8,
  UNRECOGNIZED = -1,
}

export function discoveryCloudStorageConditions_CloudStorageObjectAttributeFromJSON(
  object: any,
): DiscoveryCloudStorageConditions_CloudStorageObjectAttribute {
  switch (object) {
    case 0:
    case "CLOUD_STORAGE_OBJECT_ATTRIBUTE_UNSPECIFIED":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.CLOUD_STORAGE_OBJECT_ATTRIBUTE_UNSPECIFIED;
    case 1:
    case "ALL_SUPPORTED_OBJECTS":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.ALL_SUPPORTED_OBJECTS;
    case 2:
    case "STANDARD":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.STANDARD;
    case 3:
    case "NEARLINE":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.NEARLINE;
    case 4:
    case "COLDLINE":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.COLDLINE;
    case 5:
    case "ARCHIVE":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.ARCHIVE;
    case 6:
    case "REGIONAL":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.REGIONAL;
    case 7:
    case "MULTI_REGIONAL":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.MULTI_REGIONAL;
    case 8:
    case "DURABLE_REDUCED_AVAILABILITY":
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.DURABLE_REDUCED_AVAILABILITY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.UNRECOGNIZED;
  }
}

export function discoveryCloudStorageConditions_CloudStorageObjectAttributeToJSON(
  object: DiscoveryCloudStorageConditions_CloudStorageObjectAttribute,
): string {
  switch (object) {
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.CLOUD_STORAGE_OBJECT_ATTRIBUTE_UNSPECIFIED:
      return "CLOUD_STORAGE_OBJECT_ATTRIBUTE_UNSPECIFIED";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.ALL_SUPPORTED_OBJECTS:
      return "ALL_SUPPORTED_OBJECTS";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.STANDARD:
      return "STANDARD";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.NEARLINE:
      return "NEARLINE";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.COLDLINE:
      return "COLDLINE";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.ARCHIVE:
      return "ARCHIVE";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.REGIONAL:
      return "REGIONAL";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.MULTI_REGIONAL:
      return "MULTI_REGIONAL";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.DURABLE_REDUCED_AVAILABILITY:
      return "DURABLE_REDUCED_AVAILABILITY";
    case DiscoveryCloudStorageConditions_CloudStorageObjectAttribute.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The attribute of a bucket. */
export enum DiscoveryCloudStorageConditions_CloudStorageBucketAttribute {
  /** CLOUD_STORAGE_BUCKET_ATTRIBUTE_UNSPECIFIED - Unused. */
  CLOUD_STORAGE_BUCKET_ATTRIBUTE_UNSPECIFIED = 0,
  /** ALL_SUPPORTED_BUCKETS - Scan buckets regardless of the attribute. */
  ALL_SUPPORTED_BUCKETS = 1,
  /**
   * AUTOCLASS_DISABLED - Buckets with autoclass disabled
   * (https://cloud.google.com/storage/docs/autoclass). Only one of
   * AUTOCLASS_DISABLED or AUTOCLASS_ENABLED should be set.
   */
  AUTOCLASS_DISABLED = 2,
  /**
   * AUTOCLASS_ENABLED - Buckets with autoclass enabled
   * (https://cloud.google.com/storage/docs/autoclass). Only one of
   * AUTOCLASS_DISABLED or AUTOCLASS_ENABLED should be set. Scanning
   * Autoclass-enabled buckets can affect object storage classes.
   */
  AUTOCLASS_ENABLED = 3,
  UNRECOGNIZED = -1,
}

export function discoveryCloudStorageConditions_CloudStorageBucketAttributeFromJSON(
  object: any,
): DiscoveryCloudStorageConditions_CloudStorageBucketAttribute {
  switch (object) {
    case 0:
    case "CLOUD_STORAGE_BUCKET_ATTRIBUTE_UNSPECIFIED":
      return DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.CLOUD_STORAGE_BUCKET_ATTRIBUTE_UNSPECIFIED;
    case 1:
    case "ALL_SUPPORTED_BUCKETS":
      return DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.ALL_SUPPORTED_BUCKETS;
    case 2:
    case "AUTOCLASS_DISABLED":
      return DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.AUTOCLASS_DISABLED;
    case 3:
    case "AUTOCLASS_ENABLED":
      return DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.AUTOCLASS_ENABLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.UNRECOGNIZED;
  }
}

export function discoveryCloudStorageConditions_CloudStorageBucketAttributeToJSON(
  object: DiscoveryCloudStorageConditions_CloudStorageBucketAttribute,
): string {
  switch (object) {
    case DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.CLOUD_STORAGE_BUCKET_ATTRIBUTE_UNSPECIFIED:
      return "CLOUD_STORAGE_BUCKET_ATTRIBUTE_UNSPECIFIED";
    case DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.ALL_SUPPORTED_BUCKETS:
      return "ALL_SUPPORTED_BUCKETS";
    case DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.AUTOCLASS_DISABLED:
      return "AUTOCLASS_DISABLED";
    case DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.AUTOCLASS_ENABLED:
      return "AUTOCLASS_ENABLED";
    case DiscoveryCloudStorageConditions_CloudStorageBucketAttribute.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Requirements that must be true before a file store is scanned in discovery
 * for the first time. There is an AND relationship between the top-level
 * attributes.
 */
export interface DiscoveryFileStoreConditions {
  /**
   * Optional. File store must have been created after this date. Used to avoid
   * backfilling.
   */
  createdAfter:
    | Date
    | undefined;
  /**
   * Optional. Minimum age a file store must have. If set, the value must be 1
   * hour or greater.
   */
  minAge:
    | Duration
    | undefined;
  /** Optional. Cloud Storage conditions. */
  cloudStorageConditions?: DiscoveryCloudStorageConditions | undefined;
}

/**
 * Target used to match against for discovery of resources from other clouds.
 * An [AWS connector in Security Command Center
 * (Enterprise](https://cloud.google.com/security-command-center/docs/connect-scc-to-aws)
 * is required to use this feature.
 */
export interface OtherCloudDiscoveryTarget {
  /**
   * Required. The type of data profiles generated by this discovery target.
   * Supported values are:
   * * aws/s3/bucket
   */
  dataSourceType:
    | DataSourceType
    | undefined;
  /**
   * Required. The resources that the discovery cadence applies to. The
   * first target with a matching filter will be the one to apply to a resource.
   */
  filter:
    | DiscoveryOtherCloudFilter
    | undefined;
  /**
   * Optional. In addition to matching the filter, these conditions must be true
   * before a profile is generated.
   */
  conditions:
    | DiscoveryOtherCloudConditions
    | undefined;
  /**
   * How often and when to update data profiles. New resources that match both
   * the filter and conditions are scanned as quickly as possible depending on
   * system capacity.
   */
  generationCadence?:
    | DiscoveryOtherCloudGenerationCadence
    | undefined;
  /** Disable profiling for resources that match this filter. */
  disabled?: Disabled | undefined;
}

/**
 * Determines which resources from the other cloud will have profiles generated.
 * Includes the ability to filter by resource names.
 */
export interface DiscoveryOtherCloudFilter {
  /** A collection of resources for this filter to apply to. */
  collection?:
    | OtherCloudResourceCollection
    | undefined;
  /**
   * The resource to scan. Configs using this filter can only have one target
   * (the target with this single resource reference).
   */
  singleResource?:
    | OtherCloudSingleResourceReference
    | undefined;
  /**
   * Optional. Catch-all. This should always be the last target in the list
   * because anything above it will apply first. Should only appear once in a
   * configuration. If none is specified, a default one will be added
   * automatically.
   */
  others?: AllOtherResources | undefined;
}

/** Match resources using regex filters. */
export interface OtherCloudResourceCollection {
  /** A collection of regular expressions to match a resource against. */
  includeRegexes?: OtherCloudResourceRegexes | undefined;
}

/**
 * A collection of regular expressions to determine what resources to match
 * against.
 */
export interface OtherCloudResourceRegexes {
  /**
   * A group of regular expression patterns to match against one or more
   * resources.
   * Maximum of 100 entries. The sum of all regular expression's length can't
   * exceed 10 KiB.
   */
  patterns: OtherCloudResourceRegex[];
}

/**
 * A pattern to match against one or more resources. At least one pattern must
 * be specified. Regular expressions use RE2
 * [syntax](https://github.com/google/re2/wiki/Syntax); a guide can be found
 * under the google/re2 repository on GitHub.
 */
export interface OtherCloudResourceRegex {
  /** Regex for Amazon S3 buckets. */
  amazonS3BucketRegex?: AmazonS3BucketRegex | undefined;
}

/** AWS account regex. */
export interface AwsAccountRegex {
  /**
   * Optional. Regex to test the AWS account ID against.
   * If empty, all accounts match.
   */
  accountIdRegex: string;
}

/** Amazon S3 bucket regex. */
export interface AmazonS3BucketRegex {
  /** The AWS account regex. */
  awsAccountRegex:
    | AwsAccountRegex
    | undefined;
  /**
   * Optional. Regex to test the bucket name against.
   * If empty, all buckets match.
   */
  bucketNameRegex: string;
}

/** Identifies a single resource, like a single Amazon S3 bucket. */
export interface OtherCloudSingleResourceReference {
  /** Amazon S3 bucket. */
  amazonS3Bucket?: AmazonS3Bucket | undefined;
}

/** AWS account. */
export interface AwsAccount {
  /** Required. AWS account ID. */
  accountId: string;
}

/** Amazon S3 bucket. */
export interface AmazonS3Bucket {
  /** The AWS account. */
  awsAccount:
    | AwsAccount
    | undefined;
  /** Required. The bucket name. */
  bucketName: string;
}

/**
 * Requirements that must be true before a resource is profiled for the first
 * time.
 */
export interface DiscoveryOtherCloudConditions {
  /**
   * Minimum age a resource must be before Cloud DLP can profile it. Value must
   * be 1 hour or greater.
   */
  minAge:
    | Duration
    | undefined;
  /** Amazon S3 bucket conditions. */
  amazonS3BucketConditions?: AmazonS3BucketConditions | undefined;
}

/** Amazon S3 bucket conditions. */
export interface AmazonS3BucketConditions {
  /**
   * Optional. Bucket types that should be profiled.
   * Optional. Defaults to TYPE_ALL_SUPPORTED if unspecified.
   */
  bucketTypes: AmazonS3BucketConditions_BucketType[];
  /**
   * Optional. Object classes that should be profiled.
   * Optional. Defaults to ALL_SUPPORTED_CLASSES if unspecified.
   */
  objectStorageClasses: AmazonS3BucketConditions_ObjectStorageClass[];
}

/**
 * Supported Amazon S3 bucket types.
 * Defaults to TYPE_ALL_SUPPORTED.
 */
export enum AmazonS3BucketConditions_BucketType {
  /** TYPE_UNSPECIFIED - Unused. */
  TYPE_UNSPECIFIED = 0,
  /** TYPE_ALL_SUPPORTED - All supported classes. */
  TYPE_ALL_SUPPORTED = 1,
  /** TYPE_GENERAL_PURPOSE - A general purpose Amazon S3 bucket. */
  TYPE_GENERAL_PURPOSE = 2,
  UNRECOGNIZED = -1,
}

export function amazonS3BucketConditions_BucketTypeFromJSON(object: any): AmazonS3BucketConditions_BucketType {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return AmazonS3BucketConditions_BucketType.TYPE_UNSPECIFIED;
    case 1:
    case "TYPE_ALL_SUPPORTED":
      return AmazonS3BucketConditions_BucketType.TYPE_ALL_SUPPORTED;
    case 2:
    case "TYPE_GENERAL_PURPOSE":
      return AmazonS3BucketConditions_BucketType.TYPE_GENERAL_PURPOSE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AmazonS3BucketConditions_BucketType.UNRECOGNIZED;
  }
}

export function amazonS3BucketConditions_BucketTypeToJSON(object: AmazonS3BucketConditions_BucketType): string {
  switch (object) {
    case AmazonS3BucketConditions_BucketType.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case AmazonS3BucketConditions_BucketType.TYPE_ALL_SUPPORTED:
      return "TYPE_ALL_SUPPORTED";
    case AmazonS3BucketConditions_BucketType.TYPE_GENERAL_PURPOSE:
      return "TYPE_GENERAL_PURPOSE";
    case AmazonS3BucketConditions_BucketType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Supported Amazon S3 object storage classes.
 * Defaults to ALL_SUPPORTED_CLASSES.
 */
export enum AmazonS3BucketConditions_ObjectStorageClass {
  /** UNSPECIFIED - Unused. */
  UNSPECIFIED = 0,
  /** ALL_SUPPORTED_CLASSES - All supported classes. */
  ALL_SUPPORTED_CLASSES = 1,
  /** STANDARD - Standard object class. */
  STANDARD = 2,
  /** STANDARD_INFREQUENT_ACCESS - Standard - infrequent access object class. */
  STANDARD_INFREQUENT_ACCESS = 4,
  /** GLACIER_INSTANT_RETRIEVAL - Glacier - instant retrieval object class. */
  GLACIER_INSTANT_RETRIEVAL = 6,
  /** INTELLIGENT_TIERING - Objects in the S3 Intelligent-Tiering access tiers. */
  INTELLIGENT_TIERING = 7,
  UNRECOGNIZED = -1,
}

export function amazonS3BucketConditions_ObjectStorageClassFromJSON(
  object: any,
): AmazonS3BucketConditions_ObjectStorageClass {
  switch (object) {
    case 0:
    case "UNSPECIFIED":
      return AmazonS3BucketConditions_ObjectStorageClass.UNSPECIFIED;
    case 1:
    case "ALL_SUPPORTED_CLASSES":
      return AmazonS3BucketConditions_ObjectStorageClass.ALL_SUPPORTED_CLASSES;
    case 2:
    case "STANDARD":
      return AmazonS3BucketConditions_ObjectStorageClass.STANDARD;
    case 4:
    case "STANDARD_INFREQUENT_ACCESS":
      return AmazonS3BucketConditions_ObjectStorageClass.STANDARD_INFREQUENT_ACCESS;
    case 6:
    case "GLACIER_INSTANT_RETRIEVAL":
      return AmazonS3BucketConditions_ObjectStorageClass.GLACIER_INSTANT_RETRIEVAL;
    case 7:
    case "INTELLIGENT_TIERING":
      return AmazonS3BucketConditions_ObjectStorageClass.INTELLIGENT_TIERING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AmazonS3BucketConditions_ObjectStorageClass.UNRECOGNIZED;
  }
}

export function amazonS3BucketConditions_ObjectStorageClassToJSON(
  object: AmazonS3BucketConditions_ObjectStorageClass,
): string {
  switch (object) {
    case AmazonS3BucketConditions_ObjectStorageClass.UNSPECIFIED:
      return "UNSPECIFIED";
    case AmazonS3BucketConditions_ObjectStorageClass.ALL_SUPPORTED_CLASSES:
      return "ALL_SUPPORTED_CLASSES";
    case AmazonS3BucketConditions_ObjectStorageClass.STANDARD:
      return "STANDARD";
    case AmazonS3BucketConditions_ObjectStorageClass.STANDARD_INFREQUENT_ACCESS:
      return "STANDARD_INFREQUENT_ACCESS";
    case AmazonS3BucketConditions_ObjectStorageClass.GLACIER_INSTANT_RETRIEVAL:
      return "GLACIER_INSTANT_RETRIEVAL";
    case AmazonS3BucketConditions_ObjectStorageClass.INTELLIGENT_TIERING:
      return "INTELLIGENT_TIERING";
    case AmazonS3BucketConditions_ObjectStorageClass.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * How often existing resources should have their profiles refreshed.
 * New resources are scanned as quickly as possible depending on system
 * capacity.
 */
export interface DiscoveryOtherCloudGenerationCadence {
  /**
   * Optional. Frequency to update profiles regardless of whether the underlying
   * resource has changes. Defaults to never.
   */
  refreshFrequency: DataProfileUpdateFrequency;
  /**
   * Optional. Governs when to update data profiles when the inspection rules
   * defined by the `InspectTemplate` change.
   * If not set, changing the template will not cause a data profile to update.
   */
  inspectTemplateModifiedCadence: DiscoveryInspectTemplateModifiedCadence | undefined;
}

/**
 * The location to begin a discovery scan. Denotes an organization ID or folder
 * ID within an organization.
 */
export interface DiscoveryStartingLocation {
  /** The ID of an organization to scan. */
  organizationId?:
    | Long
    | undefined;
  /** The ID of the folder within an organization to be scanned. */
  folderId?: Long | undefined;
}

/** The other cloud starting location for discovery. */
export interface OtherCloudDiscoveryStartingLocation {
  /** The AWS starting location for discovery. */
  awsLocation?: OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation | undefined;
}

/** The AWS starting location for discovery. */
export interface OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation {
  /**
   * The AWS account ID that this discovery config applies to.
   * Within an AWS organization, you can find the AWS account ID inside an
   * AWS account ARN. Example:
   * arn:{partition}:organizations::{management_account_id}:account/{org_id}/{account_id}
   */
  accountId?:
    | string
    | undefined;
  /**
   * All AWS assets stored in Asset Inventory that didn't match other AWS
   * discovery configs.
   */
  allAssetInventoryAssets?: boolean | undefined;
}

/** Match discovery resources not covered by any other filter. */
export interface AllOtherResources {
}

/** Combines all of the information about a DLP job. */
export interface DlpJob {
  /** The server-assigned name. */
  name: string;
  /** The type of job. */
  type: DlpJobType;
  /** State of a job. */
  state: DlpJob_JobState;
  /** Results from analyzing risk of a data source. */
  riskDetails?:
    | AnalyzeDataSourceRiskDetails
    | undefined;
  /** Results from inspecting a data source. */
  inspectDetails?:
    | InspectDataSourceDetails
    | undefined;
  /** Time when the job was created. */
  createTime:
    | Date
    | undefined;
  /** Time when the job started. */
  startTime:
    | Date
    | undefined;
  /** Time when the job finished. */
  endTime:
    | Date
    | undefined;
  /** Time when the job was last modified by the system. */
  lastModified:
    | Date
    | undefined;
  /**
   * If created by a job trigger, the resource name of the trigger that
   * instantiated the job.
   */
  jobTriggerName: string;
  /** A stream of errors encountered running the job. */
  errors: Error[];
  /** Events that should occur after the job has completed. */
  actionDetails: ActionDetails[];
}

/** Possible states of a job. New items may be added. */
export enum DlpJob_JobState {
  /** JOB_STATE_UNSPECIFIED - Unused. */
  JOB_STATE_UNSPECIFIED = 0,
  /** PENDING - The job has not yet started. */
  PENDING = 1,
  /**
   * RUNNING - The job is currently running. Once a job has finished it will transition
   * to FAILED or DONE.
   */
  RUNNING = 2,
  /** DONE - The job is no longer running. */
  DONE = 3,
  /** CANCELED - The job was canceled before it could be completed. */
  CANCELED = 4,
  /** FAILED - The job had an error and did not complete. */
  FAILED = 5,
  /**
   * ACTIVE - The job is currently accepting findings via hybridInspect.
   * A hybrid job in ACTIVE state may continue to have findings added to it
   * through the calling of hybridInspect. After the job has finished no more
   * calls to hybridInspect may be made. ACTIVE jobs can transition to DONE.
   */
  ACTIVE = 6,
  UNRECOGNIZED = -1,
}

export function dlpJob_JobStateFromJSON(object: any): DlpJob_JobState {
  switch (object) {
    case 0:
    case "JOB_STATE_UNSPECIFIED":
      return DlpJob_JobState.JOB_STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return DlpJob_JobState.PENDING;
    case 2:
    case "RUNNING":
      return DlpJob_JobState.RUNNING;
    case 3:
    case "DONE":
      return DlpJob_JobState.DONE;
    case 4:
    case "CANCELED":
      return DlpJob_JobState.CANCELED;
    case 5:
    case "FAILED":
      return DlpJob_JobState.FAILED;
    case 6:
    case "ACTIVE":
      return DlpJob_JobState.ACTIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DlpJob_JobState.UNRECOGNIZED;
  }
}

export function dlpJob_JobStateToJSON(object: DlpJob_JobState): string {
  switch (object) {
    case DlpJob_JobState.JOB_STATE_UNSPECIFIED:
      return "JOB_STATE_UNSPECIFIED";
    case DlpJob_JobState.PENDING:
      return "PENDING";
    case DlpJob_JobState.RUNNING:
      return "RUNNING";
    case DlpJob_JobState.DONE:
      return "DONE";
    case DlpJob_JobState.CANCELED:
      return "CANCELED";
    case DlpJob_JobState.FAILED:
      return "FAILED";
    case DlpJob_JobState.ACTIVE:
      return "ACTIVE";
    case DlpJob_JobState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The request message for [DlpJobs.GetDlpJob][]. */
export interface GetDlpJobRequest {
  /** Required. The name of the DlpJob resource. */
  name: string;
}

/** The request message for listing DLP jobs. */
export interface ListDlpJobsRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on whether you have [specified a
   * processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Allows filtering.
   *
   * Supported syntax:
   *
   * * Filter expressions are made up of one or more restrictions.
   * * Restrictions can be combined by `AND` or `OR` logical operators. A
   * sequence of restrictions implicitly uses `AND`.
   * * A restriction has the form of `{field} {operator} {value}`.
   * * Supported fields/values for inspect jobs:
   *     - `state` - PENDING|RUNNING|CANCELED|FINISHED|FAILED
   *     - `inspected_storage` - DATASTORE|CLOUD_STORAGE|BIGQUERY
   *     - `trigger_name` - The name of the trigger that created the job.
   *     - 'end_time` - Corresponds to the time the job finished.
   *     - 'start_time` - Corresponds to the time the job finished.
   * * Supported fields for risk analysis jobs:
   *     - `state` - RUNNING|CANCELED|FINISHED|FAILED
   *     - 'end_time` - Corresponds to the time the job finished.
   *     - 'start_time` - Corresponds to the time the job finished.
   * * The operator must be `=` or `!=`.
   *
   * Examples:
   *
   * * inspected_storage = cloud_storage AND state = done
   * * inspected_storage = cloud_storage OR inspected_storage = bigquery
   * * inspected_storage = cloud_storage AND (state = done OR state = canceled)
   * * end_time > \"2017-12-12T00:00:00+00:00\"
   *
   * The length of this field should be no more than 500 characters.
   */
  filter: string;
  /** The standard list page size. */
  pageSize: number;
  /** The standard list page token. */
  pageToken: string;
  /** The type of job. Defaults to `DlpJobType.INSPECT` */
  type: DlpJobType;
  /**
   * Comma-separated list of fields to order by,
   * followed by `asc` or `desc` postfix. This list is case insensitive. The
   * default sorting order is ascending. Redundant space characters are
   * insignificant.
   *
   * Example: `name asc, end_time asc, create_time desc`
   *
   * Supported fields are:
   *
   * - `create_time`: corresponds to the time the job was created.
   * - `end_time`: corresponds to the time the job ended.
   * - `name`: corresponds to the job's name.
   * - `state`: corresponds to `state`
   */
  orderBy: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** The response message for listing DLP jobs. */
export interface ListDlpJobsResponse {
  /** A list of DlpJobs that matches the specified filter in the request. */
  jobs: DlpJob[];
  /** The standard List next-page token. */
  nextPageToken: string;
}

/** The request message for canceling a DLP job. */
export interface CancelDlpJobRequest {
  /** Required. The name of the DlpJob resource to be cancelled. */
  name: string;
}

/** The request message for finishing a DLP hybrid job. */
export interface FinishDlpJobRequest {
  /** Required. The name of the DlpJob resource to be finished. */
  name: string;
}

/** The request message for deleting a DLP job. */
export interface DeleteDlpJobRequest {
  /** Required. The name of the DlpJob resource to be deleted. */
  name: string;
}

/** Request message for CreateDeidentifyTemplate. */
export interface CreateDeidentifyTemplateRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization) and whether you have [specified a processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   * + Organizations scope, location specified:
   *   `organizations/{org_id}/locations/{location_id}`
   * + Organizations scope, no location specified (defaults to global):
   *   `organizations/{org_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** Required. The DeidentifyTemplate to create. */
  deidentifyTemplate:
    | DeidentifyTemplate
    | undefined;
  /**
   * The template id can contain uppercase and lowercase letters,
   * numbers, and hyphens; that is, it must match the regular
   * expression: `[a-zA-Z\d-_]+`. The maximum length is 100
   * characters. Can be empty to allow the system to generate one.
   */
  templateId: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Request message for UpdateDeidentifyTemplate. */
export interface UpdateDeidentifyTemplateRequest {
  /**
   * Required. Resource name of organization and deidentify template to be
   * updated, for example
   * `organizations/433245324/deidentifyTemplates/432452342` or
   * projects/project-id/deidentifyTemplates/432452342.
   */
  name: string;
  /** New DeidentifyTemplate value. */
  deidentifyTemplate:
    | DeidentifyTemplate
    | undefined;
  /** Mask to control which fields get updated. */
  updateMask: string[] | undefined;
}

/** Request message for GetDeidentifyTemplate. */
export interface GetDeidentifyTemplateRequest {
  /**
   * Required. Resource name of the organization and deidentify template to be
   * read, for example `organizations/433245324/deidentifyTemplates/432452342`
   * or projects/project-id/deidentifyTemplates/432452342.
   */
  name: string;
}

/** Request message for ListDeidentifyTemplates. */
export interface ListDeidentifyTemplatesRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization) and whether you have [specified a processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   * + Organizations scope, location specified:
   *   `organizations/{org_id}/locations/{location_id}`
   * + Organizations scope, no location specified (defaults to global):
   *   `organizations/{org_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Page token to continue retrieval. Comes from the previous call
   * to `ListDeidentifyTemplates`.
   */
  pageToken: string;
  /**
   * Size of the page. This value can be limited by the server. If zero server
   * returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Comma-separated list of fields to order by,
   * followed by `asc` or `desc` postfix. This list is case insensitive. The
   * default sorting order is ascending. Redundant space characters are
   * insignificant.
   *
   * Example: `name asc,update_time, create_time desc`
   *
   * Supported fields are:
   *
   * - `create_time`: corresponds to the time the template was created.
   * - `update_time`: corresponds to the time the template was last updated.
   * - `name`: corresponds to the template's name.
   * - `display_name`: corresponds to the template's display name.
   */
  orderBy: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Response message for ListDeidentifyTemplates. */
export interface ListDeidentifyTemplatesResponse {
  /**
   * List of deidentify templates, up to page_size in
   * ListDeidentifyTemplatesRequest.
   */
  deidentifyTemplates: DeidentifyTemplate[];
  /**
   * If the next page is available then the next page token to be used in the
   * following ListDeidentifyTemplates request.
   */
  nextPageToken: string;
}

/** Request message for DeleteDeidentifyTemplate. */
export interface DeleteDeidentifyTemplateRequest {
  /**
   * Required. Resource name of the organization and deidentify template to be
   * deleted, for example
   * `organizations/433245324/deidentifyTemplates/432452342` or
   * projects/project-id/deidentifyTemplates/432452342.
   */
  name: string;
}

/**
 * Configuration for a custom dictionary created from a data source of any size
 * up to the maximum size defined in the
 * [limits](https://cloud.google.com/sensitive-data-protection/limits) page. The
 * artifacts of dictionary creation are stored in the specified Cloud Storage
 * location. Consider using `CustomInfoType.Dictionary` for smaller dictionaries
 * that satisfy the size requirements.
 */
export interface LargeCustomDictionaryConfig {
  /**
   * Location to store dictionary artifacts in Cloud Storage. These files
   * will only be accessible by project owners and the DLP API. If any of these
   * artifacts are modified, the dictionary is considered invalid and can no
   * longer be used.
   */
  outputPath:
    | CloudStoragePath
    | undefined;
  /** Set of files containing newline-delimited lists of dictionary phrases. */
  cloudStorageFileSet?:
    | CloudStorageFileSet
    | undefined;
  /** Field in a BigQuery table where each cell represents a dictionary phrase. */
  bigQueryField?: BigQueryField | undefined;
}

/** Summary statistics of a custom dictionary. */
export interface LargeCustomDictionaryStats {
  /** Approximate number of distinct phrases in the dictionary. */
  approxNumPhrases: Long;
}

/**
 * Configuration for stored infoTypes. All fields and subfield are provided
 * by the user. For more information, see
 * https://cloud.google.com/sensitive-data-protection/docs/creating-custom-infotypes.
 */
export interface StoredInfoTypeConfig {
  /** Display name of the StoredInfoType (max 256 characters). */
  displayName: string;
  /** Description of the StoredInfoType (max 256 characters). */
  description: string;
  /** StoredInfoType where findings are defined by a dictionary of phrases. */
  largeCustomDictionary?:
    | LargeCustomDictionaryConfig
    | undefined;
  /** Store dictionary-based CustomInfoType. */
  dictionary?:
    | CustomInfoType_Dictionary
    | undefined;
  /** Store regular expression-based StoredInfoType. */
  regex?: CustomInfoType_Regex | undefined;
}

/** Statistics for a StoredInfoType. */
export interface StoredInfoTypeStats {
  /** StoredInfoType where findings are defined by a dictionary of phrases. */
  largeCustomDictionary?: LargeCustomDictionaryStats | undefined;
}

/**
 * Version of a StoredInfoType, including the configuration used to build it,
 * create timestamp, and current state.
 */
export interface StoredInfoTypeVersion {
  /** StoredInfoType configuration. */
  config:
    | StoredInfoTypeConfig
    | undefined;
  /**
   * Create timestamp of the version. Read-only, determined by the system
   * when the version is created.
   */
  createTime:
    | Date
    | undefined;
  /**
   * Stored info type version state. Read-only, updated by the system
   * during dictionary creation.
   */
  state: StoredInfoTypeState;
  /**
   * Errors that occurred when creating this storedInfoType version, or
   * anomalies detected in the storedInfoType data that render it unusable. Only
   * the five most recent errors will be displayed, with the most recent error
   * appearing first.
   *
   * For example, some of the data for stored custom dictionaries is put in
   * the user's Cloud Storage bucket, and if this data is modified or
   * deleted by the user or another system, the dictionary becomes invalid.
   *
   * If any errors occur, fix the problem indicated by the error message and
   * use the UpdateStoredInfoType API method to create another version of the
   * storedInfoType to continue using it, reusing the same `config` if it was
   * not the source of the error.
   */
  errors: Error[];
  /** Statistics about this storedInfoType version. */
  stats: StoredInfoTypeStats | undefined;
}

/**
 * StoredInfoType resource message that contains information about the current
 * version and any pending updates.
 */
export interface StoredInfoType {
  /** Resource name. */
  name: string;
  /** Current version of the stored info type. */
  currentVersion:
    | StoredInfoTypeVersion
    | undefined;
  /**
   * Pending versions of the stored info type. Empty if no versions are
   * pending.
   */
  pendingVersions: StoredInfoTypeVersion[];
}

/** Request message for CreateStoredInfoType. */
export interface CreateStoredInfoTypeRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization) and whether you have [specified a processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   * + Organizations scope, location specified:
   *   `organizations/{org_id}/locations/{location_id}`
   * + Organizations scope, no location specified (defaults to global):
   *   `organizations/{org_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /** Required. Configuration of the storedInfoType to create. */
  config:
    | StoredInfoTypeConfig
    | undefined;
  /**
   * The storedInfoType ID can contain uppercase and lowercase letters,
   * numbers, and hyphens; that is, it must match the regular
   * expression: `[a-zA-Z\d-_]+`. The maximum length is 100
   * characters. Can be empty to allow the system to generate one.
   */
  storedInfoTypeId: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Request message for UpdateStoredInfoType. */
export interface UpdateStoredInfoTypeRequest {
  /**
   * Required. Resource name of organization and storedInfoType to be updated,
   * for example `organizations/433245324/storedInfoTypes/432452342` or
   * projects/project-id/storedInfoTypes/432452342.
   */
  name: string;
  /**
   * Updated configuration for the storedInfoType. If not provided, a new
   * version of the storedInfoType will be created with the existing
   * configuration.
   */
  config:
    | StoredInfoTypeConfig
    | undefined;
  /** Mask to control which fields get updated. */
  updateMask: string[] | undefined;
}

/** Request message for GetStoredInfoType. */
export interface GetStoredInfoTypeRequest {
  /**
   * Required. Resource name of the organization and storedInfoType to be read,
   * for example `organizations/433245324/storedInfoTypes/432452342` or
   * projects/project-id/storedInfoTypes/432452342.
   */
  name: string;
}

/** Request message for ListStoredInfoTypes. */
export interface ListStoredInfoTypesRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization) and whether you have [specified a processing
   * location](https://cloud.google.com/sensitive-data-protection/docs/specifying-location):
   *
   * + Projects scope, location specified:
   *   `projects/{project_id}/locations/{location_id}`
   * + Projects scope, no location specified (defaults to global):
   *   `projects/{project_id}`
   *
   * The following example `parent` string specifies a parent project with the
   * identifier `example-project`, and specifies the `europe-west3` location
   * for processing data:
   *
   *     parent=projects/example-project/locations/europe-west3
   */
  parent: string;
  /**
   * Page token to continue retrieval. Comes from the previous call
   * to `ListStoredInfoTypes`.
   */
  pageToken: string;
  /**
   * Size of the page. This value can be limited by the server. If zero server
   * returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Comma-separated list of fields to order by,
   * followed by `asc` or `desc` postfix. This list is case insensitive. The
   * default sorting order is ascending. Redundant space characters are
   * insignificant.
   *
   * Example: `name asc, display_name, create_time desc`
   *
   * Supported fields are:
   *
   * - `create_time`: corresponds to the time the most recent version of the
   * resource was created.
   * - `state`: corresponds to the state of the resource.
   * - `name`: corresponds to resource name.
   * - `display_name`: corresponds to info type's display name.
   */
  orderBy: string;
  /** Deprecated. This field has no effect. */
  locationId: string;
}

/** Response message for ListStoredInfoTypes. */
export interface ListStoredInfoTypesResponse {
  /** List of storedInfoTypes, up to page_size in ListStoredInfoTypesRequest. */
  storedInfoTypes: StoredInfoType[];
  /**
   * If the next page is available then the next page token to be used
   * in the following ListStoredInfoTypes request.
   */
  nextPageToken: string;
}

/** Request message for DeleteStoredInfoType. */
export interface DeleteStoredInfoTypeRequest {
  /**
   * Required. Resource name of the organization and storedInfoType to be
   * deleted, for example `organizations/433245324/storedInfoTypes/432452342` or
   * projects/project-id/storedInfoTypes/432452342.
   */
  name: string;
}

/** Request to search for potentially sensitive info in a custom location. */
export interface HybridInspectJobTriggerRequest {
  /**
   * Required. Resource name of the trigger to execute a hybrid inspect on, for
   * example `projects/dlp-test-project/jobTriggers/53234423`.
   */
  name: string;
  /** The item to inspect. */
  hybridItem: HybridContentItem | undefined;
}

/** Request to search for potentially sensitive info in a custom location. */
export interface HybridInspectDlpJobRequest {
  /**
   * Required. Resource name of the job to execute a hybrid inspect on, for
   * example `projects/dlp-test-project/dlpJob/53234423`.
   */
  name: string;
  /** The item to inspect. */
  hybridItem: HybridContentItem | undefined;
}

/**
 * An individual hybrid item to inspect. Will be stored temporarily during
 * processing.
 */
export interface HybridContentItem {
  /** The item to inspect. */
  item:
    | ContentItem
    | undefined;
  /** Supplementary information that will be added to each finding. */
  findingDetails: HybridFindingDetails | undefined;
}

/** Populate to associate additional data with each finding. */
export interface HybridFindingDetails {
  /** Details about the container where the content being inspected is from. */
  containerDetails:
    | Container
    | undefined;
  /**
   * Offset in bytes of the line, from the beginning of the file, where the
   * finding  is located. Populate if the item being scanned is only part of a
   * bigger item, such as a shard of a file and you want to track the absolute
   * position of the finding.
   */
  fileOffset: Long;
  /**
   * Offset of the row for tables. Populate if the row(s) being scanned are
   * part of a bigger dataset and you want to keep track of their absolute
   * position.
   */
  rowOffset: Long;
  /**
   * If the container is a table, additional information to make findings
   * meaningful such as the columns that are primary keys. If not known ahead
   * of time, can also be set within each inspect hybrid call and the two
   * will be merged. Note that identifying_fields will only be stored to
   * BigQuery, and only if the BigQuery action has been included.
   */
  tableOptions:
    | TableOptions
    | undefined;
  /**
   * Labels to represent user provided metadata about the data being inspected.
   * If configured by the job, some key values may be required.
   * The labels associated with `Finding`'s produced by hybrid
   * inspection.
   *
   * Label keys must be between 1 and 63 characters long and must conform
   * to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`.
   *
   * Label values must be between 0 and 63 characters long and must conform
   * to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`.
   *
   * No more than 10 labels can be associated with a given finding.
   *
   * Examples:
   *
   * * `"environment" : "production"`
   * * `"pipeline" : "etl"`
   */
  labels: { [key: string]: string };
}

export interface HybridFindingDetails_LabelsEntry {
  key: string;
  value: string;
}

/** Quota exceeded errors will be thrown once quota has been met. */
export interface HybridInspectResponse {
}

/** Request to list the profiles generated for a given organization or project. */
export interface ListProjectDataProfilesRequest {
  /** Required. organizations/{org_id}/locations/{loc_id} */
  parent: string;
  /** Page token to continue retrieval. */
  pageToken: string;
  /**
   * Size of the page. This value can be limited by the server. If zero, server
   * returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Comma-separated list of fields to order by, followed by `asc` or `desc`
   * postfix. This list is case insensitive. The default sorting order is
   * ascending. Redundant space characters are insignificant. Only one order
   * field at a time is allowed.
   *
   * Examples:
   * * `project_id`
   * * `sensitivity_level desc`
   *
   * Supported fields are:
   *
   * - `project_id`: Google Cloud project ID
   * - `sensitivity_level`: How sensitive the data in a project is, at most.
   * - `data_risk_level`: How much risk is associated with this data.
   * - `profile_last_generated`: When the profile was last updated in epoch
   * seconds.
   */
  orderBy: string;
  /**
   * Allows filtering.
   *
   * Supported syntax:
   *
   * * Filter expressions are made up of one or more restrictions.
   * * Restrictions can be combined by `AND` or `OR` logical operators. A
   * sequence of restrictions implicitly uses `AND`.
   * * A restriction has the form of `{field} {operator} {value}`.
   * * Supported fields/values:
   *     - `sensitivity_level` - HIGH|MODERATE|LOW
   *     - `data_risk_level` - HIGH|MODERATE|LOW
   *     - `status_code` - an RPC status code as defined in
   *     https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto
   * * The operator must be `=` or `!=`.
   *
   * Examples:
   *
   * * `project_id = 12345 AND status_code = 1`
   * * `project_id = 12345 AND sensitivity_level = HIGH`
   *
   * The length of this field should be no more than 500 characters.
   */
  filter: string;
}

/** List of profiles generated for a given organization or project. */
export interface ListProjectDataProfilesResponse {
  /** List of data profiles. */
  projectDataProfiles: ProjectDataProfile[];
  /** The next page token. */
  nextPageToken: string;
}

/** Request to list the profiles generated for a given organization or project. */
export interface ListTableDataProfilesRequest {
  /**
   * Required. Resource name of the organization or project, for
   * example `organizations/433245324/locations/europe` or
   * `projects/project-id/locations/asia`.
   */
  parent: string;
  /** Page token to continue retrieval. */
  pageToken: string;
  /**
   * Size of the page. This value can be limited by the server. If zero, server
   * returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Comma-separated list of fields to order by, followed by `asc` or `desc`
   * postfix. This list is case insensitive. The default sorting order is
   * ascending. Redundant space characters are insignificant. Only one order
   * field at a time is allowed.
   *
   * Examples:
   * * `project_id asc`
   * * `table_id`
   * * `sensitivity_level desc`
   *
   * Supported fields are:
   *
   * - `project_id`: The Google Cloud project ID.
   * - `dataset_id`: The ID of a BigQuery dataset.
   * - `table_id`: The ID of a BigQuery table.
   * - `sensitivity_level`: How sensitive the data in a table is, at most.
   * - `data_risk_level`: How much risk is associated with this data.
   * - `profile_last_generated`: When the profile was last updated in epoch
   * seconds.
   * - `last_modified`: The last time the resource was modified.
   * - `resource_visibility`: Visibility restriction for this resource.
   * - `row_count`: Number of rows in this resource.
   */
  orderBy: string;
  /**
   * Allows filtering.
   *
   * Supported syntax:
   *
   * * Filter expressions are made up of one or more restrictions.
   * * Restrictions can be combined by `AND` or `OR` logical operators. A
   * sequence of restrictions implicitly uses `AND`.
   * * A restriction has the form of `{field} {operator} {value}`.
   * * Supported fields/values:
   *     - `project_id` - The Google Cloud project ID.
   *     - `dataset_id` - The BigQuery dataset ID.
   *     - `table_id` - The ID of the BigQuery table.
   *     - `sensitivity_level` - HIGH|MODERATE|LOW
   *     - `data_risk_level` - HIGH|MODERATE|LOW
   *     - `resource_visibility`: PUBLIC|RESTRICTED
   *     - `status_code` - an RPC status code as defined in
   *     https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto
   * * The operator must be `=` or `!=`.
   *
   * Examples:
   *
   * * `project_id = 12345 AND status_code = 1`
   * * `project_id = 12345 AND sensitivity_level = HIGH`
   * * `project_id = 12345 AND resource_visibility = PUBLIC`
   *
   * The length of this field should be no more than 500 characters.
   */
  filter: string;
}

/** List of profiles generated for a given organization or project. */
export interface ListTableDataProfilesResponse {
  /** List of data profiles. */
  tableDataProfiles: TableDataProfile[];
  /** The next page token. */
  nextPageToken: string;
}

/** Request to list the profiles generated for a given organization or project. */
export interface ListColumnDataProfilesRequest {
  /**
   * Required. Resource name of the organization or project, for
   * example `organizations/433245324/locations/europe` or
   * `projects/project-id/locations/asia`.
   */
  parent: string;
  /** Page token to continue retrieval. */
  pageToken: string;
  /**
   * Size of the page. This value can be limited by the server. If zero, server
   * returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Comma-separated list of fields to order by, followed by `asc` or `desc`
   * postfix. This list is case insensitive. The default sorting order is
   * ascending. Redundant space characters are insignificant. Only one order
   * field at a time is allowed.
   *
   * Examples:
   *
   * * `project_id asc`
   * * `table_id`
   * * `sensitivity_level desc`
   *
   * Supported fields are:
   *
   * - `project_id`: The Google Cloud project ID.
   * - `dataset_id`: The ID of a BigQuery dataset.
   * - `table_id`: The ID of a BigQuery table.
   * - `sensitivity_level`: How sensitive the data in a column is, at most.
   * - `data_risk_level`: How much risk is associated with this data.
   * - `profile_last_generated`: When the profile was last updated in epoch
   * seconds.
   */
  orderBy: string;
  /**
   * Allows filtering.
   *
   * Supported syntax:
   *
   * * Filter expressions are made up of one or more restrictions.
   * * Restrictions can be combined by `AND` or `OR` logical operators. A
   * sequence of restrictions implicitly uses `AND`.
   * * A restriction has the form of `{field} {operator} {value}`.
   * * Supported fields/values:
   *     - `table_data_profile_name` - The name of the related table data
   *     profile.
   *     - `project_id` - The Google Cloud project ID. (REQUIRED)
   *     - `dataset_id` - The BigQuery dataset ID. (REQUIRED)
   *     - `table_id` - The BigQuery table ID. (REQUIRED)
   *     - `field_id` - The ID of the BigQuery field.
   *     - `info_type` - The infotype detected in the resource.
   *     - `sensitivity_level` - HIGH|MEDIUM|LOW
   *     - `data_risk_level`: How much risk is associated with this data.
   *     - `status_code` - an RPC status code as defined in
   *     https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto
   * * The operator must be `=` for project_id, dataset_id, and table_id. Other
   *   filters also support `!=`.
   *
   * Examples:
   *
   * * project_id = 12345 AND status_code = 1
   * * project_id = 12345 AND sensitivity_level = HIGH
   * * project_id = 12345 AND info_type = STREET_ADDRESS
   *
   * The length of this field should be no more than 500 characters.
   */
  filter: string;
}

/** List of profiles generated for a given organization or project. */
export interface ListColumnDataProfilesResponse {
  /** List of data profiles. */
  columnDataProfiles: ColumnDataProfile[];
  /** The next page token. */
  nextPageToken: string;
}

/**
 * Score is a summary of all elements in the data profile.
 * A higher number means more risk.
 */
export interface DataRiskLevel {
  /** The score applied to the resource. */
  score: DataRiskLevel_DataRiskLevelScore;
}

/** Various score levels for resources. */
export enum DataRiskLevel_DataRiskLevelScore {
  /** RISK_SCORE_UNSPECIFIED - Unused. */
  RISK_SCORE_UNSPECIFIED = 0,
  /**
   * RISK_LOW - Low risk - Lower indication of sensitive data that appears to have
   * additional access restrictions in place or no indication of sensitive
   * data found.
   */
  RISK_LOW = 10,
  /** RISK_UNKNOWN - Unable to determine risk. */
  RISK_UNKNOWN = 12,
  /**
   * RISK_MODERATE - Medium risk - Sensitive data may be present but additional access or fine
   * grain access restrictions appear to be present.  Consider limiting
   * access even further or transform data to mask.
   */
  RISK_MODERATE = 20,
  /**
   * RISK_HIGH - High risk  SPII may be present. Access controls may include public
   * ACLs. Exfiltration of data may lead to user data loss. Re-identification
   * of users may be possible. Consider limiting usage and or removing SPII.
   */
  RISK_HIGH = 30,
  UNRECOGNIZED = -1,
}

export function dataRiskLevel_DataRiskLevelScoreFromJSON(object: any): DataRiskLevel_DataRiskLevelScore {
  switch (object) {
    case 0:
    case "RISK_SCORE_UNSPECIFIED":
      return DataRiskLevel_DataRiskLevelScore.RISK_SCORE_UNSPECIFIED;
    case 10:
    case "RISK_LOW":
      return DataRiskLevel_DataRiskLevelScore.RISK_LOW;
    case 12:
    case "RISK_UNKNOWN":
      return DataRiskLevel_DataRiskLevelScore.RISK_UNKNOWN;
    case 20:
    case "RISK_MODERATE":
      return DataRiskLevel_DataRiskLevelScore.RISK_MODERATE;
    case 30:
    case "RISK_HIGH":
      return DataRiskLevel_DataRiskLevelScore.RISK_HIGH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataRiskLevel_DataRiskLevelScore.UNRECOGNIZED;
  }
}

export function dataRiskLevel_DataRiskLevelScoreToJSON(object: DataRiskLevel_DataRiskLevelScore): string {
  switch (object) {
    case DataRiskLevel_DataRiskLevelScore.RISK_SCORE_UNSPECIFIED:
      return "RISK_SCORE_UNSPECIFIED";
    case DataRiskLevel_DataRiskLevelScore.RISK_LOW:
      return "RISK_LOW";
    case DataRiskLevel_DataRiskLevelScore.RISK_UNKNOWN:
      return "RISK_UNKNOWN";
    case DataRiskLevel_DataRiskLevelScore.RISK_MODERATE:
      return "RISK_MODERATE";
    case DataRiskLevel_DataRiskLevelScore.RISK_HIGH:
      return "RISK_HIGH";
    case DataRiskLevel_DataRiskLevelScore.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * An aggregated profile for this project, based on the resources profiled
 * within it.
 */
export interface ProjectDataProfile {
  /** The resource name of the profile. */
  name: string;
  /** Project ID or account that was profiled. */
  projectId: string;
  /** The last time the profile was generated. */
  profileLastGenerated:
    | Date
    | undefined;
  /** The sensitivity score of this project. */
  sensitivityScore:
    | SensitivityScore
    | undefined;
  /** The data risk level of this project. */
  dataRiskLevel:
    | DataRiskLevel
    | undefined;
  /** Success or error status of the last attempt to profile the project. */
  profileStatus:
    | ProfileStatus
    | undefined;
  /** The number of table data profiles generated for this project. */
  tableDataProfileCount: Long;
  /** The number of file store data profiles generated for this project. */
  fileStoreDataProfileCount: Long;
}

/** Snapshot of the configurations used to generate the profile. */
export interface DataProfileConfigSnapshot {
  /**
   * A copy of the inspection config used to generate this profile. This
   * is a copy of the inspect_template specified in `DataProfileJobConfig`.
   */
  inspectConfig:
    | InspectConfig
    | undefined;
  /**
   * A copy of the configuration used to generate this profile. This is
   * deprecated, and the DiscoveryConfig field is preferred moving forward.
   * DataProfileJobConfig will still be written here for Discovery in BigQuery
   * for backwards compatibility, but will not be updated with new fields, while
   * DiscoveryConfig will.
   *
   * @deprecated
   */
  dataProfileJob:
    | DataProfileJobConfig
    | undefined;
  /** A copy of the configuration used to generate this profile. */
  discoveryConfig:
    | DiscoveryConfig
    | undefined;
  /** Name of the inspection template used to generate this profile */
  inspectTemplateName: string;
  /** Timestamp when the template was modified */
  inspectTemplateModifiedTime: Date | undefined;
}

/** The profile for a scanned table. */
export interface TableDataProfile {
  /** The name of the profile. */
  name: string;
  /** The resource type that was profiled. */
  dataSourceType:
    | DataSourceType
    | undefined;
  /** The resource name of the project data profile for this table. */
  projectDataProfile: string;
  /** The Google Cloud project ID that owns the resource. */
  datasetProjectId: string;
  /**
   * If supported, the location where the dataset's data is stored.
   * See https://cloud.google.com/bigquery/docs/locations for supported
   * locations.
   */
  datasetLocation: string;
  /** If the resource is BigQuery, the  dataset ID. */
  datasetId: string;
  /** If the resource is BigQuery, the BigQuery table ID. */
  tableId: string;
  /**
   * The resource name of the resource profiled.
   * https://cloud.google.com/apis/design/resource_names#full_resource_name
   */
  fullResource: string;
  /**
   * Success or error status from the most recent profile generation attempt.
   * May be empty if the profile is still being generated.
   */
  profileStatus:
    | ProfileStatus
    | undefined;
  /** State of a profile. */
  state: TableDataProfile_State;
  /** The sensitivity score of this table. */
  sensitivityScore:
    | SensitivityScore
    | undefined;
  /** The data risk level of this table. */
  dataRiskLevel:
    | DataRiskLevel
    | undefined;
  /** The infoTypes predicted from this table's data. */
  predictedInfoTypes: InfoTypeSummary[];
  /** Other infoTypes found in this table's data. */
  otherInfoTypes: OtherInfoTypeSummary[];
  /** The snapshot of the configurations used to generate the profile. */
  configSnapshot:
    | DataProfileConfigSnapshot
    | undefined;
  /** The time when this table was last modified */
  lastModifiedTime:
    | Date
    | undefined;
  /** Optional. The time when this table expires. */
  expirationTime:
    | Date
    | undefined;
  /** The number of columns profiled in the table. */
  scannedColumnCount: Long;
  /** The number of columns skipped in the table because of an error. */
  failedColumnCount: Long;
  /** The size of the table when the profile was generated. */
  tableSizeBytes: Long;
  /**
   * Number of rows in the table when the profile was generated.
   * This will not be populated for BigLake tables.
   */
  rowCount: Long;
  /** How the table is encrypted. */
  encryptionStatus: EncryptionStatus;
  /** How broadly a resource has been shared. */
  resourceVisibility: ResourceVisibility;
  /** The last time the profile was generated. */
  profileLastGenerated:
    | Date
    | undefined;
  /** The labels applied to the resource at the time the profile was generated. */
  resourceLabels: { [key: string]: string };
  /** The time at which the table was created. */
  createTime: Date | undefined;
}

/** Possible states of a profile. New items may be added. */
export enum TableDataProfile_State {
  /** STATE_UNSPECIFIED - Unused. */
  STATE_UNSPECIFIED = 0,
  /**
   * RUNNING - The profile is currently running. Once a profile has finished it will
   * transition to DONE.
   */
  RUNNING = 1,
  /**
   * DONE - The profile is no longer generating.
   * If profile_status.status.code is 0, the profile succeeded, otherwise, it
   * failed.
   */
  DONE = 2,
  UNRECOGNIZED = -1,
}

export function tableDataProfile_StateFromJSON(object: any): TableDataProfile_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return TableDataProfile_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return TableDataProfile_State.RUNNING;
    case 2:
    case "DONE":
      return TableDataProfile_State.DONE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TableDataProfile_State.UNRECOGNIZED;
  }
}

export function tableDataProfile_StateToJSON(object: TableDataProfile_State): string {
  switch (object) {
    case TableDataProfile_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case TableDataProfile_State.RUNNING:
      return "RUNNING";
    case TableDataProfile_State.DONE:
      return "DONE";
    case TableDataProfile_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface TableDataProfile_ResourceLabelsEntry {
  key: string;
  value: string;
}

/** Success or errors for the profile generation. */
export interface ProfileStatus {
  /**
   * Profiling status code and optional message. The `status.code` value is 0
   * (default value) for OK.
   */
  status:
    | Status
    | undefined;
  /** Time when the profile generation status was updated */
  timestamp: Date | undefined;
}

/** The infoType details for this column. */
export interface InfoTypeSummary {
  /** The infoType. */
  infoType:
    | InfoType
    | undefined;
  /**
   * Not populated for predicted infotypes.
   *
   * @deprecated
   */
  estimatedPrevalence: number;
}

/** Infotype details for other infoTypes found within a column. */
export interface OtherInfoTypeSummary {
  /** The other infoType. */
  infoType:
    | InfoType
    | undefined;
  /**
   * Approximate percentage of non-null rows that contained data detected by
   * this infotype.
   */
  estimatedPrevalence: number;
  /**
   * Whether this infoType was excluded from sensitivity and risk analysis due
   * to factors such as low prevalence (subject to change).
   */
  excludedFromAnalysis: boolean;
}

/** The profile for a scanned column within a table. */
export interface ColumnDataProfile {
  /** The name of the profile. */
  name: string;
  /**
   * Success or error status from the most recent profile generation attempt.
   * May be empty if the profile is still being generated.
   */
  profileStatus:
    | ProfileStatus
    | undefined;
  /** State of a profile. */
  state: ColumnDataProfile_State;
  /** The last time the profile was generated. */
  profileLastGenerated:
    | Date
    | undefined;
  /** The resource name of the table data profile. */
  tableDataProfile: string;
  /** The resource name of the resource this column is within. */
  tableFullResource: string;
  /** The Google Cloud project ID that owns the profiled resource. */
  datasetProjectId: string;
  /**
   * The BigQuery location where the dataset's data is stored.
   * See https://cloud.google.com/bigquery/docs/locations for supported
   * locations.
   */
  datasetLocation: string;
  /** The BigQuery dataset ID. */
  datasetId: string;
  /** The BigQuery table ID. */
  tableId: string;
  /** The name of the column. */
  column: string;
  /** The sensitivity of this column. */
  sensitivityScore:
    | SensitivityScore
    | undefined;
  /** The data risk level for this column. */
  dataRiskLevel:
    | DataRiskLevel
    | undefined;
  /**
   * If it's been determined this column can be identified as a single type,
   * this will be set. Otherwise the column either has unidentifiable content
   * or mixed types.
   */
  columnInfoType:
    | InfoTypeSummary
    | undefined;
  /** Other types found within this column. List will be unordered. */
  otherMatches: OtherInfoTypeSummary[];
  /** Approximate percentage of entries being null in the column. */
  estimatedNullPercentage: NullPercentageLevel;
  /** Approximate uniqueness of the column. */
  estimatedUniquenessScore: UniquenessScoreLevel;
  /**
   * The likelihood that this column contains free-form text.
   * A value close to 1 may indicate the column is likely to contain
   * free-form or natural language text.
   * Range in 0-1.
   */
  freeTextScore: number;
  /** The data type of a given column. */
  columnType: ColumnDataProfile_ColumnDataType;
  /** Indicates if a policy tag has been applied to the column. */
  policyState: ColumnDataProfile_ColumnPolicyState;
}

/** Possible states of a profile. New items may be added. */
export enum ColumnDataProfile_State {
  /** STATE_UNSPECIFIED - Unused. */
  STATE_UNSPECIFIED = 0,
  /**
   * RUNNING - The profile is currently running. Once a profile has finished it will
   * transition to DONE.
   */
  RUNNING = 1,
  /**
   * DONE - The profile is no longer generating.
   * If profile_status.status.code is 0, the profile succeeded, otherwise, it
   * failed.
   */
  DONE = 2,
  UNRECOGNIZED = -1,
}

export function columnDataProfile_StateFromJSON(object: any): ColumnDataProfile_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return ColumnDataProfile_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return ColumnDataProfile_State.RUNNING;
    case 2:
    case "DONE":
      return ColumnDataProfile_State.DONE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ColumnDataProfile_State.UNRECOGNIZED;
  }
}

export function columnDataProfile_StateToJSON(object: ColumnDataProfile_State): string {
  switch (object) {
    case ColumnDataProfile_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case ColumnDataProfile_State.RUNNING:
      return "RUNNING";
    case ColumnDataProfile_State.DONE:
      return "DONE";
    case ColumnDataProfile_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Data types of the data in a column. Types may be added over time. */
export enum ColumnDataProfile_ColumnDataType {
  /** COLUMN_DATA_TYPE_UNSPECIFIED - Invalid type. */
  COLUMN_DATA_TYPE_UNSPECIFIED = 0,
  /** TYPE_INT64 - Encoded as a string in decimal format. */
  TYPE_INT64 = 1,
  /** TYPE_BOOL - Encoded as a boolean "false" or "true". */
  TYPE_BOOL = 2,
  /** TYPE_FLOAT64 - Encoded as a number, or string "NaN", "Infinity" or "-Infinity". */
  TYPE_FLOAT64 = 3,
  /** TYPE_STRING - Encoded as a string value. */
  TYPE_STRING = 4,
  /** TYPE_BYTES - Encoded as a base64 string per RFC 4648, section 4. */
  TYPE_BYTES = 5,
  /**
   * TYPE_TIMESTAMP - Encoded as an RFC 3339 timestamp with mandatory "Z" time zone string:
   * 1985-04-12T23:20:50.52Z
   */
  TYPE_TIMESTAMP = 6,
  /** TYPE_DATE - Encoded as RFC 3339 full-date format string: 1985-04-12 */
  TYPE_DATE = 7,
  /** TYPE_TIME - Encoded as RFC 3339 partial-time format string: 23:20:50.52 */
  TYPE_TIME = 8,
  /** TYPE_DATETIME - Encoded as RFC 3339 full-date "T" partial-time: 1985-04-12T23:20:50.52 */
  TYPE_DATETIME = 9,
  /** TYPE_GEOGRAPHY - Encoded as WKT */
  TYPE_GEOGRAPHY = 10,
  /** TYPE_NUMERIC - Encoded as a decimal string. */
  TYPE_NUMERIC = 11,
  /** TYPE_RECORD - Container of ordered fields, each with a type and field name. */
  TYPE_RECORD = 12,
  /** TYPE_BIGNUMERIC - Decimal type. */
  TYPE_BIGNUMERIC = 13,
  /** TYPE_JSON - Json type. */
  TYPE_JSON = 14,
  /** TYPE_INTERVAL - Interval type. */
  TYPE_INTERVAL = 15,
  /** TYPE_RANGE_DATE - `Range<Date>` type. */
  TYPE_RANGE_DATE = 16,
  /** TYPE_RANGE_DATETIME - `Range<Datetime>` type. */
  TYPE_RANGE_DATETIME = 17,
  /** TYPE_RANGE_TIMESTAMP - `Range<Timestamp>` type. */
  TYPE_RANGE_TIMESTAMP = 18,
  UNRECOGNIZED = -1,
}

export function columnDataProfile_ColumnDataTypeFromJSON(object: any): ColumnDataProfile_ColumnDataType {
  switch (object) {
    case 0:
    case "COLUMN_DATA_TYPE_UNSPECIFIED":
      return ColumnDataProfile_ColumnDataType.COLUMN_DATA_TYPE_UNSPECIFIED;
    case 1:
    case "TYPE_INT64":
      return ColumnDataProfile_ColumnDataType.TYPE_INT64;
    case 2:
    case "TYPE_BOOL":
      return ColumnDataProfile_ColumnDataType.TYPE_BOOL;
    case 3:
    case "TYPE_FLOAT64":
      return ColumnDataProfile_ColumnDataType.TYPE_FLOAT64;
    case 4:
    case "TYPE_STRING":
      return ColumnDataProfile_ColumnDataType.TYPE_STRING;
    case 5:
    case "TYPE_BYTES":
      return ColumnDataProfile_ColumnDataType.TYPE_BYTES;
    case 6:
    case "TYPE_TIMESTAMP":
      return ColumnDataProfile_ColumnDataType.TYPE_TIMESTAMP;
    case 7:
    case "TYPE_DATE":
      return ColumnDataProfile_ColumnDataType.TYPE_DATE;
    case 8:
    case "TYPE_TIME":
      return ColumnDataProfile_ColumnDataType.TYPE_TIME;
    case 9:
    case "TYPE_DATETIME":
      return ColumnDataProfile_ColumnDataType.TYPE_DATETIME;
    case 10:
    case "TYPE_GEOGRAPHY":
      return ColumnDataProfile_ColumnDataType.TYPE_GEOGRAPHY;
    case 11:
    case "TYPE_NUMERIC":
      return ColumnDataProfile_ColumnDataType.TYPE_NUMERIC;
    case 12:
    case "TYPE_RECORD":
      return ColumnDataProfile_ColumnDataType.TYPE_RECORD;
    case 13:
    case "TYPE_BIGNUMERIC":
      return ColumnDataProfile_ColumnDataType.TYPE_BIGNUMERIC;
    case 14:
    case "TYPE_JSON":
      return ColumnDataProfile_ColumnDataType.TYPE_JSON;
    case 15:
    case "TYPE_INTERVAL":
      return ColumnDataProfile_ColumnDataType.TYPE_INTERVAL;
    case 16:
    case "TYPE_RANGE_DATE":
      return ColumnDataProfile_ColumnDataType.TYPE_RANGE_DATE;
    case 17:
    case "TYPE_RANGE_DATETIME":
      return ColumnDataProfile_ColumnDataType.TYPE_RANGE_DATETIME;
    case 18:
    case "TYPE_RANGE_TIMESTAMP":
      return ColumnDataProfile_ColumnDataType.TYPE_RANGE_TIMESTAMP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ColumnDataProfile_ColumnDataType.UNRECOGNIZED;
  }
}

export function columnDataProfile_ColumnDataTypeToJSON(object: ColumnDataProfile_ColumnDataType): string {
  switch (object) {
    case ColumnDataProfile_ColumnDataType.COLUMN_DATA_TYPE_UNSPECIFIED:
      return "COLUMN_DATA_TYPE_UNSPECIFIED";
    case ColumnDataProfile_ColumnDataType.TYPE_INT64:
      return "TYPE_INT64";
    case ColumnDataProfile_ColumnDataType.TYPE_BOOL:
      return "TYPE_BOOL";
    case ColumnDataProfile_ColumnDataType.TYPE_FLOAT64:
      return "TYPE_FLOAT64";
    case ColumnDataProfile_ColumnDataType.TYPE_STRING:
      return "TYPE_STRING";
    case ColumnDataProfile_ColumnDataType.TYPE_BYTES:
      return "TYPE_BYTES";
    case ColumnDataProfile_ColumnDataType.TYPE_TIMESTAMP:
      return "TYPE_TIMESTAMP";
    case ColumnDataProfile_ColumnDataType.TYPE_DATE:
      return "TYPE_DATE";
    case ColumnDataProfile_ColumnDataType.TYPE_TIME:
      return "TYPE_TIME";
    case ColumnDataProfile_ColumnDataType.TYPE_DATETIME:
      return "TYPE_DATETIME";
    case ColumnDataProfile_ColumnDataType.TYPE_GEOGRAPHY:
      return "TYPE_GEOGRAPHY";
    case ColumnDataProfile_ColumnDataType.TYPE_NUMERIC:
      return "TYPE_NUMERIC";
    case ColumnDataProfile_ColumnDataType.TYPE_RECORD:
      return "TYPE_RECORD";
    case ColumnDataProfile_ColumnDataType.TYPE_BIGNUMERIC:
      return "TYPE_BIGNUMERIC";
    case ColumnDataProfile_ColumnDataType.TYPE_JSON:
      return "TYPE_JSON";
    case ColumnDataProfile_ColumnDataType.TYPE_INTERVAL:
      return "TYPE_INTERVAL";
    case ColumnDataProfile_ColumnDataType.TYPE_RANGE_DATE:
      return "TYPE_RANGE_DATE";
    case ColumnDataProfile_ColumnDataType.TYPE_RANGE_DATETIME:
      return "TYPE_RANGE_DATETIME";
    case ColumnDataProfile_ColumnDataType.TYPE_RANGE_TIMESTAMP:
      return "TYPE_RANGE_TIMESTAMP";
    case ColumnDataProfile_ColumnDataType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The possible policy states for a column. */
export enum ColumnDataProfile_ColumnPolicyState {
  /** COLUMN_POLICY_STATE_UNSPECIFIED - No policy tags. */
  COLUMN_POLICY_STATE_UNSPECIFIED = 0,
  /** COLUMN_POLICY_TAGGED - Column has policy tag applied. */
  COLUMN_POLICY_TAGGED = 1,
  UNRECOGNIZED = -1,
}

export function columnDataProfile_ColumnPolicyStateFromJSON(object: any): ColumnDataProfile_ColumnPolicyState {
  switch (object) {
    case 0:
    case "COLUMN_POLICY_STATE_UNSPECIFIED":
      return ColumnDataProfile_ColumnPolicyState.COLUMN_POLICY_STATE_UNSPECIFIED;
    case 1:
    case "COLUMN_POLICY_TAGGED":
      return ColumnDataProfile_ColumnPolicyState.COLUMN_POLICY_TAGGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ColumnDataProfile_ColumnPolicyState.UNRECOGNIZED;
  }
}

export function columnDataProfile_ColumnPolicyStateToJSON(object: ColumnDataProfile_ColumnPolicyState): string {
  switch (object) {
    case ColumnDataProfile_ColumnPolicyState.COLUMN_POLICY_STATE_UNSPECIFIED:
      return "COLUMN_POLICY_STATE_UNSPECIFIED";
    case ColumnDataProfile_ColumnPolicyState.COLUMN_POLICY_TAGGED:
      return "COLUMN_POLICY_TAGGED";
    case ColumnDataProfile_ColumnPolicyState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The profile for a file store.
 *
 * * Cloud Storage: maps 1:1 with a bucket.
 * * Amazon S3: maps 1:1 with a bucket.
 */
export interface FileStoreDataProfile {
  /** The name of the profile. */
  name: string;
  /** The resource type that was profiled. */
  dataSourceType:
    | DataSourceType
    | undefined;
  /** The resource name of the project data profile for this file store. */
  projectDataProfile: string;
  /**
   * The Google Cloud project ID that owns the resource.
   * For Amazon S3 buckets, this is the AWS Account Id.
   */
  projectId: string;
  /**
   * The location of the file store.
   *
   * * Cloud Storage:
   * https://cloud.google.com/storage/docs/locations#available-locations
   * * Amazon S3:
   * https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints
   */
  fileStoreLocation: string;
  /**
   * For resources that have multiple storage locations, these are those
   * regions. For Cloud Storage this is the list of regions chosen for
   * dual-region storage. `file_store_location` will normally be the
   * corresponding multi-region for the list of individual locations. The first
   * region is always picked as the processing and storage location for the data
   * profile.
   */
  dataStorageLocations: string[];
  /**
   * The location type of the bucket (region, dual-region, multi-region, etc).
   * If dual-region, expect data_storage_locations to be populated.
   */
  locationType: string;
  /**
   * The file store path.
   *
   * * Cloud Storage: `gs://{bucket}`
   * * Amazon S3: `s3://{bucket}`
   */
  fileStorePath: string;
  /**
   * The resource name of the resource profiled.
   * https://cloud.google.com/apis/design/resource_names#full_resource_name
   *
   * Example format of an S3 bucket full resource name:
   * `//cloudasset.googleapis.com/organizations/{org_id}/otherCloudConnections/aws/arn:aws:s3:::{bucket_name}`
   */
  fullResource: string;
  /** The snapshot of the configurations used to generate the profile. */
  configSnapshot:
    | DataProfileConfigSnapshot
    | undefined;
  /**
   * Success or error status from the most recent profile generation attempt.
   * May be empty if the profile is still being generated.
   */
  profileStatus:
    | ProfileStatus
    | undefined;
  /** State of a profile. */
  state: FileStoreDataProfile_State;
  /** The last time the profile was generated. */
  profileLastGenerated:
    | Date
    | undefined;
  /** How broadly a resource has been shared. */
  resourceVisibility: ResourceVisibility;
  /** The sensitivity score of this resource. */
  sensitivityScore:
    | SensitivityScore
    | undefined;
  /** The data risk level of this resource. */
  dataRiskLevel:
    | DataRiskLevel
    | undefined;
  /** The time the file store was first created. */
  createTime:
    | Date
    | undefined;
  /** The time the file store was last modified. */
  lastModifiedTime:
    | Date
    | undefined;
  /** FileClusterSummary per each cluster. */
  fileClusterSummaries: FileClusterSummary[];
  /**
   * Attributes of the resource being profiled.
   * Currently used attributes:
   *
   * * customer_managed_encryption: boolean
   *     - true: the resource is encrypted with a customer-managed key.
   *     - false: the resource is encrypted with a provider-managed key.
   */
  resourceAttributes: { [key: string]: Value };
  /** The labels applied to the resource at the time the profile was generated. */
  resourceLabels: { [key: string]: string };
  /** InfoTypes detected in this file store. */
  fileStoreInfoTypeSummaries: FileStoreInfoTypeSummary[];
  /** The file store does not have any files. */
  fileStoreIsEmpty: boolean;
}

/** Possible states of a profile. New items may be added. */
export enum FileStoreDataProfile_State {
  /** STATE_UNSPECIFIED - Unused. */
  STATE_UNSPECIFIED = 0,
  /**
   * RUNNING - The profile is currently running. Once a profile has finished it will
   * transition to DONE.
   */
  RUNNING = 1,
  /**
   * DONE - The profile is no longer generating.
   * If profile_status.status.code is 0, the profile succeeded, otherwise, it
   * failed.
   */
  DONE = 2,
  UNRECOGNIZED = -1,
}

export function fileStoreDataProfile_StateFromJSON(object: any): FileStoreDataProfile_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return FileStoreDataProfile_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return FileStoreDataProfile_State.RUNNING;
    case 2:
    case "DONE":
      return FileStoreDataProfile_State.DONE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FileStoreDataProfile_State.UNRECOGNIZED;
  }
}

export function fileStoreDataProfile_StateToJSON(object: FileStoreDataProfile_State): string {
  switch (object) {
    case FileStoreDataProfile_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case FileStoreDataProfile_State.RUNNING:
      return "RUNNING";
    case FileStoreDataProfile_State.DONE:
      return "DONE";
    case FileStoreDataProfile_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface FileStoreDataProfile_ResourceAttributesEntry {
  key: string;
  value: Value | undefined;
}

export interface FileStoreDataProfile_ResourceLabelsEntry {
  key: string;
  value: string;
}

/** Information regarding the discovered InfoType. */
export interface FileStoreInfoTypeSummary {
  /** The InfoType seen. */
  infoType: InfoType | undefined;
}

/** Information regarding the discovered file extension. */
export interface FileExtensionInfo {
  /** The file extension if set. (aka .pdf, .jpg, .txt) */
  fileExtension: string;
}

/** The file cluster summary. */
export interface FileClusterSummary {
  /** The file cluster type. */
  fileClusterType:
    | FileClusterType
    | undefined;
  /** InfoTypes detected in this cluster. */
  fileStoreInfoTypeSummaries: FileStoreInfoTypeSummary[];
  /**
   * The sensitivity score of this cluster. The score will be SENSITIVITY_LOW
   * if nothing has been scanned.
   */
  sensitivityScore:
    | SensitivityScore
    | undefined;
  /**
   * The data risk level of this cluster. RISK_LOW if nothing has been
   * scanned.
   */
  dataRiskLevel:
    | DataRiskLevel
    | undefined;
  /**
   * A list of errors detected while scanning this cluster. The list is
   * truncated to 10 per cluster.
   */
  errors: Error[];
  /**
   * A sample of file types scanned in this cluster. Empty if no files were
   * scanned. File extensions can be derived from the file name or the file
   * content.
   */
  fileExtensionsScanned: FileExtensionInfo[];
  /**
   * A sample of file types seen in this cluster. Empty if no files were seen.
   * File extensions can be derived from the file name or the file content.
   */
  fileExtensionsSeen: FileExtensionInfo[];
  /**
   * True if no files exist in this cluster. If the bucket had more files than
   * could be listed, this will be false even if no files for this cluster
   * were seen and file_extensions_seen is empty.
   */
  noFilesExist: boolean;
}

/** Request to get a project data profile. */
export interface GetProjectDataProfileRequest {
  /**
   * Required. Resource name, for example
   * `organizations/12345/locations/us/projectDataProfiles/53234423`.
   */
  name: string;
}

/** Request to get a file store data profile. */
export interface GetFileStoreDataProfileRequest {
  /**
   * Required. Resource name, for example
   * `organizations/12345/locations/us/fileStoreDataProfiles/53234423`.
   */
  name: string;
}

/**
 * Request to list the file store profiles generated for a given organization or
 * project.
 */
export interface ListFileStoreDataProfilesRequest {
  /**
   * Required. Resource name of the organization or project, for
   * example `organizations/433245324/locations/europe` or
   * `projects/project-id/locations/asia`.
   */
  parent: string;
  /** Optional. Page token to continue retrieval. */
  pageToken: string;
  /**
   * Optional. Size of the page. This value can be limited by the server. If
   * zero, server returns a page of max size 100.
   */
  pageSize: number;
  /**
   * Optional. Comma-separated list of fields to order by, followed by `asc` or
   * `desc` postfix. This list is case insensitive. The default sorting order is
   * ascending. Redundant space characters are insignificant. Only one order
   * field at a time is allowed.
   *
   * Examples:
   *
   * * `project_id asc`
   * * `name`
   * * `sensitivity_level desc`
   *
   * Supported fields are:
   *
   * - `project_id`: The Google Cloud project ID.
   * - `sensitivity_level`: How sensitive the data in a table is, at most.
   * - `data_risk_level`: How much risk is associated with this data.
   * - `profile_last_generated`: When the profile was last updated in epoch
   * seconds.
   * - `last_modified`: The last time the resource was modified.
   * - `resource_visibility`: Visibility restriction for this resource.
   * - `name`: The name of the profile.
   * - `create_time`: The time the file store was first created.
   */
  orderBy: string;
  /**
   * Optional. Allows filtering.
   *
   * Supported syntax:
   *
   * * Filter expressions are made up of one or more restrictions.
   * * Restrictions can be combined by `AND` or `OR` logical operators. A
   * sequence of restrictions implicitly uses `AND`.
   * * A restriction has the form of `{field} {operator} {value}`.
   * * Supported fields/values:
   *     - `project_id` - The Google Cloud project ID.
   *     - `account_id` - The AWS account ID.
   *     - `file_store_path` - The path like "gs://bucket".
   *     - `data_source_type` - The profile's data source type, like
   *     "google/storage/bucket".
   *     - `data_storage_location` - The location where the file store's data is
   *     stored, like "us-central1".
   *     - `sensitivity_level` - HIGH|MODERATE|LOW
   *     - `data_risk_level` - HIGH|MODERATE|LOW
   *     - `resource_visibility`: PUBLIC|RESTRICTED
   *     - `status_code` - an RPC status code as defined in
   *     https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto
   * * The operator must be `=` or `!=`.
   *
   * Examples:
   *
   * * `project_id = 12345 AND status_code = 1`
   * * `project_id = 12345 AND sensitivity_level = HIGH`
   * * `project_id = 12345 AND resource_visibility = PUBLIC`
   * * `file_store_path = "gs://mybucket"`
   *
   * The length of this field should be no more than 500 characters.
   */
  filter: string;
}

/**
 * List of file store data profiles generated for a given organization or
 * project.
 */
export interface ListFileStoreDataProfilesResponse {
  /** List of data profiles. */
  fileStoreDataProfiles: FileStoreDataProfile[];
  /** The next page token. */
  nextPageToken: string;
}

/** Request message for DeleteFileStoreProfile. */
export interface DeleteFileStoreDataProfileRequest {
  /** Required. Resource name of the file store data profile. */
  name: string;
}

/** Request to get a table data profile. */
export interface GetTableDataProfileRequest {
  /**
   * Required. Resource name, for example
   * `organizations/12345/locations/us/tableDataProfiles/53234423`.
   */
  name: string;
}

/** Request to get a column data profile. */
export interface GetColumnDataProfileRequest {
  /**
   * Required. Resource name, for example
   * `organizations/12345/locations/us/columnDataProfiles/53234423`.
   */
  name: string;
}

/** A condition for determining whether a Pub/Sub should be triggered. */
export interface DataProfilePubSubCondition {
  /** An expression. */
  expressions: DataProfilePubSubCondition_PubSubExpressions | undefined;
}

/** Various score levels for resources. */
export enum DataProfilePubSubCondition_ProfileScoreBucket {
  /** PROFILE_SCORE_BUCKET_UNSPECIFIED - Unused. */
  PROFILE_SCORE_BUCKET_UNSPECIFIED = 0,
  /** HIGH - High risk/sensitivity detected. */
  HIGH = 1,
  /** MEDIUM_OR_HIGH - Medium or high risk/sensitivity detected. */
  MEDIUM_OR_HIGH = 2,
  UNRECOGNIZED = -1,
}

export function dataProfilePubSubCondition_ProfileScoreBucketFromJSON(
  object: any,
): DataProfilePubSubCondition_ProfileScoreBucket {
  switch (object) {
    case 0:
    case "PROFILE_SCORE_BUCKET_UNSPECIFIED":
      return DataProfilePubSubCondition_ProfileScoreBucket.PROFILE_SCORE_BUCKET_UNSPECIFIED;
    case 1:
    case "HIGH":
      return DataProfilePubSubCondition_ProfileScoreBucket.HIGH;
    case 2:
    case "MEDIUM_OR_HIGH":
      return DataProfilePubSubCondition_ProfileScoreBucket.MEDIUM_OR_HIGH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataProfilePubSubCondition_ProfileScoreBucket.UNRECOGNIZED;
  }
}

export function dataProfilePubSubCondition_ProfileScoreBucketToJSON(
  object: DataProfilePubSubCondition_ProfileScoreBucket,
): string {
  switch (object) {
    case DataProfilePubSubCondition_ProfileScoreBucket.PROFILE_SCORE_BUCKET_UNSPECIFIED:
      return "PROFILE_SCORE_BUCKET_UNSPECIFIED";
    case DataProfilePubSubCondition_ProfileScoreBucket.HIGH:
      return "HIGH";
    case DataProfilePubSubCondition_ProfileScoreBucket.MEDIUM_OR_HIGH:
      return "MEDIUM_OR_HIGH";
    case DataProfilePubSubCondition_ProfileScoreBucket.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A condition consisting of a value. */
export interface DataProfilePubSubCondition_PubSubCondition {
  /** The minimum data risk score that triggers the condition. */
  minimumRiskScore?:
    | DataProfilePubSubCondition_ProfileScoreBucket
    | undefined;
  /** The minimum sensitivity level that triggers the condition. */
  minimumSensitivityScore?: DataProfilePubSubCondition_ProfileScoreBucket | undefined;
}

/** An expression, consisting of an operator and conditions. */
export interface DataProfilePubSubCondition_PubSubExpressions {
  /** The operator to apply to the collection of conditions. */
  logicalOperator: DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator;
  /** Conditions to apply to the expression. */
  conditions: DataProfilePubSubCondition_PubSubCondition[];
}

/** Logical operators for conditional checks. */
export enum DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator {
  /** LOGICAL_OPERATOR_UNSPECIFIED - Unused. */
  LOGICAL_OPERATOR_UNSPECIFIED = 0,
  /** OR - Conditional OR. */
  OR = 1,
  /** AND - Conditional AND. */
  AND = 2,
  UNRECOGNIZED = -1,
}

export function dataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperatorFromJSON(
  object: any,
): DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator {
  switch (object) {
    case 0:
    case "LOGICAL_OPERATOR_UNSPECIFIED":
      return DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.LOGICAL_OPERATOR_UNSPECIFIED;
    case 1:
    case "OR":
      return DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.OR;
    case 2:
    case "AND":
      return DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.AND;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.UNRECOGNIZED;
  }
}

export function dataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperatorToJSON(
  object: DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator,
): string {
  switch (object) {
    case DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.LOGICAL_OPERATOR_UNSPECIFIED:
      return "LOGICAL_OPERATOR_UNSPECIFIED";
    case DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.OR:
      return "OR";
    case DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.AND:
      return "AND";
    case DataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperator.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Pub/Sub topic message for a DataProfileAction.PubSubNotification event.
 * To receive a message of protocol buffer schema type, convert the message data
 * to an object of this proto class.
 */
export interface DataProfilePubSubMessage {
  /**
   * If `DetailLevel` is `TABLE_PROFILE` this will be fully populated.
   * Otherwise, if `DetailLevel` is `RESOURCE_NAME`, then only `name` and
   * `full_resource` will be populated.
   */
  profile:
    | TableDataProfile
    | undefined;
  /**
   * If `DetailLevel` is `FILE_STORE_PROFILE` this will be fully populated.
   * Otherwise, if `DetailLevel` is `RESOURCE_NAME`, then only `name` and
   * `file_store_path` will be populated.
   */
  fileStoreProfile:
    | FileStoreDataProfile
    | undefined;
  /** The event that caused the Pub/Sub message to be sent. */
  event: DataProfileAction_EventType;
}

/** Request message for CreateConnection. */
export interface CreateConnectionRequest {
  /**
   * Required. Parent resource name.
   *
   * The format of this value varies depending on the scope of the request
   * (project or organization):
   *
   * + Projects scope:
   *   `projects/{project_id}/locations/{location_id}`
   * + Organizations scope:
   *   `organizations/{org_id}/locations/{location_id}`
   */
  parent: string;
  /** Required. The connection resource. */
  connection: Connection | undefined;
}

/** Request message for GetConnection. */
export interface GetConnectionRequest {
  /**
   * Required. Resource name in the format:
   * `projects/{project}/locations/{location}/connections/{connection}`.
   */
  name: string;
}

/** Request message for ListConnections. */
export interface ListConnectionsRequest {
  /**
   * Required. Resource name of the organization or project, for
   * example, `organizations/433245324/locations/europe` or
   * `projects/project-id/locations/asia`.
   */
  parent: string;
  /** Optional. Number of results per page, max 1000. */
  pageSize: number;
  /**
   * Optional. Page token from a previous page to return the next set of
   * results. If set, all other request fields must match the original request.
   */
  pageToken: string;
  /** Optional. Supported field/value: `state` - MISSING|AVAILABLE|ERROR */
  filter: string;
}

/** Request message for SearchConnections. */
export interface SearchConnectionsRequest {
  /**
   * Required. Resource name of the organization or project with a wildcard
   * location, for example, `organizations/433245324/locations/-` or
   * `projects/project-id/locations/-`.
   */
  parent: string;
  /** Optional. Number of results per page, max 1000. */
  pageSize: number;
  /**
   * Optional. Page token from a previous page to return the next set of
   * results. If set, all other request fields must match the original request.
   */
  pageToken: string;
  /** Optional. Supported field/value: - `state` - MISSING|AVAILABLE|ERROR */
  filter: string;
}

/** Response message for ListConnections. */
export interface ListConnectionsResponse {
  /** List of connections. */
  connections: Connection[];
  /**
   * Token to retrieve the next page of results. An empty value means there are
   * no more results.
   */
  nextPageToken: string;
}

/** Response message for SearchConnections. */
export interface SearchConnectionsResponse {
  /**
   * List of connections that match the search query. Note that only a subset
   * of the fields will be populated, and only "name" is guaranteed to be set.
   * For full details of a Connection, call GetConnection with the name.
   */
  connections: Connection[];
  /**
   * Token to retrieve the next page of results. An empty value means there are
   * no more results.
   */
  nextPageToken: string;
}

/** Request message for UpdateConnection. */
export interface UpdateConnectionRequest {
  /**
   * Required. Resource name in the format:
   * `projects/{project}/locations/{location}/connections/{connection}`.
   */
  name: string;
  /** Required. The connection with new values for the relevant fields. */
  connection:
    | Connection
    | undefined;
  /** Optional. Mask to control which fields get updated. */
  updateMask: string[] | undefined;
}

/** Request message for DeleteConnection. */
export interface DeleteConnectionRequest {
  /**
   * Required. Resource name of the Connection to be deleted, in the format:
   * `projects/{project}/locations/{location}/connections/{connection}`.
   */
  name: string;
}

/**
 * A data connection to allow DLP to profile data in locations that require
 * additional configuration.
 */
export interface Connection {
  /**
   * Output only. Name of the connection:
   * `projects/{project}/locations/{location}/connections/{name}`.
   */
  name: string;
  /** Required. The connection's state in its lifecycle. */
  state: ConnectionState;
  /**
   * Output only. Set if status == ERROR, to provide additional details. Will
   * store the last 10 errors sorted with the most recent first.
   */
  errors: Error[];
  /** Connect to a Cloud SQL instance. */
  cloudSql?: CloudSqlProperties | undefined;
}

/**
 * A credential consisting of a username and password, where the password is
 * stored in a Secret Manager resource.
 * Note: Secret Manager [charges
 * apply](https://cloud.google.com/secret-manager/pricing).
 */
export interface SecretManagerCredential {
  /** Required. The username. */
  username: string;
  /**
   * Required. The name of the Secret Manager resource that stores the password,
   * in the form `projects/project-id/secrets/secret-name/versions/version`.
   */
  passwordSecretVersionName: string;
}

/**
 * Use IAM authentication to connect. This requires the Cloud SQL IAM feature
 * to be enabled on the instance, which is not the default for Cloud SQL.
 * See https://cloud.google.com/sql/docs/postgres/authentication and
 * https://cloud.google.com/sql/docs/mysql/authentication.
 */
export interface CloudSqlIamCredential {
}

/** Cloud SQL connection properties. */
export interface CloudSqlProperties {
  /**
   * Optional. Immutable. The Cloud SQL instance for which the connection is
   * defined. Only one connection per instance is allowed. This can only be set
   * at creation time, and cannot be updated.
   *
   * It is an error to use a connection_name from different project or region
   * than the one that holds the connection.
   * For example, a Connection resource for Cloud SQL connection_name
   * `project-id:us-central1:sql-instance`
   * must be created under the parent
   * `projects/project-id/locations/us-central1`
   */
  connectionName: string;
  /** A username and password stored in Secret Manager. */
  usernamePassword?:
    | SecretManagerCredential
    | undefined;
  /** Built-in IAM authentication (must be configured in Cloud SQL). */
  cloudSqlIam?:
    | CloudSqlIamCredential
    | undefined;
  /**
   * Required. DLP will limit its connections to max_connections.
   * Must be 2 or greater.
   */
  maxConnections: number;
  /**
   * Required. The database engine used by the Cloud SQL instance that this
   * connection configures.
   */
  databaseEngine: CloudSqlProperties_DatabaseEngine;
}

/**
 * Database engine of a Cloud SQL instance.
 * New values may be added over time.
 */
export enum CloudSqlProperties_DatabaseEngine {
  /** DATABASE_ENGINE_UNKNOWN - An engine that is not currently supported by Sensitive Data Protection. */
  DATABASE_ENGINE_UNKNOWN = 0,
  /** DATABASE_ENGINE_MYSQL - Cloud SQL for MySQL instance. */
  DATABASE_ENGINE_MYSQL = 1,
  /** DATABASE_ENGINE_POSTGRES - Cloud SQL for PostgreSQL instance. */
  DATABASE_ENGINE_POSTGRES = 2,
  UNRECOGNIZED = -1,
}

export function cloudSqlProperties_DatabaseEngineFromJSON(object: any): CloudSqlProperties_DatabaseEngine {
  switch (object) {
    case 0:
    case "DATABASE_ENGINE_UNKNOWN":
      return CloudSqlProperties_DatabaseEngine.DATABASE_ENGINE_UNKNOWN;
    case 1:
    case "DATABASE_ENGINE_MYSQL":
      return CloudSqlProperties_DatabaseEngine.DATABASE_ENGINE_MYSQL;
    case 2:
    case "DATABASE_ENGINE_POSTGRES":
      return CloudSqlProperties_DatabaseEngine.DATABASE_ENGINE_POSTGRES;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudSqlProperties_DatabaseEngine.UNRECOGNIZED;
  }
}

export function cloudSqlProperties_DatabaseEngineToJSON(object: CloudSqlProperties_DatabaseEngine): string {
  switch (object) {
    case CloudSqlProperties_DatabaseEngine.DATABASE_ENGINE_UNKNOWN:
      return "DATABASE_ENGINE_UNKNOWN";
    case CloudSqlProperties_DatabaseEngine.DATABASE_ENGINE_MYSQL:
      return "DATABASE_ENGINE_MYSQL";
    case CloudSqlProperties_DatabaseEngine.DATABASE_ENGINE_POSTGRES:
      return "DATABASE_ENGINE_POSTGRES";
    case CloudSqlProperties_DatabaseEngine.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Request message for DeleteTableProfile. */
export interface DeleteTableDataProfileRequest {
  /** Required. Resource name of the table data profile. */
  name: string;
}

/** Message used to identify the type of resource being profiled. */
export interface DataSourceType {
  /**
   * Output only. An identifying string to the type of resource being profiled.
   * Current values:
   *
   * * google/bigquery/table
   * * google/project
   * * google/sql/table
   * * google/gcs/bucket
   */
  dataSource: string;
}

/** Message used to identify file cluster type being profiled. */
export interface FileClusterType {
  /** Cluster type. */
  cluster?: FileClusterType_Cluster | undefined;
}

/**
 * Cluster type. Each cluster corresponds to a set of file types.
 * Over time, new types may be added and files may move between clusters.
 */
export enum FileClusterType_Cluster {
  /** CLUSTER_UNSPECIFIED - Unused. */
  CLUSTER_UNSPECIFIED = 0,
  /** CLUSTER_UNKNOWN - Unsupported files. */
  CLUSTER_UNKNOWN = 1,
  /** CLUSTER_TEXT - Plain text. */
  CLUSTER_TEXT = 2,
  /** CLUSTER_STRUCTURED_DATA - Structured data like CSV, TSV etc. */
  CLUSTER_STRUCTURED_DATA = 3,
  /** CLUSTER_SOURCE_CODE - Source code. */
  CLUSTER_SOURCE_CODE = 4,
  /** CLUSTER_RICH_DOCUMENT - Rich document like docx, xlsx etc. */
  CLUSTER_RICH_DOCUMENT = 5,
  /** CLUSTER_IMAGE - Images like jpeg, bmp. */
  CLUSTER_IMAGE = 6,
  /** CLUSTER_ARCHIVE - Archives and containers like .zip, .tar etc. */
  CLUSTER_ARCHIVE = 7,
  /** CLUSTER_MULTIMEDIA - Multimedia like .mp4, .avi etc. */
  CLUSTER_MULTIMEDIA = 8,
  /** CLUSTER_EXECUTABLE - Executable files like .exe, .class, .apk etc. */
  CLUSTER_EXECUTABLE = 9,
  UNRECOGNIZED = -1,
}

export function fileClusterType_ClusterFromJSON(object: any): FileClusterType_Cluster {
  switch (object) {
    case 0:
    case "CLUSTER_UNSPECIFIED":
      return FileClusterType_Cluster.CLUSTER_UNSPECIFIED;
    case 1:
    case "CLUSTER_UNKNOWN":
      return FileClusterType_Cluster.CLUSTER_UNKNOWN;
    case 2:
    case "CLUSTER_TEXT":
      return FileClusterType_Cluster.CLUSTER_TEXT;
    case 3:
    case "CLUSTER_STRUCTURED_DATA":
      return FileClusterType_Cluster.CLUSTER_STRUCTURED_DATA;
    case 4:
    case "CLUSTER_SOURCE_CODE":
      return FileClusterType_Cluster.CLUSTER_SOURCE_CODE;
    case 5:
    case "CLUSTER_RICH_DOCUMENT":
      return FileClusterType_Cluster.CLUSTER_RICH_DOCUMENT;
    case 6:
    case "CLUSTER_IMAGE":
      return FileClusterType_Cluster.CLUSTER_IMAGE;
    case 7:
    case "CLUSTER_ARCHIVE":
      return FileClusterType_Cluster.CLUSTER_ARCHIVE;
    case 8:
    case "CLUSTER_MULTIMEDIA":
      return FileClusterType_Cluster.CLUSTER_MULTIMEDIA;
    case 9:
    case "CLUSTER_EXECUTABLE":
      return FileClusterType_Cluster.CLUSTER_EXECUTABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FileClusterType_Cluster.UNRECOGNIZED;
  }
}

export function fileClusterType_ClusterToJSON(object: FileClusterType_Cluster): string {
  switch (object) {
    case FileClusterType_Cluster.CLUSTER_UNSPECIFIED:
      return "CLUSTER_UNSPECIFIED";
    case FileClusterType_Cluster.CLUSTER_UNKNOWN:
      return "CLUSTER_UNKNOWN";
    case FileClusterType_Cluster.CLUSTER_TEXT:
      return "CLUSTER_TEXT";
    case FileClusterType_Cluster.CLUSTER_STRUCTURED_DATA:
      return "CLUSTER_STRUCTURED_DATA";
    case FileClusterType_Cluster.CLUSTER_SOURCE_CODE:
      return "CLUSTER_SOURCE_CODE";
    case FileClusterType_Cluster.CLUSTER_RICH_DOCUMENT:
      return "CLUSTER_RICH_DOCUMENT";
    case FileClusterType_Cluster.CLUSTER_IMAGE:
      return "CLUSTER_IMAGE";
    case FileClusterType_Cluster.CLUSTER_ARCHIVE:
      return "CLUSTER_ARCHIVE";
    case FileClusterType_Cluster.CLUSTER_MULTIMEDIA:
      return "CLUSTER_MULTIMEDIA";
    case FileClusterType_Cluster.CLUSTER_EXECUTABLE:
      return "CLUSTER_EXECUTABLE";
    case FileClusterType_Cluster.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseExcludeInfoTypes(): ExcludeInfoTypes {
  return { infoTypes: [] };
}

export const ExcludeInfoTypes: MessageFns<ExcludeInfoTypes> = {
  encode(message: ExcludeInfoTypes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.infoTypes) {
      InfoType.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExcludeInfoTypes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExcludeInfoTypes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoTypes.push(InfoType.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExcludeInfoTypes {
    return {
      infoTypes: globalThis.Array.isArray(object?.infoTypes)
        ? object.infoTypes.map((e: any) => InfoType.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ExcludeInfoTypes): unknown {
    const obj: any = {};
    if (message.infoTypes?.length) {
      obj.infoTypes = message.infoTypes.map((e) => InfoType.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ExcludeInfoTypes>): ExcludeInfoTypes {
    return ExcludeInfoTypes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExcludeInfoTypes>): ExcludeInfoTypes {
    const message = createBaseExcludeInfoTypes();
    message.infoTypes = object.infoTypes?.map((e) => InfoType.fromPartial(e)) || [];
    return message;
  },
};

function createBaseExcludeByHotword(): ExcludeByHotword {
  return { hotwordRegex: undefined, proximity: undefined };
}

export const ExcludeByHotword: MessageFns<ExcludeByHotword> = {
  encode(message: ExcludeByHotword, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hotwordRegex !== undefined) {
      CustomInfoType_Regex.encode(message.hotwordRegex, writer.uint32(10).fork()).join();
    }
    if (message.proximity !== undefined) {
      CustomInfoType_DetectionRule_Proximity.encode(message.proximity, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExcludeByHotword {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExcludeByHotword();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hotwordRegex = CustomInfoType_Regex.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.proximity = CustomInfoType_DetectionRule_Proximity.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExcludeByHotword {
    return {
      hotwordRegex: isSet(object.hotwordRegex) ? CustomInfoType_Regex.fromJSON(object.hotwordRegex) : undefined,
      proximity: isSet(object.proximity)
        ? CustomInfoType_DetectionRule_Proximity.fromJSON(object.proximity)
        : undefined,
    };
  },

  toJSON(message: ExcludeByHotword): unknown {
    const obj: any = {};
    if (message.hotwordRegex !== undefined) {
      obj.hotwordRegex = CustomInfoType_Regex.toJSON(message.hotwordRegex);
    }
    if (message.proximity !== undefined) {
      obj.proximity = CustomInfoType_DetectionRule_Proximity.toJSON(message.proximity);
    }
    return obj;
  },

  create(base?: DeepPartial<ExcludeByHotword>): ExcludeByHotword {
    return ExcludeByHotword.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExcludeByHotword>): ExcludeByHotword {
    const message = createBaseExcludeByHotword();
    message.hotwordRegex = (object.hotwordRegex !== undefined && object.hotwordRegex !== null)
      ? CustomInfoType_Regex.fromPartial(object.hotwordRegex)
      : undefined;
    message.proximity = (object.proximity !== undefined && object.proximity !== null)
      ? CustomInfoType_DetectionRule_Proximity.fromPartial(object.proximity)
      : undefined;
    return message;
  },
};

function createBaseExclusionRule(): ExclusionRule {
  return {
    dictionary: undefined,
    regex: undefined,
    excludeInfoTypes: undefined,
    excludeByHotword: undefined,
    matchingType: 0,
  };
}

export const ExclusionRule: MessageFns<ExclusionRule> = {
  encode(message: ExclusionRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dictionary !== undefined) {
      CustomInfoType_Dictionary.encode(message.dictionary, writer.uint32(10).fork()).join();
    }
    if (message.regex !== undefined) {
      CustomInfoType_Regex.encode(message.regex, writer.uint32(18).fork()).join();
    }
    if (message.excludeInfoTypes !== undefined) {
      ExcludeInfoTypes.encode(message.excludeInfoTypes, writer.uint32(26).fork()).join();
    }
    if (message.excludeByHotword !== undefined) {
      ExcludeByHotword.encode(message.excludeByHotword, writer.uint32(42).fork()).join();
    }
    if (message.matchingType !== 0) {
      writer.uint32(32).int32(message.matchingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExclusionRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExclusionRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dictionary = CustomInfoType_Dictionary.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.regex = CustomInfoType_Regex.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.excludeInfoTypes = ExcludeInfoTypes.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.excludeByHotword = ExcludeByHotword.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.matchingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExclusionRule {
    return {
      dictionary: isSet(object.dictionary) ? CustomInfoType_Dictionary.fromJSON(object.dictionary) : undefined,
      regex: isSet(object.regex) ? CustomInfoType_Regex.fromJSON(object.regex) : undefined,
      excludeInfoTypes: isSet(object.excludeInfoTypes) ? ExcludeInfoTypes.fromJSON(object.excludeInfoTypes) : undefined,
      excludeByHotword: isSet(object.excludeByHotword) ? ExcludeByHotword.fromJSON(object.excludeByHotword) : undefined,
      matchingType: isSet(object.matchingType) ? matchingTypeFromJSON(object.matchingType) : 0,
    };
  },

  toJSON(message: ExclusionRule): unknown {
    const obj: any = {};
    if (message.dictionary !== undefined) {
      obj.dictionary = CustomInfoType_Dictionary.toJSON(message.dictionary);
    }
    if (message.regex !== undefined) {
      obj.regex = CustomInfoType_Regex.toJSON(message.regex);
    }
    if (message.excludeInfoTypes !== undefined) {
      obj.excludeInfoTypes = ExcludeInfoTypes.toJSON(message.excludeInfoTypes);
    }
    if (message.excludeByHotword !== undefined) {
      obj.excludeByHotword = ExcludeByHotword.toJSON(message.excludeByHotword);
    }
    if (message.matchingType !== 0) {
      obj.matchingType = matchingTypeToJSON(message.matchingType);
    }
    return obj;
  },

  create(base?: DeepPartial<ExclusionRule>): ExclusionRule {
    return ExclusionRule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExclusionRule>): ExclusionRule {
    const message = createBaseExclusionRule();
    message.dictionary = (object.dictionary !== undefined && object.dictionary !== null)
      ? CustomInfoType_Dictionary.fromPartial(object.dictionary)
      : undefined;
    message.regex = (object.regex !== undefined && object.regex !== null)
      ? CustomInfoType_Regex.fromPartial(object.regex)
      : undefined;
    message.excludeInfoTypes = (object.excludeInfoTypes !== undefined && object.excludeInfoTypes !== null)
      ? ExcludeInfoTypes.fromPartial(object.excludeInfoTypes)
      : undefined;
    message.excludeByHotword = (object.excludeByHotword !== undefined && object.excludeByHotword !== null)
      ? ExcludeByHotword.fromPartial(object.excludeByHotword)
      : undefined;
    message.matchingType = object.matchingType ?? 0;
    return message;
  },
};

function createBaseInspectionRule(): InspectionRule {
  return { hotwordRule: undefined, exclusionRule: undefined };
}

export const InspectionRule: MessageFns<InspectionRule> = {
  encode(message: InspectionRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hotwordRule !== undefined) {
      CustomInfoType_DetectionRule_HotwordRule.encode(message.hotwordRule, writer.uint32(10).fork()).join();
    }
    if (message.exclusionRule !== undefined) {
      ExclusionRule.encode(message.exclusionRule, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectionRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectionRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hotwordRule = CustomInfoType_DetectionRule_HotwordRule.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.exclusionRule = ExclusionRule.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectionRule {
    return {
      hotwordRule: isSet(object.hotwordRule)
        ? CustomInfoType_DetectionRule_HotwordRule.fromJSON(object.hotwordRule)
        : undefined,
      exclusionRule: isSet(object.exclusionRule) ? ExclusionRule.fromJSON(object.exclusionRule) : undefined,
    };
  },

  toJSON(message: InspectionRule): unknown {
    const obj: any = {};
    if (message.hotwordRule !== undefined) {
      obj.hotwordRule = CustomInfoType_DetectionRule_HotwordRule.toJSON(message.hotwordRule);
    }
    if (message.exclusionRule !== undefined) {
      obj.exclusionRule = ExclusionRule.toJSON(message.exclusionRule);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectionRule>): InspectionRule {
    return InspectionRule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectionRule>): InspectionRule {
    const message = createBaseInspectionRule();
    message.hotwordRule = (object.hotwordRule !== undefined && object.hotwordRule !== null)
      ? CustomInfoType_DetectionRule_HotwordRule.fromPartial(object.hotwordRule)
      : undefined;
    message.exclusionRule = (object.exclusionRule !== undefined && object.exclusionRule !== null)
      ? ExclusionRule.fromPartial(object.exclusionRule)
      : undefined;
    return message;
  },
};

function createBaseInspectionRuleSet(): InspectionRuleSet {
  return { infoTypes: [], rules: [] };
}

export const InspectionRuleSet: MessageFns<InspectionRuleSet> = {
  encode(message: InspectionRuleSet, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.infoTypes) {
      InfoType.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.rules) {
      InspectionRule.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectionRuleSet {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectionRuleSet();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoTypes.push(InfoType.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rules.push(InspectionRule.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectionRuleSet {
    return {
      infoTypes: globalThis.Array.isArray(object?.infoTypes)
        ? object.infoTypes.map((e: any) => InfoType.fromJSON(e))
        : [],
      rules: globalThis.Array.isArray(object?.rules) ? object.rules.map((e: any) => InspectionRule.fromJSON(e)) : [],
    };
  },

  toJSON(message: InspectionRuleSet): unknown {
    const obj: any = {};
    if (message.infoTypes?.length) {
      obj.infoTypes = message.infoTypes.map((e) => InfoType.toJSON(e));
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => InspectionRule.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<InspectionRuleSet>): InspectionRuleSet {
    return InspectionRuleSet.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectionRuleSet>): InspectionRuleSet {
    const message = createBaseInspectionRuleSet();
    message.infoTypes = object.infoTypes?.map((e) => InfoType.fromPartial(e)) || [];
    message.rules = object.rules?.map((e) => InspectionRule.fromPartial(e)) || [];
    return message;
  },
};

function createBaseInspectConfig(): InspectConfig {
  return {
    infoTypes: [],
    minLikelihood: 0,
    minLikelihoodPerInfoType: [],
    limits: undefined,
    includeQuote: false,
    excludeInfoTypes: false,
    customInfoTypes: [],
    contentOptions: [],
    ruleSet: [],
  };
}

export const InspectConfig: MessageFns<InspectConfig> = {
  encode(message: InspectConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.infoTypes) {
      InfoType.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.minLikelihood !== 0) {
      writer.uint32(16).int32(message.minLikelihood);
    }
    for (const v of message.minLikelihoodPerInfoType) {
      InspectConfig_InfoTypeLikelihood.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.limits !== undefined) {
      InspectConfig_FindingLimits.encode(message.limits, writer.uint32(26).fork()).join();
    }
    if (message.includeQuote !== false) {
      writer.uint32(32).bool(message.includeQuote);
    }
    if (message.excludeInfoTypes !== false) {
      writer.uint32(40).bool(message.excludeInfoTypes);
    }
    for (const v of message.customInfoTypes) {
      CustomInfoType.encode(v!, writer.uint32(50).fork()).join();
    }
    writer.uint32(66).fork();
    for (const v of message.contentOptions) {
      writer.int32(v);
    }
    writer.join();
    for (const v of message.ruleSet) {
      InspectionRuleSet.encode(v!, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoTypes.push(InfoType.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.minLikelihood = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.minLikelihoodPerInfoType.push(InspectConfig_InfoTypeLikelihood.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.limits = InspectConfig_FindingLimits.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.includeQuote = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.excludeInfoTypes = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.customInfoTypes.push(CustomInfoType.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag === 64) {
            message.contentOptions.push(reader.int32() as any);

            continue;
          }

          if (tag === 66) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.contentOptions.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.ruleSet.push(InspectionRuleSet.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectConfig {
    return {
      infoTypes: globalThis.Array.isArray(object?.infoTypes)
        ? object.infoTypes.map((e: any) => InfoType.fromJSON(e))
        : [],
      minLikelihood: isSet(object.minLikelihood) ? likelihoodFromJSON(object.minLikelihood) : 0,
      minLikelihoodPerInfoType: globalThis.Array.isArray(object?.minLikelihoodPerInfoType)
        ? object.minLikelihoodPerInfoType.map((e: any) => InspectConfig_InfoTypeLikelihood.fromJSON(e))
        : [],
      limits: isSet(object.limits) ? InspectConfig_FindingLimits.fromJSON(object.limits) : undefined,
      includeQuote: isSet(object.includeQuote) ? globalThis.Boolean(object.includeQuote) : false,
      excludeInfoTypes: isSet(object.excludeInfoTypes) ? globalThis.Boolean(object.excludeInfoTypes) : false,
      customInfoTypes: globalThis.Array.isArray(object?.customInfoTypes)
        ? object.customInfoTypes.map((e: any) => CustomInfoType.fromJSON(e))
        : [],
      contentOptions: globalThis.Array.isArray(object?.contentOptions)
        ? object.contentOptions.map((e: any) => contentOptionFromJSON(e))
        : [],
      ruleSet: globalThis.Array.isArray(object?.ruleSet)
        ? object.ruleSet.map((e: any) => InspectionRuleSet.fromJSON(e))
        : [],
    };
  },

  toJSON(message: InspectConfig): unknown {
    const obj: any = {};
    if (message.infoTypes?.length) {
      obj.infoTypes = message.infoTypes.map((e) => InfoType.toJSON(e));
    }
    if (message.minLikelihood !== 0) {
      obj.minLikelihood = likelihoodToJSON(message.minLikelihood);
    }
    if (message.minLikelihoodPerInfoType?.length) {
      obj.minLikelihoodPerInfoType = message.minLikelihoodPerInfoType.map((e) =>
        InspectConfig_InfoTypeLikelihood.toJSON(e)
      );
    }
    if (message.limits !== undefined) {
      obj.limits = InspectConfig_FindingLimits.toJSON(message.limits);
    }
    if (message.includeQuote !== false) {
      obj.includeQuote = message.includeQuote;
    }
    if (message.excludeInfoTypes !== false) {
      obj.excludeInfoTypes = message.excludeInfoTypes;
    }
    if (message.customInfoTypes?.length) {
      obj.customInfoTypes = message.customInfoTypes.map((e) => CustomInfoType.toJSON(e));
    }
    if (message.contentOptions?.length) {
      obj.contentOptions = message.contentOptions.map((e) => contentOptionToJSON(e));
    }
    if (message.ruleSet?.length) {
      obj.ruleSet = message.ruleSet.map((e) => InspectionRuleSet.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<InspectConfig>): InspectConfig {
    return InspectConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectConfig>): InspectConfig {
    const message = createBaseInspectConfig();
    message.infoTypes = object.infoTypes?.map((e) => InfoType.fromPartial(e)) || [];
    message.minLikelihood = object.minLikelihood ?? 0;
    message.minLikelihoodPerInfoType =
      object.minLikelihoodPerInfoType?.map((e) => InspectConfig_InfoTypeLikelihood.fromPartial(e)) || [];
    message.limits = (object.limits !== undefined && object.limits !== null)
      ? InspectConfig_FindingLimits.fromPartial(object.limits)
      : undefined;
    message.includeQuote = object.includeQuote ?? false;
    message.excludeInfoTypes = object.excludeInfoTypes ?? false;
    message.customInfoTypes = object.customInfoTypes?.map((e) => CustomInfoType.fromPartial(e)) || [];
    message.contentOptions = object.contentOptions?.map((e) => e) || [];
    message.ruleSet = object.ruleSet?.map((e) => InspectionRuleSet.fromPartial(e)) || [];
    return message;
  },
};

function createBaseInspectConfig_InfoTypeLikelihood(): InspectConfig_InfoTypeLikelihood {
  return { infoType: undefined, minLikelihood: 0 };
}

export const InspectConfig_InfoTypeLikelihood: MessageFns<InspectConfig_InfoTypeLikelihood> = {
  encode(message: InspectConfig_InfoTypeLikelihood, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (message.minLikelihood !== 0) {
      writer.uint32(16).int32(message.minLikelihood);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectConfig_InfoTypeLikelihood {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectConfig_InfoTypeLikelihood();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.minLikelihood = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectConfig_InfoTypeLikelihood {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      minLikelihood: isSet(object.minLikelihood) ? likelihoodFromJSON(object.minLikelihood) : 0,
    };
  },

  toJSON(message: InspectConfig_InfoTypeLikelihood): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.minLikelihood !== 0) {
      obj.minLikelihood = likelihoodToJSON(message.minLikelihood);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectConfig_InfoTypeLikelihood>): InspectConfig_InfoTypeLikelihood {
    return InspectConfig_InfoTypeLikelihood.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectConfig_InfoTypeLikelihood>): InspectConfig_InfoTypeLikelihood {
    const message = createBaseInspectConfig_InfoTypeLikelihood();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.minLikelihood = object.minLikelihood ?? 0;
    return message;
  },
};

function createBaseInspectConfig_FindingLimits(): InspectConfig_FindingLimits {
  return { maxFindingsPerItem: 0, maxFindingsPerRequest: 0, maxFindingsPerInfoType: [] };
}

export const InspectConfig_FindingLimits: MessageFns<InspectConfig_FindingLimits> = {
  encode(message: InspectConfig_FindingLimits, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxFindingsPerItem !== 0) {
      writer.uint32(8).int32(message.maxFindingsPerItem);
    }
    if (message.maxFindingsPerRequest !== 0) {
      writer.uint32(16).int32(message.maxFindingsPerRequest);
    }
    for (const v of message.maxFindingsPerInfoType) {
      InspectConfig_FindingLimits_InfoTypeLimit.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectConfig_FindingLimits {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectConfig_FindingLimits();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.maxFindingsPerItem = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxFindingsPerRequest = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.maxFindingsPerInfoType.push(
            InspectConfig_FindingLimits_InfoTypeLimit.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectConfig_FindingLimits {
    return {
      maxFindingsPerItem: isSet(object.maxFindingsPerItem) ? globalThis.Number(object.maxFindingsPerItem) : 0,
      maxFindingsPerRequest: isSet(object.maxFindingsPerRequest) ? globalThis.Number(object.maxFindingsPerRequest) : 0,
      maxFindingsPerInfoType: globalThis.Array.isArray(object?.maxFindingsPerInfoType)
        ? object.maxFindingsPerInfoType.map((e: any) => InspectConfig_FindingLimits_InfoTypeLimit.fromJSON(e))
        : [],
    };
  },

  toJSON(message: InspectConfig_FindingLimits): unknown {
    const obj: any = {};
    if (message.maxFindingsPerItem !== 0) {
      obj.maxFindingsPerItem = Math.round(message.maxFindingsPerItem);
    }
    if (message.maxFindingsPerRequest !== 0) {
      obj.maxFindingsPerRequest = Math.round(message.maxFindingsPerRequest);
    }
    if (message.maxFindingsPerInfoType?.length) {
      obj.maxFindingsPerInfoType = message.maxFindingsPerInfoType.map((e) =>
        InspectConfig_FindingLimits_InfoTypeLimit.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<InspectConfig_FindingLimits>): InspectConfig_FindingLimits {
    return InspectConfig_FindingLimits.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectConfig_FindingLimits>): InspectConfig_FindingLimits {
    const message = createBaseInspectConfig_FindingLimits();
    message.maxFindingsPerItem = object.maxFindingsPerItem ?? 0;
    message.maxFindingsPerRequest = object.maxFindingsPerRequest ?? 0;
    message.maxFindingsPerInfoType =
      object.maxFindingsPerInfoType?.map((e) => InspectConfig_FindingLimits_InfoTypeLimit.fromPartial(e)) || [];
    return message;
  },
};

function createBaseInspectConfig_FindingLimits_InfoTypeLimit(): InspectConfig_FindingLimits_InfoTypeLimit {
  return { infoType: undefined, maxFindings: 0 };
}

export const InspectConfig_FindingLimits_InfoTypeLimit: MessageFns<InspectConfig_FindingLimits_InfoTypeLimit> = {
  encode(message: InspectConfig_FindingLimits_InfoTypeLimit, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (message.maxFindings !== 0) {
      writer.uint32(16).int32(message.maxFindings);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectConfig_FindingLimits_InfoTypeLimit {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectConfig_FindingLimits_InfoTypeLimit();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxFindings = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectConfig_FindingLimits_InfoTypeLimit {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      maxFindings: isSet(object.maxFindings) ? globalThis.Number(object.maxFindings) : 0,
    };
  },

  toJSON(message: InspectConfig_FindingLimits_InfoTypeLimit): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.maxFindings !== 0) {
      obj.maxFindings = Math.round(message.maxFindings);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectConfig_FindingLimits_InfoTypeLimit>): InspectConfig_FindingLimits_InfoTypeLimit {
    return InspectConfig_FindingLimits_InfoTypeLimit.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<InspectConfig_FindingLimits_InfoTypeLimit>,
  ): InspectConfig_FindingLimits_InfoTypeLimit {
    const message = createBaseInspectConfig_FindingLimits_InfoTypeLimit();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.maxFindings = object.maxFindings ?? 0;
    return message;
  },
};

function createBaseByteContentItem(): ByteContentItem {
  return { type: 0, data: Buffer.alloc(0) };
}

export const ByteContentItem: MessageFns<ByteContentItem> = {
  encode(message: ByteContentItem, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.data.length !== 0) {
      writer.uint32(18).bytes(message.data);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ByteContentItem {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseByteContentItem();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.data = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ByteContentItem {
    return {
      type: isSet(object.type) ? byteContentItem_BytesTypeFromJSON(object.type) : 0,
      data: isSet(object.data) ? Buffer.from(bytesFromBase64(object.data)) : Buffer.alloc(0),
    };
  },

  toJSON(message: ByteContentItem): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = byteContentItem_BytesTypeToJSON(message.type);
    }
    if (message.data.length !== 0) {
      obj.data = base64FromBytes(message.data);
    }
    return obj;
  },

  create(base?: DeepPartial<ByteContentItem>): ByteContentItem {
    return ByteContentItem.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ByteContentItem>): ByteContentItem {
    const message = createBaseByteContentItem();
    message.type = object.type ?? 0;
    message.data = object.data ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseContentItem(): ContentItem {
  return { value: undefined, table: undefined, byteItem: undefined };
}

export const ContentItem: MessageFns<ContentItem> = {
  encode(message: ContentItem, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== undefined) {
      writer.uint32(26).string(message.value);
    }
    if (message.table !== undefined) {
      Table.encode(message.table, writer.uint32(34).fork()).join();
    }
    if (message.byteItem !== undefined) {
      ByteContentItem.encode(message.byteItem, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContentItem {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContentItem();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.value = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.table = Table.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.byteItem = ByteContentItem.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContentItem {
    return {
      value: isSet(object.value) ? globalThis.String(object.value) : undefined,
      table: isSet(object.table) ? Table.fromJSON(object.table) : undefined,
      byteItem: isSet(object.byteItem) ? ByteContentItem.fromJSON(object.byteItem) : undefined,
    };
  },

  toJSON(message: ContentItem): unknown {
    const obj: any = {};
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    if (message.table !== undefined) {
      obj.table = Table.toJSON(message.table);
    }
    if (message.byteItem !== undefined) {
      obj.byteItem = ByteContentItem.toJSON(message.byteItem);
    }
    return obj;
  },

  create(base?: DeepPartial<ContentItem>): ContentItem {
    return ContentItem.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContentItem>): ContentItem {
    const message = createBaseContentItem();
    message.value = object.value ?? undefined;
    message.table = (object.table !== undefined && object.table !== null) ? Table.fromPartial(object.table) : undefined;
    message.byteItem = (object.byteItem !== undefined && object.byteItem !== null)
      ? ByteContentItem.fromPartial(object.byteItem)
      : undefined;
    return message;
  },
};

function createBaseTable(): Table {
  return { headers: [], rows: [] };
}

export const Table: MessageFns<Table> = {
  encode(message: Table, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.headers) {
      FieldId.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.rows) {
      Table_Row.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Table {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.headers.push(FieldId.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rows.push(Table_Row.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Table {
    return {
      headers: globalThis.Array.isArray(object?.headers) ? object.headers.map((e: any) => FieldId.fromJSON(e)) : [],
      rows: globalThis.Array.isArray(object?.rows) ? object.rows.map((e: any) => Table_Row.fromJSON(e)) : [],
    };
  },

  toJSON(message: Table): unknown {
    const obj: any = {};
    if (message.headers?.length) {
      obj.headers = message.headers.map((e) => FieldId.toJSON(e));
    }
    if (message.rows?.length) {
      obj.rows = message.rows.map((e) => Table_Row.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Table>): Table {
    return Table.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Table>): Table {
    const message = createBaseTable();
    message.headers = object.headers?.map((e) => FieldId.fromPartial(e)) || [];
    message.rows = object.rows?.map((e) => Table_Row.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTable_Row(): Table_Row {
  return { values: [] };
}

export const Table_Row: MessageFns<Table_Row> = {
  encode(message: Table_Row, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.values) {
      Value.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Table_Row {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTable_Row();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.values.push(Value.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Table_Row {
    return { values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => Value.fromJSON(e)) : [] };
  },

  toJSON(message: Table_Row): unknown {
    const obj: any = {};
    if (message.values?.length) {
      obj.values = message.values.map((e) => Value.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Table_Row>): Table_Row {
    return Table_Row.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Table_Row>): Table_Row {
    const message = createBaseTable_Row();
    message.values = object.values?.map((e) => Value.fromPartial(e)) || [];
    return message;
  },
};

function createBaseInspectResult(): InspectResult {
  return { findings: [], findingsTruncated: false };
}

export const InspectResult: MessageFns<InspectResult> = {
  encode(message: InspectResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.findings) {
      Finding.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.findingsTruncated !== false) {
      writer.uint32(16).bool(message.findingsTruncated);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.findings.push(Finding.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.findingsTruncated = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectResult {
    return {
      findings: globalThis.Array.isArray(object?.findings) ? object.findings.map((e: any) => Finding.fromJSON(e)) : [],
      findingsTruncated: isSet(object.findingsTruncated) ? globalThis.Boolean(object.findingsTruncated) : false,
    };
  },

  toJSON(message: InspectResult): unknown {
    const obj: any = {};
    if (message.findings?.length) {
      obj.findings = message.findings.map((e) => Finding.toJSON(e));
    }
    if (message.findingsTruncated !== false) {
      obj.findingsTruncated = message.findingsTruncated;
    }
    return obj;
  },

  create(base?: DeepPartial<InspectResult>): InspectResult {
    return InspectResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectResult>): InspectResult {
    const message = createBaseInspectResult();
    message.findings = object.findings?.map((e) => Finding.fromPartial(e)) || [];
    message.findingsTruncated = object.findingsTruncated ?? false;
    return message;
  },
};

function createBaseFinding(): Finding {
  return {
    name: "",
    quote: "",
    infoType: undefined,
    likelihood: 0,
    location: undefined,
    createTime: undefined,
    quoteInfo: undefined,
    resourceName: "",
    triggerName: "",
    labels: {},
    jobCreateTime: undefined,
    jobName: "",
    findingId: "",
  };
}

export const Finding: MessageFns<Finding> = {
  encode(message: Finding, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(114).string(message.name);
    }
    if (message.quote !== "") {
      writer.uint32(10).string(message.quote);
    }
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(18).fork()).join();
    }
    if (message.likelihood !== 0) {
      writer.uint32(24).int32(message.likelihood);
    }
    if (message.location !== undefined) {
      Location.encode(message.location, writer.uint32(34).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.quoteInfo !== undefined) {
      QuoteInfo.encode(message.quoteInfo, writer.uint32(58).fork()).join();
    }
    if (message.resourceName !== "") {
      writer.uint32(66).string(message.resourceName);
    }
    if (message.triggerName !== "") {
      writer.uint32(74).string(message.triggerName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Finding_LabelsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.jobCreateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.jobCreateTime), writer.uint32(90).fork()).join();
    }
    if (message.jobName !== "") {
      writer.uint32(106).string(message.jobName);
    }
    if (message.findingId !== "") {
      writer.uint32(122).string(message.findingId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Finding {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFinding();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 14:
          if (tag !== 114) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quote = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.likelihood = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.location = Location.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.quoteInfo = QuoteInfo.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.resourceName = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.triggerName = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          const entry10 = Finding_LabelsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.labels[entry10.key] = entry10.value;
          }
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.jobCreateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.jobName = reader.string();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.findingId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Finding {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      quote: isSet(object.quote) ? globalThis.String(object.quote) : "",
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      likelihood: isSet(object.likelihood) ? likelihoodFromJSON(object.likelihood) : 0,
      location: isSet(object.location) ? Location.fromJSON(object.location) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      quoteInfo: isSet(object.quoteInfo) ? QuoteInfo.fromJSON(object.quoteInfo) : undefined,
      resourceName: isSet(object.resourceName) ? globalThis.String(object.resourceName) : "",
      triggerName: isSet(object.triggerName) ? globalThis.String(object.triggerName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      jobCreateTime: isSet(object.jobCreateTime) ? fromJsonTimestamp(object.jobCreateTime) : undefined,
      jobName: isSet(object.jobName) ? globalThis.String(object.jobName) : "",
      findingId: isSet(object.findingId) ? globalThis.String(object.findingId) : "",
    };
  },

  toJSON(message: Finding): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.quote !== "") {
      obj.quote = message.quote;
    }
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.likelihood !== 0) {
      obj.likelihood = likelihoodToJSON(message.likelihood);
    }
    if (message.location !== undefined) {
      obj.location = Location.toJSON(message.location);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.quoteInfo !== undefined) {
      obj.quoteInfo = QuoteInfo.toJSON(message.quoteInfo);
    }
    if (message.resourceName !== "") {
      obj.resourceName = message.resourceName;
    }
    if (message.triggerName !== "") {
      obj.triggerName = message.triggerName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.jobCreateTime !== undefined) {
      obj.jobCreateTime = message.jobCreateTime.toISOString();
    }
    if (message.jobName !== "") {
      obj.jobName = message.jobName;
    }
    if (message.findingId !== "") {
      obj.findingId = message.findingId;
    }
    return obj;
  },

  create(base?: DeepPartial<Finding>): Finding {
    return Finding.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Finding>): Finding {
    const message = createBaseFinding();
    message.name = object.name ?? "";
    message.quote = object.quote ?? "";
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.likelihood = object.likelihood ?? 0;
    message.location = (object.location !== undefined && object.location !== null)
      ? Location.fromPartial(object.location)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.quoteInfo = (object.quoteInfo !== undefined && object.quoteInfo !== null)
      ? QuoteInfo.fromPartial(object.quoteInfo)
      : undefined;
    message.resourceName = object.resourceName ?? "";
    message.triggerName = object.triggerName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.jobCreateTime = object.jobCreateTime ?? undefined;
    message.jobName = object.jobName ?? "";
    message.findingId = object.findingId ?? "";
    return message;
  },
};

function createBaseFinding_LabelsEntry(): Finding_LabelsEntry {
  return { key: "", value: "" };
}

export const Finding_LabelsEntry: MessageFns<Finding_LabelsEntry> = {
  encode(message: Finding_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Finding_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFinding_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Finding_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Finding_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Finding_LabelsEntry>): Finding_LabelsEntry {
    return Finding_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Finding_LabelsEntry>): Finding_LabelsEntry {
    const message = createBaseFinding_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseLocation(): Location {
  return { byteRange: undefined, codepointRange: undefined, contentLocations: [], container: undefined };
}

export const Location: MessageFns<Location> = {
  encode(message: Location, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.byteRange !== undefined) {
      Range.encode(message.byteRange, writer.uint32(10).fork()).join();
    }
    if (message.codepointRange !== undefined) {
      Range.encode(message.codepointRange, writer.uint32(18).fork()).join();
    }
    for (const v of message.contentLocations) {
      ContentLocation.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.container !== undefined) {
      Container.encode(message.container, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Location {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.byteRange = Range.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.codepointRange = Range.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.contentLocations.push(ContentLocation.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.container = Container.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Location {
    return {
      byteRange: isSet(object.byteRange) ? Range.fromJSON(object.byteRange) : undefined,
      codepointRange: isSet(object.codepointRange) ? Range.fromJSON(object.codepointRange) : undefined,
      contentLocations: globalThis.Array.isArray(object?.contentLocations)
        ? object.contentLocations.map((e: any) => ContentLocation.fromJSON(e))
        : [],
      container: isSet(object.container) ? Container.fromJSON(object.container) : undefined,
    };
  },

  toJSON(message: Location): unknown {
    const obj: any = {};
    if (message.byteRange !== undefined) {
      obj.byteRange = Range.toJSON(message.byteRange);
    }
    if (message.codepointRange !== undefined) {
      obj.codepointRange = Range.toJSON(message.codepointRange);
    }
    if (message.contentLocations?.length) {
      obj.contentLocations = message.contentLocations.map((e) => ContentLocation.toJSON(e));
    }
    if (message.container !== undefined) {
      obj.container = Container.toJSON(message.container);
    }
    return obj;
  },

  create(base?: DeepPartial<Location>): Location {
    return Location.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Location>): Location {
    const message = createBaseLocation();
    message.byteRange = (object.byteRange !== undefined && object.byteRange !== null)
      ? Range.fromPartial(object.byteRange)
      : undefined;
    message.codepointRange = (object.codepointRange !== undefined && object.codepointRange !== null)
      ? Range.fromPartial(object.codepointRange)
      : undefined;
    message.contentLocations = object.contentLocations?.map((e) => ContentLocation.fromPartial(e)) || [];
    message.container = (object.container !== undefined && object.container !== null)
      ? Container.fromPartial(object.container)
      : undefined;
    return message;
  },
};

function createBaseContentLocation(): ContentLocation {
  return {
    containerName: "",
    recordLocation: undefined,
    imageLocation: undefined,
    documentLocation: undefined,
    metadataLocation: undefined,
    containerTimestamp: undefined,
    containerVersion: "",
  };
}

export const ContentLocation: MessageFns<ContentLocation> = {
  encode(message: ContentLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.containerName !== "") {
      writer.uint32(10).string(message.containerName);
    }
    if (message.recordLocation !== undefined) {
      RecordLocation.encode(message.recordLocation, writer.uint32(18).fork()).join();
    }
    if (message.imageLocation !== undefined) {
      ImageLocation.encode(message.imageLocation, writer.uint32(26).fork()).join();
    }
    if (message.documentLocation !== undefined) {
      DocumentLocation.encode(message.documentLocation, writer.uint32(42).fork()).join();
    }
    if (message.metadataLocation !== undefined) {
      MetadataLocation.encode(message.metadataLocation, writer.uint32(66).fork()).join();
    }
    if (message.containerTimestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.containerTimestamp), writer.uint32(50).fork()).join();
    }
    if (message.containerVersion !== "") {
      writer.uint32(58).string(message.containerVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContentLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContentLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.containerName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.recordLocation = RecordLocation.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.imageLocation = ImageLocation.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.documentLocation = DocumentLocation.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.metadataLocation = MetadataLocation.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.containerTimestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.containerVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContentLocation {
    return {
      containerName: isSet(object.containerName) ? globalThis.String(object.containerName) : "",
      recordLocation: isSet(object.recordLocation) ? RecordLocation.fromJSON(object.recordLocation) : undefined,
      imageLocation: isSet(object.imageLocation) ? ImageLocation.fromJSON(object.imageLocation) : undefined,
      documentLocation: isSet(object.documentLocation) ? DocumentLocation.fromJSON(object.documentLocation) : undefined,
      metadataLocation: isSet(object.metadataLocation) ? MetadataLocation.fromJSON(object.metadataLocation) : undefined,
      containerTimestamp: isSet(object.containerTimestamp) ? fromJsonTimestamp(object.containerTimestamp) : undefined,
      containerVersion: isSet(object.containerVersion) ? globalThis.String(object.containerVersion) : "",
    };
  },

  toJSON(message: ContentLocation): unknown {
    const obj: any = {};
    if (message.containerName !== "") {
      obj.containerName = message.containerName;
    }
    if (message.recordLocation !== undefined) {
      obj.recordLocation = RecordLocation.toJSON(message.recordLocation);
    }
    if (message.imageLocation !== undefined) {
      obj.imageLocation = ImageLocation.toJSON(message.imageLocation);
    }
    if (message.documentLocation !== undefined) {
      obj.documentLocation = DocumentLocation.toJSON(message.documentLocation);
    }
    if (message.metadataLocation !== undefined) {
      obj.metadataLocation = MetadataLocation.toJSON(message.metadataLocation);
    }
    if (message.containerTimestamp !== undefined) {
      obj.containerTimestamp = message.containerTimestamp.toISOString();
    }
    if (message.containerVersion !== "") {
      obj.containerVersion = message.containerVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<ContentLocation>): ContentLocation {
    return ContentLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContentLocation>): ContentLocation {
    const message = createBaseContentLocation();
    message.containerName = object.containerName ?? "";
    message.recordLocation = (object.recordLocation !== undefined && object.recordLocation !== null)
      ? RecordLocation.fromPartial(object.recordLocation)
      : undefined;
    message.imageLocation = (object.imageLocation !== undefined && object.imageLocation !== null)
      ? ImageLocation.fromPartial(object.imageLocation)
      : undefined;
    message.documentLocation = (object.documentLocation !== undefined && object.documentLocation !== null)
      ? DocumentLocation.fromPartial(object.documentLocation)
      : undefined;
    message.metadataLocation = (object.metadataLocation !== undefined && object.metadataLocation !== null)
      ? MetadataLocation.fromPartial(object.metadataLocation)
      : undefined;
    message.containerTimestamp = object.containerTimestamp ?? undefined;
    message.containerVersion = object.containerVersion ?? "";
    return message;
  },
};

function createBaseMetadataLocation(): MetadataLocation {
  return { type: 0, storageLabel: undefined };
}

export const MetadataLocation: MessageFns<MetadataLocation> = {
  encode(message: MetadataLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.storageLabel !== undefined) {
      StorageMetadataLabel.encode(message.storageLabel, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.storageLabel = StorageMetadataLabel.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataLocation {
    return {
      type: isSet(object.type) ? metadataTypeFromJSON(object.type) : 0,
      storageLabel: isSet(object.storageLabel) ? StorageMetadataLabel.fromJSON(object.storageLabel) : undefined,
    };
  },

  toJSON(message: MetadataLocation): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = metadataTypeToJSON(message.type);
    }
    if (message.storageLabel !== undefined) {
      obj.storageLabel = StorageMetadataLabel.toJSON(message.storageLabel);
    }
    return obj;
  },

  create(base?: DeepPartial<MetadataLocation>): MetadataLocation {
    return MetadataLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetadataLocation>): MetadataLocation {
    const message = createBaseMetadataLocation();
    message.type = object.type ?? 0;
    message.storageLabel = (object.storageLabel !== undefined && object.storageLabel !== null)
      ? StorageMetadataLabel.fromPartial(object.storageLabel)
      : undefined;
    return message;
  },
};

function createBaseStorageMetadataLabel(): StorageMetadataLabel {
  return { key: "" };
}

export const StorageMetadataLabel: MessageFns<StorageMetadataLabel> = {
  encode(message: StorageMetadataLabel, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageMetadataLabel {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageMetadataLabel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageMetadataLabel {
    return { key: isSet(object.key) ? globalThis.String(object.key) : "" };
  },

  toJSON(message: StorageMetadataLabel): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    return obj;
  },

  create(base?: DeepPartial<StorageMetadataLabel>): StorageMetadataLabel {
    return StorageMetadataLabel.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageMetadataLabel>): StorageMetadataLabel {
    const message = createBaseStorageMetadataLabel();
    message.key = object.key ?? "";
    return message;
  },
};

function createBaseDocumentLocation(): DocumentLocation {
  return { fileOffset: Long.ZERO };
}

export const DocumentLocation: MessageFns<DocumentLocation> = {
  encode(message: DocumentLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.fileOffset.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.fileOffset.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DocumentLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDocumentLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.fileOffset = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DocumentLocation {
    return { fileOffset: isSet(object.fileOffset) ? Long.fromValue(object.fileOffset) : Long.ZERO };
  },

  toJSON(message: DocumentLocation): unknown {
    const obj: any = {};
    if (!message.fileOffset.equals(Long.ZERO)) {
      obj.fileOffset = (message.fileOffset || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DocumentLocation>): DocumentLocation {
    return DocumentLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DocumentLocation>): DocumentLocation {
    const message = createBaseDocumentLocation();
    message.fileOffset = (object.fileOffset !== undefined && object.fileOffset !== null)
      ? Long.fromValue(object.fileOffset)
      : Long.ZERO;
    return message;
  },
};

function createBaseRecordLocation(): RecordLocation {
  return { recordKey: undefined, fieldId: undefined, tableLocation: undefined };
}

export const RecordLocation: MessageFns<RecordLocation> = {
  encode(message: RecordLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recordKey !== undefined) {
      RecordKey.encode(message.recordKey, writer.uint32(10).fork()).join();
    }
    if (message.fieldId !== undefined) {
      FieldId.encode(message.fieldId, writer.uint32(18).fork()).join();
    }
    if (message.tableLocation !== undefined) {
      TableLocation.encode(message.tableLocation, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recordKey = RecordKey.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fieldId = FieldId.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tableLocation = TableLocation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordLocation {
    return {
      recordKey: isSet(object.recordKey) ? RecordKey.fromJSON(object.recordKey) : undefined,
      fieldId: isSet(object.fieldId) ? FieldId.fromJSON(object.fieldId) : undefined,
      tableLocation: isSet(object.tableLocation) ? TableLocation.fromJSON(object.tableLocation) : undefined,
    };
  },

  toJSON(message: RecordLocation): unknown {
    const obj: any = {};
    if (message.recordKey !== undefined) {
      obj.recordKey = RecordKey.toJSON(message.recordKey);
    }
    if (message.fieldId !== undefined) {
      obj.fieldId = FieldId.toJSON(message.fieldId);
    }
    if (message.tableLocation !== undefined) {
      obj.tableLocation = TableLocation.toJSON(message.tableLocation);
    }
    return obj;
  },

  create(base?: DeepPartial<RecordLocation>): RecordLocation {
    return RecordLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordLocation>): RecordLocation {
    const message = createBaseRecordLocation();
    message.recordKey = (object.recordKey !== undefined && object.recordKey !== null)
      ? RecordKey.fromPartial(object.recordKey)
      : undefined;
    message.fieldId = (object.fieldId !== undefined && object.fieldId !== null)
      ? FieldId.fromPartial(object.fieldId)
      : undefined;
    message.tableLocation = (object.tableLocation !== undefined && object.tableLocation !== null)
      ? TableLocation.fromPartial(object.tableLocation)
      : undefined;
    return message;
  },
};

function createBaseTableLocation(): TableLocation {
  return { rowIndex: Long.ZERO };
}

export const TableLocation: MessageFns<TableLocation> = {
  encode(message: TableLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.rowIndex.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.rowIndex.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.rowIndex = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableLocation {
    return { rowIndex: isSet(object.rowIndex) ? Long.fromValue(object.rowIndex) : Long.ZERO };
  },

  toJSON(message: TableLocation): unknown {
    const obj: any = {};
    if (!message.rowIndex.equals(Long.ZERO)) {
      obj.rowIndex = (message.rowIndex || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<TableLocation>): TableLocation {
    return TableLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableLocation>): TableLocation {
    const message = createBaseTableLocation();
    message.rowIndex = (object.rowIndex !== undefined && object.rowIndex !== null)
      ? Long.fromValue(object.rowIndex)
      : Long.ZERO;
    return message;
  },
};

function createBaseContainer(): Container {
  return { type: "", projectId: "", fullPath: "", rootPath: "", relativePath: "", updateTime: undefined, version: "" };
}

export const Container: MessageFns<Container> = {
  encode(message: Container, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.fullPath !== "") {
      writer.uint32(26).string(message.fullPath);
    }
    if (message.rootPath !== "") {
      writer.uint32(34).string(message.rootPath);
    }
    if (message.relativePath !== "") {
      writer.uint32(42).string(message.relativePath);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(50).fork()).join();
    }
    if (message.version !== "") {
      writer.uint32(58).string(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Container {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainer();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.fullPath = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.rootPath = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.relativePath = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.version = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Container {
    return {
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      fullPath: isSet(object.fullPath) ? globalThis.String(object.fullPath) : "",
      rootPath: isSet(object.rootPath) ? globalThis.String(object.rootPath) : "",
      relativePath: isSet(object.relativePath) ? globalThis.String(object.relativePath) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      version: isSet(object.version) ? globalThis.String(object.version) : "",
    };
  },

  toJSON(message: Container): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.fullPath !== "") {
      obj.fullPath = message.fullPath;
    }
    if (message.rootPath !== "") {
      obj.rootPath = message.rootPath;
    }
    if (message.relativePath !== "") {
      obj.relativePath = message.relativePath;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    return obj;
  },

  create(base?: DeepPartial<Container>): Container {
    return Container.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Container>): Container {
    const message = createBaseContainer();
    message.type = object.type ?? "";
    message.projectId = object.projectId ?? "";
    message.fullPath = object.fullPath ?? "";
    message.rootPath = object.rootPath ?? "";
    message.relativePath = object.relativePath ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.version = object.version ?? "";
    return message;
  },
};

function createBaseRange(): Range {
  return { start: Long.ZERO, end: Long.ZERO };
}

export const Range: MessageFns<Range> = {
  encode(message: Range, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.start.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.start.toString());
    }
    if (!message.end.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.end.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Range {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.start = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.end = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Range {
    return {
      start: isSet(object.start) ? Long.fromValue(object.start) : Long.ZERO,
      end: isSet(object.end) ? Long.fromValue(object.end) : Long.ZERO,
    };
  },

  toJSON(message: Range): unknown {
    const obj: any = {};
    if (!message.start.equals(Long.ZERO)) {
      obj.start = (message.start || Long.ZERO).toString();
    }
    if (!message.end.equals(Long.ZERO)) {
      obj.end = (message.end || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Range>): Range {
    return Range.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Range>): Range {
    const message = createBaseRange();
    message.start = (object.start !== undefined && object.start !== null) ? Long.fromValue(object.start) : Long.ZERO;
    message.end = (object.end !== undefined && object.end !== null) ? Long.fromValue(object.end) : Long.ZERO;
    return message;
  },
};

function createBaseImageLocation(): ImageLocation {
  return { boundingBoxes: [] };
}

export const ImageLocation: MessageFns<ImageLocation> = {
  encode(message: ImageLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.boundingBoxes) {
      BoundingBox.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.boundingBoxes.push(BoundingBox.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageLocation {
    return {
      boundingBoxes: globalThis.Array.isArray(object?.boundingBoxes)
        ? object.boundingBoxes.map((e: any) => BoundingBox.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ImageLocation): unknown {
    const obj: any = {};
    if (message.boundingBoxes?.length) {
      obj.boundingBoxes = message.boundingBoxes.map((e) => BoundingBox.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ImageLocation>): ImageLocation {
    return ImageLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageLocation>): ImageLocation {
    const message = createBaseImageLocation();
    message.boundingBoxes = object.boundingBoxes?.map((e) => BoundingBox.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBoundingBox(): BoundingBox {
  return { top: 0, left: 0, width: 0, height: 0 };
}

export const BoundingBox: MessageFns<BoundingBox> = {
  encode(message: BoundingBox, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.top !== 0) {
      writer.uint32(8).int32(message.top);
    }
    if (message.left !== 0) {
      writer.uint32(16).int32(message.left);
    }
    if (message.width !== 0) {
      writer.uint32(24).int32(message.width);
    }
    if (message.height !== 0) {
      writer.uint32(32).int32(message.height);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoundingBox {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoundingBox();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.top = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.left = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.width = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.height = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoundingBox {
    return {
      top: isSet(object.top) ? globalThis.Number(object.top) : 0,
      left: isSet(object.left) ? globalThis.Number(object.left) : 0,
      width: isSet(object.width) ? globalThis.Number(object.width) : 0,
      height: isSet(object.height) ? globalThis.Number(object.height) : 0,
    };
  },

  toJSON(message: BoundingBox): unknown {
    const obj: any = {};
    if (message.top !== 0) {
      obj.top = Math.round(message.top);
    }
    if (message.left !== 0) {
      obj.left = Math.round(message.left);
    }
    if (message.width !== 0) {
      obj.width = Math.round(message.width);
    }
    if (message.height !== 0) {
      obj.height = Math.round(message.height);
    }
    return obj;
  },

  create(base?: DeepPartial<BoundingBox>): BoundingBox {
    return BoundingBox.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BoundingBox>): BoundingBox {
    const message = createBaseBoundingBox();
    message.top = object.top ?? 0;
    message.left = object.left ?? 0;
    message.width = object.width ?? 0;
    message.height = object.height ?? 0;
    return message;
  },
};

function createBaseRedactImageRequest(): RedactImageRequest {
  return {
    parent: "",
    locationId: "",
    inspectConfig: undefined,
    imageRedactionConfigs: [],
    includeFindings: false,
    byteItem: undefined,
  };
}

export const RedactImageRequest: MessageFns<RedactImageRequest> = {
  encode(message: RedactImageRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.locationId !== "") {
      writer.uint32(66).string(message.locationId);
    }
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(18).fork()).join();
    }
    for (const v of message.imageRedactionConfigs) {
      RedactImageRequest_ImageRedactionConfig.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.includeFindings !== false) {
      writer.uint32(48).bool(message.includeFindings);
    }
    if (message.byteItem !== undefined) {
      ByteContentItem.encode(message.byteItem, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedactImageRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedactImageRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.locationId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.imageRedactionConfigs.push(RedactImageRequest_ImageRedactionConfig.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.includeFindings = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.byteItem = ByteContentItem.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedactImageRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
      imageRedactionConfigs: globalThis.Array.isArray(object?.imageRedactionConfigs)
        ? object.imageRedactionConfigs.map((e: any) => RedactImageRequest_ImageRedactionConfig.fromJSON(e))
        : [],
      includeFindings: isSet(object.includeFindings) ? globalThis.Boolean(object.includeFindings) : false,
      byteItem: isSet(object.byteItem) ? ByteContentItem.fromJSON(object.byteItem) : undefined,
    };
  },

  toJSON(message: RedactImageRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    if (message.imageRedactionConfigs?.length) {
      obj.imageRedactionConfigs = message.imageRedactionConfigs.map((e) =>
        RedactImageRequest_ImageRedactionConfig.toJSON(e)
      );
    }
    if (message.includeFindings !== false) {
      obj.includeFindings = message.includeFindings;
    }
    if (message.byteItem !== undefined) {
      obj.byteItem = ByteContentItem.toJSON(message.byteItem);
    }
    return obj;
  },

  create(base?: DeepPartial<RedactImageRequest>): RedactImageRequest {
    return RedactImageRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RedactImageRequest>): RedactImageRequest {
    const message = createBaseRedactImageRequest();
    message.parent = object.parent ?? "";
    message.locationId = object.locationId ?? "";
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    message.imageRedactionConfigs =
      object.imageRedactionConfigs?.map((e) => RedactImageRequest_ImageRedactionConfig.fromPartial(e)) || [];
    message.includeFindings = object.includeFindings ?? false;
    message.byteItem = (object.byteItem !== undefined && object.byteItem !== null)
      ? ByteContentItem.fromPartial(object.byteItem)
      : undefined;
    return message;
  },
};

function createBaseRedactImageRequest_ImageRedactionConfig(): RedactImageRequest_ImageRedactionConfig {
  return { infoType: undefined, redactAllText: undefined, redactionColor: undefined };
}

export const RedactImageRequest_ImageRedactionConfig: MessageFns<RedactImageRequest_ImageRedactionConfig> = {
  encode(message: RedactImageRequest_ImageRedactionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (message.redactAllText !== undefined) {
      writer.uint32(16).bool(message.redactAllText);
    }
    if (message.redactionColor !== undefined) {
      Color.encode(message.redactionColor, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedactImageRequest_ImageRedactionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedactImageRequest_ImageRedactionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.redactAllText = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.redactionColor = Color.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedactImageRequest_ImageRedactionConfig {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      redactAllText: isSet(object.redactAllText) ? globalThis.Boolean(object.redactAllText) : undefined,
      redactionColor: isSet(object.redactionColor) ? Color.fromJSON(object.redactionColor) : undefined,
    };
  },

  toJSON(message: RedactImageRequest_ImageRedactionConfig): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.redactAllText !== undefined) {
      obj.redactAllText = message.redactAllText;
    }
    if (message.redactionColor !== undefined) {
      obj.redactionColor = Color.toJSON(message.redactionColor);
    }
    return obj;
  },

  create(base?: DeepPartial<RedactImageRequest_ImageRedactionConfig>): RedactImageRequest_ImageRedactionConfig {
    return RedactImageRequest_ImageRedactionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RedactImageRequest_ImageRedactionConfig>): RedactImageRequest_ImageRedactionConfig {
    const message = createBaseRedactImageRequest_ImageRedactionConfig();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.redactAllText = object.redactAllText ?? undefined;
    message.redactionColor = (object.redactionColor !== undefined && object.redactionColor !== null)
      ? Color.fromPartial(object.redactionColor)
      : undefined;
    return message;
  },
};

function createBaseColor(): Color {
  return { red: 0, green: 0, blue: 0 };
}

export const Color: MessageFns<Color> = {
  encode(message: Color, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.red !== 0) {
      writer.uint32(13).float(message.red);
    }
    if (message.green !== 0) {
      writer.uint32(21).float(message.green);
    }
    if (message.blue !== 0) {
      writer.uint32(29).float(message.blue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Color {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseColor();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.red = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.green = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.blue = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Color {
    return {
      red: isSet(object.red) ? globalThis.Number(object.red) : 0,
      green: isSet(object.green) ? globalThis.Number(object.green) : 0,
      blue: isSet(object.blue) ? globalThis.Number(object.blue) : 0,
    };
  },

  toJSON(message: Color): unknown {
    const obj: any = {};
    if (message.red !== 0) {
      obj.red = message.red;
    }
    if (message.green !== 0) {
      obj.green = message.green;
    }
    if (message.blue !== 0) {
      obj.blue = message.blue;
    }
    return obj;
  },

  create(base?: DeepPartial<Color>): Color {
    return Color.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Color>): Color {
    const message = createBaseColor();
    message.red = object.red ?? 0;
    message.green = object.green ?? 0;
    message.blue = object.blue ?? 0;
    return message;
  },
};

function createBaseRedactImageResponse(): RedactImageResponse {
  return { redactedImage: Buffer.alloc(0), extractedText: "", inspectResult: undefined };
}

export const RedactImageResponse: MessageFns<RedactImageResponse> = {
  encode(message: RedactImageResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.redactedImage.length !== 0) {
      writer.uint32(10).bytes(message.redactedImage);
    }
    if (message.extractedText !== "") {
      writer.uint32(18).string(message.extractedText);
    }
    if (message.inspectResult !== undefined) {
      InspectResult.encode(message.inspectResult, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedactImageResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedactImageResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.redactedImage = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.extractedText = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectResult = InspectResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedactImageResponse {
    return {
      redactedImage: isSet(object.redactedImage) ? Buffer.from(bytesFromBase64(object.redactedImage)) : Buffer.alloc(0),
      extractedText: isSet(object.extractedText) ? globalThis.String(object.extractedText) : "",
      inspectResult: isSet(object.inspectResult) ? InspectResult.fromJSON(object.inspectResult) : undefined,
    };
  },

  toJSON(message: RedactImageResponse): unknown {
    const obj: any = {};
    if (message.redactedImage.length !== 0) {
      obj.redactedImage = base64FromBytes(message.redactedImage);
    }
    if (message.extractedText !== "") {
      obj.extractedText = message.extractedText;
    }
    if (message.inspectResult !== undefined) {
      obj.inspectResult = InspectResult.toJSON(message.inspectResult);
    }
    return obj;
  },

  create(base?: DeepPartial<RedactImageResponse>): RedactImageResponse {
    return RedactImageResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RedactImageResponse>): RedactImageResponse {
    const message = createBaseRedactImageResponse();
    message.redactedImage = object.redactedImage ?? Buffer.alloc(0);
    message.extractedText = object.extractedText ?? "";
    message.inspectResult = (object.inspectResult !== undefined && object.inspectResult !== null)
      ? InspectResult.fromPartial(object.inspectResult)
      : undefined;
    return message;
  },
};

function createBaseDeidentifyContentRequest(): DeidentifyContentRequest {
  return {
    parent: "",
    deidentifyConfig: undefined,
    inspectConfig: undefined,
    item: undefined,
    inspectTemplateName: "",
    deidentifyTemplateName: "",
    locationId: "",
  };
}

export const DeidentifyContentRequest: MessageFns<DeidentifyContentRequest> = {
  encode(message: DeidentifyContentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.deidentifyConfig !== undefined) {
      DeidentifyConfig.encode(message.deidentifyConfig, writer.uint32(18).fork()).join();
    }
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(26).fork()).join();
    }
    if (message.item !== undefined) {
      ContentItem.encode(message.item, writer.uint32(34).fork()).join();
    }
    if (message.inspectTemplateName !== "") {
      writer.uint32(42).string(message.inspectTemplateName);
    }
    if (message.deidentifyTemplateName !== "") {
      writer.uint32(50).string(message.deidentifyTemplateName);
    }
    if (message.locationId !== "") {
      writer.uint32(58).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyContentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyContentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deidentifyConfig = DeidentifyConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.item = ContentItem.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inspectTemplateName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.deidentifyTemplateName = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyContentRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      deidentifyConfig: isSet(object.deidentifyConfig) ? DeidentifyConfig.fromJSON(object.deidentifyConfig) : undefined,
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
      item: isSet(object.item) ? ContentItem.fromJSON(object.item) : undefined,
      inspectTemplateName: isSet(object.inspectTemplateName) ? globalThis.String(object.inspectTemplateName) : "",
      deidentifyTemplateName: isSet(object.deidentifyTemplateName)
        ? globalThis.String(object.deidentifyTemplateName)
        : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: DeidentifyContentRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.deidentifyConfig !== undefined) {
      obj.deidentifyConfig = DeidentifyConfig.toJSON(message.deidentifyConfig);
    }
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    if (message.item !== undefined) {
      obj.item = ContentItem.toJSON(message.item);
    }
    if (message.inspectTemplateName !== "") {
      obj.inspectTemplateName = message.inspectTemplateName;
    }
    if (message.deidentifyTemplateName !== "") {
      obj.deidentifyTemplateName = message.deidentifyTemplateName;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<DeidentifyContentRequest>): DeidentifyContentRequest {
    return DeidentifyContentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeidentifyContentRequest>): DeidentifyContentRequest {
    const message = createBaseDeidentifyContentRequest();
    message.parent = object.parent ?? "";
    message.deidentifyConfig = (object.deidentifyConfig !== undefined && object.deidentifyConfig !== null)
      ? DeidentifyConfig.fromPartial(object.deidentifyConfig)
      : undefined;
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    message.item = (object.item !== undefined && object.item !== null)
      ? ContentItem.fromPartial(object.item)
      : undefined;
    message.inspectTemplateName = object.inspectTemplateName ?? "";
    message.deidentifyTemplateName = object.deidentifyTemplateName ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseDeidentifyContentResponse(): DeidentifyContentResponse {
  return { item: undefined, overview: undefined };
}

export const DeidentifyContentResponse: MessageFns<DeidentifyContentResponse> = {
  encode(message: DeidentifyContentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.item !== undefined) {
      ContentItem.encode(message.item, writer.uint32(10).fork()).join();
    }
    if (message.overview !== undefined) {
      TransformationOverview.encode(message.overview, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyContentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyContentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.item = ContentItem.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.overview = TransformationOverview.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyContentResponse {
    return {
      item: isSet(object.item) ? ContentItem.fromJSON(object.item) : undefined,
      overview: isSet(object.overview) ? TransformationOverview.fromJSON(object.overview) : undefined,
    };
  },

  toJSON(message: DeidentifyContentResponse): unknown {
    const obj: any = {};
    if (message.item !== undefined) {
      obj.item = ContentItem.toJSON(message.item);
    }
    if (message.overview !== undefined) {
      obj.overview = TransformationOverview.toJSON(message.overview);
    }
    return obj;
  },

  create(base?: DeepPartial<DeidentifyContentResponse>): DeidentifyContentResponse {
    return DeidentifyContentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeidentifyContentResponse>): DeidentifyContentResponse {
    const message = createBaseDeidentifyContentResponse();
    message.item = (object.item !== undefined && object.item !== null)
      ? ContentItem.fromPartial(object.item)
      : undefined;
    message.overview = (object.overview !== undefined && object.overview !== null)
      ? TransformationOverview.fromPartial(object.overview)
      : undefined;
    return message;
  },
};

function createBaseReidentifyContentRequest(): ReidentifyContentRequest {
  return {
    parent: "",
    reidentifyConfig: undefined,
    inspectConfig: undefined,
    item: undefined,
    inspectTemplateName: "",
    reidentifyTemplateName: "",
    locationId: "",
  };
}

export const ReidentifyContentRequest: MessageFns<ReidentifyContentRequest> = {
  encode(message: ReidentifyContentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.reidentifyConfig !== undefined) {
      DeidentifyConfig.encode(message.reidentifyConfig, writer.uint32(18).fork()).join();
    }
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(26).fork()).join();
    }
    if (message.item !== undefined) {
      ContentItem.encode(message.item, writer.uint32(34).fork()).join();
    }
    if (message.inspectTemplateName !== "") {
      writer.uint32(42).string(message.inspectTemplateName);
    }
    if (message.reidentifyTemplateName !== "") {
      writer.uint32(50).string(message.reidentifyTemplateName);
    }
    if (message.locationId !== "") {
      writer.uint32(58).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReidentifyContentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReidentifyContentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.reidentifyConfig = DeidentifyConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.item = ContentItem.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inspectTemplateName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.reidentifyTemplateName = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReidentifyContentRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      reidentifyConfig: isSet(object.reidentifyConfig) ? DeidentifyConfig.fromJSON(object.reidentifyConfig) : undefined,
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
      item: isSet(object.item) ? ContentItem.fromJSON(object.item) : undefined,
      inspectTemplateName: isSet(object.inspectTemplateName) ? globalThis.String(object.inspectTemplateName) : "",
      reidentifyTemplateName: isSet(object.reidentifyTemplateName)
        ? globalThis.String(object.reidentifyTemplateName)
        : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ReidentifyContentRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.reidentifyConfig !== undefined) {
      obj.reidentifyConfig = DeidentifyConfig.toJSON(message.reidentifyConfig);
    }
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    if (message.item !== undefined) {
      obj.item = ContentItem.toJSON(message.item);
    }
    if (message.inspectTemplateName !== "") {
      obj.inspectTemplateName = message.inspectTemplateName;
    }
    if (message.reidentifyTemplateName !== "") {
      obj.reidentifyTemplateName = message.reidentifyTemplateName;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ReidentifyContentRequest>): ReidentifyContentRequest {
    return ReidentifyContentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReidentifyContentRequest>): ReidentifyContentRequest {
    const message = createBaseReidentifyContentRequest();
    message.parent = object.parent ?? "";
    message.reidentifyConfig = (object.reidentifyConfig !== undefined && object.reidentifyConfig !== null)
      ? DeidentifyConfig.fromPartial(object.reidentifyConfig)
      : undefined;
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    message.item = (object.item !== undefined && object.item !== null)
      ? ContentItem.fromPartial(object.item)
      : undefined;
    message.inspectTemplateName = object.inspectTemplateName ?? "";
    message.reidentifyTemplateName = object.reidentifyTemplateName ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseReidentifyContentResponse(): ReidentifyContentResponse {
  return { item: undefined, overview: undefined };
}

export const ReidentifyContentResponse: MessageFns<ReidentifyContentResponse> = {
  encode(message: ReidentifyContentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.item !== undefined) {
      ContentItem.encode(message.item, writer.uint32(10).fork()).join();
    }
    if (message.overview !== undefined) {
      TransformationOverview.encode(message.overview, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReidentifyContentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReidentifyContentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.item = ContentItem.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.overview = TransformationOverview.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReidentifyContentResponse {
    return {
      item: isSet(object.item) ? ContentItem.fromJSON(object.item) : undefined,
      overview: isSet(object.overview) ? TransformationOverview.fromJSON(object.overview) : undefined,
    };
  },

  toJSON(message: ReidentifyContentResponse): unknown {
    const obj: any = {};
    if (message.item !== undefined) {
      obj.item = ContentItem.toJSON(message.item);
    }
    if (message.overview !== undefined) {
      obj.overview = TransformationOverview.toJSON(message.overview);
    }
    return obj;
  },

  create(base?: DeepPartial<ReidentifyContentResponse>): ReidentifyContentResponse {
    return ReidentifyContentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReidentifyContentResponse>): ReidentifyContentResponse {
    const message = createBaseReidentifyContentResponse();
    message.item = (object.item !== undefined && object.item !== null)
      ? ContentItem.fromPartial(object.item)
      : undefined;
    message.overview = (object.overview !== undefined && object.overview !== null)
      ? TransformationOverview.fromPartial(object.overview)
      : undefined;
    return message;
  },
};

function createBaseInspectContentRequest(): InspectContentRequest {
  return { parent: "", inspectConfig: undefined, item: undefined, inspectTemplateName: "", locationId: "" };
}

export const InspectContentRequest: MessageFns<InspectContentRequest> = {
  encode(message: InspectContentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(18).fork()).join();
    }
    if (message.item !== undefined) {
      ContentItem.encode(message.item, writer.uint32(26).fork()).join();
    }
    if (message.inspectTemplateName !== "") {
      writer.uint32(34).string(message.inspectTemplateName);
    }
    if (message.locationId !== "") {
      writer.uint32(42).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectContentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectContentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.item = ContentItem.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.inspectTemplateName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectContentRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
      item: isSet(object.item) ? ContentItem.fromJSON(object.item) : undefined,
      inspectTemplateName: isSet(object.inspectTemplateName) ? globalThis.String(object.inspectTemplateName) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: InspectContentRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    if (message.item !== undefined) {
      obj.item = ContentItem.toJSON(message.item);
    }
    if (message.inspectTemplateName !== "") {
      obj.inspectTemplateName = message.inspectTemplateName;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<InspectContentRequest>): InspectContentRequest {
    return InspectContentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectContentRequest>): InspectContentRequest {
    const message = createBaseInspectContentRequest();
    message.parent = object.parent ?? "";
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    message.item = (object.item !== undefined && object.item !== null)
      ? ContentItem.fromPartial(object.item)
      : undefined;
    message.inspectTemplateName = object.inspectTemplateName ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseInspectContentResponse(): InspectContentResponse {
  return { result: undefined };
}

export const InspectContentResponse: MessageFns<InspectContentResponse> = {
  encode(message: InspectContentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.result !== undefined) {
      InspectResult.encode(message.result, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectContentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectContentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.result = InspectResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectContentResponse {
    return { result: isSet(object.result) ? InspectResult.fromJSON(object.result) : undefined };
  },

  toJSON(message: InspectContentResponse): unknown {
    const obj: any = {};
    if (message.result !== undefined) {
      obj.result = InspectResult.toJSON(message.result);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectContentResponse>): InspectContentResponse {
    return InspectContentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectContentResponse>): InspectContentResponse {
    const message = createBaseInspectContentResponse();
    message.result = (object.result !== undefined && object.result !== null)
      ? InspectResult.fromPartial(object.result)
      : undefined;
    return message;
  },
};

function createBaseOutputStorageConfig(): OutputStorageConfig {
  return { table: undefined, outputSchema: 0 };
}

export const OutputStorageConfig: MessageFns<OutputStorageConfig> = {
  encode(message: OutputStorageConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== undefined) {
      BigQueryTable.encode(message.table, writer.uint32(10).fork()).join();
    }
    if (message.outputSchema !== 0) {
      writer.uint32(24).int32(message.outputSchema);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OutputStorageConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOutputStorageConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = BigQueryTable.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.outputSchema = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OutputStorageConfig {
    return {
      table: isSet(object.table) ? BigQueryTable.fromJSON(object.table) : undefined,
      outputSchema: isSet(object.outputSchema) ? outputStorageConfig_OutputSchemaFromJSON(object.outputSchema) : 0,
    };
  },

  toJSON(message: OutputStorageConfig): unknown {
    const obj: any = {};
    if (message.table !== undefined) {
      obj.table = BigQueryTable.toJSON(message.table);
    }
    if (message.outputSchema !== 0) {
      obj.outputSchema = outputStorageConfig_OutputSchemaToJSON(message.outputSchema);
    }
    return obj;
  },

  create(base?: DeepPartial<OutputStorageConfig>): OutputStorageConfig {
    return OutputStorageConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OutputStorageConfig>): OutputStorageConfig {
    const message = createBaseOutputStorageConfig();
    message.table = (object.table !== undefined && object.table !== null)
      ? BigQueryTable.fromPartial(object.table)
      : undefined;
    message.outputSchema = object.outputSchema ?? 0;
    return message;
  },
};

function createBaseInfoTypeStats(): InfoTypeStats {
  return { infoType: undefined, count: Long.ZERO };
}

export const InfoTypeStats: MessageFns<InfoTypeStats> = {
  encode(message: InfoTypeStats, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (!message.count.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.count.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InfoTypeStats {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInfoTypeStats();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.count = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InfoTypeStats {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      count: isSet(object.count) ? Long.fromValue(object.count) : Long.ZERO,
    };
  },

  toJSON(message: InfoTypeStats): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (!message.count.equals(Long.ZERO)) {
      obj.count = (message.count || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<InfoTypeStats>): InfoTypeStats {
    return InfoTypeStats.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InfoTypeStats>): InfoTypeStats {
    const message = createBaseInfoTypeStats();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : Long.ZERO;
    return message;
  },
};

function createBaseInspectDataSourceDetails(): InspectDataSourceDetails {
  return { requestedOptions: undefined, result: undefined };
}

export const InspectDataSourceDetails: MessageFns<InspectDataSourceDetails> = {
  encode(message: InspectDataSourceDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requestedOptions !== undefined) {
      InspectDataSourceDetails_RequestedOptions.encode(message.requestedOptions, writer.uint32(18).fork()).join();
    }
    if (message.result !== undefined) {
      InspectDataSourceDetails_Result.encode(message.result, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectDataSourceDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectDataSourceDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestedOptions = InspectDataSourceDetails_RequestedOptions.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.result = InspectDataSourceDetails_Result.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectDataSourceDetails {
    return {
      requestedOptions: isSet(object.requestedOptions)
        ? InspectDataSourceDetails_RequestedOptions.fromJSON(object.requestedOptions)
        : undefined,
      result: isSet(object.result) ? InspectDataSourceDetails_Result.fromJSON(object.result) : undefined,
    };
  },

  toJSON(message: InspectDataSourceDetails): unknown {
    const obj: any = {};
    if (message.requestedOptions !== undefined) {
      obj.requestedOptions = InspectDataSourceDetails_RequestedOptions.toJSON(message.requestedOptions);
    }
    if (message.result !== undefined) {
      obj.result = InspectDataSourceDetails_Result.toJSON(message.result);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectDataSourceDetails>): InspectDataSourceDetails {
    return InspectDataSourceDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectDataSourceDetails>): InspectDataSourceDetails {
    const message = createBaseInspectDataSourceDetails();
    message.requestedOptions = (object.requestedOptions !== undefined && object.requestedOptions !== null)
      ? InspectDataSourceDetails_RequestedOptions.fromPartial(object.requestedOptions)
      : undefined;
    message.result = (object.result !== undefined && object.result !== null)
      ? InspectDataSourceDetails_Result.fromPartial(object.result)
      : undefined;
    return message;
  },
};

function createBaseInspectDataSourceDetails_RequestedOptions(): InspectDataSourceDetails_RequestedOptions {
  return { snapshotInspectTemplate: undefined, jobConfig: undefined };
}

export const InspectDataSourceDetails_RequestedOptions: MessageFns<InspectDataSourceDetails_RequestedOptions> = {
  encode(message: InspectDataSourceDetails_RequestedOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshotInspectTemplate !== undefined) {
      InspectTemplate.encode(message.snapshotInspectTemplate, writer.uint32(10).fork()).join();
    }
    if (message.jobConfig !== undefined) {
      InspectJobConfig.encode(message.jobConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectDataSourceDetails_RequestedOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectDataSourceDetails_RequestedOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshotInspectTemplate = InspectTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.jobConfig = InspectJobConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectDataSourceDetails_RequestedOptions {
    return {
      snapshotInspectTemplate: isSet(object.snapshotInspectTemplate)
        ? InspectTemplate.fromJSON(object.snapshotInspectTemplate)
        : undefined,
      jobConfig: isSet(object.jobConfig) ? InspectJobConfig.fromJSON(object.jobConfig) : undefined,
    };
  },

  toJSON(message: InspectDataSourceDetails_RequestedOptions): unknown {
    const obj: any = {};
    if (message.snapshotInspectTemplate !== undefined) {
      obj.snapshotInspectTemplate = InspectTemplate.toJSON(message.snapshotInspectTemplate);
    }
    if (message.jobConfig !== undefined) {
      obj.jobConfig = InspectJobConfig.toJSON(message.jobConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectDataSourceDetails_RequestedOptions>): InspectDataSourceDetails_RequestedOptions {
    return InspectDataSourceDetails_RequestedOptions.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<InspectDataSourceDetails_RequestedOptions>,
  ): InspectDataSourceDetails_RequestedOptions {
    const message = createBaseInspectDataSourceDetails_RequestedOptions();
    message.snapshotInspectTemplate =
      (object.snapshotInspectTemplate !== undefined && object.snapshotInspectTemplate !== null)
        ? InspectTemplate.fromPartial(object.snapshotInspectTemplate)
        : undefined;
    message.jobConfig = (object.jobConfig !== undefined && object.jobConfig !== null)
      ? InspectJobConfig.fromPartial(object.jobConfig)
      : undefined;
    return message;
  },
};

function createBaseInspectDataSourceDetails_Result(): InspectDataSourceDetails_Result {
  return {
    processedBytes: Long.ZERO,
    totalEstimatedBytes: Long.ZERO,
    infoTypeStats: [],
    numRowsProcessed: Long.ZERO,
    hybridStats: undefined,
  };
}

export const InspectDataSourceDetails_Result: MessageFns<InspectDataSourceDetails_Result> = {
  encode(message: InspectDataSourceDetails_Result, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.processedBytes.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.processedBytes.toString());
    }
    if (!message.totalEstimatedBytes.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.totalEstimatedBytes.toString());
    }
    for (const v of message.infoTypeStats) {
      InfoTypeStats.encode(v!, writer.uint32(26).fork()).join();
    }
    if (!message.numRowsProcessed.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.numRowsProcessed.toString());
    }
    if (message.hybridStats !== undefined) {
      HybridInspectStatistics.encode(message.hybridStats, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectDataSourceDetails_Result {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectDataSourceDetails_Result();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.processedBytes = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.totalEstimatedBytes = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.infoTypeStats.push(InfoTypeStats.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.numRowsProcessed = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.hybridStats = HybridInspectStatistics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectDataSourceDetails_Result {
    return {
      processedBytes: isSet(object.processedBytes) ? Long.fromValue(object.processedBytes) : Long.ZERO,
      totalEstimatedBytes: isSet(object.totalEstimatedBytes) ? Long.fromValue(object.totalEstimatedBytes) : Long.ZERO,
      infoTypeStats: globalThis.Array.isArray(object?.infoTypeStats)
        ? object.infoTypeStats.map((e: any) => InfoTypeStats.fromJSON(e))
        : [],
      numRowsProcessed: isSet(object.numRowsProcessed) ? Long.fromValue(object.numRowsProcessed) : Long.ZERO,
      hybridStats: isSet(object.hybridStats) ? HybridInspectStatistics.fromJSON(object.hybridStats) : undefined,
    };
  },

  toJSON(message: InspectDataSourceDetails_Result): unknown {
    const obj: any = {};
    if (!message.processedBytes.equals(Long.ZERO)) {
      obj.processedBytes = (message.processedBytes || Long.ZERO).toString();
    }
    if (!message.totalEstimatedBytes.equals(Long.ZERO)) {
      obj.totalEstimatedBytes = (message.totalEstimatedBytes || Long.ZERO).toString();
    }
    if (message.infoTypeStats?.length) {
      obj.infoTypeStats = message.infoTypeStats.map((e) => InfoTypeStats.toJSON(e));
    }
    if (!message.numRowsProcessed.equals(Long.ZERO)) {
      obj.numRowsProcessed = (message.numRowsProcessed || Long.ZERO).toString();
    }
    if (message.hybridStats !== undefined) {
      obj.hybridStats = HybridInspectStatistics.toJSON(message.hybridStats);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectDataSourceDetails_Result>): InspectDataSourceDetails_Result {
    return InspectDataSourceDetails_Result.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectDataSourceDetails_Result>): InspectDataSourceDetails_Result {
    const message = createBaseInspectDataSourceDetails_Result();
    message.processedBytes = (object.processedBytes !== undefined && object.processedBytes !== null)
      ? Long.fromValue(object.processedBytes)
      : Long.ZERO;
    message.totalEstimatedBytes = (object.totalEstimatedBytes !== undefined && object.totalEstimatedBytes !== null)
      ? Long.fromValue(object.totalEstimatedBytes)
      : Long.ZERO;
    message.infoTypeStats = object.infoTypeStats?.map((e) => InfoTypeStats.fromPartial(e)) || [];
    message.numRowsProcessed = (object.numRowsProcessed !== undefined && object.numRowsProcessed !== null)
      ? Long.fromValue(object.numRowsProcessed)
      : Long.ZERO;
    message.hybridStats = (object.hybridStats !== undefined && object.hybridStats !== null)
      ? HybridInspectStatistics.fromPartial(object.hybridStats)
      : undefined;
    return message;
  },
};

function createBaseDataProfileBigQueryRowSchema(): DataProfileBigQueryRowSchema {
  return { tableProfile: undefined, columnProfile: undefined, fileStoreProfile: undefined };
}

export const DataProfileBigQueryRowSchema: MessageFns<DataProfileBigQueryRowSchema> = {
  encode(message: DataProfileBigQueryRowSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableProfile !== undefined) {
      TableDataProfile.encode(message.tableProfile, writer.uint32(10).fork()).join();
    }
    if (message.columnProfile !== undefined) {
      ColumnDataProfile.encode(message.columnProfile, writer.uint32(18).fork()).join();
    }
    if (message.fileStoreProfile !== undefined) {
      FileStoreDataProfile.encode(message.fileStoreProfile, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileBigQueryRowSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileBigQueryRowSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableProfile = TableDataProfile.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.columnProfile = ColumnDataProfile.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.fileStoreProfile = FileStoreDataProfile.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileBigQueryRowSchema {
    return {
      tableProfile: isSet(object.tableProfile) ? TableDataProfile.fromJSON(object.tableProfile) : undefined,
      columnProfile: isSet(object.columnProfile) ? ColumnDataProfile.fromJSON(object.columnProfile) : undefined,
      fileStoreProfile: isSet(object.fileStoreProfile)
        ? FileStoreDataProfile.fromJSON(object.fileStoreProfile)
        : undefined,
    };
  },

  toJSON(message: DataProfileBigQueryRowSchema): unknown {
    const obj: any = {};
    if (message.tableProfile !== undefined) {
      obj.tableProfile = TableDataProfile.toJSON(message.tableProfile);
    }
    if (message.columnProfile !== undefined) {
      obj.columnProfile = ColumnDataProfile.toJSON(message.columnProfile);
    }
    if (message.fileStoreProfile !== undefined) {
      obj.fileStoreProfile = FileStoreDataProfile.toJSON(message.fileStoreProfile);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileBigQueryRowSchema>): DataProfileBigQueryRowSchema {
    return DataProfileBigQueryRowSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileBigQueryRowSchema>): DataProfileBigQueryRowSchema {
    const message = createBaseDataProfileBigQueryRowSchema();
    message.tableProfile = (object.tableProfile !== undefined && object.tableProfile !== null)
      ? TableDataProfile.fromPartial(object.tableProfile)
      : undefined;
    message.columnProfile = (object.columnProfile !== undefined && object.columnProfile !== null)
      ? ColumnDataProfile.fromPartial(object.columnProfile)
      : undefined;
    message.fileStoreProfile = (object.fileStoreProfile !== undefined && object.fileStoreProfile !== null)
      ? FileStoreDataProfile.fromPartial(object.fileStoreProfile)
      : undefined;
    return message;
  },
};

function createBaseHybridInspectStatistics(): HybridInspectStatistics {
  return { processedCount: Long.ZERO, abortedCount: Long.ZERO, pendingCount: Long.ZERO };
}

export const HybridInspectStatistics: MessageFns<HybridInspectStatistics> = {
  encode(message: HybridInspectStatistics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.processedCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.processedCount.toString());
    }
    if (!message.abortedCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.abortedCount.toString());
    }
    if (!message.pendingCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.pendingCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridInspectStatistics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridInspectStatistics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.processedCount = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.abortedCount = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pendingCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HybridInspectStatistics {
    return {
      processedCount: isSet(object.processedCount) ? Long.fromValue(object.processedCount) : Long.ZERO,
      abortedCount: isSet(object.abortedCount) ? Long.fromValue(object.abortedCount) : Long.ZERO,
      pendingCount: isSet(object.pendingCount) ? Long.fromValue(object.pendingCount) : Long.ZERO,
    };
  },

  toJSON(message: HybridInspectStatistics): unknown {
    const obj: any = {};
    if (!message.processedCount.equals(Long.ZERO)) {
      obj.processedCount = (message.processedCount || Long.ZERO).toString();
    }
    if (!message.abortedCount.equals(Long.ZERO)) {
      obj.abortedCount = (message.abortedCount || Long.ZERO).toString();
    }
    if (!message.pendingCount.equals(Long.ZERO)) {
      obj.pendingCount = (message.pendingCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<HybridInspectStatistics>): HybridInspectStatistics {
    return HybridInspectStatistics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HybridInspectStatistics>): HybridInspectStatistics {
    const message = createBaseHybridInspectStatistics();
    message.processedCount = (object.processedCount !== undefined && object.processedCount !== null)
      ? Long.fromValue(object.processedCount)
      : Long.ZERO;
    message.abortedCount = (object.abortedCount !== undefined && object.abortedCount !== null)
      ? Long.fromValue(object.abortedCount)
      : Long.ZERO;
    message.pendingCount = (object.pendingCount !== undefined && object.pendingCount !== null)
      ? Long.fromValue(object.pendingCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseActionDetails(): ActionDetails {
  return { deidentifyDetails: undefined };
}

export const ActionDetails: MessageFns<ActionDetails> = {
  encode(message: ActionDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deidentifyDetails !== undefined) {
      DeidentifyDataSourceDetails.encode(message.deidentifyDetails, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.deidentifyDetails = DeidentifyDataSourceDetails.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionDetails {
    return {
      deidentifyDetails: isSet(object.deidentifyDetails)
        ? DeidentifyDataSourceDetails.fromJSON(object.deidentifyDetails)
        : undefined,
    };
  },

  toJSON(message: ActionDetails): unknown {
    const obj: any = {};
    if (message.deidentifyDetails !== undefined) {
      obj.deidentifyDetails = DeidentifyDataSourceDetails.toJSON(message.deidentifyDetails);
    }
    return obj;
  },

  create(base?: DeepPartial<ActionDetails>): ActionDetails {
    return ActionDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ActionDetails>): ActionDetails {
    const message = createBaseActionDetails();
    message.deidentifyDetails = (object.deidentifyDetails !== undefined && object.deidentifyDetails !== null)
      ? DeidentifyDataSourceDetails.fromPartial(object.deidentifyDetails)
      : undefined;
    return message;
  },
};

function createBaseDeidentifyDataSourceStats(): DeidentifyDataSourceStats {
  return { transformedBytes: Long.ZERO, transformationCount: Long.ZERO, transformationErrorCount: Long.ZERO };
}

export const DeidentifyDataSourceStats: MessageFns<DeidentifyDataSourceStats> = {
  encode(message: DeidentifyDataSourceStats, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.transformedBytes.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.transformedBytes.toString());
    }
    if (!message.transformationCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.transformationCount.toString());
    }
    if (!message.transformationErrorCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.transformationErrorCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyDataSourceStats {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyDataSourceStats();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.transformedBytes = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.transformationCount = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.transformationErrorCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyDataSourceStats {
    return {
      transformedBytes: isSet(object.transformedBytes) ? Long.fromValue(object.transformedBytes) : Long.ZERO,
      transformationCount: isSet(object.transformationCount) ? Long.fromValue(object.transformationCount) : Long.ZERO,
      transformationErrorCount: isSet(object.transformationErrorCount)
        ? Long.fromValue(object.transformationErrorCount)
        : Long.ZERO,
    };
  },

  toJSON(message: DeidentifyDataSourceStats): unknown {
    const obj: any = {};
    if (!message.transformedBytes.equals(Long.ZERO)) {
      obj.transformedBytes = (message.transformedBytes || Long.ZERO).toString();
    }
    if (!message.transformationCount.equals(Long.ZERO)) {
      obj.transformationCount = (message.transformationCount || Long.ZERO).toString();
    }
    if (!message.transformationErrorCount.equals(Long.ZERO)) {
      obj.transformationErrorCount = (message.transformationErrorCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DeidentifyDataSourceStats>): DeidentifyDataSourceStats {
    return DeidentifyDataSourceStats.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeidentifyDataSourceStats>): DeidentifyDataSourceStats {
    const message = createBaseDeidentifyDataSourceStats();
    message.transformedBytes = (object.transformedBytes !== undefined && object.transformedBytes !== null)
      ? Long.fromValue(object.transformedBytes)
      : Long.ZERO;
    message.transformationCount = (object.transformationCount !== undefined && object.transformationCount !== null)
      ? Long.fromValue(object.transformationCount)
      : Long.ZERO;
    message.transformationErrorCount =
      (object.transformationErrorCount !== undefined && object.transformationErrorCount !== null)
        ? Long.fromValue(object.transformationErrorCount)
        : Long.ZERO;
    return message;
  },
};

function createBaseDeidentifyDataSourceDetails(): DeidentifyDataSourceDetails {
  return { requestedOptions: undefined, deidentifyStats: undefined };
}

export const DeidentifyDataSourceDetails: MessageFns<DeidentifyDataSourceDetails> = {
  encode(message: DeidentifyDataSourceDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requestedOptions !== undefined) {
      DeidentifyDataSourceDetails_RequestedDeidentifyOptions.encode(message.requestedOptions, writer.uint32(10).fork())
        .join();
    }
    if (message.deidentifyStats !== undefined) {
      DeidentifyDataSourceStats.encode(message.deidentifyStats, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyDataSourceDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyDataSourceDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.requestedOptions = DeidentifyDataSourceDetails_RequestedDeidentifyOptions.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deidentifyStats = DeidentifyDataSourceStats.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyDataSourceDetails {
    return {
      requestedOptions: isSet(object.requestedOptions)
        ? DeidentifyDataSourceDetails_RequestedDeidentifyOptions.fromJSON(object.requestedOptions)
        : undefined,
      deidentifyStats: isSet(object.deidentifyStats)
        ? DeidentifyDataSourceStats.fromJSON(object.deidentifyStats)
        : undefined,
    };
  },

  toJSON(message: DeidentifyDataSourceDetails): unknown {
    const obj: any = {};
    if (message.requestedOptions !== undefined) {
      obj.requestedOptions = DeidentifyDataSourceDetails_RequestedDeidentifyOptions.toJSON(message.requestedOptions);
    }
    if (message.deidentifyStats !== undefined) {
      obj.deidentifyStats = DeidentifyDataSourceStats.toJSON(message.deidentifyStats);
    }
    return obj;
  },

  create(base?: DeepPartial<DeidentifyDataSourceDetails>): DeidentifyDataSourceDetails {
    return DeidentifyDataSourceDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeidentifyDataSourceDetails>): DeidentifyDataSourceDetails {
    const message = createBaseDeidentifyDataSourceDetails();
    message.requestedOptions = (object.requestedOptions !== undefined && object.requestedOptions !== null)
      ? DeidentifyDataSourceDetails_RequestedDeidentifyOptions.fromPartial(object.requestedOptions)
      : undefined;
    message.deidentifyStats = (object.deidentifyStats !== undefined && object.deidentifyStats !== null)
      ? DeidentifyDataSourceStats.fromPartial(object.deidentifyStats)
      : undefined;
    return message;
  },
};

function createBaseDeidentifyDataSourceDetails_RequestedDeidentifyOptions(): DeidentifyDataSourceDetails_RequestedDeidentifyOptions {
  return {
    snapshotDeidentifyTemplate: undefined,
    snapshotStructuredDeidentifyTemplate: undefined,
    snapshotImageRedactTemplate: undefined,
  };
}

export const DeidentifyDataSourceDetails_RequestedDeidentifyOptions: MessageFns<
  DeidentifyDataSourceDetails_RequestedDeidentifyOptions
> = {
  encode(
    message: DeidentifyDataSourceDetails_RequestedDeidentifyOptions,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.snapshotDeidentifyTemplate !== undefined) {
      DeidentifyTemplate.encode(message.snapshotDeidentifyTemplate, writer.uint32(10).fork()).join();
    }
    if (message.snapshotStructuredDeidentifyTemplate !== undefined) {
      DeidentifyTemplate.encode(message.snapshotStructuredDeidentifyTemplate, writer.uint32(18).fork()).join();
    }
    if (message.snapshotImageRedactTemplate !== undefined) {
      DeidentifyTemplate.encode(message.snapshotImageRedactTemplate, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyDataSourceDetails_RequestedDeidentifyOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyDataSourceDetails_RequestedDeidentifyOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshotDeidentifyTemplate = DeidentifyTemplate.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.snapshotStructuredDeidentifyTemplate = DeidentifyTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.snapshotImageRedactTemplate = DeidentifyTemplate.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyDataSourceDetails_RequestedDeidentifyOptions {
    return {
      snapshotDeidentifyTemplate: isSet(object.snapshotDeidentifyTemplate)
        ? DeidentifyTemplate.fromJSON(object.snapshotDeidentifyTemplate)
        : undefined,
      snapshotStructuredDeidentifyTemplate: isSet(object.snapshotStructuredDeidentifyTemplate)
        ? DeidentifyTemplate.fromJSON(object.snapshotStructuredDeidentifyTemplate)
        : undefined,
      snapshotImageRedactTemplate: isSet(object.snapshotImageRedactTemplate)
        ? DeidentifyTemplate.fromJSON(object.snapshotImageRedactTemplate)
        : undefined,
    };
  },

  toJSON(message: DeidentifyDataSourceDetails_RequestedDeidentifyOptions): unknown {
    const obj: any = {};
    if (message.snapshotDeidentifyTemplate !== undefined) {
      obj.snapshotDeidentifyTemplate = DeidentifyTemplate.toJSON(message.snapshotDeidentifyTemplate);
    }
    if (message.snapshotStructuredDeidentifyTemplate !== undefined) {
      obj.snapshotStructuredDeidentifyTemplate = DeidentifyTemplate.toJSON(
        message.snapshotStructuredDeidentifyTemplate,
      );
    }
    if (message.snapshotImageRedactTemplate !== undefined) {
      obj.snapshotImageRedactTemplate = DeidentifyTemplate.toJSON(message.snapshotImageRedactTemplate);
    }
    return obj;
  },

  create(
    base?: DeepPartial<DeidentifyDataSourceDetails_RequestedDeidentifyOptions>,
  ): DeidentifyDataSourceDetails_RequestedDeidentifyOptions {
    return DeidentifyDataSourceDetails_RequestedDeidentifyOptions.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DeidentifyDataSourceDetails_RequestedDeidentifyOptions>,
  ): DeidentifyDataSourceDetails_RequestedDeidentifyOptions {
    const message = createBaseDeidentifyDataSourceDetails_RequestedDeidentifyOptions();
    message.snapshotDeidentifyTemplate =
      (object.snapshotDeidentifyTemplate !== undefined && object.snapshotDeidentifyTemplate !== null)
        ? DeidentifyTemplate.fromPartial(object.snapshotDeidentifyTemplate)
        : undefined;
    message.snapshotStructuredDeidentifyTemplate =
      (object.snapshotStructuredDeidentifyTemplate !== undefined &&
          object.snapshotStructuredDeidentifyTemplate !== null)
        ? DeidentifyTemplate.fromPartial(object.snapshotStructuredDeidentifyTemplate)
        : undefined;
    message.snapshotImageRedactTemplate =
      (object.snapshotImageRedactTemplate !== undefined && object.snapshotImageRedactTemplate !== null)
        ? DeidentifyTemplate.fromPartial(object.snapshotImageRedactTemplate)
        : undefined;
    return message;
  },
};

function createBaseInfoTypeDescription(): InfoTypeDescription {
  return {
    name: "",
    displayName: "",
    supportedBy: [],
    description: "",
    versions: [],
    categories: [],
    sensitivityScore: undefined,
  };
}

export const InfoTypeDescription: MessageFns<InfoTypeDescription> = {
  encode(message: InfoTypeDescription, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    writer.uint32(26).fork();
    for (const v of message.supportedBy) {
      writer.int32(v);
    }
    writer.join();
    if (message.description !== "") {
      writer.uint32(34).string(message.description);
    }
    for (const v of message.versions) {
      VersionDescription.encode(v!, writer.uint32(74).fork()).join();
    }
    for (const v of message.categories) {
      InfoTypeCategory.encode(v!, writer.uint32(82).fork()).join();
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InfoTypeDescription {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInfoTypeDescription();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag === 24) {
            message.supportedBy.push(reader.int32() as any);

            continue;
          }

          if (tag === 26) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.supportedBy.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.description = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.versions.push(VersionDescription.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.categories.push(InfoTypeCategory.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InfoTypeDescription {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      supportedBy: globalThis.Array.isArray(object?.supportedBy)
        ? object.supportedBy.map((e: any) => infoTypeSupportedByFromJSON(e))
        : [],
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      versions: globalThis.Array.isArray(object?.versions)
        ? object.versions.map((e: any) => VersionDescription.fromJSON(e))
        : [],
      categories: globalThis.Array.isArray(object?.categories)
        ? object.categories.map((e: any) => InfoTypeCategory.fromJSON(e))
        : [],
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
    };
  },

  toJSON(message: InfoTypeDescription): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.supportedBy?.length) {
      obj.supportedBy = message.supportedBy.map((e) => infoTypeSupportedByToJSON(e));
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.versions?.length) {
      obj.versions = message.versions.map((e) => VersionDescription.toJSON(e));
    }
    if (message.categories?.length) {
      obj.categories = message.categories.map((e) => InfoTypeCategory.toJSON(e));
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    return obj;
  },

  create(base?: DeepPartial<InfoTypeDescription>): InfoTypeDescription {
    return InfoTypeDescription.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InfoTypeDescription>): InfoTypeDescription {
    const message = createBaseInfoTypeDescription();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.supportedBy = object.supportedBy?.map((e) => e) || [];
    message.description = object.description ?? "";
    message.versions = object.versions?.map((e) => VersionDescription.fromPartial(e)) || [];
    message.categories = object.categories?.map((e) => InfoTypeCategory.fromPartial(e)) || [];
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    return message;
  },
};

function createBaseInfoTypeCategory(): InfoTypeCategory {
  return { locationCategory: undefined, industryCategory: undefined, typeCategory: undefined };
}

export const InfoTypeCategory: MessageFns<InfoTypeCategory> = {
  encode(message: InfoTypeCategory, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.locationCategory !== undefined) {
      writer.uint32(8).int32(message.locationCategory);
    }
    if (message.industryCategory !== undefined) {
      writer.uint32(16).int32(message.industryCategory);
    }
    if (message.typeCategory !== undefined) {
      writer.uint32(24).int32(message.typeCategory);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InfoTypeCategory {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInfoTypeCategory();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.locationCategory = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.industryCategory = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.typeCategory = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InfoTypeCategory {
    return {
      locationCategory: isSet(object.locationCategory)
        ? infoTypeCategory_LocationCategoryFromJSON(object.locationCategory)
        : undefined,
      industryCategory: isSet(object.industryCategory)
        ? infoTypeCategory_IndustryCategoryFromJSON(object.industryCategory)
        : undefined,
      typeCategory: isSet(object.typeCategory) ? infoTypeCategory_TypeCategoryFromJSON(object.typeCategory) : undefined,
    };
  },

  toJSON(message: InfoTypeCategory): unknown {
    const obj: any = {};
    if (message.locationCategory !== undefined) {
      obj.locationCategory = infoTypeCategory_LocationCategoryToJSON(message.locationCategory);
    }
    if (message.industryCategory !== undefined) {
      obj.industryCategory = infoTypeCategory_IndustryCategoryToJSON(message.industryCategory);
    }
    if (message.typeCategory !== undefined) {
      obj.typeCategory = infoTypeCategory_TypeCategoryToJSON(message.typeCategory);
    }
    return obj;
  },

  create(base?: DeepPartial<InfoTypeCategory>): InfoTypeCategory {
    return InfoTypeCategory.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InfoTypeCategory>): InfoTypeCategory {
    const message = createBaseInfoTypeCategory();
    message.locationCategory = object.locationCategory ?? undefined;
    message.industryCategory = object.industryCategory ?? undefined;
    message.typeCategory = object.typeCategory ?? undefined;
    return message;
  },
};

function createBaseVersionDescription(): VersionDescription {
  return { version: "", description: "" };
}

export const VersionDescription: MessageFns<VersionDescription> = {
  encode(message: VersionDescription, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VersionDescription {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVersionDescription();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VersionDescription {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: VersionDescription): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create(base?: DeepPartial<VersionDescription>): VersionDescription {
    return VersionDescription.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VersionDescription>): VersionDescription {
    const message = createBaseVersionDescription();
    message.version = object.version ?? "";
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseListInfoTypesRequest(): ListInfoTypesRequest {
  return { parent: "", languageCode: "", filter: "", locationId: "" };
}

export const ListInfoTypesRequest: MessageFns<ListInfoTypesRequest> = {
  encode(message: ListInfoTypesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    if (message.languageCode !== "") {
      writer.uint32(10).string(message.languageCode);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.locationId !== "") {
      writer.uint32(26).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInfoTypesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInfoTypesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInfoTypesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ListInfoTypesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInfoTypesRequest>): ListInfoTypesRequest {
    return ListInfoTypesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInfoTypesRequest>): ListInfoTypesRequest {
    const message = createBaseListInfoTypesRequest();
    message.parent = object.parent ?? "";
    message.languageCode = object.languageCode ?? "";
    message.filter = object.filter ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListInfoTypesResponse(): ListInfoTypesResponse {
  return { infoTypes: [] };
}

export const ListInfoTypesResponse: MessageFns<ListInfoTypesResponse> = {
  encode(message: ListInfoTypesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.infoTypes) {
      InfoTypeDescription.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInfoTypesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInfoTypesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoTypes.push(InfoTypeDescription.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInfoTypesResponse {
    return {
      infoTypes: globalThis.Array.isArray(object?.infoTypes)
        ? object.infoTypes.map((e: any) => InfoTypeDescription.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ListInfoTypesResponse): unknown {
    const obj: any = {};
    if (message.infoTypes?.length) {
      obj.infoTypes = message.infoTypes.map((e) => InfoTypeDescription.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ListInfoTypesResponse>): ListInfoTypesResponse {
    return ListInfoTypesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInfoTypesResponse>): ListInfoTypesResponse {
    const message = createBaseListInfoTypesResponse();
    message.infoTypes = object.infoTypes?.map((e) => InfoTypeDescription.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRiskAnalysisJobConfig(): RiskAnalysisJobConfig {
  return { privacyMetric: undefined, sourceTable: undefined, actions: [] };
}

export const RiskAnalysisJobConfig: MessageFns<RiskAnalysisJobConfig> = {
  encode(message: RiskAnalysisJobConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.privacyMetric !== undefined) {
      PrivacyMetric.encode(message.privacyMetric, writer.uint32(10).fork()).join();
    }
    if (message.sourceTable !== undefined) {
      BigQueryTable.encode(message.sourceTable, writer.uint32(18).fork()).join();
    }
    for (const v of message.actions) {
      Action.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RiskAnalysisJobConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRiskAnalysisJobConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.privacyMetric = PrivacyMetric.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceTable = BigQueryTable.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.actions.push(Action.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RiskAnalysisJobConfig {
    return {
      privacyMetric: isSet(object.privacyMetric) ? PrivacyMetric.fromJSON(object.privacyMetric) : undefined,
      sourceTable: isSet(object.sourceTable) ? BigQueryTable.fromJSON(object.sourceTable) : undefined,
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => Action.fromJSON(e)) : [],
    };
  },

  toJSON(message: RiskAnalysisJobConfig): unknown {
    const obj: any = {};
    if (message.privacyMetric !== undefined) {
      obj.privacyMetric = PrivacyMetric.toJSON(message.privacyMetric);
    }
    if (message.sourceTable !== undefined) {
      obj.sourceTable = BigQueryTable.toJSON(message.sourceTable);
    }
    if (message.actions?.length) {
      obj.actions = message.actions.map((e) => Action.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<RiskAnalysisJobConfig>): RiskAnalysisJobConfig {
    return RiskAnalysisJobConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RiskAnalysisJobConfig>): RiskAnalysisJobConfig {
    const message = createBaseRiskAnalysisJobConfig();
    message.privacyMetric = (object.privacyMetric !== undefined && object.privacyMetric !== null)
      ? PrivacyMetric.fromPartial(object.privacyMetric)
      : undefined;
    message.sourceTable = (object.sourceTable !== undefined && object.sourceTable !== null)
      ? BigQueryTable.fromPartial(object.sourceTable)
      : undefined;
    message.actions = object.actions?.map((e) => Action.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQuasiId(): QuasiId {
  return { field: undefined, infoType: undefined, customTag: undefined, inferred: undefined };
}

export const QuasiId: MessageFns<QuasiId> = {
  encode(message: QuasiId, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(18).fork()).join();
    }
    if (message.customTag !== undefined) {
      writer.uint32(26).string(message.customTag);
    }
    if (message.inferred !== undefined) {
      Empty.encode(message.inferred, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QuasiId {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuasiId();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.customTag = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.inferred = Empty.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QuasiId {
    return {
      field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined,
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      customTag: isSet(object.customTag) ? globalThis.String(object.customTag) : undefined,
      inferred: isSet(object.inferred) ? Empty.fromJSON(object.inferred) : undefined,
    };
  },

  toJSON(message: QuasiId): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.customTag !== undefined) {
      obj.customTag = message.customTag;
    }
    if (message.inferred !== undefined) {
      obj.inferred = Empty.toJSON(message.inferred);
    }
    return obj;
  },

  create(base?: DeepPartial<QuasiId>): QuasiId {
    return QuasiId.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QuasiId>): QuasiId {
    const message = createBaseQuasiId();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.customTag = object.customTag ?? undefined;
    message.inferred = (object.inferred !== undefined && object.inferred !== null)
      ? Empty.fromPartial(object.inferred)
      : undefined;
    return message;
  },
};

function createBaseStatisticalTable(): StatisticalTable {
  return { table: undefined, quasiIds: [], relativeFrequency: undefined };
}

export const StatisticalTable: MessageFns<StatisticalTable> = {
  encode(message: StatisticalTable, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== undefined) {
      BigQueryTable.encode(message.table, writer.uint32(26).fork()).join();
    }
    for (const v of message.quasiIds) {
      StatisticalTable_QuasiIdentifierField.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.relativeFrequency !== undefined) {
      FieldId.encode(message.relativeFrequency, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StatisticalTable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStatisticalTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.table = BigQueryTable.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIds.push(StatisticalTable_QuasiIdentifierField.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.relativeFrequency = FieldId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StatisticalTable {
    return {
      table: isSet(object.table) ? BigQueryTable.fromJSON(object.table) : undefined,
      quasiIds: globalThis.Array.isArray(object?.quasiIds)
        ? object.quasiIds.map((e: any) => StatisticalTable_QuasiIdentifierField.fromJSON(e))
        : [],
      relativeFrequency: isSet(object.relativeFrequency) ? FieldId.fromJSON(object.relativeFrequency) : undefined,
    };
  },

  toJSON(message: StatisticalTable): unknown {
    const obj: any = {};
    if (message.table !== undefined) {
      obj.table = BigQueryTable.toJSON(message.table);
    }
    if (message.quasiIds?.length) {
      obj.quasiIds = message.quasiIds.map((e) => StatisticalTable_QuasiIdentifierField.toJSON(e));
    }
    if (message.relativeFrequency !== undefined) {
      obj.relativeFrequency = FieldId.toJSON(message.relativeFrequency);
    }
    return obj;
  },

  create(base?: DeepPartial<StatisticalTable>): StatisticalTable {
    return StatisticalTable.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StatisticalTable>): StatisticalTable {
    const message = createBaseStatisticalTable();
    message.table = (object.table !== undefined && object.table !== null)
      ? BigQueryTable.fromPartial(object.table)
      : undefined;
    message.quasiIds = object.quasiIds?.map((e) => StatisticalTable_QuasiIdentifierField.fromPartial(e)) || [];
    message.relativeFrequency = (object.relativeFrequency !== undefined && object.relativeFrequency !== null)
      ? FieldId.fromPartial(object.relativeFrequency)
      : undefined;
    return message;
  },
};

function createBaseStatisticalTable_QuasiIdentifierField(): StatisticalTable_QuasiIdentifierField {
  return { field: undefined, customTag: "" };
}

export const StatisticalTable_QuasiIdentifierField: MessageFns<StatisticalTable_QuasiIdentifierField> = {
  encode(message: StatisticalTable_QuasiIdentifierField, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    if (message.customTag !== "") {
      writer.uint32(18).string(message.customTag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StatisticalTable_QuasiIdentifierField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStatisticalTable_QuasiIdentifierField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.customTag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StatisticalTable_QuasiIdentifierField {
    return {
      field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined,
      customTag: isSet(object.customTag) ? globalThis.String(object.customTag) : "",
    };
  },

  toJSON(message: StatisticalTable_QuasiIdentifierField): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    if (message.customTag !== "") {
      obj.customTag = message.customTag;
    }
    return obj;
  },

  create(base?: DeepPartial<StatisticalTable_QuasiIdentifierField>): StatisticalTable_QuasiIdentifierField {
    return StatisticalTable_QuasiIdentifierField.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StatisticalTable_QuasiIdentifierField>): StatisticalTable_QuasiIdentifierField {
    const message = createBaseStatisticalTable_QuasiIdentifierField();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    message.customTag = object.customTag ?? "";
    return message;
  },
};

function createBasePrivacyMetric(): PrivacyMetric {
  return {
    numericalStatsConfig: undefined,
    categoricalStatsConfig: undefined,
    kAnonymityConfig: undefined,
    lDiversityConfig: undefined,
    kMapEstimationConfig: undefined,
    deltaPresenceEstimationConfig: undefined,
  };
}

export const PrivacyMetric: MessageFns<PrivacyMetric> = {
  encode(message: PrivacyMetric, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.numericalStatsConfig !== undefined) {
      PrivacyMetric_NumericalStatsConfig.encode(message.numericalStatsConfig, writer.uint32(10).fork()).join();
    }
    if (message.categoricalStatsConfig !== undefined) {
      PrivacyMetric_CategoricalStatsConfig.encode(message.categoricalStatsConfig, writer.uint32(18).fork()).join();
    }
    if (message.kAnonymityConfig !== undefined) {
      PrivacyMetric_KAnonymityConfig.encode(message.kAnonymityConfig, writer.uint32(26).fork()).join();
    }
    if (message.lDiversityConfig !== undefined) {
      PrivacyMetric_LDiversityConfig.encode(message.lDiversityConfig, writer.uint32(34).fork()).join();
    }
    if (message.kMapEstimationConfig !== undefined) {
      PrivacyMetric_KMapEstimationConfig.encode(message.kMapEstimationConfig, writer.uint32(42).fork()).join();
    }
    if (message.deltaPresenceEstimationConfig !== undefined) {
      PrivacyMetric_DeltaPresenceEstimationConfig.encode(
        message.deltaPresenceEstimationConfig,
        writer.uint32(50).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.numericalStatsConfig = PrivacyMetric_NumericalStatsConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.categoricalStatsConfig = PrivacyMetric_CategoricalStatsConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kAnonymityConfig = PrivacyMetric_KAnonymityConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lDiversityConfig = PrivacyMetric_LDiversityConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.kMapEstimationConfig = PrivacyMetric_KMapEstimationConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.deltaPresenceEstimationConfig = PrivacyMetric_DeltaPresenceEstimationConfig.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric {
    return {
      numericalStatsConfig: isSet(object.numericalStatsConfig)
        ? PrivacyMetric_NumericalStatsConfig.fromJSON(object.numericalStatsConfig)
        : undefined,
      categoricalStatsConfig: isSet(object.categoricalStatsConfig)
        ? PrivacyMetric_CategoricalStatsConfig.fromJSON(object.categoricalStatsConfig)
        : undefined,
      kAnonymityConfig: isSet(object.kAnonymityConfig)
        ? PrivacyMetric_KAnonymityConfig.fromJSON(object.kAnonymityConfig)
        : undefined,
      lDiversityConfig: isSet(object.lDiversityConfig)
        ? PrivacyMetric_LDiversityConfig.fromJSON(object.lDiversityConfig)
        : undefined,
      kMapEstimationConfig: isSet(object.kMapEstimationConfig)
        ? PrivacyMetric_KMapEstimationConfig.fromJSON(object.kMapEstimationConfig)
        : undefined,
      deltaPresenceEstimationConfig: isSet(object.deltaPresenceEstimationConfig)
        ? PrivacyMetric_DeltaPresenceEstimationConfig.fromJSON(object.deltaPresenceEstimationConfig)
        : undefined,
    };
  },

  toJSON(message: PrivacyMetric): unknown {
    const obj: any = {};
    if (message.numericalStatsConfig !== undefined) {
      obj.numericalStatsConfig = PrivacyMetric_NumericalStatsConfig.toJSON(message.numericalStatsConfig);
    }
    if (message.categoricalStatsConfig !== undefined) {
      obj.categoricalStatsConfig = PrivacyMetric_CategoricalStatsConfig.toJSON(message.categoricalStatsConfig);
    }
    if (message.kAnonymityConfig !== undefined) {
      obj.kAnonymityConfig = PrivacyMetric_KAnonymityConfig.toJSON(message.kAnonymityConfig);
    }
    if (message.lDiversityConfig !== undefined) {
      obj.lDiversityConfig = PrivacyMetric_LDiversityConfig.toJSON(message.lDiversityConfig);
    }
    if (message.kMapEstimationConfig !== undefined) {
      obj.kMapEstimationConfig = PrivacyMetric_KMapEstimationConfig.toJSON(message.kMapEstimationConfig);
    }
    if (message.deltaPresenceEstimationConfig !== undefined) {
      obj.deltaPresenceEstimationConfig = PrivacyMetric_DeltaPresenceEstimationConfig.toJSON(
        message.deltaPresenceEstimationConfig,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric>): PrivacyMetric {
    return PrivacyMetric.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivacyMetric>): PrivacyMetric {
    const message = createBasePrivacyMetric();
    message.numericalStatsConfig = (object.numericalStatsConfig !== undefined && object.numericalStatsConfig !== null)
      ? PrivacyMetric_NumericalStatsConfig.fromPartial(object.numericalStatsConfig)
      : undefined;
    message.categoricalStatsConfig =
      (object.categoricalStatsConfig !== undefined && object.categoricalStatsConfig !== null)
        ? PrivacyMetric_CategoricalStatsConfig.fromPartial(object.categoricalStatsConfig)
        : undefined;
    message.kAnonymityConfig = (object.kAnonymityConfig !== undefined && object.kAnonymityConfig !== null)
      ? PrivacyMetric_KAnonymityConfig.fromPartial(object.kAnonymityConfig)
      : undefined;
    message.lDiversityConfig = (object.lDiversityConfig !== undefined && object.lDiversityConfig !== null)
      ? PrivacyMetric_LDiversityConfig.fromPartial(object.lDiversityConfig)
      : undefined;
    message.kMapEstimationConfig = (object.kMapEstimationConfig !== undefined && object.kMapEstimationConfig !== null)
      ? PrivacyMetric_KMapEstimationConfig.fromPartial(object.kMapEstimationConfig)
      : undefined;
    message.deltaPresenceEstimationConfig =
      (object.deltaPresenceEstimationConfig !== undefined && object.deltaPresenceEstimationConfig !== null)
        ? PrivacyMetric_DeltaPresenceEstimationConfig.fromPartial(object.deltaPresenceEstimationConfig)
        : undefined;
    return message;
  },
};

function createBasePrivacyMetric_NumericalStatsConfig(): PrivacyMetric_NumericalStatsConfig {
  return { field: undefined };
}

export const PrivacyMetric_NumericalStatsConfig: MessageFns<PrivacyMetric_NumericalStatsConfig> = {
  encode(message: PrivacyMetric_NumericalStatsConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_NumericalStatsConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_NumericalStatsConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_NumericalStatsConfig {
    return { field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined };
  },

  toJSON(message: PrivacyMetric_NumericalStatsConfig): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric_NumericalStatsConfig>): PrivacyMetric_NumericalStatsConfig {
    return PrivacyMetric_NumericalStatsConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivacyMetric_NumericalStatsConfig>): PrivacyMetric_NumericalStatsConfig {
    const message = createBasePrivacyMetric_NumericalStatsConfig();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    return message;
  },
};

function createBasePrivacyMetric_CategoricalStatsConfig(): PrivacyMetric_CategoricalStatsConfig {
  return { field: undefined };
}

export const PrivacyMetric_CategoricalStatsConfig: MessageFns<PrivacyMetric_CategoricalStatsConfig> = {
  encode(message: PrivacyMetric_CategoricalStatsConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_CategoricalStatsConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_CategoricalStatsConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_CategoricalStatsConfig {
    return { field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined };
  },

  toJSON(message: PrivacyMetric_CategoricalStatsConfig): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric_CategoricalStatsConfig>): PrivacyMetric_CategoricalStatsConfig {
    return PrivacyMetric_CategoricalStatsConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivacyMetric_CategoricalStatsConfig>): PrivacyMetric_CategoricalStatsConfig {
    const message = createBasePrivacyMetric_CategoricalStatsConfig();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    return message;
  },
};

function createBasePrivacyMetric_KAnonymityConfig(): PrivacyMetric_KAnonymityConfig {
  return { quasiIds: [], entityId: undefined };
}

export const PrivacyMetric_KAnonymityConfig: MessageFns<PrivacyMetric_KAnonymityConfig> = {
  encode(message: PrivacyMetric_KAnonymityConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.quasiIds) {
      FieldId.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.entityId !== undefined) {
      EntityId.encode(message.entityId, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_KAnonymityConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_KAnonymityConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIds.push(FieldId.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entityId = EntityId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_KAnonymityConfig {
    return {
      quasiIds: globalThis.Array.isArray(object?.quasiIds) ? object.quasiIds.map((e: any) => FieldId.fromJSON(e)) : [],
      entityId: isSet(object.entityId) ? EntityId.fromJSON(object.entityId) : undefined,
    };
  },

  toJSON(message: PrivacyMetric_KAnonymityConfig): unknown {
    const obj: any = {};
    if (message.quasiIds?.length) {
      obj.quasiIds = message.quasiIds.map((e) => FieldId.toJSON(e));
    }
    if (message.entityId !== undefined) {
      obj.entityId = EntityId.toJSON(message.entityId);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric_KAnonymityConfig>): PrivacyMetric_KAnonymityConfig {
    return PrivacyMetric_KAnonymityConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivacyMetric_KAnonymityConfig>): PrivacyMetric_KAnonymityConfig {
    const message = createBasePrivacyMetric_KAnonymityConfig();
    message.quasiIds = object.quasiIds?.map((e) => FieldId.fromPartial(e)) || [];
    message.entityId = (object.entityId !== undefined && object.entityId !== null)
      ? EntityId.fromPartial(object.entityId)
      : undefined;
    return message;
  },
};

function createBasePrivacyMetric_LDiversityConfig(): PrivacyMetric_LDiversityConfig {
  return { quasiIds: [], sensitiveAttribute: undefined };
}

export const PrivacyMetric_LDiversityConfig: MessageFns<PrivacyMetric_LDiversityConfig> = {
  encode(message: PrivacyMetric_LDiversityConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.quasiIds) {
      FieldId.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.sensitiveAttribute !== undefined) {
      FieldId.encode(message.sensitiveAttribute, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_LDiversityConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_LDiversityConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIds.push(FieldId.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sensitiveAttribute = FieldId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_LDiversityConfig {
    return {
      quasiIds: globalThis.Array.isArray(object?.quasiIds) ? object.quasiIds.map((e: any) => FieldId.fromJSON(e)) : [],
      sensitiveAttribute: isSet(object.sensitiveAttribute) ? FieldId.fromJSON(object.sensitiveAttribute) : undefined,
    };
  },

  toJSON(message: PrivacyMetric_LDiversityConfig): unknown {
    const obj: any = {};
    if (message.quasiIds?.length) {
      obj.quasiIds = message.quasiIds.map((e) => FieldId.toJSON(e));
    }
    if (message.sensitiveAttribute !== undefined) {
      obj.sensitiveAttribute = FieldId.toJSON(message.sensitiveAttribute);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric_LDiversityConfig>): PrivacyMetric_LDiversityConfig {
    return PrivacyMetric_LDiversityConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivacyMetric_LDiversityConfig>): PrivacyMetric_LDiversityConfig {
    const message = createBasePrivacyMetric_LDiversityConfig();
    message.quasiIds = object.quasiIds?.map((e) => FieldId.fromPartial(e)) || [];
    message.sensitiveAttribute = (object.sensitiveAttribute !== undefined && object.sensitiveAttribute !== null)
      ? FieldId.fromPartial(object.sensitiveAttribute)
      : undefined;
    return message;
  },
};

function createBasePrivacyMetric_KMapEstimationConfig(): PrivacyMetric_KMapEstimationConfig {
  return { quasiIds: [], regionCode: "", auxiliaryTables: [] };
}

export const PrivacyMetric_KMapEstimationConfig: MessageFns<PrivacyMetric_KMapEstimationConfig> = {
  encode(message: PrivacyMetric_KMapEstimationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.quasiIds) {
      PrivacyMetric_KMapEstimationConfig_TaggedField.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.regionCode !== "") {
      writer.uint32(18).string(message.regionCode);
    }
    for (const v of message.auxiliaryTables) {
      PrivacyMetric_KMapEstimationConfig_AuxiliaryTable.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_KMapEstimationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_KMapEstimationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIds.push(PrivacyMetric_KMapEstimationConfig_TaggedField.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.regionCode = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.auxiliaryTables.push(
            PrivacyMetric_KMapEstimationConfig_AuxiliaryTable.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_KMapEstimationConfig {
    return {
      quasiIds: globalThis.Array.isArray(object?.quasiIds)
        ? object.quasiIds.map((e: any) => PrivacyMetric_KMapEstimationConfig_TaggedField.fromJSON(e))
        : [],
      regionCode: isSet(object.regionCode) ? globalThis.String(object.regionCode) : "",
      auxiliaryTables: globalThis.Array.isArray(object?.auxiliaryTables)
        ? object.auxiliaryTables.map((e: any) => PrivacyMetric_KMapEstimationConfig_AuxiliaryTable.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PrivacyMetric_KMapEstimationConfig): unknown {
    const obj: any = {};
    if (message.quasiIds?.length) {
      obj.quasiIds = message.quasiIds.map((e) => PrivacyMetric_KMapEstimationConfig_TaggedField.toJSON(e));
    }
    if (message.regionCode !== "") {
      obj.regionCode = message.regionCode;
    }
    if (message.auxiliaryTables?.length) {
      obj.auxiliaryTables = message.auxiliaryTables.map((e) =>
        PrivacyMetric_KMapEstimationConfig_AuxiliaryTable.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric_KMapEstimationConfig>): PrivacyMetric_KMapEstimationConfig {
    return PrivacyMetric_KMapEstimationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivacyMetric_KMapEstimationConfig>): PrivacyMetric_KMapEstimationConfig {
    const message = createBasePrivacyMetric_KMapEstimationConfig();
    message.quasiIds = object.quasiIds?.map((e) => PrivacyMetric_KMapEstimationConfig_TaggedField.fromPartial(e)) || [];
    message.regionCode = object.regionCode ?? "";
    message.auxiliaryTables =
      object.auxiliaryTables?.map((e) => PrivacyMetric_KMapEstimationConfig_AuxiliaryTable.fromPartial(e)) || [];
    return message;
  },
};

function createBasePrivacyMetric_KMapEstimationConfig_TaggedField(): PrivacyMetric_KMapEstimationConfig_TaggedField {
  return { field: undefined, infoType: undefined, customTag: undefined, inferred: undefined };
}

export const PrivacyMetric_KMapEstimationConfig_TaggedField: MessageFns<
  PrivacyMetric_KMapEstimationConfig_TaggedField
> = {
  encode(
    message: PrivacyMetric_KMapEstimationConfig_TaggedField,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(18).fork()).join();
    }
    if (message.customTag !== undefined) {
      writer.uint32(26).string(message.customTag);
    }
    if (message.inferred !== undefined) {
      Empty.encode(message.inferred, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_KMapEstimationConfig_TaggedField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_KMapEstimationConfig_TaggedField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.customTag = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.inferred = Empty.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_KMapEstimationConfig_TaggedField {
    return {
      field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined,
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      customTag: isSet(object.customTag) ? globalThis.String(object.customTag) : undefined,
      inferred: isSet(object.inferred) ? Empty.fromJSON(object.inferred) : undefined,
    };
  },

  toJSON(message: PrivacyMetric_KMapEstimationConfig_TaggedField): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.customTag !== undefined) {
      obj.customTag = message.customTag;
    }
    if (message.inferred !== undefined) {
      obj.inferred = Empty.toJSON(message.inferred);
    }
    return obj;
  },

  create(
    base?: DeepPartial<PrivacyMetric_KMapEstimationConfig_TaggedField>,
  ): PrivacyMetric_KMapEstimationConfig_TaggedField {
    return PrivacyMetric_KMapEstimationConfig_TaggedField.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PrivacyMetric_KMapEstimationConfig_TaggedField>,
  ): PrivacyMetric_KMapEstimationConfig_TaggedField {
    const message = createBasePrivacyMetric_KMapEstimationConfig_TaggedField();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.customTag = object.customTag ?? undefined;
    message.inferred = (object.inferred !== undefined && object.inferred !== null)
      ? Empty.fromPartial(object.inferred)
      : undefined;
    return message;
  },
};

function createBasePrivacyMetric_KMapEstimationConfig_AuxiliaryTable(): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable {
  return { table: undefined, quasiIds: [], relativeFrequency: undefined };
}

export const PrivacyMetric_KMapEstimationConfig_AuxiliaryTable: MessageFns<
  PrivacyMetric_KMapEstimationConfig_AuxiliaryTable
> = {
  encode(
    message: PrivacyMetric_KMapEstimationConfig_AuxiliaryTable,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.table !== undefined) {
      BigQueryTable.encode(message.table, writer.uint32(26).fork()).join();
    }
    for (const v of message.quasiIds) {
      PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.relativeFrequency !== undefined) {
      FieldId.encode(message.relativeFrequency, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_KMapEstimationConfig_AuxiliaryTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.table = BigQueryTable.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIds.push(
            PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField.decode(reader, reader.uint32()),
          );
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.relativeFrequency = FieldId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable {
    return {
      table: isSet(object.table) ? BigQueryTable.fromJSON(object.table) : undefined,
      quasiIds: globalThis.Array.isArray(object?.quasiIds)
        ? object.quasiIds.map((e: any) => PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField.fromJSON(e))
        : [],
      relativeFrequency: isSet(object.relativeFrequency) ? FieldId.fromJSON(object.relativeFrequency) : undefined,
    };
  },

  toJSON(message: PrivacyMetric_KMapEstimationConfig_AuxiliaryTable): unknown {
    const obj: any = {};
    if (message.table !== undefined) {
      obj.table = BigQueryTable.toJSON(message.table);
    }
    if (message.quasiIds?.length) {
      obj.quasiIds = message.quasiIds.map((e) =>
        PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField.toJSON(e)
      );
    }
    if (message.relativeFrequency !== undefined) {
      obj.relativeFrequency = FieldId.toJSON(message.relativeFrequency);
    }
    return obj;
  },

  create(
    base?: DeepPartial<PrivacyMetric_KMapEstimationConfig_AuxiliaryTable>,
  ): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable {
    return PrivacyMetric_KMapEstimationConfig_AuxiliaryTable.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PrivacyMetric_KMapEstimationConfig_AuxiliaryTable>,
  ): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable {
    const message = createBasePrivacyMetric_KMapEstimationConfig_AuxiliaryTable();
    message.table = (object.table !== undefined && object.table !== null)
      ? BigQueryTable.fromPartial(object.table)
      : undefined;
    message.quasiIds =
      object.quasiIds?.map((e) => PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField.fromPartial(e)) || [];
    message.relativeFrequency = (object.relativeFrequency !== undefined && object.relativeFrequency !== null)
      ? FieldId.fromPartial(object.relativeFrequency)
      : undefined;
    return message;
  },
};

function createBasePrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField(): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField {
  return { field: undefined, customTag: "" };
}

export const PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField: MessageFns<
  PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField
> = {
  encode(
    message: PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    if (message.customTag !== "") {
      writer.uint32(18).string(message.customTag);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.customTag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField {
    return {
      field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined,
      customTag: isSet(object.customTag) ? globalThis.String(object.customTag) : "",
    };
  },

  toJSON(message: PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    if (message.customTag !== "") {
      obj.customTag = message.customTag;
    }
    return obj;
  },

  create(
    base?: DeepPartial<PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField>,
  ): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField {
    return PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField>,
  ): PrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField {
    const message = createBasePrivacyMetric_KMapEstimationConfig_AuxiliaryTable_QuasiIdField();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    message.customTag = object.customTag ?? "";
    return message;
  },
};

function createBasePrivacyMetric_DeltaPresenceEstimationConfig(): PrivacyMetric_DeltaPresenceEstimationConfig {
  return { quasiIds: [], regionCode: "", auxiliaryTables: [] };
}

export const PrivacyMetric_DeltaPresenceEstimationConfig: MessageFns<PrivacyMetric_DeltaPresenceEstimationConfig> = {
  encode(
    message: PrivacyMetric_DeltaPresenceEstimationConfig,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.quasiIds) {
      QuasiId.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.regionCode !== "") {
      writer.uint32(18).string(message.regionCode);
    }
    for (const v of message.auxiliaryTables) {
      StatisticalTable.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivacyMetric_DeltaPresenceEstimationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivacyMetric_DeltaPresenceEstimationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIds.push(QuasiId.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.regionCode = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.auxiliaryTables.push(StatisticalTable.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivacyMetric_DeltaPresenceEstimationConfig {
    return {
      quasiIds: globalThis.Array.isArray(object?.quasiIds) ? object.quasiIds.map((e: any) => QuasiId.fromJSON(e)) : [],
      regionCode: isSet(object.regionCode) ? globalThis.String(object.regionCode) : "",
      auxiliaryTables: globalThis.Array.isArray(object?.auxiliaryTables)
        ? object.auxiliaryTables.map((e: any) => StatisticalTable.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PrivacyMetric_DeltaPresenceEstimationConfig): unknown {
    const obj: any = {};
    if (message.quasiIds?.length) {
      obj.quasiIds = message.quasiIds.map((e) => QuasiId.toJSON(e));
    }
    if (message.regionCode !== "") {
      obj.regionCode = message.regionCode;
    }
    if (message.auxiliaryTables?.length) {
      obj.auxiliaryTables = message.auxiliaryTables.map((e) => StatisticalTable.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PrivacyMetric_DeltaPresenceEstimationConfig>): PrivacyMetric_DeltaPresenceEstimationConfig {
    return PrivacyMetric_DeltaPresenceEstimationConfig.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PrivacyMetric_DeltaPresenceEstimationConfig>,
  ): PrivacyMetric_DeltaPresenceEstimationConfig {
    const message = createBasePrivacyMetric_DeltaPresenceEstimationConfig();
    message.quasiIds = object.quasiIds?.map((e) => QuasiId.fromPartial(e)) || [];
    message.regionCode = object.regionCode ?? "";
    message.auxiliaryTables = object.auxiliaryTables?.map((e) => StatisticalTable.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails(): AnalyzeDataSourceRiskDetails {
  return {
    requestedPrivacyMetric: undefined,
    requestedSourceTable: undefined,
    numericalStatsResult: undefined,
    categoricalStatsResult: undefined,
    kAnonymityResult: undefined,
    lDiversityResult: undefined,
    kMapEstimationResult: undefined,
    deltaPresenceEstimationResult: undefined,
    requestedOptions: undefined,
  };
}

export const AnalyzeDataSourceRiskDetails: MessageFns<AnalyzeDataSourceRiskDetails> = {
  encode(message: AnalyzeDataSourceRiskDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requestedPrivacyMetric !== undefined) {
      PrivacyMetric.encode(message.requestedPrivacyMetric, writer.uint32(10).fork()).join();
    }
    if (message.requestedSourceTable !== undefined) {
      BigQueryTable.encode(message.requestedSourceTable, writer.uint32(18).fork()).join();
    }
    if (message.numericalStatsResult !== undefined) {
      AnalyzeDataSourceRiskDetails_NumericalStatsResult.encode(message.numericalStatsResult, writer.uint32(26).fork())
        .join();
    }
    if (message.categoricalStatsResult !== undefined) {
      AnalyzeDataSourceRiskDetails_CategoricalStatsResult.encode(
        message.categoricalStatsResult,
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.kAnonymityResult !== undefined) {
      AnalyzeDataSourceRiskDetails_KAnonymityResult.encode(message.kAnonymityResult, writer.uint32(42).fork()).join();
    }
    if (message.lDiversityResult !== undefined) {
      AnalyzeDataSourceRiskDetails_LDiversityResult.encode(message.lDiversityResult, writer.uint32(50).fork()).join();
    }
    if (message.kMapEstimationResult !== undefined) {
      AnalyzeDataSourceRiskDetails_KMapEstimationResult.encode(message.kMapEstimationResult, writer.uint32(58).fork())
        .join();
    }
    if (message.deltaPresenceEstimationResult !== undefined) {
      AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult.encode(
        message.deltaPresenceEstimationResult,
        writer.uint32(74).fork(),
      ).join();
    }
    if (message.requestedOptions !== undefined) {
      AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions.encode(
        message.requestedOptions,
        writer.uint32(82).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.requestedPrivacyMetric = PrivacyMetric.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestedSourceTable = BigQueryTable.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.numericalStatsResult = AnalyzeDataSourceRiskDetails_NumericalStatsResult.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.categoricalStatsResult = AnalyzeDataSourceRiskDetails_CategoricalStatsResult.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.kAnonymityResult = AnalyzeDataSourceRiskDetails_KAnonymityResult.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.lDiversityResult = AnalyzeDataSourceRiskDetails_LDiversityResult.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.kMapEstimationResult = AnalyzeDataSourceRiskDetails_KMapEstimationResult.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.deltaPresenceEstimationResult = AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.requestedOptions = AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails {
    return {
      requestedPrivacyMetric: isSet(object.requestedPrivacyMetric)
        ? PrivacyMetric.fromJSON(object.requestedPrivacyMetric)
        : undefined,
      requestedSourceTable: isSet(object.requestedSourceTable)
        ? BigQueryTable.fromJSON(object.requestedSourceTable)
        : undefined,
      numericalStatsResult: isSet(object.numericalStatsResult)
        ? AnalyzeDataSourceRiskDetails_NumericalStatsResult.fromJSON(object.numericalStatsResult)
        : undefined,
      categoricalStatsResult: isSet(object.categoricalStatsResult)
        ? AnalyzeDataSourceRiskDetails_CategoricalStatsResult.fromJSON(object.categoricalStatsResult)
        : undefined,
      kAnonymityResult: isSet(object.kAnonymityResult)
        ? AnalyzeDataSourceRiskDetails_KAnonymityResult.fromJSON(object.kAnonymityResult)
        : undefined,
      lDiversityResult: isSet(object.lDiversityResult)
        ? AnalyzeDataSourceRiskDetails_LDiversityResult.fromJSON(object.lDiversityResult)
        : undefined,
      kMapEstimationResult: isSet(object.kMapEstimationResult)
        ? AnalyzeDataSourceRiskDetails_KMapEstimationResult.fromJSON(object.kMapEstimationResult)
        : undefined,
      deltaPresenceEstimationResult: isSet(object.deltaPresenceEstimationResult)
        ? AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult.fromJSON(object.deltaPresenceEstimationResult)
        : undefined,
      requestedOptions: isSet(object.requestedOptions)
        ? AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions.fromJSON(object.requestedOptions)
        : undefined,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails): unknown {
    const obj: any = {};
    if (message.requestedPrivacyMetric !== undefined) {
      obj.requestedPrivacyMetric = PrivacyMetric.toJSON(message.requestedPrivacyMetric);
    }
    if (message.requestedSourceTable !== undefined) {
      obj.requestedSourceTable = BigQueryTable.toJSON(message.requestedSourceTable);
    }
    if (message.numericalStatsResult !== undefined) {
      obj.numericalStatsResult = AnalyzeDataSourceRiskDetails_NumericalStatsResult.toJSON(message.numericalStatsResult);
    }
    if (message.categoricalStatsResult !== undefined) {
      obj.categoricalStatsResult = AnalyzeDataSourceRiskDetails_CategoricalStatsResult.toJSON(
        message.categoricalStatsResult,
      );
    }
    if (message.kAnonymityResult !== undefined) {
      obj.kAnonymityResult = AnalyzeDataSourceRiskDetails_KAnonymityResult.toJSON(message.kAnonymityResult);
    }
    if (message.lDiversityResult !== undefined) {
      obj.lDiversityResult = AnalyzeDataSourceRiskDetails_LDiversityResult.toJSON(message.lDiversityResult);
    }
    if (message.kMapEstimationResult !== undefined) {
      obj.kMapEstimationResult = AnalyzeDataSourceRiskDetails_KMapEstimationResult.toJSON(message.kMapEstimationResult);
    }
    if (message.deltaPresenceEstimationResult !== undefined) {
      obj.deltaPresenceEstimationResult = AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult.toJSON(
        message.deltaPresenceEstimationResult,
      );
    }
    if (message.requestedOptions !== undefined) {
      obj.requestedOptions = AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions.toJSON(message.requestedOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeDataSourceRiskDetails>): AnalyzeDataSourceRiskDetails {
    return AnalyzeDataSourceRiskDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeDataSourceRiskDetails>): AnalyzeDataSourceRiskDetails {
    const message = createBaseAnalyzeDataSourceRiskDetails();
    message.requestedPrivacyMetric =
      (object.requestedPrivacyMetric !== undefined && object.requestedPrivacyMetric !== null)
        ? PrivacyMetric.fromPartial(object.requestedPrivacyMetric)
        : undefined;
    message.requestedSourceTable = (object.requestedSourceTable !== undefined && object.requestedSourceTable !== null)
      ? BigQueryTable.fromPartial(object.requestedSourceTable)
      : undefined;
    message.numericalStatsResult = (object.numericalStatsResult !== undefined && object.numericalStatsResult !== null)
      ? AnalyzeDataSourceRiskDetails_NumericalStatsResult.fromPartial(object.numericalStatsResult)
      : undefined;
    message.categoricalStatsResult =
      (object.categoricalStatsResult !== undefined && object.categoricalStatsResult !== null)
        ? AnalyzeDataSourceRiskDetails_CategoricalStatsResult.fromPartial(object.categoricalStatsResult)
        : undefined;
    message.kAnonymityResult = (object.kAnonymityResult !== undefined && object.kAnonymityResult !== null)
      ? AnalyzeDataSourceRiskDetails_KAnonymityResult.fromPartial(object.kAnonymityResult)
      : undefined;
    message.lDiversityResult = (object.lDiversityResult !== undefined && object.lDiversityResult !== null)
      ? AnalyzeDataSourceRiskDetails_LDiversityResult.fromPartial(object.lDiversityResult)
      : undefined;
    message.kMapEstimationResult = (object.kMapEstimationResult !== undefined && object.kMapEstimationResult !== null)
      ? AnalyzeDataSourceRiskDetails_KMapEstimationResult.fromPartial(object.kMapEstimationResult)
      : undefined;
    message.deltaPresenceEstimationResult =
      (object.deltaPresenceEstimationResult !== undefined && object.deltaPresenceEstimationResult !== null)
        ? AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult.fromPartial(object.deltaPresenceEstimationResult)
        : undefined;
    message.requestedOptions = (object.requestedOptions !== undefined && object.requestedOptions !== null)
      ? AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions.fromPartial(object.requestedOptions)
      : undefined;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_NumericalStatsResult(): AnalyzeDataSourceRiskDetails_NumericalStatsResult {
  return { minValue: undefined, maxValue: undefined, quantileValues: [] };
}

export const AnalyzeDataSourceRiskDetails_NumericalStatsResult: MessageFns<
  AnalyzeDataSourceRiskDetails_NumericalStatsResult
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_NumericalStatsResult,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.minValue !== undefined) {
      Value.encode(message.minValue, writer.uint32(10).fork()).join();
    }
    if (message.maxValue !== undefined) {
      Value.encode(message.maxValue, writer.uint32(18).fork()).join();
    }
    for (const v of message.quantileValues) {
      Value.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails_NumericalStatsResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_NumericalStatsResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.minValue = Value.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.maxValue = Value.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.quantileValues.push(Value.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_NumericalStatsResult {
    return {
      minValue: isSet(object.minValue) ? Value.fromJSON(object.minValue) : undefined,
      maxValue: isSet(object.maxValue) ? Value.fromJSON(object.maxValue) : undefined,
      quantileValues: globalThis.Array.isArray(object?.quantileValues)
        ? object.quantileValues.map((e: any) => Value.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_NumericalStatsResult): unknown {
    const obj: any = {};
    if (message.minValue !== undefined) {
      obj.minValue = Value.toJSON(message.minValue);
    }
    if (message.maxValue !== undefined) {
      obj.maxValue = Value.toJSON(message.maxValue);
    }
    if (message.quantileValues?.length) {
      obj.quantileValues = message.quantileValues.map((e) => Value.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_NumericalStatsResult>,
  ): AnalyzeDataSourceRiskDetails_NumericalStatsResult {
    return AnalyzeDataSourceRiskDetails_NumericalStatsResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_NumericalStatsResult>,
  ): AnalyzeDataSourceRiskDetails_NumericalStatsResult {
    const message = createBaseAnalyzeDataSourceRiskDetails_NumericalStatsResult();
    message.minValue = (object.minValue !== undefined && object.minValue !== null)
      ? Value.fromPartial(object.minValue)
      : undefined;
    message.maxValue = (object.maxValue !== undefined && object.maxValue !== null)
      ? Value.fromPartial(object.maxValue)
      : undefined;
    message.quantileValues = object.quantileValues?.map((e) => Value.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_CategoricalStatsResult(): AnalyzeDataSourceRiskDetails_CategoricalStatsResult {
  return { valueFrequencyHistogramBuckets: [] };
}

export const AnalyzeDataSourceRiskDetails_CategoricalStatsResult: MessageFns<
  AnalyzeDataSourceRiskDetails_CategoricalStatsResult
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_CategoricalStatsResult,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.valueFrequencyHistogramBuckets) {
      AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket.encode(
        v!,
        writer.uint32(42).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails_CategoricalStatsResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_CategoricalStatsResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.valueFrequencyHistogramBuckets.push(
            AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket.decode(
              reader,
              reader.uint32(),
            ),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_CategoricalStatsResult {
    return {
      valueFrequencyHistogramBuckets: globalThis.Array.isArray(object?.valueFrequencyHistogramBuckets)
        ? object.valueFrequencyHistogramBuckets.map((e: any) =>
          AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_CategoricalStatsResult): unknown {
    const obj: any = {};
    if (message.valueFrequencyHistogramBuckets?.length) {
      obj.valueFrequencyHistogramBuckets = message.valueFrequencyHistogramBuckets.map((e) =>
        AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket.toJSON(e)
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_CategoricalStatsResult>,
  ): AnalyzeDataSourceRiskDetails_CategoricalStatsResult {
    return AnalyzeDataSourceRiskDetails_CategoricalStatsResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_CategoricalStatsResult>,
  ): AnalyzeDataSourceRiskDetails_CategoricalStatsResult {
    const message = createBaseAnalyzeDataSourceRiskDetails_CategoricalStatsResult();
    message.valueFrequencyHistogramBuckets =
      object.valueFrequencyHistogramBuckets?.map((e) =>
        AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket(): AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket {
  return {
    valueFrequencyLowerBound: Long.ZERO,
    valueFrequencyUpperBound: Long.ZERO,
    bucketSize: Long.ZERO,
    bucketValues: [],
    bucketValueCount: Long.ZERO,
  };
}

export const AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket: MessageFns<
  AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (!message.valueFrequencyLowerBound.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.valueFrequencyLowerBound.toString());
    }
    if (!message.valueFrequencyUpperBound.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.valueFrequencyUpperBound.toString());
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.bucketSize.toString());
    }
    for (const v of message.bucketValues) {
      ValueFrequency.encode(v!, writer.uint32(34).fork()).join();
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.bucketValueCount.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.valueFrequencyLowerBound = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.valueFrequencyUpperBound = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.bucketSize = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.bucketValues.push(ValueFrequency.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.bucketValueCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket {
    return {
      valueFrequencyLowerBound: isSet(object.valueFrequencyLowerBound)
        ? Long.fromValue(object.valueFrequencyLowerBound)
        : Long.ZERO,
      valueFrequencyUpperBound: isSet(object.valueFrequencyUpperBound)
        ? Long.fromValue(object.valueFrequencyUpperBound)
        : Long.ZERO,
      bucketSize: isSet(object.bucketSize) ? Long.fromValue(object.bucketSize) : Long.ZERO,
      bucketValues: globalThis.Array.isArray(object?.bucketValues)
        ? object.bucketValues.map((e: any) => ValueFrequency.fromJSON(e))
        : [],
      bucketValueCount: isSet(object.bucketValueCount) ? Long.fromValue(object.bucketValueCount) : Long.ZERO,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket): unknown {
    const obj: any = {};
    if (!message.valueFrequencyLowerBound.equals(Long.ZERO)) {
      obj.valueFrequencyLowerBound = (message.valueFrequencyLowerBound || Long.ZERO).toString();
    }
    if (!message.valueFrequencyUpperBound.equals(Long.ZERO)) {
      obj.valueFrequencyUpperBound = (message.valueFrequencyUpperBound || Long.ZERO).toString();
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      obj.bucketSize = (message.bucketSize || Long.ZERO).toString();
    }
    if (message.bucketValues?.length) {
      obj.bucketValues = message.bucketValues.map((e) => ValueFrequency.toJSON(e));
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      obj.bucketValueCount = (message.bucketValueCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket {
    return AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket {
    const message = createBaseAnalyzeDataSourceRiskDetails_CategoricalStatsResult_CategoricalStatsHistogramBucket();
    message.valueFrequencyLowerBound =
      (object.valueFrequencyLowerBound !== undefined && object.valueFrequencyLowerBound !== null)
        ? Long.fromValue(object.valueFrequencyLowerBound)
        : Long.ZERO;
    message.valueFrequencyUpperBound =
      (object.valueFrequencyUpperBound !== undefined && object.valueFrequencyUpperBound !== null)
        ? Long.fromValue(object.valueFrequencyUpperBound)
        : Long.ZERO;
    message.bucketSize = (object.bucketSize !== undefined && object.bucketSize !== null)
      ? Long.fromValue(object.bucketSize)
      : Long.ZERO;
    message.bucketValues = object.bucketValues?.map((e) => ValueFrequency.fromPartial(e)) || [];
    message.bucketValueCount = (object.bucketValueCount !== undefined && object.bucketValueCount !== null)
      ? Long.fromValue(object.bucketValueCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult(): AnalyzeDataSourceRiskDetails_KAnonymityResult {
  return { equivalenceClassHistogramBuckets: [] };
}

export const AnalyzeDataSourceRiskDetails_KAnonymityResult: MessageFns<AnalyzeDataSourceRiskDetails_KAnonymityResult> =
  {
    encode(
      message: AnalyzeDataSourceRiskDetails_KAnonymityResult,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.equivalenceClassHistogramBuckets) {
        AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket.encode(v!, writer.uint32(42).fork())
          .join();
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails_KAnonymityResult {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 5:
            if (tag !== 42) {
              break;
            }

            message.equivalenceClassHistogramBuckets.push(
              AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket.decode(reader, reader.uint32()),
            );
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): AnalyzeDataSourceRiskDetails_KAnonymityResult {
      return {
        equivalenceClassHistogramBuckets: globalThis.Array.isArray(object?.equivalenceClassHistogramBuckets)
          ? object.equivalenceClassHistogramBuckets.map((e: any) =>
            AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket.fromJSON(e)
          )
          : [],
      };
    },

    toJSON(message: AnalyzeDataSourceRiskDetails_KAnonymityResult): unknown {
      const obj: any = {};
      if (message.equivalenceClassHistogramBuckets?.length) {
        obj.equivalenceClassHistogramBuckets = message.equivalenceClassHistogramBuckets.map((e) =>
          AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket.toJSON(e)
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<AnalyzeDataSourceRiskDetails_KAnonymityResult>,
    ): AnalyzeDataSourceRiskDetails_KAnonymityResult {
      return AnalyzeDataSourceRiskDetails_KAnonymityResult.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<AnalyzeDataSourceRiskDetails_KAnonymityResult>,
    ): AnalyzeDataSourceRiskDetails_KAnonymityResult {
      const message = createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult();
      message.equivalenceClassHistogramBuckets =
        object.equivalenceClassHistogramBuckets?.map((e) =>
          AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket.fromPartial(e)
        ) || [];
      return message;
    },
  };

function createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass(): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass {
  return { quasiIdsValues: [], equivalenceClassSize: Long.ZERO };
}

export const AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass: MessageFns<
  AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.quasiIdsValues) {
      Value.encode(v!, writer.uint32(10).fork()).join();
    }
    if (!message.equivalenceClassSize.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.equivalenceClassSize.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIdsValues.push(Value.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.equivalenceClassSize = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass {
    return {
      quasiIdsValues: globalThis.Array.isArray(object?.quasiIdsValues)
        ? object.quasiIdsValues.map((e: any) => Value.fromJSON(e))
        : [],
      equivalenceClassSize: isSet(object.equivalenceClassSize)
        ? Long.fromValue(object.equivalenceClassSize)
        : Long.ZERO,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass): unknown {
    const obj: any = {};
    if (message.quasiIdsValues?.length) {
      obj.quasiIdsValues = message.quasiIdsValues.map((e) => Value.toJSON(e));
    }
    if (!message.equivalenceClassSize.equals(Long.ZERO)) {
      obj.equivalenceClassSize = (message.equivalenceClassSize || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass>,
  ): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass {
    return AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass>,
  ): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass {
    const message = createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass();
    message.quasiIdsValues = object.quasiIdsValues?.map((e) => Value.fromPartial(e)) || [];
    message.equivalenceClassSize = (object.equivalenceClassSize !== undefined && object.equivalenceClassSize !== null)
      ? Long.fromValue(object.equivalenceClassSize)
      : Long.ZERO;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket(): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket {
  return {
    equivalenceClassSizeLowerBound: Long.ZERO,
    equivalenceClassSizeUpperBound: Long.ZERO,
    bucketSize: Long.ZERO,
    bucketValues: [],
    bucketValueCount: Long.ZERO,
  };
}

export const AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket: MessageFns<
  AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (!message.equivalenceClassSizeLowerBound.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.equivalenceClassSizeLowerBound.toString());
    }
    if (!message.equivalenceClassSizeUpperBound.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.equivalenceClassSizeUpperBound.toString());
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.bucketSize.toString());
    }
    for (const v of message.bucketValues) {
      AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass.encode(v!, writer.uint32(34).fork())
        .join();
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.bucketValueCount.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.equivalenceClassSizeLowerBound = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.equivalenceClassSizeUpperBound = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.bucketSize = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.bucketValues.push(
            AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass.decode(reader, reader.uint32()),
          );
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.bucketValueCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket {
    return {
      equivalenceClassSizeLowerBound: isSet(object.equivalenceClassSizeLowerBound)
        ? Long.fromValue(object.equivalenceClassSizeLowerBound)
        : Long.ZERO,
      equivalenceClassSizeUpperBound: isSet(object.equivalenceClassSizeUpperBound)
        ? Long.fromValue(object.equivalenceClassSizeUpperBound)
        : Long.ZERO,
      bucketSize: isSet(object.bucketSize) ? Long.fromValue(object.bucketSize) : Long.ZERO,
      bucketValues: globalThis.Array.isArray(object?.bucketValues)
        ? object.bucketValues.map((e: any) =>
          AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass.fromJSON(e)
        )
        : [],
      bucketValueCount: isSet(object.bucketValueCount) ? Long.fromValue(object.bucketValueCount) : Long.ZERO,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket): unknown {
    const obj: any = {};
    if (!message.equivalenceClassSizeLowerBound.equals(Long.ZERO)) {
      obj.equivalenceClassSizeLowerBound = (message.equivalenceClassSizeLowerBound || Long.ZERO).toString();
    }
    if (!message.equivalenceClassSizeUpperBound.equals(Long.ZERO)) {
      obj.equivalenceClassSizeUpperBound = (message.equivalenceClassSizeUpperBound || Long.ZERO).toString();
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      obj.bucketSize = (message.bucketSize || Long.ZERO).toString();
    }
    if (message.bucketValues?.length) {
      obj.bucketValues = message.bucketValues.map((e) =>
        AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass.toJSON(e)
      );
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      obj.bucketValueCount = (message.bucketValueCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket {
    return AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket {
    const message = createBaseAnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityHistogramBucket();
    message.equivalenceClassSizeLowerBound =
      (object.equivalenceClassSizeLowerBound !== undefined && object.equivalenceClassSizeLowerBound !== null)
        ? Long.fromValue(object.equivalenceClassSizeLowerBound)
        : Long.ZERO;
    message.equivalenceClassSizeUpperBound =
      (object.equivalenceClassSizeUpperBound !== undefined && object.equivalenceClassSizeUpperBound !== null)
        ? Long.fromValue(object.equivalenceClassSizeUpperBound)
        : Long.ZERO;
    message.bucketSize = (object.bucketSize !== undefined && object.bucketSize !== null)
      ? Long.fromValue(object.bucketSize)
      : Long.ZERO;
    message.bucketValues =
      object.bucketValues?.map((e) =>
        AnalyzeDataSourceRiskDetails_KAnonymityResult_KAnonymityEquivalenceClass.fromPartial(e)
      ) || [];
    message.bucketValueCount = (object.bucketValueCount !== undefined && object.bucketValueCount !== null)
      ? Long.fromValue(object.bucketValueCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_LDiversityResult(): AnalyzeDataSourceRiskDetails_LDiversityResult {
  return { sensitiveValueFrequencyHistogramBuckets: [] };
}

export const AnalyzeDataSourceRiskDetails_LDiversityResult: MessageFns<AnalyzeDataSourceRiskDetails_LDiversityResult> =
  {
    encode(
      message: AnalyzeDataSourceRiskDetails_LDiversityResult,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.sensitiveValueFrequencyHistogramBuckets) {
        AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket.encode(v!, writer.uint32(42).fork())
          .join();
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails_LDiversityResult {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseAnalyzeDataSourceRiskDetails_LDiversityResult();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 5:
            if (tag !== 42) {
              break;
            }

            message.sensitiveValueFrequencyHistogramBuckets.push(
              AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket.decode(reader, reader.uint32()),
            );
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): AnalyzeDataSourceRiskDetails_LDiversityResult {
      return {
        sensitiveValueFrequencyHistogramBuckets:
          globalThis.Array.isArray(object?.sensitiveValueFrequencyHistogramBuckets)
            ? object.sensitiveValueFrequencyHistogramBuckets.map((e: any) =>
              AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket.fromJSON(e)
            )
            : [],
      };
    },

    toJSON(message: AnalyzeDataSourceRiskDetails_LDiversityResult): unknown {
      const obj: any = {};
      if (message.sensitiveValueFrequencyHistogramBuckets?.length) {
        obj.sensitiveValueFrequencyHistogramBuckets = message.sensitiveValueFrequencyHistogramBuckets.map((e) =>
          AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket.toJSON(e)
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<AnalyzeDataSourceRiskDetails_LDiversityResult>,
    ): AnalyzeDataSourceRiskDetails_LDiversityResult {
      return AnalyzeDataSourceRiskDetails_LDiversityResult.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<AnalyzeDataSourceRiskDetails_LDiversityResult>,
    ): AnalyzeDataSourceRiskDetails_LDiversityResult {
      const message = createBaseAnalyzeDataSourceRiskDetails_LDiversityResult();
      message.sensitiveValueFrequencyHistogramBuckets =
        object.sensitiveValueFrequencyHistogramBuckets?.map((e) =>
          AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket.fromPartial(e)
        ) || [];
      return message;
    },
  };

function createBaseAnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass(): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass {
  return {
    quasiIdsValues: [],
    equivalenceClassSize: Long.ZERO,
    numDistinctSensitiveValues: Long.ZERO,
    topSensitiveValues: [],
  };
}

export const AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass: MessageFns<
  AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.quasiIdsValues) {
      Value.encode(v!, writer.uint32(10).fork()).join();
    }
    if (!message.equivalenceClassSize.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.equivalenceClassSize.toString());
    }
    if (!message.numDistinctSensitiveValues.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.numDistinctSensitiveValues.toString());
    }
    for (const v of message.topSensitiveValues) {
      ValueFrequency.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIdsValues.push(Value.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.equivalenceClassSize = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.numDistinctSensitiveValues = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.topSensitiveValues.push(ValueFrequency.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass {
    return {
      quasiIdsValues: globalThis.Array.isArray(object?.quasiIdsValues)
        ? object.quasiIdsValues.map((e: any) => Value.fromJSON(e))
        : [],
      equivalenceClassSize: isSet(object.equivalenceClassSize)
        ? Long.fromValue(object.equivalenceClassSize)
        : Long.ZERO,
      numDistinctSensitiveValues: isSet(object.numDistinctSensitiveValues)
        ? Long.fromValue(object.numDistinctSensitiveValues)
        : Long.ZERO,
      topSensitiveValues: globalThis.Array.isArray(object?.topSensitiveValues)
        ? object.topSensitiveValues.map((e: any) => ValueFrequency.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass): unknown {
    const obj: any = {};
    if (message.quasiIdsValues?.length) {
      obj.quasiIdsValues = message.quasiIdsValues.map((e) => Value.toJSON(e));
    }
    if (!message.equivalenceClassSize.equals(Long.ZERO)) {
      obj.equivalenceClassSize = (message.equivalenceClassSize || Long.ZERO).toString();
    }
    if (!message.numDistinctSensitiveValues.equals(Long.ZERO)) {
      obj.numDistinctSensitiveValues = (message.numDistinctSensitiveValues || Long.ZERO).toString();
    }
    if (message.topSensitiveValues?.length) {
      obj.topSensitiveValues = message.topSensitiveValues.map((e) => ValueFrequency.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass>,
  ): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass {
    return AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass>,
  ): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass {
    const message = createBaseAnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass();
    message.quasiIdsValues = object.quasiIdsValues?.map((e) => Value.fromPartial(e)) || [];
    message.equivalenceClassSize = (object.equivalenceClassSize !== undefined && object.equivalenceClassSize !== null)
      ? Long.fromValue(object.equivalenceClassSize)
      : Long.ZERO;
    message.numDistinctSensitiveValues =
      (object.numDistinctSensitiveValues !== undefined && object.numDistinctSensitiveValues !== null)
        ? Long.fromValue(object.numDistinctSensitiveValues)
        : Long.ZERO;
    message.topSensitiveValues = object.topSensitiveValues?.map((e) => ValueFrequency.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket(): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket {
  return {
    sensitiveValueFrequencyLowerBound: Long.ZERO,
    sensitiveValueFrequencyUpperBound: Long.ZERO,
    bucketSize: Long.ZERO,
    bucketValues: [],
    bucketValueCount: Long.ZERO,
  };
}

export const AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket: MessageFns<
  AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (!message.sensitiveValueFrequencyLowerBound.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.sensitiveValueFrequencyLowerBound.toString());
    }
    if (!message.sensitiveValueFrequencyUpperBound.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.sensitiveValueFrequencyUpperBound.toString());
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.bucketSize.toString());
    }
    for (const v of message.bucketValues) {
      AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass.encode(v!, writer.uint32(34).fork())
        .join();
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.bucketValueCount.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sensitiveValueFrequencyLowerBound = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sensitiveValueFrequencyUpperBound = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.bucketSize = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.bucketValues.push(
            AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass.decode(reader, reader.uint32()),
          );
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.bucketValueCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket {
    return {
      sensitiveValueFrequencyLowerBound: isSet(object.sensitiveValueFrequencyLowerBound)
        ? Long.fromValue(object.sensitiveValueFrequencyLowerBound)
        : Long.ZERO,
      sensitiveValueFrequencyUpperBound: isSet(object.sensitiveValueFrequencyUpperBound)
        ? Long.fromValue(object.sensitiveValueFrequencyUpperBound)
        : Long.ZERO,
      bucketSize: isSet(object.bucketSize) ? Long.fromValue(object.bucketSize) : Long.ZERO,
      bucketValues: globalThis.Array.isArray(object?.bucketValues)
        ? object.bucketValues.map((e: any) =>
          AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass.fromJSON(e)
        )
        : [],
      bucketValueCount: isSet(object.bucketValueCount) ? Long.fromValue(object.bucketValueCount) : Long.ZERO,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket): unknown {
    const obj: any = {};
    if (!message.sensitiveValueFrequencyLowerBound.equals(Long.ZERO)) {
      obj.sensitiveValueFrequencyLowerBound = (message.sensitiveValueFrequencyLowerBound || Long.ZERO).toString();
    }
    if (!message.sensitiveValueFrequencyUpperBound.equals(Long.ZERO)) {
      obj.sensitiveValueFrequencyUpperBound = (message.sensitiveValueFrequencyUpperBound || Long.ZERO).toString();
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      obj.bucketSize = (message.bucketSize || Long.ZERO).toString();
    }
    if (message.bucketValues?.length) {
      obj.bucketValues = message.bucketValues.map((e) =>
        AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass.toJSON(e)
      );
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      obj.bucketValueCount = (message.bucketValueCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket {
    return AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket {
    const message = createBaseAnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityHistogramBucket();
    message.sensitiveValueFrequencyLowerBound =
      (object.sensitiveValueFrequencyLowerBound !== undefined && object.sensitiveValueFrequencyLowerBound !== null)
        ? Long.fromValue(object.sensitiveValueFrequencyLowerBound)
        : Long.ZERO;
    message.sensitiveValueFrequencyUpperBound =
      (object.sensitiveValueFrequencyUpperBound !== undefined && object.sensitiveValueFrequencyUpperBound !== null)
        ? Long.fromValue(object.sensitiveValueFrequencyUpperBound)
        : Long.ZERO;
    message.bucketSize = (object.bucketSize !== undefined && object.bucketSize !== null)
      ? Long.fromValue(object.bucketSize)
      : Long.ZERO;
    message.bucketValues =
      object.bucketValues?.map((e) =>
        AnalyzeDataSourceRiskDetails_LDiversityResult_LDiversityEquivalenceClass.fromPartial(e)
      ) || [];
    message.bucketValueCount = (object.bucketValueCount !== undefined && object.bucketValueCount !== null)
      ? Long.fromValue(object.bucketValueCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult(): AnalyzeDataSourceRiskDetails_KMapEstimationResult {
  return { kMapEstimationHistogram: [] };
}

export const AnalyzeDataSourceRiskDetails_KMapEstimationResult: MessageFns<
  AnalyzeDataSourceRiskDetails_KMapEstimationResult
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_KMapEstimationResult,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.kMapEstimationHistogram) {
      AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket.encode(
        v!,
        writer.uint32(10).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails_KMapEstimationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kMapEstimationHistogram.push(
            AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket.decode(
              reader,
              reader.uint32(),
            ),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_KMapEstimationResult {
    return {
      kMapEstimationHistogram: globalThis.Array.isArray(object?.kMapEstimationHistogram)
        ? object.kMapEstimationHistogram.map((e: any) =>
          AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_KMapEstimationResult): unknown {
    const obj: any = {};
    if (message.kMapEstimationHistogram?.length) {
      obj.kMapEstimationHistogram = message.kMapEstimationHistogram.map((e) =>
        AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket.toJSON(e)
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_KMapEstimationResult>,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult {
    return AnalyzeDataSourceRiskDetails_KMapEstimationResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_KMapEstimationResult>,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult {
    const message = createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult();
    message.kMapEstimationHistogram =
      object.kMapEstimationHistogram?.map((e) =>
        AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues(): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues {
  return { quasiIdsValues: [], estimatedAnonymity: Long.ZERO };
}

export const AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues: MessageFns<
  AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.quasiIdsValues) {
      Value.encode(v!, writer.uint32(10).fork()).join();
    }
    if (!message.estimatedAnonymity.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.estimatedAnonymity.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.quasiIdsValues.push(Value.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.estimatedAnonymity = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues {
    return {
      quasiIdsValues: globalThis.Array.isArray(object?.quasiIdsValues)
        ? object.quasiIdsValues.map((e: any) => Value.fromJSON(e))
        : [],
      estimatedAnonymity: isSet(object.estimatedAnonymity) ? Long.fromValue(object.estimatedAnonymity) : Long.ZERO,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues): unknown {
    const obj: any = {};
    if (message.quasiIdsValues?.length) {
      obj.quasiIdsValues = message.quasiIdsValues.map((e) => Value.toJSON(e));
    }
    if (!message.estimatedAnonymity.equals(Long.ZERO)) {
      obj.estimatedAnonymity = (message.estimatedAnonymity || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues>,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues {
    return AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues>,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues {
    const message = createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues();
    message.quasiIdsValues = object.quasiIdsValues?.map((e) => Value.fromPartial(e)) || [];
    message.estimatedAnonymity = (object.estimatedAnonymity !== undefined && object.estimatedAnonymity !== null)
      ? Long.fromValue(object.estimatedAnonymity)
      : Long.ZERO;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket(): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket {
  return {
    minAnonymity: Long.ZERO,
    maxAnonymity: Long.ZERO,
    bucketSize: Long.ZERO,
    bucketValues: [],
    bucketValueCount: Long.ZERO,
  };
}

export const AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket: MessageFns<
  AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (!message.minAnonymity.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.minAnonymity.toString());
    }
    if (!message.maxAnonymity.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.maxAnonymity.toString());
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.bucketSize.toString());
    }
    for (const v of message.bucketValues) {
      AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues.encode(v!, writer.uint32(50).fork())
        .join();
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.bucketValueCount.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.minAnonymity = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxAnonymity = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.bucketSize = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.bucketValues.push(
            AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues.decode(
              reader,
              reader.uint32(),
            ),
          );
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.bucketValueCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket {
    return {
      minAnonymity: isSet(object.minAnonymity) ? Long.fromValue(object.minAnonymity) : Long.ZERO,
      maxAnonymity: isSet(object.maxAnonymity) ? Long.fromValue(object.maxAnonymity) : Long.ZERO,
      bucketSize: isSet(object.bucketSize) ? Long.fromValue(object.bucketSize) : Long.ZERO,
      bucketValues: globalThis.Array.isArray(object?.bucketValues)
        ? object.bucketValues.map((e: any) =>
          AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues.fromJSON(e)
        )
        : [],
      bucketValueCount: isSet(object.bucketValueCount) ? Long.fromValue(object.bucketValueCount) : Long.ZERO,
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket): unknown {
    const obj: any = {};
    if (!message.minAnonymity.equals(Long.ZERO)) {
      obj.minAnonymity = (message.minAnonymity || Long.ZERO).toString();
    }
    if (!message.maxAnonymity.equals(Long.ZERO)) {
      obj.maxAnonymity = (message.maxAnonymity || Long.ZERO).toString();
    }
    if (!message.bucketSize.equals(Long.ZERO)) {
      obj.bucketSize = (message.bucketSize || Long.ZERO).toString();
    }
    if (message.bucketValues?.length) {
      obj.bucketValues = message.bucketValues.map((e) =>
        AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues.toJSON(e)
      );
    }
    if (!message.bucketValueCount.equals(Long.ZERO)) {
      obj.bucketValueCount = (message.bucketValueCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket {
    return AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket>,
  ): AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket {
    const message = createBaseAnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationHistogramBucket();
    message.minAnonymity = (object.minAnonymity !== undefined && object.minAnonymity !== null)
      ? Long.fromValue(object.minAnonymity)
      : Long.ZERO;
    message.maxAnonymity = (object.maxAnonymity !== undefined && object.maxAnonymity !== null)
      ? Long.fromValue(object.maxAnonymity)
      : Long.ZERO;
    message.bucketSize = (object.bucketSize !== undefined && object.bucketSize !== null)
      ? Long.fromValue(object.bucketSize)
      : Long.ZERO;
    message.bucketValues =
      object.bucketValues?.map((e) =>
        AnalyzeDataSourceRiskDetails_KMapEstimationResult_KMapEstimationQuasiIdValues.fromPartial(e)
      ) || [];
    message.bucketValueCount = (object.bucketValueCount !== undefined && object.bucketValueCount !== null)
      ? Long.fromValue(object.bucketValueCount)
      : Long.ZERO;
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult(): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult {
  return { deltaPresenceEstimationHistogram: [] };
}

export const AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult: MessageFns<
  AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.deltaPresenceEstimationHistogram) {
      AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket.encode(
        v!,
        writer.uint32(10).fork(),
      ).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.deltaPresenceEstimationHistogram.push(
            AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket.decode(
              reader,
              reader.uint32(),
            ),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult {
    return {
      deltaPresenceEstimationHistogram: globalThis.Array.isArray(object?.deltaPresenceEstimationHistogram)
        ? object.deltaPresenceEstimationHistogram.map((e: any) =>
          AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult): unknown {
    const obj: any = {};
    if (message.deltaPresenceEstimationHistogram?.length) {
      obj.deltaPresenceEstimationHistogram = message.deltaPresenceEstimationHistogram.map((e) =>
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket.toJSON(e)
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult>,
  ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult {
    return AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult>,
  ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult {
    const message = createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult();
    message.deltaPresenceEstimationHistogram =
      object.deltaPresenceEstimationHistogram?.map((e) =>
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues(): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues {
  return { quasiIdsValues: [], estimatedProbability: 0 };
}

export const AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues:
  MessageFns<AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues> = {
    encode(
      message: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.quasiIdsValues) {
        Value.encode(v!, writer.uint32(10).fork()).join();
      }
      if (message.estimatedProbability !== 0) {
        writer.uint32(17).double(message.estimatedProbability);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message =
        createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.quasiIdsValues.push(Value.decode(reader, reader.uint32()));
            continue;
          case 2:
            if (tag !== 17) {
              break;
            }

            message.estimatedProbability = reader.double();
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(
      object: any,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues {
      return {
        quasiIdsValues: globalThis.Array.isArray(object?.quasiIdsValues)
          ? object.quasiIdsValues.map((e: any) => Value.fromJSON(e))
          : [],
        estimatedProbability: isSet(object.estimatedProbability) ? globalThis.Number(object.estimatedProbability) : 0,
      };
    },

    toJSON(
      message: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues,
    ): unknown {
      const obj: any = {};
      if (message.quasiIdsValues?.length) {
        obj.quasiIdsValues = message.quasiIdsValues.map((e) => Value.toJSON(e));
      }
      if (message.estimatedProbability !== 0) {
        obj.estimatedProbability = message.estimatedProbability;
      }
      return obj;
    },

    create(
      base?: DeepPartial<
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues
      >,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues {
      return AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues
        .fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues
      >,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues {
      const message =
        createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues();
      message.quasiIdsValues = object.quasiIdsValues?.map((e) => Value.fromPartial(e)) || [];
      message.estimatedProbability = object.estimatedProbability ?? 0;
      return message;
    },
  };

function createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket(): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket {
  return { minProbability: 0, maxProbability: 0, bucketSize: Long.ZERO, bucketValues: [], bucketValueCount: Long.ZERO };
}

export const AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket:
  MessageFns<AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket> = {
    encode(
      message: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.minProbability !== 0) {
        writer.uint32(9).double(message.minProbability);
      }
      if (message.maxProbability !== 0) {
        writer.uint32(17).double(message.maxProbability);
      }
      if (!message.bucketSize.equals(Long.ZERO)) {
        writer.uint32(40).int64(message.bucketSize.toString());
      }
      for (const v of message.bucketValues) {
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues.encode(
          v!,
          writer.uint32(50).fork(),
        ).join();
      }
      if (!message.bucketValueCount.equals(Long.ZERO)) {
        writer.uint32(56).int64(message.bucketValueCount.toString());
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message =
        createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 9) {
              break;
            }

            message.minProbability = reader.double();
            continue;
          case 2:
            if (tag !== 17) {
              break;
            }

            message.maxProbability = reader.double();
            continue;
          case 5:
            if (tag !== 40) {
              break;
            }

            message.bucketSize = Long.fromString(reader.int64().toString());
            continue;
          case 6:
            if (tag !== 50) {
              break;
            }

            message.bucketValues.push(
              AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues.decode(
                reader,
                reader.uint32(),
              ),
            );
            continue;
          case 7:
            if (tag !== 56) {
              break;
            }

            message.bucketValueCount = Long.fromString(reader.int64().toString());
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(
      object: any,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket {
      return {
        minProbability: isSet(object.minProbability) ? globalThis.Number(object.minProbability) : 0,
        maxProbability: isSet(object.maxProbability) ? globalThis.Number(object.maxProbability) : 0,
        bucketSize: isSet(object.bucketSize) ? Long.fromValue(object.bucketSize) : Long.ZERO,
        bucketValues: globalThis.Array.isArray(object?.bucketValues)
          ? object.bucketValues.map((e: any) =>
            AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues.fromJSON(e)
          )
          : [],
        bucketValueCount: isSet(object.bucketValueCount) ? Long.fromValue(object.bucketValueCount) : Long.ZERO,
      };
    },

    toJSON(
      message: AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket,
    ): unknown {
      const obj: any = {};
      if (message.minProbability !== 0) {
        obj.minProbability = message.minProbability;
      }
      if (message.maxProbability !== 0) {
        obj.maxProbability = message.maxProbability;
      }
      if (!message.bucketSize.equals(Long.ZERO)) {
        obj.bucketSize = (message.bucketSize || Long.ZERO).toString();
      }
      if (message.bucketValues?.length) {
        obj.bucketValues = message.bucketValues.map((e) =>
          AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues.toJSON(e)
        );
      }
      if (!message.bucketValueCount.equals(Long.ZERO)) {
        obj.bucketValueCount = (message.bucketValueCount || Long.ZERO).toString();
      }
      return obj;
    },

    create(
      base?: DeepPartial<
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket
      >,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket {
      return AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket
        .fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<
        AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket
      >,
    ): AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket {
      const message =
        createBaseAnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationHistogramBucket();
      message.minProbability = object.minProbability ?? 0;
      message.maxProbability = object.maxProbability ?? 0;
      message.bucketSize = (object.bucketSize !== undefined && object.bucketSize !== null)
        ? Long.fromValue(object.bucketSize)
        : Long.ZERO;
      message.bucketValues =
        object.bucketValues?.map((e) =>
          AnalyzeDataSourceRiskDetails_DeltaPresenceEstimationResult_DeltaPresenceEstimationQuasiIdValues.fromPartial(e)
        ) || [];
      message.bucketValueCount = (object.bucketValueCount !== undefined && object.bucketValueCount !== null)
        ? Long.fromValue(object.bucketValueCount)
        : Long.ZERO;
      return message;
    },
  };

function createBaseAnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions(): AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions {
  return { jobConfig: undefined };
}

export const AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions: MessageFns<
  AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions
> = {
  encode(
    message: AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.jobConfig !== undefined) {
      RiskAnalysisJobConfig.encode(message.jobConfig, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobConfig = RiskAnalysisJobConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions {
    return { jobConfig: isSet(object.jobConfig) ? RiskAnalysisJobConfig.fromJSON(object.jobConfig) : undefined };
  },

  toJSON(message: AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions): unknown {
    const obj: any = {};
    if (message.jobConfig !== undefined) {
      obj.jobConfig = RiskAnalysisJobConfig.toJSON(message.jobConfig);
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions>,
  ): AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions {
    return AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions>,
  ): AnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions {
    const message = createBaseAnalyzeDataSourceRiskDetails_RequestedRiskAnalysisOptions();
    message.jobConfig = (object.jobConfig !== undefined && object.jobConfig !== null)
      ? RiskAnalysisJobConfig.fromPartial(object.jobConfig)
      : undefined;
    return message;
  },
};

function createBaseValueFrequency(): ValueFrequency {
  return { value: undefined, count: Long.ZERO };
}

export const ValueFrequency: MessageFns<ValueFrequency> = {
  encode(message: ValueFrequency, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(10).fork()).join();
    }
    if (!message.count.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.count.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ValueFrequency {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValueFrequency();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.count = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ValueFrequency {
    return {
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
      count: isSet(object.count) ? Long.fromValue(object.count) : Long.ZERO,
    };
  },

  toJSON(message: ValueFrequency): unknown {
    const obj: any = {};
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    if (!message.count.equals(Long.ZERO)) {
      obj.count = (message.count || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<ValueFrequency>): ValueFrequency {
    return ValueFrequency.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ValueFrequency>): ValueFrequency {
    const message = createBaseValueFrequency();
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : Long.ZERO;
    return message;
  },
};

function createBaseValue(): Value {
  return {
    integerValue: undefined,
    floatValue: undefined,
    stringValue: undefined,
    booleanValue: undefined,
    timestampValue: undefined,
    timeValue: undefined,
    dateValue: undefined,
    dayOfWeekValue: undefined,
  };
}

export const Value: MessageFns<Value> = {
  encode(message: Value, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.integerValue !== undefined) {
      writer.uint32(8).int64(message.integerValue.toString());
    }
    if (message.floatValue !== undefined) {
      writer.uint32(17).double(message.floatValue);
    }
    if (message.stringValue !== undefined) {
      writer.uint32(26).string(message.stringValue);
    }
    if (message.booleanValue !== undefined) {
      writer.uint32(32).bool(message.booleanValue);
    }
    if (message.timestampValue !== undefined) {
      Timestamp.encode(toTimestamp(message.timestampValue), writer.uint32(42).fork()).join();
    }
    if (message.timeValue !== undefined) {
      TimeOfDay.encode(message.timeValue, writer.uint32(50).fork()).join();
    }
    if (message.dateValue !== undefined) {
      DateMessage.encode(message.dateValue, writer.uint32(58).fork()).join();
    }
    if (message.dayOfWeekValue !== undefined) {
      writer.uint32(64).int32(message.dayOfWeekValue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Value {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.integerValue = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.floatValue = reader.double();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.stringValue = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.booleanValue = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.timestampValue = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.timeValue = TimeOfDay.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.dateValue = DateMessage.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.dayOfWeekValue = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Value {
    return {
      integerValue: isSet(object.integerValue) ? Long.fromValue(object.integerValue) : undefined,
      floatValue: isSet(object.floatValue) ? globalThis.Number(object.floatValue) : undefined,
      stringValue: isSet(object.stringValue) ? globalThis.String(object.stringValue) : undefined,
      booleanValue: isSet(object.booleanValue) ? globalThis.Boolean(object.booleanValue) : undefined,
      timestampValue: isSet(object.timestampValue) ? fromJsonTimestamp(object.timestampValue) : undefined,
      timeValue: isSet(object.timeValue) ? TimeOfDay.fromJSON(object.timeValue) : undefined,
      dateValue: isSet(object.dateValue) ? DateMessage.fromJSON(object.dateValue) : undefined,
      dayOfWeekValue: isSet(object.dayOfWeekValue) ? dayOfWeekFromJSON(object.dayOfWeekValue) : undefined,
    };
  },

  toJSON(message: Value): unknown {
    const obj: any = {};
    if (message.integerValue !== undefined) {
      obj.integerValue = (message.integerValue || Long.ZERO).toString();
    }
    if (message.floatValue !== undefined) {
      obj.floatValue = message.floatValue;
    }
    if (message.stringValue !== undefined) {
      obj.stringValue = message.stringValue;
    }
    if (message.booleanValue !== undefined) {
      obj.booleanValue = message.booleanValue;
    }
    if (message.timestampValue !== undefined) {
      obj.timestampValue = message.timestampValue.toISOString();
    }
    if (message.timeValue !== undefined) {
      obj.timeValue = TimeOfDay.toJSON(message.timeValue);
    }
    if (message.dateValue !== undefined) {
      obj.dateValue = DateMessage.toJSON(message.dateValue);
    }
    if (message.dayOfWeekValue !== undefined) {
      obj.dayOfWeekValue = dayOfWeekToJSON(message.dayOfWeekValue);
    }
    return obj;
  },

  create(base?: DeepPartial<Value>): Value {
    return Value.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Value>): Value {
    const message = createBaseValue();
    message.integerValue = (object.integerValue !== undefined && object.integerValue !== null)
      ? Long.fromValue(object.integerValue)
      : undefined;
    message.floatValue = object.floatValue ?? undefined;
    message.stringValue = object.stringValue ?? undefined;
    message.booleanValue = object.booleanValue ?? undefined;
    message.timestampValue = object.timestampValue ?? undefined;
    message.timeValue = (object.timeValue !== undefined && object.timeValue !== null)
      ? TimeOfDay.fromPartial(object.timeValue)
      : undefined;
    message.dateValue = (object.dateValue !== undefined && object.dateValue !== null)
      ? DateMessage.fromPartial(object.dateValue)
      : undefined;
    message.dayOfWeekValue = object.dayOfWeekValue ?? undefined;
    return message;
  },
};

function createBaseQuoteInfo(): QuoteInfo {
  return { dateTime: undefined };
}

export const QuoteInfo: MessageFns<QuoteInfo> = {
  encode(message: QuoteInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dateTime !== undefined) {
      DateTime.encode(message.dateTime, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QuoteInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuoteInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dateTime = DateTime.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QuoteInfo {
    return { dateTime: isSet(object.dateTime) ? DateTime.fromJSON(object.dateTime) : undefined };
  },

  toJSON(message: QuoteInfo): unknown {
    const obj: any = {};
    if (message.dateTime !== undefined) {
      obj.dateTime = DateTime.toJSON(message.dateTime);
    }
    return obj;
  },

  create(base?: DeepPartial<QuoteInfo>): QuoteInfo {
    return QuoteInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QuoteInfo>): QuoteInfo {
    const message = createBaseQuoteInfo();
    message.dateTime = (object.dateTime !== undefined && object.dateTime !== null)
      ? DateTime.fromPartial(object.dateTime)
      : undefined;
    return message;
  },
};

function createBaseDateTime(): DateTime {
  return { date: undefined, dayOfWeek: 0, time: undefined, timeZone: undefined };
}

export const DateTime: MessageFns<DateTime> = {
  encode(message: DateTime, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.date !== undefined) {
      DateMessage.encode(message.date, writer.uint32(10).fork()).join();
    }
    if (message.dayOfWeek !== 0) {
      writer.uint32(16).int32(message.dayOfWeek);
    }
    if (message.time !== undefined) {
      TimeOfDay.encode(message.time, writer.uint32(26).fork()).join();
    }
    if (message.timeZone !== undefined) {
      DateTime_TimeZone.encode(message.timeZone, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DateTime {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDateTime();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.date = DateMessage.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.dayOfWeek = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.time = TimeOfDay.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.timeZone = DateTime_TimeZone.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DateTime {
    return {
      date: isSet(object.date) ? DateMessage.fromJSON(object.date) : undefined,
      dayOfWeek: isSet(object.dayOfWeek) ? dayOfWeekFromJSON(object.dayOfWeek) : 0,
      time: isSet(object.time) ? TimeOfDay.fromJSON(object.time) : undefined,
      timeZone: isSet(object.timeZone) ? DateTime_TimeZone.fromJSON(object.timeZone) : undefined,
    };
  },

  toJSON(message: DateTime): unknown {
    const obj: any = {};
    if (message.date !== undefined) {
      obj.date = DateMessage.toJSON(message.date);
    }
    if (message.dayOfWeek !== 0) {
      obj.dayOfWeek = dayOfWeekToJSON(message.dayOfWeek);
    }
    if (message.time !== undefined) {
      obj.time = TimeOfDay.toJSON(message.time);
    }
    if (message.timeZone !== undefined) {
      obj.timeZone = DateTime_TimeZone.toJSON(message.timeZone);
    }
    return obj;
  },

  create(base?: DeepPartial<DateTime>): DateTime {
    return DateTime.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DateTime>): DateTime {
    const message = createBaseDateTime();
    message.date = (object.date !== undefined && object.date !== null)
      ? DateMessage.fromPartial(object.date)
      : undefined;
    message.dayOfWeek = object.dayOfWeek ?? 0;
    message.time = (object.time !== undefined && object.time !== null) ? TimeOfDay.fromPartial(object.time) : undefined;
    message.timeZone = (object.timeZone !== undefined && object.timeZone !== null)
      ? DateTime_TimeZone.fromPartial(object.timeZone)
      : undefined;
    return message;
  },
};

function createBaseDateTime_TimeZone(): DateTime_TimeZone {
  return { offsetMinutes: 0 };
}

export const DateTime_TimeZone: MessageFns<DateTime_TimeZone> = {
  encode(message: DateTime_TimeZone, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.offsetMinutes !== 0) {
      writer.uint32(8).int32(message.offsetMinutes);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DateTime_TimeZone {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDateTime_TimeZone();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.offsetMinutes = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DateTime_TimeZone {
    return { offsetMinutes: isSet(object.offsetMinutes) ? globalThis.Number(object.offsetMinutes) : 0 };
  },

  toJSON(message: DateTime_TimeZone): unknown {
    const obj: any = {};
    if (message.offsetMinutes !== 0) {
      obj.offsetMinutes = Math.round(message.offsetMinutes);
    }
    return obj;
  },

  create(base?: DeepPartial<DateTime_TimeZone>): DateTime_TimeZone {
    return DateTime_TimeZone.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DateTime_TimeZone>): DateTime_TimeZone {
    const message = createBaseDateTime_TimeZone();
    message.offsetMinutes = object.offsetMinutes ?? 0;
    return message;
  },
};

function createBaseDeidentifyConfig(): DeidentifyConfig {
  return {
    infoTypeTransformations: undefined,
    recordTransformations: undefined,
    imageTransformations: undefined,
    transformationErrorHandling: undefined,
  };
}

export const DeidentifyConfig: MessageFns<DeidentifyConfig> = {
  encode(message: DeidentifyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoTypeTransformations !== undefined) {
      InfoTypeTransformations.encode(message.infoTypeTransformations, writer.uint32(10).fork()).join();
    }
    if (message.recordTransformations !== undefined) {
      RecordTransformations.encode(message.recordTransformations, writer.uint32(18).fork()).join();
    }
    if (message.imageTransformations !== undefined) {
      ImageTransformations.encode(message.imageTransformations, writer.uint32(34).fork()).join();
    }
    if (message.transformationErrorHandling !== undefined) {
      TransformationErrorHandling.encode(message.transformationErrorHandling, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoTypeTransformations = InfoTypeTransformations.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.recordTransformations = RecordTransformations.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.imageTransformations = ImageTransformations.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transformationErrorHandling = TransformationErrorHandling.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyConfig {
    return {
      infoTypeTransformations: isSet(object.infoTypeTransformations)
        ? InfoTypeTransformations.fromJSON(object.infoTypeTransformations)
        : undefined,
      recordTransformations: isSet(object.recordTransformations)
        ? RecordTransformations.fromJSON(object.recordTransformations)
        : undefined,
      imageTransformations: isSet(object.imageTransformations)
        ? ImageTransformations.fromJSON(object.imageTransformations)
        : undefined,
      transformationErrorHandling: isSet(object.transformationErrorHandling)
        ? TransformationErrorHandling.fromJSON(object.transformationErrorHandling)
        : undefined,
    };
  },

  toJSON(message: DeidentifyConfig): unknown {
    const obj: any = {};
    if (message.infoTypeTransformations !== undefined) {
      obj.infoTypeTransformations = InfoTypeTransformations.toJSON(message.infoTypeTransformations);
    }
    if (message.recordTransformations !== undefined) {
      obj.recordTransformations = RecordTransformations.toJSON(message.recordTransformations);
    }
    if (message.imageTransformations !== undefined) {
      obj.imageTransformations = ImageTransformations.toJSON(message.imageTransformations);
    }
    if (message.transformationErrorHandling !== undefined) {
      obj.transformationErrorHandling = TransformationErrorHandling.toJSON(message.transformationErrorHandling);
    }
    return obj;
  },

  create(base?: DeepPartial<DeidentifyConfig>): DeidentifyConfig {
    return DeidentifyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeidentifyConfig>): DeidentifyConfig {
    const message = createBaseDeidentifyConfig();
    message.infoTypeTransformations =
      (object.infoTypeTransformations !== undefined && object.infoTypeTransformations !== null)
        ? InfoTypeTransformations.fromPartial(object.infoTypeTransformations)
        : undefined;
    message.recordTransformations =
      (object.recordTransformations !== undefined && object.recordTransformations !== null)
        ? RecordTransformations.fromPartial(object.recordTransformations)
        : undefined;
    message.imageTransformations = (object.imageTransformations !== undefined && object.imageTransformations !== null)
      ? ImageTransformations.fromPartial(object.imageTransformations)
      : undefined;
    message.transformationErrorHandling =
      (object.transformationErrorHandling !== undefined && object.transformationErrorHandling !== null)
        ? TransformationErrorHandling.fromPartial(object.transformationErrorHandling)
        : undefined;
    return message;
  },
};

function createBaseImageTransformations(): ImageTransformations {
  return { transforms: [] };
}

export const ImageTransformations: MessageFns<ImageTransformations> = {
  encode(message: ImageTransformations, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.transforms) {
      ImageTransformations_ImageTransformation.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageTransformations {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageTransformations();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transforms.push(ImageTransformations_ImageTransformation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageTransformations {
    return {
      transforms: globalThis.Array.isArray(object?.transforms)
        ? object.transforms.map((e: any) => ImageTransformations_ImageTransformation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ImageTransformations): unknown {
    const obj: any = {};
    if (message.transforms?.length) {
      obj.transforms = message.transforms.map((e) => ImageTransformations_ImageTransformation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ImageTransformations>): ImageTransformations {
    return ImageTransformations.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageTransformations>): ImageTransformations {
    const message = createBaseImageTransformations();
    message.transforms = object.transforms?.map((e) => ImageTransformations_ImageTransformation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseImageTransformations_ImageTransformation(): ImageTransformations_ImageTransformation {
  return { selectedInfoTypes: undefined, allInfoTypes: undefined, allText: undefined, redactionColor: undefined };
}

export const ImageTransformations_ImageTransformation: MessageFns<ImageTransformations_ImageTransformation> = {
  encode(message: ImageTransformations_ImageTransformation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.selectedInfoTypes !== undefined) {
      ImageTransformations_ImageTransformation_SelectedInfoTypes.encode(
        message.selectedInfoTypes,
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.allInfoTypes !== undefined) {
      ImageTransformations_ImageTransformation_AllInfoTypes.encode(message.allInfoTypes, writer.uint32(42).fork())
        .join();
    }
    if (message.allText !== undefined) {
      ImageTransformations_ImageTransformation_AllText.encode(message.allText, writer.uint32(50).fork()).join();
    }
    if (message.redactionColor !== undefined) {
      Color.encode(message.redactionColor, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageTransformations_ImageTransformation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageTransformations_ImageTransformation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.selectedInfoTypes = ImageTransformations_ImageTransformation_SelectedInfoTypes.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.allInfoTypes = ImageTransformations_ImageTransformation_AllInfoTypes.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.allText = ImageTransformations_ImageTransformation_AllText.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.redactionColor = Color.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageTransformations_ImageTransformation {
    return {
      selectedInfoTypes: isSet(object.selectedInfoTypes)
        ? ImageTransformations_ImageTransformation_SelectedInfoTypes.fromJSON(object.selectedInfoTypes)
        : undefined,
      allInfoTypes: isSet(object.allInfoTypes)
        ? ImageTransformations_ImageTransformation_AllInfoTypes.fromJSON(object.allInfoTypes)
        : undefined,
      allText: isSet(object.allText)
        ? ImageTransformations_ImageTransformation_AllText.fromJSON(object.allText)
        : undefined,
      redactionColor: isSet(object.redactionColor) ? Color.fromJSON(object.redactionColor) : undefined,
    };
  },

  toJSON(message: ImageTransformations_ImageTransformation): unknown {
    const obj: any = {};
    if (message.selectedInfoTypes !== undefined) {
      obj.selectedInfoTypes = ImageTransformations_ImageTransformation_SelectedInfoTypes.toJSON(
        message.selectedInfoTypes,
      );
    }
    if (message.allInfoTypes !== undefined) {
      obj.allInfoTypes = ImageTransformations_ImageTransformation_AllInfoTypes.toJSON(message.allInfoTypes);
    }
    if (message.allText !== undefined) {
      obj.allText = ImageTransformations_ImageTransformation_AllText.toJSON(message.allText);
    }
    if (message.redactionColor !== undefined) {
      obj.redactionColor = Color.toJSON(message.redactionColor);
    }
    return obj;
  },

  create(base?: DeepPartial<ImageTransformations_ImageTransformation>): ImageTransformations_ImageTransformation {
    return ImageTransformations_ImageTransformation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageTransformations_ImageTransformation>): ImageTransformations_ImageTransformation {
    const message = createBaseImageTransformations_ImageTransformation();
    message.selectedInfoTypes = (object.selectedInfoTypes !== undefined && object.selectedInfoTypes !== null)
      ? ImageTransformations_ImageTransformation_SelectedInfoTypes.fromPartial(object.selectedInfoTypes)
      : undefined;
    message.allInfoTypes = (object.allInfoTypes !== undefined && object.allInfoTypes !== null)
      ? ImageTransformations_ImageTransformation_AllInfoTypes.fromPartial(object.allInfoTypes)
      : undefined;
    message.allText = (object.allText !== undefined && object.allText !== null)
      ? ImageTransformations_ImageTransformation_AllText.fromPartial(object.allText)
      : undefined;
    message.redactionColor = (object.redactionColor !== undefined && object.redactionColor !== null)
      ? Color.fromPartial(object.redactionColor)
      : undefined;
    return message;
  },
};

function createBaseImageTransformations_ImageTransformation_SelectedInfoTypes(): ImageTransformations_ImageTransformation_SelectedInfoTypes {
  return { infoTypes: [] };
}

export const ImageTransformations_ImageTransformation_SelectedInfoTypes: MessageFns<
  ImageTransformations_ImageTransformation_SelectedInfoTypes
> = {
  encode(
    message: ImageTransformations_ImageTransformation_SelectedInfoTypes,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.infoTypes) {
      InfoType.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): ImageTransformations_ImageTransformation_SelectedInfoTypes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageTransformations_ImageTransformation_SelectedInfoTypes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.infoTypes.push(InfoType.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageTransformations_ImageTransformation_SelectedInfoTypes {
    return {
      infoTypes: globalThis.Array.isArray(object?.infoTypes)
        ? object.infoTypes.map((e: any) => InfoType.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ImageTransformations_ImageTransformation_SelectedInfoTypes): unknown {
    const obj: any = {};
    if (message.infoTypes?.length) {
      obj.infoTypes = message.infoTypes.map((e) => InfoType.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<ImageTransformations_ImageTransformation_SelectedInfoTypes>,
  ): ImageTransformations_ImageTransformation_SelectedInfoTypes {
    return ImageTransformations_ImageTransformation_SelectedInfoTypes.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ImageTransformations_ImageTransformation_SelectedInfoTypes>,
  ): ImageTransformations_ImageTransformation_SelectedInfoTypes {
    const message = createBaseImageTransformations_ImageTransformation_SelectedInfoTypes();
    message.infoTypes = object.infoTypes?.map((e) => InfoType.fromPartial(e)) || [];
    return message;
  },
};

function createBaseImageTransformations_ImageTransformation_AllInfoTypes(): ImageTransformations_ImageTransformation_AllInfoTypes {
  return {};
}

export const ImageTransformations_ImageTransformation_AllInfoTypes: MessageFns<
  ImageTransformations_ImageTransformation_AllInfoTypes
> = {
  encode(
    _: ImageTransformations_ImageTransformation_AllInfoTypes,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageTransformations_ImageTransformation_AllInfoTypes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageTransformations_ImageTransformation_AllInfoTypes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ImageTransformations_ImageTransformation_AllInfoTypes {
    return {};
  },

  toJSON(_: ImageTransformations_ImageTransformation_AllInfoTypes): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<ImageTransformations_ImageTransformation_AllInfoTypes>,
  ): ImageTransformations_ImageTransformation_AllInfoTypes {
    return ImageTransformations_ImageTransformation_AllInfoTypes.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<ImageTransformations_ImageTransformation_AllInfoTypes>,
  ): ImageTransformations_ImageTransformation_AllInfoTypes {
    const message = createBaseImageTransformations_ImageTransformation_AllInfoTypes();
    return message;
  },
};

function createBaseImageTransformations_ImageTransformation_AllText(): ImageTransformations_ImageTransformation_AllText {
  return {};
}

export const ImageTransformations_ImageTransformation_AllText: MessageFns<
  ImageTransformations_ImageTransformation_AllText
> = {
  encode(_: ImageTransformations_ImageTransformation_AllText, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageTransformations_ImageTransformation_AllText {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageTransformations_ImageTransformation_AllText();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ImageTransformations_ImageTransformation_AllText {
    return {};
  },

  toJSON(_: ImageTransformations_ImageTransformation_AllText): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<ImageTransformations_ImageTransformation_AllText>,
  ): ImageTransformations_ImageTransformation_AllText {
    return ImageTransformations_ImageTransformation_AllText.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<ImageTransformations_ImageTransformation_AllText>,
  ): ImageTransformations_ImageTransformation_AllText {
    const message = createBaseImageTransformations_ImageTransformation_AllText();
    return message;
  },
};

function createBaseTransformationErrorHandling(): TransformationErrorHandling {
  return { throwError: undefined, leaveUntransformed: undefined };
}

export const TransformationErrorHandling: MessageFns<TransformationErrorHandling> = {
  encode(message: TransformationErrorHandling, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.throwError !== undefined) {
      TransformationErrorHandling_ThrowError.encode(message.throwError, writer.uint32(10).fork()).join();
    }
    if (message.leaveUntransformed !== undefined) {
      TransformationErrorHandling_LeaveUntransformed.encode(message.leaveUntransformed, writer.uint32(18).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationErrorHandling {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationErrorHandling();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.throwError = TransformationErrorHandling_ThrowError.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.leaveUntransformed = TransformationErrorHandling_LeaveUntransformed.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationErrorHandling {
    return {
      throwError: isSet(object.throwError)
        ? TransformationErrorHandling_ThrowError.fromJSON(object.throwError)
        : undefined,
      leaveUntransformed: isSet(object.leaveUntransformed)
        ? TransformationErrorHandling_LeaveUntransformed.fromJSON(object.leaveUntransformed)
        : undefined,
    };
  },

  toJSON(message: TransformationErrorHandling): unknown {
    const obj: any = {};
    if (message.throwError !== undefined) {
      obj.throwError = TransformationErrorHandling_ThrowError.toJSON(message.throwError);
    }
    if (message.leaveUntransformed !== undefined) {
      obj.leaveUntransformed = TransformationErrorHandling_LeaveUntransformed.toJSON(message.leaveUntransformed);
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationErrorHandling>): TransformationErrorHandling {
    return TransformationErrorHandling.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationErrorHandling>): TransformationErrorHandling {
    const message = createBaseTransformationErrorHandling();
    message.throwError = (object.throwError !== undefined && object.throwError !== null)
      ? TransformationErrorHandling_ThrowError.fromPartial(object.throwError)
      : undefined;
    message.leaveUntransformed = (object.leaveUntransformed !== undefined && object.leaveUntransformed !== null)
      ? TransformationErrorHandling_LeaveUntransformed.fromPartial(object.leaveUntransformed)
      : undefined;
    return message;
  },
};

function createBaseTransformationErrorHandling_ThrowError(): TransformationErrorHandling_ThrowError {
  return {};
}

export const TransformationErrorHandling_ThrowError: MessageFns<TransformationErrorHandling_ThrowError> = {
  encode(_: TransformationErrorHandling_ThrowError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationErrorHandling_ThrowError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationErrorHandling_ThrowError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): TransformationErrorHandling_ThrowError {
    return {};
  },

  toJSON(_: TransformationErrorHandling_ThrowError): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<TransformationErrorHandling_ThrowError>): TransformationErrorHandling_ThrowError {
    return TransformationErrorHandling_ThrowError.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<TransformationErrorHandling_ThrowError>): TransformationErrorHandling_ThrowError {
    const message = createBaseTransformationErrorHandling_ThrowError();
    return message;
  },
};

function createBaseTransformationErrorHandling_LeaveUntransformed(): TransformationErrorHandling_LeaveUntransformed {
  return {};
}

export const TransformationErrorHandling_LeaveUntransformed: MessageFns<
  TransformationErrorHandling_LeaveUntransformed
> = {
  encode(_: TransformationErrorHandling_LeaveUntransformed, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationErrorHandling_LeaveUntransformed {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationErrorHandling_LeaveUntransformed();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): TransformationErrorHandling_LeaveUntransformed {
    return {};
  },

  toJSON(_: TransformationErrorHandling_LeaveUntransformed): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<TransformationErrorHandling_LeaveUntransformed>,
  ): TransformationErrorHandling_LeaveUntransformed {
    return TransformationErrorHandling_LeaveUntransformed.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<TransformationErrorHandling_LeaveUntransformed>,
  ): TransformationErrorHandling_LeaveUntransformed {
    const message = createBaseTransformationErrorHandling_LeaveUntransformed();
    return message;
  },
};

function createBasePrimitiveTransformation(): PrimitiveTransformation {
  return {
    replaceConfig: undefined,
    redactConfig: undefined,
    characterMaskConfig: undefined,
    cryptoReplaceFfxFpeConfig: undefined,
    fixedSizeBucketingConfig: undefined,
    bucketingConfig: undefined,
    replaceWithInfoTypeConfig: undefined,
    timePartConfig: undefined,
    cryptoHashConfig: undefined,
    dateShiftConfig: undefined,
    cryptoDeterministicConfig: undefined,
    replaceDictionaryConfig: undefined,
  };
}

export const PrimitiveTransformation: MessageFns<PrimitiveTransformation> = {
  encode(message: PrimitiveTransformation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.replaceConfig !== undefined) {
      ReplaceValueConfig.encode(message.replaceConfig, writer.uint32(10).fork()).join();
    }
    if (message.redactConfig !== undefined) {
      RedactConfig.encode(message.redactConfig, writer.uint32(18).fork()).join();
    }
    if (message.characterMaskConfig !== undefined) {
      CharacterMaskConfig.encode(message.characterMaskConfig, writer.uint32(26).fork()).join();
    }
    if (message.cryptoReplaceFfxFpeConfig !== undefined) {
      CryptoReplaceFfxFpeConfig.encode(message.cryptoReplaceFfxFpeConfig, writer.uint32(34).fork()).join();
    }
    if (message.fixedSizeBucketingConfig !== undefined) {
      FixedSizeBucketingConfig.encode(message.fixedSizeBucketingConfig, writer.uint32(42).fork()).join();
    }
    if (message.bucketingConfig !== undefined) {
      BucketingConfig.encode(message.bucketingConfig, writer.uint32(50).fork()).join();
    }
    if (message.replaceWithInfoTypeConfig !== undefined) {
      ReplaceWithInfoTypeConfig.encode(message.replaceWithInfoTypeConfig, writer.uint32(58).fork()).join();
    }
    if (message.timePartConfig !== undefined) {
      TimePartConfig.encode(message.timePartConfig, writer.uint32(66).fork()).join();
    }
    if (message.cryptoHashConfig !== undefined) {
      CryptoHashConfig.encode(message.cryptoHashConfig, writer.uint32(74).fork()).join();
    }
    if (message.dateShiftConfig !== undefined) {
      DateShiftConfig.encode(message.dateShiftConfig, writer.uint32(90).fork()).join();
    }
    if (message.cryptoDeterministicConfig !== undefined) {
      CryptoDeterministicConfig.encode(message.cryptoDeterministicConfig, writer.uint32(98).fork()).join();
    }
    if (message.replaceDictionaryConfig !== undefined) {
      ReplaceDictionaryConfig.encode(message.replaceDictionaryConfig, writer.uint32(106).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrimitiveTransformation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrimitiveTransformation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.replaceConfig = ReplaceValueConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.redactConfig = RedactConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.characterMaskConfig = CharacterMaskConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cryptoReplaceFfxFpeConfig = CryptoReplaceFfxFpeConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.fixedSizeBucketingConfig = FixedSizeBucketingConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.bucketingConfig = BucketingConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.replaceWithInfoTypeConfig = ReplaceWithInfoTypeConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.timePartConfig = TimePartConfig.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.cryptoHashConfig = CryptoHashConfig.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.dateShiftConfig = DateShiftConfig.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.cryptoDeterministicConfig = CryptoDeterministicConfig.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.replaceDictionaryConfig = ReplaceDictionaryConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrimitiveTransformation {
    return {
      replaceConfig: isSet(object.replaceConfig) ? ReplaceValueConfig.fromJSON(object.replaceConfig) : undefined,
      redactConfig: isSet(object.redactConfig) ? RedactConfig.fromJSON(object.redactConfig) : undefined,
      characterMaskConfig: isSet(object.characterMaskConfig)
        ? CharacterMaskConfig.fromJSON(object.characterMaskConfig)
        : undefined,
      cryptoReplaceFfxFpeConfig: isSet(object.cryptoReplaceFfxFpeConfig)
        ? CryptoReplaceFfxFpeConfig.fromJSON(object.cryptoReplaceFfxFpeConfig)
        : undefined,
      fixedSizeBucketingConfig: isSet(object.fixedSizeBucketingConfig)
        ? FixedSizeBucketingConfig.fromJSON(object.fixedSizeBucketingConfig)
        : undefined,
      bucketingConfig: isSet(object.bucketingConfig) ? BucketingConfig.fromJSON(object.bucketingConfig) : undefined,
      replaceWithInfoTypeConfig: isSet(object.replaceWithInfoTypeConfig)
        ? ReplaceWithInfoTypeConfig.fromJSON(object.replaceWithInfoTypeConfig)
        : undefined,
      timePartConfig: isSet(object.timePartConfig) ? TimePartConfig.fromJSON(object.timePartConfig) : undefined,
      cryptoHashConfig: isSet(object.cryptoHashConfig) ? CryptoHashConfig.fromJSON(object.cryptoHashConfig) : undefined,
      dateShiftConfig: isSet(object.dateShiftConfig) ? DateShiftConfig.fromJSON(object.dateShiftConfig) : undefined,
      cryptoDeterministicConfig: isSet(object.cryptoDeterministicConfig)
        ? CryptoDeterministicConfig.fromJSON(object.cryptoDeterministicConfig)
        : undefined,
      replaceDictionaryConfig: isSet(object.replaceDictionaryConfig)
        ? ReplaceDictionaryConfig.fromJSON(object.replaceDictionaryConfig)
        : undefined,
    };
  },

  toJSON(message: PrimitiveTransformation): unknown {
    const obj: any = {};
    if (message.replaceConfig !== undefined) {
      obj.replaceConfig = ReplaceValueConfig.toJSON(message.replaceConfig);
    }
    if (message.redactConfig !== undefined) {
      obj.redactConfig = RedactConfig.toJSON(message.redactConfig);
    }
    if (message.characterMaskConfig !== undefined) {
      obj.characterMaskConfig = CharacterMaskConfig.toJSON(message.characterMaskConfig);
    }
    if (message.cryptoReplaceFfxFpeConfig !== undefined) {
      obj.cryptoReplaceFfxFpeConfig = CryptoReplaceFfxFpeConfig.toJSON(message.cryptoReplaceFfxFpeConfig);
    }
    if (message.fixedSizeBucketingConfig !== undefined) {
      obj.fixedSizeBucketingConfig = FixedSizeBucketingConfig.toJSON(message.fixedSizeBucketingConfig);
    }
    if (message.bucketingConfig !== undefined) {
      obj.bucketingConfig = BucketingConfig.toJSON(message.bucketingConfig);
    }
    if (message.replaceWithInfoTypeConfig !== undefined) {
      obj.replaceWithInfoTypeConfig = ReplaceWithInfoTypeConfig.toJSON(message.replaceWithInfoTypeConfig);
    }
    if (message.timePartConfig !== undefined) {
      obj.timePartConfig = TimePartConfig.toJSON(message.timePartConfig);
    }
    if (message.cryptoHashConfig !== undefined) {
      obj.cryptoHashConfig = CryptoHashConfig.toJSON(message.cryptoHashConfig);
    }
    if (message.dateShiftConfig !== undefined) {
      obj.dateShiftConfig = DateShiftConfig.toJSON(message.dateShiftConfig);
    }
    if (message.cryptoDeterministicConfig !== undefined) {
      obj.cryptoDeterministicConfig = CryptoDeterministicConfig.toJSON(message.cryptoDeterministicConfig);
    }
    if (message.replaceDictionaryConfig !== undefined) {
      obj.replaceDictionaryConfig = ReplaceDictionaryConfig.toJSON(message.replaceDictionaryConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<PrimitiveTransformation>): PrimitiveTransformation {
    return PrimitiveTransformation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrimitiveTransformation>): PrimitiveTransformation {
    const message = createBasePrimitiveTransformation();
    message.replaceConfig = (object.replaceConfig !== undefined && object.replaceConfig !== null)
      ? ReplaceValueConfig.fromPartial(object.replaceConfig)
      : undefined;
    message.redactConfig = (object.redactConfig !== undefined && object.redactConfig !== null)
      ? RedactConfig.fromPartial(object.redactConfig)
      : undefined;
    message.characterMaskConfig = (object.characterMaskConfig !== undefined && object.characterMaskConfig !== null)
      ? CharacterMaskConfig.fromPartial(object.characterMaskConfig)
      : undefined;
    message.cryptoReplaceFfxFpeConfig =
      (object.cryptoReplaceFfxFpeConfig !== undefined && object.cryptoReplaceFfxFpeConfig !== null)
        ? CryptoReplaceFfxFpeConfig.fromPartial(object.cryptoReplaceFfxFpeConfig)
        : undefined;
    message.fixedSizeBucketingConfig =
      (object.fixedSizeBucketingConfig !== undefined && object.fixedSizeBucketingConfig !== null)
        ? FixedSizeBucketingConfig.fromPartial(object.fixedSizeBucketingConfig)
        : undefined;
    message.bucketingConfig = (object.bucketingConfig !== undefined && object.bucketingConfig !== null)
      ? BucketingConfig.fromPartial(object.bucketingConfig)
      : undefined;
    message.replaceWithInfoTypeConfig =
      (object.replaceWithInfoTypeConfig !== undefined && object.replaceWithInfoTypeConfig !== null)
        ? ReplaceWithInfoTypeConfig.fromPartial(object.replaceWithInfoTypeConfig)
        : undefined;
    message.timePartConfig = (object.timePartConfig !== undefined && object.timePartConfig !== null)
      ? TimePartConfig.fromPartial(object.timePartConfig)
      : undefined;
    message.cryptoHashConfig = (object.cryptoHashConfig !== undefined && object.cryptoHashConfig !== null)
      ? CryptoHashConfig.fromPartial(object.cryptoHashConfig)
      : undefined;
    message.dateShiftConfig = (object.dateShiftConfig !== undefined && object.dateShiftConfig !== null)
      ? DateShiftConfig.fromPartial(object.dateShiftConfig)
      : undefined;
    message.cryptoDeterministicConfig =
      (object.cryptoDeterministicConfig !== undefined && object.cryptoDeterministicConfig !== null)
        ? CryptoDeterministicConfig.fromPartial(object.cryptoDeterministicConfig)
        : undefined;
    message.replaceDictionaryConfig =
      (object.replaceDictionaryConfig !== undefined && object.replaceDictionaryConfig !== null)
        ? ReplaceDictionaryConfig.fromPartial(object.replaceDictionaryConfig)
        : undefined;
    return message;
  },
};

function createBaseTimePartConfig(): TimePartConfig {
  return { partToExtract: 0 };
}

export const TimePartConfig: MessageFns<TimePartConfig> = {
  encode(message: TimePartConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.partToExtract !== 0) {
      writer.uint32(8).int32(message.partToExtract);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TimePartConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTimePartConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.partToExtract = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TimePartConfig {
    return { partToExtract: isSet(object.partToExtract) ? timePartConfig_TimePartFromJSON(object.partToExtract) : 0 };
  },

  toJSON(message: TimePartConfig): unknown {
    const obj: any = {};
    if (message.partToExtract !== 0) {
      obj.partToExtract = timePartConfig_TimePartToJSON(message.partToExtract);
    }
    return obj;
  },

  create(base?: DeepPartial<TimePartConfig>): TimePartConfig {
    return TimePartConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TimePartConfig>): TimePartConfig {
    const message = createBaseTimePartConfig();
    message.partToExtract = object.partToExtract ?? 0;
    return message;
  },
};

function createBaseCryptoHashConfig(): CryptoHashConfig {
  return { cryptoKey: undefined };
}

export const CryptoHashConfig: MessageFns<CryptoHashConfig> = {
  encode(message: CryptoHashConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cryptoKey !== undefined) {
      CryptoKey.encode(message.cryptoKey, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CryptoHashConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCryptoHashConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cryptoKey = CryptoKey.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CryptoHashConfig {
    return { cryptoKey: isSet(object.cryptoKey) ? CryptoKey.fromJSON(object.cryptoKey) : undefined };
  },

  toJSON(message: CryptoHashConfig): unknown {
    const obj: any = {};
    if (message.cryptoKey !== undefined) {
      obj.cryptoKey = CryptoKey.toJSON(message.cryptoKey);
    }
    return obj;
  },

  create(base?: DeepPartial<CryptoHashConfig>): CryptoHashConfig {
    return CryptoHashConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CryptoHashConfig>): CryptoHashConfig {
    const message = createBaseCryptoHashConfig();
    message.cryptoKey = (object.cryptoKey !== undefined && object.cryptoKey !== null)
      ? CryptoKey.fromPartial(object.cryptoKey)
      : undefined;
    return message;
  },
};

function createBaseCryptoDeterministicConfig(): CryptoDeterministicConfig {
  return { cryptoKey: undefined, surrogateInfoType: undefined, context: undefined };
}

export const CryptoDeterministicConfig: MessageFns<CryptoDeterministicConfig> = {
  encode(message: CryptoDeterministicConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cryptoKey !== undefined) {
      CryptoKey.encode(message.cryptoKey, writer.uint32(10).fork()).join();
    }
    if (message.surrogateInfoType !== undefined) {
      InfoType.encode(message.surrogateInfoType, writer.uint32(18).fork()).join();
    }
    if (message.context !== undefined) {
      FieldId.encode(message.context, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CryptoDeterministicConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCryptoDeterministicConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cryptoKey = CryptoKey.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.surrogateInfoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.context = FieldId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CryptoDeterministicConfig {
    return {
      cryptoKey: isSet(object.cryptoKey) ? CryptoKey.fromJSON(object.cryptoKey) : undefined,
      surrogateInfoType: isSet(object.surrogateInfoType) ? InfoType.fromJSON(object.surrogateInfoType) : undefined,
      context: isSet(object.context) ? FieldId.fromJSON(object.context) : undefined,
    };
  },

  toJSON(message: CryptoDeterministicConfig): unknown {
    const obj: any = {};
    if (message.cryptoKey !== undefined) {
      obj.cryptoKey = CryptoKey.toJSON(message.cryptoKey);
    }
    if (message.surrogateInfoType !== undefined) {
      obj.surrogateInfoType = InfoType.toJSON(message.surrogateInfoType);
    }
    if (message.context !== undefined) {
      obj.context = FieldId.toJSON(message.context);
    }
    return obj;
  },

  create(base?: DeepPartial<CryptoDeterministicConfig>): CryptoDeterministicConfig {
    return CryptoDeterministicConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CryptoDeterministicConfig>): CryptoDeterministicConfig {
    const message = createBaseCryptoDeterministicConfig();
    message.cryptoKey = (object.cryptoKey !== undefined && object.cryptoKey !== null)
      ? CryptoKey.fromPartial(object.cryptoKey)
      : undefined;
    message.surrogateInfoType = (object.surrogateInfoType !== undefined && object.surrogateInfoType !== null)
      ? InfoType.fromPartial(object.surrogateInfoType)
      : undefined;
    message.context = (object.context !== undefined && object.context !== null)
      ? FieldId.fromPartial(object.context)
      : undefined;
    return message;
  },
};

function createBaseReplaceValueConfig(): ReplaceValueConfig {
  return { newValue: undefined };
}

export const ReplaceValueConfig: MessageFns<ReplaceValueConfig> = {
  encode(message: ReplaceValueConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.newValue !== undefined) {
      Value.encode(message.newValue, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplaceValueConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplaceValueConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.newValue = Value.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplaceValueConfig {
    return { newValue: isSet(object.newValue) ? Value.fromJSON(object.newValue) : undefined };
  },

  toJSON(message: ReplaceValueConfig): unknown {
    const obj: any = {};
    if (message.newValue !== undefined) {
      obj.newValue = Value.toJSON(message.newValue);
    }
    return obj;
  },

  create(base?: DeepPartial<ReplaceValueConfig>): ReplaceValueConfig {
    return ReplaceValueConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReplaceValueConfig>): ReplaceValueConfig {
    const message = createBaseReplaceValueConfig();
    message.newValue = (object.newValue !== undefined && object.newValue !== null)
      ? Value.fromPartial(object.newValue)
      : undefined;
    return message;
  },
};

function createBaseReplaceDictionaryConfig(): ReplaceDictionaryConfig {
  return { wordList: undefined };
}

export const ReplaceDictionaryConfig: MessageFns<ReplaceDictionaryConfig> = {
  encode(message: ReplaceDictionaryConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.wordList !== undefined) {
      CustomInfoType_Dictionary_WordList.encode(message.wordList, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplaceDictionaryConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplaceDictionaryConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.wordList = CustomInfoType_Dictionary_WordList.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplaceDictionaryConfig {
    return {
      wordList: isSet(object.wordList) ? CustomInfoType_Dictionary_WordList.fromJSON(object.wordList) : undefined,
    };
  },

  toJSON(message: ReplaceDictionaryConfig): unknown {
    const obj: any = {};
    if (message.wordList !== undefined) {
      obj.wordList = CustomInfoType_Dictionary_WordList.toJSON(message.wordList);
    }
    return obj;
  },

  create(base?: DeepPartial<ReplaceDictionaryConfig>): ReplaceDictionaryConfig {
    return ReplaceDictionaryConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReplaceDictionaryConfig>): ReplaceDictionaryConfig {
    const message = createBaseReplaceDictionaryConfig();
    message.wordList = (object.wordList !== undefined && object.wordList !== null)
      ? CustomInfoType_Dictionary_WordList.fromPartial(object.wordList)
      : undefined;
    return message;
  },
};

function createBaseReplaceWithInfoTypeConfig(): ReplaceWithInfoTypeConfig {
  return {};
}

export const ReplaceWithInfoTypeConfig: MessageFns<ReplaceWithInfoTypeConfig> = {
  encode(_: ReplaceWithInfoTypeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplaceWithInfoTypeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplaceWithInfoTypeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ReplaceWithInfoTypeConfig {
    return {};
  },

  toJSON(_: ReplaceWithInfoTypeConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ReplaceWithInfoTypeConfig>): ReplaceWithInfoTypeConfig {
    return ReplaceWithInfoTypeConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ReplaceWithInfoTypeConfig>): ReplaceWithInfoTypeConfig {
    const message = createBaseReplaceWithInfoTypeConfig();
    return message;
  },
};

function createBaseRedactConfig(): RedactConfig {
  return {};
}

export const RedactConfig: MessageFns<RedactConfig> = {
  encode(_: RedactConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedactConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedactConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): RedactConfig {
    return {};
  },

  toJSON(_: RedactConfig): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<RedactConfig>): RedactConfig {
    return RedactConfig.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<RedactConfig>): RedactConfig {
    const message = createBaseRedactConfig();
    return message;
  },
};

function createBaseCharsToIgnore(): CharsToIgnore {
  return { charactersToSkip: undefined, commonCharactersToIgnore: undefined };
}

export const CharsToIgnore: MessageFns<CharsToIgnore> = {
  encode(message: CharsToIgnore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.charactersToSkip !== undefined) {
      writer.uint32(10).string(message.charactersToSkip);
    }
    if (message.commonCharactersToIgnore !== undefined) {
      writer.uint32(16).int32(message.commonCharactersToIgnore);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CharsToIgnore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCharsToIgnore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.charactersToSkip = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.commonCharactersToIgnore = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CharsToIgnore {
    return {
      charactersToSkip: isSet(object.charactersToSkip) ? globalThis.String(object.charactersToSkip) : undefined,
      commonCharactersToIgnore: isSet(object.commonCharactersToIgnore)
        ? charsToIgnore_CommonCharsToIgnoreFromJSON(object.commonCharactersToIgnore)
        : undefined,
    };
  },

  toJSON(message: CharsToIgnore): unknown {
    const obj: any = {};
    if (message.charactersToSkip !== undefined) {
      obj.charactersToSkip = message.charactersToSkip;
    }
    if (message.commonCharactersToIgnore !== undefined) {
      obj.commonCharactersToIgnore = charsToIgnore_CommonCharsToIgnoreToJSON(message.commonCharactersToIgnore);
    }
    return obj;
  },

  create(base?: DeepPartial<CharsToIgnore>): CharsToIgnore {
    return CharsToIgnore.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CharsToIgnore>): CharsToIgnore {
    const message = createBaseCharsToIgnore();
    message.charactersToSkip = object.charactersToSkip ?? undefined;
    message.commonCharactersToIgnore = object.commonCharactersToIgnore ?? undefined;
    return message;
  },
};

function createBaseCharacterMaskConfig(): CharacterMaskConfig {
  return { maskingCharacter: "", numberToMask: 0, reverseOrder: false, charactersToIgnore: [] };
}

export const CharacterMaskConfig: MessageFns<CharacterMaskConfig> = {
  encode(message: CharacterMaskConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maskingCharacter !== "") {
      writer.uint32(10).string(message.maskingCharacter);
    }
    if (message.numberToMask !== 0) {
      writer.uint32(16).int32(message.numberToMask);
    }
    if (message.reverseOrder !== false) {
      writer.uint32(24).bool(message.reverseOrder);
    }
    for (const v of message.charactersToIgnore) {
      CharsToIgnore.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CharacterMaskConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCharacterMaskConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.maskingCharacter = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.numberToMask = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.reverseOrder = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.charactersToIgnore.push(CharsToIgnore.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CharacterMaskConfig {
    return {
      maskingCharacter: isSet(object.maskingCharacter) ? globalThis.String(object.maskingCharacter) : "",
      numberToMask: isSet(object.numberToMask) ? globalThis.Number(object.numberToMask) : 0,
      reverseOrder: isSet(object.reverseOrder) ? globalThis.Boolean(object.reverseOrder) : false,
      charactersToIgnore: globalThis.Array.isArray(object?.charactersToIgnore)
        ? object.charactersToIgnore.map((e: any) => CharsToIgnore.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CharacterMaskConfig): unknown {
    const obj: any = {};
    if (message.maskingCharacter !== "") {
      obj.maskingCharacter = message.maskingCharacter;
    }
    if (message.numberToMask !== 0) {
      obj.numberToMask = Math.round(message.numberToMask);
    }
    if (message.reverseOrder !== false) {
      obj.reverseOrder = message.reverseOrder;
    }
    if (message.charactersToIgnore?.length) {
      obj.charactersToIgnore = message.charactersToIgnore.map((e) => CharsToIgnore.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CharacterMaskConfig>): CharacterMaskConfig {
    return CharacterMaskConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CharacterMaskConfig>): CharacterMaskConfig {
    const message = createBaseCharacterMaskConfig();
    message.maskingCharacter = object.maskingCharacter ?? "";
    message.numberToMask = object.numberToMask ?? 0;
    message.reverseOrder = object.reverseOrder ?? false;
    message.charactersToIgnore = object.charactersToIgnore?.map((e) => CharsToIgnore.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFixedSizeBucketingConfig(): FixedSizeBucketingConfig {
  return { lowerBound: undefined, upperBound: undefined, bucketSize: 0 };
}

export const FixedSizeBucketingConfig: MessageFns<FixedSizeBucketingConfig> = {
  encode(message: FixedSizeBucketingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.lowerBound !== undefined) {
      Value.encode(message.lowerBound, writer.uint32(10).fork()).join();
    }
    if (message.upperBound !== undefined) {
      Value.encode(message.upperBound, writer.uint32(18).fork()).join();
    }
    if (message.bucketSize !== 0) {
      writer.uint32(25).double(message.bucketSize);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FixedSizeBucketingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFixedSizeBucketingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.lowerBound = Value.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.upperBound = Value.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 25) {
            break;
          }

          message.bucketSize = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FixedSizeBucketingConfig {
    return {
      lowerBound: isSet(object.lowerBound) ? Value.fromJSON(object.lowerBound) : undefined,
      upperBound: isSet(object.upperBound) ? Value.fromJSON(object.upperBound) : undefined,
      bucketSize: isSet(object.bucketSize) ? globalThis.Number(object.bucketSize) : 0,
    };
  },

  toJSON(message: FixedSizeBucketingConfig): unknown {
    const obj: any = {};
    if (message.lowerBound !== undefined) {
      obj.lowerBound = Value.toJSON(message.lowerBound);
    }
    if (message.upperBound !== undefined) {
      obj.upperBound = Value.toJSON(message.upperBound);
    }
    if (message.bucketSize !== 0) {
      obj.bucketSize = message.bucketSize;
    }
    return obj;
  },

  create(base?: DeepPartial<FixedSizeBucketingConfig>): FixedSizeBucketingConfig {
    return FixedSizeBucketingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FixedSizeBucketingConfig>): FixedSizeBucketingConfig {
    const message = createBaseFixedSizeBucketingConfig();
    message.lowerBound = (object.lowerBound !== undefined && object.lowerBound !== null)
      ? Value.fromPartial(object.lowerBound)
      : undefined;
    message.upperBound = (object.upperBound !== undefined && object.upperBound !== null)
      ? Value.fromPartial(object.upperBound)
      : undefined;
    message.bucketSize = object.bucketSize ?? 0;
    return message;
  },
};

function createBaseBucketingConfig(): BucketingConfig {
  return { buckets: [] };
}

export const BucketingConfig: MessageFns<BucketingConfig> = {
  encode(message: BucketingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.buckets) {
      BucketingConfig_Bucket.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BucketingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucketingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.buckets.push(BucketingConfig_Bucket.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BucketingConfig {
    return {
      buckets: globalThis.Array.isArray(object?.buckets)
        ? object.buckets.map((e: any) => BucketingConfig_Bucket.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BucketingConfig): unknown {
    const obj: any = {};
    if (message.buckets?.length) {
      obj.buckets = message.buckets.map((e) => BucketingConfig_Bucket.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BucketingConfig>): BucketingConfig {
    return BucketingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BucketingConfig>): BucketingConfig {
    const message = createBaseBucketingConfig();
    message.buckets = object.buckets?.map((e) => BucketingConfig_Bucket.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBucketingConfig_Bucket(): BucketingConfig_Bucket {
  return { min: undefined, max: undefined, replacementValue: undefined };
}

export const BucketingConfig_Bucket: MessageFns<BucketingConfig_Bucket> = {
  encode(message: BucketingConfig_Bucket, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.min !== undefined) {
      Value.encode(message.min, writer.uint32(10).fork()).join();
    }
    if (message.max !== undefined) {
      Value.encode(message.max, writer.uint32(18).fork()).join();
    }
    if (message.replacementValue !== undefined) {
      Value.encode(message.replacementValue, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BucketingConfig_Bucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucketingConfig_Bucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.min = Value.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.max = Value.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.replacementValue = Value.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BucketingConfig_Bucket {
    return {
      min: isSet(object.min) ? Value.fromJSON(object.min) : undefined,
      max: isSet(object.max) ? Value.fromJSON(object.max) : undefined,
      replacementValue: isSet(object.replacementValue) ? Value.fromJSON(object.replacementValue) : undefined,
    };
  },

  toJSON(message: BucketingConfig_Bucket): unknown {
    const obj: any = {};
    if (message.min !== undefined) {
      obj.min = Value.toJSON(message.min);
    }
    if (message.max !== undefined) {
      obj.max = Value.toJSON(message.max);
    }
    if (message.replacementValue !== undefined) {
      obj.replacementValue = Value.toJSON(message.replacementValue);
    }
    return obj;
  },

  create(base?: DeepPartial<BucketingConfig_Bucket>): BucketingConfig_Bucket {
    return BucketingConfig_Bucket.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BucketingConfig_Bucket>): BucketingConfig_Bucket {
    const message = createBaseBucketingConfig_Bucket();
    message.min = (object.min !== undefined && object.min !== null) ? Value.fromPartial(object.min) : undefined;
    message.max = (object.max !== undefined && object.max !== null) ? Value.fromPartial(object.max) : undefined;
    message.replacementValue = (object.replacementValue !== undefined && object.replacementValue !== null)
      ? Value.fromPartial(object.replacementValue)
      : undefined;
    return message;
  },
};

function createBaseCryptoReplaceFfxFpeConfig(): CryptoReplaceFfxFpeConfig {
  return {
    cryptoKey: undefined,
    context: undefined,
    commonAlphabet: undefined,
    customAlphabet: undefined,
    radix: undefined,
    surrogateInfoType: undefined,
  };
}

export const CryptoReplaceFfxFpeConfig: MessageFns<CryptoReplaceFfxFpeConfig> = {
  encode(message: CryptoReplaceFfxFpeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cryptoKey !== undefined) {
      CryptoKey.encode(message.cryptoKey, writer.uint32(10).fork()).join();
    }
    if (message.context !== undefined) {
      FieldId.encode(message.context, writer.uint32(18).fork()).join();
    }
    if (message.commonAlphabet !== undefined) {
      writer.uint32(32).int32(message.commonAlphabet);
    }
    if (message.customAlphabet !== undefined) {
      writer.uint32(42).string(message.customAlphabet);
    }
    if (message.radix !== undefined) {
      writer.uint32(48).int32(message.radix);
    }
    if (message.surrogateInfoType !== undefined) {
      InfoType.encode(message.surrogateInfoType, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CryptoReplaceFfxFpeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCryptoReplaceFfxFpeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cryptoKey = CryptoKey.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.context = FieldId.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.commonAlphabet = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.customAlphabet = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.radix = reader.int32();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.surrogateInfoType = InfoType.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CryptoReplaceFfxFpeConfig {
    return {
      cryptoKey: isSet(object.cryptoKey) ? CryptoKey.fromJSON(object.cryptoKey) : undefined,
      context: isSet(object.context) ? FieldId.fromJSON(object.context) : undefined,
      commonAlphabet: isSet(object.commonAlphabet)
        ? cryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabetFromJSON(object.commonAlphabet)
        : undefined,
      customAlphabet: isSet(object.customAlphabet) ? globalThis.String(object.customAlphabet) : undefined,
      radix: isSet(object.radix) ? globalThis.Number(object.radix) : undefined,
      surrogateInfoType: isSet(object.surrogateInfoType) ? InfoType.fromJSON(object.surrogateInfoType) : undefined,
    };
  },

  toJSON(message: CryptoReplaceFfxFpeConfig): unknown {
    const obj: any = {};
    if (message.cryptoKey !== undefined) {
      obj.cryptoKey = CryptoKey.toJSON(message.cryptoKey);
    }
    if (message.context !== undefined) {
      obj.context = FieldId.toJSON(message.context);
    }
    if (message.commonAlphabet !== undefined) {
      obj.commonAlphabet = cryptoReplaceFfxFpeConfig_FfxCommonNativeAlphabetToJSON(message.commonAlphabet);
    }
    if (message.customAlphabet !== undefined) {
      obj.customAlphabet = message.customAlphabet;
    }
    if (message.radix !== undefined) {
      obj.radix = Math.round(message.radix);
    }
    if (message.surrogateInfoType !== undefined) {
      obj.surrogateInfoType = InfoType.toJSON(message.surrogateInfoType);
    }
    return obj;
  },

  create(base?: DeepPartial<CryptoReplaceFfxFpeConfig>): CryptoReplaceFfxFpeConfig {
    return CryptoReplaceFfxFpeConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CryptoReplaceFfxFpeConfig>): CryptoReplaceFfxFpeConfig {
    const message = createBaseCryptoReplaceFfxFpeConfig();
    message.cryptoKey = (object.cryptoKey !== undefined && object.cryptoKey !== null)
      ? CryptoKey.fromPartial(object.cryptoKey)
      : undefined;
    message.context = (object.context !== undefined && object.context !== null)
      ? FieldId.fromPartial(object.context)
      : undefined;
    message.commonAlphabet = object.commonAlphabet ?? undefined;
    message.customAlphabet = object.customAlphabet ?? undefined;
    message.radix = object.radix ?? undefined;
    message.surrogateInfoType = (object.surrogateInfoType !== undefined && object.surrogateInfoType !== null)
      ? InfoType.fromPartial(object.surrogateInfoType)
      : undefined;
    return message;
  },
};

function createBaseCryptoKey(): CryptoKey {
  return { transient: undefined, unwrapped: undefined, kmsWrapped: undefined };
}

export const CryptoKey: MessageFns<CryptoKey> = {
  encode(message: CryptoKey, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transient !== undefined) {
      TransientCryptoKey.encode(message.transient, writer.uint32(10).fork()).join();
    }
    if (message.unwrapped !== undefined) {
      UnwrappedCryptoKey.encode(message.unwrapped, writer.uint32(18).fork()).join();
    }
    if (message.kmsWrapped !== undefined) {
      KmsWrappedCryptoKey.encode(message.kmsWrapped, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CryptoKey {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCryptoKey();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transient = TransientCryptoKey.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.unwrapped = UnwrappedCryptoKey.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kmsWrapped = KmsWrappedCryptoKey.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CryptoKey {
    return {
      transient: isSet(object.transient) ? TransientCryptoKey.fromJSON(object.transient) : undefined,
      unwrapped: isSet(object.unwrapped) ? UnwrappedCryptoKey.fromJSON(object.unwrapped) : undefined,
      kmsWrapped: isSet(object.kmsWrapped) ? KmsWrappedCryptoKey.fromJSON(object.kmsWrapped) : undefined,
    };
  },

  toJSON(message: CryptoKey): unknown {
    const obj: any = {};
    if (message.transient !== undefined) {
      obj.transient = TransientCryptoKey.toJSON(message.transient);
    }
    if (message.unwrapped !== undefined) {
      obj.unwrapped = UnwrappedCryptoKey.toJSON(message.unwrapped);
    }
    if (message.kmsWrapped !== undefined) {
      obj.kmsWrapped = KmsWrappedCryptoKey.toJSON(message.kmsWrapped);
    }
    return obj;
  },

  create(base?: DeepPartial<CryptoKey>): CryptoKey {
    return CryptoKey.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CryptoKey>): CryptoKey {
    const message = createBaseCryptoKey();
    message.transient = (object.transient !== undefined && object.transient !== null)
      ? TransientCryptoKey.fromPartial(object.transient)
      : undefined;
    message.unwrapped = (object.unwrapped !== undefined && object.unwrapped !== null)
      ? UnwrappedCryptoKey.fromPartial(object.unwrapped)
      : undefined;
    message.kmsWrapped = (object.kmsWrapped !== undefined && object.kmsWrapped !== null)
      ? KmsWrappedCryptoKey.fromPartial(object.kmsWrapped)
      : undefined;
    return message;
  },
};

function createBaseTransientCryptoKey(): TransientCryptoKey {
  return { name: "" };
}

export const TransientCryptoKey: MessageFns<TransientCryptoKey> = {
  encode(message: TransientCryptoKey, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransientCryptoKey {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransientCryptoKey();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransientCryptoKey {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: TransientCryptoKey): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<TransientCryptoKey>): TransientCryptoKey {
    return TransientCryptoKey.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransientCryptoKey>): TransientCryptoKey {
    const message = createBaseTransientCryptoKey();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUnwrappedCryptoKey(): UnwrappedCryptoKey {
  return { key: Buffer.alloc(0) };
}

export const UnwrappedCryptoKey: MessageFns<UnwrappedCryptoKey> = {
  encode(message: UnwrappedCryptoKey, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key.length !== 0) {
      writer.uint32(10).bytes(message.key);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UnwrappedCryptoKey {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUnwrappedCryptoKey();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UnwrappedCryptoKey {
    return { key: isSet(object.key) ? Buffer.from(bytesFromBase64(object.key)) : Buffer.alloc(0) };
  },

  toJSON(message: UnwrappedCryptoKey): unknown {
    const obj: any = {};
    if (message.key.length !== 0) {
      obj.key = base64FromBytes(message.key);
    }
    return obj;
  },

  create(base?: DeepPartial<UnwrappedCryptoKey>): UnwrappedCryptoKey {
    return UnwrappedCryptoKey.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UnwrappedCryptoKey>): UnwrappedCryptoKey {
    const message = createBaseUnwrappedCryptoKey();
    message.key = object.key ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseKmsWrappedCryptoKey(): KmsWrappedCryptoKey {
  return { wrappedKey: Buffer.alloc(0), cryptoKeyName: "" };
}

export const KmsWrappedCryptoKey: MessageFns<KmsWrappedCryptoKey> = {
  encode(message: KmsWrappedCryptoKey, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.wrappedKey.length !== 0) {
      writer.uint32(10).bytes(message.wrappedKey);
    }
    if (message.cryptoKeyName !== "") {
      writer.uint32(18).string(message.cryptoKeyName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KmsWrappedCryptoKey {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKmsWrappedCryptoKey();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.wrappedKey = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cryptoKeyName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KmsWrappedCryptoKey {
    return {
      wrappedKey: isSet(object.wrappedKey) ? Buffer.from(bytesFromBase64(object.wrappedKey)) : Buffer.alloc(0),
      cryptoKeyName: isSet(object.cryptoKeyName) ? globalThis.String(object.cryptoKeyName) : "",
    };
  },

  toJSON(message: KmsWrappedCryptoKey): unknown {
    const obj: any = {};
    if (message.wrappedKey.length !== 0) {
      obj.wrappedKey = base64FromBytes(message.wrappedKey);
    }
    if (message.cryptoKeyName !== "") {
      obj.cryptoKeyName = message.cryptoKeyName;
    }
    return obj;
  },

  create(base?: DeepPartial<KmsWrappedCryptoKey>): KmsWrappedCryptoKey {
    return KmsWrappedCryptoKey.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<KmsWrappedCryptoKey>): KmsWrappedCryptoKey {
    const message = createBaseKmsWrappedCryptoKey();
    message.wrappedKey = object.wrappedKey ?? Buffer.alloc(0);
    message.cryptoKeyName = object.cryptoKeyName ?? "";
    return message;
  },
};

function createBaseDateShiftConfig(): DateShiftConfig {
  return { upperBoundDays: 0, lowerBoundDays: 0, context: undefined, cryptoKey: undefined };
}

export const DateShiftConfig: MessageFns<DateShiftConfig> = {
  encode(message: DateShiftConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.upperBoundDays !== 0) {
      writer.uint32(8).int32(message.upperBoundDays);
    }
    if (message.lowerBoundDays !== 0) {
      writer.uint32(16).int32(message.lowerBoundDays);
    }
    if (message.context !== undefined) {
      FieldId.encode(message.context, writer.uint32(26).fork()).join();
    }
    if (message.cryptoKey !== undefined) {
      CryptoKey.encode(message.cryptoKey, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DateShiftConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDateShiftConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.upperBoundDays = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.lowerBoundDays = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.context = FieldId.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cryptoKey = CryptoKey.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DateShiftConfig {
    return {
      upperBoundDays: isSet(object.upperBoundDays) ? globalThis.Number(object.upperBoundDays) : 0,
      lowerBoundDays: isSet(object.lowerBoundDays) ? globalThis.Number(object.lowerBoundDays) : 0,
      context: isSet(object.context) ? FieldId.fromJSON(object.context) : undefined,
      cryptoKey: isSet(object.cryptoKey) ? CryptoKey.fromJSON(object.cryptoKey) : undefined,
    };
  },

  toJSON(message: DateShiftConfig): unknown {
    const obj: any = {};
    if (message.upperBoundDays !== 0) {
      obj.upperBoundDays = Math.round(message.upperBoundDays);
    }
    if (message.lowerBoundDays !== 0) {
      obj.lowerBoundDays = Math.round(message.lowerBoundDays);
    }
    if (message.context !== undefined) {
      obj.context = FieldId.toJSON(message.context);
    }
    if (message.cryptoKey !== undefined) {
      obj.cryptoKey = CryptoKey.toJSON(message.cryptoKey);
    }
    return obj;
  },

  create(base?: DeepPartial<DateShiftConfig>): DateShiftConfig {
    return DateShiftConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DateShiftConfig>): DateShiftConfig {
    const message = createBaseDateShiftConfig();
    message.upperBoundDays = object.upperBoundDays ?? 0;
    message.lowerBoundDays = object.lowerBoundDays ?? 0;
    message.context = (object.context !== undefined && object.context !== null)
      ? FieldId.fromPartial(object.context)
      : undefined;
    message.cryptoKey = (object.cryptoKey !== undefined && object.cryptoKey !== null)
      ? CryptoKey.fromPartial(object.cryptoKey)
      : undefined;
    return message;
  },
};

function createBaseInfoTypeTransformations(): InfoTypeTransformations {
  return { transformations: [] };
}

export const InfoTypeTransformations: MessageFns<InfoTypeTransformations> = {
  encode(message: InfoTypeTransformations, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.transformations) {
      InfoTypeTransformations_InfoTypeTransformation.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InfoTypeTransformations {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInfoTypeTransformations();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.transformations.push(InfoTypeTransformations_InfoTypeTransformation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InfoTypeTransformations {
    return {
      transformations: globalThis.Array.isArray(object?.transformations)
        ? object.transformations.map((e: any) => InfoTypeTransformations_InfoTypeTransformation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: InfoTypeTransformations): unknown {
    const obj: any = {};
    if (message.transformations?.length) {
      obj.transformations = message.transformations.map((e) =>
        InfoTypeTransformations_InfoTypeTransformation.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<InfoTypeTransformations>): InfoTypeTransformations {
    return InfoTypeTransformations.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InfoTypeTransformations>): InfoTypeTransformations {
    const message = createBaseInfoTypeTransformations();
    message.transformations =
      object.transformations?.map((e) => InfoTypeTransformations_InfoTypeTransformation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseInfoTypeTransformations_InfoTypeTransformation(): InfoTypeTransformations_InfoTypeTransformation {
  return { infoTypes: [], primitiveTransformation: undefined };
}

export const InfoTypeTransformations_InfoTypeTransformation: MessageFns<
  InfoTypeTransformations_InfoTypeTransformation
> = {
  encode(
    message: InfoTypeTransformations_InfoTypeTransformation,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.infoTypes) {
      InfoType.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.primitiveTransformation !== undefined) {
      PrimitiveTransformation.encode(message.primitiveTransformation, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InfoTypeTransformations_InfoTypeTransformation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInfoTypeTransformations_InfoTypeTransformation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoTypes.push(InfoType.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.primitiveTransformation = PrimitiveTransformation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InfoTypeTransformations_InfoTypeTransformation {
    return {
      infoTypes: globalThis.Array.isArray(object?.infoTypes)
        ? object.infoTypes.map((e: any) => InfoType.fromJSON(e))
        : [],
      primitiveTransformation: isSet(object.primitiveTransformation)
        ? PrimitiveTransformation.fromJSON(object.primitiveTransformation)
        : undefined,
    };
  },

  toJSON(message: InfoTypeTransformations_InfoTypeTransformation): unknown {
    const obj: any = {};
    if (message.infoTypes?.length) {
      obj.infoTypes = message.infoTypes.map((e) => InfoType.toJSON(e));
    }
    if (message.primitiveTransformation !== undefined) {
      obj.primitiveTransformation = PrimitiveTransformation.toJSON(message.primitiveTransformation);
    }
    return obj;
  },

  create(
    base?: DeepPartial<InfoTypeTransformations_InfoTypeTransformation>,
  ): InfoTypeTransformations_InfoTypeTransformation {
    return InfoTypeTransformations_InfoTypeTransformation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<InfoTypeTransformations_InfoTypeTransformation>,
  ): InfoTypeTransformations_InfoTypeTransformation {
    const message = createBaseInfoTypeTransformations_InfoTypeTransformation();
    message.infoTypes = object.infoTypes?.map((e) => InfoType.fromPartial(e)) || [];
    message.primitiveTransformation =
      (object.primitiveTransformation !== undefined && object.primitiveTransformation !== null)
        ? PrimitiveTransformation.fromPartial(object.primitiveTransformation)
        : undefined;
    return message;
  },
};

function createBaseFieldTransformation(): FieldTransformation {
  return { fields: [], condition: undefined, primitiveTransformation: undefined, infoTypeTransformations: undefined };
}

export const FieldTransformation: MessageFns<FieldTransformation> = {
  encode(message: FieldTransformation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fields) {
      FieldId.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.condition !== undefined) {
      RecordCondition.encode(message.condition, writer.uint32(26).fork()).join();
    }
    if (message.primitiveTransformation !== undefined) {
      PrimitiveTransformation.encode(message.primitiveTransformation, writer.uint32(34).fork()).join();
    }
    if (message.infoTypeTransformations !== undefined) {
      InfoTypeTransformations.encode(message.infoTypeTransformations, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FieldTransformation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFieldTransformation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fields.push(FieldId.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.condition = RecordCondition.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.primitiveTransformation = PrimitiveTransformation.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.infoTypeTransformations = InfoTypeTransformations.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FieldTransformation {
    return {
      fields: globalThis.Array.isArray(object?.fields) ? object.fields.map((e: any) => FieldId.fromJSON(e)) : [],
      condition: isSet(object.condition) ? RecordCondition.fromJSON(object.condition) : undefined,
      primitiveTransformation: isSet(object.primitiveTransformation)
        ? PrimitiveTransformation.fromJSON(object.primitiveTransformation)
        : undefined,
      infoTypeTransformations: isSet(object.infoTypeTransformations)
        ? InfoTypeTransformations.fromJSON(object.infoTypeTransformations)
        : undefined,
    };
  },

  toJSON(message: FieldTransformation): unknown {
    const obj: any = {};
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => FieldId.toJSON(e));
    }
    if (message.condition !== undefined) {
      obj.condition = RecordCondition.toJSON(message.condition);
    }
    if (message.primitiveTransformation !== undefined) {
      obj.primitiveTransformation = PrimitiveTransformation.toJSON(message.primitiveTransformation);
    }
    if (message.infoTypeTransformations !== undefined) {
      obj.infoTypeTransformations = InfoTypeTransformations.toJSON(message.infoTypeTransformations);
    }
    return obj;
  },

  create(base?: DeepPartial<FieldTransformation>): FieldTransformation {
    return FieldTransformation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FieldTransformation>): FieldTransformation {
    const message = createBaseFieldTransformation();
    message.fields = object.fields?.map((e) => FieldId.fromPartial(e)) || [];
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? RecordCondition.fromPartial(object.condition)
      : undefined;
    message.primitiveTransformation =
      (object.primitiveTransformation !== undefined && object.primitiveTransformation !== null)
        ? PrimitiveTransformation.fromPartial(object.primitiveTransformation)
        : undefined;
    message.infoTypeTransformations =
      (object.infoTypeTransformations !== undefined && object.infoTypeTransformations !== null)
        ? InfoTypeTransformations.fromPartial(object.infoTypeTransformations)
        : undefined;
    return message;
  },
};

function createBaseRecordTransformations(): RecordTransformations {
  return { fieldTransformations: [], recordSuppressions: [] };
}

export const RecordTransformations: MessageFns<RecordTransformations> = {
  encode(message: RecordTransformations, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fieldTransformations) {
      FieldTransformation.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.recordSuppressions) {
      RecordSuppression.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordTransformations {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordTransformations();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fieldTransformations.push(FieldTransformation.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.recordSuppressions.push(RecordSuppression.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordTransformations {
    return {
      fieldTransformations: globalThis.Array.isArray(object?.fieldTransformations)
        ? object.fieldTransformations.map((e: any) => FieldTransformation.fromJSON(e))
        : [],
      recordSuppressions: globalThis.Array.isArray(object?.recordSuppressions)
        ? object.recordSuppressions.map((e: any) => RecordSuppression.fromJSON(e))
        : [],
    };
  },

  toJSON(message: RecordTransformations): unknown {
    const obj: any = {};
    if (message.fieldTransformations?.length) {
      obj.fieldTransformations = message.fieldTransformations.map((e) => FieldTransformation.toJSON(e));
    }
    if (message.recordSuppressions?.length) {
      obj.recordSuppressions = message.recordSuppressions.map((e) => RecordSuppression.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<RecordTransformations>): RecordTransformations {
    return RecordTransformations.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordTransformations>): RecordTransformations {
    const message = createBaseRecordTransformations();
    message.fieldTransformations = object.fieldTransformations?.map((e) => FieldTransformation.fromPartial(e)) || [];
    message.recordSuppressions = object.recordSuppressions?.map((e) => RecordSuppression.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRecordSuppression(): RecordSuppression {
  return { condition: undefined };
}

export const RecordSuppression: MessageFns<RecordSuppression> = {
  encode(message: RecordSuppression, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.condition !== undefined) {
      RecordCondition.encode(message.condition, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordSuppression {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordSuppression();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.condition = RecordCondition.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordSuppression {
    return { condition: isSet(object.condition) ? RecordCondition.fromJSON(object.condition) : undefined };
  },

  toJSON(message: RecordSuppression): unknown {
    const obj: any = {};
    if (message.condition !== undefined) {
      obj.condition = RecordCondition.toJSON(message.condition);
    }
    return obj;
  },

  create(base?: DeepPartial<RecordSuppression>): RecordSuppression {
    return RecordSuppression.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordSuppression>): RecordSuppression {
    const message = createBaseRecordSuppression();
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? RecordCondition.fromPartial(object.condition)
      : undefined;
    return message;
  },
};

function createBaseRecordCondition(): RecordCondition {
  return { expressions: undefined };
}

export const RecordCondition: MessageFns<RecordCondition> = {
  encode(message: RecordCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.expressions !== undefined) {
      RecordCondition_Expressions.encode(message.expressions, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.expressions = RecordCondition_Expressions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordCondition {
    return {
      expressions: isSet(object.expressions) ? RecordCondition_Expressions.fromJSON(object.expressions) : undefined,
    };
  },

  toJSON(message: RecordCondition): unknown {
    const obj: any = {};
    if (message.expressions !== undefined) {
      obj.expressions = RecordCondition_Expressions.toJSON(message.expressions);
    }
    return obj;
  },

  create(base?: DeepPartial<RecordCondition>): RecordCondition {
    return RecordCondition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordCondition>): RecordCondition {
    const message = createBaseRecordCondition();
    message.expressions = (object.expressions !== undefined && object.expressions !== null)
      ? RecordCondition_Expressions.fromPartial(object.expressions)
      : undefined;
    return message;
  },
};

function createBaseRecordCondition_Condition(): RecordCondition_Condition {
  return { field: undefined, operator: 0, value: undefined };
}

export const RecordCondition_Condition: MessageFns<RecordCondition_Condition> = {
  encode(message: RecordCondition_Condition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(10).fork()).join();
    }
    if (message.operator !== 0) {
      writer.uint32(24).int32(message.operator);
    }
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordCondition_Condition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordCondition_Condition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.operator = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordCondition_Condition {
    return {
      field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined,
      operator: isSet(object.operator) ? relationalOperatorFromJSON(object.operator) : 0,
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: RecordCondition_Condition): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    if (message.operator !== 0) {
      obj.operator = relationalOperatorToJSON(message.operator);
    }
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<RecordCondition_Condition>): RecordCondition_Condition {
    return RecordCondition_Condition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordCondition_Condition>): RecordCondition_Condition {
    const message = createBaseRecordCondition_Condition();
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    message.operator = object.operator ?? 0;
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    return message;
  },
};

function createBaseRecordCondition_Conditions(): RecordCondition_Conditions {
  return { conditions: [] };
}

export const RecordCondition_Conditions: MessageFns<RecordCondition_Conditions> = {
  encode(message: RecordCondition_Conditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.conditions) {
      RecordCondition_Condition.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordCondition_Conditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordCondition_Conditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conditions.push(RecordCondition_Condition.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordCondition_Conditions {
    return {
      conditions: globalThis.Array.isArray(object?.conditions)
        ? object.conditions.map((e: any) => RecordCondition_Condition.fromJSON(e))
        : [],
    };
  },

  toJSON(message: RecordCondition_Conditions): unknown {
    const obj: any = {};
    if (message.conditions?.length) {
      obj.conditions = message.conditions.map((e) => RecordCondition_Condition.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<RecordCondition_Conditions>): RecordCondition_Conditions {
    return RecordCondition_Conditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordCondition_Conditions>): RecordCondition_Conditions {
    const message = createBaseRecordCondition_Conditions();
    message.conditions = object.conditions?.map((e) => RecordCondition_Condition.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRecordCondition_Expressions(): RecordCondition_Expressions {
  return { logicalOperator: 0, conditions: undefined };
}

export const RecordCondition_Expressions: MessageFns<RecordCondition_Expressions> = {
  encode(message: RecordCondition_Expressions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.logicalOperator !== 0) {
      writer.uint32(8).int32(message.logicalOperator);
    }
    if (message.conditions !== undefined) {
      RecordCondition_Conditions.encode(message.conditions, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordCondition_Expressions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordCondition_Expressions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.logicalOperator = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.conditions = RecordCondition_Conditions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordCondition_Expressions {
    return {
      logicalOperator: isSet(object.logicalOperator)
        ? recordCondition_Expressions_LogicalOperatorFromJSON(object.logicalOperator)
        : 0,
      conditions: isSet(object.conditions) ? RecordCondition_Conditions.fromJSON(object.conditions) : undefined,
    };
  },

  toJSON(message: RecordCondition_Expressions): unknown {
    const obj: any = {};
    if (message.logicalOperator !== 0) {
      obj.logicalOperator = recordCondition_Expressions_LogicalOperatorToJSON(message.logicalOperator);
    }
    if (message.conditions !== undefined) {
      obj.conditions = RecordCondition_Conditions.toJSON(message.conditions);
    }
    return obj;
  },

  create(base?: DeepPartial<RecordCondition_Expressions>): RecordCondition_Expressions {
    return RecordCondition_Expressions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordCondition_Expressions>): RecordCondition_Expressions {
    const message = createBaseRecordCondition_Expressions();
    message.logicalOperator = object.logicalOperator ?? 0;
    message.conditions = (object.conditions !== undefined && object.conditions !== null)
      ? RecordCondition_Conditions.fromPartial(object.conditions)
      : undefined;
    return message;
  },
};

function createBaseTransformationOverview(): TransformationOverview {
  return { transformedBytes: Long.ZERO, transformationSummaries: [] };
}

export const TransformationOverview: MessageFns<TransformationOverview> = {
  encode(message: TransformationOverview, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.transformedBytes.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.transformedBytes.toString());
    }
    for (const v of message.transformationSummaries) {
      TransformationSummary.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationOverview {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationOverview();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 16) {
            break;
          }

          message.transformedBytes = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transformationSummaries.push(TransformationSummary.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationOverview {
    return {
      transformedBytes: isSet(object.transformedBytes) ? Long.fromValue(object.transformedBytes) : Long.ZERO,
      transformationSummaries: globalThis.Array.isArray(object?.transformationSummaries)
        ? object.transformationSummaries.map((e: any) => TransformationSummary.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TransformationOverview): unknown {
    const obj: any = {};
    if (!message.transformedBytes.equals(Long.ZERO)) {
      obj.transformedBytes = (message.transformedBytes || Long.ZERO).toString();
    }
    if (message.transformationSummaries?.length) {
      obj.transformationSummaries = message.transformationSummaries.map((e) => TransformationSummary.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationOverview>): TransformationOverview {
    return TransformationOverview.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationOverview>): TransformationOverview {
    const message = createBaseTransformationOverview();
    message.transformedBytes = (object.transformedBytes !== undefined && object.transformedBytes !== null)
      ? Long.fromValue(object.transformedBytes)
      : Long.ZERO;
    message.transformationSummaries =
      object.transformationSummaries?.map((e) => TransformationSummary.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTransformationSummary(): TransformationSummary {
  return {
    infoType: undefined,
    field: undefined,
    transformation: undefined,
    fieldTransformations: [],
    recordSuppress: undefined,
    results: [],
    transformedBytes: Long.ZERO,
  };
}

export const TransformationSummary: MessageFns<TransformationSummary> = {
  encode(message: TransformationSummary, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (message.field !== undefined) {
      FieldId.encode(message.field, writer.uint32(18).fork()).join();
    }
    if (message.transformation !== undefined) {
      PrimitiveTransformation.encode(message.transformation, writer.uint32(26).fork()).join();
    }
    for (const v of message.fieldTransformations) {
      FieldTransformation.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.recordSuppress !== undefined) {
      RecordSuppression.encode(message.recordSuppress, writer.uint32(50).fork()).join();
    }
    for (const v of message.results) {
      TransformationSummary_SummaryResult.encode(v!, writer.uint32(34).fork()).join();
    }
    if (!message.transformedBytes.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.transformedBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationSummary {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationSummary();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.field = FieldId.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transformation = PrimitiveTransformation.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.fieldTransformations.push(FieldTransformation.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.recordSuppress = RecordSuppression.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.results.push(TransformationSummary_SummaryResult.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.transformedBytes = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationSummary {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      field: isSet(object.field) ? FieldId.fromJSON(object.field) : undefined,
      transformation: isSet(object.transformation)
        ? PrimitiveTransformation.fromJSON(object.transformation)
        : undefined,
      fieldTransformations: globalThis.Array.isArray(object?.fieldTransformations)
        ? object.fieldTransformations.map((e: any) => FieldTransformation.fromJSON(e))
        : [],
      recordSuppress: isSet(object.recordSuppress) ? RecordSuppression.fromJSON(object.recordSuppress) : undefined,
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => TransformationSummary_SummaryResult.fromJSON(e))
        : [],
      transformedBytes: isSet(object.transformedBytes) ? Long.fromValue(object.transformedBytes) : Long.ZERO,
    };
  },

  toJSON(message: TransformationSummary): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.field !== undefined) {
      obj.field = FieldId.toJSON(message.field);
    }
    if (message.transformation !== undefined) {
      obj.transformation = PrimitiveTransformation.toJSON(message.transformation);
    }
    if (message.fieldTransformations?.length) {
      obj.fieldTransformations = message.fieldTransformations.map((e) => FieldTransformation.toJSON(e));
    }
    if (message.recordSuppress !== undefined) {
      obj.recordSuppress = RecordSuppression.toJSON(message.recordSuppress);
    }
    if (message.results?.length) {
      obj.results = message.results.map((e) => TransformationSummary_SummaryResult.toJSON(e));
    }
    if (!message.transformedBytes.equals(Long.ZERO)) {
      obj.transformedBytes = (message.transformedBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationSummary>): TransformationSummary {
    return TransformationSummary.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationSummary>): TransformationSummary {
    const message = createBaseTransformationSummary();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.field = (object.field !== undefined && object.field !== null)
      ? FieldId.fromPartial(object.field)
      : undefined;
    message.transformation = (object.transformation !== undefined && object.transformation !== null)
      ? PrimitiveTransformation.fromPartial(object.transformation)
      : undefined;
    message.fieldTransformations = object.fieldTransformations?.map((e) => FieldTransformation.fromPartial(e)) || [];
    message.recordSuppress = (object.recordSuppress !== undefined && object.recordSuppress !== null)
      ? RecordSuppression.fromPartial(object.recordSuppress)
      : undefined;
    message.results = object.results?.map((e) => TransformationSummary_SummaryResult.fromPartial(e)) || [];
    message.transformedBytes = (object.transformedBytes !== undefined && object.transformedBytes !== null)
      ? Long.fromValue(object.transformedBytes)
      : Long.ZERO;
    return message;
  },
};

function createBaseTransformationSummary_SummaryResult(): TransformationSummary_SummaryResult {
  return { count: Long.ZERO, code: 0, details: "" };
}

export const TransformationSummary_SummaryResult: MessageFns<TransformationSummary_SummaryResult> = {
  encode(message: TransformationSummary_SummaryResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.count.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.count.toString());
    }
    if (message.code !== 0) {
      writer.uint32(16).int32(message.code);
    }
    if (message.details !== "") {
      writer.uint32(26).string(message.details);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationSummary_SummaryResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationSummary_SummaryResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.count = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.code = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.details = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationSummary_SummaryResult {
    return {
      count: isSet(object.count) ? Long.fromValue(object.count) : Long.ZERO,
      code: isSet(object.code) ? transformationSummary_TransformationResultCodeFromJSON(object.code) : 0,
      details: isSet(object.details) ? globalThis.String(object.details) : "",
    };
  },

  toJSON(message: TransformationSummary_SummaryResult): unknown {
    const obj: any = {};
    if (!message.count.equals(Long.ZERO)) {
      obj.count = (message.count || Long.ZERO).toString();
    }
    if (message.code !== 0) {
      obj.code = transformationSummary_TransformationResultCodeToJSON(message.code);
    }
    if (message.details !== "") {
      obj.details = message.details;
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationSummary_SummaryResult>): TransformationSummary_SummaryResult {
    return TransformationSummary_SummaryResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationSummary_SummaryResult>): TransformationSummary_SummaryResult {
    const message = createBaseTransformationSummary_SummaryResult();
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : Long.ZERO;
    message.code = object.code ?? 0;
    message.details = object.details ?? "";
    return message;
  },
};

function createBaseTransformationDescription(): TransformationDescription {
  return { type: 0, description: "", condition: "", infoType: undefined };
}

export const TransformationDescription: MessageFns<TransformationDescription> = {
  encode(message: TransformationDescription, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.condition !== "") {
      writer.uint32(26).string(message.condition);
    }
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationDescription {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationDescription();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.condition = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationDescription {
    return {
      type: isSet(object.type) ? transformationTypeFromJSON(object.type) : 0,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      condition: isSet(object.condition) ? globalThis.String(object.condition) : "",
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
    };
  },

  toJSON(message: TransformationDescription): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = transformationTypeToJSON(message.type);
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.condition !== "") {
      obj.condition = message.condition;
    }
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationDescription>): TransformationDescription {
    return TransformationDescription.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationDescription>): TransformationDescription {
    const message = createBaseTransformationDescription();
    message.type = object.type ?? 0;
    message.description = object.description ?? "";
    message.condition = object.condition ?? "";
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    return message;
  },
};

function createBaseTransformationDetails(): TransformationDetails {
  return {
    resourceName: "",
    containerName: "",
    transformation: [],
    statusDetails: undefined,
    transformedBytes: Long.ZERO,
    transformationLocation: undefined,
  };
}

export const TransformationDetails: MessageFns<TransformationDetails> = {
  encode(message: TransformationDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resourceName !== "") {
      writer.uint32(10).string(message.resourceName);
    }
    if (message.containerName !== "") {
      writer.uint32(18).string(message.containerName);
    }
    for (const v of message.transformation) {
      TransformationDescription.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.statusDetails !== undefined) {
      TransformationResultStatus.encode(message.statusDetails, writer.uint32(34).fork()).join();
    }
    if (!message.transformedBytes.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.transformedBytes.toString());
    }
    if (message.transformationLocation !== undefined) {
      TransformationLocation.encode(message.transformationLocation, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resourceName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.containerName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transformation.push(TransformationDescription.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.statusDetails = TransformationResultStatus.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.transformedBytes = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.transformationLocation = TransformationLocation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationDetails {
    return {
      resourceName: isSet(object.resourceName) ? globalThis.String(object.resourceName) : "",
      containerName: isSet(object.containerName) ? globalThis.String(object.containerName) : "",
      transformation: globalThis.Array.isArray(object?.transformation)
        ? object.transformation.map((e: any) => TransformationDescription.fromJSON(e))
        : [],
      statusDetails: isSet(object.statusDetails)
        ? TransformationResultStatus.fromJSON(object.statusDetails)
        : undefined,
      transformedBytes: isSet(object.transformedBytes) ? Long.fromValue(object.transformedBytes) : Long.ZERO,
      transformationLocation: isSet(object.transformationLocation)
        ? TransformationLocation.fromJSON(object.transformationLocation)
        : undefined,
    };
  },

  toJSON(message: TransformationDetails): unknown {
    const obj: any = {};
    if (message.resourceName !== "") {
      obj.resourceName = message.resourceName;
    }
    if (message.containerName !== "") {
      obj.containerName = message.containerName;
    }
    if (message.transformation?.length) {
      obj.transformation = message.transformation.map((e) => TransformationDescription.toJSON(e));
    }
    if (message.statusDetails !== undefined) {
      obj.statusDetails = TransformationResultStatus.toJSON(message.statusDetails);
    }
    if (!message.transformedBytes.equals(Long.ZERO)) {
      obj.transformedBytes = (message.transformedBytes || Long.ZERO).toString();
    }
    if (message.transformationLocation !== undefined) {
      obj.transformationLocation = TransformationLocation.toJSON(message.transformationLocation);
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationDetails>): TransformationDetails {
    return TransformationDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationDetails>): TransformationDetails {
    const message = createBaseTransformationDetails();
    message.resourceName = object.resourceName ?? "";
    message.containerName = object.containerName ?? "";
    message.transformation = object.transformation?.map((e) => TransformationDescription.fromPartial(e)) || [];
    message.statusDetails = (object.statusDetails !== undefined && object.statusDetails !== null)
      ? TransformationResultStatus.fromPartial(object.statusDetails)
      : undefined;
    message.transformedBytes = (object.transformedBytes !== undefined && object.transformedBytes !== null)
      ? Long.fromValue(object.transformedBytes)
      : Long.ZERO;
    message.transformationLocation =
      (object.transformationLocation !== undefined && object.transformationLocation !== null)
        ? TransformationLocation.fromPartial(object.transformationLocation)
        : undefined;
    return message;
  },
};

function createBaseTransformationLocation(): TransformationLocation {
  return { findingId: undefined, recordTransformation: undefined, containerType: 0 };
}

export const TransformationLocation: MessageFns<TransformationLocation> = {
  encode(message: TransformationLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.findingId !== undefined) {
      writer.uint32(10).string(message.findingId);
    }
    if (message.recordTransformation !== undefined) {
      RecordTransformation.encode(message.recordTransformation, writer.uint32(18).fork()).join();
    }
    if (message.containerType !== 0) {
      writer.uint32(24).int32(message.containerType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.findingId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.recordTransformation = RecordTransformation.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.containerType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationLocation {
    return {
      findingId: isSet(object.findingId) ? globalThis.String(object.findingId) : undefined,
      recordTransformation: isSet(object.recordTransformation)
        ? RecordTransformation.fromJSON(object.recordTransformation)
        : undefined,
      containerType: isSet(object.containerType) ? transformationContainerTypeFromJSON(object.containerType) : 0,
    };
  },

  toJSON(message: TransformationLocation): unknown {
    const obj: any = {};
    if (message.findingId !== undefined) {
      obj.findingId = message.findingId;
    }
    if (message.recordTransformation !== undefined) {
      obj.recordTransformation = RecordTransformation.toJSON(message.recordTransformation);
    }
    if (message.containerType !== 0) {
      obj.containerType = transformationContainerTypeToJSON(message.containerType);
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationLocation>): TransformationLocation {
    return TransformationLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationLocation>): TransformationLocation {
    const message = createBaseTransformationLocation();
    message.findingId = object.findingId ?? undefined;
    message.recordTransformation = (object.recordTransformation !== undefined && object.recordTransformation !== null)
      ? RecordTransformation.fromPartial(object.recordTransformation)
      : undefined;
    message.containerType = object.containerType ?? 0;
    return message;
  },
};

function createBaseRecordTransformation(): RecordTransformation {
  return { fieldId: undefined, containerTimestamp: undefined, containerVersion: "" };
}

export const RecordTransformation: MessageFns<RecordTransformation> = {
  encode(message: RecordTransformation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fieldId !== undefined) {
      FieldId.encode(message.fieldId, writer.uint32(10).fork()).join();
    }
    if (message.containerTimestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.containerTimestamp), writer.uint32(18).fork()).join();
    }
    if (message.containerVersion !== "") {
      writer.uint32(26).string(message.containerVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecordTransformation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecordTransformation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fieldId = FieldId.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.containerTimestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.containerVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecordTransformation {
    return {
      fieldId: isSet(object.fieldId) ? FieldId.fromJSON(object.fieldId) : undefined,
      containerTimestamp: isSet(object.containerTimestamp) ? fromJsonTimestamp(object.containerTimestamp) : undefined,
      containerVersion: isSet(object.containerVersion) ? globalThis.String(object.containerVersion) : "",
    };
  },

  toJSON(message: RecordTransformation): unknown {
    const obj: any = {};
    if (message.fieldId !== undefined) {
      obj.fieldId = FieldId.toJSON(message.fieldId);
    }
    if (message.containerTimestamp !== undefined) {
      obj.containerTimestamp = message.containerTimestamp.toISOString();
    }
    if (message.containerVersion !== "") {
      obj.containerVersion = message.containerVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<RecordTransformation>): RecordTransformation {
    return RecordTransformation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RecordTransformation>): RecordTransformation {
    const message = createBaseRecordTransformation();
    message.fieldId = (object.fieldId !== undefined && object.fieldId !== null)
      ? FieldId.fromPartial(object.fieldId)
      : undefined;
    message.containerTimestamp = object.containerTimestamp ?? undefined;
    message.containerVersion = object.containerVersion ?? "";
    return message;
  },
};

function createBaseTransformationResultStatus(): TransformationResultStatus {
  return { resultStatusType: 0, details: undefined };
}

export const TransformationResultStatus: MessageFns<TransformationResultStatus> = {
  encode(message: TransformationResultStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resultStatusType !== 0) {
      writer.uint32(8).int32(message.resultStatusType);
    }
    if (message.details !== undefined) {
      Status.encode(message.details, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationResultStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationResultStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.resultStatusType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.details = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationResultStatus {
    return {
      resultStatusType: isSet(object.resultStatusType)
        ? transformationResultStatusTypeFromJSON(object.resultStatusType)
        : 0,
      details: isSet(object.details) ? Status.fromJSON(object.details) : undefined,
    };
  },

  toJSON(message: TransformationResultStatus): unknown {
    const obj: any = {};
    if (message.resultStatusType !== 0) {
      obj.resultStatusType = transformationResultStatusTypeToJSON(message.resultStatusType);
    }
    if (message.details !== undefined) {
      obj.details = Status.toJSON(message.details);
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationResultStatus>): TransformationResultStatus {
    return TransformationResultStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationResultStatus>): TransformationResultStatus {
    const message = createBaseTransformationResultStatus();
    message.resultStatusType = object.resultStatusType ?? 0;
    message.details = (object.details !== undefined && object.details !== null)
      ? Status.fromPartial(object.details)
      : undefined;
    return message;
  },
};

function createBaseTransformationDetailsStorageConfig(): TransformationDetailsStorageConfig {
  return { table: undefined };
}

export const TransformationDetailsStorageConfig: MessageFns<TransformationDetailsStorageConfig> = {
  encode(message: TransformationDetailsStorageConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== undefined) {
      BigQueryTable.encode(message.table, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationDetailsStorageConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationDetailsStorageConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = BigQueryTable.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationDetailsStorageConfig {
    return { table: isSet(object.table) ? BigQueryTable.fromJSON(object.table) : undefined };
  },

  toJSON(message: TransformationDetailsStorageConfig): unknown {
    const obj: any = {};
    if (message.table !== undefined) {
      obj.table = BigQueryTable.toJSON(message.table);
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationDetailsStorageConfig>): TransformationDetailsStorageConfig {
    return TransformationDetailsStorageConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationDetailsStorageConfig>): TransformationDetailsStorageConfig {
    const message = createBaseTransformationDetailsStorageConfig();
    message.table = (object.table !== undefined && object.table !== null)
      ? BigQueryTable.fromPartial(object.table)
      : undefined;
    return message;
  },
};

function createBaseSchedule(): Schedule {
  return { recurrencePeriodDuration: undefined };
}

export const Schedule: MessageFns<Schedule> = {
  encode(message: Schedule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recurrencePeriodDuration !== undefined) {
      Duration.encode(message.recurrencePeriodDuration, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schedule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchedule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recurrencePeriodDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schedule {
    return {
      recurrencePeriodDuration: isSet(object.recurrencePeriodDuration)
        ? Duration.fromJSON(object.recurrencePeriodDuration)
        : undefined,
    };
  },

  toJSON(message: Schedule): unknown {
    const obj: any = {};
    if (message.recurrencePeriodDuration !== undefined) {
      obj.recurrencePeriodDuration = Duration.toJSON(message.recurrencePeriodDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<Schedule>): Schedule {
    return Schedule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Schedule>): Schedule {
    const message = createBaseSchedule();
    message.recurrencePeriodDuration =
      (object.recurrencePeriodDuration !== undefined && object.recurrencePeriodDuration !== null)
        ? Duration.fromPartial(object.recurrencePeriodDuration)
        : undefined;
    return message;
  },
};

function createBaseManual(): Manual {
  return {};
}

export const Manual: MessageFns<Manual> = {
  encode(_: Manual, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Manual {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseManual();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Manual {
    return {};
  },

  toJSON(_: Manual): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Manual>): Manual {
    return Manual.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Manual>): Manual {
    const message = createBaseManual();
    return message;
  },
};

function createBaseInspectTemplate(): InspectTemplate {
  return {
    name: "",
    displayName: "",
    description: "",
    createTime: undefined,
    updateTime: undefined,
    inspectConfig: undefined,
  };
}

export const InspectTemplate: MessageFns<InspectTemplate> = {
  encode(message: InspectTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectTemplate {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
    };
  },

  toJSON(message: InspectTemplate): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<InspectTemplate>): InspectTemplate {
    return InspectTemplate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectTemplate>): InspectTemplate {
    const message = createBaseInspectTemplate();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    return message;
  },
};

function createBaseDeidentifyTemplate(): DeidentifyTemplate {
  return {
    name: "",
    displayName: "",
    description: "",
    createTime: undefined,
    updateTime: undefined,
    deidentifyConfig: undefined,
  };
}

export const DeidentifyTemplate: MessageFns<DeidentifyTemplate> = {
  encode(message: DeidentifyTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    if (message.deidentifyConfig !== undefined) {
      DeidentifyConfig.encode(message.deidentifyConfig, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeidentifyTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeidentifyTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.deidentifyConfig = DeidentifyConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeidentifyTemplate {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      deidentifyConfig: isSet(object.deidentifyConfig) ? DeidentifyConfig.fromJSON(object.deidentifyConfig) : undefined,
    };
  },

  toJSON(message: DeidentifyTemplate): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.deidentifyConfig !== undefined) {
      obj.deidentifyConfig = DeidentifyConfig.toJSON(message.deidentifyConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<DeidentifyTemplate>): DeidentifyTemplate {
    return DeidentifyTemplate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeidentifyTemplate>): DeidentifyTemplate {
    const message = createBaseDeidentifyTemplate();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.deidentifyConfig = (object.deidentifyConfig !== undefined && object.deidentifyConfig !== null)
      ? DeidentifyConfig.fromPartial(object.deidentifyConfig)
      : undefined;
    return message;
  },
};

function createBaseError(): Error {
  return { details: undefined, timestamps: [], extraInfo: 0 };
}

export const Error: MessageFns<Error> = {
  encode(message: Error, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.details !== undefined) {
      Status.encode(message.details, writer.uint32(10).fork()).join();
    }
    for (const v of message.timestamps) {
      Timestamp.encode(toTimestamp(v!), writer.uint32(18).fork()).join();
    }
    if (message.extraInfo !== 0) {
      writer.uint32(32).int32(message.extraInfo);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Error {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.details = Status.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.timestamps.push(fromTimestamp(Timestamp.decode(reader, reader.uint32())));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.extraInfo = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Error {
    return {
      details: isSet(object.details) ? Status.fromJSON(object.details) : undefined,
      timestamps: globalThis.Array.isArray(object?.timestamps)
        ? object.timestamps.map((e: any) => fromJsonTimestamp(e))
        : [],
      extraInfo: isSet(object.extraInfo) ? error_ErrorExtraInfoFromJSON(object.extraInfo) : 0,
    };
  },

  toJSON(message: Error): unknown {
    const obj: any = {};
    if (message.details !== undefined) {
      obj.details = Status.toJSON(message.details);
    }
    if (message.timestamps?.length) {
      obj.timestamps = message.timestamps.map((e) => e.toISOString());
    }
    if (message.extraInfo !== 0) {
      obj.extraInfo = error_ErrorExtraInfoToJSON(message.extraInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<Error>): Error {
    return Error.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Error>): Error {
    const message = createBaseError();
    message.details = (object.details !== undefined && object.details !== null)
      ? Status.fromPartial(object.details)
      : undefined;
    message.timestamps = object.timestamps?.map((e) => e) || [];
    message.extraInfo = object.extraInfo ?? 0;
    return message;
  },
};

function createBaseJobTrigger(): JobTrigger {
  return {
    name: "",
    displayName: "",
    description: "",
    inspectJob: undefined,
    triggers: [],
    errors: [],
    createTime: undefined,
    updateTime: undefined,
    lastRunTime: undefined,
    status: 0,
  };
}

export const JobTrigger: MessageFns<JobTrigger> = {
  encode(message: JobTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.inspectJob !== undefined) {
      InspectJobConfig.encode(message.inspectJob, writer.uint32(34).fork()).join();
    }
    for (const v of message.triggers) {
      JobTrigger_Trigger.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(66).fork()).join();
    }
    if (message.lastRunTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastRunTime), writer.uint32(74).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(80).int32(message.status);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.inspectJob = InspectJobConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.triggers.push(JobTrigger_Trigger.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.lastRunTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobTrigger {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      inspectJob: isSet(object.inspectJob) ? InspectJobConfig.fromJSON(object.inspectJob) : undefined,
      triggers: globalThis.Array.isArray(object?.triggers)
        ? object.triggers.map((e: any) => JobTrigger_Trigger.fromJSON(e))
        : [],
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      lastRunTime: isSet(object.lastRunTime) ? fromJsonTimestamp(object.lastRunTime) : undefined,
      status: isSet(object.status) ? jobTrigger_StatusFromJSON(object.status) : 0,
    };
  },

  toJSON(message: JobTrigger): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.inspectJob !== undefined) {
      obj.inspectJob = InspectJobConfig.toJSON(message.inspectJob);
    }
    if (message.triggers?.length) {
      obj.triggers = message.triggers.map((e) => JobTrigger_Trigger.toJSON(e));
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.lastRunTime !== undefined) {
      obj.lastRunTime = message.lastRunTime.toISOString();
    }
    if (message.status !== 0) {
      obj.status = jobTrigger_StatusToJSON(message.status);
    }
    return obj;
  },

  create(base?: DeepPartial<JobTrigger>): JobTrigger {
    return JobTrigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobTrigger>): JobTrigger {
    const message = createBaseJobTrigger();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.inspectJob = (object.inspectJob !== undefined && object.inspectJob !== null)
      ? InspectJobConfig.fromPartial(object.inspectJob)
      : undefined;
    message.triggers = object.triggers?.map((e) => JobTrigger_Trigger.fromPartial(e)) || [];
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.lastRunTime = object.lastRunTime ?? undefined;
    message.status = object.status ?? 0;
    return message;
  },
};

function createBaseJobTrigger_Trigger(): JobTrigger_Trigger {
  return { schedule: undefined, manual: undefined };
}

export const JobTrigger_Trigger: MessageFns<JobTrigger_Trigger> = {
  encode(message: JobTrigger_Trigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schedule !== undefined) {
      Schedule.encode(message.schedule, writer.uint32(10).fork()).join();
    }
    if (message.manual !== undefined) {
      Manual.encode(message.manual, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobTrigger_Trigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobTrigger_Trigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schedule = Schedule.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.manual = Manual.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobTrigger_Trigger {
    return {
      schedule: isSet(object.schedule) ? Schedule.fromJSON(object.schedule) : undefined,
      manual: isSet(object.manual) ? Manual.fromJSON(object.manual) : undefined,
    };
  },

  toJSON(message: JobTrigger_Trigger): unknown {
    const obj: any = {};
    if (message.schedule !== undefined) {
      obj.schedule = Schedule.toJSON(message.schedule);
    }
    if (message.manual !== undefined) {
      obj.manual = Manual.toJSON(message.manual);
    }
    return obj;
  },

  create(base?: DeepPartial<JobTrigger_Trigger>): JobTrigger_Trigger {
    return JobTrigger_Trigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobTrigger_Trigger>): JobTrigger_Trigger {
    const message = createBaseJobTrigger_Trigger();
    message.schedule = (object.schedule !== undefined && object.schedule !== null)
      ? Schedule.fromPartial(object.schedule)
      : undefined;
    message.manual = (object.manual !== undefined && object.manual !== null)
      ? Manual.fromPartial(object.manual)
      : undefined;
    return message;
  },
};

function createBaseAction(): Action {
  return {
    saveFindings: undefined,
    pubSub: undefined,
    publishSummaryToCscc: undefined,
    publishFindingsToCloudDataCatalog: undefined,
    deidentify: undefined,
    jobNotificationEmails: undefined,
    publishToStackdriver: undefined,
  };
}

export const Action: MessageFns<Action> = {
  encode(message: Action, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.saveFindings !== undefined) {
      Action_SaveFindings.encode(message.saveFindings, writer.uint32(10).fork()).join();
    }
    if (message.pubSub !== undefined) {
      Action_PublishToPubSub.encode(message.pubSub, writer.uint32(18).fork()).join();
    }
    if (message.publishSummaryToCscc !== undefined) {
      Action_PublishSummaryToCscc.encode(message.publishSummaryToCscc, writer.uint32(26).fork()).join();
    }
    if (message.publishFindingsToCloudDataCatalog !== undefined) {
      Action_PublishFindingsToCloudDataCatalog.encode(
        message.publishFindingsToCloudDataCatalog,
        writer.uint32(42).fork(),
      ).join();
    }
    if (message.deidentify !== undefined) {
      Action_Deidentify.encode(message.deidentify, writer.uint32(58).fork()).join();
    }
    if (message.jobNotificationEmails !== undefined) {
      Action_JobNotificationEmails.encode(message.jobNotificationEmails, writer.uint32(66).fork()).join();
    }
    if (message.publishToStackdriver !== undefined) {
      Action_PublishToStackdriver.encode(message.publishToStackdriver, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.saveFindings = Action_SaveFindings.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pubSub = Action_PublishToPubSub.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.publishSummaryToCscc = Action_PublishSummaryToCscc.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.publishFindingsToCloudDataCatalog = Action_PublishFindingsToCloudDataCatalog.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.deidentify = Action_Deidentify.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.jobNotificationEmails = Action_JobNotificationEmails.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.publishToStackdriver = Action_PublishToStackdriver.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action {
    return {
      saveFindings: isSet(object.saveFindings) ? Action_SaveFindings.fromJSON(object.saveFindings) : undefined,
      pubSub: isSet(object.pubSub) ? Action_PublishToPubSub.fromJSON(object.pubSub) : undefined,
      publishSummaryToCscc: isSet(object.publishSummaryToCscc)
        ? Action_PublishSummaryToCscc.fromJSON(object.publishSummaryToCscc)
        : undefined,
      publishFindingsToCloudDataCatalog: isSet(object.publishFindingsToCloudDataCatalog)
        ? Action_PublishFindingsToCloudDataCatalog.fromJSON(object.publishFindingsToCloudDataCatalog)
        : undefined,
      deidentify: isSet(object.deidentify) ? Action_Deidentify.fromJSON(object.deidentify) : undefined,
      jobNotificationEmails: isSet(object.jobNotificationEmails)
        ? Action_JobNotificationEmails.fromJSON(object.jobNotificationEmails)
        : undefined,
      publishToStackdriver: isSet(object.publishToStackdriver)
        ? Action_PublishToStackdriver.fromJSON(object.publishToStackdriver)
        : undefined,
    };
  },

  toJSON(message: Action): unknown {
    const obj: any = {};
    if (message.saveFindings !== undefined) {
      obj.saveFindings = Action_SaveFindings.toJSON(message.saveFindings);
    }
    if (message.pubSub !== undefined) {
      obj.pubSub = Action_PublishToPubSub.toJSON(message.pubSub);
    }
    if (message.publishSummaryToCscc !== undefined) {
      obj.publishSummaryToCscc = Action_PublishSummaryToCscc.toJSON(message.publishSummaryToCscc);
    }
    if (message.publishFindingsToCloudDataCatalog !== undefined) {
      obj.publishFindingsToCloudDataCatalog = Action_PublishFindingsToCloudDataCatalog.toJSON(
        message.publishFindingsToCloudDataCatalog,
      );
    }
    if (message.deidentify !== undefined) {
      obj.deidentify = Action_Deidentify.toJSON(message.deidentify);
    }
    if (message.jobNotificationEmails !== undefined) {
      obj.jobNotificationEmails = Action_JobNotificationEmails.toJSON(message.jobNotificationEmails);
    }
    if (message.publishToStackdriver !== undefined) {
      obj.publishToStackdriver = Action_PublishToStackdriver.toJSON(message.publishToStackdriver);
    }
    return obj;
  },

  create(base?: DeepPartial<Action>): Action {
    return Action.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action>): Action {
    const message = createBaseAction();
    message.saveFindings = (object.saveFindings !== undefined && object.saveFindings !== null)
      ? Action_SaveFindings.fromPartial(object.saveFindings)
      : undefined;
    message.pubSub = (object.pubSub !== undefined && object.pubSub !== null)
      ? Action_PublishToPubSub.fromPartial(object.pubSub)
      : undefined;
    message.publishSummaryToCscc = (object.publishSummaryToCscc !== undefined && object.publishSummaryToCscc !== null)
      ? Action_PublishSummaryToCscc.fromPartial(object.publishSummaryToCscc)
      : undefined;
    message.publishFindingsToCloudDataCatalog =
      (object.publishFindingsToCloudDataCatalog !== undefined && object.publishFindingsToCloudDataCatalog !== null)
        ? Action_PublishFindingsToCloudDataCatalog.fromPartial(object.publishFindingsToCloudDataCatalog)
        : undefined;
    message.deidentify = (object.deidentify !== undefined && object.deidentify !== null)
      ? Action_Deidentify.fromPartial(object.deidentify)
      : undefined;
    message.jobNotificationEmails =
      (object.jobNotificationEmails !== undefined && object.jobNotificationEmails !== null)
        ? Action_JobNotificationEmails.fromPartial(object.jobNotificationEmails)
        : undefined;
    message.publishToStackdriver = (object.publishToStackdriver !== undefined && object.publishToStackdriver !== null)
      ? Action_PublishToStackdriver.fromPartial(object.publishToStackdriver)
      : undefined;
    return message;
  },
};

function createBaseAction_SaveFindings(): Action_SaveFindings {
  return { outputConfig: undefined };
}

export const Action_SaveFindings: MessageFns<Action_SaveFindings> = {
  encode(message: Action_SaveFindings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputConfig !== undefined) {
      OutputStorageConfig.encode(message.outputConfig, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_SaveFindings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_SaveFindings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputConfig = OutputStorageConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_SaveFindings {
    return { outputConfig: isSet(object.outputConfig) ? OutputStorageConfig.fromJSON(object.outputConfig) : undefined };
  },

  toJSON(message: Action_SaveFindings): unknown {
    const obj: any = {};
    if (message.outputConfig !== undefined) {
      obj.outputConfig = OutputStorageConfig.toJSON(message.outputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<Action_SaveFindings>): Action_SaveFindings {
    return Action_SaveFindings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_SaveFindings>): Action_SaveFindings {
    const message = createBaseAction_SaveFindings();
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? OutputStorageConfig.fromPartial(object.outputConfig)
      : undefined;
    return message;
  },
};

function createBaseAction_PublishToPubSub(): Action_PublishToPubSub {
  return { topic: "" };
}

export const Action_PublishToPubSub: MessageFns<Action_PublishToPubSub> = {
  encode(message: Action_PublishToPubSub, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_PublishToPubSub {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_PublishToPubSub();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_PublishToPubSub {
    return { topic: isSet(object.topic) ? globalThis.String(object.topic) : "" };
  },

  toJSON(message: Action_PublishToPubSub): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    return obj;
  },

  create(base?: DeepPartial<Action_PublishToPubSub>): Action_PublishToPubSub {
    return Action_PublishToPubSub.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_PublishToPubSub>): Action_PublishToPubSub {
    const message = createBaseAction_PublishToPubSub();
    message.topic = object.topic ?? "";
    return message;
  },
};

function createBaseAction_PublishSummaryToCscc(): Action_PublishSummaryToCscc {
  return {};
}

export const Action_PublishSummaryToCscc: MessageFns<Action_PublishSummaryToCscc> = {
  encode(_: Action_PublishSummaryToCscc, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_PublishSummaryToCscc {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_PublishSummaryToCscc();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_PublishSummaryToCscc {
    return {};
  },

  toJSON(_: Action_PublishSummaryToCscc): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_PublishSummaryToCscc>): Action_PublishSummaryToCscc {
    return Action_PublishSummaryToCscc.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_PublishSummaryToCscc>): Action_PublishSummaryToCscc {
    const message = createBaseAction_PublishSummaryToCscc();
    return message;
  },
};

function createBaseAction_PublishFindingsToCloudDataCatalog(): Action_PublishFindingsToCloudDataCatalog {
  return {};
}

export const Action_PublishFindingsToCloudDataCatalog: MessageFns<Action_PublishFindingsToCloudDataCatalog> = {
  encode(_: Action_PublishFindingsToCloudDataCatalog, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_PublishFindingsToCloudDataCatalog {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_PublishFindingsToCloudDataCatalog();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_PublishFindingsToCloudDataCatalog {
    return {};
  },

  toJSON(_: Action_PublishFindingsToCloudDataCatalog): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_PublishFindingsToCloudDataCatalog>): Action_PublishFindingsToCloudDataCatalog {
    return Action_PublishFindingsToCloudDataCatalog.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_PublishFindingsToCloudDataCatalog>): Action_PublishFindingsToCloudDataCatalog {
    const message = createBaseAction_PublishFindingsToCloudDataCatalog();
    return message;
  },
};

function createBaseAction_Deidentify(): Action_Deidentify {
  return {
    transformationConfig: undefined,
    transformationDetailsStorageConfig: undefined,
    cloudStorageOutput: undefined,
    fileTypesToTransform: [],
  };
}

export const Action_Deidentify: MessageFns<Action_Deidentify> = {
  encode(message: Action_Deidentify, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transformationConfig !== undefined) {
      TransformationConfig.encode(message.transformationConfig, writer.uint32(58).fork()).join();
    }
    if (message.transformationDetailsStorageConfig !== undefined) {
      TransformationDetailsStorageConfig.encode(message.transformationDetailsStorageConfig, writer.uint32(26).fork())
        .join();
    }
    if (message.cloudStorageOutput !== undefined) {
      writer.uint32(74).string(message.cloudStorageOutput);
    }
    writer.uint32(66).fork();
    for (const v of message.fileTypesToTransform) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_Deidentify {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_Deidentify();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 7:
          if (tag !== 58) {
            break;
          }

          message.transformationConfig = TransformationConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transformationDetailsStorageConfig = TransformationDetailsStorageConfig.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.cloudStorageOutput = reader.string();
          continue;
        case 8:
          if (tag === 64) {
            message.fileTypesToTransform.push(reader.int32() as any);

            continue;
          }

          if (tag === 66) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.fileTypesToTransform.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Action_Deidentify {
    return {
      transformationConfig: isSet(object.transformationConfig)
        ? TransformationConfig.fromJSON(object.transformationConfig)
        : undefined,
      transformationDetailsStorageConfig: isSet(object.transformationDetailsStorageConfig)
        ? TransformationDetailsStorageConfig.fromJSON(object.transformationDetailsStorageConfig)
        : undefined,
      cloudStorageOutput: isSet(object.cloudStorageOutput) ? globalThis.String(object.cloudStorageOutput) : undefined,
      fileTypesToTransform: globalThis.Array.isArray(object?.fileTypesToTransform)
        ? object.fileTypesToTransform.map((e: any) => fileTypeFromJSON(e))
        : [],
    };
  },

  toJSON(message: Action_Deidentify): unknown {
    const obj: any = {};
    if (message.transformationConfig !== undefined) {
      obj.transformationConfig = TransformationConfig.toJSON(message.transformationConfig);
    }
    if (message.transformationDetailsStorageConfig !== undefined) {
      obj.transformationDetailsStorageConfig = TransformationDetailsStorageConfig.toJSON(
        message.transformationDetailsStorageConfig,
      );
    }
    if (message.cloudStorageOutput !== undefined) {
      obj.cloudStorageOutput = message.cloudStorageOutput;
    }
    if (message.fileTypesToTransform?.length) {
      obj.fileTypesToTransform = message.fileTypesToTransform.map((e) => fileTypeToJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Action_Deidentify>): Action_Deidentify {
    return Action_Deidentify.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Action_Deidentify>): Action_Deidentify {
    const message = createBaseAction_Deidentify();
    message.transformationConfig = (object.transformationConfig !== undefined && object.transformationConfig !== null)
      ? TransformationConfig.fromPartial(object.transformationConfig)
      : undefined;
    message.transformationDetailsStorageConfig =
      (object.transformationDetailsStorageConfig !== undefined && object.transformationDetailsStorageConfig !== null)
        ? TransformationDetailsStorageConfig.fromPartial(object.transformationDetailsStorageConfig)
        : undefined;
    message.cloudStorageOutput = object.cloudStorageOutput ?? undefined;
    message.fileTypesToTransform = object.fileTypesToTransform?.map((e) => e) || [];
    return message;
  },
};

function createBaseAction_JobNotificationEmails(): Action_JobNotificationEmails {
  return {};
}

export const Action_JobNotificationEmails: MessageFns<Action_JobNotificationEmails> = {
  encode(_: Action_JobNotificationEmails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_JobNotificationEmails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_JobNotificationEmails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_JobNotificationEmails {
    return {};
  },

  toJSON(_: Action_JobNotificationEmails): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_JobNotificationEmails>): Action_JobNotificationEmails {
    return Action_JobNotificationEmails.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_JobNotificationEmails>): Action_JobNotificationEmails {
    const message = createBaseAction_JobNotificationEmails();
    return message;
  },
};

function createBaseAction_PublishToStackdriver(): Action_PublishToStackdriver {
  return {};
}

export const Action_PublishToStackdriver: MessageFns<Action_PublishToStackdriver> = {
  encode(_: Action_PublishToStackdriver, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Action_PublishToStackdriver {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAction_PublishToStackdriver();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Action_PublishToStackdriver {
    return {};
  },

  toJSON(_: Action_PublishToStackdriver): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Action_PublishToStackdriver>): Action_PublishToStackdriver {
    return Action_PublishToStackdriver.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Action_PublishToStackdriver>): Action_PublishToStackdriver {
    const message = createBaseAction_PublishToStackdriver();
    return message;
  },
};

function createBaseTransformationConfig(): TransformationConfig {
  return { deidentifyTemplate: "", structuredDeidentifyTemplate: "", imageRedactTemplate: "" };
}

export const TransformationConfig: MessageFns<TransformationConfig> = {
  encode(message: TransformationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deidentifyTemplate !== "") {
      writer.uint32(10).string(message.deidentifyTemplate);
    }
    if (message.structuredDeidentifyTemplate !== "") {
      writer.uint32(18).string(message.structuredDeidentifyTemplate);
    }
    if (message.imageRedactTemplate !== "") {
      writer.uint32(34).string(message.imageRedactTemplate);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransformationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransformationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.deidentifyTemplate = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.structuredDeidentifyTemplate = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.imageRedactTemplate = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransformationConfig {
    return {
      deidentifyTemplate: isSet(object.deidentifyTemplate) ? globalThis.String(object.deidentifyTemplate) : "",
      structuredDeidentifyTemplate: isSet(object.structuredDeidentifyTemplate)
        ? globalThis.String(object.structuredDeidentifyTemplate)
        : "",
      imageRedactTemplate: isSet(object.imageRedactTemplate) ? globalThis.String(object.imageRedactTemplate) : "",
    };
  },

  toJSON(message: TransformationConfig): unknown {
    const obj: any = {};
    if (message.deidentifyTemplate !== "") {
      obj.deidentifyTemplate = message.deidentifyTemplate;
    }
    if (message.structuredDeidentifyTemplate !== "") {
      obj.structuredDeidentifyTemplate = message.structuredDeidentifyTemplate;
    }
    if (message.imageRedactTemplate !== "") {
      obj.imageRedactTemplate = message.imageRedactTemplate;
    }
    return obj;
  },

  create(base?: DeepPartial<TransformationConfig>): TransformationConfig {
    return TransformationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransformationConfig>): TransformationConfig {
    const message = createBaseTransformationConfig();
    message.deidentifyTemplate = object.deidentifyTemplate ?? "";
    message.structuredDeidentifyTemplate = object.structuredDeidentifyTemplate ?? "";
    message.imageRedactTemplate = object.imageRedactTemplate ?? "";
    return message;
  },
};

function createBaseCreateInspectTemplateRequest(): CreateInspectTemplateRequest {
  return { parent: "", inspectTemplate: undefined, templateId: "", locationId: "" };
}

export const CreateInspectTemplateRequest: MessageFns<CreateInspectTemplateRequest> = {
  encode(message: CreateInspectTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.inspectTemplate !== undefined) {
      InspectTemplate.encode(message.inspectTemplate, writer.uint32(18).fork()).join();
    }
    if (message.templateId !== "") {
      writer.uint32(26).string(message.templateId);
    }
    if (message.locationId !== "") {
      writer.uint32(34).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateInspectTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateInspectTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectTemplate = InspectTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.templateId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateInspectTemplateRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      inspectTemplate: isSet(object.inspectTemplate) ? InspectTemplate.fromJSON(object.inspectTemplate) : undefined,
      templateId: isSet(object.templateId) ? globalThis.String(object.templateId) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: CreateInspectTemplateRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.inspectTemplate !== undefined) {
      obj.inspectTemplate = InspectTemplate.toJSON(message.inspectTemplate);
    }
    if (message.templateId !== "") {
      obj.templateId = message.templateId;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateInspectTemplateRequest>): CreateInspectTemplateRequest {
    return CreateInspectTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateInspectTemplateRequest>): CreateInspectTemplateRequest {
    const message = createBaseCreateInspectTemplateRequest();
    message.parent = object.parent ?? "";
    message.inspectTemplate = (object.inspectTemplate !== undefined && object.inspectTemplate !== null)
      ? InspectTemplate.fromPartial(object.inspectTemplate)
      : undefined;
    message.templateId = object.templateId ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseUpdateInspectTemplateRequest(): UpdateInspectTemplateRequest {
  return { name: "", inspectTemplate: undefined, updateMask: undefined };
}

export const UpdateInspectTemplateRequest: MessageFns<UpdateInspectTemplateRequest> = {
  encode(message: UpdateInspectTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.inspectTemplate !== undefined) {
      InspectTemplate.encode(message.inspectTemplate, writer.uint32(18).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateInspectTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateInspectTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectTemplate = InspectTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateInspectTemplateRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      inspectTemplate: isSet(object.inspectTemplate) ? InspectTemplate.fromJSON(object.inspectTemplate) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateInspectTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.inspectTemplate !== undefined) {
      obj.inspectTemplate = InspectTemplate.toJSON(message.inspectTemplate);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateInspectTemplateRequest>): UpdateInspectTemplateRequest {
    return UpdateInspectTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateInspectTemplateRequest>): UpdateInspectTemplateRequest {
    const message = createBaseUpdateInspectTemplateRequest();
    message.name = object.name ?? "";
    message.inspectTemplate = (object.inspectTemplate !== undefined && object.inspectTemplate !== null)
      ? InspectTemplate.fromPartial(object.inspectTemplate)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetInspectTemplateRequest(): GetInspectTemplateRequest {
  return { name: "" };
}

export const GetInspectTemplateRequest: MessageFns<GetInspectTemplateRequest> = {
  encode(message: GetInspectTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetInspectTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetInspectTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetInspectTemplateRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetInspectTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetInspectTemplateRequest>): GetInspectTemplateRequest {
    return GetInspectTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetInspectTemplateRequest>): GetInspectTemplateRequest {
    const message = createBaseGetInspectTemplateRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListInspectTemplatesRequest(): ListInspectTemplatesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", locationId: "" };
}

export const ListInspectTemplatesRequest: MessageFns<ListInspectTemplatesRequest> = {
  encode(message: ListInspectTemplatesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.locationId !== "") {
      writer.uint32(42).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInspectTemplatesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInspectTemplatesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInspectTemplatesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ListInspectTemplatesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInspectTemplatesRequest>): ListInspectTemplatesRequest {
    return ListInspectTemplatesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInspectTemplatesRequest>): ListInspectTemplatesRequest {
    const message = createBaseListInspectTemplatesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListInspectTemplatesResponse(): ListInspectTemplatesResponse {
  return { inspectTemplates: [], nextPageToken: "" };
}

export const ListInspectTemplatesResponse: MessageFns<ListInspectTemplatesResponse> = {
  encode(message: ListInspectTemplatesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.inspectTemplates) {
      InspectTemplate.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInspectTemplatesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInspectTemplatesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inspectTemplates.push(InspectTemplate.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInspectTemplatesResponse {
    return {
      inspectTemplates: globalThis.Array.isArray(object?.inspectTemplates)
        ? object.inspectTemplates.map((e: any) => InspectTemplate.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListInspectTemplatesResponse): unknown {
    const obj: any = {};
    if (message.inspectTemplates?.length) {
      obj.inspectTemplates = message.inspectTemplates.map((e) => InspectTemplate.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInspectTemplatesResponse>): ListInspectTemplatesResponse {
    return ListInspectTemplatesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInspectTemplatesResponse>): ListInspectTemplatesResponse {
    const message = createBaseListInspectTemplatesResponse();
    message.inspectTemplates = object.inspectTemplates?.map((e) => InspectTemplate.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteInspectTemplateRequest(): DeleteInspectTemplateRequest {
  return { name: "" };
}

export const DeleteInspectTemplateRequest: MessageFns<DeleteInspectTemplateRequest> = {
  encode(message: DeleteInspectTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteInspectTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteInspectTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteInspectTemplateRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteInspectTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteInspectTemplateRequest>): DeleteInspectTemplateRequest {
    return DeleteInspectTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteInspectTemplateRequest>): DeleteInspectTemplateRequest {
    const message = createBaseDeleteInspectTemplateRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateJobTriggerRequest(): CreateJobTriggerRequest {
  return { parent: "", jobTrigger: undefined, triggerId: "", locationId: "" };
}

export const CreateJobTriggerRequest: MessageFns<CreateJobTriggerRequest> = {
  encode(message: CreateJobTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.jobTrigger !== undefined) {
      JobTrigger.encode(message.jobTrigger, writer.uint32(18).fork()).join();
    }
    if (message.triggerId !== "") {
      writer.uint32(26).string(message.triggerId);
    }
    if (message.locationId !== "") {
      writer.uint32(34).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateJobTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateJobTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobTrigger = JobTrigger.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.triggerId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateJobTriggerRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      jobTrigger: isSet(object.jobTrigger) ? JobTrigger.fromJSON(object.jobTrigger) : undefined,
      triggerId: isSet(object.triggerId) ? globalThis.String(object.triggerId) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: CreateJobTriggerRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.jobTrigger !== undefined) {
      obj.jobTrigger = JobTrigger.toJSON(message.jobTrigger);
    }
    if (message.triggerId !== "") {
      obj.triggerId = message.triggerId;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateJobTriggerRequest>): CreateJobTriggerRequest {
    return CreateJobTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateJobTriggerRequest>): CreateJobTriggerRequest {
    const message = createBaseCreateJobTriggerRequest();
    message.parent = object.parent ?? "";
    message.jobTrigger = (object.jobTrigger !== undefined && object.jobTrigger !== null)
      ? JobTrigger.fromPartial(object.jobTrigger)
      : undefined;
    message.triggerId = object.triggerId ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseActivateJobTriggerRequest(): ActivateJobTriggerRequest {
  return { name: "" };
}

export const ActivateJobTriggerRequest: MessageFns<ActivateJobTriggerRequest> = {
  encode(message: ActivateJobTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActivateJobTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActivateJobTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActivateJobTriggerRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: ActivateJobTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<ActivateJobTriggerRequest>): ActivateJobTriggerRequest {
    return ActivateJobTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ActivateJobTriggerRequest>): ActivateJobTriggerRequest {
    const message = createBaseActivateJobTriggerRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateJobTriggerRequest(): UpdateJobTriggerRequest {
  return { name: "", jobTrigger: undefined, updateMask: undefined };
}

export const UpdateJobTriggerRequest: MessageFns<UpdateJobTriggerRequest> = {
  encode(message: UpdateJobTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.jobTrigger !== undefined) {
      JobTrigger.encode(message.jobTrigger, writer.uint32(18).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateJobTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateJobTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobTrigger = JobTrigger.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateJobTriggerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      jobTrigger: isSet(object.jobTrigger) ? JobTrigger.fromJSON(object.jobTrigger) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateJobTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.jobTrigger !== undefined) {
      obj.jobTrigger = JobTrigger.toJSON(message.jobTrigger);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateJobTriggerRequest>): UpdateJobTriggerRequest {
    return UpdateJobTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateJobTriggerRequest>): UpdateJobTriggerRequest {
    const message = createBaseUpdateJobTriggerRequest();
    message.name = object.name ?? "";
    message.jobTrigger = (object.jobTrigger !== undefined && object.jobTrigger !== null)
      ? JobTrigger.fromPartial(object.jobTrigger)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetJobTriggerRequest(): GetJobTriggerRequest {
  return { name: "" };
}

export const GetJobTriggerRequest: MessageFns<GetJobTriggerRequest> = {
  encode(message: GetJobTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetJobTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetJobTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetJobTriggerRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetJobTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetJobTriggerRequest>): GetJobTriggerRequest {
    return GetJobTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetJobTriggerRequest>): GetJobTriggerRequest {
    const message = createBaseGetJobTriggerRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateDiscoveryConfigRequest(): CreateDiscoveryConfigRequest {
  return { parent: "", discoveryConfig: undefined, configId: "" };
}

export const CreateDiscoveryConfigRequest: MessageFns<CreateDiscoveryConfigRequest> = {
  encode(message: CreateDiscoveryConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.discoveryConfig !== undefined) {
      DiscoveryConfig.encode(message.discoveryConfig, writer.uint32(18).fork()).join();
    }
    if (message.configId !== "") {
      writer.uint32(26).string(message.configId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDiscoveryConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDiscoveryConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.discoveryConfig = DiscoveryConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.configId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDiscoveryConfigRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      discoveryConfig: isSet(object.discoveryConfig) ? DiscoveryConfig.fromJSON(object.discoveryConfig) : undefined,
      configId: isSet(object.configId) ? globalThis.String(object.configId) : "",
    };
  },

  toJSON(message: CreateDiscoveryConfigRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.discoveryConfig !== undefined) {
      obj.discoveryConfig = DiscoveryConfig.toJSON(message.discoveryConfig);
    }
    if (message.configId !== "") {
      obj.configId = message.configId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDiscoveryConfigRequest>): CreateDiscoveryConfigRequest {
    return CreateDiscoveryConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDiscoveryConfigRequest>): CreateDiscoveryConfigRequest {
    const message = createBaseCreateDiscoveryConfigRequest();
    message.parent = object.parent ?? "";
    message.discoveryConfig = (object.discoveryConfig !== undefined && object.discoveryConfig !== null)
      ? DiscoveryConfig.fromPartial(object.discoveryConfig)
      : undefined;
    message.configId = object.configId ?? "";
    return message;
  },
};

function createBaseUpdateDiscoveryConfigRequest(): UpdateDiscoveryConfigRequest {
  return { name: "", discoveryConfig: undefined, updateMask: undefined };
}

export const UpdateDiscoveryConfigRequest: MessageFns<UpdateDiscoveryConfigRequest> = {
  encode(message: UpdateDiscoveryConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.discoveryConfig !== undefined) {
      DiscoveryConfig.encode(message.discoveryConfig, writer.uint32(18).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDiscoveryConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDiscoveryConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.discoveryConfig = DiscoveryConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDiscoveryConfigRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      discoveryConfig: isSet(object.discoveryConfig) ? DiscoveryConfig.fromJSON(object.discoveryConfig) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateDiscoveryConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.discoveryConfig !== undefined) {
      obj.discoveryConfig = DiscoveryConfig.toJSON(message.discoveryConfig);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDiscoveryConfigRequest>): UpdateDiscoveryConfigRequest {
    return UpdateDiscoveryConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDiscoveryConfigRequest>): UpdateDiscoveryConfigRequest {
    const message = createBaseUpdateDiscoveryConfigRequest();
    message.name = object.name ?? "";
    message.discoveryConfig = (object.discoveryConfig !== undefined && object.discoveryConfig !== null)
      ? DiscoveryConfig.fromPartial(object.discoveryConfig)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetDiscoveryConfigRequest(): GetDiscoveryConfigRequest {
  return { name: "" };
}

export const GetDiscoveryConfigRequest: MessageFns<GetDiscoveryConfigRequest> = {
  encode(message: GetDiscoveryConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDiscoveryConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDiscoveryConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDiscoveryConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetDiscoveryConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDiscoveryConfigRequest>): GetDiscoveryConfigRequest {
    return GetDiscoveryConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDiscoveryConfigRequest>): GetDiscoveryConfigRequest {
    const message = createBaseGetDiscoveryConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListDiscoveryConfigsRequest(): ListDiscoveryConfigsRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "" };
}

export const ListDiscoveryConfigsRequest: MessageFns<ListDiscoveryConfigsRequest> = {
  encode(message: ListDiscoveryConfigsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDiscoveryConfigsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDiscoveryConfigsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDiscoveryConfigsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListDiscoveryConfigsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDiscoveryConfigsRequest>): ListDiscoveryConfigsRequest {
    return ListDiscoveryConfigsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDiscoveryConfigsRequest>): ListDiscoveryConfigsRequest {
    const message = createBaseListDiscoveryConfigsRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListDiscoveryConfigsResponse(): ListDiscoveryConfigsResponse {
  return { discoveryConfigs: [], nextPageToken: "" };
}

export const ListDiscoveryConfigsResponse: MessageFns<ListDiscoveryConfigsResponse> = {
  encode(message: ListDiscoveryConfigsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.discoveryConfigs) {
      DiscoveryConfig.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDiscoveryConfigsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDiscoveryConfigsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.discoveryConfigs.push(DiscoveryConfig.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDiscoveryConfigsResponse {
    return {
      discoveryConfigs: globalThis.Array.isArray(object?.discoveryConfigs)
        ? object.discoveryConfigs.map((e: any) => DiscoveryConfig.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDiscoveryConfigsResponse): unknown {
    const obj: any = {};
    if (message.discoveryConfigs?.length) {
      obj.discoveryConfigs = message.discoveryConfigs.map((e) => DiscoveryConfig.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDiscoveryConfigsResponse>): ListDiscoveryConfigsResponse {
    return ListDiscoveryConfigsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDiscoveryConfigsResponse>): ListDiscoveryConfigsResponse {
    const message = createBaseListDiscoveryConfigsResponse();
    message.discoveryConfigs = object.discoveryConfigs?.map((e) => DiscoveryConfig.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteDiscoveryConfigRequest(): DeleteDiscoveryConfigRequest {
  return { name: "" };
}

export const DeleteDiscoveryConfigRequest: MessageFns<DeleteDiscoveryConfigRequest> = {
  encode(message: DeleteDiscoveryConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteDiscoveryConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteDiscoveryConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteDiscoveryConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteDiscoveryConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteDiscoveryConfigRequest>): DeleteDiscoveryConfigRequest {
    return DeleteDiscoveryConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteDiscoveryConfigRequest>): DeleteDiscoveryConfigRequest {
    const message = createBaseDeleteDiscoveryConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateDlpJobRequest(): CreateDlpJobRequest {
  return { parent: "", inspectJob: undefined, riskJob: undefined, jobId: "", locationId: "" };
}

export const CreateDlpJobRequest: MessageFns<CreateDlpJobRequest> = {
  encode(message: CreateDlpJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.inspectJob !== undefined) {
      InspectJobConfig.encode(message.inspectJob, writer.uint32(18).fork()).join();
    }
    if (message.riskJob !== undefined) {
      RiskAnalysisJobConfig.encode(message.riskJob, writer.uint32(26).fork()).join();
    }
    if (message.jobId !== "") {
      writer.uint32(34).string(message.jobId);
    }
    if (message.locationId !== "") {
      writer.uint32(42).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDlpJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDlpJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectJob = InspectJobConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.riskJob = RiskAnalysisJobConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDlpJobRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      inspectJob: isSet(object.inspectJob) ? InspectJobConfig.fromJSON(object.inspectJob) : undefined,
      riskJob: isSet(object.riskJob) ? RiskAnalysisJobConfig.fromJSON(object.riskJob) : undefined,
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: CreateDlpJobRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.inspectJob !== undefined) {
      obj.inspectJob = InspectJobConfig.toJSON(message.inspectJob);
    }
    if (message.riskJob !== undefined) {
      obj.riskJob = RiskAnalysisJobConfig.toJSON(message.riskJob);
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDlpJobRequest>): CreateDlpJobRequest {
    return CreateDlpJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDlpJobRequest>): CreateDlpJobRequest {
    const message = createBaseCreateDlpJobRequest();
    message.parent = object.parent ?? "";
    message.inspectJob = (object.inspectJob !== undefined && object.inspectJob !== null)
      ? InspectJobConfig.fromPartial(object.inspectJob)
      : undefined;
    message.riskJob = (object.riskJob !== undefined && object.riskJob !== null)
      ? RiskAnalysisJobConfig.fromPartial(object.riskJob)
      : undefined;
    message.jobId = object.jobId ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListJobTriggersRequest(): ListJobTriggersRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", filter: "", type: 0, locationId: "" };
}

export const ListJobTriggersRequest: MessageFns<ListJobTriggersRequest> = {
  encode(message: ListJobTriggersRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    if (message.type !== 0) {
      writer.uint32(48).int32(message.type);
    }
    if (message.locationId !== "") {
      writer.uint32(58).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListJobTriggersRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListJobTriggersRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListJobTriggersRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      type: isSet(object.type) ? dlpJobTypeFromJSON(object.type) : 0,
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ListJobTriggersRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.type !== 0) {
      obj.type = dlpJobTypeToJSON(message.type);
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListJobTriggersRequest>): ListJobTriggersRequest {
    return ListJobTriggersRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListJobTriggersRequest>): ListJobTriggersRequest {
    const message = createBaseListJobTriggersRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    message.type = object.type ?? 0;
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListJobTriggersResponse(): ListJobTriggersResponse {
  return { jobTriggers: [], nextPageToken: "" };
}

export const ListJobTriggersResponse: MessageFns<ListJobTriggersResponse> = {
  encode(message: ListJobTriggersResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.jobTriggers) {
      JobTrigger.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListJobTriggersResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListJobTriggersResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobTriggers.push(JobTrigger.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListJobTriggersResponse {
    return {
      jobTriggers: globalThis.Array.isArray(object?.jobTriggers)
        ? object.jobTriggers.map((e: any) => JobTrigger.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListJobTriggersResponse): unknown {
    const obj: any = {};
    if (message.jobTriggers?.length) {
      obj.jobTriggers = message.jobTriggers.map((e) => JobTrigger.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListJobTriggersResponse>): ListJobTriggersResponse {
    return ListJobTriggersResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListJobTriggersResponse>): ListJobTriggersResponse {
    const message = createBaseListJobTriggersResponse();
    message.jobTriggers = object.jobTriggers?.map((e) => JobTrigger.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteJobTriggerRequest(): DeleteJobTriggerRequest {
  return { name: "" };
}

export const DeleteJobTriggerRequest: MessageFns<DeleteJobTriggerRequest> = {
  encode(message: DeleteJobTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteJobTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteJobTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteJobTriggerRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteJobTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteJobTriggerRequest>): DeleteJobTriggerRequest {
    return DeleteJobTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteJobTriggerRequest>): DeleteJobTriggerRequest {
    const message = createBaseDeleteJobTriggerRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseInspectJobConfig(): InspectJobConfig {
  return { storageConfig: undefined, inspectConfig: undefined, inspectTemplateName: "", actions: [] };
}

export const InspectJobConfig: MessageFns<InspectJobConfig> = {
  encode(message: InspectJobConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.storageConfig !== undefined) {
      StorageConfig.encode(message.storageConfig, writer.uint32(10).fork()).join();
    }
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(18).fork()).join();
    }
    if (message.inspectTemplateName !== "") {
      writer.uint32(26).string(message.inspectTemplateName);
    }
    for (const v of message.actions) {
      Action.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InspectJobConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInspectJobConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.storageConfig = StorageConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectTemplateName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.actions.push(Action.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InspectJobConfig {
    return {
      storageConfig: isSet(object.storageConfig) ? StorageConfig.fromJSON(object.storageConfig) : undefined,
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
      inspectTemplateName: isSet(object.inspectTemplateName) ? globalThis.String(object.inspectTemplateName) : "",
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => Action.fromJSON(e)) : [],
    };
  },

  toJSON(message: InspectJobConfig): unknown {
    const obj: any = {};
    if (message.storageConfig !== undefined) {
      obj.storageConfig = StorageConfig.toJSON(message.storageConfig);
    }
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    if (message.inspectTemplateName !== "") {
      obj.inspectTemplateName = message.inspectTemplateName;
    }
    if (message.actions?.length) {
      obj.actions = message.actions.map((e) => Action.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<InspectJobConfig>): InspectJobConfig {
    return InspectJobConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InspectJobConfig>): InspectJobConfig {
    const message = createBaseInspectJobConfig();
    message.storageConfig = (object.storageConfig !== undefined && object.storageConfig !== null)
      ? StorageConfig.fromPartial(object.storageConfig)
      : undefined;
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    message.inspectTemplateName = object.inspectTemplateName ?? "";
    message.actions = object.actions?.map((e) => Action.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDataProfileAction(): DataProfileAction {
  return {
    exportData: undefined,
    pubSubNotification: undefined,
    publishToChronicle: undefined,
    publishToScc: undefined,
    tagResources: undefined,
  };
}

export const DataProfileAction: MessageFns<DataProfileAction> = {
  encode(message: DataProfileAction, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.exportData !== undefined) {
      DataProfileAction_Export.encode(message.exportData, writer.uint32(10).fork()).join();
    }
    if (message.pubSubNotification !== undefined) {
      DataProfileAction_PubSubNotification.encode(message.pubSubNotification, writer.uint32(18).fork()).join();
    }
    if (message.publishToChronicle !== undefined) {
      DataProfileAction_PublishToChronicle.encode(message.publishToChronicle, writer.uint32(26).fork()).join();
    }
    if (message.publishToScc !== undefined) {
      DataProfileAction_PublishToSecurityCommandCenter.encode(message.publishToScc, writer.uint32(34).fork()).join();
    }
    if (message.tagResources !== undefined) {
      DataProfileAction_TagResources.encode(message.tagResources, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.exportData = DataProfileAction_Export.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pubSubNotification = DataProfileAction_PubSubNotification.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.publishToChronicle = DataProfileAction_PublishToChronicle.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.publishToScc = DataProfileAction_PublishToSecurityCommandCenter.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.tagResources = DataProfileAction_TagResources.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileAction {
    return {
      exportData: isSet(object.exportData) ? DataProfileAction_Export.fromJSON(object.exportData) : undefined,
      pubSubNotification: isSet(object.pubSubNotification)
        ? DataProfileAction_PubSubNotification.fromJSON(object.pubSubNotification)
        : undefined,
      publishToChronicle: isSet(object.publishToChronicle)
        ? DataProfileAction_PublishToChronicle.fromJSON(object.publishToChronicle)
        : undefined,
      publishToScc: isSet(object.publishToScc)
        ? DataProfileAction_PublishToSecurityCommandCenter.fromJSON(object.publishToScc)
        : undefined,
      tagResources: isSet(object.tagResources)
        ? DataProfileAction_TagResources.fromJSON(object.tagResources)
        : undefined,
    };
  },

  toJSON(message: DataProfileAction): unknown {
    const obj: any = {};
    if (message.exportData !== undefined) {
      obj.exportData = DataProfileAction_Export.toJSON(message.exportData);
    }
    if (message.pubSubNotification !== undefined) {
      obj.pubSubNotification = DataProfileAction_PubSubNotification.toJSON(message.pubSubNotification);
    }
    if (message.publishToChronicle !== undefined) {
      obj.publishToChronicle = DataProfileAction_PublishToChronicle.toJSON(message.publishToChronicle);
    }
    if (message.publishToScc !== undefined) {
      obj.publishToScc = DataProfileAction_PublishToSecurityCommandCenter.toJSON(message.publishToScc);
    }
    if (message.tagResources !== undefined) {
      obj.tagResources = DataProfileAction_TagResources.toJSON(message.tagResources);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction>): DataProfileAction {
    return DataProfileAction.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileAction>): DataProfileAction {
    const message = createBaseDataProfileAction();
    message.exportData = (object.exportData !== undefined && object.exportData !== null)
      ? DataProfileAction_Export.fromPartial(object.exportData)
      : undefined;
    message.pubSubNotification = (object.pubSubNotification !== undefined && object.pubSubNotification !== null)
      ? DataProfileAction_PubSubNotification.fromPartial(object.pubSubNotification)
      : undefined;
    message.publishToChronicle = (object.publishToChronicle !== undefined && object.publishToChronicle !== null)
      ? DataProfileAction_PublishToChronicle.fromPartial(object.publishToChronicle)
      : undefined;
    message.publishToScc = (object.publishToScc !== undefined && object.publishToScc !== null)
      ? DataProfileAction_PublishToSecurityCommandCenter.fromPartial(object.publishToScc)
      : undefined;
    message.tagResources = (object.tagResources !== undefined && object.tagResources !== null)
      ? DataProfileAction_TagResources.fromPartial(object.tagResources)
      : undefined;
    return message;
  },
};

function createBaseDataProfileAction_Export(): DataProfileAction_Export {
  return { profileTable: undefined };
}

export const DataProfileAction_Export: MessageFns<DataProfileAction_Export> = {
  encode(message: DataProfileAction_Export, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.profileTable !== undefined) {
      BigQueryTable.encode(message.profileTable, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_Export {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_Export();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.profileTable = BigQueryTable.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileAction_Export {
    return { profileTable: isSet(object.profileTable) ? BigQueryTable.fromJSON(object.profileTable) : undefined };
  },

  toJSON(message: DataProfileAction_Export): unknown {
    const obj: any = {};
    if (message.profileTable !== undefined) {
      obj.profileTable = BigQueryTable.toJSON(message.profileTable);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction_Export>): DataProfileAction_Export {
    return DataProfileAction_Export.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileAction_Export>): DataProfileAction_Export {
    const message = createBaseDataProfileAction_Export();
    message.profileTable = (object.profileTable !== undefined && object.profileTable !== null)
      ? BigQueryTable.fromPartial(object.profileTable)
      : undefined;
    return message;
  },
};

function createBaseDataProfileAction_PubSubNotification(): DataProfileAction_PubSubNotification {
  return { topic: "", event: 0, pubsubCondition: undefined, detailOfMessage: 0 };
}

export const DataProfileAction_PubSubNotification: MessageFns<DataProfileAction_PubSubNotification> = {
  encode(message: DataProfileAction_PubSubNotification, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    if (message.event !== 0) {
      writer.uint32(16).int32(message.event);
    }
    if (message.pubsubCondition !== undefined) {
      DataProfilePubSubCondition.encode(message.pubsubCondition, writer.uint32(26).fork()).join();
    }
    if (message.detailOfMessage !== 0) {
      writer.uint32(32).int32(message.detailOfMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_PubSubNotification {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_PubSubNotification();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.event = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pubsubCondition = DataProfilePubSubCondition.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.detailOfMessage = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileAction_PubSubNotification {
    return {
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      event: isSet(object.event) ? dataProfileAction_EventTypeFromJSON(object.event) : 0,
      pubsubCondition: isSet(object.pubsubCondition)
        ? DataProfilePubSubCondition.fromJSON(object.pubsubCondition)
        : undefined,
      detailOfMessage: isSet(object.detailOfMessage)
        ? dataProfileAction_PubSubNotification_DetailLevelFromJSON(object.detailOfMessage)
        : 0,
    };
  },

  toJSON(message: DataProfileAction_PubSubNotification): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.event !== 0) {
      obj.event = dataProfileAction_EventTypeToJSON(message.event);
    }
    if (message.pubsubCondition !== undefined) {
      obj.pubsubCondition = DataProfilePubSubCondition.toJSON(message.pubsubCondition);
    }
    if (message.detailOfMessage !== 0) {
      obj.detailOfMessage = dataProfileAction_PubSubNotification_DetailLevelToJSON(message.detailOfMessage);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction_PubSubNotification>): DataProfileAction_PubSubNotification {
    return DataProfileAction_PubSubNotification.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileAction_PubSubNotification>): DataProfileAction_PubSubNotification {
    const message = createBaseDataProfileAction_PubSubNotification();
    message.topic = object.topic ?? "";
    message.event = object.event ?? 0;
    message.pubsubCondition = (object.pubsubCondition !== undefined && object.pubsubCondition !== null)
      ? DataProfilePubSubCondition.fromPartial(object.pubsubCondition)
      : undefined;
    message.detailOfMessage = object.detailOfMessage ?? 0;
    return message;
  },
};

function createBaseDataProfileAction_PublishToChronicle(): DataProfileAction_PublishToChronicle {
  return {};
}

export const DataProfileAction_PublishToChronicle: MessageFns<DataProfileAction_PublishToChronicle> = {
  encode(_: DataProfileAction_PublishToChronicle, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_PublishToChronicle {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_PublishToChronicle();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataProfileAction_PublishToChronicle {
    return {};
  },

  toJSON(_: DataProfileAction_PublishToChronicle): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction_PublishToChronicle>): DataProfileAction_PublishToChronicle {
    return DataProfileAction_PublishToChronicle.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DataProfileAction_PublishToChronicle>): DataProfileAction_PublishToChronicle {
    const message = createBaseDataProfileAction_PublishToChronicle();
    return message;
  },
};

function createBaseDataProfileAction_PublishToSecurityCommandCenter(): DataProfileAction_PublishToSecurityCommandCenter {
  return {};
}

export const DataProfileAction_PublishToSecurityCommandCenter: MessageFns<
  DataProfileAction_PublishToSecurityCommandCenter
> = {
  encode(_: DataProfileAction_PublishToSecurityCommandCenter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_PublishToSecurityCommandCenter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_PublishToSecurityCommandCenter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataProfileAction_PublishToSecurityCommandCenter {
    return {};
  },

  toJSON(_: DataProfileAction_PublishToSecurityCommandCenter): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<DataProfileAction_PublishToSecurityCommandCenter>,
  ): DataProfileAction_PublishToSecurityCommandCenter {
    return DataProfileAction_PublishToSecurityCommandCenter.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<DataProfileAction_PublishToSecurityCommandCenter>,
  ): DataProfileAction_PublishToSecurityCommandCenter {
    const message = createBaseDataProfileAction_PublishToSecurityCommandCenter();
    return message;
  },
};

function createBaseDataProfileAction_TagResources(): DataProfileAction_TagResources {
  return { tagConditions: [], profileGenerationsToTag: [], lowerDataRiskToLow: false };
}

export const DataProfileAction_TagResources: MessageFns<DataProfileAction_TagResources> = {
  encode(message: DataProfileAction_TagResources, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tagConditions) {
      DataProfileAction_TagResources_TagCondition.encode(v!, writer.uint32(10).fork()).join();
    }
    writer.uint32(18).fork();
    for (const v of message.profileGenerationsToTag) {
      writer.int32(v);
    }
    writer.join();
    if (message.lowerDataRiskToLow !== false) {
      writer.uint32(24).bool(message.lowerDataRiskToLow);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_TagResources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_TagResources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tagConditions.push(DataProfileAction_TagResources_TagCondition.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag === 16) {
            message.profileGenerationsToTag.push(reader.int32() as any);

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.profileGenerationsToTag.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.lowerDataRiskToLow = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileAction_TagResources {
    return {
      tagConditions: globalThis.Array.isArray(object?.tagConditions)
        ? object.tagConditions.map((e: any) => DataProfileAction_TagResources_TagCondition.fromJSON(e))
        : [],
      profileGenerationsToTag: globalThis.Array.isArray(object?.profileGenerationsToTag)
        ? object.profileGenerationsToTag.map((e: any) => profileGenerationFromJSON(e))
        : [],
      lowerDataRiskToLow: isSet(object.lowerDataRiskToLow) ? globalThis.Boolean(object.lowerDataRiskToLow) : false,
    };
  },

  toJSON(message: DataProfileAction_TagResources): unknown {
    const obj: any = {};
    if (message.tagConditions?.length) {
      obj.tagConditions = message.tagConditions.map((e) => DataProfileAction_TagResources_TagCondition.toJSON(e));
    }
    if (message.profileGenerationsToTag?.length) {
      obj.profileGenerationsToTag = message.profileGenerationsToTag.map((e) => profileGenerationToJSON(e));
    }
    if (message.lowerDataRiskToLow !== false) {
      obj.lowerDataRiskToLow = message.lowerDataRiskToLow;
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction_TagResources>): DataProfileAction_TagResources {
    return DataProfileAction_TagResources.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileAction_TagResources>): DataProfileAction_TagResources {
    const message = createBaseDataProfileAction_TagResources();
    message.tagConditions =
      object.tagConditions?.map((e) => DataProfileAction_TagResources_TagCondition.fromPartial(e)) || [];
    message.profileGenerationsToTag = object.profileGenerationsToTag?.map((e) => e) || [];
    message.lowerDataRiskToLow = object.lowerDataRiskToLow ?? false;
    return message;
  },
};

function createBaseDataProfileAction_TagResources_TagCondition(): DataProfileAction_TagResources_TagCondition {
  return { tag: undefined, sensitivityScore: undefined };
}

export const DataProfileAction_TagResources_TagCondition: MessageFns<DataProfileAction_TagResources_TagCondition> = {
  encode(
    message: DataProfileAction_TagResources_TagCondition,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.tag !== undefined) {
      DataProfileAction_TagResources_TagValue.encode(message.tag, writer.uint32(10).fork()).join();
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_TagResources_TagCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_TagResources_TagCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tag = DataProfileAction_TagResources_TagValue.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileAction_TagResources_TagCondition {
    return {
      tag: isSet(object.tag) ? DataProfileAction_TagResources_TagValue.fromJSON(object.tag) : undefined,
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
    };
  },

  toJSON(message: DataProfileAction_TagResources_TagCondition): unknown {
    const obj: any = {};
    if (message.tag !== undefined) {
      obj.tag = DataProfileAction_TagResources_TagValue.toJSON(message.tag);
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction_TagResources_TagCondition>): DataProfileAction_TagResources_TagCondition {
    return DataProfileAction_TagResources_TagCondition.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataProfileAction_TagResources_TagCondition>,
  ): DataProfileAction_TagResources_TagCondition {
    const message = createBaseDataProfileAction_TagResources_TagCondition();
    message.tag = (object.tag !== undefined && object.tag !== null)
      ? DataProfileAction_TagResources_TagValue.fromPartial(object.tag)
      : undefined;
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    return message;
  },
};

function createBaseDataProfileAction_TagResources_TagValue(): DataProfileAction_TagResources_TagValue {
  return { namespacedValue: undefined };
}

export const DataProfileAction_TagResources_TagValue: MessageFns<DataProfileAction_TagResources_TagValue> = {
  encode(message: DataProfileAction_TagResources_TagValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespacedValue !== undefined) {
      writer.uint32(10).string(message.namespacedValue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileAction_TagResources_TagValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileAction_TagResources_TagValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.namespacedValue = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileAction_TagResources_TagValue {
    return { namespacedValue: isSet(object.namespacedValue) ? globalThis.String(object.namespacedValue) : undefined };
  },

  toJSON(message: DataProfileAction_TagResources_TagValue): unknown {
    const obj: any = {};
    if (message.namespacedValue !== undefined) {
      obj.namespacedValue = message.namespacedValue;
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileAction_TagResources_TagValue>): DataProfileAction_TagResources_TagValue {
    return DataProfileAction_TagResources_TagValue.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileAction_TagResources_TagValue>): DataProfileAction_TagResources_TagValue {
    const message = createBaseDataProfileAction_TagResources_TagValue();
    message.namespacedValue = object.namespacedValue ?? undefined;
    return message;
  },
};

function createBaseDataProfileJobConfig(): DataProfileJobConfig {
  return {
    location: undefined,
    projectId: "",
    otherCloudStartingLocation: undefined,
    inspectTemplates: [],
    dataProfileActions: [],
  };
}

export const DataProfileJobConfig: MessageFns<DataProfileJobConfig> = {
  encode(message: DataProfileJobConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== undefined) {
      DataProfileLocation.encode(message.location, writer.uint32(10).fork()).join();
    }
    if (message.projectId !== "") {
      writer.uint32(42).string(message.projectId);
    }
    if (message.otherCloudStartingLocation !== undefined) {
      OtherCloudDiscoveryStartingLocation.encode(message.otherCloudStartingLocation, writer.uint32(66).fork()).join();
    }
    for (const v of message.inspectTemplates) {
      writer.uint32(58).string(v!);
    }
    for (const v of message.dataProfileActions) {
      DataProfileAction.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileJobConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileJobConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = DataProfileLocation.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.otherCloudStartingLocation = OtherCloudDiscoveryStartingLocation.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.inspectTemplates.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.dataProfileActions.push(DataProfileAction.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileJobConfig {
    return {
      location: isSet(object.location) ? DataProfileLocation.fromJSON(object.location) : undefined,
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      otherCloudStartingLocation: isSet(object.otherCloudStartingLocation)
        ? OtherCloudDiscoveryStartingLocation.fromJSON(object.otherCloudStartingLocation)
        : undefined,
      inspectTemplates: globalThis.Array.isArray(object?.inspectTemplates)
        ? object.inspectTemplates.map((e: any) => globalThis.String(e))
        : [],
      dataProfileActions: globalThis.Array.isArray(object?.dataProfileActions)
        ? object.dataProfileActions.map((e: any) => DataProfileAction.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DataProfileJobConfig): unknown {
    const obj: any = {};
    if (message.location !== undefined) {
      obj.location = DataProfileLocation.toJSON(message.location);
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.otherCloudStartingLocation !== undefined) {
      obj.otherCloudStartingLocation = OtherCloudDiscoveryStartingLocation.toJSON(message.otherCloudStartingLocation);
    }
    if (message.inspectTemplates?.length) {
      obj.inspectTemplates = message.inspectTemplates;
    }
    if (message.dataProfileActions?.length) {
      obj.dataProfileActions = message.dataProfileActions.map((e) => DataProfileAction.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileJobConfig>): DataProfileJobConfig {
    return DataProfileJobConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileJobConfig>): DataProfileJobConfig {
    const message = createBaseDataProfileJobConfig();
    message.location = (object.location !== undefined && object.location !== null)
      ? DataProfileLocation.fromPartial(object.location)
      : undefined;
    message.projectId = object.projectId ?? "";
    message.otherCloudStartingLocation =
      (object.otherCloudStartingLocation !== undefined && object.otherCloudStartingLocation !== null)
        ? OtherCloudDiscoveryStartingLocation.fromPartial(object.otherCloudStartingLocation)
        : undefined;
    message.inspectTemplates = object.inspectTemplates?.map((e) => e) || [];
    message.dataProfileActions = object.dataProfileActions?.map((e) => DataProfileAction.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBigQueryRegex(): BigQueryRegex {
  return { projectIdRegex: "", datasetIdRegex: "", tableIdRegex: "" };
}

export const BigQueryRegex: MessageFns<BigQueryRegex> = {
  encode(message: BigQueryRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectIdRegex !== "") {
      writer.uint32(10).string(message.projectIdRegex);
    }
    if (message.datasetIdRegex !== "") {
      writer.uint32(18).string(message.datasetIdRegex);
    }
    if (message.tableIdRegex !== "") {
      writer.uint32(26).string(message.tableIdRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectIdRegex = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetIdRegex = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tableIdRegex = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryRegex {
    return {
      projectIdRegex: isSet(object.projectIdRegex) ? globalThis.String(object.projectIdRegex) : "",
      datasetIdRegex: isSet(object.datasetIdRegex) ? globalThis.String(object.datasetIdRegex) : "",
      tableIdRegex: isSet(object.tableIdRegex) ? globalThis.String(object.tableIdRegex) : "",
    };
  },

  toJSON(message: BigQueryRegex): unknown {
    const obj: any = {};
    if (message.projectIdRegex !== "") {
      obj.projectIdRegex = message.projectIdRegex;
    }
    if (message.datasetIdRegex !== "") {
      obj.datasetIdRegex = message.datasetIdRegex;
    }
    if (message.tableIdRegex !== "") {
      obj.tableIdRegex = message.tableIdRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryRegex>): BigQueryRegex {
    return BigQueryRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryRegex>): BigQueryRegex {
    const message = createBaseBigQueryRegex();
    message.projectIdRegex = object.projectIdRegex ?? "";
    message.datasetIdRegex = object.datasetIdRegex ?? "";
    message.tableIdRegex = object.tableIdRegex ?? "";
    return message;
  },
};

function createBaseBigQueryRegexes(): BigQueryRegexes {
  return { patterns: [] };
}

export const BigQueryRegexes: MessageFns<BigQueryRegexes> = {
  encode(message: BigQueryRegexes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.patterns) {
      BigQueryRegex.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryRegexes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryRegexes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.patterns.push(BigQueryRegex.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryRegexes {
    return {
      patterns: globalThis.Array.isArray(object?.patterns)
        ? object.patterns.map((e: any) => BigQueryRegex.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BigQueryRegexes): unknown {
    const obj: any = {};
    if (message.patterns?.length) {
      obj.patterns = message.patterns.map((e) => BigQueryRegex.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryRegexes>): BigQueryRegexes {
    return BigQueryRegexes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryRegexes>): BigQueryRegexes {
    const message = createBaseBigQueryRegexes();
    message.patterns = object.patterns?.map((e) => BigQueryRegex.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBigQueryTableTypes(): BigQueryTableTypes {
  return { types: [] };
}

export const BigQueryTableTypes: MessageFns<BigQueryTableTypes> = {
  encode(message: BigQueryTableTypes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.types) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryTableTypes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryTableTypes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.types.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.types.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryTableTypes {
    return {
      types: globalThis.Array.isArray(object?.types) ? object.types.map((e: any) => bigQueryTableTypeFromJSON(e)) : [],
    };
  },

  toJSON(message: BigQueryTableTypes): unknown {
    const obj: any = {};
    if (message.types?.length) {
      obj.types = message.types.map((e) => bigQueryTableTypeToJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryTableTypes>): BigQueryTableTypes {
    return BigQueryTableTypes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryTableTypes>): BigQueryTableTypes {
    const message = createBaseBigQueryTableTypes();
    message.types = object.types?.map((e) => e) || [];
    return message;
  },
};

function createBaseDisabled(): Disabled {
  return {};
}

export const Disabled: MessageFns<Disabled> = {
  encode(_: Disabled, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Disabled {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDisabled();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Disabled {
    return {};
  },

  toJSON(_: Disabled): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Disabled>): Disabled {
    return Disabled.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Disabled>): Disabled {
    const message = createBaseDisabled();
    return message;
  },
};

function createBaseDataProfileLocation(): DataProfileLocation {
  return { organizationId: undefined, folderId: undefined };
}

export const DataProfileLocation: MessageFns<DataProfileLocation> = {
  encode(message: DataProfileLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.organizationId !== undefined) {
      writer.uint32(8).int64(message.organizationId.toString());
    }
    if (message.folderId !== undefined) {
      writer.uint32(16).int64(message.folderId.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.organizationId = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.folderId = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileLocation {
    return {
      organizationId: isSet(object.organizationId) ? Long.fromValue(object.organizationId) : undefined,
      folderId: isSet(object.folderId) ? Long.fromValue(object.folderId) : undefined,
    };
  },

  toJSON(message: DataProfileLocation): unknown {
    const obj: any = {};
    if (message.organizationId !== undefined) {
      obj.organizationId = (message.organizationId || Long.ZERO).toString();
    }
    if (message.folderId !== undefined) {
      obj.folderId = (message.folderId || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileLocation>): DataProfileLocation {
    return DataProfileLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileLocation>): DataProfileLocation {
    const message = createBaseDataProfileLocation();
    message.organizationId = (object.organizationId !== undefined && object.organizationId !== null)
      ? Long.fromValue(object.organizationId)
      : undefined;
    message.folderId = (object.folderId !== undefined && object.folderId !== null)
      ? Long.fromValue(object.folderId)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryConfig(): DiscoveryConfig {
  return {
    name: "",
    displayName: "",
    orgConfig: undefined,
    otherCloudStartingLocation: undefined,
    inspectTemplates: [],
    actions: [],
    targets: [],
    errors: [],
    createTime: undefined,
    updateTime: undefined,
    lastRunTime: undefined,
    status: 0,
  };
}

export const DiscoveryConfig: MessageFns<DiscoveryConfig> = {
  encode(message: DiscoveryConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(90).string(message.displayName);
    }
    if (message.orgConfig !== undefined) {
      DiscoveryConfig_OrgConfig.encode(message.orgConfig, writer.uint32(18).fork()).join();
    }
    if (message.otherCloudStartingLocation !== undefined) {
      OtherCloudDiscoveryStartingLocation.encode(message.otherCloudStartingLocation, writer.uint32(98).fork()).join();
    }
    for (const v of message.inspectTemplates) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.actions) {
      DataProfileAction.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.targets) {
      DiscoveryTarget.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(66).fork()).join();
    }
    if (message.lastRunTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastRunTime), writer.uint32(74).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(80).int32(message.status);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.orgConfig = DiscoveryConfig_OrgConfig.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.otherCloudStartingLocation = OtherCloudDiscoveryStartingLocation.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectTemplates.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.actions.push(DataProfileAction.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.targets.push(DiscoveryTarget.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.lastRunTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      orgConfig: isSet(object.orgConfig) ? DiscoveryConfig_OrgConfig.fromJSON(object.orgConfig) : undefined,
      otherCloudStartingLocation: isSet(object.otherCloudStartingLocation)
        ? OtherCloudDiscoveryStartingLocation.fromJSON(object.otherCloudStartingLocation)
        : undefined,
      inspectTemplates: globalThis.Array.isArray(object?.inspectTemplates)
        ? object.inspectTemplates.map((e: any) => globalThis.String(e))
        : [],
      actions: globalThis.Array.isArray(object?.actions)
        ? object.actions.map((e: any) => DataProfileAction.fromJSON(e))
        : [],
      targets: globalThis.Array.isArray(object?.targets)
        ? object.targets.map((e: any) => DiscoveryTarget.fromJSON(e))
        : [],
      errors: globalThis.Array.isArray(object?.errors)
        ? object.errors.map((e: any) => Error.fromJSON(e))
        : [],
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      lastRunTime: isSet(object.lastRunTime) ? fromJsonTimestamp(object.lastRunTime) : undefined,
      status: isSet(object.status) ? discoveryConfig_StatusFromJSON(object.status) : 0,
    };
  },

  toJSON(message: DiscoveryConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.orgConfig !== undefined) {
      obj.orgConfig = DiscoveryConfig_OrgConfig.toJSON(message.orgConfig);
    }
    if (message.otherCloudStartingLocation !== undefined) {
      obj.otherCloudStartingLocation = OtherCloudDiscoveryStartingLocation.toJSON(message.otherCloudStartingLocation);
    }
    if (message.inspectTemplates?.length) {
      obj.inspectTemplates = message.inspectTemplates;
    }
    if (message.actions?.length) {
      obj.actions = message.actions.map((e) => DataProfileAction.toJSON(e));
    }
    if (message.targets?.length) {
      obj.targets = message.targets.map((e) => DiscoveryTarget.toJSON(e));
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.lastRunTime !== undefined) {
      obj.lastRunTime = message.lastRunTime.toISOString();
    }
    if (message.status !== 0) {
      obj.status = discoveryConfig_StatusToJSON(message.status);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryConfig>): DiscoveryConfig {
    return DiscoveryConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryConfig>): DiscoveryConfig {
    const message = createBaseDiscoveryConfig();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.orgConfig = (object.orgConfig !== undefined && object.orgConfig !== null)
      ? DiscoveryConfig_OrgConfig.fromPartial(object.orgConfig)
      : undefined;
    message.otherCloudStartingLocation =
      (object.otherCloudStartingLocation !== undefined && object.otherCloudStartingLocation !== null)
        ? OtherCloudDiscoveryStartingLocation.fromPartial(object.otherCloudStartingLocation)
        : undefined;
    message.inspectTemplates = object.inspectTemplates?.map((e) => e) || [];
    message.actions = object.actions?.map((e) => DataProfileAction.fromPartial(e)) || [];
    message.targets = object.targets?.map((e) => DiscoveryTarget.fromPartial(e)) || [];
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.lastRunTime = object.lastRunTime ?? undefined;
    message.status = object.status ?? 0;
    return message;
  },
};

function createBaseDiscoveryConfig_OrgConfig(): DiscoveryConfig_OrgConfig {
  return { location: undefined, projectId: "" };
}

export const DiscoveryConfig_OrgConfig: MessageFns<DiscoveryConfig_OrgConfig> = {
  encode(message: DiscoveryConfig_OrgConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== undefined) {
      DiscoveryStartingLocation.encode(message.location, writer.uint32(10).fork()).join();
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryConfig_OrgConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryConfig_OrgConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = DiscoveryStartingLocation.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryConfig_OrgConfig {
    return {
      location: isSet(object.location) ? DiscoveryStartingLocation.fromJSON(object.location) : undefined,
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
    };
  },

  toJSON(message: DiscoveryConfig_OrgConfig): unknown {
    const obj: any = {};
    if (message.location !== undefined) {
      obj.location = DiscoveryStartingLocation.toJSON(message.location);
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryConfig_OrgConfig>): DiscoveryConfig_OrgConfig {
    return DiscoveryConfig_OrgConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryConfig_OrgConfig>): DiscoveryConfig_OrgConfig {
    const message = createBaseDiscoveryConfig_OrgConfig();
    message.location = (object.location !== undefined && object.location !== null)
      ? DiscoveryStartingLocation.fromPartial(object.location)
      : undefined;
    message.projectId = object.projectId ?? "";
    return message;
  },
};

function createBaseDiscoveryTarget(): DiscoveryTarget {
  return {
    bigQueryTarget: undefined,
    cloudSqlTarget: undefined,
    secretsTarget: undefined,
    cloudStorageTarget: undefined,
    otherCloudTarget: undefined,
  };
}

export const DiscoveryTarget: MessageFns<DiscoveryTarget> = {
  encode(message: DiscoveryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bigQueryTarget !== undefined) {
      BigQueryDiscoveryTarget.encode(message.bigQueryTarget, writer.uint32(10).fork()).join();
    }
    if (message.cloudSqlTarget !== undefined) {
      CloudSqlDiscoveryTarget.encode(message.cloudSqlTarget, writer.uint32(18).fork()).join();
    }
    if (message.secretsTarget !== undefined) {
      SecretsDiscoveryTarget.encode(message.secretsTarget, writer.uint32(26).fork()).join();
    }
    if (message.cloudStorageTarget !== undefined) {
      CloudStorageDiscoveryTarget.encode(message.cloudStorageTarget, writer.uint32(34).fork()).join();
    }
    if (message.otherCloudTarget !== undefined) {
      OtherCloudDiscoveryTarget.encode(message.otherCloudTarget, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bigQueryTarget = BigQueryDiscoveryTarget.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cloudSqlTarget = CloudSqlDiscoveryTarget.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secretsTarget = SecretsDiscoveryTarget.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cloudStorageTarget = CloudStorageDiscoveryTarget.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.otherCloudTarget = OtherCloudDiscoveryTarget.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryTarget {
    return {
      bigQueryTarget: isSet(object.bigQueryTarget)
        ? BigQueryDiscoveryTarget.fromJSON(object.bigQueryTarget)
        : undefined,
      cloudSqlTarget: isSet(object.cloudSqlTarget)
        ? CloudSqlDiscoveryTarget.fromJSON(object.cloudSqlTarget)
        : undefined,
      secretsTarget: isSet(object.secretsTarget) ? SecretsDiscoveryTarget.fromJSON(object.secretsTarget) : undefined,
      cloudStorageTarget: isSet(object.cloudStorageTarget)
        ? CloudStorageDiscoveryTarget.fromJSON(object.cloudStorageTarget)
        : undefined,
      otherCloudTarget: isSet(object.otherCloudTarget)
        ? OtherCloudDiscoveryTarget.fromJSON(object.otherCloudTarget)
        : undefined,
    };
  },

  toJSON(message: DiscoveryTarget): unknown {
    const obj: any = {};
    if (message.bigQueryTarget !== undefined) {
      obj.bigQueryTarget = BigQueryDiscoveryTarget.toJSON(message.bigQueryTarget);
    }
    if (message.cloudSqlTarget !== undefined) {
      obj.cloudSqlTarget = CloudSqlDiscoveryTarget.toJSON(message.cloudSqlTarget);
    }
    if (message.secretsTarget !== undefined) {
      obj.secretsTarget = SecretsDiscoveryTarget.toJSON(message.secretsTarget);
    }
    if (message.cloudStorageTarget !== undefined) {
      obj.cloudStorageTarget = CloudStorageDiscoveryTarget.toJSON(message.cloudStorageTarget);
    }
    if (message.otherCloudTarget !== undefined) {
      obj.otherCloudTarget = OtherCloudDiscoveryTarget.toJSON(message.otherCloudTarget);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryTarget>): DiscoveryTarget {
    return DiscoveryTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryTarget>): DiscoveryTarget {
    const message = createBaseDiscoveryTarget();
    message.bigQueryTarget = (object.bigQueryTarget !== undefined && object.bigQueryTarget !== null)
      ? BigQueryDiscoveryTarget.fromPartial(object.bigQueryTarget)
      : undefined;
    message.cloudSqlTarget = (object.cloudSqlTarget !== undefined && object.cloudSqlTarget !== null)
      ? CloudSqlDiscoveryTarget.fromPartial(object.cloudSqlTarget)
      : undefined;
    message.secretsTarget = (object.secretsTarget !== undefined && object.secretsTarget !== null)
      ? SecretsDiscoveryTarget.fromPartial(object.secretsTarget)
      : undefined;
    message.cloudStorageTarget = (object.cloudStorageTarget !== undefined && object.cloudStorageTarget !== null)
      ? CloudStorageDiscoveryTarget.fromPartial(object.cloudStorageTarget)
      : undefined;
    message.otherCloudTarget = (object.otherCloudTarget !== undefined && object.otherCloudTarget !== null)
      ? OtherCloudDiscoveryTarget.fromPartial(object.otherCloudTarget)
      : undefined;
    return message;
  },
};

function createBaseBigQueryDiscoveryTarget(): BigQueryDiscoveryTarget {
  return { filter: undefined, conditions: undefined, cadence: undefined, disabled: undefined };
}

export const BigQueryDiscoveryTarget: MessageFns<BigQueryDiscoveryTarget> = {
  encode(message: BigQueryDiscoveryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.filter !== undefined) {
      DiscoveryBigQueryFilter.encode(message.filter, writer.uint32(10).fork()).join();
    }
    if (message.conditions !== undefined) {
      DiscoveryBigQueryConditions.encode(message.conditions, writer.uint32(18).fork()).join();
    }
    if (message.cadence !== undefined) {
      DiscoveryGenerationCadence.encode(message.cadence, writer.uint32(26).fork()).join();
    }
    if (message.disabled !== undefined) {
      Disabled.encode(message.disabled, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDiscoveryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDiscoveryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.filter = DiscoveryBigQueryFilter.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.conditions = DiscoveryBigQueryConditions.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cadence = DiscoveryGenerationCadence.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.disabled = Disabled.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDiscoveryTarget {
    return {
      filter: isSet(object.filter) ? DiscoveryBigQueryFilter.fromJSON(object.filter) : undefined,
      conditions: isSet(object.conditions) ? DiscoveryBigQueryConditions.fromJSON(object.conditions) : undefined,
      cadence: isSet(object.cadence) ? DiscoveryGenerationCadence.fromJSON(object.cadence) : undefined,
      disabled: isSet(object.disabled) ? Disabled.fromJSON(object.disabled) : undefined,
    };
  },

  toJSON(message: BigQueryDiscoveryTarget): unknown {
    const obj: any = {};
    if (message.filter !== undefined) {
      obj.filter = DiscoveryBigQueryFilter.toJSON(message.filter);
    }
    if (message.conditions !== undefined) {
      obj.conditions = DiscoveryBigQueryConditions.toJSON(message.conditions);
    }
    if (message.cadence !== undefined) {
      obj.cadence = DiscoveryGenerationCadence.toJSON(message.cadence);
    }
    if (message.disabled !== undefined) {
      obj.disabled = Disabled.toJSON(message.disabled);
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryDiscoveryTarget>): BigQueryDiscoveryTarget {
    return BigQueryDiscoveryTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryDiscoveryTarget>): BigQueryDiscoveryTarget {
    const message = createBaseBigQueryDiscoveryTarget();
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? DiscoveryBigQueryFilter.fromPartial(object.filter)
      : undefined;
    message.conditions = (object.conditions !== undefined && object.conditions !== null)
      ? DiscoveryBigQueryConditions.fromPartial(object.conditions)
      : undefined;
    message.cadence = (object.cadence !== undefined && object.cadence !== null)
      ? DiscoveryGenerationCadence.fromPartial(object.cadence)
      : undefined;
    message.disabled = (object.disabled !== undefined && object.disabled !== null)
      ? Disabled.fromPartial(object.disabled)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryBigQueryFilter(): DiscoveryBigQueryFilter {
  return { tables: undefined, otherTables: undefined, tableReference: undefined };
}

export const DiscoveryBigQueryFilter: MessageFns<DiscoveryBigQueryFilter> = {
  encode(message: DiscoveryBigQueryFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tables !== undefined) {
      BigQueryTableCollection.encode(message.tables, writer.uint32(10).fork()).join();
    }
    if (message.otherTables !== undefined) {
      DiscoveryBigQueryFilter_AllOtherBigQueryTables.encode(message.otherTables, writer.uint32(18).fork()).join();
    }
    if (message.tableReference !== undefined) {
      TableReference.encode(message.tableReference, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryBigQueryFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryBigQueryFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tables = BigQueryTableCollection.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.otherTables = DiscoveryBigQueryFilter_AllOtherBigQueryTables.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tableReference = TableReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryBigQueryFilter {
    return {
      tables: isSet(object.tables) ? BigQueryTableCollection.fromJSON(object.tables) : undefined,
      otherTables: isSet(object.otherTables)
        ? DiscoveryBigQueryFilter_AllOtherBigQueryTables.fromJSON(object.otherTables)
        : undefined,
      tableReference: isSet(object.tableReference) ? TableReference.fromJSON(object.tableReference) : undefined,
    };
  },

  toJSON(message: DiscoveryBigQueryFilter): unknown {
    const obj: any = {};
    if (message.tables !== undefined) {
      obj.tables = BigQueryTableCollection.toJSON(message.tables);
    }
    if (message.otherTables !== undefined) {
      obj.otherTables = DiscoveryBigQueryFilter_AllOtherBigQueryTables.toJSON(message.otherTables);
    }
    if (message.tableReference !== undefined) {
      obj.tableReference = TableReference.toJSON(message.tableReference);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryBigQueryFilter>): DiscoveryBigQueryFilter {
    return DiscoveryBigQueryFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryBigQueryFilter>): DiscoveryBigQueryFilter {
    const message = createBaseDiscoveryBigQueryFilter();
    message.tables = (object.tables !== undefined && object.tables !== null)
      ? BigQueryTableCollection.fromPartial(object.tables)
      : undefined;
    message.otherTables = (object.otherTables !== undefined && object.otherTables !== null)
      ? DiscoveryBigQueryFilter_AllOtherBigQueryTables.fromPartial(object.otherTables)
      : undefined;
    message.tableReference = (object.tableReference !== undefined && object.tableReference !== null)
      ? TableReference.fromPartial(object.tableReference)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryBigQueryFilter_AllOtherBigQueryTables(): DiscoveryBigQueryFilter_AllOtherBigQueryTables {
  return {};
}

export const DiscoveryBigQueryFilter_AllOtherBigQueryTables: MessageFns<
  DiscoveryBigQueryFilter_AllOtherBigQueryTables
> = {
  encode(_: DiscoveryBigQueryFilter_AllOtherBigQueryTables, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryBigQueryFilter_AllOtherBigQueryTables {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryBigQueryFilter_AllOtherBigQueryTables();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DiscoveryBigQueryFilter_AllOtherBigQueryTables {
    return {};
  },

  toJSON(_: DiscoveryBigQueryFilter_AllOtherBigQueryTables): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<DiscoveryBigQueryFilter_AllOtherBigQueryTables>,
  ): DiscoveryBigQueryFilter_AllOtherBigQueryTables {
    return DiscoveryBigQueryFilter_AllOtherBigQueryTables.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<DiscoveryBigQueryFilter_AllOtherBigQueryTables>,
  ): DiscoveryBigQueryFilter_AllOtherBigQueryTables {
    const message = createBaseDiscoveryBigQueryFilter_AllOtherBigQueryTables();
    return message;
  },
};

function createBaseBigQueryTableCollection(): BigQueryTableCollection {
  return { includeRegexes: undefined };
}

export const BigQueryTableCollection: MessageFns<BigQueryTableCollection> = {
  encode(message: BigQueryTableCollection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeRegexes !== undefined) {
      BigQueryRegexes.encode(message.includeRegexes, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryTableCollection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryTableCollection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeRegexes = BigQueryRegexes.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryTableCollection {
    return {
      includeRegexes: isSet(object.includeRegexes) ? BigQueryRegexes.fromJSON(object.includeRegexes) : undefined,
    };
  },

  toJSON(message: BigQueryTableCollection): unknown {
    const obj: any = {};
    if (message.includeRegexes !== undefined) {
      obj.includeRegexes = BigQueryRegexes.toJSON(message.includeRegexes);
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryTableCollection>): BigQueryTableCollection {
    return BigQueryTableCollection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryTableCollection>): BigQueryTableCollection {
    const message = createBaseBigQueryTableCollection();
    message.includeRegexes = (object.includeRegexes !== undefined && object.includeRegexes !== null)
      ? BigQueryRegexes.fromPartial(object.includeRegexes)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryBigQueryConditions(): DiscoveryBigQueryConditions {
  return { createdAfter: undefined, types: undefined, typeCollection: undefined, orConditions: undefined };
}

export const DiscoveryBigQueryConditions: MessageFns<DiscoveryBigQueryConditions> = {
  encode(message: DiscoveryBigQueryConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createdAfter !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAfter), writer.uint32(10).fork()).join();
    }
    if (message.types !== undefined) {
      BigQueryTableTypes.encode(message.types, writer.uint32(18).fork()).join();
    }
    if (message.typeCollection !== undefined) {
      writer.uint32(24).int32(message.typeCollection);
    }
    if (message.orConditions !== undefined) {
      DiscoveryBigQueryConditions_OrConditions.encode(message.orConditions, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryBigQueryConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryBigQueryConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createdAfter = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.types = BigQueryTableTypes.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.typeCollection = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orConditions = DiscoveryBigQueryConditions_OrConditions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryBigQueryConditions {
    return {
      createdAfter: isSet(object.createdAfter) ? fromJsonTimestamp(object.createdAfter) : undefined,
      types: isSet(object.types) ? BigQueryTableTypes.fromJSON(object.types) : undefined,
      typeCollection: isSet(object.typeCollection)
        ? bigQueryTableTypeCollectionFromJSON(object.typeCollection)
        : undefined,
      orConditions: isSet(object.orConditions)
        ? DiscoveryBigQueryConditions_OrConditions.fromJSON(object.orConditions)
        : undefined,
    };
  },

  toJSON(message: DiscoveryBigQueryConditions): unknown {
    const obj: any = {};
    if (message.createdAfter !== undefined) {
      obj.createdAfter = message.createdAfter.toISOString();
    }
    if (message.types !== undefined) {
      obj.types = BigQueryTableTypes.toJSON(message.types);
    }
    if (message.typeCollection !== undefined) {
      obj.typeCollection = bigQueryTableTypeCollectionToJSON(message.typeCollection);
    }
    if (message.orConditions !== undefined) {
      obj.orConditions = DiscoveryBigQueryConditions_OrConditions.toJSON(message.orConditions);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryBigQueryConditions>): DiscoveryBigQueryConditions {
    return DiscoveryBigQueryConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryBigQueryConditions>): DiscoveryBigQueryConditions {
    const message = createBaseDiscoveryBigQueryConditions();
    message.createdAfter = object.createdAfter ?? undefined;
    message.types = (object.types !== undefined && object.types !== null)
      ? BigQueryTableTypes.fromPartial(object.types)
      : undefined;
    message.typeCollection = object.typeCollection ?? undefined;
    message.orConditions = (object.orConditions !== undefined && object.orConditions !== null)
      ? DiscoveryBigQueryConditions_OrConditions.fromPartial(object.orConditions)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryBigQueryConditions_OrConditions(): DiscoveryBigQueryConditions_OrConditions {
  return { minRowCount: 0, minAge: undefined };
}

export const DiscoveryBigQueryConditions_OrConditions: MessageFns<DiscoveryBigQueryConditions_OrConditions> = {
  encode(message: DiscoveryBigQueryConditions_OrConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minRowCount !== 0) {
      writer.uint32(8).int32(message.minRowCount);
    }
    if (message.minAge !== undefined) {
      Duration.encode(message.minAge, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryBigQueryConditions_OrConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryBigQueryConditions_OrConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.minRowCount = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.minAge = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryBigQueryConditions_OrConditions {
    return {
      minRowCount: isSet(object.minRowCount) ? globalThis.Number(object.minRowCount) : 0,
      minAge: isSet(object.minAge) ? Duration.fromJSON(object.minAge) : undefined,
    };
  },

  toJSON(message: DiscoveryBigQueryConditions_OrConditions): unknown {
    const obj: any = {};
    if (message.minRowCount !== 0) {
      obj.minRowCount = Math.round(message.minRowCount);
    }
    if (message.minAge !== undefined) {
      obj.minAge = Duration.toJSON(message.minAge);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryBigQueryConditions_OrConditions>): DiscoveryBigQueryConditions_OrConditions {
    return DiscoveryBigQueryConditions_OrConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryBigQueryConditions_OrConditions>): DiscoveryBigQueryConditions_OrConditions {
    const message = createBaseDiscoveryBigQueryConditions_OrConditions();
    message.minRowCount = object.minRowCount ?? 0;
    message.minAge = (object.minAge !== undefined && object.minAge !== null)
      ? Duration.fromPartial(object.minAge)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryGenerationCadence(): DiscoveryGenerationCadence {
  return {
    schemaModifiedCadence: undefined,
    tableModifiedCadence: undefined,
    inspectTemplateModifiedCadence: undefined,
    refreshFrequency: 0,
  };
}

export const DiscoveryGenerationCadence: MessageFns<DiscoveryGenerationCadence> = {
  encode(message: DiscoveryGenerationCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schemaModifiedCadence !== undefined) {
      DiscoverySchemaModifiedCadence.encode(message.schemaModifiedCadence, writer.uint32(10).fork()).join();
    }
    if (message.tableModifiedCadence !== undefined) {
      DiscoveryTableModifiedCadence.encode(message.tableModifiedCadence, writer.uint32(18).fork()).join();
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      DiscoveryInspectTemplateModifiedCadence.encode(message.inspectTemplateModifiedCadence, writer.uint32(26).fork())
        .join();
    }
    if (message.refreshFrequency !== 0) {
      writer.uint32(32).int32(message.refreshFrequency);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryGenerationCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryGenerationCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schemaModifiedCadence = DiscoverySchemaModifiedCadence.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tableModifiedCadence = DiscoveryTableModifiedCadence.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.refreshFrequency = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryGenerationCadence {
    return {
      schemaModifiedCadence: isSet(object.schemaModifiedCadence)
        ? DiscoverySchemaModifiedCadence.fromJSON(object.schemaModifiedCadence)
        : undefined,
      tableModifiedCadence: isSet(object.tableModifiedCadence)
        ? DiscoveryTableModifiedCadence.fromJSON(object.tableModifiedCadence)
        : undefined,
      inspectTemplateModifiedCadence: isSet(object.inspectTemplateModifiedCadence)
        ? DiscoveryInspectTemplateModifiedCadence.fromJSON(object.inspectTemplateModifiedCadence)
        : undefined,
      refreshFrequency: isSet(object.refreshFrequency)
        ? dataProfileUpdateFrequencyFromJSON(object.refreshFrequency)
        : 0,
    };
  },

  toJSON(message: DiscoveryGenerationCadence): unknown {
    const obj: any = {};
    if (message.schemaModifiedCadence !== undefined) {
      obj.schemaModifiedCadence = DiscoverySchemaModifiedCadence.toJSON(message.schemaModifiedCadence);
    }
    if (message.tableModifiedCadence !== undefined) {
      obj.tableModifiedCadence = DiscoveryTableModifiedCadence.toJSON(message.tableModifiedCadence);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      obj.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.toJSON(
        message.inspectTemplateModifiedCadence,
      );
    }
    if (message.refreshFrequency !== 0) {
      obj.refreshFrequency = dataProfileUpdateFrequencyToJSON(message.refreshFrequency);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryGenerationCadence>): DiscoveryGenerationCadence {
    return DiscoveryGenerationCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryGenerationCadence>): DiscoveryGenerationCadence {
    const message = createBaseDiscoveryGenerationCadence();
    message.schemaModifiedCadence =
      (object.schemaModifiedCadence !== undefined && object.schemaModifiedCadence !== null)
        ? DiscoverySchemaModifiedCadence.fromPartial(object.schemaModifiedCadence)
        : undefined;
    message.tableModifiedCadence = (object.tableModifiedCadence !== undefined && object.tableModifiedCadence !== null)
      ? DiscoveryTableModifiedCadence.fromPartial(object.tableModifiedCadence)
      : undefined;
    message.inspectTemplateModifiedCadence =
      (object.inspectTemplateModifiedCadence !== undefined && object.inspectTemplateModifiedCadence !== null)
        ? DiscoveryInspectTemplateModifiedCadence.fromPartial(object.inspectTemplateModifiedCadence)
        : undefined;
    message.refreshFrequency = object.refreshFrequency ?? 0;
    return message;
  },
};

function createBaseDiscoveryTableModifiedCadence(): DiscoveryTableModifiedCadence {
  return { types: [], frequency: 0 };
}

export const DiscoveryTableModifiedCadence: MessageFns<DiscoveryTableModifiedCadence> = {
  encode(message: DiscoveryTableModifiedCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.types) {
      writer.int32(v);
    }
    writer.join();
    if (message.frequency !== 0) {
      writer.uint32(16).int32(message.frequency);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryTableModifiedCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryTableModifiedCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.types.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.types.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.frequency = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryTableModifiedCadence {
    return {
      types: globalThis.Array.isArray(object?.types)
        ? object.types.map((e: any) => bigQueryTableModificationFromJSON(e))
        : [],
      frequency: isSet(object.frequency) ? dataProfileUpdateFrequencyFromJSON(object.frequency) : 0,
    };
  },

  toJSON(message: DiscoveryTableModifiedCadence): unknown {
    const obj: any = {};
    if (message.types?.length) {
      obj.types = message.types.map((e) => bigQueryTableModificationToJSON(e));
    }
    if (message.frequency !== 0) {
      obj.frequency = dataProfileUpdateFrequencyToJSON(message.frequency);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryTableModifiedCadence>): DiscoveryTableModifiedCadence {
    return DiscoveryTableModifiedCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryTableModifiedCadence>): DiscoveryTableModifiedCadence {
    const message = createBaseDiscoveryTableModifiedCadence();
    message.types = object.types?.map((e) => e) || [];
    message.frequency = object.frequency ?? 0;
    return message;
  },
};

function createBaseDiscoverySchemaModifiedCadence(): DiscoverySchemaModifiedCadence {
  return { types: [], frequency: 0 };
}

export const DiscoverySchemaModifiedCadence: MessageFns<DiscoverySchemaModifiedCadence> = {
  encode(message: DiscoverySchemaModifiedCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.types) {
      writer.int32(v);
    }
    writer.join();
    if (message.frequency !== 0) {
      writer.uint32(16).int32(message.frequency);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoverySchemaModifiedCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoverySchemaModifiedCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.types.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.types.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.frequency = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoverySchemaModifiedCadence {
    return {
      types: globalThis.Array.isArray(object?.types)
        ? object.types.map((e: any) => bigQuerySchemaModificationFromJSON(e))
        : [],
      frequency: isSet(object.frequency) ? dataProfileUpdateFrequencyFromJSON(object.frequency) : 0,
    };
  },

  toJSON(message: DiscoverySchemaModifiedCadence): unknown {
    const obj: any = {};
    if (message.types?.length) {
      obj.types = message.types.map((e) => bigQuerySchemaModificationToJSON(e));
    }
    if (message.frequency !== 0) {
      obj.frequency = dataProfileUpdateFrequencyToJSON(message.frequency);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoverySchemaModifiedCadence>): DiscoverySchemaModifiedCadence {
    return DiscoverySchemaModifiedCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoverySchemaModifiedCadence>): DiscoverySchemaModifiedCadence {
    const message = createBaseDiscoverySchemaModifiedCadence();
    message.types = object.types?.map((e) => e) || [];
    message.frequency = object.frequency ?? 0;
    return message;
  },
};

function createBaseDiscoveryInspectTemplateModifiedCadence(): DiscoveryInspectTemplateModifiedCadence {
  return { frequency: 0 };
}

export const DiscoveryInspectTemplateModifiedCadence: MessageFns<DiscoveryInspectTemplateModifiedCadence> = {
  encode(message: DiscoveryInspectTemplateModifiedCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.frequency !== 0) {
      writer.uint32(8).int32(message.frequency);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryInspectTemplateModifiedCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryInspectTemplateModifiedCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.frequency = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryInspectTemplateModifiedCadence {
    return { frequency: isSet(object.frequency) ? dataProfileUpdateFrequencyFromJSON(object.frequency) : 0 };
  },

  toJSON(message: DiscoveryInspectTemplateModifiedCadence): unknown {
    const obj: any = {};
    if (message.frequency !== 0) {
      obj.frequency = dataProfileUpdateFrequencyToJSON(message.frequency);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryInspectTemplateModifiedCadence>): DiscoveryInspectTemplateModifiedCadence {
    return DiscoveryInspectTemplateModifiedCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryInspectTemplateModifiedCadence>): DiscoveryInspectTemplateModifiedCadence {
    const message = createBaseDiscoveryInspectTemplateModifiedCadence();
    message.frequency = object.frequency ?? 0;
    return message;
  },
};

function createBaseCloudSqlDiscoveryTarget(): CloudSqlDiscoveryTarget {
  return { filter: undefined, conditions: undefined, generationCadence: undefined, disabled: undefined };
}

export const CloudSqlDiscoveryTarget: MessageFns<CloudSqlDiscoveryTarget> = {
  encode(message: CloudSqlDiscoveryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.filter !== undefined) {
      DiscoveryCloudSqlFilter.encode(message.filter, writer.uint32(10).fork()).join();
    }
    if (message.conditions !== undefined) {
      DiscoveryCloudSqlConditions.encode(message.conditions, writer.uint32(18).fork()).join();
    }
    if (message.generationCadence !== undefined) {
      DiscoveryCloudSqlGenerationCadence.encode(message.generationCadence, writer.uint32(26).fork()).join();
    }
    if (message.disabled !== undefined) {
      Disabled.encode(message.disabled, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlDiscoveryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlDiscoveryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.filter = DiscoveryCloudSqlFilter.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.conditions = DiscoveryCloudSqlConditions.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.generationCadence = DiscoveryCloudSqlGenerationCadence.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.disabled = Disabled.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlDiscoveryTarget {
    return {
      filter: isSet(object.filter) ? DiscoveryCloudSqlFilter.fromJSON(object.filter) : undefined,
      conditions: isSet(object.conditions) ? DiscoveryCloudSqlConditions.fromJSON(object.conditions) : undefined,
      generationCadence: isSet(object.generationCadence)
        ? DiscoveryCloudSqlGenerationCadence.fromJSON(object.generationCadence)
        : undefined,
      disabled: isSet(object.disabled) ? Disabled.fromJSON(object.disabled) : undefined,
    };
  },

  toJSON(message: CloudSqlDiscoveryTarget): unknown {
    const obj: any = {};
    if (message.filter !== undefined) {
      obj.filter = DiscoveryCloudSqlFilter.toJSON(message.filter);
    }
    if (message.conditions !== undefined) {
      obj.conditions = DiscoveryCloudSqlConditions.toJSON(message.conditions);
    }
    if (message.generationCadence !== undefined) {
      obj.generationCadence = DiscoveryCloudSqlGenerationCadence.toJSON(message.generationCadence);
    }
    if (message.disabled !== undefined) {
      obj.disabled = Disabled.toJSON(message.disabled);
    }
    return obj;
  },

  create(base?: DeepPartial<CloudSqlDiscoveryTarget>): CloudSqlDiscoveryTarget {
    return CloudSqlDiscoveryTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudSqlDiscoveryTarget>): CloudSqlDiscoveryTarget {
    const message = createBaseCloudSqlDiscoveryTarget();
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? DiscoveryCloudSqlFilter.fromPartial(object.filter)
      : undefined;
    message.conditions = (object.conditions !== undefined && object.conditions !== null)
      ? DiscoveryCloudSqlConditions.fromPartial(object.conditions)
      : undefined;
    message.generationCadence = (object.generationCadence !== undefined && object.generationCadence !== null)
      ? DiscoveryCloudSqlGenerationCadence.fromPartial(object.generationCadence)
      : undefined;
    message.disabled = (object.disabled !== undefined && object.disabled !== null)
      ? Disabled.fromPartial(object.disabled)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryCloudSqlFilter(): DiscoveryCloudSqlFilter {
  return { collection: undefined, others: undefined, databaseResourceReference: undefined };
}

export const DiscoveryCloudSqlFilter: MessageFns<DiscoveryCloudSqlFilter> = {
  encode(message: DiscoveryCloudSqlFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.collection !== undefined) {
      DatabaseResourceCollection.encode(message.collection, writer.uint32(10).fork()).join();
    }
    if (message.others !== undefined) {
      AllOtherDatabaseResources.encode(message.others, writer.uint32(18).fork()).join();
    }
    if (message.databaseResourceReference !== undefined) {
      DatabaseResourceReference.encode(message.databaseResourceReference, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudSqlFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudSqlFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.collection = DatabaseResourceCollection.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.others = AllOtherDatabaseResources.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.databaseResourceReference = DatabaseResourceReference.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudSqlFilter {
    return {
      collection: isSet(object.collection) ? DatabaseResourceCollection.fromJSON(object.collection) : undefined,
      others: isSet(object.others) ? AllOtherDatabaseResources.fromJSON(object.others) : undefined,
      databaseResourceReference: isSet(object.databaseResourceReference)
        ? DatabaseResourceReference.fromJSON(object.databaseResourceReference)
        : undefined,
    };
  },

  toJSON(message: DiscoveryCloudSqlFilter): unknown {
    const obj: any = {};
    if (message.collection !== undefined) {
      obj.collection = DatabaseResourceCollection.toJSON(message.collection);
    }
    if (message.others !== undefined) {
      obj.others = AllOtherDatabaseResources.toJSON(message.others);
    }
    if (message.databaseResourceReference !== undefined) {
      obj.databaseResourceReference = DatabaseResourceReference.toJSON(message.databaseResourceReference);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryCloudSqlFilter>): DiscoveryCloudSqlFilter {
    return DiscoveryCloudSqlFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryCloudSqlFilter>): DiscoveryCloudSqlFilter {
    const message = createBaseDiscoveryCloudSqlFilter();
    message.collection = (object.collection !== undefined && object.collection !== null)
      ? DatabaseResourceCollection.fromPartial(object.collection)
      : undefined;
    message.others = (object.others !== undefined && object.others !== null)
      ? AllOtherDatabaseResources.fromPartial(object.others)
      : undefined;
    message.databaseResourceReference =
      (object.databaseResourceReference !== undefined && object.databaseResourceReference !== null)
        ? DatabaseResourceReference.fromPartial(object.databaseResourceReference)
        : undefined;
    return message;
  },
};

function createBaseDatabaseResourceCollection(): DatabaseResourceCollection {
  return { includeRegexes: undefined };
}

export const DatabaseResourceCollection: MessageFns<DatabaseResourceCollection> = {
  encode(message: DatabaseResourceCollection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeRegexes !== undefined) {
      DatabaseResourceRegexes.encode(message.includeRegexes, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseResourceCollection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseResourceCollection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeRegexes = DatabaseResourceRegexes.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseResourceCollection {
    return {
      includeRegexes: isSet(object.includeRegexes)
        ? DatabaseResourceRegexes.fromJSON(object.includeRegexes)
        : undefined,
    };
  },

  toJSON(message: DatabaseResourceCollection): unknown {
    const obj: any = {};
    if (message.includeRegexes !== undefined) {
      obj.includeRegexes = DatabaseResourceRegexes.toJSON(message.includeRegexes);
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseResourceCollection>): DatabaseResourceCollection {
    return DatabaseResourceCollection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseResourceCollection>): DatabaseResourceCollection {
    const message = createBaseDatabaseResourceCollection();
    message.includeRegexes = (object.includeRegexes !== undefined && object.includeRegexes !== null)
      ? DatabaseResourceRegexes.fromPartial(object.includeRegexes)
      : undefined;
    return message;
  },
};

function createBaseDatabaseResourceRegexes(): DatabaseResourceRegexes {
  return { patterns: [] };
}

export const DatabaseResourceRegexes: MessageFns<DatabaseResourceRegexes> = {
  encode(message: DatabaseResourceRegexes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.patterns) {
      DatabaseResourceRegex.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseResourceRegexes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseResourceRegexes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.patterns.push(DatabaseResourceRegex.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseResourceRegexes {
    return {
      patterns: globalThis.Array.isArray(object?.patterns)
        ? object.patterns.map((e: any) => DatabaseResourceRegex.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DatabaseResourceRegexes): unknown {
    const obj: any = {};
    if (message.patterns?.length) {
      obj.patterns = message.patterns.map((e) => DatabaseResourceRegex.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseResourceRegexes>): DatabaseResourceRegexes {
    return DatabaseResourceRegexes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseResourceRegexes>): DatabaseResourceRegexes {
    const message = createBaseDatabaseResourceRegexes();
    message.patterns = object.patterns?.map((e) => DatabaseResourceRegex.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDatabaseResourceRegex(): DatabaseResourceRegex {
  return { projectIdRegex: "", instanceRegex: "", databaseRegex: "", databaseResourceNameRegex: "" };
}

export const DatabaseResourceRegex: MessageFns<DatabaseResourceRegex> = {
  encode(message: DatabaseResourceRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectIdRegex !== "") {
      writer.uint32(10).string(message.projectIdRegex);
    }
    if (message.instanceRegex !== "") {
      writer.uint32(18).string(message.instanceRegex);
    }
    if (message.databaseRegex !== "") {
      writer.uint32(26).string(message.databaseRegex);
    }
    if (message.databaseResourceNameRegex !== "") {
      writer.uint32(34).string(message.databaseResourceNameRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseResourceRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseResourceRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectIdRegex = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instanceRegex = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.databaseRegex = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.databaseResourceNameRegex = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseResourceRegex {
    return {
      projectIdRegex: isSet(object.projectIdRegex) ? globalThis.String(object.projectIdRegex) : "",
      instanceRegex: isSet(object.instanceRegex) ? globalThis.String(object.instanceRegex) : "",
      databaseRegex: isSet(object.databaseRegex) ? globalThis.String(object.databaseRegex) : "",
      databaseResourceNameRegex: isSet(object.databaseResourceNameRegex)
        ? globalThis.String(object.databaseResourceNameRegex)
        : "",
    };
  },

  toJSON(message: DatabaseResourceRegex): unknown {
    const obj: any = {};
    if (message.projectIdRegex !== "") {
      obj.projectIdRegex = message.projectIdRegex;
    }
    if (message.instanceRegex !== "") {
      obj.instanceRegex = message.instanceRegex;
    }
    if (message.databaseRegex !== "") {
      obj.databaseRegex = message.databaseRegex;
    }
    if (message.databaseResourceNameRegex !== "") {
      obj.databaseResourceNameRegex = message.databaseResourceNameRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseResourceRegex>): DatabaseResourceRegex {
    return DatabaseResourceRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseResourceRegex>): DatabaseResourceRegex {
    const message = createBaseDatabaseResourceRegex();
    message.projectIdRegex = object.projectIdRegex ?? "";
    message.instanceRegex = object.instanceRegex ?? "";
    message.databaseRegex = object.databaseRegex ?? "";
    message.databaseResourceNameRegex = object.databaseResourceNameRegex ?? "";
    return message;
  },
};

function createBaseAllOtherDatabaseResources(): AllOtherDatabaseResources {
  return {};
}

export const AllOtherDatabaseResources: MessageFns<AllOtherDatabaseResources> = {
  encode(_: AllOtherDatabaseResources, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllOtherDatabaseResources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllOtherDatabaseResources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AllOtherDatabaseResources {
    return {};
  },

  toJSON(_: AllOtherDatabaseResources): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AllOtherDatabaseResources>): AllOtherDatabaseResources {
    return AllOtherDatabaseResources.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AllOtherDatabaseResources>): AllOtherDatabaseResources {
    const message = createBaseAllOtherDatabaseResources();
    return message;
  },
};

function createBaseDatabaseResourceReference(): DatabaseResourceReference {
  return { projectId: "", instance: "", database: "", databaseResource: "" };
}

export const DatabaseResourceReference: MessageFns<DatabaseResourceReference> = {
  encode(message: DatabaseResourceReference, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.instance !== "") {
      writer.uint32(18).string(message.instance);
    }
    if (message.database !== "") {
      writer.uint32(26).string(message.database);
    }
    if (message.databaseResource !== "") {
      writer.uint32(34).string(message.databaseResource);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseResourceReference {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseResourceReference();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instance = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.database = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.databaseResource = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseResourceReference {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      instance: isSet(object.instance) ? globalThis.String(object.instance) : "",
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      databaseResource: isSet(object.databaseResource) ? globalThis.String(object.databaseResource) : "",
    };
  },

  toJSON(message: DatabaseResourceReference): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.databaseResource !== "") {
      obj.databaseResource = message.databaseResource;
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseResourceReference>): DatabaseResourceReference {
    return DatabaseResourceReference.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseResourceReference>): DatabaseResourceReference {
    const message = createBaseDatabaseResourceReference();
    message.projectId = object.projectId ?? "";
    message.instance = object.instance ?? "";
    message.database = object.database ?? "";
    message.databaseResource = object.databaseResource ?? "";
    return message;
  },
};

function createBaseDiscoveryCloudSqlConditions(): DiscoveryCloudSqlConditions {
  return { databaseEngines: [], types: [] };
}

export const DiscoveryCloudSqlConditions: MessageFns<DiscoveryCloudSqlConditions> = {
  encode(message: DiscoveryCloudSqlConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.databaseEngines) {
      writer.int32(v);
    }
    writer.join();
    writer.uint32(26).fork();
    for (const v of message.types) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudSqlConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudSqlConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.databaseEngines.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.databaseEngines.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 3:
          if (tag === 24) {
            message.types.push(reader.int32() as any);

            continue;
          }

          if (tag === 26) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.types.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudSqlConditions {
    return {
      databaseEngines: globalThis.Array.isArray(object?.databaseEngines)
        ? object.databaseEngines.map((e: any) => discoveryCloudSqlConditions_DatabaseEngineFromJSON(e))
        : [],
      types: globalThis.Array.isArray(object?.types)
        ? object.types.map((e: any) => discoveryCloudSqlConditions_DatabaseResourceTypeFromJSON(e))
        : [],
    };
  },

  toJSON(message: DiscoveryCloudSqlConditions): unknown {
    const obj: any = {};
    if (message.databaseEngines?.length) {
      obj.databaseEngines = message.databaseEngines.map((e) => discoveryCloudSqlConditions_DatabaseEngineToJSON(e));
    }
    if (message.types?.length) {
      obj.types = message.types.map((e) => discoveryCloudSqlConditions_DatabaseResourceTypeToJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryCloudSqlConditions>): DiscoveryCloudSqlConditions {
    return DiscoveryCloudSqlConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryCloudSqlConditions>): DiscoveryCloudSqlConditions {
    const message = createBaseDiscoveryCloudSqlConditions();
    message.databaseEngines = object.databaseEngines?.map((e) => e) || [];
    message.types = object.types?.map((e) => e) || [];
    return message;
  },
};

function createBaseDiscoveryCloudSqlGenerationCadence(): DiscoveryCloudSqlGenerationCadence {
  return { schemaModifiedCadence: undefined, refreshFrequency: 0, inspectTemplateModifiedCadence: undefined };
}

export const DiscoveryCloudSqlGenerationCadence: MessageFns<DiscoveryCloudSqlGenerationCadence> = {
  encode(message: DiscoveryCloudSqlGenerationCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schemaModifiedCadence !== undefined) {
      DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence.encode(
        message.schemaModifiedCadence,
        writer.uint32(10).fork(),
      ).join();
    }
    if (message.refreshFrequency !== 0) {
      writer.uint32(16).int32(message.refreshFrequency);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      DiscoveryInspectTemplateModifiedCadence.encode(message.inspectTemplateModifiedCadence, writer.uint32(26).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudSqlGenerationCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudSqlGenerationCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schemaModifiedCadence = DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.refreshFrequency = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudSqlGenerationCadence {
    return {
      schemaModifiedCadence: isSet(object.schemaModifiedCadence)
        ? DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence.fromJSON(object.schemaModifiedCadence)
        : undefined,
      refreshFrequency: isSet(object.refreshFrequency)
        ? dataProfileUpdateFrequencyFromJSON(object.refreshFrequency)
        : 0,
      inspectTemplateModifiedCadence: isSet(object.inspectTemplateModifiedCadence)
        ? DiscoveryInspectTemplateModifiedCadence.fromJSON(object.inspectTemplateModifiedCadence)
        : undefined,
    };
  },

  toJSON(message: DiscoveryCloudSqlGenerationCadence): unknown {
    const obj: any = {};
    if (message.schemaModifiedCadence !== undefined) {
      obj.schemaModifiedCadence = DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence.toJSON(
        message.schemaModifiedCadence,
      );
    }
    if (message.refreshFrequency !== 0) {
      obj.refreshFrequency = dataProfileUpdateFrequencyToJSON(message.refreshFrequency);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      obj.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.toJSON(
        message.inspectTemplateModifiedCadence,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryCloudSqlGenerationCadence>): DiscoveryCloudSqlGenerationCadence {
    return DiscoveryCloudSqlGenerationCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryCloudSqlGenerationCadence>): DiscoveryCloudSqlGenerationCadence {
    const message = createBaseDiscoveryCloudSqlGenerationCadence();
    message.schemaModifiedCadence =
      (object.schemaModifiedCadence !== undefined && object.schemaModifiedCadence !== null)
        ? DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence.fromPartial(object.schemaModifiedCadence)
        : undefined;
    message.refreshFrequency = object.refreshFrequency ?? 0;
    message.inspectTemplateModifiedCadence =
      (object.inspectTemplateModifiedCadence !== undefined && object.inspectTemplateModifiedCadence !== null)
        ? DiscoveryInspectTemplateModifiedCadence.fromPartial(object.inspectTemplateModifiedCadence)
        : undefined;
    return message;
  },
};

function createBaseDiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence(): DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence {
  return { types: [], frequency: 0 };
}

export const DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence: MessageFns<
  DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence
> = {
  encode(
    message: DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.types) {
      writer.int32(v);
    }
    writer.join();
    if (message.frequency !== 0) {
      writer.uint32(16).int32(message.frequency);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.types.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.types.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.frequency = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence {
    return {
      types: globalThis.Array.isArray(object?.types)
        ? object.types.map((e: any) =>
          discoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModificationFromJSON(e)
        )
        : [],
      frequency: isSet(object.frequency) ? dataProfileUpdateFrequencyFromJSON(object.frequency) : 0,
    };
  },

  toJSON(message: DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence): unknown {
    const obj: any = {};
    if (message.types?.length) {
      obj.types = message.types.map((e) =>
        discoveryCloudSqlGenerationCadence_SchemaModifiedCadence_CloudSqlSchemaModificationToJSON(e)
      );
    }
    if (message.frequency !== 0) {
      obj.frequency = dataProfileUpdateFrequencyToJSON(message.frequency);
    }
    return obj;
  },

  create(
    base?: DeepPartial<DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence>,
  ): DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence {
    return DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence>,
  ): DiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence {
    const message = createBaseDiscoveryCloudSqlGenerationCadence_SchemaModifiedCadence();
    message.types = object.types?.map((e) => e) || [];
    message.frequency = object.frequency ?? 0;
    return message;
  },
};

function createBaseSecretsDiscoveryTarget(): SecretsDiscoveryTarget {
  return {};
}

export const SecretsDiscoveryTarget: MessageFns<SecretsDiscoveryTarget> = {
  encode(_: SecretsDiscoveryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretsDiscoveryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretsDiscoveryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): SecretsDiscoveryTarget {
    return {};
  },

  toJSON(_: SecretsDiscoveryTarget): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<SecretsDiscoveryTarget>): SecretsDiscoveryTarget {
    return SecretsDiscoveryTarget.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<SecretsDiscoveryTarget>): SecretsDiscoveryTarget {
    const message = createBaseSecretsDiscoveryTarget();
    return message;
  },
};

function createBaseCloudStorageDiscoveryTarget(): CloudStorageDiscoveryTarget {
  return { filter: undefined, conditions: undefined, generationCadence: undefined, disabled: undefined };
}

export const CloudStorageDiscoveryTarget: MessageFns<CloudStorageDiscoveryTarget> = {
  encode(message: CloudStorageDiscoveryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.filter !== undefined) {
      DiscoveryCloudStorageFilter.encode(message.filter, writer.uint32(10).fork()).join();
    }
    if (message.conditions !== undefined) {
      DiscoveryFileStoreConditions.encode(message.conditions, writer.uint32(34).fork()).join();
    }
    if (message.generationCadence !== undefined) {
      DiscoveryCloudStorageGenerationCadence.encode(message.generationCadence, writer.uint32(18).fork()).join();
    }
    if (message.disabled !== undefined) {
      Disabled.encode(message.disabled, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageDiscoveryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageDiscoveryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.filter = DiscoveryCloudStorageFilter.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.conditions = DiscoveryFileStoreConditions.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.generationCadence = DiscoveryCloudStorageGenerationCadence.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.disabled = Disabled.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudStorageDiscoveryTarget {
    return {
      filter: isSet(object.filter) ? DiscoveryCloudStorageFilter.fromJSON(object.filter) : undefined,
      conditions: isSet(object.conditions) ? DiscoveryFileStoreConditions.fromJSON(object.conditions) : undefined,
      generationCadence: isSet(object.generationCadence)
        ? DiscoveryCloudStorageGenerationCadence.fromJSON(object.generationCadence)
        : undefined,
      disabled: isSet(object.disabled) ? Disabled.fromJSON(object.disabled) : undefined,
    };
  },

  toJSON(message: CloudStorageDiscoveryTarget): unknown {
    const obj: any = {};
    if (message.filter !== undefined) {
      obj.filter = DiscoveryCloudStorageFilter.toJSON(message.filter);
    }
    if (message.conditions !== undefined) {
      obj.conditions = DiscoveryFileStoreConditions.toJSON(message.conditions);
    }
    if (message.generationCadence !== undefined) {
      obj.generationCadence = DiscoveryCloudStorageGenerationCadence.toJSON(message.generationCadence);
    }
    if (message.disabled !== undefined) {
      obj.disabled = Disabled.toJSON(message.disabled);
    }
    return obj;
  },

  create(base?: DeepPartial<CloudStorageDiscoveryTarget>): CloudStorageDiscoveryTarget {
    return CloudStorageDiscoveryTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudStorageDiscoveryTarget>): CloudStorageDiscoveryTarget {
    const message = createBaseCloudStorageDiscoveryTarget();
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? DiscoveryCloudStorageFilter.fromPartial(object.filter)
      : undefined;
    message.conditions = (object.conditions !== undefined && object.conditions !== null)
      ? DiscoveryFileStoreConditions.fromPartial(object.conditions)
      : undefined;
    message.generationCadence = (object.generationCadence !== undefined && object.generationCadence !== null)
      ? DiscoveryCloudStorageGenerationCadence.fromPartial(object.generationCadence)
      : undefined;
    message.disabled = (object.disabled !== undefined && object.disabled !== null)
      ? Disabled.fromPartial(object.disabled)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryCloudStorageFilter(): DiscoveryCloudStorageFilter {
  return { collection: undefined, cloudStorageResourceReference: undefined, others: undefined };
}

export const DiscoveryCloudStorageFilter: MessageFns<DiscoveryCloudStorageFilter> = {
  encode(message: DiscoveryCloudStorageFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.collection !== undefined) {
      FileStoreCollection.encode(message.collection, writer.uint32(10).fork()).join();
    }
    if (message.cloudStorageResourceReference !== undefined) {
      CloudStorageResourceReference.encode(message.cloudStorageResourceReference, writer.uint32(18).fork()).join();
    }
    if (message.others !== undefined) {
      AllOtherResources.encode(message.others, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudStorageFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudStorageFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.collection = FileStoreCollection.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cloudStorageResourceReference = CloudStorageResourceReference.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.others = AllOtherResources.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudStorageFilter {
    return {
      collection: isSet(object.collection) ? FileStoreCollection.fromJSON(object.collection) : undefined,
      cloudStorageResourceReference: isSet(object.cloudStorageResourceReference)
        ? CloudStorageResourceReference.fromJSON(object.cloudStorageResourceReference)
        : undefined,
      others: isSet(object.others) ? AllOtherResources.fromJSON(object.others) : undefined,
    };
  },

  toJSON(message: DiscoveryCloudStorageFilter): unknown {
    const obj: any = {};
    if (message.collection !== undefined) {
      obj.collection = FileStoreCollection.toJSON(message.collection);
    }
    if (message.cloudStorageResourceReference !== undefined) {
      obj.cloudStorageResourceReference = CloudStorageResourceReference.toJSON(message.cloudStorageResourceReference);
    }
    if (message.others !== undefined) {
      obj.others = AllOtherResources.toJSON(message.others);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryCloudStorageFilter>): DiscoveryCloudStorageFilter {
    return DiscoveryCloudStorageFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryCloudStorageFilter>): DiscoveryCloudStorageFilter {
    const message = createBaseDiscoveryCloudStorageFilter();
    message.collection = (object.collection !== undefined && object.collection !== null)
      ? FileStoreCollection.fromPartial(object.collection)
      : undefined;
    message.cloudStorageResourceReference =
      (object.cloudStorageResourceReference !== undefined && object.cloudStorageResourceReference !== null)
        ? CloudStorageResourceReference.fromPartial(object.cloudStorageResourceReference)
        : undefined;
    message.others = (object.others !== undefined && object.others !== null)
      ? AllOtherResources.fromPartial(object.others)
      : undefined;
    return message;
  },
};

function createBaseFileStoreCollection(): FileStoreCollection {
  return { includeRegexes: undefined };
}

export const FileStoreCollection: MessageFns<FileStoreCollection> = {
  encode(message: FileStoreCollection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeRegexes !== undefined) {
      FileStoreRegexes.encode(message.includeRegexes, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreCollection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreCollection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeRegexes = FileStoreRegexes.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreCollection {
    return {
      includeRegexes: isSet(object.includeRegexes) ? FileStoreRegexes.fromJSON(object.includeRegexes) : undefined,
    };
  },

  toJSON(message: FileStoreCollection): unknown {
    const obj: any = {};
    if (message.includeRegexes !== undefined) {
      obj.includeRegexes = FileStoreRegexes.toJSON(message.includeRegexes);
    }
    return obj;
  },

  create(base?: DeepPartial<FileStoreCollection>): FileStoreCollection {
    return FileStoreCollection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStoreCollection>): FileStoreCollection {
    const message = createBaseFileStoreCollection();
    message.includeRegexes = (object.includeRegexes !== undefined && object.includeRegexes !== null)
      ? FileStoreRegexes.fromPartial(object.includeRegexes)
      : undefined;
    return message;
  },
};

function createBaseFileStoreRegexes(): FileStoreRegexes {
  return { patterns: [] };
}

export const FileStoreRegexes: MessageFns<FileStoreRegexes> = {
  encode(message: FileStoreRegexes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.patterns) {
      FileStoreRegex.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreRegexes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreRegexes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.patterns.push(FileStoreRegex.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreRegexes {
    return {
      patterns: globalThis.Array.isArray(object?.patterns)
        ? object.patterns.map((e: any) => FileStoreRegex.fromJSON(e))
        : [],
    };
  },

  toJSON(message: FileStoreRegexes): unknown {
    const obj: any = {};
    if (message.patterns?.length) {
      obj.patterns = message.patterns.map((e) => FileStoreRegex.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<FileStoreRegexes>): FileStoreRegexes {
    return FileStoreRegexes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStoreRegexes>): FileStoreRegexes {
    const message = createBaseFileStoreRegexes();
    message.patterns = object.patterns?.map((e) => FileStoreRegex.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFileStoreRegex(): FileStoreRegex {
  return { cloudStorageRegex: undefined };
}

export const FileStoreRegex: MessageFns<FileStoreRegex> = {
  encode(message: FileStoreRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloudStorageRegex !== undefined) {
      CloudStorageRegex.encode(message.cloudStorageRegex, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cloudStorageRegex = CloudStorageRegex.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreRegex {
    return {
      cloudStorageRegex: isSet(object.cloudStorageRegex)
        ? CloudStorageRegex.fromJSON(object.cloudStorageRegex)
        : undefined,
    };
  },

  toJSON(message: FileStoreRegex): unknown {
    const obj: any = {};
    if (message.cloudStorageRegex !== undefined) {
      obj.cloudStorageRegex = CloudStorageRegex.toJSON(message.cloudStorageRegex);
    }
    return obj;
  },

  create(base?: DeepPartial<FileStoreRegex>): FileStoreRegex {
    return FileStoreRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStoreRegex>): FileStoreRegex {
    const message = createBaseFileStoreRegex();
    message.cloudStorageRegex = (object.cloudStorageRegex !== undefined && object.cloudStorageRegex !== null)
      ? CloudStorageRegex.fromPartial(object.cloudStorageRegex)
      : undefined;
    return message;
  },
};

function createBaseCloudStorageRegex(): CloudStorageRegex {
  return { projectIdRegex: "", bucketNameRegex: "" };
}

export const CloudStorageRegex: MessageFns<CloudStorageRegex> = {
  encode(message: CloudStorageRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectIdRegex !== "") {
      writer.uint32(10).string(message.projectIdRegex);
    }
    if (message.bucketNameRegex !== "") {
      writer.uint32(18).string(message.bucketNameRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectIdRegex = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucketNameRegex = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudStorageRegex {
    return {
      projectIdRegex: isSet(object.projectIdRegex) ? globalThis.String(object.projectIdRegex) : "",
      bucketNameRegex: isSet(object.bucketNameRegex) ? globalThis.String(object.bucketNameRegex) : "",
    };
  },

  toJSON(message: CloudStorageRegex): unknown {
    const obj: any = {};
    if (message.projectIdRegex !== "") {
      obj.projectIdRegex = message.projectIdRegex;
    }
    if (message.bucketNameRegex !== "") {
      obj.bucketNameRegex = message.bucketNameRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudStorageRegex>): CloudStorageRegex {
    return CloudStorageRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudStorageRegex>): CloudStorageRegex {
    const message = createBaseCloudStorageRegex();
    message.projectIdRegex = object.projectIdRegex ?? "";
    message.bucketNameRegex = object.bucketNameRegex ?? "";
    return message;
  },
};

function createBaseCloudStorageResourceReference(): CloudStorageResourceReference {
  return { bucketName: "", projectId: "" };
}

export const CloudStorageResourceReference: MessageFns<CloudStorageResourceReference> = {
  encode(message: CloudStorageResourceReference, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucketName !== "") {
      writer.uint32(10).string(message.bucketName);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudStorageResourceReference {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudStorageResourceReference();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucketName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudStorageResourceReference {
    return {
      bucketName: isSet(object.bucketName) ? globalThis.String(object.bucketName) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
    };
  },

  toJSON(message: CloudStorageResourceReference): unknown {
    const obj: any = {};
    if (message.bucketName !== "") {
      obj.bucketName = message.bucketName;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudStorageResourceReference>): CloudStorageResourceReference {
    return CloudStorageResourceReference.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudStorageResourceReference>): CloudStorageResourceReference {
    const message = createBaseCloudStorageResourceReference();
    message.bucketName = object.bucketName ?? "";
    message.projectId = object.projectId ?? "";
    return message;
  },
};

function createBaseDiscoveryCloudStorageGenerationCadence(): DiscoveryCloudStorageGenerationCadence {
  return { refreshFrequency: 0, inspectTemplateModifiedCadence: undefined };
}

export const DiscoveryCloudStorageGenerationCadence: MessageFns<DiscoveryCloudStorageGenerationCadence> = {
  encode(message: DiscoveryCloudStorageGenerationCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.refreshFrequency !== 0) {
      writer.uint32(8).int32(message.refreshFrequency);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      DiscoveryInspectTemplateModifiedCadence.encode(message.inspectTemplateModifiedCadence, writer.uint32(18).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudStorageGenerationCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudStorageGenerationCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.refreshFrequency = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudStorageGenerationCadence {
    return {
      refreshFrequency: isSet(object.refreshFrequency)
        ? dataProfileUpdateFrequencyFromJSON(object.refreshFrequency)
        : 0,
      inspectTemplateModifiedCadence: isSet(object.inspectTemplateModifiedCadence)
        ? DiscoveryInspectTemplateModifiedCadence.fromJSON(object.inspectTemplateModifiedCadence)
        : undefined,
    };
  },

  toJSON(message: DiscoveryCloudStorageGenerationCadence): unknown {
    const obj: any = {};
    if (message.refreshFrequency !== 0) {
      obj.refreshFrequency = dataProfileUpdateFrequencyToJSON(message.refreshFrequency);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      obj.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.toJSON(
        message.inspectTemplateModifiedCadence,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryCloudStorageGenerationCadence>): DiscoveryCloudStorageGenerationCadence {
    return DiscoveryCloudStorageGenerationCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryCloudStorageGenerationCadence>): DiscoveryCloudStorageGenerationCadence {
    const message = createBaseDiscoveryCloudStorageGenerationCadence();
    message.refreshFrequency = object.refreshFrequency ?? 0;
    message.inspectTemplateModifiedCadence =
      (object.inspectTemplateModifiedCadence !== undefined && object.inspectTemplateModifiedCadence !== null)
        ? DiscoveryInspectTemplateModifiedCadence.fromPartial(object.inspectTemplateModifiedCadence)
        : undefined;
    return message;
  },
};

function createBaseDiscoveryCloudStorageConditions(): DiscoveryCloudStorageConditions {
  return { includedObjectAttributes: [], includedBucketAttributes: [] };
}

export const DiscoveryCloudStorageConditions: MessageFns<DiscoveryCloudStorageConditions> = {
  encode(message: DiscoveryCloudStorageConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.includedObjectAttributes) {
      writer.int32(v);
    }
    writer.join();
    writer.uint32(18).fork();
    for (const v of message.includedBucketAttributes) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryCloudStorageConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryCloudStorageConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.includedObjectAttributes.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.includedObjectAttributes.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 2:
          if (tag === 16) {
            message.includedBucketAttributes.push(reader.int32() as any);

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.includedBucketAttributes.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryCloudStorageConditions {
    return {
      includedObjectAttributes: globalThis.Array.isArray(object?.includedObjectAttributes)
        ? object.includedObjectAttributes.map((e: any) =>
          discoveryCloudStorageConditions_CloudStorageObjectAttributeFromJSON(e)
        )
        : [],
      includedBucketAttributes: globalThis.Array.isArray(object?.includedBucketAttributes)
        ? object.includedBucketAttributes.map((e: any) =>
          discoveryCloudStorageConditions_CloudStorageBucketAttributeFromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: DiscoveryCloudStorageConditions): unknown {
    const obj: any = {};
    if (message.includedObjectAttributes?.length) {
      obj.includedObjectAttributes = message.includedObjectAttributes.map((e) =>
        discoveryCloudStorageConditions_CloudStorageObjectAttributeToJSON(e)
      );
    }
    if (message.includedBucketAttributes?.length) {
      obj.includedBucketAttributes = message.includedBucketAttributes.map((e) =>
        discoveryCloudStorageConditions_CloudStorageBucketAttributeToJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryCloudStorageConditions>): DiscoveryCloudStorageConditions {
    return DiscoveryCloudStorageConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryCloudStorageConditions>): DiscoveryCloudStorageConditions {
    const message = createBaseDiscoveryCloudStorageConditions();
    message.includedObjectAttributes = object.includedObjectAttributes?.map((e) => e) || [];
    message.includedBucketAttributes = object.includedBucketAttributes?.map((e) => e) || [];
    return message;
  },
};

function createBaseDiscoveryFileStoreConditions(): DiscoveryFileStoreConditions {
  return { createdAfter: undefined, minAge: undefined, cloudStorageConditions: undefined };
}

export const DiscoveryFileStoreConditions: MessageFns<DiscoveryFileStoreConditions> = {
  encode(message: DiscoveryFileStoreConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createdAfter !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAfter), writer.uint32(10).fork()).join();
    }
    if (message.minAge !== undefined) {
      Duration.encode(message.minAge, writer.uint32(18).fork()).join();
    }
    if (message.cloudStorageConditions !== undefined) {
      DiscoveryCloudStorageConditions.encode(message.cloudStorageConditions, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryFileStoreConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryFileStoreConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createdAfter = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.minAge = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cloudStorageConditions = DiscoveryCloudStorageConditions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryFileStoreConditions {
    return {
      createdAfter: isSet(object.createdAfter) ? fromJsonTimestamp(object.createdAfter) : undefined,
      minAge: isSet(object.minAge) ? Duration.fromJSON(object.minAge) : undefined,
      cloudStorageConditions: isSet(object.cloudStorageConditions)
        ? DiscoveryCloudStorageConditions.fromJSON(object.cloudStorageConditions)
        : undefined,
    };
  },

  toJSON(message: DiscoveryFileStoreConditions): unknown {
    const obj: any = {};
    if (message.createdAfter !== undefined) {
      obj.createdAfter = message.createdAfter.toISOString();
    }
    if (message.minAge !== undefined) {
      obj.minAge = Duration.toJSON(message.minAge);
    }
    if (message.cloudStorageConditions !== undefined) {
      obj.cloudStorageConditions = DiscoveryCloudStorageConditions.toJSON(message.cloudStorageConditions);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryFileStoreConditions>): DiscoveryFileStoreConditions {
    return DiscoveryFileStoreConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryFileStoreConditions>): DiscoveryFileStoreConditions {
    const message = createBaseDiscoveryFileStoreConditions();
    message.createdAfter = object.createdAfter ?? undefined;
    message.minAge = (object.minAge !== undefined && object.minAge !== null)
      ? Duration.fromPartial(object.minAge)
      : undefined;
    message.cloudStorageConditions =
      (object.cloudStorageConditions !== undefined && object.cloudStorageConditions !== null)
        ? DiscoveryCloudStorageConditions.fromPartial(object.cloudStorageConditions)
        : undefined;
    return message;
  },
};

function createBaseOtherCloudDiscoveryTarget(): OtherCloudDiscoveryTarget {
  return {
    dataSourceType: undefined,
    filter: undefined,
    conditions: undefined,
    generationCadence: undefined,
    disabled: undefined,
  };
}

export const OtherCloudDiscoveryTarget: MessageFns<OtherCloudDiscoveryTarget> = {
  encode(message: OtherCloudDiscoveryTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataSourceType !== undefined) {
      DataSourceType.encode(message.dataSourceType, writer.uint32(10).fork()).join();
    }
    if (message.filter !== undefined) {
      DiscoveryOtherCloudFilter.encode(message.filter, writer.uint32(18).fork()).join();
    }
    if (message.conditions !== undefined) {
      DiscoveryOtherCloudConditions.encode(message.conditions, writer.uint32(26).fork()).join();
    }
    if (message.generationCadence !== undefined) {
      DiscoveryOtherCloudGenerationCadence.encode(message.generationCadence, writer.uint32(34).fork()).join();
    }
    if (message.disabled !== undefined) {
      Disabled.encode(message.disabled, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherCloudDiscoveryTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudDiscoveryTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataSourceType = DataSourceType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = DiscoveryOtherCloudFilter.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.conditions = DiscoveryOtherCloudConditions.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.generationCadence = DiscoveryOtherCloudGenerationCadence.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.disabled = Disabled.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudDiscoveryTarget {
    return {
      dataSourceType: isSet(object.dataSourceType) ? DataSourceType.fromJSON(object.dataSourceType) : undefined,
      filter: isSet(object.filter) ? DiscoveryOtherCloudFilter.fromJSON(object.filter) : undefined,
      conditions: isSet(object.conditions) ? DiscoveryOtherCloudConditions.fromJSON(object.conditions) : undefined,
      generationCadence: isSet(object.generationCadence)
        ? DiscoveryOtherCloudGenerationCadence.fromJSON(object.generationCadence)
        : undefined,
      disabled: isSet(object.disabled) ? Disabled.fromJSON(object.disabled) : undefined,
    };
  },

  toJSON(message: OtherCloudDiscoveryTarget): unknown {
    const obj: any = {};
    if (message.dataSourceType !== undefined) {
      obj.dataSourceType = DataSourceType.toJSON(message.dataSourceType);
    }
    if (message.filter !== undefined) {
      obj.filter = DiscoveryOtherCloudFilter.toJSON(message.filter);
    }
    if (message.conditions !== undefined) {
      obj.conditions = DiscoveryOtherCloudConditions.toJSON(message.conditions);
    }
    if (message.generationCadence !== undefined) {
      obj.generationCadence = DiscoveryOtherCloudGenerationCadence.toJSON(message.generationCadence);
    }
    if (message.disabled !== undefined) {
      obj.disabled = Disabled.toJSON(message.disabled);
    }
    return obj;
  },

  create(base?: DeepPartial<OtherCloudDiscoveryTarget>): OtherCloudDiscoveryTarget {
    return OtherCloudDiscoveryTarget.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherCloudDiscoveryTarget>): OtherCloudDiscoveryTarget {
    const message = createBaseOtherCloudDiscoveryTarget();
    message.dataSourceType = (object.dataSourceType !== undefined && object.dataSourceType !== null)
      ? DataSourceType.fromPartial(object.dataSourceType)
      : undefined;
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? DiscoveryOtherCloudFilter.fromPartial(object.filter)
      : undefined;
    message.conditions = (object.conditions !== undefined && object.conditions !== null)
      ? DiscoveryOtherCloudConditions.fromPartial(object.conditions)
      : undefined;
    message.generationCadence = (object.generationCadence !== undefined && object.generationCadence !== null)
      ? DiscoveryOtherCloudGenerationCadence.fromPartial(object.generationCadence)
      : undefined;
    message.disabled = (object.disabled !== undefined && object.disabled !== null)
      ? Disabled.fromPartial(object.disabled)
      : undefined;
    return message;
  },
};

function createBaseDiscoveryOtherCloudFilter(): DiscoveryOtherCloudFilter {
  return { collection: undefined, singleResource: undefined, others: undefined };
}

export const DiscoveryOtherCloudFilter: MessageFns<DiscoveryOtherCloudFilter> = {
  encode(message: DiscoveryOtherCloudFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.collection !== undefined) {
      OtherCloudResourceCollection.encode(message.collection, writer.uint32(10).fork()).join();
    }
    if (message.singleResource !== undefined) {
      OtherCloudSingleResourceReference.encode(message.singleResource, writer.uint32(18).fork()).join();
    }
    if (message.others !== undefined) {
      AllOtherResources.encode(message.others, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryOtherCloudFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryOtherCloudFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.collection = OtherCloudResourceCollection.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.singleResource = OtherCloudSingleResourceReference.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.others = AllOtherResources.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryOtherCloudFilter {
    return {
      collection: isSet(object.collection) ? OtherCloudResourceCollection.fromJSON(object.collection) : undefined,
      singleResource: isSet(object.singleResource)
        ? OtherCloudSingleResourceReference.fromJSON(object.singleResource)
        : undefined,
      others: isSet(object.others) ? AllOtherResources.fromJSON(object.others) : undefined,
    };
  },

  toJSON(message: DiscoveryOtherCloudFilter): unknown {
    const obj: any = {};
    if (message.collection !== undefined) {
      obj.collection = OtherCloudResourceCollection.toJSON(message.collection);
    }
    if (message.singleResource !== undefined) {
      obj.singleResource = OtherCloudSingleResourceReference.toJSON(message.singleResource);
    }
    if (message.others !== undefined) {
      obj.others = AllOtherResources.toJSON(message.others);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryOtherCloudFilter>): DiscoveryOtherCloudFilter {
    return DiscoveryOtherCloudFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryOtherCloudFilter>): DiscoveryOtherCloudFilter {
    const message = createBaseDiscoveryOtherCloudFilter();
    message.collection = (object.collection !== undefined && object.collection !== null)
      ? OtherCloudResourceCollection.fromPartial(object.collection)
      : undefined;
    message.singleResource = (object.singleResource !== undefined && object.singleResource !== null)
      ? OtherCloudSingleResourceReference.fromPartial(object.singleResource)
      : undefined;
    message.others = (object.others !== undefined && object.others !== null)
      ? AllOtherResources.fromPartial(object.others)
      : undefined;
    return message;
  },
};

function createBaseOtherCloudResourceCollection(): OtherCloudResourceCollection {
  return { includeRegexes: undefined };
}

export const OtherCloudResourceCollection: MessageFns<OtherCloudResourceCollection> = {
  encode(message: OtherCloudResourceCollection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeRegexes !== undefined) {
      OtherCloudResourceRegexes.encode(message.includeRegexes, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherCloudResourceCollection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudResourceCollection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeRegexes = OtherCloudResourceRegexes.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudResourceCollection {
    return {
      includeRegexes: isSet(object.includeRegexes)
        ? OtherCloudResourceRegexes.fromJSON(object.includeRegexes)
        : undefined,
    };
  },

  toJSON(message: OtherCloudResourceCollection): unknown {
    const obj: any = {};
    if (message.includeRegexes !== undefined) {
      obj.includeRegexes = OtherCloudResourceRegexes.toJSON(message.includeRegexes);
    }
    return obj;
  },

  create(base?: DeepPartial<OtherCloudResourceCollection>): OtherCloudResourceCollection {
    return OtherCloudResourceCollection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherCloudResourceCollection>): OtherCloudResourceCollection {
    const message = createBaseOtherCloudResourceCollection();
    message.includeRegexes = (object.includeRegexes !== undefined && object.includeRegexes !== null)
      ? OtherCloudResourceRegexes.fromPartial(object.includeRegexes)
      : undefined;
    return message;
  },
};

function createBaseOtherCloudResourceRegexes(): OtherCloudResourceRegexes {
  return { patterns: [] };
}

export const OtherCloudResourceRegexes: MessageFns<OtherCloudResourceRegexes> = {
  encode(message: OtherCloudResourceRegexes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.patterns) {
      OtherCloudResourceRegex.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherCloudResourceRegexes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudResourceRegexes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.patterns.push(OtherCloudResourceRegex.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudResourceRegexes {
    return {
      patterns: globalThis.Array.isArray(object?.patterns)
        ? object.patterns.map((e: any) => OtherCloudResourceRegex.fromJSON(e))
        : [],
    };
  },

  toJSON(message: OtherCloudResourceRegexes): unknown {
    const obj: any = {};
    if (message.patterns?.length) {
      obj.patterns = message.patterns.map((e) => OtherCloudResourceRegex.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<OtherCloudResourceRegexes>): OtherCloudResourceRegexes {
    return OtherCloudResourceRegexes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherCloudResourceRegexes>): OtherCloudResourceRegexes {
    const message = createBaseOtherCloudResourceRegexes();
    message.patterns = object.patterns?.map((e) => OtherCloudResourceRegex.fromPartial(e)) || [];
    return message;
  },
};

function createBaseOtherCloudResourceRegex(): OtherCloudResourceRegex {
  return { amazonS3BucketRegex: undefined };
}

export const OtherCloudResourceRegex: MessageFns<OtherCloudResourceRegex> = {
  encode(message: OtherCloudResourceRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.amazonS3BucketRegex !== undefined) {
      AmazonS3BucketRegex.encode(message.amazonS3BucketRegex, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherCloudResourceRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudResourceRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.amazonS3BucketRegex = AmazonS3BucketRegex.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudResourceRegex {
    return {
      amazonS3BucketRegex: isSet(object.amazonS3BucketRegex)
        ? AmazonS3BucketRegex.fromJSON(object.amazonS3BucketRegex)
        : undefined,
    };
  },

  toJSON(message: OtherCloudResourceRegex): unknown {
    const obj: any = {};
    if (message.amazonS3BucketRegex !== undefined) {
      obj.amazonS3BucketRegex = AmazonS3BucketRegex.toJSON(message.amazonS3BucketRegex);
    }
    return obj;
  },

  create(base?: DeepPartial<OtherCloudResourceRegex>): OtherCloudResourceRegex {
    return OtherCloudResourceRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherCloudResourceRegex>): OtherCloudResourceRegex {
    const message = createBaseOtherCloudResourceRegex();
    message.amazonS3BucketRegex = (object.amazonS3BucketRegex !== undefined && object.amazonS3BucketRegex !== null)
      ? AmazonS3BucketRegex.fromPartial(object.amazonS3BucketRegex)
      : undefined;
    return message;
  },
};

function createBaseAwsAccountRegex(): AwsAccountRegex {
  return { accountIdRegex: "" };
}

export const AwsAccountRegex: MessageFns<AwsAccountRegex> = {
  encode(message: AwsAccountRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accountIdRegex !== "") {
      writer.uint32(10).string(message.accountIdRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsAccountRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsAccountRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.accountIdRegex = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsAccountRegex {
    return { accountIdRegex: isSet(object.accountIdRegex) ? globalThis.String(object.accountIdRegex) : "" };
  },

  toJSON(message: AwsAccountRegex): unknown {
    const obj: any = {};
    if (message.accountIdRegex !== "") {
      obj.accountIdRegex = message.accountIdRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsAccountRegex>): AwsAccountRegex {
    return AwsAccountRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsAccountRegex>): AwsAccountRegex {
    const message = createBaseAwsAccountRegex();
    message.accountIdRegex = object.accountIdRegex ?? "";
    return message;
  },
};

function createBaseAmazonS3BucketRegex(): AmazonS3BucketRegex {
  return { awsAccountRegex: undefined, bucketNameRegex: "" };
}

export const AmazonS3BucketRegex: MessageFns<AmazonS3BucketRegex> = {
  encode(message: AmazonS3BucketRegex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.awsAccountRegex !== undefined) {
      AwsAccountRegex.encode(message.awsAccountRegex, writer.uint32(10).fork()).join();
    }
    if (message.bucketNameRegex !== "") {
      writer.uint32(18).string(message.bucketNameRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AmazonS3BucketRegex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAmazonS3BucketRegex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.awsAccountRegex = AwsAccountRegex.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucketNameRegex = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AmazonS3BucketRegex {
    return {
      awsAccountRegex: isSet(object.awsAccountRegex) ? AwsAccountRegex.fromJSON(object.awsAccountRegex) : undefined,
      bucketNameRegex: isSet(object.bucketNameRegex) ? globalThis.String(object.bucketNameRegex) : "",
    };
  },

  toJSON(message: AmazonS3BucketRegex): unknown {
    const obj: any = {};
    if (message.awsAccountRegex !== undefined) {
      obj.awsAccountRegex = AwsAccountRegex.toJSON(message.awsAccountRegex);
    }
    if (message.bucketNameRegex !== "") {
      obj.bucketNameRegex = message.bucketNameRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<AmazonS3BucketRegex>): AmazonS3BucketRegex {
    return AmazonS3BucketRegex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AmazonS3BucketRegex>): AmazonS3BucketRegex {
    const message = createBaseAmazonS3BucketRegex();
    message.awsAccountRegex = (object.awsAccountRegex !== undefined && object.awsAccountRegex !== null)
      ? AwsAccountRegex.fromPartial(object.awsAccountRegex)
      : undefined;
    message.bucketNameRegex = object.bucketNameRegex ?? "";
    return message;
  },
};

function createBaseOtherCloudSingleResourceReference(): OtherCloudSingleResourceReference {
  return { amazonS3Bucket: undefined };
}

export const OtherCloudSingleResourceReference: MessageFns<OtherCloudSingleResourceReference> = {
  encode(message: OtherCloudSingleResourceReference, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.amazonS3Bucket !== undefined) {
      AmazonS3Bucket.encode(message.amazonS3Bucket, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherCloudSingleResourceReference {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudSingleResourceReference();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.amazonS3Bucket = AmazonS3Bucket.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudSingleResourceReference {
    return {
      amazonS3Bucket: isSet(object.amazonS3Bucket) ? AmazonS3Bucket.fromJSON(object.amazonS3Bucket) : undefined,
    };
  },

  toJSON(message: OtherCloudSingleResourceReference): unknown {
    const obj: any = {};
    if (message.amazonS3Bucket !== undefined) {
      obj.amazonS3Bucket = AmazonS3Bucket.toJSON(message.amazonS3Bucket);
    }
    return obj;
  },

  create(base?: DeepPartial<OtherCloudSingleResourceReference>): OtherCloudSingleResourceReference {
    return OtherCloudSingleResourceReference.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherCloudSingleResourceReference>): OtherCloudSingleResourceReference {
    const message = createBaseOtherCloudSingleResourceReference();
    message.amazonS3Bucket = (object.amazonS3Bucket !== undefined && object.amazonS3Bucket !== null)
      ? AmazonS3Bucket.fromPartial(object.amazonS3Bucket)
      : undefined;
    return message;
  },
};

function createBaseAwsAccount(): AwsAccount {
  return { accountId: "" };
}

export const AwsAccount: MessageFns<AwsAccount> = {
  encode(message: AwsAccount, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accountId !== "") {
      writer.uint32(10).string(message.accountId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsAccount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsAccount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.accountId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsAccount {
    return { accountId: isSet(object.accountId) ? globalThis.String(object.accountId) : "" };
  },

  toJSON(message: AwsAccount): unknown {
    const obj: any = {};
    if (message.accountId !== "") {
      obj.accountId = message.accountId;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsAccount>): AwsAccount {
    return AwsAccount.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsAccount>): AwsAccount {
    const message = createBaseAwsAccount();
    message.accountId = object.accountId ?? "";
    return message;
  },
};

function createBaseAmazonS3Bucket(): AmazonS3Bucket {
  return { awsAccount: undefined, bucketName: "" };
}

export const AmazonS3Bucket: MessageFns<AmazonS3Bucket> = {
  encode(message: AmazonS3Bucket, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.awsAccount !== undefined) {
      AwsAccount.encode(message.awsAccount, writer.uint32(10).fork()).join();
    }
    if (message.bucketName !== "") {
      writer.uint32(18).string(message.bucketName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AmazonS3Bucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAmazonS3Bucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.awsAccount = AwsAccount.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucketName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AmazonS3Bucket {
    return {
      awsAccount: isSet(object.awsAccount) ? AwsAccount.fromJSON(object.awsAccount) : undefined,
      bucketName: isSet(object.bucketName) ? globalThis.String(object.bucketName) : "",
    };
  },

  toJSON(message: AmazonS3Bucket): unknown {
    const obj: any = {};
    if (message.awsAccount !== undefined) {
      obj.awsAccount = AwsAccount.toJSON(message.awsAccount);
    }
    if (message.bucketName !== "") {
      obj.bucketName = message.bucketName;
    }
    return obj;
  },

  create(base?: DeepPartial<AmazonS3Bucket>): AmazonS3Bucket {
    return AmazonS3Bucket.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AmazonS3Bucket>): AmazonS3Bucket {
    const message = createBaseAmazonS3Bucket();
    message.awsAccount = (object.awsAccount !== undefined && object.awsAccount !== null)
      ? AwsAccount.fromPartial(object.awsAccount)
      : undefined;
    message.bucketName = object.bucketName ?? "";
    return message;
  },
};

function createBaseDiscoveryOtherCloudConditions(): DiscoveryOtherCloudConditions {
  return { minAge: undefined, amazonS3BucketConditions: undefined };
}

export const DiscoveryOtherCloudConditions: MessageFns<DiscoveryOtherCloudConditions> = {
  encode(message: DiscoveryOtherCloudConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minAge !== undefined) {
      Duration.encode(message.minAge, writer.uint32(10).fork()).join();
    }
    if (message.amazonS3BucketConditions !== undefined) {
      AmazonS3BucketConditions.encode(message.amazonS3BucketConditions, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryOtherCloudConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryOtherCloudConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.minAge = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.amazonS3BucketConditions = AmazonS3BucketConditions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryOtherCloudConditions {
    return {
      minAge: isSet(object.minAge) ? Duration.fromJSON(object.minAge) : undefined,
      amazonS3BucketConditions: isSet(object.amazonS3BucketConditions)
        ? AmazonS3BucketConditions.fromJSON(object.amazonS3BucketConditions)
        : undefined,
    };
  },

  toJSON(message: DiscoveryOtherCloudConditions): unknown {
    const obj: any = {};
    if (message.minAge !== undefined) {
      obj.minAge = Duration.toJSON(message.minAge);
    }
    if (message.amazonS3BucketConditions !== undefined) {
      obj.amazonS3BucketConditions = AmazonS3BucketConditions.toJSON(message.amazonS3BucketConditions);
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryOtherCloudConditions>): DiscoveryOtherCloudConditions {
    return DiscoveryOtherCloudConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryOtherCloudConditions>): DiscoveryOtherCloudConditions {
    const message = createBaseDiscoveryOtherCloudConditions();
    message.minAge = (object.minAge !== undefined && object.minAge !== null)
      ? Duration.fromPartial(object.minAge)
      : undefined;
    message.amazonS3BucketConditions =
      (object.amazonS3BucketConditions !== undefined && object.amazonS3BucketConditions !== null)
        ? AmazonS3BucketConditions.fromPartial(object.amazonS3BucketConditions)
        : undefined;
    return message;
  },
};

function createBaseAmazonS3BucketConditions(): AmazonS3BucketConditions {
  return { bucketTypes: [], objectStorageClasses: [] };
}

export const AmazonS3BucketConditions: MessageFns<AmazonS3BucketConditions> = {
  encode(message: AmazonS3BucketConditions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.bucketTypes) {
      writer.int32(v);
    }
    writer.join();
    writer.uint32(18).fork();
    for (const v of message.objectStorageClasses) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AmazonS3BucketConditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAmazonS3BucketConditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.bucketTypes.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.bucketTypes.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 2:
          if (tag === 16) {
            message.objectStorageClasses.push(reader.int32() as any);

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.objectStorageClasses.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AmazonS3BucketConditions {
    return {
      bucketTypes: globalThis.Array.isArray(object?.bucketTypes)
        ? object.bucketTypes.map((e: any) => amazonS3BucketConditions_BucketTypeFromJSON(e))
        : [],
      objectStorageClasses: globalThis.Array.isArray(object?.objectStorageClasses)
        ? object.objectStorageClasses.map((e: any) => amazonS3BucketConditions_ObjectStorageClassFromJSON(e))
        : [],
    };
  },

  toJSON(message: AmazonS3BucketConditions): unknown {
    const obj: any = {};
    if (message.bucketTypes?.length) {
      obj.bucketTypes = message.bucketTypes.map((e) => amazonS3BucketConditions_BucketTypeToJSON(e));
    }
    if (message.objectStorageClasses?.length) {
      obj.objectStorageClasses = message.objectStorageClasses.map((e) =>
        amazonS3BucketConditions_ObjectStorageClassToJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<AmazonS3BucketConditions>): AmazonS3BucketConditions {
    return AmazonS3BucketConditions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AmazonS3BucketConditions>): AmazonS3BucketConditions {
    const message = createBaseAmazonS3BucketConditions();
    message.bucketTypes = object.bucketTypes?.map((e) => e) || [];
    message.objectStorageClasses = object.objectStorageClasses?.map((e) => e) || [];
    return message;
  },
};

function createBaseDiscoveryOtherCloudGenerationCadence(): DiscoveryOtherCloudGenerationCadence {
  return { refreshFrequency: 0, inspectTemplateModifiedCadence: undefined };
}

export const DiscoveryOtherCloudGenerationCadence: MessageFns<DiscoveryOtherCloudGenerationCadence> = {
  encode(message: DiscoveryOtherCloudGenerationCadence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.refreshFrequency !== 0) {
      writer.uint32(8).int32(message.refreshFrequency);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      DiscoveryInspectTemplateModifiedCadence.encode(message.inspectTemplateModifiedCadence, writer.uint32(18).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryOtherCloudGenerationCadence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryOtherCloudGenerationCadence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.refreshFrequency = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryOtherCloudGenerationCadence {
    return {
      refreshFrequency: isSet(object.refreshFrequency)
        ? dataProfileUpdateFrequencyFromJSON(object.refreshFrequency)
        : 0,
      inspectTemplateModifiedCadence: isSet(object.inspectTemplateModifiedCadence)
        ? DiscoveryInspectTemplateModifiedCadence.fromJSON(object.inspectTemplateModifiedCadence)
        : undefined,
    };
  },

  toJSON(message: DiscoveryOtherCloudGenerationCadence): unknown {
    const obj: any = {};
    if (message.refreshFrequency !== 0) {
      obj.refreshFrequency = dataProfileUpdateFrequencyToJSON(message.refreshFrequency);
    }
    if (message.inspectTemplateModifiedCadence !== undefined) {
      obj.inspectTemplateModifiedCadence = DiscoveryInspectTemplateModifiedCadence.toJSON(
        message.inspectTemplateModifiedCadence,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryOtherCloudGenerationCadence>): DiscoveryOtherCloudGenerationCadence {
    return DiscoveryOtherCloudGenerationCadence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryOtherCloudGenerationCadence>): DiscoveryOtherCloudGenerationCadence {
    const message = createBaseDiscoveryOtherCloudGenerationCadence();
    message.refreshFrequency = object.refreshFrequency ?? 0;
    message.inspectTemplateModifiedCadence =
      (object.inspectTemplateModifiedCadence !== undefined && object.inspectTemplateModifiedCadence !== null)
        ? DiscoveryInspectTemplateModifiedCadence.fromPartial(object.inspectTemplateModifiedCadence)
        : undefined;
    return message;
  },
};

function createBaseDiscoveryStartingLocation(): DiscoveryStartingLocation {
  return { organizationId: undefined, folderId: undefined };
}

export const DiscoveryStartingLocation: MessageFns<DiscoveryStartingLocation> = {
  encode(message: DiscoveryStartingLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.organizationId !== undefined) {
      writer.uint32(8).int64(message.organizationId.toString());
    }
    if (message.folderId !== undefined) {
      writer.uint32(16).int64(message.folderId.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DiscoveryStartingLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDiscoveryStartingLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.organizationId = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.folderId = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DiscoveryStartingLocation {
    return {
      organizationId: isSet(object.organizationId) ? Long.fromValue(object.organizationId) : undefined,
      folderId: isSet(object.folderId) ? Long.fromValue(object.folderId) : undefined,
    };
  },

  toJSON(message: DiscoveryStartingLocation): unknown {
    const obj: any = {};
    if (message.organizationId !== undefined) {
      obj.organizationId = (message.organizationId || Long.ZERO).toString();
    }
    if (message.folderId !== undefined) {
      obj.folderId = (message.folderId || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DiscoveryStartingLocation>): DiscoveryStartingLocation {
    return DiscoveryStartingLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DiscoveryStartingLocation>): DiscoveryStartingLocation {
    const message = createBaseDiscoveryStartingLocation();
    message.organizationId = (object.organizationId !== undefined && object.organizationId !== null)
      ? Long.fromValue(object.organizationId)
      : undefined;
    message.folderId = (object.folderId !== undefined && object.folderId !== null)
      ? Long.fromValue(object.folderId)
      : undefined;
    return message;
  },
};

function createBaseOtherCloudDiscoveryStartingLocation(): OtherCloudDiscoveryStartingLocation {
  return { awsLocation: undefined };
}

export const OtherCloudDiscoveryStartingLocation: MessageFns<OtherCloudDiscoveryStartingLocation> = {
  encode(message: OtherCloudDiscoveryStartingLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.awsLocation !== undefined) {
      OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation.encode(
        message.awsLocation,
        writer.uint32(10).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherCloudDiscoveryStartingLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudDiscoveryStartingLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.awsLocation = OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudDiscoveryStartingLocation {
    return {
      awsLocation: isSet(object.awsLocation)
        ? OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation.fromJSON(object.awsLocation)
        : undefined,
    };
  },

  toJSON(message: OtherCloudDiscoveryStartingLocation): unknown {
    const obj: any = {};
    if (message.awsLocation !== undefined) {
      obj.awsLocation = OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation.toJSON(message.awsLocation);
    }
    return obj;
  },

  create(base?: DeepPartial<OtherCloudDiscoveryStartingLocation>): OtherCloudDiscoveryStartingLocation {
    return OtherCloudDiscoveryStartingLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherCloudDiscoveryStartingLocation>): OtherCloudDiscoveryStartingLocation {
    const message = createBaseOtherCloudDiscoveryStartingLocation();
    message.awsLocation = (object.awsLocation !== undefined && object.awsLocation !== null)
      ? OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation.fromPartial(object.awsLocation)
      : undefined;
    return message;
  },
};

function createBaseOtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation(): OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation {
  return { accountId: undefined, allAssetInventoryAssets: undefined };
}

export const OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation: MessageFns<
  OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation
> = {
  encode(
    message: OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.accountId !== undefined) {
      writer.uint32(18).string(message.accountId);
    }
    if (message.allAssetInventoryAssets !== undefined) {
      writer.uint32(24).bool(message.allAssetInventoryAssets);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.accountId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.allAssetInventoryAssets = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation {
    return {
      accountId: isSet(object.accountId) ? globalThis.String(object.accountId) : undefined,
      allAssetInventoryAssets: isSet(object.allAssetInventoryAssets)
        ? globalThis.Boolean(object.allAssetInventoryAssets)
        : undefined,
    };
  },

  toJSON(message: OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation): unknown {
    const obj: any = {};
    if (message.accountId !== undefined) {
      obj.accountId = message.accountId;
    }
    if (message.allAssetInventoryAssets !== undefined) {
      obj.allAssetInventoryAssets = message.allAssetInventoryAssets;
    }
    return obj;
  },

  create(
    base?: DeepPartial<OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation>,
  ): OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation {
    return OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation>,
  ): OtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation {
    const message = createBaseOtherCloudDiscoveryStartingLocation_AwsDiscoveryStartingLocation();
    message.accountId = object.accountId ?? undefined;
    message.allAssetInventoryAssets = object.allAssetInventoryAssets ?? undefined;
    return message;
  },
};

function createBaseAllOtherResources(): AllOtherResources {
  return {};
}

export const AllOtherResources: MessageFns<AllOtherResources> = {
  encode(_: AllOtherResources, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllOtherResources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllOtherResources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AllOtherResources {
    return {};
  },

  toJSON(_: AllOtherResources): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AllOtherResources>): AllOtherResources {
    return AllOtherResources.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AllOtherResources>): AllOtherResources {
    const message = createBaseAllOtherResources();
    return message;
  },
};

function createBaseDlpJob(): DlpJob {
  return {
    name: "",
    type: 0,
    state: 0,
    riskDetails: undefined,
    inspectDetails: undefined,
    createTime: undefined,
    startTime: undefined,
    endTime: undefined,
    lastModified: undefined,
    jobTriggerName: "",
    errors: [],
    actionDetails: [],
  };
}

export const DlpJob: MessageFns<DlpJob> = {
  encode(message: DlpJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.riskDetails !== undefined) {
      AnalyzeDataSourceRiskDetails.encode(message.riskDetails, writer.uint32(34).fork()).join();
    }
    if (message.inspectDetails !== undefined) {
      InspectDataSourceDetails.encode(message.inspectDetails, writer.uint32(42).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(58).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(66).fork()).join();
    }
    if (message.lastModified !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModified), writer.uint32(122).fork()).join();
    }
    if (message.jobTriggerName !== "") {
      writer.uint32(82).string(message.jobTriggerName);
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(90).fork()).join();
    }
    for (const v of message.actionDetails) {
      ActionDetails.encode(v!, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DlpJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDlpJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.riskDetails = AnalyzeDataSourceRiskDetails.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inspectDetails = InspectDataSourceDetails.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.lastModified = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.jobTriggerName = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.actionDetails.push(ActionDetails.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DlpJob {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? dlpJobTypeFromJSON(object.type) : 0,
      state: isSet(object.state) ? dlpJob_JobStateFromJSON(object.state) : 0,
      riskDetails: isSet(object.riskDetails) ? AnalyzeDataSourceRiskDetails.fromJSON(object.riskDetails) : undefined,
      inspectDetails: isSet(object.inspectDetails)
        ? InspectDataSourceDetails.fromJSON(object.inspectDetails)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      lastModified: isSet(object.lastModified) ? fromJsonTimestamp(object.lastModified) : undefined,
      jobTriggerName: isSet(object.jobTriggerName) ? globalThis.String(object.jobTriggerName) : "",
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      actionDetails: globalThis.Array.isArray(object?.actionDetails)
        ? object.actionDetails.map((e: any) => ActionDetails.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DlpJob): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = dlpJobTypeToJSON(message.type);
    }
    if (message.state !== 0) {
      obj.state = dlpJob_JobStateToJSON(message.state);
    }
    if (message.riskDetails !== undefined) {
      obj.riskDetails = AnalyzeDataSourceRiskDetails.toJSON(message.riskDetails);
    }
    if (message.inspectDetails !== undefined) {
      obj.inspectDetails = InspectDataSourceDetails.toJSON(message.inspectDetails);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.lastModified !== undefined) {
      obj.lastModified = message.lastModified.toISOString();
    }
    if (message.jobTriggerName !== "") {
      obj.jobTriggerName = message.jobTriggerName;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.actionDetails?.length) {
      obj.actionDetails = message.actionDetails.map((e) => ActionDetails.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<DlpJob>): DlpJob {
    return DlpJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DlpJob>): DlpJob {
    const message = createBaseDlpJob();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    message.state = object.state ?? 0;
    message.riskDetails = (object.riskDetails !== undefined && object.riskDetails !== null)
      ? AnalyzeDataSourceRiskDetails.fromPartial(object.riskDetails)
      : undefined;
    message.inspectDetails = (object.inspectDetails !== undefined && object.inspectDetails !== null)
      ? InspectDataSourceDetails.fromPartial(object.inspectDetails)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.lastModified = object.lastModified ?? undefined;
    message.jobTriggerName = object.jobTriggerName ?? "";
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.actionDetails = object.actionDetails?.map((e) => ActionDetails.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGetDlpJobRequest(): GetDlpJobRequest {
  return { name: "" };
}

export const GetDlpJobRequest: MessageFns<GetDlpJobRequest> = {
  encode(message: GetDlpJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDlpJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDlpJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDlpJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetDlpJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDlpJobRequest>): GetDlpJobRequest {
    return GetDlpJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDlpJobRequest>): GetDlpJobRequest {
    const message = createBaseGetDlpJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListDlpJobsRequest(): ListDlpJobsRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", type: 0, orderBy: "", locationId: "" };
}

export const ListDlpJobsRequest: MessageFns<ListDlpJobsRequest> = {
  encode(message: ListDlpJobsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(10).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.orderBy !== "") {
      writer.uint32(50).string(message.orderBy);
    }
    if (message.locationId !== "") {
      writer.uint32(58).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDlpJobsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDlpJobsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDlpJobsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      type: isSet(object.type) ? dlpJobTypeFromJSON(object.type) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ListDlpJobsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.type !== 0) {
      obj.type = dlpJobTypeToJSON(message.type);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDlpJobsRequest>): ListDlpJobsRequest {
    return ListDlpJobsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDlpJobsRequest>): ListDlpJobsRequest {
    const message = createBaseListDlpJobsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.type = object.type ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListDlpJobsResponse(): ListDlpJobsResponse {
  return { jobs: [], nextPageToken: "" };
}

export const ListDlpJobsResponse: MessageFns<ListDlpJobsResponse> = {
  encode(message: ListDlpJobsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.jobs) {
      DlpJob.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDlpJobsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDlpJobsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobs.push(DlpJob.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDlpJobsResponse {
    return {
      jobs: globalThis.Array.isArray(object?.jobs) ? object.jobs.map((e: any) => DlpJob.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDlpJobsResponse): unknown {
    const obj: any = {};
    if (message.jobs?.length) {
      obj.jobs = message.jobs.map((e) => DlpJob.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDlpJobsResponse>): ListDlpJobsResponse {
    return ListDlpJobsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDlpJobsResponse>): ListDlpJobsResponse {
    const message = createBaseListDlpJobsResponse();
    message.jobs = object.jobs?.map((e) => DlpJob.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCancelDlpJobRequest(): CancelDlpJobRequest {
  return { name: "" };
}

export const CancelDlpJobRequest: MessageFns<CancelDlpJobRequest> = {
  encode(message: CancelDlpJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelDlpJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelDlpJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelDlpJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: CancelDlpJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelDlpJobRequest>): CancelDlpJobRequest {
    return CancelDlpJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelDlpJobRequest>): CancelDlpJobRequest {
    const message = createBaseCancelDlpJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseFinishDlpJobRequest(): FinishDlpJobRequest {
  return { name: "" };
}

export const FinishDlpJobRequest: MessageFns<FinishDlpJobRequest> = {
  encode(message: FinishDlpJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FinishDlpJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFinishDlpJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FinishDlpJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: FinishDlpJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<FinishDlpJobRequest>): FinishDlpJobRequest {
    return FinishDlpJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FinishDlpJobRequest>): FinishDlpJobRequest {
    const message = createBaseFinishDlpJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDeleteDlpJobRequest(): DeleteDlpJobRequest {
  return { name: "" };
}

export const DeleteDlpJobRequest: MessageFns<DeleteDlpJobRequest> = {
  encode(message: DeleteDlpJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteDlpJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteDlpJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteDlpJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteDlpJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteDlpJobRequest>): DeleteDlpJobRequest {
    return DeleteDlpJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteDlpJobRequest>): DeleteDlpJobRequest {
    const message = createBaseDeleteDlpJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateDeidentifyTemplateRequest(): CreateDeidentifyTemplateRequest {
  return { parent: "", deidentifyTemplate: undefined, templateId: "", locationId: "" };
}

export const CreateDeidentifyTemplateRequest: MessageFns<CreateDeidentifyTemplateRequest> = {
  encode(message: CreateDeidentifyTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.deidentifyTemplate !== undefined) {
      DeidentifyTemplate.encode(message.deidentifyTemplate, writer.uint32(18).fork()).join();
    }
    if (message.templateId !== "") {
      writer.uint32(26).string(message.templateId);
    }
    if (message.locationId !== "") {
      writer.uint32(34).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDeidentifyTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDeidentifyTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deidentifyTemplate = DeidentifyTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.templateId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDeidentifyTemplateRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      deidentifyTemplate: isSet(object.deidentifyTemplate)
        ? DeidentifyTemplate.fromJSON(object.deidentifyTemplate)
        : undefined,
      templateId: isSet(object.templateId) ? globalThis.String(object.templateId) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: CreateDeidentifyTemplateRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.deidentifyTemplate !== undefined) {
      obj.deidentifyTemplate = DeidentifyTemplate.toJSON(message.deidentifyTemplate);
    }
    if (message.templateId !== "") {
      obj.templateId = message.templateId;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDeidentifyTemplateRequest>): CreateDeidentifyTemplateRequest {
    return CreateDeidentifyTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDeidentifyTemplateRequest>): CreateDeidentifyTemplateRequest {
    const message = createBaseCreateDeidentifyTemplateRequest();
    message.parent = object.parent ?? "";
    message.deidentifyTemplate = (object.deidentifyTemplate !== undefined && object.deidentifyTemplate !== null)
      ? DeidentifyTemplate.fromPartial(object.deidentifyTemplate)
      : undefined;
    message.templateId = object.templateId ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseUpdateDeidentifyTemplateRequest(): UpdateDeidentifyTemplateRequest {
  return { name: "", deidentifyTemplate: undefined, updateMask: undefined };
}

export const UpdateDeidentifyTemplateRequest: MessageFns<UpdateDeidentifyTemplateRequest> = {
  encode(message: UpdateDeidentifyTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.deidentifyTemplate !== undefined) {
      DeidentifyTemplate.encode(message.deidentifyTemplate, writer.uint32(18).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDeidentifyTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDeidentifyTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deidentifyTemplate = DeidentifyTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDeidentifyTemplateRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      deidentifyTemplate: isSet(object.deidentifyTemplate)
        ? DeidentifyTemplate.fromJSON(object.deidentifyTemplate)
        : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateDeidentifyTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.deidentifyTemplate !== undefined) {
      obj.deidentifyTemplate = DeidentifyTemplate.toJSON(message.deidentifyTemplate);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDeidentifyTemplateRequest>): UpdateDeidentifyTemplateRequest {
    return UpdateDeidentifyTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDeidentifyTemplateRequest>): UpdateDeidentifyTemplateRequest {
    const message = createBaseUpdateDeidentifyTemplateRequest();
    message.name = object.name ?? "";
    message.deidentifyTemplate = (object.deidentifyTemplate !== undefined && object.deidentifyTemplate !== null)
      ? DeidentifyTemplate.fromPartial(object.deidentifyTemplate)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetDeidentifyTemplateRequest(): GetDeidentifyTemplateRequest {
  return { name: "" };
}

export const GetDeidentifyTemplateRequest: MessageFns<GetDeidentifyTemplateRequest> = {
  encode(message: GetDeidentifyTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDeidentifyTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDeidentifyTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDeidentifyTemplateRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetDeidentifyTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDeidentifyTemplateRequest>): GetDeidentifyTemplateRequest {
    return GetDeidentifyTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDeidentifyTemplateRequest>): GetDeidentifyTemplateRequest {
    const message = createBaseGetDeidentifyTemplateRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListDeidentifyTemplatesRequest(): ListDeidentifyTemplatesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", locationId: "" };
}

export const ListDeidentifyTemplatesRequest: MessageFns<ListDeidentifyTemplatesRequest> = {
  encode(message: ListDeidentifyTemplatesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.locationId !== "") {
      writer.uint32(42).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDeidentifyTemplatesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDeidentifyTemplatesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDeidentifyTemplatesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ListDeidentifyTemplatesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDeidentifyTemplatesRequest>): ListDeidentifyTemplatesRequest {
    return ListDeidentifyTemplatesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDeidentifyTemplatesRequest>): ListDeidentifyTemplatesRequest {
    const message = createBaseListDeidentifyTemplatesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListDeidentifyTemplatesResponse(): ListDeidentifyTemplatesResponse {
  return { deidentifyTemplates: [], nextPageToken: "" };
}

export const ListDeidentifyTemplatesResponse: MessageFns<ListDeidentifyTemplatesResponse> = {
  encode(message: ListDeidentifyTemplatesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.deidentifyTemplates) {
      DeidentifyTemplate.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDeidentifyTemplatesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDeidentifyTemplatesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.deidentifyTemplates.push(DeidentifyTemplate.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDeidentifyTemplatesResponse {
    return {
      deidentifyTemplates: globalThis.Array.isArray(object?.deidentifyTemplates)
        ? object.deidentifyTemplates.map((e: any) => DeidentifyTemplate.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDeidentifyTemplatesResponse): unknown {
    const obj: any = {};
    if (message.deidentifyTemplates?.length) {
      obj.deidentifyTemplates = message.deidentifyTemplates.map((e) => DeidentifyTemplate.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDeidentifyTemplatesResponse>): ListDeidentifyTemplatesResponse {
    return ListDeidentifyTemplatesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDeidentifyTemplatesResponse>): ListDeidentifyTemplatesResponse {
    const message = createBaseListDeidentifyTemplatesResponse();
    message.deidentifyTemplates = object.deidentifyTemplates?.map((e) => DeidentifyTemplate.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteDeidentifyTemplateRequest(): DeleteDeidentifyTemplateRequest {
  return { name: "" };
}

export const DeleteDeidentifyTemplateRequest: MessageFns<DeleteDeidentifyTemplateRequest> = {
  encode(message: DeleteDeidentifyTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteDeidentifyTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteDeidentifyTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteDeidentifyTemplateRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteDeidentifyTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteDeidentifyTemplateRequest>): DeleteDeidentifyTemplateRequest {
    return DeleteDeidentifyTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteDeidentifyTemplateRequest>): DeleteDeidentifyTemplateRequest {
    const message = createBaseDeleteDeidentifyTemplateRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseLargeCustomDictionaryConfig(): LargeCustomDictionaryConfig {
  return { outputPath: undefined, cloudStorageFileSet: undefined, bigQueryField: undefined };
}

export const LargeCustomDictionaryConfig: MessageFns<LargeCustomDictionaryConfig> = {
  encode(message: LargeCustomDictionaryConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputPath !== undefined) {
      CloudStoragePath.encode(message.outputPath, writer.uint32(10).fork()).join();
    }
    if (message.cloudStorageFileSet !== undefined) {
      CloudStorageFileSet.encode(message.cloudStorageFileSet, writer.uint32(18).fork()).join();
    }
    if (message.bigQueryField !== undefined) {
      BigQueryField.encode(message.bigQueryField, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LargeCustomDictionaryConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLargeCustomDictionaryConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputPath = CloudStoragePath.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cloudStorageFileSet = CloudStorageFileSet.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.bigQueryField = BigQueryField.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LargeCustomDictionaryConfig {
    return {
      outputPath: isSet(object.outputPath) ? CloudStoragePath.fromJSON(object.outputPath) : undefined,
      cloudStorageFileSet: isSet(object.cloudStorageFileSet)
        ? CloudStorageFileSet.fromJSON(object.cloudStorageFileSet)
        : undefined,
      bigQueryField: isSet(object.bigQueryField) ? BigQueryField.fromJSON(object.bigQueryField) : undefined,
    };
  },

  toJSON(message: LargeCustomDictionaryConfig): unknown {
    const obj: any = {};
    if (message.outputPath !== undefined) {
      obj.outputPath = CloudStoragePath.toJSON(message.outputPath);
    }
    if (message.cloudStorageFileSet !== undefined) {
      obj.cloudStorageFileSet = CloudStorageFileSet.toJSON(message.cloudStorageFileSet);
    }
    if (message.bigQueryField !== undefined) {
      obj.bigQueryField = BigQueryField.toJSON(message.bigQueryField);
    }
    return obj;
  },

  create(base?: DeepPartial<LargeCustomDictionaryConfig>): LargeCustomDictionaryConfig {
    return LargeCustomDictionaryConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LargeCustomDictionaryConfig>): LargeCustomDictionaryConfig {
    const message = createBaseLargeCustomDictionaryConfig();
    message.outputPath = (object.outputPath !== undefined && object.outputPath !== null)
      ? CloudStoragePath.fromPartial(object.outputPath)
      : undefined;
    message.cloudStorageFileSet = (object.cloudStorageFileSet !== undefined && object.cloudStorageFileSet !== null)
      ? CloudStorageFileSet.fromPartial(object.cloudStorageFileSet)
      : undefined;
    message.bigQueryField = (object.bigQueryField !== undefined && object.bigQueryField !== null)
      ? BigQueryField.fromPartial(object.bigQueryField)
      : undefined;
    return message;
  },
};

function createBaseLargeCustomDictionaryStats(): LargeCustomDictionaryStats {
  return { approxNumPhrases: Long.ZERO };
}

export const LargeCustomDictionaryStats: MessageFns<LargeCustomDictionaryStats> = {
  encode(message: LargeCustomDictionaryStats, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.approxNumPhrases.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.approxNumPhrases.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LargeCustomDictionaryStats {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLargeCustomDictionaryStats();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.approxNumPhrases = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LargeCustomDictionaryStats {
    return { approxNumPhrases: isSet(object.approxNumPhrases) ? Long.fromValue(object.approxNumPhrases) : Long.ZERO };
  },

  toJSON(message: LargeCustomDictionaryStats): unknown {
    const obj: any = {};
    if (!message.approxNumPhrases.equals(Long.ZERO)) {
      obj.approxNumPhrases = (message.approxNumPhrases || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<LargeCustomDictionaryStats>): LargeCustomDictionaryStats {
    return LargeCustomDictionaryStats.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LargeCustomDictionaryStats>): LargeCustomDictionaryStats {
    const message = createBaseLargeCustomDictionaryStats();
    message.approxNumPhrases = (object.approxNumPhrases !== undefined && object.approxNumPhrases !== null)
      ? Long.fromValue(object.approxNumPhrases)
      : Long.ZERO;
    return message;
  },
};

function createBaseStoredInfoTypeConfig(): StoredInfoTypeConfig {
  return {
    displayName: "",
    description: "",
    largeCustomDictionary: undefined,
    dictionary: undefined,
    regex: undefined,
  };
}

export const StoredInfoTypeConfig: MessageFns<StoredInfoTypeConfig> = {
  encode(message: StoredInfoTypeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.displayName !== "") {
      writer.uint32(10).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.largeCustomDictionary !== undefined) {
      LargeCustomDictionaryConfig.encode(message.largeCustomDictionary, writer.uint32(26).fork()).join();
    }
    if (message.dictionary !== undefined) {
      CustomInfoType_Dictionary.encode(message.dictionary, writer.uint32(34).fork()).join();
    }
    if (message.regex !== undefined) {
      CustomInfoType_Regex.encode(message.regex, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StoredInfoTypeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStoredInfoTypeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.largeCustomDictionary = LargeCustomDictionaryConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.dictionary = CustomInfoType_Dictionary.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.regex = CustomInfoType_Regex.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StoredInfoTypeConfig {
    return {
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      largeCustomDictionary: isSet(object.largeCustomDictionary)
        ? LargeCustomDictionaryConfig.fromJSON(object.largeCustomDictionary)
        : undefined,
      dictionary: isSet(object.dictionary) ? CustomInfoType_Dictionary.fromJSON(object.dictionary) : undefined,
      regex: isSet(object.regex) ? CustomInfoType_Regex.fromJSON(object.regex) : undefined,
    };
  },

  toJSON(message: StoredInfoTypeConfig): unknown {
    const obj: any = {};
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.largeCustomDictionary !== undefined) {
      obj.largeCustomDictionary = LargeCustomDictionaryConfig.toJSON(message.largeCustomDictionary);
    }
    if (message.dictionary !== undefined) {
      obj.dictionary = CustomInfoType_Dictionary.toJSON(message.dictionary);
    }
    if (message.regex !== undefined) {
      obj.regex = CustomInfoType_Regex.toJSON(message.regex);
    }
    return obj;
  },

  create(base?: DeepPartial<StoredInfoTypeConfig>): StoredInfoTypeConfig {
    return StoredInfoTypeConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StoredInfoTypeConfig>): StoredInfoTypeConfig {
    const message = createBaseStoredInfoTypeConfig();
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.largeCustomDictionary =
      (object.largeCustomDictionary !== undefined && object.largeCustomDictionary !== null)
        ? LargeCustomDictionaryConfig.fromPartial(object.largeCustomDictionary)
        : undefined;
    message.dictionary = (object.dictionary !== undefined && object.dictionary !== null)
      ? CustomInfoType_Dictionary.fromPartial(object.dictionary)
      : undefined;
    message.regex = (object.regex !== undefined && object.regex !== null)
      ? CustomInfoType_Regex.fromPartial(object.regex)
      : undefined;
    return message;
  },
};

function createBaseStoredInfoTypeStats(): StoredInfoTypeStats {
  return { largeCustomDictionary: undefined };
}

export const StoredInfoTypeStats: MessageFns<StoredInfoTypeStats> = {
  encode(message: StoredInfoTypeStats, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.largeCustomDictionary !== undefined) {
      LargeCustomDictionaryStats.encode(message.largeCustomDictionary, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StoredInfoTypeStats {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStoredInfoTypeStats();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.largeCustomDictionary = LargeCustomDictionaryStats.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StoredInfoTypeStats {
    return {
      largeCustomDictionary: isSet(object.largeCustomDictionary)
        ? LargeCustomDictionaryStats.fromJSON(object.largeCustomDictionary)
        : undefined,
    };
  },

  toJSON(message: StoredInfoTypeStats): unknown {
    const obj: any = {};
    if (message.largeCustomDictionary !== undefined) {
      obj.largeCustomDictionary = LargeCustomDictionaryStats.toJSON(message.largeCustomDictionary);
    }
    return obj;
  },

  create(base?: DeepPartial<StoredInfoTypeStats>): StoredInfoTypeStats {
    return StoredInfoTypeStats.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StoredInfoTypeStats>): StoredInfoTypeStats {
    const message = createBaseStoredInfoTypeStats();
    message.largeCustomDictionary =
      (object.largeCustomDictionary !== undefined && object.largeCustomDictionary !== null)
        ? LargeCustomDictionaryStats.fromPartial(object.largeCustomDictionary)
        : undefined;
    return message;
  },
};

function createBaseStoredInfoTypeVersion(): StoredInfoTypeVersion {
  return { config: undefined, createTime: undefined, state: 0, errors: [], stats: undefined };
}

export const StoredInfoTypeVersion: MessageFns<StoredInfoTypeVersion> = {
  encode(message: StoredInfoTypeVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.config !== undefined) {
      StoredInfoTypeConfig.encode(message.config, writer.uint32(10).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.stats !== undefined) {
      StoredInfoTypeStats.encode(message.stats, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StoredInfoTypeVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStoredInfoTypeVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.config = StoredInfoTypeConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.stats = StoredInfoTypeStats.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StoredInfoTypeVersion {
    return {
      config: isSet(object.config) ? StoredInfoTypeConfig.fromJSON(object.config) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      state: isSet(object.state) ? storedInfoTypeStateFromJSON(object.state) : 0,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      stats: isSet(object.stats) ? StoredInfoTypeStats.fromJSON(object.stats) : undefined,
    };
  },

  toJSON(message: StoredInfoTypeVersion): unknown {
    const obj: any = {};
    if (message.config !== undefined) {
      obj.config = StoredInfoTypeConfig.toJSON(message.config);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = storedInfoTypeStateToJSON(message.state);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.stats !== undefined) {
      obj.stats = StoredInfoTypeStats.toJSON(message.stats);
    }
    return obj;
  },

  create(base?: DeepPartial<StoredInfoTypeVersion>): StoredInfoTypeVersion {
    return StoredInfoTypeVersion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StoredInfoTypeVersion>): StoredInfoTypeVersion {
    const message = createBaseStoredInfoTypeVersion();
    message.config = (object.config !== undefined && object.config !== null)
      ? StoredInfoTypeConfig.fromPartial(object.config)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.state = object.state ?? 0;
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.stats = (object.stats !== undefined && object.stats !== null)
      ? StoredInfoTypeStats.fromPartial(object.stats)
      : undefined;
    return message;
  },
};

function createBaseStoredInfoType(): StoredInfoType {
  return { name: "", currentVersion: undefined, pendingVersions: [] };
}

export const StoredInfoType: MessageFns<StoredInfoType> = {
  encode(message: StoredInfoType, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.currentVersion !== undefined) {
      StoredInfoTypeVersion.encode(message.currentVersion, writer.uint32(18).fork()).join();
    }
    for (const v of message.pendingVersions) {
      StoredInfoTypeVersion.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StoredInfoType {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStoredInfoType();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.currentVersion = StoredInfoTypeVersion.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pendingVersions.push(StoredInfoTypeVersion.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StoredInfoType {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      currentVersion: isSet(object.currentVersion) ? StoredInfoTypeVersion.fromJSON(object.currentVersion) : undefined,
      pendingVersions: globalThis.Array.isArray(object?.pendingVersions)
        ? object.pendingVersions.map((e: any) => StoredInfoTypeVersion.fromJSON(e))
        : [],
    };
  },

  toJSON(message: StoredInfoType): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.currentVersion !== undefined) {
      obj.currentVersion = StoredInfoTypeVersion.toJSON(message.currentVersion);
    }
    if (message.pendingVersions?.length) {
      obj.pendingVersions = message.pendingVersions.map((e) => StoredInfoTypeVersion.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<StoredInfoType>): StoredInfoType {
    return StoredInfoType.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StoredInfoType>): StoredInfoType {
    const message = createBaseStoredInfoType();
    message.name = object.name ?? "";
    message.currentVersion = (object.currentVersion !== undefined && object.currentVersion !== null)
      ? StoredInfoTypeVersion.fromPartial(object.currentVersion)
      : undefined;
    message.pendingVersions = object.pendingVersions?.map((e) => StoredInfoTypeVersion.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCreateStoredInfoTypeRequest(): CreateStoredInfoTypeRequest {
  return { parent: "", config: undefined, storedInfoTypeId: "", locationId: "" };
}

export const CreateStoredInfoTypeRequest: MessageFns<CreateStoredInfoTypeRequest> = {
  encode(message: CreateStoredInfoTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.config !== undefined) {
      StoredInfoTypeConfig.encode(message.config, writer.uint32(18).fork()).join();
    }
    if (message.storedInfoTypeId !== "") {
      writer.uint32(26).string(message.storedInfoTypeId);
    }
    if (message.locationId !== "") {
      writer.uint32(34).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateStoredInfoTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateStoredInfoTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.config = StoredInfoTypeConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.storedInfoTypeId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateStoredInfoTypeRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      config: isSet(object.config) ? StoredInfoTypeConfig.fromJSON(object.config) : undefined,
      storedInfoTypeId: isSet(object.storedInfoTypeId) ? globalThis.String(object.storedInfoTypeId) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: CreateStoredInfoTypeRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.config !== undefined) {
      obj.config = StoredInfoTypeConfig.toJSON(message.config);
    }
    if (message.storedInfoTypeId !== "") {
      obj.storedInfoTypeId = message.storedInfoTypeId;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateStoredInfoTypeRequest>): CreateStoredInfoTypeRequest {
    return CreateStoredInfoTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateStoredInfoTypeRequest>): CreateStoredInfoTypeRequest {
    const message = createBaseCreateStoredInfoTypeRequest();
    message.parent = object.parent ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? StoredInfoTypeConfig.fromPartial(object.config)
      : undefined;
    message.storedInfoTypeId = object.storedInfoTypeId ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseUpdateStoredInfoTypeRequest(): UpdateStoredInfoTypeRequest {
  return { name: "", config: undefined, updateMask: undefined };
}

export const UpdateStoredInfoTypeRequest: MessageFns<UpdateStoredInfoTypeRequest> = {
  encode(message: UpdateStoredInfoTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.config !== undefined) {
      StoredInfoTypeConfig.encode(message.config, writer.uint32(18).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateStoredInfoTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateStoredInfoTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.config = StoredInfoTypeConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateStoredInfoTypeRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      config: isSet(object.config) ? StoredInfoTypeConfig.fromJSON(object.config) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateStoredInfoTypeRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.config !== undefined) {
      obj.config = StoredInfoTypeConfig.toJSON(message.config);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateStoredInfoTypeRequest>): UpdateStoredInfoTypeRequest {
    return UpdateStoredInfoTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateStoredInfoTypeRequest>): UpdateStoredInfoTypeRequest {
    const message = createBaseUpdateStoredInfoTypeRequest();
    message.name = object.name ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? StoredInfoTypeConfig.fromPartial(object.config)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetStoredInfoTypeRequest(): GetStoredInfoTypeRequest {
  return { name: "" };
}

export const GetStoredInfoTypeRequest: MessageFns<GetStoredInfoTypeRequest> = {
  encode(message: GetStoredInfoTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetStoredInfoTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetStoredInfoTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetStoredInfoTypeRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetStoredInfoTypeRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetStoredInfoTypeRequest>): GetStoredInfoTypeRequest {
    return GetStoredInfoTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetStoredInfoTypeRequest>): GetStoredInfoTypeRequest {
    const message = createBaseGetStoredInfoTypeRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListStoredInfoTypesRequest(): ListStoredInfoTypesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", locationId: "" };
}

export const ListStoredInfoTypesRequest: MessageFns<ListStoredInfoTypesRequest> = {
  encode(message: ListStoredInfoTypesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.locationId !== "") {
      writer.uint32(42).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListStoredInfoTypesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListStoredInfoTypesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListStoredInfoTypesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: ListStoredInfoTypesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<ListStoredInfoTypesRequest>): ListStoredInfoTypesRequest {
    return ListStoredInfoTypesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListStoredInfoTypesRequest>): ListStoredInfoTypesRequest {
    const message = createBaseListStoredInfoTypesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseListStoredInfoTypesResponse(): ListStoredInfoTypesResponse {
  return { storedInfoTypes: [], nextPageToken: "" };
}

export const ListStoredInfoTypesResponse: MessageFns<ListStoredInfoTypesResponse> = {
  encode(message: ListStoredInfoTypesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.storedInfoTypes) {
      StoredInfoType.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListStoredInfoTypesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListStoredInfoTypesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.storedInfoTypes.push(StoredInfoType.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListStoredInfoTypesResponse {
    return {
      storedInfoTypes: globalThis.Array.isArray(object?.storedInfoTypes)
        ? object.storedInfoTypes.map((e: any) => StoredInfoType.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListStoredInfoTypesResponse): unknown {
    const obj: any = {};
    if (message.storedInfoTypes?.length) {
      obj.storedInfoTypes = message.storedInfoTypes.map((e) => StoredInfoType.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListStoredInfoTypesResponse>): ListStoredInfoTypesResponse {
    return ListStoredInfoTypesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListStoredInfoTypesResponse>): ListStoredInfoTypesResponse {
    const message = createBaseListStoredInfoTypesResponse();
    message.storedInfoTypes = object.storedInfoTypes?.map((e) => StoredInfoType.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteStoredInfoTypeRequest(): DeleteStoredInfoTypeRequest {
  return { name: "" };
}

export const DeleteStoredInfoTypeRequest: MessageFns<DeleteStoredInfoTypeRequest> = {
  encode(message: DeleteStoredInfoTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteStoredInfoTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteStoredInfoTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteStoredInfoTypeRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteStoredInfoTypeRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteStoredInfoTypeRequest>): DeleteStoredInfoTypeRequest {
    return DeleteStoredInfoTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteStoredInfoTypeRequest>): DeleteStoredInfoTypeRequest {
    const message = createBaseDeleteStoredInfoTypeRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseHybridInspectJobTriggerRequest(): HybridInspectJobTriggerRequest {
  return { name: "", hybridItem: undefined };
}

export const HybridInspectJobTriggerRequest: MessageFns<HybridInspectJobTriggerRequest> = {
  encode(message: HybridInspectJobTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.hybridItem !== undefined) {
      HybridContentItem.encode(message.hybridItem, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridInspectJobTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridInspectJobTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.hybridItem = HybridContentItem.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HybridInspectJobTriggerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      hybridItem: isSet(object.hybridItem) ? HybridContentItem.fromJSON(object.hybridItem) : undefined,
    };
  },

  toJSON(message: HybridInspectJobTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.hybridItem !== undefined) {
      obj.hybridItem = HybridContentItem.toJSON(message.hybridItem);
    }
    return obj;
  },

  create(base?: DeepPartial<HybridInspectJobTriggerRequest>): HybridInspectJobTriggerRequest {
    return HybridInspectJobTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HybridInspectJobTriggerRequest>): HybridInspectJobTriggerRequest {
    const message = createBaseHybridInspectJobTriggerRequest();
    message.name = object.name ?? "";
    message.hybridItem = (object.hybridItem !== undefined && object.hybridItem !== null)
      ? HybridContentItem.fromPartial(object.hybridItem)
      : undefined;
    return message;
  },
};

function createBaseHybridInspectDlpJobRequest(): HybridInspectDlpJobRequest {
  return { name: "", hybridItem: undefined };
}

export const HybridInspectDlpJobRequest: MessageFns<HybridInspectDlpJobRequest> = {
  encode(message: HybridInspectDlpJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.hybridItem !== undefined) {
      HybridContentItem.encode(message.hybridItem, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridInspectDlpJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridInspectDlpJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.hybridItem = HybridContentItem.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HybridInspectDlpJobRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      hybridItem: isSet(object.hybridItem) ? HybridContentItem.fromJSON(object.hybridItem) : undefined,
    };
  },

  toJSON(message: HybridInspectDlpJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.hybridItem !== undefined) {
      obj.hybridItem = HybridContentItem.toJSON(message.hybridItem);
    }
    return obj;
  },

  create(base?: DeepPartial<HybridInspectDlpJobRequest>): HybridInspectDlpJobRequest {
    return HybridInspectDlpJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HybridInspectDlpJobRequest>): HybridInspectDlpJobRequest {
    const message = createBaseHybridInspectDlpJobRequest();
    message.name = object.name ?? "";
    message.hybridItem = (object.hybridItem !== undefined && object.hybridItem !== null)
      ? HybridContentItem.fromPartial(object.hybridItem)
      : undefined;
    return message;
  },
};

function createBaseHybridContentItem(): HybridContentItem {
  return { item: undefined, findingDetails: undefined };
}

export const HybridContentItem: MessageFns<HybridContentItem> = {
  encode(message: HybridContentItem, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.item !== undefined) {
      ContentItem.encode(message.item, writer.uint32(10).fork()).join();
    }
    if (message.findingDetails !== undefined) {
      HybridFindingDetails.encode(message.findingDetails, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridContentItem {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridContentItem();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.item = ContentItem.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.findingDetails = HybridFindingDetails.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HybridContentItem {
    return {
      item: isSet(object.item) ? ContentItem.fromJSON(object.item) : undefined,
      findingDetails: isSet(object.findingDetails) ? HybridFindingDetails.fromJSON(object.findingDetails) : undefined,
    };
  },

  toJSON(message: HybridContentItem): unknown {
    const obj: any = {};
    if (message.item !== undefined) {
      obj.item = ContentItem.toJSON(message.item);
    }
    if (message.findingDetails !== undefined) {
      obj.findingDetails = HybridFindingDetails.toJSON(message.findingDetails);
    }
    return obj;
  },

  create(base?: DeepPartial<HybridContentItem>): HybridContentItem {
    return HybridContentItem.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HybridContentItem>): HybridContentItem {
    const message = createBaseHybridContentItem();
    message.item = (object.item !== undefined && object.item !== null)
      ? ContentItem.fromPartial(object.item)
      : undefined;
    message.findingDetails = (object.findingDetails !== undefined && object.findingDetails !== null)
      ? HybridFindingDetails.fromPartial(object.findingDetails)
      : undefined;
    return message;
  },
};

function createBaseHybridFindingDetails(): HybridFindingDetails {
  return {
    containerDetails: undefined,
    fileOffset: Long.ZERO,
    rowOffset: Long.ZERO,
    tableOptions: undefined,
    labels: {},
  };
}

export const HybridFindingDetails: MessageFns<HybridFindingDetails> = {
  encode(message: HybridFindingDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.containerDetails !== undefined) {
      Container.encode(message.containerDetails, writer.uint32(10).fork()).join();
    }
    if (!message.fileOffset.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.fileOffset.toString());
    }
    if (!message.rowOffset.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.rowOffset.toString());
    }
    if (message.tableOptions !== undefined) {
      TableOptions.encode(message.tableOptions, writer.uint32(34).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      HybridFindingDetails_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridFindingDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridFindingDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.containerDetails = Container.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.fileOffset = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.rowOffset = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.tableOptions = TableOptions.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = HybridFindingDetails_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HybridFindingDetails {
    return {
      containerDetails: isSet(object.containerDetails) ? Container.fromJSON(object.containerDetails) : undefined,
      fileOffset: isSet(object.fileOffset) ? Long.fromValue(object.fileOffset) : Long.ZERO,
      rowOffset: isSet(object.rowOffset) ? Long.fromValue(object.rowOffset) : Long.ZERO,
      tableOptions: isSet(object.tableOptions) ? TableOptions.fromJSON(object.tableOptions) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: HybridFindingDetails): unknown {
    const obj: any = {};
    if (message.containerDetails !== undefined) {
      obj.containerDetails = Container.toJSON(message.containerDetails);
    }
    if (!message.fileOffset.equals(Long.ZERO)) {
      obj.fileOffset = (message.fileOffset || Long.ZERO).toString();
    }
    if (!message.rowOffset.equals(Long.ZERO)) {
      obj.rowOffset = (message.rowOffset || Long.ZERO).toString();
    }
    if (message.tableOptions !== undefined) {
      obj.tableOptions = TableOptions.toJSON(message.tableOptions);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<HybridFindingDetails>): HybridFindingDetails {
    return HybridFindingDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HybridFindingDetails>): HybridFindingDetails {
    const message = createBaseHybridFindingDetails();
    message.containerDetails = (object.containerDetails !== undefined && object.containerDetails !== null)
      ? Container.fromPartial(object.containerDetails)
      : undefined;
    message.fileOffset = (object.fileOffset !== undefined && object.fileOffset !== null)
      ? Long.fromValue(object.fileOffset)
      : Long.ZERO;
    message.rowOffset = (object.rowOffset !== undefined && object.rowOffset !== null)
      ? Long.fromValue(object.rowOffset)
      : Long.ZERO;
    message.tableOptions = (object.tableOptions !== undefined && object.tableOptions !== null)
      ? TableOptions.fromPartial(object.tableOptions)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseHybridFindingDetails_LabelsEntry(): HybridFindingDetails_LabelsEntry {
  return { key: "", value: "" };
}

export const HybridFindingDetails_LabelsEntry: MessageFns<HybridFindingDetails_LabelsEntry> = {
  encode(message: HybridFindingDetails_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridFindingDetails_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridFindingDetails_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HybridFindingDetails_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: HybridFindingDetails_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<HybridFindingDetails_LabelsEntry>): HybridFindingDetails_LabelsEntry {
    return HybridFindingDetails_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HybridFindingDetails_LabelsEntry>): HybridFindingDetails_LabelsEntry {
    const message = createBaseHybridFindingDetails_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseHybridInspectResponse(): HybridInspectResponse {
  return {};
}

export const HybridInspectResponse: MessageFns<HybridInspectResponse> = {
  encode(_: HybridInspectResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HybridInspectResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHybridInspectResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): HybridInspectResponse {
    return {};
  },

  toJSON(_: HybridInspectResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<HybridInspectResponse>): HybridInspectResponse {
    return HybridInspectResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<HybridInspectResponse>): HybridInspectResponse {
    const message = createBaseHybridInspectResponse();
    return message;
  },
};

function createBaseListProjectDataProfilesRequest(): ListProjectDataProfilesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", filter: "" };
}

export const ListProjectDataProfilesRequest: MessageFns<ListProjectDataProfilesRequest> = {
  encode(message: ListProjectDataProfilesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListProjectDataProfilesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListProjectDataProfilesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListProjectDataProfilesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListProjectDataProfilesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListProjectDataProfilesRequest>): ListProjectDataProfilesRequest {
    return ListProjectDataProfilesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListProjectDataProfilesRequest>): ListProjectDataProfilesRequest {
    const message = createBaseListProjectDataProfilesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListProjectDataProfilesResponse(): ListProjectDataProfilesResponse {
  return { projectDataProfiles: [], nextPageToken: "" };
}

export const ListProjectDataProfilesResponse: MessageFns<ListProjectDataProfilesResponse> = {
  encode(message: ListProjectDataProfilesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.projectDataProfiles) {
      ProjectDataProfile.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListProjectDataProfilesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListProjectDataProfilesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectDataProfiles.push(ProjectDataProfile.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListProjectDataProfilesResponse {
    return {
      projectDataProfiles: globalThis.Array.isArray(object?.projectDataProfiles)
        ? object.projectDataProfiles.map((e: any) => ProjectDataProfile.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListProjectDataProfilesResponse): unknown {
    const obj: any = {};
    if (message.projectDataProfiles?.length) {
      obj.projectDataProfiles = message.projectDataProfiles.map((e) => ProjectDataProfile.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListProjectDataProfilesResponse>): ListProjectDataProfilesResponse {
    return ListProjectDataProfilesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListProjectDataProfilesResponse>): ListProjectDataProfilesResponse {
    const message = createBaseListProjectDataProfilesResponse();
    message.projectDataProfiles = object.projectDataProfiles?.map((e) => ProjectDataProfile.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseListTableDataProfilesRequest(): ListTableDataProfilesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", filter: "" };
}

export const ListTableDataProfilesRequest: MessageFns<ListTableDataProfilesRequest> = {
  encode(message: ListTableDataProfilesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTableDataProfilesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTableDataProfilesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTableDataProfilesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListTableDataProfilesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTableDataProfilesRequest>): ListTableDataProfilesRequest {
    return ListTableDataProfilesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTableDataProfilesRequest>): ListTableDataProfilesRequest {
    const message = createBaseListTableDataProfilesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListTableDataProfilesResponse(): ListTableDataProfilesResponse {
  return { tableDataProfiles: [], nextPageToken: "" };
}

export const ListTableDataProfilesResponse: MessageFns<ListTableDataProfilesResponse> = {
  encode(message: ListTableDataProfilesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tableDataProfiles) {
      TableDataProfile.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTableDataProfilesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTableDataProfilesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableDataProfiles.push(TableDataProfile.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTableDataProfilesResponse {
    return {
      tableDataProfiles: globalThis.Array.isArray(object?.tableDataProfiles)
        ? object.tableDataProfiles.map((e: any) => TableDataProfile.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTableDataProfilesResponse): unknown {
    const obj: any = {};
    if (message.tableDataProfiles?.length) {
      obj.tableDataProfiles = message.tableDataProfiles.map((e) => TableDataProfile.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTableDataProfilesResponse>): ListTableDataProfilesResponse {
    return ListTableDataProfilesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTableDataProfilesResponse>): ListTableDataProfilesResponse {
    const message = createBaseListTableDataProfilesResponse();
    message.tableDataProfiles = object.tableDataProfiles?.map((e) => TableDataProfile.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseListColumnDataProfilesRequest(): ListColumnDataProfilesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", filter: "" };
}

export const ListColumnDataProfilesRequest: MessageFns<ListColumnDataProfilesRequest> = {
  encode(message: ListColumnDataProfilesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListColumnDataProfilesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListColumnDataProfilesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListColumnDataProfilesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListColumnDataProfilesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListColumnDataProfilesRequest>): ListColumnDataProfilesRequest {
    return ListColumnDataProfilesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListColumnDataProfilesRequest>): ListColumnDataProfilesRequest {
    const message = createBaseListColumnDataProfilesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListColumnDataProfilesResponse(): ListColumnDataProfilesResponse {
  return { columnDataProfiles: [], nextPageToken: "" };
}

export const ListColumnDataProfilesResponse: MessageFns<ListColumnDataProfilesResponse> = {
  encode(message: ListColumnDataProfilesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.columnDataProfiles) {
      ColumnDataProfile.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListColumnDataProfilesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListColumnDataProfilesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.columnDataProfiles.push(ColumnDataProfile.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListColumnDataProfilesResponse {
    return {
      columnDataProfiles: globalThis.Array.isArray(object?.columnDataProfiles)
        ? object.columnDataProfiles.map((e: any) => ColumnDataProfile.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListColumnDataProfilesResponse): unknown {
    const obj: any = {};
    if (message.columnDataProfiles?.length) {
      obj.columnDataProfiles = message.columnDataProfiles.map((e) => ColumnDataProfile.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListColumnDataProfilesResponse>): ListColumnDataProfilesResponse {
    return ListColumnDataProfilesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListColumnDataProfilesResponse>): ListColumnDataProfilesResponse {
    const message = createBaseListColumnDataProfilesResponse();
    message.columnDataProfiles = object.columnDataProfiles?.map((e) => ColumnDataProfile.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDataRiskLevel(): DataRiskLevel {
  return { score: 0 };
}

export const DataRiskLevel: MessageFns<DataRiskLevel> = {
  encode(message: DataRiskLevel, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.score !== 0) {
      writer.uint32(8).int32(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataRiskLevel {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataRiskLevel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.score = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataRiskLevel {
    return { score: isSet(object.score) ? dataRiskLevel_DataRiskLevelScoreFromJSON(object.score) : 0 };
  },

  toJSON(message: DataRiskLevel): unknown {
    const obj: any = {};
    if (message.score !== 0) {
      obj.score = dataRiskLevel_DataRiskLevelScoreToJSON(message.score);
    }
    return obj;
  },

  create(base?: DeepPartial<DataRiskLevel>): DataRiskLevel {
    return DataRiskLevel.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataRiskLevel>): DataRiskLevel {
    const message = createBaseDataRiskLevel();
    message.score = object.score ?? 0;
    return message;
  },
};

function createBaseProjectDataProfile(): ProjectDataProfile {
  return {
    name: "",
    projectId: "",
    profileLastGenerated: undefined,
    sensitivityScore: undefined,
    dataRiskLevel: undefined,
    profileStatus: undefined,
    tableDataProfileCount: Long.ZERO,
    fileStoreDataProfileCount: Long.ZERO,
  };
}

export const ProjectDataProfile: MessageFns<ProjectDataProfile> = {
  encode(message: ProjectDataProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.profileLastGenerated !== undefined) {
      Timestamp.encode(toTimestamp(message.profileLastGenerated), writer.uint32(26).fork()).join();
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(34).fork()).join();
    }
    if (message.dataRiskLevel !== undefined) {
      DataRiskLevel.encode(message.dataRiskLevel, writer.uint32(42).fork()).join();
    }
    if (message.profileStatus !== undefined) {
      ProfileStatus.encode(message.profileStatus, writer.uint32(58).fork()).join();
    }
    if (!message.tableDataProfileCount.equals(Long.ZERO)) {
      writer.uint32(72).int64(message.tableDataProfileCount.toString());
    }
    if (!message.fileStoreDataProfileCount.equals(Long.ZERO)) {
      writer.uint32(80).int64(message.fileStoreDataProfileCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ProjectDataProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProjectDataProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.profileLastGenerated = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.dataRiskLevel = DataRiskLevel.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.profileStatus = ProfileStatus.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.tableDataProfileCount = Long.fromString(reader.int64().toString());
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.fileStoreDataProfileCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProjectDataProfile {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      profileLastGenerated: isSet(object.profileLastGenerated)
        ? fromJsonTimestamp(object.profileLastGenerated)
        : undefined,
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
      dataRiskLevel: isSet(object.dataRiskLevel) ? DataRiskLevel.fromJSON(object.dataRiskLevel) : undefined,
      profileStatus: isSet(object.profileStatus) ? ProfileStatus.fromJSON(object.profileStatus) : undefined,
      tableDataProfileCount: isSet(object.tableDataProfileCount)
        ? Long.fromValue(object.tableDataProfileCount)
        : Long.ZERO,
      fileStoreDataProfileCount: isSet(object.fileStoreDataProfileCount)
        ? Long.fromValue(object.fileStoreDataProfileCount)
        : Long.ZERO,
    };
  },

  toJSON(message: ProjectDataProfile): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.profileLastGenerated !== undefined) {
      obj.profileLastGenerated = message.profileLastGenerated.toISOString();
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    if (message.dataRiskLevel !== undefined) {
      obj.dataRiskLevel = DataRiskLevel.toJSON(message.dataRiskLevel);
    }
    if (message.profileStatus !== undefined) {
      obj.profileStatus = ProfileStatus.toJSON(message.profileStatus);
    }
    if (!message.tableDataProfileCount.equals(Long.ZERO)) {
      obj.tableDataProfileCount = (message.tableDataProfileCount || Long.ZERO).toString();
    }
    if (!message.fileStoreDataProfileCount.equals(Long.ZERO)) {
      obj.fileStoreDataProfileCount = (message.fileStoreDataProfileCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<ProjectDataProfile>): ProjectDataProfile {
    return ProjectDataProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ProjectDataProfile>): ProjectDataProfile {
    const message = createBaseProjectDataProfile();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.profileLastGenerated = object.profileLastGenerated ?? undefined;
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    message.dataRiskLevel = (object.dataRiskLevel !== undefined && object.dataRiskLevel !== null)
      ? DataRiskLevel.fromPartial(object.dataRiskLevel)
      : undefined;
    message.profileStatus = (object.profileStatus !== undefined && object.profileStatus !== null)
      ? ProfileStatus.fromPartial(object.profileStatus)
      : undefined;
    message.tableDataProfileCount =
      (object.tableDataProfileCount !== undefined && object.tableDataProfileCount !== null)
        ? Long.fromValue(object.tableDataProfileCount)
        : Long.ZERO;
    message.fileStoreDataProfileCount =
      (object.fileStoreDataProfileCount !== undefined && object.fileStoreDataProfileCount !== null)
        ? Long.fromValue(object.fileStoreDataProfileCount)
        : Long.ZERO;
    return message;
  },
};

function createBaseDataProfileConfigSnapshot(): DataProfileConfigSnapshot {
  return {
    inspectConfig: undefined,
    dataProfileJob: undefined,
    discoveryConfig: undefined,
    inspectTemplateName: "",
    inspectTemplateModifiedTime: undefined,
  };
}

export const DataProfileConfigSnapshot: MessageFns<DataProfileConfigSnapshot> = {
  encode(message: DataProfileConfigSnapshot, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.inspectConfig !== undefined) {
      InspectConfig.encode(message.inspectConfig, writer.uint32(18).fork()).join();
    }
    if (message.dataProfileJob !== undefined) {
      DataProfileJobConfig.encode(message.dataProfileJob, writer.uint32(26).fork()).join();
    }
    if (message.discoveryConfig !== undefined) {
      DiscoveryConfig.encode(message.discoveryConfig, writer.uint32(34).fork()).join();
    }
    if (message.inspectTemplateName !== "") {
      writer.uint32(42).string(message.inspectTemplateName);
    }
    if (message.inspectTemplateModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.inspectTemplateModifiedTime), writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileConfigSnapshot {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileConfigSnapshot();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inspectConfig = InspectConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.dataProfileJob = DataProfileJobConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.discoveryConfig = DiscoveryConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inspectTemplateName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.inspectTemplateModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileConfigSnapshot {
    return {
      inspectConfig: isSet(object.inspectConfig) ? InspectConfig.fromJSON(object.inspectConfig) : undefined,
      dataProfileJob: isSet(object.dataProfileJob) ? DataProfileJobConfig.fromJSON(object.dataProfileJob) : undefined,
      discoveryConfig: isSet(object.discoveryConfig) ? DiscoveryConfig.fromJSON(object.discoveryConfig) : undefined,
      inspectTemplateName: isSet(object.inspectTemplateName) ? globalThis.String(object.inspectTemplateName) : "",
      inspectTemplateModifiedTime: isSet(object.inspectTemplateModifiedTime)
        ? fromJsonTimestamp(object.inspectTemplateModifiedTime)
        : undefined,
    };
  },

  toJSON(message: DataProfileConfigSnapshot): unknown {
    const obj: any = {};
    if (message.inspectConfig !== undefined) {
      obj.inspectConfig = InspectConfig.toJSON(message.inspectConfig);
    }
    if (message.dataProfileJob !== undefined) {
      obj.dataProfileJob = DataProfileJobConfig.toJSON(message.dataProfileJob);
    }
    if (message.discoveryConfig !== undefined) {
      obj.discoveryConfig = DiscoveryConfig.toJSON(message.discoveryConfig);
    }
    if (message.inspectTemplateName !== "") {
      obj.inspectTemplateName = message.inspectTemplateName;
    }
    if (message.inspectTemplateModifiedTime !== undefined) {
      obj.inspectTemplateModifiedTime = message.inspectTemplateModifiedTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfileConfigSnapshot>): DataProfileConfigSnapshot {
    return DataProfileConfigSnapshot.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfileConfigSnapshot>): DataProfileConfigSnapshot {
    const message = createBaseDataProfileConfigSnapshot();
    message.inspectConfig = (object.inspectConfig !== undefined && object.inspectConfig !== null)
      ? InspectConfig.fromPartial(object.inspectConfig)
      : undefined;
    message.dataProfileJob = (object.dataProfileJob !== undefined && object.dataProfileJob !== null)
      ? DataProfileJobConfig.fromPartial(object.dataProfileJob)
      : undefined;
    message.discoveryConfig = (object.discoveryConfig !== undefined && object.discoveryConfig !== null)
      ? DiscoveryConfig.fromPartial(object.discoveryConfig)
      : undefined;
    message.inspectTemplateName = object.inspectTemplateName ?? "";
    message.inspectTemplateModifiedTime = object.inspectTemplateModifiedTime ?? undefined;
    return message;
  },
};

function createBaseTableDataProfile(): TableDataProfile {
  return {
    name: "",
    dataSourceType: undefined,
    projectDataProfile: "",
    datasetProjectId: "",
    datasetLocation: "",
    datasetId: "",
    tableId: "",
    fullResource: "",
    profileStatus: undefined,
    state: 0,
    sensitivityScore: undefined,
    dataRiskLevel: undefined,
    predictedInfoTypes: [],
    otherInfoTypes: [],
    configSnapshot: undefined,
    lastModifiedTime: undefined,
    expirationTime: undefined,
    scannedColumnCount: Long.ZERO,
    failedColumnCount: Long.ZERO,
    tableSizeBytes: Long.ZERO,
    rowCount: Long.ZERO,
    encryptionStatus: 0,
    resourceVisibility: 0,
    profileLastGenerated: undefined,
    resourceLabels: {},
    createTime: undefined,
  };
}

export const TableDataProfile: MessageFns<TableDataProfile> = {
  encode(message: TableDataProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.dataSourceType !== undefined) {
      DataSourceType.encode(message.dataSourceType, writer.uint32(290).fork()).join();
    }
    if (message.projectDataProfile !== "") {
      writer.uint32(18).string(message.projectDataProfile);
    }
    if (message.datasetProjectId !== "") {
      writer.uint32(194).string(message.datasetProjectId);
    }
    if (message.datasetLocation !== "") {
      writer.uint32(234).string(message.datasetLocation);
    }
    if (message.datasetId !== "") {
      writer.uint32(202).string(message.datasetId);
    }
    if (message.tableId !== "") {
      writer.uint32(210).string(message.tableId);
    }
    if (message.fullResource !== "") {
      writer.uint32(26).string(message.fullResource);
    }
    if (message.profileStatus !== undefined) {
      ProfileStatus.encode(message.profileStatus, writer.uint32(170).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(176).int32(message.state);
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(42).fork()).join();
    }
    if (message.dataRiskLevel !== undefined) {
      DataRiskLevel.encode(message.dataRiskLevel, writer.uint32(50).fork()).join();
    }
    for (const v of message.predictedInfoTypes) {
      InfoTypeSummary.encode(v!, writer.uint32(218).fork()).join();
    }
    for (const v of message.otherInfoTypes) {
      OtherInfoTypeSummary.encode(v!, writer.uint32(226).fork()).join();
    }
    if (message.configSnapshot !== undefined) {
      DataProfileConfigSnapshot.encode(message.configSnapshot, writer.uint32(58).fork()).join();
    }
    if (message.lastModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedTime), writer.uint32(66).fork()).join();
    }
    if (message.expirationTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expirationTime), writer.uint32(74).fork()).join();
    }
    if (!message.scannedColumnCount.equals(Long.ZERO)) {
      writer.uint32(80).int64(message.scannedColumnCount.toString());
    }
    if (!message.failedColumnCount.equals(Long.ZERO)) {
      writer.uint32(88).int64(message.failedColumnCount.toString());
    }
    if (!message.tableSizeBytes.equals(Long.ZERO)) {
      writer.uint32(96).int64(message.tableSizeBytes.toString());
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(104).int64(message.rowCount.toString());
    }
    if (message.encryptionStatus !== 0) {
      writer.uint32(112).int32(message.encryptionStatus);
    }
    if (message.resourceVisibility !== 0) {
      writer.uint32(120).int32(message.resourceVisibility);
    }
    if (message.profileLastGenerated !== undefined) {
      Timestamp.encode(toTimestamp(message.profileLastGenerated), writer.uint32(130).fork()).join();
    }
    Object.entries(message.resourceLabels).forEach(([key, value]) => {
      TableDataProfile_ResourceLabelsEntry.encode({ key: key as any, value }, writer.uint32(138).fork()).join();
    });
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(186).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableDataProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableDataProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 36:
          if (tag !== 290) {
            break;
          }

          message.dataSourceType = DataSourceType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectDataProfile = reader.string();
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.datasetProjectId = reader.string();
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.datasetLocation = reader.string();
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.tableId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.fullResource = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.profileStatus = ProfileStatus.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.dataRiskLevel = DataRiskLevel.decode(reader, reader.uint32());
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.predictedInfoTypes.push(InfoTypeSummary.decode(reader, reader.uint32()));
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.otherInfoTypes.push(OtherInfoTypeSummary.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.configSnapshot = DataProfileConfigSnapshot.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.lastModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.expirationTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.scannedColumnCount = Long.fromString(reader.int64().toString());
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.failedColumnCount = Long.fromString(reader.int64().toString());
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.tableSizeBytes = Long.fromString(reader.int64().toString());
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.encryptionStatus = reader.int32() as any;
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.resourceVisibility = reader.int32() as any;
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.profileLastGenerated = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          const entry17 = TableDataProfile_ResourceLabelsEntry.decode(reader, reader.uint32());
          if (entry17.value !== undefined) {
            message.resourceLabels[entry17.key] = entry17.value;
          }
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableDataProfile {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      dataSourceType: isSet(object.dataSourceType) ? DataSourceType.fromJSON(object.dataSourceType) : undefined,
      projectDataProfile: isSet(object.projectDataProfile) ? globalThis.String(object.projectDataProfile) : "",
      datasetProjectId: isSet(object.datasetProjectId) ? globalThis.String(object.datasetProjectId) : "",
      datasetLocation: isSet(object.datasetLocation) ? globalThis.String(object.datasetLocation) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      tableId: isSet(object.tableId) ? globalThis.String(object.tableId) : "",
      fullResource: isSet(object.fullResource) ? globalThis.String(object.fullResource) : "",
      profileStatus: isSet(object.profileStatus) ? ProfileStatus.fromJSON(object.profileStatus) : undefined,
      state: isSet(object.state) ? tableDataProfile_StateFromJSON(object.state) : 0,
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
      dataRiskLevel: isSet(object.dataRiskLevel) ? DataRiskLevel.fromJSON(object.dataRiskLevel) : undefined,
      predictedInfoTypes: globalThis.Array.isArray(object?.predictedInfoTypes)
        ? object.predictedInfoTypes.map((e: any) => InfoTypeSummary.fromJSON(e))
        : [],
      otherInfoTypes: globalThis.Array.isArray(object?.otherInfoTypes)
        ? object.otherInfoTypes.map((e: any) => OtherInfoTypeSummary.fromJSON(e))
        : [],
      configSnapshot: isSet(object.configSnapshot)
        ? DataProfileConfigSnapshot.fromJSON(object.configSnapshot)
        : undefined,
      lastModifiedTime: isSet(object.lastModifiedTime) ? fromJsonTimestamp(object.lastModifiedTime) : undefined,
      expirationTime: isSet(object.expirationTime) ? fromJsonTimestamp(object.expirationTime) : undefined,
      scannedColumnCount: isSet(object.scannedColumnCount) ? Long.fromValue(object.scannedColumnCount) : Long.ZERO,
      failedColumnCount: isSet(object.failedColumnCount) ? Long.fromValue(object.failedColumnCount) : Long.ZERO,
      tableSizeBytes: isSet(object.tableSizeBytes) ? Long.fromValue(object.tableSizeBytes) : Long.ZERO,
      rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO,
      encryptionStatus: isSet(object.encryptionStatus) ? encryptionStatusFromJSON(object.encryptionStatus) : 0,
      resourceVisibility: isSet(object.resourceVisibility) ? resourceVisibilityFromJSON(object.resourceVisibility) : 0,
      profileLastGenerated: isSet(object.profileLastGenerated)
        ? fromJsonTimestamp(object.profileLastGenerated)
        : undefined,
      resourceLabels: isObject(object.resourceLabels)
        ? Object.entries(object.resourceLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: TableDataProfile): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.dataSourceType !== undefined) {
      obj.dataSourceType = DataSourceType.toJSON(message.dataSourceType);
    }
    if (message.projectDataProfile !== "") {
      obj.projectDataProfile = message.projectDataProfile;
    }
    if (message.datasetProjectId !== "") {
      obj.datasetProjectId = message.datasetProjectId;
    }
    if (message.datasetLocation !== "") {
      obj.datasetLocation = message.datasetLocation;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.tableId !== "") {
      obj.tableId = message.tableId;
    }
    if (message.fullResource !== "") {
      obj.fullResource = message.fullResource;
    }
    if (message.profileStatus !== undefined) {
      obj.profileStatus = ProfileStatus.toJSON(message.profileStatus);
    }
    if (message.state !== 0) {
      obj.state = tableDataProfile_StateToJSON(message.state);
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    if (message.dataRiskLevel !== undefined) {
      obj.dataRiskLevel = DataRiskLevel.toJSON(message.dataRiskLevel);
    }
    if (message.predictedInfoTypes?.length) {
      obj.predictedInfoTypes = message.predictedInfoTypes.map((e) => InfoTypeSummary.toJSON(e));
    }
    if (message.otherInfoTypes?.length) {
      obj.otherInfoTypes = message.otherInfoTypes.map((e) => OtherInfoTypeSummary.toJSON(e));
    }
    if (message.configSnapshot !== undefined) {
      obj.configSnapshot = DataProfileConfigSnapshot.toJSON(message.configSnapshot);
    }
    if (message.lastModifiedTime !== undefined) {
      obj.lastModifiedTime = message.lastModifiedTime.toISOString();
    }
    if (message.expirationTime !== undefined) {
      obj.expirationTime = message.expirationTime.toISOString();
    }
    if (!message.scannedColumnCount.equals(Long.ZERO)) {
      obj.scannedColumnCount = (message.scannedColumnCount || Long.ZERO).toString();
    }
    if (!message.failedColumnCount.equals(Long.ZERO)) {
      obj.failedColumnCount = (message.failedColumnCount || Long.ZERO).toString();
    }
    if (!message.tableSizeBytes.equals(Long.ZERO)) {
      obj.tableSizeBytes = (message.tableSizeBytes || Long.ZERO).toString();
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    if (message.encryptionStatus !== 0) {
      obj.encryptionStatus = encryptionStatusToJSON(message.encryptionStatus);
    }
    if (message.resourceVisibility !== 0) {
      obj.resourceVisibility = resourceVisibilityToJSON(message.resourceVisibility);
    }
    if (message.profileLastGenerated !== undefined) {
      obj.profileLastGenerated = message.profileLastGenerated.toISOString();
    }
    if (message.resourceLabels) {
      const entries = Object.entries(message.resourceLabels);
      if (entries.length > 0) {
        obj.resourceLabels = {};
        entries.forEach(([k, v]) => {
          obj.resourceLabels[k] = v;
        });
      }
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<TableDataProfile>): TableDataProfile {
    return TableDataProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableDataProfile>): TableDataProfile {
    const message = createBaseTableDataProfile();
    message.name = object.name ?? "";
    message.dataSourceType = (object.dataSourceType !== undefined && object.dataSourceType !== null)
      ? DataSourceType.fromPartial(object.dataSourceType)
      : undefined;
    message.projectDataProfile = object.projectDataProfile ?? "";
    message.datasetProjectId = object.datasetProjectId ?? "";
    message.datasetLocation = object.datasetLocation ?? "";
    message.datasetId = object.datasetId ?? "";
    message.tableId = object.tableId ?? "";
    message.fullResource = object.fullResource ?? "";
    message.profileStatus = (object.profileStatus !== undefined && object.profileStatus !== null)
      ? ProfileStatus.fromPartial(object.profileStatus)
      : undefined;
    message.state = object.state ?? 0;
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    message.dataRiskLevel = (object.dataRiskLevel !== undefined && object.dataRiskLevel !== null)
      ? DataRiskLevel.fromPartial(object.dataRiskLevel)
      : undefined;
    message.predictedInfoTypes = object.predictedInfoTypes?.map((e) => InfoTypeSummary.fromPartial(e)) || [];
    message.otherInfoTypes = object.otherInfoTypes?.map((e) => OtherInfoTypeSummary.fromPartial(e)) || [];
    message.configSnapshot = (object.configSnapshot !== undefined && object.configSnapshot !== null)
      ? DataProfileConfigSnapshot.fromPartial(object.configSnapshot)
      : undefined;
    message.lastModifiedTime = object.lastModifiedTime ?? undefined;
    message.expirationTime = object.expirationTime ?? undefined;
    message.scannedColumnCount = (object.scannedColumnCount !== undefined && object.scannedColumnCount !== null)
      ? Long.fromValue(object.scannedColumnCount)
      : Long.ZERO;
    message.failedColumnCount = (object.failedColumnCount !== undefined && object.failedColumnCount !== null)
      ? Long.fromValue(object.failedColumnCount)
      : Long.ZERO;
    message.tableSizeBytes = (object.tableSizeBytes !== undefined && object.tableSizeBytes !== null)
      ? Long.fromValue(object.tableSizeBytes)
      : Long.ZERO;
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    message.encryptionStatus = object.encryptionStatus ?? 0;
    message.resourceVisibility = object.resourceVisibility ?? 0;
    message.profileLastGenerated = object.profileLastGenerated ?? undefined;
    message.resourceLabels = Object.entries(object.resourceLabels ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseTableDataProfile_ResourceLabelsEntry(): TableDataProfile_ResourceLabelsEntry {
  return { key: "", value: "" };
}

export const TableDataProfile_ResourceLabelsEntry: MessageFns<TableDataProfile_ResourceLabelsEntry> = {
  encode(message: TableDataProfile_ResourceLabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableDataProfile_ResourceLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableDataProfile_ResourceLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableDataProfile_ResourceLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: TableDataProfile_ResourceLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<TableDataProfile_ResourceLabelsEntry>): TableDataProfile_ResourceLabelsEntry {
    return TableDataProfile_ResourceLabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableDataProfile_ResourceLabelsEntry>): TableDataProfile_ResourceLabelsEntry {
    const message = createBaseTableDataProfile_ResourceLabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseProfileStatus(): ProfileStatus {
  return { status: undefined, timestamp: undefined };
}

export const ProfileStatus: MessageFns<ProfileStatus> = {
  encode(message: ProfileStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== undefined) {
      Status.encode(message.status, writer.uint32(10).fork()).join();
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ProfileStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProfileStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.status = Status.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProfileStatus {
    return {
      status: isSet(object.status) ? Status.fromJSON(object.status) : undefined,
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: ProfileStatus): unknown {
    const obj: any = {};
    if (message.status !== undefined) {
      obj.status = Status.toJSON(message.status);
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ProfileStatus>): ProfileStatus {
    return ProfileStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ProfileStatus>): ProfileStatus {
    const message = createBaseProfileStatus();
    message.status = (object.status !== undefined && object.status !== null)
      ? Status.fromPartial(object.status)
      : undefined;
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

function createBaseInfoTypeSummary(): InfoTypeSummary {
  return { infoType: undefined, estimatedPrevalence: 0 };
}

export const InfoTypeSummary: MessageFns<InfoTypeSummary> = {
  encode(message: InfoTypeSummary, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (message.estimatedPrevalence !== 0) {
      writer.uint32(16).int32(message.estimatedPrevalence);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InfoTypeSummary {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInfoTypeSummary();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.estimatedPrevalence = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InfoTypeSummary {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      estimatedPrevalence: isSet(object.estimatedPrevalence) ? globalThis.Number(object.estimatedPrevalence) : 0,
    };
  },

  toJSON(message: InfoTypeSummary): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.estimatedPrevalence !== 0) {
      obj.estimatedPrevalence = Math.round(message.estimatedPrevalence);
    }
    return obj;
  },

  create(base?: DeepPartial<InfoTypeSummary>): InfoTypeSummary {
    return InfoTypeSummary.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InfoTypeSummary>): InfoTypeSummary {
    const message = createBaseInfoTypeSummary();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.estimatedPrevalence = object.estimatedPrevalence ?? 0;
    return message;
  },
};

function createBaseOtherInfoTypeSummary(): OtherInfoTypeSummary {
  return { infoType: undefined, estimatedPrevalence: 0, excludedFromAnalysis: false };
}

export const OtherInfoTypeSummary: MessageFns<OtherInfoTypeSummary> = {
  encode(message: OtherInfoTypeSummary, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    if (message.estimatedPrevalence !== 0) {
      writer.uint32(16).int32(message.estimatedPrevalence);
    }
    if (message.excludedFromAnalysis !== false) {
      writer.uint32(24).bool(message.excludedFromAnalysis);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OtherInfoTypeSummary {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOtherInfoTypeSummary();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.estimatedPrevalence = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.excludedFromAnalysis = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OtherInfoTypeSummary {
    return {
      infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined,
      estimatedPrevalence: isSet(object.estimatedPrevalence) ? globalThis.Number(object.estimatedPrevalence) : 0,
      excludedFromAnalysis: isSet(object.excludedFromAnalysis)
        ? globalThis.Boolean(object.excludedFromAnalysis)
        : false,
    };
  },

  toJSON(message: OtherInfoTypeSummary): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    if (message.estimatedPrevalence !== 0) {
      obj.estimatedPrevalence = Math.round(message.estimatedPrevalence);
    }
    if (message.excludedFromAnalysis !== false) {
      obj.excludedFromAnalysis = message.excludedFromAnalysis;
    }
    return obj;
  },

  create(base?: DeepPartial<OtherInfoTypeSummary>): OtherInfoTypeSummary {
    return OtherInfoTypeSummary.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OtherInfoTypeSummary>): OtherInfoTypeSummary {
    const message = createBaseOtherInfoTypeSummary();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    message.estimatedPrevalence = object.estimatedPrevalence ?? 0;
    message.excludedFromAnalysis = object.excludedFromAnalysis ?? false;
    return message;
  },
};

function createBaseColumnDataProfile(): ColumnDataProfile {
  return {
    name: "",
    profileStatus: undefined,
    state: 0,
    profileLastGenerated: undefined,
    tableDataProfile: "",
    tableFullResource: "",
    datasetProjectId: "",
    datasetLocation: "",
    datasetId: "",
    tableId: "",
    column: "",
    sensitivityScore: undefined,
    dataRiskLevel: undefined,
    columnInfoType: undefined,
    otherMatches: [],
    estimatedNullPercentage: 0,
    estimatedUniquenessScore: 0,
    freeTextScore: 0,
    columnType: 0,
    policyState: 0,
  };
}

export const ColumnDataProfile: MessageFns<ColumnDataProfile> = {
  encode(message: ColumnDataProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.profileStatus !== undefined) {
      ProfileStatus.encode(message.profileStatus, writer.uint32(138).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(144).int32(message.state);
    }
    if (message.profileLastGenerated !== undefined) {
      Timestamp.encode(toTimestamp(message.profileLastGenerated), writer.uint32(26).fork()).join();
    }
    if (message.tableDataProfile !== "") {
      writer.uint32(34).string(message.tableDataProfile);
    }
    if (message.tableFullResource !== "") {
      writer.uint32(42).string(message.tableFullResource);
    }
    if (message.datasetProjectId !== "") {
      writer.uint32(154).string(message.datasetProjectId);
    }
    if (message.datasetLocation !== "") {
      writer.uint32(162).string(message.datasetLocation);
    }
    if (message.datasetId !== "") {
      writer.uint32(170).string(message.datasetId);
    }
    if (message.tableId !== "") {
      writer.uint32(178).string(message.tableId);
    }
    if (message.column !== "") {
      writer.uint32(50).string(message.column);
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(58).fork()).join();
    }
    if (message.dataRiskLevel !== undefined) {
      DataRiskLevel.encode(message.dataRiskLevel, writer.uint32(66).fork()).join();
    }
    if (message.columnInfoType !== undefined) {
      InfoTypeSummary.encode(message.columnInfoType, writer.uint32(74).fork()).join();
    }
    for (const v of message.otherMatches) {
      OtherInfoTypeSummary.encode(v!, writer.uint32(82).fork()).join();
    }
    if (message.estimatedNullPercentage !== 0) {
      writer.uint32(184).int32(message.estimatedNullPercentage);
    }
    if (message.estimatedUniquenessScore !== 0) {
      writer.uint32(192).int32(message.estimatedUniquenessScore);
    }
    if (message.freeTextScore !== 0) {
      writer.uint32(105).double(message.freeTextScore);
    }
    if (message.columnType !== 0) {
      writer.uint32(112).int32(message.columnType);
    }
    if (message.policyState !== 0) {
      writer.uint32(120).int32(message.policyState);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ColumnDataProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseColumnDataProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.profileStatus = ProfileStatus.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.profileLastGenerated = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.tableDataProfile = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.tableFullResource = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.datasetProjectId = reader.string();
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.datasetLocation = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.tableId = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.column = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.dataRiskLevel = DataRiskLevel.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.columnInfoType = InfoTypeSummary.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.otherMatches.push(OtherInfoTypeSummary.decode(reader, reader.uint32()));
          continue;
        case 23:
          if (tag !== 184) {
            break;
          }

          message.estimatedNullPercentage = reader.int32() as any;
          continue;
        case 24:
          if (tag !== 192) {
            break;
          }

          message.estimatedUniquenessScore = reader.int32() as any;
          continue;
        case 13:
          if (tag !== 105) {
            break;
          }

          message.freeTextScore = reader.double();
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.columnType = reader.int32() as any;
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.policyState = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ColumnDataProfile {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      profileStatus: isSet(object.profileStatus) ? ProfileStatus.fromJSON(object.profileStatus) : undefined,
      state: isSet(object.state) ? columnDataProfile_StateFromJSON(object.state) : 0,
      profileLastGenerated: isSet(object.profileLastGenerated)
        ? fromJsonTimestamp(object.profileLastGenerated)
        : undefined,
      tableDataProfile: isSet(object.tableDataProfile) ? globalThis.String(object.tableDataProfile) : "",
      tableFullResource: isSet(object.tableFullResource) ? globalThis.String(object.tableFullResource) : "",
      datasetProjectId: isSet(object.datasetProjectId) ? globalThis.String(object.datasetProjectId) : "",
      datasetLocation: isSet(object.datasetLocation) ? globalThis.String(object.datasetLocation) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      tableId: isSet(object.tableId) ? globalThis.String(object.tableId) : "",
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
      dataRiskLevel: isSet(object.dataRiskLevel) ? DataRiskLevel.fromJSON(object.dataRiskLevel) : undefined,
      columnInfoType: isSet(object.columnInfoType) ? InfoTypeSummary.fromJSON(object.columnInfoType) : undefined,
      otherMatches: globalThis.Array.isArray(object?.otherMatches)
        ? object.otherMatches.map((e: any) => OtherInfoTypeSummary.fromJSON(e))
        : [],
      estimatedNullPercentage: isSet(object.estimatedNullPercentage)
        ? nullPercentageLevelFromJSON(object.estimatedNullPercentage)
        : 0,
      estimatedUniquenessScore: isSet(object.estimatedUniquenessScore)
        ? uniquenessScoreLevelFromJSON(object.estimatedUniquenessScore)
        : 0,
      freeTextScore: isSet(object.freeTextScore) ? globalThis.Number(object.freeTextScore) : 0,
      columnType: isSet(object.columnType) ? columnDataProfile_ColumnDataTypeFromJSON(object.columnType) : 0,
      policyState: isSet(object.policyState) ? columnDataProfile_ColumnPolicyStateFromJSON(object.policyState) : 0,
    };
  },

  toJSON(message: ColumnDataProfile): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.profileStatus !== undefined) {
      obj.profileStatus = ProfileStatus.toJSON(message.profileStatus);
    }
    if (message.state !== 0) {
      obj.state = columnDataProfile_StateToJSON(message.state);
    }
    if (message.profileLastGenerated !== undefined) {
      obj.profileLastGenerated = message.profileLastGenerated.toISOString();
    }
    if (message.tableDataProfile !== "") {
      obj.tableDataProfile = message.tableDataProfile;
    }
    if (message.tableFullResource !== "") {
      obj.tableFullResource = message.tableFullResource;
    }
    if (message.datasetProjectId !== "") {
      obj.datasetProjectId = message.datasetProjectId;
    }
    if (message.datasetLocation !== "") {
      obj.datasetLocation = message.datasetLocation;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.tableId !== "") {
      obj.tableId = message.tableId;
    }
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    if (message.dataRiskLevel !== undefined) {
      obj.dataRiskLevel = DataRiskLevel.toJSON(message.dataRiskLevel);
    }
    if (message.columnInfoType !== undefined) {
      obj.columnInfoType = InfoTypeSummary.toJSON(message.columnInfoType);
    }
    if (message.otherMatches?.length) {
      obj.otherMatches = message.otherMatches.map((e) => OtherInfoTypeSummary.toJSON(e));
    }
    if (message.estimatedNullPercentage !== 0) {
      obj.estimatedNullPercentage = nullPercentageLevelToJSON(message.estimatedNullPercentage);
    }
    if (message.estimatedUniquenessScore !== 0) {
      obj.estimatedUniquenessScore = uniquenessScoreLevelToJSON(message.estimatedUniquenessScore);
    }
    if (message.freeTextScore !== 0) {
      obj.freeTextScore = message.freeTextScore;
    }
    if (message.columnType !== 0) {
      obj.columnType = columnDataProfile_ColumnDataTypeToJSON(message.columnType);
    }
    if (message.policyState !== 0) {
      obj.policyState = columnDataProfile_ColumnPolicyStateToJSON(message.policyState);
    }
    return obj;
  },

  create(base?: DeepPartial<ColumnDataProfile>): ColumnDataProfile {
    return ColumnDataProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ColumnDataProfile>): ColumnDataProfile {
    const message = createBaseColumnDataProfile();
    message.name = object.name ?? "";
    message.profileStatus = (object.profileStatus !== undefined && object.profileStatus !== null)
      ? ProfileStatus.fromPartial(object.profileStatus)
      : undefined;
    message.state = object.state ?? 0;
    message.profileLastGenerated = object.profileLastGenerated ?? undefined;
    message.tableDataProfile = object.tableDataProfile ?? "";
    message.tableFullResource = object.tableFullResource ?? "";
    message.datasetProjectId = object.datasetProjectId ?? "";
    message.datasetLocation = object.datasetLocation ?? "";
    message.datasetId = object.datasetId ?? "";
    message.tableId = object.tableId ?? "";
    message.column = object.column ?? "";
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    message.dataRiskLevel = (object.dataRiskLevel !== undefined && object.dataRiskLevel !== null)
      ? DataRiskLevel.fromPartial(object.dataRiskLevel)
      : undefined;
    message.columnInfoType = (object.columnInfoType !== undefined && object.columnInfoType !== null)
      ? InfoTypeSummary.fromPartial(object.columnInfoType)
      : undefined;
    message.otherMatches = object.otherMatches?.map((e) => OtherInfoTypeSummary.fromPartial(e)) || [];
    message.estimatedNullPercentage = object.estimatedNullPercentage ?? 0;
    message.estimatedUniquenessScore = object.estimatedUniquenessScore ?? 0;
    message.freeTextScore = object.freeTextScore ?? 0;
    message.columnType = object.columnType ?? 0;
    message.policyState = object.policyState ?? 0;
    return message;
  },
};

function createBaseFileStoreDataProfile(): FileStoreDataProfile {
  return {
    name: "",
    dataSourceType: undefined,
    projectDataProfile: "",
    projectId: "",
    fileStoreLocation: "",
    dataStorageLocations: [],
    locationType: "",
    fileStorePath: "",
    fullResource: "",
    configSnapshot: undefined,
    profileStatus: undefined,
    state: 0,
    profileLastGenerated: undefined,
    resourceVisibility: 0,
    sensitivityScore: undefined,
    dataRiskLevel: undefined,
    createTime: undefined,
    lastModifiedTime: undefined,
    fileClusterSummaries: [],
    resourceAttributes: {},
    resourceLabels: {},
    fileStoreInfoTypeSummaries: [],
    fileStoreIsEmpty: false,
  };
}

export const FileStoreDataProfile: MessageFns<FileStoreDataProfile> = {
  encode(message: FileStoreDataProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.dataSourceType !== undefined) {
      DataSourceType.encode(message.dataSourceType, writer.uint32(18).fork()).join();
    }
    if (message.projectDataProfile !== "") {
      writer.uint32(26).string(message.projectDataProfile);
    }
    if (message.projectId !== "") {
      writer.uint32(34).string(message.projectId);
    }
    if (message.fileStoreLocation !== "") {
      writer.uint32(42).string(message.fileStoreLocation);
    }
    for (const v of message.dataStorageLocations) {
      writer.uint32(154).string(v!);
    }
    if (message.locationType !== "") {
      writer.uint32(162).string(message.locationType);
    }
    if (message.fileStorePath !== "") {
      writer.uint32(50).string(message.fileStorePath);
    }
    if (message.fullResource !== "") {
      writer.uint32(194).string(message.fullResource);
    }
    if (message.configSnapshot !== undefined) {
      DataProfileConfigSnapshot.encode(message.configSnapshot, writer.uint32(58).fork()).join();
    }
    if (message.profileStatus !== undefined) {
      ProfileStatus.encode(message.profileStatus, writer.uint32(66).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(72).int32(message.state);
    }
    if (message.profileLastGenerated !== undefined) {
      Timestamp.encode(toTimestamp(message.profileLastGenerated), writer.uint32(82).fork()).join();
    }
    if (message.resourceVisibility !== 0) {
      writer.uint32(88).int32(message.resourceVisibility);
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(98).fork()).join();
    }
    if (message.dataRiskLevel !== undefined) {
      DataRiskLevel.encode(message.dataRiskLevel, writer.uint32(106).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(114).fork()).join();
    }
    if (message.lastModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedTime), writer.uint32(122).fork()).join();
    }
    for (const v of message.fileClusterSummaries) {
      FileClusterSummary.encode(v!, writer.uint32(130).fork()).join();
    }
    Object.entries(message.resourceAttributes).forEach(([key, value]) => {
      FileStoreDataProfile_ResourceAttributesEntry.encode({ key: key as any, value }, writer.uint32(138).fork()).join();
    });
    Object.entries(message.resourceLabels).forEach(([key, value]) => {
      FileStoreDataProfile_ResourceLabelsEntry.encode({ key: key as any, value }, writer.uint32(146).fork()).join();
    });
    for (const v of message.fileStoreInfoTypeSummaries) {
      FileStoreInfoTypeSummary.encode(v!, writer.uint32(170).fork()).join();
    }
    if (message.fileStoreIsEmpty !== false) {
      writer.uint32(184).bool(message.fileStoreIsEmpty);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreDataProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreDataProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataSourceType = DataSourceType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.projectDataProfile = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.fileStoreLocation = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.dataStorageLocations.push(reader.string());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.locationType = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.fileStorePath = reader.string();
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.fullResource = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.configSnapshot = DataProfileConfigSnapshot.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.profileStatus = ProfileStatus.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.profileLastGenerated = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.resourceVisibility = reader.int32() as any;
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.dataRiskLevel = DataRiskLevel.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.lastModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.fileClusterSummaries.push(FileClusterSummary.decode(reader, reader.uint32()));
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          const entry17 = FileStoreDataProfile_ResourceAttributesEntry.decode(reader, reader.uint32());
          if (entry17.value !== undefined) {
            message.resourceAttributes[entry17.key] = entry17.value;
          }
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          const entry18 = FileStoreDataProfile_ResourceLabelsEntry.decode(reader, reader.uint32());
          if (entry18.value !== undefined) {
            message.resourceLabels[entry18.key] = entry18.value;
          }
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.fileStoreInfoTypeSummaries.push(FileStoreInfoTypeSummary.decode(reader, reader.uint32()));
          continue;
        case 23:
          if (tag !== 184) {
            break;
          }

          message.fileStoreIsEmpty = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreDataProfile {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      dataSourceType: isSet(object.dataSourceType) ? DataSourceType.fromJSON(object.dataSourceType) : undefined,
      projectDataProfile: isSet(object.projectDataProfile) ? globalThis.String(object.projectDataProfile) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      fileStoreLocation: isSet(object.fileStoreLocation) ? globalThis.String(object.fileStoreLocation) : "",
      dataStorageLocations: globalThis.Array.isArray(object?.dataStorageLocations)
        ? object.dataStorageLocations.map((e: any) => globalThis.String(e))
        : [],
      locationType: isSet(object.locationType) ? globalThis.String(object.locationType) : "",
      fileStorePath: isSet(object.fileStorePath) ? globalThis.String(object.fileStorePath) : "",
      fullResource: isSet(object.fullResource) ? globalThis.String(object.fullResource) : "",
      configSnapshot: isSet(object.configSnapshot)
        ? DataProfileConfigSnapshot.fromJSON(object.configSnapshot)
        : undefined,
      profileStatus: isSet(object.profileStatus) ? ProfileStatus.fromJSON(object.profileStatus) : undefined,
      state: isSet(object.state) ? fileStoreDataProfile_StateFromJSON(object.state) : 0,
      profileLastGenerated: isSet(object.profileLastGenerated)
        ? fromJsonTimestamp(object.profileLastGenerated)
        : undefined,
      resourceVisibility: isSet(object.resourceVisibility) ? resourceVisibilityFromJSON(object.resourceVisibility) : 0,
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
      dataRiskLevel: isSet(object.dataRiskLevel) ? DataRiskLevel.fromJSON(object.dataRiskLevel) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      lastModifiedTime: isSet(object.lastModifiedTime) ? fromJsonTimestamp(object.lastModifiedTime) : undefined,
      fileClusterSummaries: globalThis.Array.isArray(object?.fileClusterSummaries)
        ? object.fileClusterSummaries.map((e: any) => FileClusterSummary.fromJSON(e))
        : [],
      resourceAttributes: isObject(object.resourceAttributes)
        ? Object.entries(object.resourceAttributes).reduce<{ [key: string]: Value }>((acc, [key, value]) => {
          acc[key] = Value.fromJSON(value);
          return acc;
        }, {})
        : {},
      resourceLabels: isObject(object.resourceLabels)
        ? Object.entries(object.resourceLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      fileStoreInfoTypeSummaries: globalThis.Array.isArray(object?.fileStoreInfoTypeSummaries)
        ? object.fileStoreInfoTypeSummaries.map((e: any) => FileStoreInfoTypeSummary.fromJSON(e))
        : [],
      fileStoreIsEmpty: isSet(object.fileStoreIsEmpty) ? globalThis.Boolean(object.fileStoreIsEmpty) : false,
    };
  },

  toJSON(message: FileStoreDataProfile): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.dataSourceType !== undefined) {
      obj.dataSourceType = DataSourceType.toJSON(message.dataSourceType);
    }
    if (message.projectDataProfile !== "") {
      obj.projectDataProfile = message.projectDataProfile;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.fileStoreLocation !== "") {
      obj.fileStoreLocation = message.fileStoreLocation;
    }
    if (message.dataStorageLocations?.length) {
      obj.dataStorageLocations = message.dataStorageLocations;
    }
    if (message.locationType !== "") {
      obj.locationType = message.locationType;
    }
    if (message.fileStorePath !== "") {
      obj.fileStorePath = message.fileStorePath;
    }
    if (message.fullResource !== "") {
      obj.fullResource = message.fullResource;
    }
    if (message.configSnapshot !== undefined) {
      obj.configSnapshot = DataProfileConfigSnapshot.toJSON(message.configSnapshot);
    }
    if (message.profileStatus !== undefined) {
      obj.profileStatus = ProfileStatus.toJSON(message.profileStatus);
    }
    if (message.state !== 0) {
      obj.state = fileStoreDataProfile_StateToJSON(message.state);
    }
    if (message.profileLastGenerated !== undefined) {
      obj.profileLastGenerated = message.profileLastGenerated.toISOString();
    }
    if (message.resourceVisibility !== 0) {
      obj.resourceVisibility = resourceVisibilityToJSON(message.resourceVisibility);
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    if (message.dataRiskLevel !== undefined) {
      obj.dataRiskLevel = DataRiskLevel.toJSON(message.dataRiskLevel);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.lastModifiedTime !== undefined) {
      obj.lastModifiedTime = message.lastModifiedTime.toISOString();
    }
    if (message.fileClusterSummaries?.length) {
      obj.fileClusterSummaries = message.fileClusterSummaries.map((e) => FileClusterSummary.toJSON(e));
    }
    if (message.resourceAttributes) {
      const entries = Object.entries(message.resourceAttributes);
      if (entries.length > 0) {
        obj.resourceAttributes = {};
        entries.forEach(([k, v]) => {
          obj.resourceAttributes[k] = Value.toJSON(v);
        });
      }
    }
    if (message.resourceLabels) {
      const entries = Object.entries(message.resourceLabels);
      if (entries.length > 0) {
        obj.resourceLabels = {};
        entries.forEach(([k, v]) => {
          obj.resourceLabels[k] = v;
        });
      }
    }
    if (message.fileStoreInfoTypeSummaries?.length) {
      obj.fileStoreInfoTypeSummaries = message.fileStoreInfoTypeSummaries.map((e) =>
        FileStoreInfoTypeSummary.toJSON(e)
      );
    }
    if (message.fileStoreIsEmpty !== false) {
      obj.fileStoreIsEmpty = message.fileStoreIsEmpty;
    }
    return obj;
  },

  create(base?: DeepPartial<FileStoreDataProfile>): FileStoreDataProfile {
    return FileStoreDataProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStoreDataProfile>): FileStoreDataProfile {
    const message = createBaseFileStoreDataProfile();
    message.name = object.name ?? "";
    message.dataSourceType = (object.dataSourceType !== undefined && object.dataSourceType !== null)
      ? DataSourceType.fromPartial(object.dataSourceType)
      : undefined;
    message.projectDataProfile = object.projectDataProfile ?? "";
    message.projectId = object.projectId ?? "";
    message.fileStoreLocation = object.fileStoreLocation ?? "";
    message.dataStorageLocations = object.dataStorageLocations?.map((e) => e) || [];
    message.locationType = object.locationType ?? "";
    message.fileStorePath = object.fileStorePath ?? "";
    message.fullResource = object.fullResource ?? "";
    message.configSnapshot = (object.configSnapshot !== undefined && object.configSnapshot !== null)
      ? DataProfileConfigSnapshot.fromPartial(object.configSnapshot)
      : undefined;
    message.profileStatus = (object.profileStatus !== undefined && object.profileStatus !== null)
      ? ProfileStatus.fromPartial(object.profileStatus)
      : undefined;
    message.state = object.state ?? 0;
    message.profileLastGenerated = object.profileLastGenerated ?? undefined;
    message.resourceVisibility = object.resourceVisibility ?? 0;
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    message.dataRiskLevel = (object.dataRiskLevel !== undefined && object.dataRiskLevel !== null)
      ? DataRiskLevel.fromPartial(object.dataRiskLevel)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.lastModifiedTime = object.lastModifiedTime ?? undefined;
    message.fileClusterSummaries = object.fileClusterSummaries?.map((e) => FileClusterSummary.fromPartial(e)) || [];
    message.resourceAttributes = Object.entries(object.resourceAttributes ?? {}).reduce<{ [key: string]: Value }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = Value.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    message.resourceLabels = Object.entries(object.resourceLabels ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.fileStoreInfoTypeSummaries =
      object.fileStoreInfoTypeSummaries?.map((e) => FileStoreInfoTypeSummary.fromPartial(e)) || [];
    message.fileStoreIsEmpty = object.fileStoreIsEmpty ?? false;
    return message;
  },
};

function createBaseFileStoreDataProfile_ResourceAttributesEntry(): FileStoreDataProfile_ResourceAttributesEntry {
  return { key: "", value: undefined };
}

export const FileStoreDataProfile_ResourceAttributesEntry: MessageFns<FileStoreDataProfile_ResourceAttributesEntry> = {
  encode(
    message: FileStoreDataProfile_ResourceAttributesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreDataProfile_ResourceAttributesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreDataProfile_ResourceAttributesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreDataProfile_ResourceAttributesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: FileStoreDataProfile_ResourceAttributesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    return obj;
  },

  create(
    base?: DeepPartial<FileStoreDataProfile_ResourceAttributesEntry>,
  ): FileStoreDataProfile_ResourceAttributesEntry {
    return FileStoreDataProfile_ResourceAttributesEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<FileStoreDataProfile_ResourceAttributesEntry>,
  ): FileStoreDataProfile_ResourceAttributesEntry {
    const message = createBaseFileStoreDataProfile_ResourceAttributesEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    return message;
  },
};

function createBaseFileStoreDataProfile_ResourceLabelsEntry(): FileStoreDataProfile_ResourceLabelsEntry {
  return { key: "", value: "" };
}

export const FileStoreDataProfile_ResourceLabelsEntry: MessageFns<FileStoreDataProfile_ResourceLabelsEntry> = {
  encode(message: FileStoreDataProfile_ResourceLabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreDataProfile_ResourceLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreDataProfile_ResourceLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreDataProfile_ResourceLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: FileStoreDataProfile_ResourceLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<FileStoreDataProfile_ResourceLabelsEntry>): FileStoreDataProfile_ResourceLabelsEntry {
    return FileStoreDataProfile_ResourceLabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStoreDataProfile_ResourceLabelsEntry>): FileStoreDataProfile_ResourceLabelsEntry {
    const message = createBaseFileStoreDataProfile_ResourceLabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseFileStoreInfoTypeSummary(): FileStoreInfoTypeSummary {
  return { infoType: undefined };
}

export const FileStoreInfoTypeSummary: MessageFns<FileStoreInfoTypeSummary> = {
  encode(message: FileStoreInfoTypeSummary, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.infoType !== undefined) {
      InfoType.encode(message.infoType, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileStoreInfoTypeSummary {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileStoreInfoTypeSummary();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.infoType = InfoType.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileStoreInfoTypeSummary {
    return { infoType: isSet(object.infoType) ? InfoType.fromJSON(object.infoType) : undefined };
  },

  toJSON(message: FileStoreInfoTypeSummary): unknown {
    const obj: any = {};
    if (message.infoType !== undefined) {
      obj.infoType = InfoType.toJSON(message.infoType);
    }
    return obj;
  },

  create(base?: DeepPartial<FileStoreInfoTypeSummary>): FileStoreInfoTypeSummary {
    return FileStoreInfoTypeSummary.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileStoreInfoTypeSummary>): FileStoreInfoTypeSummary {
    const message = createBaseFileStoreInfoTypeSummary();
    message.infoType = (object.infoType !== undefined && object.infoType !== null)
      ? InfoType.fromPartial(object.infoType)
      : undefined;
    return message;
  },
};

function createBaseFileExtensionInfo(): FileExtensionInfo {
  return { fileExtension: "" };
}

export const FileExtensionInfo: MessageFns<FileExtensionInfo> = {
  encode(message: FileExtensionInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fileExtension !== "") {
      writer.uint32(10).string(message.fileExtension);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileExtensionInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileExtensionInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fileExtension = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileExtensionInfo {
    return { fileExtension: isSet(object.fileExtension) ? globalThis.String(object.fileExtension) : "" };
  },

  toJSON(message: FileExtensionInfo): unknown {
    const obj: any = {};
    if (message.fileExtension !== "") {
      obj.fileExtension = message.fileExtension;
    }
    return obj;
  },

  create(base?: DeepPartial<FileExtensionInfo>): FileExtensionInfo {
    return FileExtensionInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileExtensionInfo>): FileExtensionInfo {
    const message = createBaseFileExtensionInfo();
    message.fileExtension = object.fileExtension ?? "";
    return message;
  },
};

function createBaseFileClusterSummary(): FileClusterSummary {
  return {
    fileClusterType: undefined,
    fileStoreInfoTypeSummaries: [],
    sensitivityScore: undefined,
    dataRiskLevel: undefined,
    errors: [],
    fileExtensionsScanned: [],
    fileExtensionsSeen: [],
    noFilesExist: false,
  };
}

export const FileClusterSummary: MessageFns<FileClusterSummary> = {
  encode(message: FileClusterSummary, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fileClusterType !== undefined) {
      FileClusterType.encode(message.fileClusterType, writer.uint32(10).fork()).join();
    }
    for (const v of message.fileStoreInfoTypeSummaries) {
      FileStoreInfoTypeSummary.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.sensitivityScore !== undefined) {
      SensitivityScore.encode(message.sensitivityScore, writer.uint32(26).fork()).join();
    }
    if (message.dataRiskLevel !== undefined) {
      DataRiskLevel.encode(message.dataRiskLevel, writer.uint32(34).fork()).join();
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(50).fork()).join();
    }
    for (const v of message.fileExtensionsScanned) {
      FileExtensionInfo.encode(v!, writer.uint32(58).fork()).join();
    }
    for (const v of message.fileExtensionsSeen) {
      FileExtensionInfo.encode(v!, writer.uint32(66).fork()).join();
    }
    if (message.noFilesExist !== false) {
      writer.uint32(72).bool(message.noFilesExist);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileClusterSummary {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileClusterSummary();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fileClusterType = FileClusterType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fileStoreInfoTypeSummaries.push(FileStoreInfoTypeSummary.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sensitivityScore = SensitivityScore.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.dataRiskLevel = DataRiskLevel.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.fileExtensionsScanned.push(FileExtensionInfo.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.fileExtensionsSeen.push(FileExtensionInfo.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.noFilesExist = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileClusterSummary {
    return {
      fileClusterType: isSet(object.fileClusterType) ? FileClusterType.fromJSON(object.fileClusterType) : undefined,
      fileStoreInfoTypeSummaries: globalThis.Array.isArray(object?.fileStoreInfoTypeSummaries)
        ? object.fileStoreInfoTypeSummaries.map((e: any) => FileStoreInfoTypeSummary.fromJSON(e))
        : [],
      sensitivityScore: isSet(object.sensitivityScore) ? SensitivityScore.fromJSON(object.sensitivityScore) : undefined,
      dataRiskLevel: isSet(object.dataRiskLevel) ? DataRiskLevel.fromJSON(object.dataRiskLevel) : undefined,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      fileExtensionsScanned: globalThis.Array.isArray(object?.fileExtensionsScanned)
        ? object.fileExtensionsScanned.map((e: any) => FileExtensionInfo.fromJSON(e))
        : [],
      fileExtensionsSeen: globalThis.Array.isArray(object?.fileExtensionsSeen)
        ? object.fileExtensionsSeen.map((e: any) => FileExtensionInfo.fromJSON(e))
        : [],
      noFilesExist: isSet(object.noFilesExist) ? globalThis.Boolean(object.noFilesExist) : false,
    };
  },

  toJSON(message: FileClusterSummary): unknown {
    const obj: any = {};
    if (message.fileClusterType !== undefined) {
      obj.fileClusterType = FileClusterType.toJSON(message.fileClusterType);
    }
    if (message.fileStoreInfoTypeSummaries?.length) {
      obj.fileStoreInfoTypeSummaries = message.fileStoreInfoTypeSummaries.map((e) =>
        FileStoreInfoTypeSummary.toJSON(e)
      );
    }
    if (message.sensitivityScore !== undefined) {
      obj.sensitivityScore = SensitivityScore.toJSON(message.sensitivityScore);
    }
    if (message.dataRiskLevel !== undefined) {
      obj.dataRiskLevel = DataRiskLevel.toJSON(message.dataRiskLevel);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.fileExtensionsScanned?.length) {
      obj.fileExtensionsScanned = message.fileExtensionsScanned.map((e) => FileExtensionInfo.toJSON(e));
    }
    if (message.fileExtensionsSeen?.length) {
      obj.fileExtensionsSeen = message.fileExtensionsSeen.map((e) => FileExtensionInfo.toJSON(e));
    }
    if (message.noFilesExist !== false) {
      obj.noFilesExist = message.noFilesExist;
    }
    return obj;
  },

  create(base?: DeepPartial<FileClusterSummary>): FileClusterSummary {
    return FileClusterSummary.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileClusterSummary>): FileClusterSummary {
    const message = createBaseFileClusterSummary();
    message.fileClusterType = (object.fileClusterType !== undefined && object.fileClusterType !== null)
      ? FileClusterType.fromPartial(object.fileClusterType)
      : undefined;
    message.fileStoreInfoTypeSummaries =
      object.fileStoreInfoTypeSummaries?.map((e) => FileStoreInfoTypeSummary.fromPartial(e)) || [];
    message.sensitivityScore = (object.sensitivityScore !== undefined && object.sensitivityScore !== null)
      ? SensitivityScore.fromPartial(object.sensitivityScore)
      : undefined;
    message.dataRiskLevel = (object.dataRiskLevel !== undefined && object.dataRiskLevel !== null)
      ? DataRiskLevel.fromPartial(object.dataRiskLevel)
      : undefined;
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.fileExtensionsScanned = object.fileExtensionsScanned?.map((e) => FileExtensionInfo.fromPartial(e)) || [];
    message.fileExtensionsSeen = object.fileExtensionsSeen?.map((e) => FileExtensionInfo.fromPartial(e)) || [];
    message.noFilesExist = object.noFilesExist ?? false;
    return message;
  },
};

function createBaseGetProjectDataProfileRequest(): GetProjectDataProfileRequest {
  return { name: "" };
}

export const GetProjectDataProfileRequest: MessageFns<GetProjectDataProfileRequest> = {
  encode(message: GetProjectDataProfileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetProjectDataProfileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetProjectDataProfileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetProjectDataProfileRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetProjectDataProfileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetProjectDataProfileRequest>): GetProjectDataProfileRequest {
    return GetProjectDataProfileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetProjectDataProfileRequest>): GetProjectDataProfileRequest {
    const message = createBaseGetProjectDataProfileRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGetFileStoreDataProfileRequest(): GetFileStoreDataProfileRequest {
  return { name: "" };
}

export const GetFileStoreDataProfileRequest: MessageFns<GetFileStoreDataProfileRequest> = {
  encode(message: GetFileStoreDataProfileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFileStoreDataProfileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFileStoreDataProfileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFileStoreDataProfileRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetFileStoreDataProfileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetFileStoreDataProfileRequest>): GetFileStoreDataProfileRequest {
    return GetFileStoreDataProfileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFileStoreDataProfileRequest>): GetFileStoreDataProfileRequest {
    const message = createBaseGetFileStoreDataProfileRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListFileStoreDataProfilesRequest(): ListFileStoreDataProfilesRequest {
  return { parent: "", pageToken: "", pageSize: 0, orderBy: "", filter: "" };
}

export const ListFileStoreDataProfilesRequest: MessageFns<ListFileStoreDataProfilesRequest> = {
  encode(message: ListFileStoreDataProfilesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFileStoreDataProfilesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFileStoreDataProfilesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFileStoreDataProfilesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListFileStoreDataProfilesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFileStoreDataProfilesRequest>): ListFileStoreDataProfilesRequest {
    return ListFileStoreDataProfilesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFileStoreDataProfilesRequest>): ListFileStoreDataProfilesRequest {
    const message = createBaseListFileStoreDataProfilesRequest();
    message.parent = object.parent ?? "";
    message.pageToken = object.pageToken ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListFileStoreDataProfilesResponse(): ListFileStoreDataProfilesResponse {
  return { fileStoreDataProfiles: [], nextPageToken: "" };
}

export const ListFileStoreDataProfilesResponse: MessageFns<ListFileStoreDataProfilesResponse> = {
  encode(message: ListFileStoreDataProfilesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fileStoreDataProfiles) {
      FileStoreDataProfile.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFileStoreDataProfilesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFileStoreDataProfilesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fileStoreDataProfiles.push(FileStoreDataProfile.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFileStoreDataProfilesResponse {
    return {
      fileStoreDataProfiles: globalThis.Array.isArray(object?.fileStoreDataProfiles)
        ? object.fileStoreDataProfiles.map((e: any) => FileStoreDataProfile.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListFileStoreDataProfilesResponse): unknown {
    const obj: any = {};
    if (message.fileStoreDataProfiles?.length) {
      obj.fileStoreDataProfiles = message.fileStoreDataProfiles.map((e) => FileStoreDataProfile.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFileStoreDataProfilesResponse>): ListFileStoreDataProfilesResponse {
    return ListFileStoreDataProfilesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFileStoreDataProfilesResponse>): ListFileStoreDataProfilesResponse {
    const message = createBaseListFileStoreDataProfilesResponse();
    message.fileStoreDataProfiles = object.fileStoreDataProfiles?.map((e) => FileStoreDataProfile.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteFileStoreDataProfileRequest(): DeleteFileStoreDataProfileRequest {
  return { name: "" };
}

export const DeleteFileStoreDataProfileRequest: MessageFns<DeleteFileStoreDataProfileRequest> = {
  encode(message: DeleteFileStoreDataProfileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFileStoreDataProfileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFileStoreDataProfileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFileStoreDataProfileRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteFileStoreDataProfileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFileStoreDataProfileRequest>): DeleteFileStoreDataProfileRequest {
    return DeleteFileStoreDataProfileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFileStoreDataProfileRequest>): DeleteFileStoreDataProfileRequest {
    const message = createBaseDeleteFileStoreDataProfileRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGetTableDataProfileRequest(): GetTableDataProfileRequest {
  return { name: "" };
}

export const GetTableDataProfileRequest: MessageFns<GetTableDataProfileRequest> = {
  encode(message: GetTableDataProfileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTableDataProfileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTableDataProfileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetTableDataProfileRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetTableDataProfileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetTableDataProfileRequest>): GetTableDataProfileRequest {
    return GetTableDataProfileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetTableDataProfileRequest>): GetTableDataProfileRequest {
    const message = createBaseGetTableDataProfileRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGetColumnDataProfileRequest(): GetColumnDataProfileRequest {
  return { name: "" };
}

export const GetColumnDataProfileRequest: MessageFns<GetColumnDataProfileRequest> = {
  encode(message: GetColumnDataProfileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetColumnDataProfileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetColumnDataProfileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetColumnDataProfileRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetColumnDataProfileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetColumnDataProfileRequest>): GetColumnDataProfileRequest {
    return GetColumnDataProfileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetColumnDataProfileRequest>): GetColumnDataProfileRequest {
    const message = createBaseGetColumnDataProfileRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDataProfilePubSubCondition(): DataProfilePubSubCondition {
  return { expressions: undefined };
}

export const DataProfilePubSubCondition: MessageFns<DataProfilePubSubCondition> = {
  encode(message: DataProfilePubSubCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.expressions !== undefined) {
      DataProfilePubSubCondition_PubSubExpressions.encode(message.expressions, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfilePubSubCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfilePubSubCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.expressions = DataProfilePubSubCondition_PubSubExpressions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfilePubSubCondition {
    return {
      expressions: isSet(object.expressions)
        ? DataProfilePubSubCondition_PubSubExpressions.fromJSON(object.expressions)
        : undefined,
    };
  },

  toJSON(message: DataProfilePubSubCondition): unknown {
    const obj: any = {};
    if (message.expressions !== undefined) {
      obj.expressions = DataProfilePubSubCondition_PubSubExpressions.toJSON(message.expressions);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfilePubSubCondition>): DataProfilePubSubCondition {
    return DataProfilePubSubCondition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfilePubSubCondition>): DataProfilePubSubCondition {
    const message = createBaseDataProfilePubSubCondition();
    message.expressions = (object.expressions !== undefined && object.expressions !== null)
      ? DataProfilePubSubCondition_PubSubExpressions.fromPartial(object.expressions)
      : undefined;
    return message;
  },
};

function createBaseDataProfilePubSubCondition_PubSubCondition(): DataProfilePubSubCondition_PubSubCondition {
  return { minimumRiskScore: undefined, minimumSensitivityScore: undefined };
}

export const DataProfilePubSubCondition_PubSubCondition: MessageFns<DataProfilePubSubCondition_PubSubCondition> = {
  encode(message: DataProfilePubSubCondition_PubSubCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minimumRiskScore !== undefined) {
      writer.uint32(8).int32(message.minimumRiskScore);
    }
    if (message.minimumSensitivityScore !== undefined) {
      writer.uint32(16).int32(message.minimumSensitivityScore);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfilePubSubCondition_PubSubCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfilePubSubCondition_PubSubCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.minimumRiskScore = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.minimumSensitivityScore = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfilePubSubCondition_PubSubCondition {
    return {
      minimumRiskScore: isSet(object.minimumRiskScore)
        ? dataProfilePubSubCondition_ProfileScoreBucketFromJSON(object.minimumRiskScore)
        : undefined,
      minimumSensitivityScore: isSet(object.minimumSensitivityScore)
        ? dataProfilePubSubCondition_ProfileScoreBucketFromJSON(object.minimumSensitivityScore)
        : undefined,
    };
  },

  toJSON(message: DataProfilePubSubCondition_PubSubCondition): unknown {
    const obj: any = {};
    if (message.minimumRiskScore !== undefined) {
      obj.minimumRiskScore = dataProfilePubSubCondition_ProfileScoreBucketToJSON(message.minimumRiskScore);
    }
    if (message.minimumSensitivityScore !== undefined) {
      obj.minimumSensitivityScore = dataProfilePubSubCondition_ProfileScoreBucketToJSON(
        message.minimumSensitivityScore,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfilePubSubCondition_PubSubCondition>): DataProfilePubSubCondition_PubSubCondition {
    return DataProfilePubSubCondition_PubSubCondition.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataProfilePubSubCondition_PubSubCondition>,
  ): DataProfilePubSubCondition_PubSubCondition {
    const message = createBaseDataProfilePubSubCondition_PubSubCondition();
    message.minimumRiskScore = object.minimumRiskScore ?? undefined;
    message.minimumSensitivityScore = object.minimumSensitivityScore ?? undefined;
    return message;
  },
};

function createBaseDataProfilePubSubCondition_PubSubExpressions(): DataProfilePubSubCondition_PubSubExpressions {
  return { logicalOperator: 0, conditions: [] };
}

export const DataProfilePubSubCondition_PubSubExpressions: MessageFns<DataProfilePubSubCondition_PubSubExpressions> = {
  encode(
    message: DataProfilePubSubCondition_PubSubExpressions,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.logicalOperator !== 0) {
      writer.uint32(8).int32(message.logicalOperator);
    }
    for (const v of message.conditions) {
      DataProfilePubSubCondition_PubSubCondition.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfilePubSubCondition_PubSubExpressions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfilePubSubCondition_PubSubExpressions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.logicalOperator = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.conditions.push(DataProfilePubSubCondition_PubSubCondition.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfilePubSubCondition_PubSubExpressions {
    return {
      logicalOperator: isSet(object.logicalOperator)
        ? dataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperatorFromJSON(object.logicalOperator)
        : 0,
      conditions: globalThis.Array.isArray(object?.conditions)
        ? object.conditions.map((e: any) => DataProfilePubSubCondition_PubSubCondition.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DataProfilePubSubCondition_PubSubExpressions): unknown {
    const obj: any = {};
    if (message.logicalOperator !== 0) {
      obj.logicalOperator = dataProfilePubSubCondition_PubSubExpressions_PubSubLogicalOperatorToJSON(
        message.logicalOperator,
      );
    }
    if (message.conditions?.length) {
      obj.conditions = message.conditions.map((e) => DataProfilePubSubCondition_PubSubCondition.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<DataProfilePubSubCondition_PubSubExpressions>,
  ): DataProfilePubSubCondition_PubSubExpressions {
    return DataProfilePubSubCondition_PubSubExpressions.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DataProfilePubSubCondition_PubSubExpressions>,
  ): DataProfilePubSubCondition_PubSubExpressions {
    const message = createBaseDataProfilePubSubCondition_PubSubExpressions();
    message.logicalOperator = object.logicalOperator ?? 0;
    message.conditions = object.conditions?.map((e) => DataProfilePubSubCondition_PubSubCondition.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDataProfilePubSubMessage(): DataProfilePubSubMessage {
  return { profile: undefined, fileStoreProfile: undefined, event: 0 };
}

export const DataProfilePubSubMessage: MessageFns<DataProfilePubSubMessage> = {
  encode(message: DataProfilePubSubMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.profile !== undefined) {
      TableDataProfile.encode(message.profile, writer.uint32(10).fork()).join();
    }
    if (message.fileStoreProfile !== undefined) {
      FileStoreDataProfile.encode(message.fileStoreProfile, writer.uint32(26).fork()).join();
    }
    if (message.event !== 0) {
      writer.uint32(16).int32(message.event);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfilePubSubMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfilePubSubMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.profile = TableDataProfile.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.fileStoreProfile = FileStoreDataProfile.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.event = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfilePubSubMessage {
    return {
      profile: isSet(object.profile) ? TableDataProfile.fromJSON(object.profile) : undefined,
      fileStoreProfile: isSet(object.fileStoreProfile)
        ? FileStoreDataProfile.fromJSON(object.fileStoreProfile)
        : undefined,
      event: isSet(object.event) ? dataProfileAction_EventTypeFromJSON(object.event) : 0,
    };
  },

  toJSON(message: DataProfilePubSubMessage): unknown {
    const obj: any = {};
    if (message.profile !== undefined) {
      obj.profile = TableDataProfile.toJSON(message.profile);
    }
    if (message.fileStoreProfile !== undefined) {
      obj.fileStoreProfile = FileStoreDataProfile.toJSON(message.fileStoreProfile);
    }
    if (message.event !== 0) {
      obj.event = dataProfileAction_EventTypeToJSON(message.event);
    }
    return obj;
  },

  create(base?: DeepPartial<DataProfilePubSubMessage>): DataProfilePubSubMessage {
    return DataProfilePubSubMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataProfilePubSubMessage>): DataProfilePubSubMessage {
    const message = createBaseDataProfilePubSubMessage();
    message.profile = (object.profile !== undefined && object.profile !== null)
      ? TableDataProfile.fromPartial(object.profile)
      : undefined;
    message.fileStoreProfile = (object.fileStoreProfile !== undefined && object.fileStoreProfile !== null)
      ? FileStoreDataProfile.fromPartial(object.fileStoreProfile)
      : undefined;
    message.event = object.event ?? 0;
    return message;
  },
};

function createBaseCreateConnectionRequest(): CreateConnectionRequest {
  return { parent: "", connection: undefined };
}

export const CreateConnectionRequest: MessageFns<CreateConnectionRequest> = {
  encode(message: CreateConnectionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.connection !== undefined) {
      Connection.encode(message.connection, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConnectionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConnectionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.connection = Connection.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConnectionRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      connection: isSet(object.connection) ? Connection.fromJSON(object.connection) : undefined,
    };
  },

  toJSON(message: CreateConnectionRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.connection !== undefined) {
      obj.connection = Connection.toJSON(message.connection);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateConnectionRequest>): CreateConnectionRequest {
    return CreateConnectionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateConnectionRequest>): CreateConnectionRequest {
    const message = createBaseCreateConnectionRequest();
    message.parent = object.parent ?? "";
    message.connection = (object.connection !== undefined && object.connection !== null)
      ? Connection.fromPartial(object.connection)
      : undefined;
    return message;
  },
};

function createBaseGetConnectionRequest(): GetConnectionRequest {
  return { name: "" };
}

export const GetConnectionRequest: MessageFns<GetConnectionRequest> = {
  encode(message: GetConnectionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetConnectionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetConnectionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetConnectionRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetConnectionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetConnectionRequest>): GetConnectionRequest {
    return GetConnectionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetConnectionRequest>): GetConnectionRequest {
    const message = createBaseGetConnectionRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListConnectionsRequest(): ListConnectionsRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "" };
}

export const ListConnectionsRequest: MessageFns<ListConnectionsRequest> = {
  encode(message: ListConnectionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConnectionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConnectionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConnectionsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListConnectionsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConnectionsRequest>): ListConnectionsRequest {
    return ListConnectionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConnectionsRequest>): ListConnectionsRequest {
    const message = createBaseListConnectionsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseSearchConnectionsRequest(): SearchConnectionsRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "" };
}

export const SearchConnectionsRequest: MessageFns<SearchConnectionsRequest> = {
  encode(message: SearchConnectionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchConnectionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchConnectionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchConnectionsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: SearchConnectionsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchConnectionsRequest>): SearchConnectionsRequest {
    return SearchConnectionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchConnectionsRequest>): SearchConnectionsRequest {
    const message = createBaseSearchConnectionsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListConnectionsResponse(): ListConnectionsResponse {
  return { connections: [], nextPageToken: "" };
}

export const ListConnectionsResponse: MessageFns<ListConnectionsResponse> = {
  encode(message: ListConnectionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.connections) {
      Connection.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConnectionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConnectionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.connections.push(Connection.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConnectionsResponse {
    return {
      connections: globalThis.Array.isArray(object?.connections)
        ? object.connections.map((e: any) => Connection.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListConnectionsResponse): unknown {
    const obj: any = {};
    if (message.connections?.length) {
      obj.connections = message.connections.map((e) => Connection.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConnectionsResponse>): ListConnectionsResponse {
    return ListConnectionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConnectionsResponse>): ListConnectionsResponse {
    const message = createBaseListConnectionsResponse();
    message.connections = object.connections?.map((e) => Connection.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseSearchConnectionsResponse(): SearchConnectionsResponse {
  return { connections: [], nextPageToken: "" };
}

export const SearchConnectionsResponse: MessageFns<SearchConnectionsResponse> = {
  encode(message: SearchConnectionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.connections) {
      Connection.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchConnectionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchConnectionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.connections.push(Connection.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchConnectionsResponse {
    return {
      connections: globalThis.Array.isArray(object?.connections)
        ? object.connections.map((e: any) => Connection.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: SearchConnectionsResponse): unknown {
    const obj: any = {};
    if (message.connections?.length) {
      obj.connections = message.connections.map((e) => Connection.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchConnectionsResponse>): SearchConnectionsResponse {
    return SearchConnectionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchConnectionsResponse>): SearchConnectionsResponse {
    const message = createBaseSearchConnectionsResponse();
    message.connections = object.connections?.map((e) => Connection.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateConnectionRequest(): UpdateConnectionRequest {
  return { name: "", connection: undefined, updateMask: undefined };
}

export const UpdateConnectionRequest: MessageFns<UpdateConnectionRequest> = {
  encode(message: UpdateConnectionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.connection !== undefined) {
      Connection.encode(message.connection, writer.uint32(18).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateConnectionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateConnectionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.connection = Connection.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateConnectionRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      connection: isSet(object.connection) ? Connection.fromJSON(object.connection) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateConnectionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.connection !== undefined) {
      obj.connection = Connection.toJSON(message.connection);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateConnectionRequest>): UpdateConnectionRequest {
    return UpdateConnectionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateConnectionRequest>): UpdateConnectionRequest {
    const message = createBaseUpdateConnectionRequest();
    message.name = object.name ?? "";
    message.connection = (object.connection !== undefined && object.connection !== null)
      ? Connection.fromPartial(object.connection)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteConnectionRequest(): DeleteConnectionRequest {
  return { name: "" };
}

export const DeleteConnectionRequest: MessageFns<DeleteConnectionRequest> = {
  encode(message: DeleteConnectionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteConnectionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteConnectionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteConnectionRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteConnectionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteConnectionRequest>): DeleteConnectionRequest {
    return DeleteConnectionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteConnectionRequest>): DeleteConnectionRequest {
    const message = createBaseDeleteConnectionRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseConnection(): Connection {
  return { name: "", state: 0, errors: [], cloudSql: undefined };
}

export const Connection: MessageFns<Connection> = {
  encode(message: Connection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.cloudSql !== undefined) {
      CloudSqlProperties.encode(message.cloudSql, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Connection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cloudSql = CloudSqlProperties.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Connection {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      state: isSet(object.state) ? connectionStateFromJSON(object.state) : 0,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      cloudSql: isSet(object.cloudSql) ? CloudSqlProperties.fromJSON(object.cloudSql) : undefined,
    };
  },

  toJSON(message: Connection): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.state !== 0) {
      obj.state = connectionStateToJSON(message.state);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.cloudSql !== undefined) {
      obj.cloudSql = CloudSqlProperties.toJSON(message.cloudSql);
    }
    return obj;
  },

  create(base?: DeepPartial<Connection>): Connection {
    return Connection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Connection>): Connection {
    const message = createBaseConnection();
    message.name = object.name ?? "";
    message.state = object.state ?? 0;
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.cloudSql = (object.cloudSql !== undefined && object.cloudSql !== null)
      ? CloudSqlProperties.fromPartial(object.cloudSql)
      : undefined;
    return message;
  },
};

function createBaseSecretManagerCredential(): SecretManagerCredential {
  return { username: "", passwordSecretVersionName: "" };
}

export const SecretManagerCredential: MessageFns<SecretManagerCredential> = {
  encode(message: SecretManagerCredential, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.username !== "") {
      writer.uint32(10).string(message.username);
    }
    if (message.passwordSecretVersionName !== "") {
      writer.uint32(18).string(message.passwordSecretVersionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretManagerCredential {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretManagerCredential();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.username = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.passwordSecretVersionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretManagerCredential {
    return {
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      passwordSecretVersionName: isSet(object.passwordSecretVersionName)
        ? globalThis.String(object.passwordSecretVersionName)
        : "",
    };
  },

  toJSON(message: SecretManagerCredential): unknown {
    const obj: any = {};
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.passwordSecretVersionName !== "") {
      obj.passwordSecretVersionName = message.passwordSecretVersionName;
    }
    return obj;
  },

  create(base?: DeepPartial<SecretManagerCredential>): SecretManagerCredential {
    return SecretManagerCredential.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretManagerCredential>): SecretManagerCredential {
    const message = createBaseSecretManagerCredential();
    message.username = object.username ?? "";
    message.passwordSecretVersionName = object.passwordSecretVersionName ?? "";
    return message;
  },
};

function createBaseCloudSqlIamCredential(): CloudSqlIamCredential {
  return {};
}

export const CloudSqlIamCredential: MessageFns<CloudSqlIamCredential> = {
  encode(_: CloudSqlIamCredential, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlIamCredential {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlIamCredential();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CloudSqlIamCredential {
    return {};
  },

  toJSON(_: CloudSqlIamCredential): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<CloudSqlIamCredential>): CloudSqlIamCredential {
    return CloudSqlIamCredential.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<CloudSqlIamCredential>): CloudSqlIamCredential {
    const message = createBaseCloudSqlIamCredential();
    return message;
  },
};

function createBaseCloudSqlProperties(): CloudSqlProperties {
  return {
    connectionName: "",
    usernamePassword: undefined,
    cloudSqlIam: undefined,
    maxConnections: 0,
    databaseEngine: 0,
  };
}

export const CloudSqlProperties: MessageFns<CloudSqlProperties> = {
  encode(message: CloudSqlProperties, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.connectionName !== "") {
      writer.uint32(10).string(message.connectionName);
    }
    if (message.usernamePassword !== undefined) {
      SecretManagerCredential.encode(message.usernamePassword, writer.uint32(18).fork()).join();
    }
    if (message.cloudSqlIam !== undefined) {
      CloudSqlIamCredential.encode(message.cloudSqlIam, writer.uint32(26).fork()).join();
    }
    if (message.maxConnections !== 0) {
      writer.uint32(32).int32(message.maxConnections);
    }
    if (message.databaseEngine !== 0) {
      writer.uint32(56).int32(message.databaseEngine);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlProperties {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlProperties();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.connectionName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.usernamePassword = SecretManagerCredential.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cloudSqlIam = CloudSqlIamCredential.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.maxConnections = reader.int32();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.databaseEngine = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlProperties {
    return {
      connectionName: isSet(object.connectionName) ? globalThis.String(object.connectionName) : "",
      usernamePassword: isSet(object.usernamePassword)
        ? SecretManagerCredential.fromJSON(object.usernamePassword)
        : undefined,
      cloudSqlIam: isSet(object.cloudSqlIam) ? CloudSqlIamCredential.fromJSON(object.cloudSqlIam) : undefined,
      maxConnections: isSet(object.maxConnections) ? globalThis.Number(object.maxConnections) : 0,
      databaseEngine: isSet(object.databaseEngine)
        ? cloudSqlProperties_DatabaseEngineFromJSON(object.databaseEngine)
        : 0,
    };
  },

  toJSON(message: CloudSqlProperties): unknown {
    const obj: any = {};
    if (message.connectionName !== "") {
      obj.connectionName = message.connectionName;
    }
    if (message.usernamePassword !== undefined) {
      obj.usernamePassword = SecretManagerCredential.toJSON(message.usernamePassword);
    }
    if (message.cloudSqlIam !== undefined) {
      obj.cloudSqlIam = CloudSqlIamCredential.toJSON(message.cloudSqlIam);
    }
    if (message.maxConnections !== 0) {
      obj.maxConnections = Math.round(message.maxConnections);
    }
    if (message.databaseEngine !== 0) {
      obj.databaseEngine = cloudSqlProperties_DatabaseEngineToJSON(message.databaseEngine);
    }
    return obj;
  },

  create(base?: DeepPartial<CloudSqlProperties>): CloudSqlProperties {
    return CloudSqlProperties.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudSqlProperties>): CloudSqlProperties {
    const message = createBaseCloudSqlProperties();
    message.connectionName = object.connectionName ?? "";
    message.usernamePassword = (object.usernamePassword !== undefined && object.usernamePassword !== null)
      ? SecretManagerCredential.fromPartial(object.usernamePassword)
      : undefined;
    message.cloudSqlIam = (object.cloudSqlIam !== undefined && object.cloudSqlIam !== null)
      ? CloudSqlIamCredential.fromPartial(object.cloudSqlIam)
      : undefined;
    message.maxConnections = object.maxConnections ?? 0;
    message.databaseEngine = object.databaseEngine ?? 0;
    return message;
  },
};

function createBaseDeleteTableDataProfileRequest(): DeleteTableDataProfileRequest {
  return { name: "" };
}

export const DeleteTableDataProfileRequest: MessageFns<DeleteTableDataProfileRequest> = {
  encode(message: DeleteTableDataProfileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteTableDataProfileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteTableDataProfileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteTableDataProfileRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteTableDataProfileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteTableDataProfileRequest>): DeleteTableDataProfileRequest {
    return DeleteTableDataProfileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteTableDataProfileRequest>): DeleteTableDataProfileRequest {
    const message = createBaseDeleteTableDataProfileRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDataSourceType(): DataSourceType {
  return { dataSource: "" };
}

export const DataSourceType: MessageFns<DataSourceType> = {
  encode(message: DataSourceType, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataSource !== "") {
      writer.uint32(10).string(message.dataSource);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataSourceType {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataSourceType();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataSource = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataSourceType {
    return { dataSource: isSet(object.dataSource) ? globalThis.String(object.dataSource) : "" };
  },

  toJSON(message: DataSourceType): unknown {
    const obj: any = {};
    if (message.dataSource !== "") {
      obj.dataSource = message.dataSource;
    }
    return obj;
  },

  create(base?: DeepPartial<DataSourceType>): DataSourceType {
    return DataSourceType.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataSourceType>): DataSourceType {
    const message = createBaseDataSourceType();
    message.dataSource = object.dataSource ?? "";
    return message;
  },
};

function createBaseFileClusterType(): FileClusterType {
  return { cluster: undefined };
}

export const FileClusterType: MessageFns<FileClusterType> = {
  encode(message: FileClusterType, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cluster !== undefined) {
      writer.uint32(8).int32(message.cluster);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileClusterType {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileClusterType();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.cluster = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileClusterType {
    return { cluster: isSet(object.cluster) ? fileClusterType_ClusterFromJSON(object.cluster) : undefined };
  },

  toJSON(message: FileClusterType): unknown {
    const obj: any = {};
    if (message.cluster !== undefined) {
      obj.cluster = fileClusterType_ClusterToJSON(message.cluster);
    }
    return obj;
  },

  create(base?: DeepPartial<FileClusterType>): FileClusterType {
    return FileClusterType.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileClusterType>): FileClusterType {
    const message = createBaseFileClusterType();
    message.cluster = object.cluster ?? undefined;
    return message;
  },
};

/**
 * The Cloud Data Loss Prevention (DLP) API is a service that allows clients
 * to detect the presence of Personally Identifiable Information (PII) and other
 * privacy-sensitive data in user-supplied, unstructured data streams, like text
 * blocks or images.
 * The service also includes methods for sensitive data redaction and
 * scheduling of data scans on Google Cloud Platform based data sets.
 *
 * To learn more about concepts and find how-to guides see
 * https://cloud.google.com/sensitive-data-protection/docs/.
 */
export type DlpServiceDefinition = typeof DlpServiceDefinition;
export const DlpServiceDefinition = {
  name: "DlpService",
  fullName: "google.privacy.dlp.v2.DlpService",
  methods: {
    /**
     * Finds potentially sensitive info in content.
     * This method has limits on input size, processing time, and output size.
     *
     * When no InfoTypes or CustomInfoTypes are specified in this request, the
     * system will automatically choose what detectors to run. By default this may
     * be all types, but may change over time as detectors are updated.
     *
     * For how to guides, see
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-images
     * and
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-text,
     */
    inspectContent: {
      name: "InspectContent",
      requestType: InspectContentRequest,
      requestStream: false,
      responseType: InspectContentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              102,
              58,
              1,
              42,
              90,
              56,
              58,
              1,
              42,
              34,
              51,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
              58,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              34,
              39,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
              58,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Redacts potentially sensitive info from an image.
     * This method has limits on input size, processing time, and output size.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/redacting-sensitive-data-images
     * to learn more.
     *
     * When no InfoTypes or CustomInfoTypes are specified in this request, the
     * system will automatically choose what detectors to run. By default this may
     * be all types, but may change over time as detectors are updated.
     */
    redactImage: {
      name: "RedactImage",
      requestType: RedactImageRequest,
      requestStream: false,
      responseType: RedactImageResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              96,
              58,
              1,
              42,
              90,
              53,
              58,
              1,
              42,
              34,
              48,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              109,
              97,
              103,
              101,
              58,
              114,
              101,
              100,
              97,
              99,
              116,
              34,
              36,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              105,
              109,
              97,
              103,
              101,
              58,
              114,
              101,
              100,
              97,
              99,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * De-identifies potentially sensitive info from a ContentItem.
     * This method has limits on input size and output size.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/deidentify-sensitive-data
     * to learn more.
     *
     * When no InfoTypes or CustomInfoTypes are specified in this request, the
     * system will automatically choose what detectors to run. By default this may
     * be all types, but may change over time as detectors are updated.
     */
    deidentifyContent: {
      name: "DeidentifyContent",
      requestType: DeidentifyContentRequest,
      requestStream: false,
      responseType: DeidentifyContentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              108,
              58,
              1,
              42,
              90,
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
              58,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              34,
              42,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
              58,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Re-identifies content that has been de-identified.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/pseudonymization#re-identification_in_free_text_code_example
     * to learn more.
     */
    reidentifyContent: {
      name: "ReidentifyContent",
      requestType: ReidentifyContentRequest,
      requestStream: false,
      responseType: ReidentifyContentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              108,
              58,
              1,
              42,
              90,
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
              58,
              114,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              34,
              42,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              116,
              101,
              110,
              116,
              58,
              114,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Returns a list of the sensitive information types that DLP API
     * supports. See
     * https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference
     * to learn more.
     */
    listInfoTypes: {
      name: "ListInfoTypes",
      requestType: ListInfoTypesRequest,
      requestStream: false,
      responseType: ListInfoTypesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              53,
              90,
              36,
              18,
              34,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              18,
              13,
              47,
              118,
              50,
              47,
              105,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Creates an InspectTemplate for reusing frequently used configuration
     * for inspecting content, images, and storage.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
     * to learn more.
     */
    createInspectTemplate: {
      name: "CreateInspectTemplate",
      requestType: CreateInspectTemplateRequest,
      requestStream: false,
      responseType: InspectTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              95,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              220,
              1,
              58,
              1,
              42,
              90,
              62,
              58,
              1,
              42,
              34,
              57,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              45,
              58,
              1,
              42,
              34,
              40,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              50,
              58,
              1,
              42,
              34,
              45,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              34,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Updates the InspectTemplate.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
     * to learn more.
     */
    updateInspectTemplate: {
      name: "UpdateInspectTemplate",
      requestType: UpdateInspectTemplateRequest,
      requestStream: false,
      responseType: InspectTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              33,
              110,
              97,
              109,
              101,
              44,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              95,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              220,
              1,
              58,
              1,
              42,
              90,
              62,
              58,
              1,
              42,
              50,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              45,
              58,
              1,
              42,
              50,
              40,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              50,
              58,
              1,
              42,
              50,
              45,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              50,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Gets an InspectTemplate.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
     * to learn more.
     */
    getInspectTemplate: {
      name: "GetInspectTemplate",
      requestType: GetInspectTemplateRequest,
      requestStream: false,
      responseType: InspectTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              208,
              1,
              90,
              59,
              18,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              42,
              18,
              40,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              47,
              18,
              45,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists InspectTemplates.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
     * to learn more.
     */
    listInspectTemplates: {
      name: "ListInspectTemplates",
      requestType: ListInspectTemplatesRequest,
      requestStream: false,
      responseType: ListInspectTemplatesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              208,
              1,
              90,
              59,
              18,
              57,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              42,
              18,
              40,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              47,
              18,
              45,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes an InspectTemplate.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
     * to learn more.
     */
    deleteInspectTemplate: {
      name: "DeleteInspectTemplate",
      requestType: DeleteInspectTemplateRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              208,
              1,
              90,
              59,
              42,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              42,
              42,
              40,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              47,
              42,
              45,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              42,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              112,
              101,
              99,
              116,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a DeidentifyTemplate for reusing frequently used configuration
     * for de-identifying content, images, and storage.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
     * to learn more.
     */
    createDeidentifyTemplate: {
      name: "CreateDeidentifyTemplate",
      requestType: CreateDeidentifyTemplateRequest,
      requestStream: false,
      responseType: DeidentifyTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              26,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              95,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              232,
              1,
              58,
              1,
              42,
              90,
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              48,
              58,
              1,
              42,
              34,
              43,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              60,
              58,
              1,
              42,
              34,
              55,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              34,
              48,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Updates the DeidentifyTemplate.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
     * to learn more.
     */
    updateDeidentifyTemplate: {
      name: "UpdateDeidentifyTemplate",
      requestType: UpdateDeidentifyTemplateRequest,
      requestStream: false,
      responseType: DeidentifyTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              36,
              110,
              97,
              109,
              101,
              44,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              95,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              232,
              1,
              58,
              1,
              42,
              90,
              65,
              58,
              1,
              42,
              50,
              60,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              48,
              58,
              1,
              42,
              50,
              43,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              60,
              58,
              1,
              42,
              50,
              55,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              50,
              48,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Gets a DeidentifyTemplate.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
     * to learn more.
     */
    getDeidentifyTemplate: {
      name: "GetDeidentifyTemplate",
      requestType: GetDeidentifyTemplateRequest,
      requestStream: false,
      responseType: DeidentifyTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              220,
              1,
              90,
              62,
              18,
              60,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              45,
              18,
              43,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              57,
              18,
              55,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              18,
              48,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists DeidentifyTemplates.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
     * to learn more.
     */
    listDeidentifyTemplates: {
      name: "ListDeidentifyTemplates",
      requestType: ListDeidentifyTemplatesRequest,
      requestStream: false,
      responseType: ListDeidentifyTemplatesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              220,
              1,
              90,
              62,
              18,
              60,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              45,
              18,
              43,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              90,
              57,
              18,
              55,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              18,
              48,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a DeidentifyTemplate.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
     * to learn more.
     */
    deleteDeidentifyTemplate: {
      name: "DeleteDeidentifyTemplate",
      requestType: DeleteDeidentifyTemplateRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              220,
              1,
              90,
              62,
              42,
              60,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              45,
              42,
              43,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              90,
              57,
              42,
              55,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              42,
              48,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              101,
              105,
              100,
              101,
              110,
              116,
              105,
              102,
              121,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a job trigger to run DLP actions such as scanning storage for
     * sensitive information on a set schedule.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
     * to learn more.
     */
    createJobTrigger: {
      name: "CreateJobTrigger",
      requestType: CreateJobTriggerRequest,
      requestStream: false,
      responseType: JobTrigger,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 112, 97, 114, 101, 110, 116, 44, 106, 111, 98, 95, 116, 114, 105, 103, 103, 101, 114]),
          ],
          578365826: [
            Buffer.from([
              153,
              1,
              58,
              1,
              42,
              90,
              52,
              58,
              1,
              42,
              34,
              47,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              90,
              57,
              58,
              1,
              42,
              34,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              34,
              35,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Updates a job trigger.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
     * to learn more.
     */
    updateJobTrigger: {
      name: "UpdateJobTrigger",
      requestType: UpdateJobTriggerRequest,
      requestStream: false,
      responseType: JobTrigger,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              28,
              110,
              97,
              109,
              101,
              44,
              106,
              111,
              98,
              95,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              153,
              1,
              58,
              1,
              42,
              90,
              52,
              58,
              1,
              42,
              50,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              90,
              57,
              58,
              1,
              42,
              50,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              50,
              35,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Inspect hybrid content and store findings to a trigger. The inspection
     * will be processed asynchronously. To review the findings monitor the
     * jobs within the trigger.
     */
    hybridInspectJobTrigger: {
      name: "HybridInspectJobTrigger",
      requestType: HybridInspectJobTriggerRequest,
      requestStream: false,
      responseType: HybridInspectResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              104,
              121,
              98,
              114,
              105,
              100,
              73,
              110,
              115,
              112,
              101,
              99,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Gets a job trigger.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
     * to learn more.
     */
    getJobTrigger: {
      name: "GetJobTrigger",
      requestType: GetJobTriggerRequest,
      requestStream: false,
      responseType: JobTrigger,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              144,
              1,
              90,
              49,
              18,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              90,
              54,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              18,
              35,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists job triggers.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
     * to learn more.
     */
    listJobTriggers: {
      name: "ListJobTriggers",
      requestType: ListJobTriggersRequest,
      requestStream: false,
      responseType: ListJobTriggersResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              144,
              1,
              90,
              49,
              18,
              47,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              90,
              54,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              18,
              35,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a job trigger.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
     * to learn more.
     */
    deleteJobTrigger: {
      name: "DeleteJobTrigger",
      requestType: DeleteJobTriggerRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              144,
              1,
              90,
              49,
              42,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              90,
              54,
              42,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              42,
              35,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Activate a job trigger. Causes the immediate execute of a trigger
     * instead of waiting on the trigger event to occur.
     */
    activateJobTrigger: {
      name: "ActivateJobTrigger",
      requestType: ActivateJobTriggerRequest,
      requestStream: false,
      responseType: DlpJob,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              112,
              58,
              1,
              42,
              90,
              61,
              58,
              1,
              42,
              34,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              97,
              99,
              116,
              105,
              118,
              97,
              116,
              101,
              34,
              44,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              106,
              111,
              98,
              84,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              97,
              99,
              116,
              105,
              118,
              97,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /** Creates a config for discovery to scan and profile storage. */
    createDiscoveryConfig: {
      name: "CreateDiscoveryConfig",
      requestType: CreateDiscoveryConfigRequest,
      requestStream: false,
      responseType: DiscoveryConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
            ]),
          ],
          578365826: [
            Buffer.from([
              121,
              58,
              1,
              42,
              90,
              62,
              58,
              1,
              42,
              34,
              57,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              34,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a discovery configuration. */
    updateDiscoveryConfig: {
      name: "UpdateDiscoveryConfig",
      requestType: UpdateDiscoveryConfigRequest,
      requestStream: false,
      responseType: DiscoveryConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              33,
              110,
              97,
              109,
              101,
              44,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              121,
              58,
              1,
              42,
              90,
              62,
              58,
              1,
              42,
              50,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
              50,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets a discovery configuration. */
    getDiscoveryConfig: {
      name: "GetDiscoveryConfig",
      requestType: GetDiscoveryConfigRequest,
      requestStream: false,
      responseType: DiscoveryConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              115,
              90,
              59,
              18,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists discovery configurations. */
    listDiscoveryConfigs: {
      name: "ListDiscoveryConfigs",
      requestType: ListDiscoveryConfigsRequest,
      requestStream: false,
      responseType: ListDiscoveryConfigsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              115,
              90,
              59,
              18,
              57,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a discovery configuration. */
    deleteDiscoveryConfig: {
      name: "DeleteDiscoveryConfig",
      requestType: DeleteDiscoveryConfigRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              115,
              90,
              59,
              42,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
              42,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              105,
              115,
              99,
              111,
              118,
              101,
              114,
              121,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new job to inspect storage or calculate risk metrics.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
     * and
     * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
     * to learn more.
     *
     * When no InfoTypes or CustomInfoTypes are specified in inspect jobs, the
     * system will automatically choose what detectors to run. By default this may
     * be all types, but may change over time as detectors are updated.
     */
    createDlpJob: {
      name: "CreateDlpJob",
      requestType: CreateDlpJobRequest,
      requestStream: false,
      responseType: DlpJob,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 112, 97, 114, 101, 110, 116, 44, 105, 110, 115, 112, 101, 99, 116, 95, 106, 111, 98]),
            Buffer.from([15, 112, 97, 114, 101, 110, 116, 44, 114, 105, 115, 107, 95, 106, 111, 98]),
          ],
          578365826: [
            Buffer.from([
              86,
              58,
              1,
              42,
              90,
              48,
              58,
              1,
              42,
              34,
              43,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              34,
              31,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Lists DlpJobs that match the specified filter in the request.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
     * and
     * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
     * to learn more.
     */
    listDlpJobs: {
      name: "ListDlpJobs",
      requestType: ListDlpJobsRequest,
      requestStream: false,
      responseType: ListDlpJobsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              132,
              1,
              90,
              45,
              18,
              43,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              90,
              50,
              18,
              48,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              18,
              31,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the latest state of a long-running DlpJob.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
     * and
     * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
     * to learn more.
     */
    getDlpJob: {
      name: "GetDlpJob",
      requestType: GetDlpJobRequest,
      requestStream: false,
      responseType: DlpJob,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              80,
              90,
              45,
              18,
              43,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              18,
              31,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a long-running DlpJob. This method indicates that the client is
     * no longer interested in the DlpJob result. The job will be canceled if
     * possible.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
     * and
     * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
     * to learn more.
     */
    deleteDlpJob: {
      name: "DeleteDlpJob",
      requestType: DeleteDlpJobRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              80,
              90,
              45,
              42,
              43,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              42,
              31,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Starts asynchronous cancellation on a long-running DlpJob. The server
     * makes a best effort to cancel the DlpJob, but success is not
     * guaranteed.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
     * and
     * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
     * to learn more.
     */
    cancelDlpJob: {
      name: "CancelDlpJob",
      requestType: CancelDlpJobRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              100,
              58,
              1,
              42,
              90,
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
              34,
              38,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a pre-built stored infoType to be used for inspection.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
     * to learn more.
     */
    createStoredInfoType: {
      name: "CreateStoredInfoType",
      requestType: CreateStoredInfoTypeRequest,
      requestStream: false,
      responseType: StoredInfoType,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([13, 112, 97, 114, 101, 110, 116, 44, 99, 111, 110, 102, 105, 103])],
          578365826: [
            Buffer.from([
              216,
              1,
              58,
              1,
              42,
              90,
              61,
              58,
              1,
              42,
              34,
              56,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              90,
              44,
              58,
              1,
              42,
              34,
              39,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              90,
              56,
              58,
              1,
              42,
              34,
              51,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              34,
              44,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Updates the stored infoType by creating a new version. The existing version
     * will continue to be used until the new version is ready.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
     * to learn more.
     */
    updateStoredInfoType: {
      name: "UpdateStoredInfoType",
      requestType: UpdateStoredInfoTypeRequest,
      requestStream: false,
      responseType: StoredInfoType,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              110,
              97,
              109,
              101,
              44,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              216,
              1,
              58,
              1,
              42,
              90,
              61,
              58,
              1,
              42,
              50,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              90,
              44,
              58,
              1,
              42,
              50,
              39,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              90,
              56,
              58,
              1,
              42,
              50,
              51,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              50,
              44,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Gets a stored infoType.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
     * to learn more.
     */
    getStoredInfoType: {
      name: "GetStoredInfoType",
      requestType: GetStoredInfoTypeRequest,
      requestStream: false,
      responseType: StoredInfoType,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              204,
              1,
              90,
              58,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              90,
              41,
              18,
              39,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              90,
              53,
              18,
              51,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              18,
              44,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists stored infoTypes.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
     * to learn more.
     */
    listStoredInfoTypes: {
      name: "ListStoredInfoTypes",
      requestType: ListStoredInfoTypesRequest,
      requestStream: false,
      responseType: ListStoredInfoTypesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              204,
              1,
              90,
              58,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              90,
              41,
              18,
              39,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              90,
              53,
              18,
              51,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              18,
              44,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a stored infoType.
     * See
     * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
     * to learn more.
     */
    deleteStoredInfoType: {
      name: "DeleteStoredInfoType",
      requestType: DeleteStoredInfoTypeRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              204,
              1,
              90,
              58,
              42,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              90,
              41,
              42,
              39,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              90,
              53,
              42,
              51,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              42,
              44,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              116,
              111,
              114,
              101,
              100,
              73,
              110,
              102,
              111,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists project data profiles for an organization. */
    listProjectDataProfiles: {
      name: "ListProjectDataProfiles",
      requestType: ListProjectDataProfilesRequest,
      requestStream: false,
      responseType: ListProjectDataProfilesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              121,
              90,
              57,
              18,
              55,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              18,
              60,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists table data profiles for an organization. */
    listTableDataProfiles: {
      name: "ListTableDataProfiles",
      requestType: ListTableDataProfilesRequest,
      requestStream: false,
      responseType: ListTableDataProfilesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              117,
              90,
              55,
              18,
              53,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              116,
              97,
              98,
              108,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              18,
              58,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              116,
              97,
              98,
              108,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists column data profiles for an organization. */
    listColumnDataProfiles: {
      name: "ListColumnDataProfiles",
      requestType: ListColumnDataProfilesRequest,
      requestStream: false,
      responseType: ListColumnDataProfilesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              119,
              90,
              56,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              108,
              117,
              109,
              110,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              18,
              59,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              108,
              117,
              109,
              110,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets a project data profile. */
    getProjectDataProfile: {
      name: "GetProjectDataProfile",
      requestType: GetProjectDataProfileRequest,
      requestStream: false,
      responseType: ProjectDataProfile,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              121,
              90,
              57,
              18,
              55,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              60,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists file store data profiles for an organization. */
    listFileStoreDataProfiles: {
      name: "ListFileStoreDataProfiles",
      requestType: ListFileStoreDataProfilesRequest,
      requestStream: false,
      responseType: ListFileStoreDataProfilesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              125,
              90,
              59,
              18,
              57,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              105,
              108,
              101,
              83,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              18,
              62,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              105,
              108,
              101,
              83,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets a file store data profile. */
    getFileStoreDataProfile: {
      name: "GetFileStoreDataProfile",
      requestType: GetFileStoreDataProfileRequest,
      requestStream: false,
      responseType: FileStoreDataProfile,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              125,
              90,
              59,
              18,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              105,
              108,
              101,
              83,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              62,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              105,
              108,
              101,
              83,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Delete a FileStoreDataProfile. Will not prevent the profile from being
     * regenerated if the resource is still included in a discovery configuration.
     */
    deleteFileStoreDataProfile: {
      name: "DeleteFileStoreDataProfile",
      requestType: DeleteFileStoreDataProfileRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              125,
              90,
              59,
              42,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              105,
              108,
              101,
              83,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
              42,
              62,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              105,
              108,
              101,
              83,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets a table data profile. */
    getTableDataProfile: {
      name: "GetTableDataProfile",
      requestType: GetTableDataProfileRequest,
      requestStream: false,
      responseType: TableDataProfile,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              117,
              90,
              55,
              18,
              53,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              58,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets a column data profile. */
    getColumnDataProfile: {
      name: "GetColumnDataProfile",
      requestType: GetColumnDataProfileRequest,
      requestStream: false,
      responseType: ColumnDataProfile,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              119,
              90,
              56,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              117,
              109,
              110,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              59,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              117,
              109,
              110,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Delete a TableDataProfile. Will not prevent the profile from being
     * regenerated if the table is still included in a discovery configuration.
     */
    deleteTableDataProfile: {
      name: "DeleteTableDataProfile",
      requestType: DeleteTableDataProfileRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              117,
              90,
              55,
              42,
              53,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
              42,
              58,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              68,
              97,
              116,
              97,
              80,
              114,
              111,
              102,
              105,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Inspect hybrid content and store findings to a job.
     * To review the findings, inspect the job. Inspection will occur
     * asynchronously.
     */
    hybridInspectDlpJob: {
      name: "HybridInspectDlpJob",
      requestType: HybridInspectDlpJobRequest,
      requestStream: false,
      responseType: HybridInspectResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              62,
              58,
              1,
              42,
              34,
              57,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              58,
              104,
              121,
              98,
              114,
              105,
              100,
              73,
              110,
              115,
              112,
              101,
              99,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Finish a running hybrid DlpJob. Triggers the finalization steps and running
     * of any enabled actions that have not yet run.
     */
    finishDlpJob: {
      name: "FinishDlpJob",
      requestType: FinishDlpJobRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              100,
              108,
              112,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              58,
              102,
              105,
              110,
              105,
              115,
              104,
            ]),
          ],
        },
      },
    },
    /** Create a Connection to an external data source. */
    createConnection: {
      name: "CreateConnection",
      requestType: CreateConnectionRequest,
      requestStream: false,
      responseType: Connection,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 112, 97, 114, 101, 110, 116, 44, 32, 99, 111, 110, 110, 101, 99, 116, 105, 111, 110]),
          ],
          578365826: [
            Buffer.from([
              111,
              58,
              1,
              42,
              90,
              57,
              58,
              1,
              42,
              34,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              34,
              47,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Get a Connection by name. */
    getConnection: {
      name: "GetConnection",
      requestType: GetConnectionRequest,
      requestStream: false,
      responseType: Connection,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              105,
              90,
              54,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              18,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists Connections in a parent. Use SearchConnections to see all connections
     * within an organization.
     */
    listConnections: {
      name: "ListConnections",
      requestType: ListConnectionsRequest,
      requestStream: false,
      responseType: ListConnectionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              105,
              90,
              54,
              18,
              52,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              18,
              47,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Searches for Connections in a parent. */
    searchConnections: {
      name: "SearchConnections",
      requestType: SearchConnectionsRequest,
      requestStream: false,
      responseType: SearchConnectionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              119,
              90,
              61,
              18,
              59,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              58,
              115,
              101,
              97,
              114,
              99,
              104,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              58,
              115,
              101,
              97,
              114,
              99,
              104,
            ]),
          ],
        },
      },
    },
    /** Delete a Connection. */
    deleteConnection: {
      name: "DeleteConnection",
      requestType: DeleteConnectionRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              105,
              90,
              54,
              42,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              42,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Update a Connection. */
    updateConnection: {
      name: "UpdateConnection",
      requestType: UpdateConnectionRequest,
      requestStream: false,
      responseType: Connection,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              111,
              58,
              1,
              42,
              90,
              57,
              58,
              1,
              42,
              50,
              52,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              111,
              114,
              103,
              97,
              110,
              105,
              122,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              50,
              47,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              110,
              101,
              99,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface DlpServiceImplementation<CallContextExt = {}> {
  /**
   * Finds potentially sensitive info in content.
   * This method has limits on input size, processing time, and output size.
   *
   * When no InfoTypes or CustomInfoTypes are specified in this request, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   *
   * For how to guides, see
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-images
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-text,
   */
  inspectContent(
    request: InspectContentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InspectContentResponse>>;
  /**
   * Redacts potentially sensitive info from an image.
   * This method has limits on input size, processing time, and output size.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/redacting-sensitive-data-images
   * to learn more.
   *
   * When no InfoTypes or CustomInfoTypes are specified in this request, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   */
  redactImage(
    request: RedactImageRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<RedactImageResponse>>;
  /**
   * De-identifies potentially sensitive info from a ContentItem.
   * This method has limits on input size and output size.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/deidentify-sensitive-data
   * to learn more.
   *
   * When no InfoTypes or CustomInfoTypes are specified in this request, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   */
  deidentifyContent(
    request: DeidentifyContentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DeidentifyContentResponse>>;
  /**
   * Re-identifies content that has been de-identified.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/pseudonymization#re-identification_in_free_text_code_example
   * to learn more.
   */
  reidentifyContent(
    request: ReidentifyContentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReidentifyContentResponse>>;
  /**
   * Returns a list of the sensitive information types that DLP API
   * supports. See
   * https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference
   * to learn more.
   */
  listInfoTypes(
    request: ListInfoTypesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListInfoTypesResponse>>;
  /**
   * Creates an InspectTemplate for reusing frequently used configuration
   * for inspecting content, images, and storage.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  createInspectTemplate(
    request: CreateInspectTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InspectTemplate>>;
  /**
   * Updates the InspectTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  updateInspectTemplate(
    request: UpdateInspectTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InspectTemplate>>;
  /**
   * Gets an InspectTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  getInspectTemplate(
    request: GetInspectTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InspectTemplate>>;
  /**
   * Lists InspectTemplates.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  listInspectTemplates(
    request: ListInspectTemplatesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListInspectTemplatesResponse>>;
  /**
   * Deletes an InspectTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  deleteInspectTemplate(
    request: DeleteInspectTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Creates a DeidentifyTemplate for reusing frequently used configuration
   * for de-identifying content, images, and storage.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  createDeidentifyTemplate(
    request: CreateDeidentifyTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DeidentifyTemplate>>;
  /**
   * Updates the DeidentifyTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  updateDeidentifyTemplate(
    request: UpdateDeidentifyTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DeidentifyTemplate>>;
  /**
   * Gets a DeidentifyTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  getDeidentifyTemplate(
    request: GetDeidentifyTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DeidentifyTemplate>>;
  /**
   * Lists DeidentifyTemplates.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  listDeidentifyTemplates(
    request: ListDeidentifyTemplatesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDeidentifyTemplatesResponse>>;
  /**
   * Deletes a DeidentifyTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  deleteDeidentifyTemplate(
    request: DeleteDeidentifyTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Creates a job trigger to run DLP actions such as scanning storage for
   * sensitive information on a set schedule.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  createJobTrigger(
    request: CreateJobTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<JobTrigger>>;
  /**
   * Updates a job trigger.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  updateJobTrigger(
    request: UpdateJobTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<JobTrigger>>;
  /**
   * Inspect hybrid content and store findings to a trigger. The inspection
   * will be processed asynchronously. To review the findings monitor the
   * jobs within the trigger.
   */
  hybridInspectJobTrigger(
    request: HybridInspectJobTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<HybridInspectResponse>>;
  /**
   * Gets a job trigger.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  getJobTrigger(request: GetJobTriggerRequest, context: CallContext & CallContextExt): Promise<DeepPartial<JobTrigger>>;
  /**
   * Lists job triggers.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  listJobTriggers(
    request: ListJobTriggersRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListJobTriggersResponse>>;
  /**
   * Deletes a job trigger.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  deleteJobTrigger(
    request: DeleteJobTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Activate a job trigger. Causes the immediate execute of a trigger
   * instead of waiting on the trigger event to occur.
   */
  activateJobTrigger(
    request: ActivateJobTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DlpJob>>;
  /** Creates a config for discovery to scan and profile storage. */
  createDiscoveryConfig(
    request: CreateDiscoveryConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DiscoveryConfig>>;
  /** Updates a discovery configuration. */
  updateDiscoveryConfig(
    request: UpdateDiscoveryConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DiscoveryConfig>>;
  /** Gets a discovery configuration. */
  getDiscoveryConfig(
    request: GetDiscoveryConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DiscoveryConfig>>;
  /** Lists discovery configurations. */
  listDiscoveryConfigs(
    request: ListDiscoveryConfigsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDiscoveryConfigsResponse>>;
  /** Deletes a discovery configuration. */
  deleteDiscoveryConfig(
    request: DeleteDiscoveryConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Creates a new job to inspect storage or calculate risk metrics.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   *
   * When no InfoTypes or CustomInfoTypes are specified in inspect jobs, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   */
  createDlpJob(request: CreateDlpJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<DlpJob>>;
  /**
   * Lists DlpJobs that match the specified filter in the request.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  listDlpJobs(
    request: ListDlpJobsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDlpJobsResponse>>;
  /**
   * Gets the latest state of a long-running DlpJob.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  getDlpJob(request: GetDlpJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<DlpJob>>;
  /**
   * Deletes a long-running DlpJob. This method indicates that the client is
   * no longer interested in the DlpJob result. The job will be canceled if
   * possible.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  deleteDlpJob(request: DeleteDlpJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Starts asynchronous cancellation on a long-running DlpJob. The server
   * makes a best effort to cancel the DlpJob, but success is not
   * guaranteed.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  cancelDlpJob(request: CancelDlpJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Creates a pre-built stored infoType to be used for inspection.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  createStoredInfoType(
    request: CreateStoredInfoTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<StoredInfoType>>;
  /**
   * Updates the stored infoType by creating a new version. The existing version
   * will continue to be used until the new version is ready.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  updateStoredInfoType(
    request: UpdateStoredInfoTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<StoredInfoType>>;
  /**
   * Gets a stored infoType.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  getStoredInfoType(
    request: GetStoredInfoTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<StoredInfoType>>;
  /**
   * Lists stored infoTypes.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  listStoredInfoTypes(
    request: ListStoredInfoTypesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListStoredInfoTypesResponse>>;
  /**
   * Deletes a stored infoType.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  deleteStoredInfoType(
    request: DeleteStoredInfoTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Lists project data profiles for an organization. */
  listProjectDataProfiles(
    request: ListProjectDataProfilesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListProjectDataProfilesResponse>>;
  /** Lists table data profiles for an organization. */
  listTableDataProfiles(
    request: ListTableDataProfilesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTableDataProfilesResponse>>;
  /** Lists column data profiles for an organization. */
  listColumnDataProfiles(
    request: ListColumnDataProfilesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListColumnDataProfilesResponse>>;
  /** Gets a project data profile. */
  getProjectDataProfile(
    request: GetProjectDataProfileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ProjectDataProfile>>;
  /** Lists file store data profiles for an organization. */
  listFileStoreDataProfiles(
    request: ListFileStoreDataProfilesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListFileStoreDataProfilesResponse>>;
  /** Gets a file store data profile. */
  getFileStoreDataProfile(
    request: GetFileStoreDataProfileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FileStoreDataProfile>>;
  /**
   * Delete a FileStoreDataProfile. Will not prevent the profile from being
   * regenerated if the resource is still included in a discovery configuration.
   */
  deleteFileStoreDataProfile(
    request: DeleteFileStoreDataProfileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Gets a table data profile. */
  getTableDataProfile(
    request: GetTableDataProfileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TableDataProfile>>;
  /** Gets a column data profile. */
  getColumnDataProfile(
    request: GetColumnDataProfileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ColumnDataProfile>>;
  /**
   * Delete a TableDataProfile. Will not prevent the profile from being
   * regenerated if the table is still included in a discovery configuration.
   */
  deleteTableDataProfile(
    request: DeleteTableDataProfileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Inspect hybrid content and store findings to a job.
   * To review the findings, inspect the job. Inspection will occur
   * asynchronously.
   */
  hybridInspectDlpJob(
    request: HybridInspectDlpJobRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<HybridInspectResponse>>;
  /**
   * Finish a running hybrid DlpJob. Triggers the finalization steps and running
   * of any enabled actions that have not yet run.
   */
  finishDlpJob(request: FinishDlpJobRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Create a Connection to an external data source. */
  createConnection(
    request: CreateConnectionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Connection>>;
  /** Get a Connection by name. */
  getConnection(request: GetConnectionRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Connection>>;
  /**
   * Lists Connections in a parent. Use SearchConnections to see all connections
   * within an organization.
   */
  listConnections(
    request: ListConnectionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListConnectionsResponse>>;
  /** Searches for Connections in a parent. */
  searchConnections(
    request: SearchConnectionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SearchConnectionsResponse>>;
  /** Delete a Connection. */
  deleteConnection(
    request: DeleteConnectionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Update a Connection. */
  updateConnection(
    request: UpdateConnectionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Connection>>;
}

export interface DlpServiceClient<CallOptionsExt = {}> {
  /**
   * Finds potentially sensitive info in content.
   * This method has limits on input size, processing time, and output size.
   *
   * When no InfoTypes or CustomInfoTypes are specified in this request, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   *
   * For how to guides, see
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-images
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-text,
   */
  inspectContent(
    request: DeepPartial<InspectContentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InspectContentResponse>;
  /**
   * Redacts potentially sensitive info from an image.
   * This method has limits on input size, processing time, and output size.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/redacting-sensitive-data-images
   * to learn more.
   *
   * When no InfoTypes or CustomInfoTypes are specified in this request, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   */
  redactImage(
    request: DeepPartial<RedactImageRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<RedactImageResponse>;
  /**
   * De-identifies potentially sensitive info from a ContentItem.
   * This method has limits on input size and output size.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/deidentify-sensitive-data
   * to learn more.
   *
   * When no InfoTypes or CustomInfoTypes are specified in this request, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   */
  deidentifyContent(
    request: DeepPartial<DeidentifyContentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DeidentifyContentResponse>;
  /**
   * Re-identifies content that has been de-identified.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/pseudonymization#re-identification_in_free_text_code_example
   * to learn more.
   */
  reidentifyContent(
    request: DeepPartial<ReidentifyContentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReidentifyContentResponse>;
  /**
   * Returns a list of the sensitive information types that DLP API
   * supports. See
   * https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference
   * to learn more.
   */
  listInfoTypes(
    request: DeepPartial<ListInfoTypesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListInfoTypesResponse>;
  /**
   * Creates an InspectTemplate for reusing frequently used configuration
   * for inspecting content, images, and storage.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  createInspectTemplate(
    request: DeepPartial<CreateInspectTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InspectTemplate>;
  /**
   * Updates the InspectTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  updateInspectTemplate(
    request: DeepPartial<UpdateInspectTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InspectTemplate>;
  /**
   * Gets an InspectTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  getInspectTemplate(
    request: DeepPartial<GetInspectTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InspectTemplate>;
  /**
   * Lists InspectTemplates.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  listInspectTemplates(
    request: DeepPartial<ListInspectTemplatesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListInspectTemplatesResponse>;
  /**
   * Deletes an InspectTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates
   * to learn more.
   */
  deleteInspectTemplate(
    request: DeepPartial<DeleteInspectTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Creates a DeidentifyTemplate for reusing frequently used configuration
   * for de-identifying content, images, and storage.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  createDeidentifyTemplate(
    request: DeepPartial<CreateDeidentifyTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DeidentifyTemplate>;
  /**
   * Updates the DeidentifyTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  updateDeidentifyTemplate(
    request: DeepPartial<UpdateDeidentifyTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DeidentifyTemplate>;
  /**
   * Gets a DeidentifyTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  getDeidentifyTemplate(
    request: DeepPartial<GetDeidentifyTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DeidentifyTemplate>;
  /**
   * Lists DeidentifyTemplates.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  listDeidentifyTemplates(
    request: DeepPartial<ListDeidentifyTemplatesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDeidentifyTemplatesResponse>;
  /**
   * Deletes a DeidentifyTemplate.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-templates-deid
   * to learn more.
   */
  deleteDeidentifyTemplate(
    request: DeepPartial<DeleteDeidentifyTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Creates a job trigger to run DLP actions such as scanning storage for
   * sensitive information on a set schedule.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  createJobTrigger(
    request: DeepPartial<CreateJobTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<JobTrigger>;
  /**
   * Updates a job trigger.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  updateJobTrigger(
    request: DeepPartial<UpdateJobTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<JobTrigger>;
  /**
   * Inspect hybrid content and store findings to a trigger. The inspection
   * will be processed asynchronously. To review the findings monitor the
   * jobs within the trigger.
   */
  hybridInspectJobTrigger(
    request: DeepPartial<HybridInspectJobTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<HybridInspectResponse>;
  /**
   * Gets a job trigger.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  getJobTrigger(
    request: DeepPartial<GetJobTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<JobTrigger>;
  /**
   * Lists job triggers.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  listJobTriggers(
    request: DeepPartial<ListJobTriggersRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListJobTriggersResponse>;
  /**
   * Deletes a job trigger.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-job-triggers
   * to learn more.
   */
  deleteJobTrigger(
    request: DeepPartial<DeleteJobTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Activate a job trigger. Causes the immediate execute of a trigger
   * instead of waiting on the trigger event to occur.
   */
  activateJobTrigger(
    request: DeepPartial<ActivateJobTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DlpJob>;
  /** Creates a config for discovery to scan and profile storage. */
  createDiscoveryConfig(
    request: DeepPartial<CreateDiscoveryConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DiscoveryConfig>;
  /** Updates a discovery configuration. */
  updateDiscoveryConfig(
    request: DeepPartial<UpdateDiscoveryConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DiscoveryConfig>;
  /** Gets a discovery configuration. */
  getDiscoveryConfig(
    request: DeepPartial<GetDiscoveryConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DiscoveryConfig>;
  /** Lists discovery configurations. */
  listDiscoveryConfigs(
    request: DeepPartial<ListDiscoveryConfigsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDiscoveryConfigsResponse>;
  /** Deletes a discovery configuration. */
  deleteDiscoveryConfig(
    request: DeepPartial<DeleteDiscoveryConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Creates a new job to inspect storage or calculate risk metrics.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   *
   * When no InfoTypes or CustomInfoTypes are specified in inspect jobs, the
   * system will automatically choose what detectors to run. By default this may
   * be all types, but may change over time as detectors are updated.
   */
  createDlpJob(request: DeepPartial<CreateDlpJobRequest>, options?: CallOptions & CallOptionsExt): Promise<DlpJob>;
  /**
   * Lists DlpJobs that match the specified filter in the request.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  listDlpJobs(
    request: DeepPartial<ListDlpJobsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDlpJobsResponse>;
  /**
   * Gets the latest state of a long-running DlpJob.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  getDlpJob(request: DeepPartial<GetDlpJobRequest>, options?: CallOptions & CallOptionsExt): Promise<DlpJob>;
  /**
   * Deletes a long-running DlpJob. This method indicates that the client is
   * no longer interested in the DlpJob result. The job will be canceled if
   * possible.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  deleteDlpJob(request: DeepPartial<DeleteDlpJobRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Starts asynchronous cancellation on a long-running DlpJob. The server
   * makes a best effort to cancel the DlpJob, but success is not
   * guaranteed.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/inspecting-storage
   * and
   * https://cloud.google.com/sensitive-data-protection/docs/compute-risk-analysis
   * to learn more.
   */
  cancelDlpJob(request: DeepPartial<CancelDlpJobRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Creates a pre-built stored infoType to be used for inspection.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  createStoredInfoType(
    request: DeepPartial<CreateStoredInfoTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<StoredInfoType>;
  /**
   * Updates the stored infoType by creating a new version. The existing version
   * will continue to be used until the new version is ready.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  updateStoredInfoType(
    request: DeepPartial<UpdateStoredInfoTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<StoredInfoType>;
  /**
   * Gets a stored infoType.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  getStoredInfoType(
    request: DeepPartial<GetStoredInfoTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<StoredInfoType>;
  /**
   * Lists stored infoTypes.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  listStoredInfoTypes(
    request: DeepPartial<ListStoredInfoTypesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListStoredInfoTypesResponse>;
  /**
   * Deletes a stored infoType.
   * See
   * https://cloud.google.com/sensitive-data-protection/docs/creating-stored-infotypes
   * to learn more.
   */
  deleteStoredInfoType(
    request: DeepPartial<DeleteStoredInfoTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Lists project data profiles for an organization. */
  listProjectDataProfiles(
    request: DeepPartial<ListProjectDataProfilesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListProjectDataProfilesResponse>;
  /** Lists table data profiles for an organization. */
  listTableDataProfiles(
    request: DeepPartial<ListTableDataProfilesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTableDataProfilesResponse>;
  /** Lists column data profiles for an organization. */
  listColumnDataProfiles(
    request: DeepPartial<ListColumnDataProfilesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListColumnDataProfilesResponse>;
  /** Gets a project data profile. */
  getProjectDataProfile(
    request: DeepPartial<GetProjectDataProfileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ProjectDataProfile>;
  /** Lists file store data profiles for an organization. */
  listFileStoreDataProfiles(
    request: DeepPartial<ListFileStoreDataProfilesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListFileStoreDataProfilesResponse>;
  /** Gets a file store data profile. */
  getFileStoreDataProfile(
    request: DeepPartial<GetFileStoreDataProfileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FileStoreDataProfile>;
  /**
   * Delete a FileStoreDataProfile. Will not prevent the profile from being
   * regenerated if the resource is still included in a discovery configuration.
   */
  deleteFileStoreDataProfile(
    request: DeepPartial<DeleteFileStoreDataProfileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Gets a table data profile. */
  getTableDataProfile(
    request: DeepPartial<GetTableDataProfileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TableDataProfile>;
  /** Gets a column data profile. */
  getColumnDataProfile(
    request: DeepPartial<GetColumnDataProfileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ColumnDataProfile>;
  /**
   * Delete a TableDataProfile. Will not prevent the profile from being
   * regenerated if the table is still included in a discovery configuration.
   */
  deleteTableDataProfile(
    request: DeepPartial<DeleteTableDataProfileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Inspect hybrid content and store findings to a job.
   * To review the findings, inspect the job. Inspection will occur
   * asynchronously.
   */
  hybridInspectDlpJob(
    request: DeepPartial<HybridInspectDlpJobRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<HybridInspectResponse>;
  /**
   * Finish a running hybrid DlpJob. Triggers the finalization steps and running
   * of any enabled actions that have not yet run.
   */
  finishDlpJob(request: DeepPartial<FinishDlpJobRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Create a Connection to an external data source. */
  createConnection(
    request: DeepPartial<CreateConnectionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Connection>;
  /** Get a Connection by name. */
  getConnection(
    request: DeepPartial<GetConnectionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Connection>;
  /**
   * Lists Connections in a parent. Use SearchConnections to see all connections
   * within an organization.
   */
  listConnections(
    request: DeepPartial<ListConnectionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListConnectionsResponse>;
  /** Searches for Connections in a parent. */
  searchConnections(
    request: DeepPartial<SearchConnectionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SearchConnectionsResponse>;
  /** Delete a Connection. */
  deleteConnection(
    request: DeepPartial<DeleteConnectionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Update a Connection. */
  updateConnection(
    request: DeepPartial<UpdateConnectionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Connection>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
