// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/analytics/data/v1beta/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.analytics.data.v1beta";

/** Represents aggregation of metrics. */
export enum MetricAggregation {
  /** METRIC_AGGREGATION_UNSPECIFIED - Unspecified operator. */
  METRIC_AGGREGATION_UNSPECIFIED = 0,
  /** TOTAL - SUM operator. */
  TOTAL = 1,
  /** MINIMUM - Minimum operator. */
  MINIMUM = 5,
  /** MAXIMUM - Maximum operator. */
  MAXIMUM = 6,
  /** COUNT - Count operator. */
  COUNT = 4,
  UNRECOGNIZED = -1,
}

export function metricAggregationFromJSON(object: any): MetricAggregation {
  switch (object) {
    case 0:
    case "METRIC_AGGREGATION_UNSPECIFIED":
      return MetricAggregation.METRIC_AGGREGATION_UNSPECIFIED;
    case 1:
    case "TOTAL":
      return MetricAggregation.TOTAL;
    case 5:
    case "MINIMUM":
      return MetricAggregation.MINIMUM;
    case 6:
    case "MAXIMUM":
      return MetricAggregation.MAXIMUM;
    case 4:
    case "COUNT":
      return MetricAggregation.COUNT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetricAggregation.UNRECOGNIZED;
  }
}

export function metricAggregationToJSON(object: MetricAggregation): string {
  switch (object) {
    case MetricAggregation.METRIC_AGGREGATION_UNSPECIFIED:
      return "METRIC_AGGREGATION_UNSPECIFIED";
    case MetricAggregation.TOTAL:
      return "TOTAL";
    case MetricAggregation.MINIMUM:
      return "MINIMUM";
    case MetricAggregation.MAXIMUM:
      return "MAXIMUM";
    case MetricAggregation.COUNT:
      return "COUNT";
    case MetricAggregation.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A metric's value type. */
export enum MetricType {
  /** METRIC_TYPE_UNSPECIFIED - Unspecified type. */
  METRIC_TYPE_UNSPECIFIED = 0,
  /** TYPE_INTEGER - Integer type. */
  TYPE_INTEGER = 1,
  /** TYPE_FLOAT - Floating point type. */
  TYPE_FLOAT = 2,
  /** TYPE_SECONDS - A duration of seconds; a special floating point type. */
  TYPE_SECONDS = 4,
  /** TYPE_MILLISECONDS - A duration in milliseconds; a special floating point type. */
  TYPE_MILLISECONDS = 5,
  /** TYPE_MINUTES - A duration in minutes; a special floating point type. */
  TYPE_MINUTES = 6,
  /** TYPE_HOURS - A duration in hours; a special floating point type. */
  TYPE_HOURS = 7,
  /** TYPE_STANDARD - A custom metric of standard type; a special floating point type. */
  TYPE_STANDARD = 8,
  /** TYPE_CURRENCY - An amount of money; a special floating point type. */
  TYPE_CURRENCY = 9,
  /** TYPE_FEET - A length in feet; a special floating point type. */
  TYPE_FEET = 10,
  /** TYPE_MILES - A length in miles; a special floating point type. */
  TYPE_MILES = 11,
  /** TYPE_METERS - A length in meters; a special floating point type. */
  TYPE_METERS = 12,
  /** TYPE_KILOMETERS - A length in kilometers; a special floating point type. */
  TYPE_KILOMETERS = 13,
  UNRECOGNIZED = -1,
}

export function metricTypeFromJSON(object: any): MetricType {
  switch (object) {
    case 0:
    case "METRIC_TYPE_UNSPECIFIED":
      return MetricType.METRIC_TYPE_UNSPECIFIED;
    case 1:
    case "TYPE_INTEGER":
      return MetricType.TYPE_INTEGER;
    case 2:
    case "TYPE_FLOAT":
      return MetricType.TYPE_FLOAT;
    case 4:
    case "TYPE_SECONDS":
      return MetricType.TYPE_SECONDS;
    case 5:
    case "TYPE_MILLISECONDS":
      return MetricType.TYPE_MILLISECONDS;
    case 6:
    case "TYPE_MINUTES":
      return MetricType.TYPE_MINUTES;
    case 7:
    case "TYPE_HOURS":
      return MetricType.TYPE_HOURS;
    case 8:
    case "TYPE_STANDARD":
      return MetricType.TYPE_STANDARD;
    case 9:
    case "TYPE_CURRENCY":
      return MetricType.TYPE_CURRENCY;
    case 10:
    case "TYPE_FEET":
      return MetricType.TYPE_FEET;
    case 11:
    case "TYPE_MILES":
      return MetricType.TYPE_MILES;
    case 12:
    case "TYPE_METERS":
      return MetricType.TYPE_METERS;
    case 13:
    case "TYPE_KILOMETERS":
      return MetricType.TYPE_KILOMETERS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetricType.UNRECOGNIZED;
  }
}

export function metricTypeToJSON(object: MetricType): string {
  switch (object) {
    case MetricType.METRIC_TYPE_UNSPECIFIED:
      return "METRIC_TYPE_UNSPECIFIED";
    case MetricType.TYPE_INTEGER:
      return "TYPE_INTEGER";
    case MetricType.TYPE_FLOAT:
      return "TYPE_FLOAT";
    case MetricType.TYPE_SECONDS:
      return "TYPE_SECONDS";
    case MetricType.TYPE_MILLISECONDS:
      return "TYPE_MILLISECONDS";
    case MetricType.TYPE_MINUTES:
      return "TYPE_MINUTES";
    case MetricType.TYPE_HOURS:
      return "TYPE_HOURS";
    case MetricType.TYPE_STANDARD:
      return "TYPE_STANDARD";
    case MetricType.TYPE_CURRENCY:
      return "TYPE_CURRENCY";
    case MetricType.TYPE_FEET:
      return "TYPE_FEET";
    case MetricType.TYPE_MILES:
      return "TYPE_MILES";
    case MetricType.TYPE_METERS:
      return "TYPE_METERS";
    case MetricType.TYPE_KILOMETERS:
      return "TYPE_KILOMETERS";
    case MetricType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Categories of data that you may be restricted from viewing on certain GA4
 * properties.
 */
export enum RestrictedMetricType {
  /** RESTRICTED_METRIC_TYPE_UNSPECIFIED - Unspecified type. */
  RESTRICTED_METRIC_TYPE_UNSPECIFIED = 0,
  /** COST_DATA - Cost metrics such as `adCost`. */
  COST_DATA = 1,
  /** REVENUE_DATA - Revenue metrics such as `purchaseRevenue`. */
  REVENUE_DATA = 2,
  UNRECOGNIZED = -1,
}

export function restrictedMetricTypeFromJSON(object: any): RestrictedMetricType {
  switch (object) {
    case 0:
    case "RESTRICTED_METRIC_TYPE_UNSPECIFIED":
      return RestrictedMetricType.RESTRICTED_METRIC_TYPE_UNSPECIFIED;
    case 1:
    case "COST_DATA":
      return RestrictedMetricType.COST_DATA;
    case 2:
    case "REVENUE_DATA":
      return RestrictedMetricType.REVENUE_DATA;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RestrictedMetricType.UNRECOGNIZED;
  }
}

export function restrictedMetricTypeToJSON(object: RestrictedMetricType): string {
  switch (object) {
    case RestrictedMetricType.RESTRICTED_METRIC_TYPE_UNSPECIFIED:
      return "RESTRICTED_METRIC_TYPE_UNSPECIFIED";
    case RestrictedMetricType.COST_DATA:
      return "COST_DATA";
    case RestrictedMetricType.REVENUE_DATA:
      return "REVENUE_DATA";
    case RestrictedMetricType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The compatibility types for a single dimension or metric. */
export enum Compatibility {
  /** COMPATIBILITY_UNSPECIFIED - Unspecified compatibility. */
  COMPATIBILITY_UNSPECIFIED = 0,
  /**
   * COMPATIBLE - The dimension or metric is compatible. This dimension or metric can be
   * successfully added to a report.
   */
  COMPATIBLE = 1,
  /**
   * INCOMPATIBLE - The dimension or metric is incompatible. This dimension or metric cannot be
   * successfully added to a report.
   */
  INCOMPATIBLE = 2,
  UNRECOGNIZED = -1,
}

export function compatibilityFromJSON(object: any): Compatibility {
  switch (object) {
    case 0:
    case "COMPATIBILITY_UNSPECIFIED":
      return Compatibility.COMPATIBILITY_UNSPECIFIED;
    case 1:
    case "COMPATIBLE":
      return Compatibility.COMPATIBLE;
    case 2:
    case "INCOMPATIBLE":
      return Compatibility.INCOMPATIBLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Compatibility.UNRECOGNIZED;
  }
}

export function compatibilityToJSON(object: Compatibility): string {
  switch (object) {
    case Compatibility.COMPATIBILITY_UNSPECIFIED:
      return "COMPATIBILITY_UNSPECIFIED";
    case Compatibility.COMPATIBLE:
      return "COMPATIBLE";
    case Compatibility.INCOMPATIBLE:
      return "INCOMPATIBLE";
    case Compatibility.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A contiguous set of days: `startDate`, `startDate + 1`, ..., `endDate`.
 * Requests are allowed up to 4 date ranges.
 */
export interface DateRange {
  /**
   * The inclusive start date for the query in the format `YYYY-MM-DD`. Cannot
   * be after `end_date`. The format `NdaysAgo`, `yesterday`, or `today` is also
   * accepted, and in that case, the date is inferred based on the property's
   * reporting time zone.
   */
  startDate: string;
  /**
   * The inclusive end date for the query in the format `YYYY-MM-DD`. Cannot
   * be before `start_date`. The format `NdaysAgo`, `yesterday`, or `today` is
   * also accepted, and in that case, the date is inferred based on the
   * property's reporting time zone.
   */
  endDate: string;
  /**
   * Assigns a name to this date range. The dimension `dateRange` is valued to
   * this name in a report response. If set, cannot begin with `date_range_` or
   * `RESERVED_`. If not set, date ranges are named by their zero based index in
   * the request: `date_range_0`, `date_range_1`, etc.
   */
  name: string;
}

/**
 * A contiguous set of minutes: `startMinutesAgo`, `startMinutesAgo + 1`, ...,
 * `endMinutesAgo`. Requests are allowed up to 2 minute ranges.
 */
export interface MinuteRange {
  /**
   * The inclusive start minute for the query as a number of minutes before now.
   * For example, `"startMinutesAgo": 29` specifies the report should include
   * event data from 29 minutes ago and after. Cannot be after `endMinutesAgo`.
   *
   * If unspecified, `startMinutesAgo` is defaulted to 29. Standard Analytics
   * properties can request up to the last 30 minutes of event data
   * (`startMinutesAgo <= 29`), and 360 Analytics properties can request up to
   * the last 60 minutes of event data (`startMinutesAgo <= 59`).
   */
  startMinutesAgo?:
    | number
    | undefined;
  /**
   * The inclusive end minute for the query as a number of minutes before now.
   * Cannot be before `startMinutesAgo`. For example, `"endMinutesAgo": 15`
   * specifies the report should include event data from prior to 15 minutes
   * ago.
   *
   * If unspecified, `endMinutesAgo` is defaulted to 0. Standard Analytics
   * properties can request any minute in the last 30 minutes of event data
   * (`endMinutesAgo <= 29`), and 360 Analytics properties can request any
   * minute in the last 60 minutes of event data (`endMinutesAgo <= 59`).
   */
  endMinutesAgo?:
    | number
    | undefined;
  /**
   * Assigns a name to this minute range. The dimension `dateRange` is valued to
   * this name in a report response. If set, cannot begin with `date_range_` or
   * `RESERVED_`. If not set, minute ranges are named by their zero based index
   * in the request: `date_range_0`, `date_range_1`, etc.
   */
  name: string;
}

/**
 * Dimensions are attributes of your data. For example, the dimension city
 * indicates the city from which an event originates. Dimension values in report
 * responses are strings; for example, the city could be "Paris" or "New York".
 * Requests are allowed up to 9 dimensions.
 */
export interface Dimension {
  /**
   * The name of the dimension. See the [API
   * Dimensions](https://developers.google.com/analytics/devguides/reporting/data/v1/api-schema#dimensions)
   * for the list of dimension names supported by core reporting methods such
   * as `runReport` and `batchRunReports`. See
   * [Realtime
   * Dimensions](https://developers.google.com/analytics/devguides/reporting/data/v1/realtime-api-schema#dimensions)
   * for the list of dimension names supported by the `runRealtimeReport`
   * method. See
   * [Funnel
   * Dimensions](https://developers.google.com/analytics/devguides/reporting/data/v1/exploration-api-schema#dimensions)
   * for the list of dimension names supported by the `runFunnelReport`
   * method.
   *
   * If `dimensionExpression` is specified, `name` can be any string that you
   * would like within the allowed character set. For example if a
   * `dimensionExpression` concatenates `country` and `city`, you could call
   * that dimension `countryAndCity`. Dimension names that you choose must match
   * the regular expression `^[a-zA-Z0-9_]$`.
   *
   * Dimensions are referenced by `name` in `dimensionFilter`, `orderBys`,
   * `dimensionExpression`, and `pivots`.
   */
  name: string;
  /**
   * One dimension can be the result of an expression of multiple dimensions.
   * For example, dimension "country, city": concatenate(country, ", ", city).
   */
  dimensionExpression: DimensionExpression | undefined;
}

/**
 * Used to express a dimension which is the result of a formula of multiple
 * dimensions. Example usages:
 * 1) lower_case(dimension)
 * 2) concatenate(dimension1, symbol, dimension2).
 */
export interface DimensionExpression {
  /** Used to convert a dimension value to lower case. */
  lowerCase?:
    | DimensionExpression_CaseExpression
    | undefined;
  /** Used to convert a dimension value to upper case. */
  upperCase?:
    | DimensionExpression_CaseExpression
    | undefined;
  /**
   * Used to combine dimension values to a single dimension.
   * For example, dimension "country, city": concatenate(country, ", ", city).
   */
  concatenate?: DimensionExpression_ConcatenateExpression | undefined;
}

/** Used to convert a dimension value to a single case. */
export interface DimensionExpression_CaseExpression {
  /**
   * Name of a dimension. The name must refer back to a name in dimensions
   * field of the request.
   */
  dimensionName: string;
}

/** Used to combine dimension values to a single dimension. */
export interface DimensionExpression_ConcatenateExpression {
  /**
   * Names of dimensions. The names must refer back to names in the dimensions
   * field of the request.
   */
  dimensionNames: string[];
  /**
   * The delimiter placed between dimension names.
   *
   * Delimiters are often single characters such as "|" or "," but can be
   * longer strings. If a dimension value contains the delimiter, both will be
   * present in response with no distinction. For example if dimension 1 value
   * = "US,FR", dimension 2 value = "JP", and delimiter = ",", then the
   * response will contain "US,FR,JP".
   */
  delimiter: string;
}

/**
 * The quantitative measurements of a report. For example, the metric
 * `eventCount` is the total number of events. Requests are allowed up to 10
 * metrics.
 */
export interface Metric {
  /**
   * The name of the metric. See the [API
   * Metrics](https://developers.google.com/analytics/devguides/reporting/data/v1/api-schema#metrics)
   * for the list of metric names supported by core reporting methods such
   * as `runReport` and `batchRunReports`. See
   * [Realtime
   * Metrics](https://developers.google.com/analytics/devguides/reporting/data/v1/realtime-api-schema#metrics)
   * for the list of metric names supported by the `runRealtimeReport`
   * method. See
   * [Funnel
   * Metrics](https://developers.google.com/analytics/devguides/reporting/data/v1/exploration-api-schema#metrics)
   * for the list of metric names supported by the `runFunnelReport`
   * method.
   *
   * If `expression` is specified, `name` can be any string that you would like
   * within the allowed character set. For example if `expression` is
   * `screenPageViews/sessions`, you could call that metric's name =
   * `viewsPerSession`. Metric names that you choose must match the regular
   * expression `^[a-zA-Z0-9_]$`.
   *
   * Metrics are referenced by `name` in `metricFilter`, `orderBys`, and metric
   * `expression`.
   */
  name: string;
  /**
   * A mathematical expression for derived metrics. For example, the metric
   * Event count per user is `eventCount/totalUsers`.
   */
  expression: string;
  /**
   * Indicates if a metric is invisible in the report response. If a metric is
   * invisible, the metric will not produce a column in the response, but can be
   * used in `metricFilter`, `orderBys`, or a metric `expression`.
   */
  invisible: boolean;
}

/**
 * Defines an individual comparison. Most requests will include multiple
 * comparisons so that the report compares between the comparisons.
 */
export interface Comparison {
  /**
   * Each comparison produces separate rows in the response. In the response,
   * this comparison is identified by this name. If name is unspecified, we will
   * use the saved comparisons display name.
   */
  name?:
    | string
    | undefined;
  /** A basic comparison. */
  dimensionFilter?:
    | FilterExpression
    | undefined;
  /**
   * A saved comparison identified by the comparison's resource name.
   * For example, 'comparisons/1234'.
   */
  comparison?: string | undefined;
}

/**
 * To express dimension or metric filters. The fields in the same
 * FilterExpression need to be either all dimensions or all metrics.
 */
export interface FilterExpression {
  /** The FilterExpressions in and_group have an AND relationship. */
  andGroup?:
    | FilterExpressionList
    | undefined;
  /** The FilterExpressions in or_group have an OR relationship. */
  orGroup?:
    | FilterExpressionList
    | undefined;
  /** The FilterExpression is NOT of not_expression. */
  notExpression?:
    | FilterExpression
    | undefined;
  /**
   * A primitive filter. In the same FilterExpression, all of the filter's
   * field names need to be either all dimensions or all metrics.
   */
  filter?: Filter | undefined;
}

/** A list of filter expressions. */
export interface FilterExpressionList {
  /** A list of filter expressions. */
  expressions: FilterExpression[];
}

/** An expression to filter dimension or metric values. */
export interface Filter {
  /**
   * The dimension name or metric name.
   *
   * In most methods, dimensions & metrics can be used for the first time in
   * this field. However in a RunPivotReportRequest, this field must be
   * additionally specified by name in the RunPivotReportRequest's dimensions or
   * metrics.
   */
  fieldName: string;
  /** Strings related filter. */
  stringFilter?:
    | Filter_StringFilter
    | undefined;
  /** A filter for in list values. */
  inListFilter?:
    | Filter_InListFilter
    | undefined;
  /** A filter for numeric or date values. */
  numericFilter?:
    | Filter_NumericFilter
    | undefined;
  /** A filter for two values. */
  betweenFilter?: Filter_BetweenFilter | undefined;
}

/** The filter for string */
export interface Filter_StringFilter {
  /** The match type for this filter. */
  matchType: Filter_StringFilter_MatchType;
  /** The string value used for the matching. */
  value: string;
  /** If true, the string value is case sensitive. */
  caseSensitive: boolean;
}

/** The match type of a string filter */
export enum Filter_StringFilter_MatchType {
  /** MATCH_TYPE_UNSPECIFIED - Unspecified */
  MATCH_TYPE_UNSPECIFIED = 0,
  /** EXACT - Exact match of the string value. */
  EXACT = 1,
  /** BEGINS_WITH - Begins with the string value. */
  BEGINS_WITH = 2,
  /** ENDS_WITH - Ends with the string value. */
  ENDS_WITH = 3,
  /** CONTAINS - Contains the string value. */
  CONTAINS = 4,
  /** FULL_REGEXP - Full match for the regular expression with the string value. */
  FULL_REGEXP = 5,
  /** PARTIAL_REGEXP - Partial match for the regular expression with the string value. */
  PARTIAL_REGEXP = 6,
  UNRECOGNIZED = -1,
}

export function filter_StringFilter_MatchTypeFromJSON(object: any): Filter_StringFilter_MatchType {
  switch (object) {
    case 0:
    case "MATCH_TYPE_UNSPECIFIED":
      return Filter_StringFilter_MatchType.MATCH_TYPE_UNSPECIFIED;
    case 1:
    case "EXACT":
      return Filter_StringFilter_MatchType.EXACT;
    case 2:
    case "BEGINS_WITH":
      return Filter_StringFilter_MatchType.BEGINS_WITH;
    case 3:
    case "ENDS_WITH":
      return Filter_StringFilter_MatchType.ENDS_WITH;
    case 4:
    case "CONTAINS":
      return Filter_StringFilter_MatchType.CONTAINS;
    case 5:
    case "FULL_REGEXP":
      return Filter_StringFilter_MatchType.FULL_REGEXP;
    case 6:
    case "PARTIAL_REGEXP":
      return Filter_StringFilter_MatchType.PARTIAL_REGEXP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Filter_StringFilter_MatchType.UNRECOGNIZED;
  }
}

export function filter_StringFilter_MatchTypeToJSON(object: Filter_StringFilter_MatchType): string {
  switch (object) {
    case Filter_StringFilter_MatchType.MATCH_TYPE_UNSPECIFIED:
      return "MATCH_TYPE_UNSPECIFIED";
    case Filter_StringFilter_MatchType.EXACT:
      return "EXACT";
    case Filter_StringFilter_MatchType.BEGINS_WITH:
      return "BEGINS_WITH";
    case Filter_StringFilter_MatchType.ENDS_WITH:
      return "ENDS_WITH";
    case Filter_StringFilter_MatchType.CONTAINS:
      return "CONTAINS";
    case Filter_StringFilter_MatchType.FULL_REGEXP:
      return "FULL_REGEXP";
    case Filter_StringFilter_MatchType.PARTIAL_REGEXP:
      return "PARTIAL_REGEXP";
    case Filter_StringFilter_MatchType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The result needs to be in a list of string values. */
export interface Filter_InListFilter {
  /**
   * The list of string values.
   * Must be non-empty.
   */
  values: string[];
  /** If true, the string value is case sensitive. */
  caseSensitive: boolean;
}

/** Filters for numeric or date values. */
export interface Filter_NumericFilter {
  /** The operation type for this filter. */
  operation: Filter_NumericFilter_Operation;
  /** A numeric value or a date value. */
  value: NumericValue | undefined;
}

/** The operation applied to a numeric filter */
export enum Filter_NumericFilter_Operation {
  /** OPERATION_UNSPECIFIED - Unspecified. */
  OPERATION_UNSPECIFIED = 0,
  /** EQUAL - Equal */
  EQUAL = 1,
  /** LESS_THAN - Less than */
  LESS_THAN = 2,
  /** LESS_THAN_OR_EQUAL - Less than or equal */
  LESS_THAN_OR_EQUAL = 3,
  /** GREATER_THAN - Greater than */
  GREATER_THAN = 4,
  /** GREATER_THAN_OR_EQUAL - Greater than or equal */
  GREATER_THAN_OR_EQUAL = 5,
  UNRECOGNIZED = -1,
}

export function filter_NumericFilter_OperationFromJSON(object: any): Filter_NumericFilter_Operation {
  switch (object) {
    case 0:
    case "OPERATION_UNSPECIFIED":
      return Filter_NumericFilter_Operation.OPERATION_UNSPECIFIED;
    case 1:
    case "EQUAL":
      return Filter_NumericFilter_Operation.EQUAL;
    case 2:
    case "LESS_THAN":
      return Filter_NumericFilter_Operation.LESS_THAN;
    case 3:
    case "LESS_THAN_OR_EQUAL":
      return Filter_NumericFilter_Operation.LESS_THAN_OR_EQUAL;
    case 4:
    case "GREATER_THAN":
      return Filter_NumericFilter_Operation.GREATER_THAN;
    case 5:
    case "GREATER_THAN_OR_EQUAL":
      return Filter_NumericFilter_Operation.GREATER_THAN_OR_EQUAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Filter_NumericFilter_Operation.UNRECOGNIZED;
  }
}

export function filter_NumericFilter_OperationToJSON(object: Filter_NumericFilter_Operation): string {
  switch (object) {
    case Filter_NumericFilter_Operation.OPERATION_UNSPECIFIED:
      return "OPERATION_UNSPECIFIED";
    case Filter_NumericFilter_Operation.EQUAL:
      return "EQUAL";
    case Filter_NumericFilter_Operation.LESS_THAN:
      return "LESS_THAN";
    case Filter_NumericFilter_Operation.LESS_THAN_OR_EQUAL:
      return "LESS_THAN_OR_EQUAL";
    case Filter_NumericFilter_Operation.GREATER_THAN:
      return "GREATER_THAN";
    case Filter_NumericFilter_Operation.GREATER_THAN_OR_EQUAL:
      return "GREATER_THAN_OR_EQUAL";
    case Filter_NumericFilter_Operation.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** To express that the result needs to be between two numbers (inclusive). */
export interface Filter_BetweenFilter {
  /** Begins with this number. */
  fromValue:
    | NumericValue
    | undefined;
  /** Ends with this number. */
  toValue: NumericValue | undefined;
}

/**
 * Order bys define how rows will be sorted in the response. For example,
 * ordering rows by descending event count is one ordering, and ordering rows by
 * the event name string is a different ordering.
 */
export interface OrderBy {
  /** Sorts results by a metric's values. */
  metric?:
    | OrderBy_MetricOrderBy
    | undefined;
  /** Sorts results by a dimension's values. */
  dimension?:
    | OrderBy_DimensionOrderBy
    | undefined;
  /** Sorts results by a metric's values within a pivot column group. */
  pivot?:
    | OrderBy_PivotOrderBy
    | undefined;
  /** If true, sorts by descending order. */
  desc: boolean;
}

/** Sorts by metric values. */
export interface OrderBy_MetricOrderBy {
  /** A metric name in the request to order by. */
  metricName: string;
}

/** Sorts by dimension values. */
export interface OrderBy_DimensionOrderBy {
  /** A dimension name in the request to order by. */
  dimensionName: string;
  /** Controls the rule for dimension value ordering. */
  orderType: OrderBy_DimensionOrderBy_OrderType;
}

/** Rule to order the string dimension values by. */
export enum OrderBy_DimensionOrderBy_OrderType {
  /** ORDER_TYPE_UNSPECIFIED - Unspecified. */
  ORDER_TYPE_UNSPECIFIED = 0,
  /**
   * ALPHANUMERIC - Alphanumeric sort by Unicode code point. For example, "2" < "A" < "X" <
   * "b" < "z".
   */
  ALPHANUMERIC = 1,
  /**
   * CASE_INSENSITIVE_ALPHANUMERIC - Case insensitive alphanumeric sort by lower case Unicode code point.
   * For example, "2" < "A" < "b" < "X" < "z".
   */
  CASE_INSENSITIVE_ALPHANUMERIC = 2,
  /**
   * NUMERIC - Dimension values are converted to numbers before sorting. For example
   * in NUMERIC sort, "25" < "100", and in `ALPHANUMERIC` sort, "100" <
   * "25". Non-numeric dimension values all have equal ordering value below
   * all numeric values.
   */
  NUMERIC = 3,
  UNRECOGNIZED = -1,
}

export function orderBy_DimensionOrderBy_OrderTypeFromJSON(object: any): OrderBy_DimensionOrderBy_OrderType {
  switch (object) {
    case 0:
    case "ORDER_TYPE_UNSPECIFIED":
      return OrderBy_DimensionOrderBy_OrderType.ORDER_TYPE_UNSPECIFIED;
    case 1:
    case "ALPHANUMERIC":
      return OrderBy_DimensionOrderBy_OrderType.ALPHANUMERIC;
    case 2:
    case "CASE_INSENSITIVE_ALPHANUMERIC":
      return OrderBy_DimensionOrderBy_OrderType.CASE_INSENSITIVE_ALPHANUMERIC;
    case 3:
    case "NUMERIC":
      return OrderBy_DimensionOrderBy_OrderType.NUMERIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OrderBy_DimensionOrderBy_OrderType.UNRECOGNIZED;
  }
}

export function orderBy_DimensionOrderBy_OrderTypeToJSON(object: OrderBy_DimensionOrderBy_OrderType): string {
  switch (object) {
    case OrderBy_DimensionOrderBy_OrderType.ORDER_TYPE_UNSPECIFIED:
      return "ORDER_TYPE_UNSPECIFIED";
    case OrderBy_DimensionOrderBy_OrderType.ALPHANUMERIC:
      return "ALPHANUMERIC";
    case OrderBy_DimensionOrderBy_OrderType.CASE_INSENSITIVE_ALPHANUMERIC:
      return "CASE_INSENSITIVE_ALPHANUMERIC";
    case OrderBy_DimensionOrderBy_OrderType.NUMERIC:
      return "NUMERIC";
    case OrderBy_DimensionOrderBy_OrderType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Sorts by a pivot column group. */
export interface OrderBy_PivotOrderBy {
  /**
   * In the response to order by, order rows by this column. Must be a metric
   * name from the request.
   */
  metricName: string;
  /**
   * Used to select a dimension name and value pivot. If multiple pivot
   * selections are given, the sort occurs on rows where all pivot selection
   * dimension name and value pairs match the row's dimension name and value
   * pair.
   */
  pivotSelections: OrderBy_PivotOrderBy_PivotSelection[];
}

/**
 * A pair of dimension names and values. Rows with this dimension pivot pair
 * are ordered by the metric's value.
 *
 * For example if pivots = {{"browser", "Chrome"}} and
 * metric_name = "Sessions",
 * then the rows will be sorted based on Sessions in Chrome.
 *
 *     ---------|----------|----------------|----------|----------------
 *              |  Chrome  |    Chrome      |  Safari  |     Safari
 *     ---------|----------|----------------|----------|----------------
 *      Country | Sessions | Pages/Sessions | Sessions | Pages/Sessions
 *     ---------|----------|----------------|----------|----------------
 *         US   |    2     |       2        |     3    |        1
 *     ---------|----------|----------------|----------|----------------
 *       Canada |    3     |       1        |     4    |        1
 *     ---------|----------|----------------|----------|----------------
 */
export interface OrderBy_PivotOrderBy_PivotSelection {
  /** Must be a dimension name from the request. */
  dimensionName: string;
  /** Order by only when the named dimension is this value. */
  dimensionValue: string;
}

/** Describes the visible dimension columns and rows in the report response. */
export interface Pivot {
  /**
   * Dimension names for visible columns in the report response. Including
   * "dateRange" produces a date range column; for each row in the response,
   * dimension values in the date range column will indicate the corresponding
   * date range from the request.
   */
  fieldNames: string[];
  /**
   * Specifies how dimensions are ordered in the pivot. In the first Pivot, the
   * OrderBys determine Row and PivotDimensionHeader ordering; in subsequent
   * Pivots, the OrderBys determine only PivotDimensionHeader ordering.
   * Dimensions specified in these OrderBys must be a subset of
   * Pivot.field_names.
   */
  orderBys: OrderBy[];
  /** The row count of the start row. The first row is counted as row 0. */
  offset: Long;
  /**
   * The number of unique combinations of dimension values to return in this
   * pivot. The `limit` parameter is required. A `limit` of 10,000 is common for
   * single pivot requests.
   *
   * The product of the `limit` for each `pivot` in a `RunPivotReportRequest`
   * must not exceed 250,000. For example, a two pivot request with `limit:
   * 1000` in each pivot will fail because the product is `1,000,000`.
   */
  limit: Long;
  /**
   * Aggregate the metrics by dimensions in this pivot using the specified
   * metric_aggregations.
   */
  metricAggregations: MetricAggregation[];
}

/**
 * The specification of cohorts for a cohort report.
 *
 * Cohort reports create a time series of user retention for the cohort. For
 * example, you could select the cohort of users that were acquired in the first
 * week of September and follow that cohort for the next six weeks. Selecting
 * the users acquired in the first week of September cohort is specified in the
 * `cohort` object. Following that cohort for the next six weeks is specified in
 * the `cohortsRange` object.
 *
 * For examples, see [Cohort Report
 * Examples](https://developers.google.com/analytics/devguides/reporting/data/v1/advanced#cohort_report_examples).
 *
 * The report response could show a weekly time series where say your app has
 * retained 60% of this cohort after three weeks and 25% of this cohort after
 * six weeks. These two percentages can be calculated by the metric
 * `cohortActiveUsers/cohortTotalUsers` and will be separate rows in the report.
 */
export interface CohortSpec {
  /**
   * Defines the selection criteria to group users into cohorts.
   *
   * Most cohort reports define only a single cohort. If multiple cohorts are
   * specified, each cohort can be recognized in the report by their name.
   */
  cohorts: Cohort[];
  /**
   * Cohort reports follow cohorts over an extended reporting date range. This
   * range specifies an offset duration to follow the cohorts over.
   */
  cohortsRange:
    | CohortsRange
    | undefined;
  /** Optional settings for a cohort report. */
  cohortReportSettings: CohortReportSettings | undefined;
}

/**
 * Defines a cohort selection criteria. A cohort is a group of users who share
 * a common characteristic. For example, users with the same `firstSessionDate`
 * belong to the same cohort.
 */
export interface Cohort {
  /**
   * Assigns a name to this cohort. The dimension `cohort` is valued to this
   * name in a report response. If set, cannot begin with `cohort_` or
   * `RESERVED_`. If not set, cohorts are named by their zero based index
   * `cohort_0`, `cohort_1`, etc.
   */
  name: string;
  /**
   * Dimension used by the cohort. Required and only supports
   * `firstSessionDate`.
   */
  dimension: string;
  /**
   * The cohort selects users whose first touch date is between start date and
   * end date defined in the `dateRange`. This `dateRange` does not specify the
   * full date range of event data that is present in a cohort report. In a
   * cohort report, this `dateRange` is extended by the granularity and offset
   * present in the `cohortsRange`; event data for the extended reporting date
   * range is present in a cohort report.
   *
   * In a cohort request, this `dateRange` is required and the `dateRanges` in
   * the `RunReportRequest` or `RunPivotReportRequest` must be unspecified.
   *
   * This `dateRange` should generally be aligned with the cohort's granularity.
   * If `CohortsRange` uses daily granularity, this `dateRange` can be a single
   * day. If `CohortsRange` uses weekly granularity, this `dateRange` can be
   * aligned to a week boundary, starting at Sunday and ending Saturday. If
   * `CohortsRange` uses monthly granularity, this `dateRange` can be aligned to
   * a month, starting at the first and ending on the last day of the month.
   */
  dateRange: DateRange | undefined;
}

/**
 * Configures the extended reporting date range for a cohort report. Specifies
 * an offset duration to follow the cohorts over.
 */
export interface CohortsRange {
  /**
   * Required. The granularity used to interpret the `startOffset` and
   * `endOffset` for the extended reporting date range for a cohort report.
   */
  granularity: CohortsRange_Granularity;
  /**
   * `startOffset` specifies the start date of the extended reporting date range
   * for a cohort report. `startOffset` is commonly set to 0 so that reports
   * contain data from the acquisition of the cohort forward.
   *
   * If `granularity` is `DAILY`, the `startDate` of the extended reporting date
   * range is `startDate` of the cohort plus `startOffset` days.
   *
   * If `granularity` is `WEEKLY`, the `startDate` of the extended reporting
   * date range is `startDate` of the cohort plus `startOffset * 7` days.
   *
   * If `granularity` is `MONTHLY`, the `startDate` of the extended reporting
   * date range is `startDate` of the cohort plus `startOffset * 30` days.
   */
  startOffset: number;
  /**
   * Required. `endOffset` specifies the end date of the extended reporting date
   * range for a cohort report. `endOffset` can be any positive integer but is
   * commonly set to 5 to 10 so that reports contain data on the cohort for the
   * next several granularity time periods.
   *
   * If `granularity` is `DAILY`, the `endDate` of the extended reporting date
   * range is `endDate` of the cohort plus `endOffset` days.
   *
   * If `granularity` is `WEEKLY`, the `endDate` of the extended reporting date
   * range is `endDate` of the cohort plus `endOffset * 7` days.
   *
   * If `granularity` is `MONTHLY`, the `endDate` of the extended reporting date
   * range is `endDate` of the cohort plus `endOffset * 30` days.
   */
  endOffset: number;
}

/**
 * The granularity used to interpret the `startOffset` and `endOffset` for the
 * extended reporting date range for a cohort report.
 */
export enum CohortsRange_Granularity {
  /** GRANULARITY_UNSPECIFIED - Should never be specified. */
  GRANULARITY_UNSPECIFIED = 0,
  /**
   * DAILY - Daily granularity. Commonly used if the cohort's `dateRange` is a single
   * day and the request contains `cohortNthDay`.
   */
  DAILY = 1,
  /**
   * WEEKLY - Weekly granularity. Commonly used if the cohort's `dateRange` is a week
   * in duration (starting on Sunday and ending on Saturday) and the request
   * contains `cohortNthWeek`.
   */
  WEEKLY = 2,
  /**
   * MONTHLY - Monthly granularity. Commonly used if the cohort's `dateRange` is a month
   * in duration and the request contains `cohortNthMonth`.
   */
  MONTHLY = 3,
  UNRECOGNIZED = -1,
}

export function cohortsRange_GranularityFromJSON(object: any): CohortsRange_Granularity {
  switch (object) {
    case 0:
    case "GRANULARITY_UNSPECIFIED":
      return CohortsRange_Granularity.GRANULARITY_UNSPECIFIED;
    case 1:
    case "DAILY":
      return CohortsRange_Granularity.DAILY;
    case 2:
    case "WEEKLY":
      return CohortsRange_Granularity.WEEKLY;
    case 3:
    case "MONTHLY":
      return CohortsRange_Granularity.MONTHLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CohortsRange_Granularity.UNRECOGNIZED;
  }
}

export function cohortsRange_GranularityToJSON(object: CohortsRange_Granularity): string {
  switch (object) {
    case CohortsRange_Granularity.GRANULARITY_UNSPECIFIED:
      return "GRANULARITY_UNSPECIFIED";
    case CohortsRange_Granularity.DAILY:
      return "DAILY";
    case CohortsRange_Granularity.WEEKLY:
      return "WEEKLY";
    case CohortsRange_Granularity.MONTHLY:
      return "MONTHLY";
    case CohortsRange_Granularity.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Optional settings of a cohort report. */
export interface CohortReportSettings {
  /**
   * If true, accumulates the result from first touch day to the end day. Not
   * supported in `RunReportRequest`.
   */
  accumulate: boolean;
}

/** Response's metadata carrying additional information about the report content. */
export interface ResponseMetaData {
  /**
   * If true, indicates some buckets of dimension combinations are rolled into
   * "(other)" row. This can happen for high cardinality reports.
   *
   * The metadata parameter dataLossFromOtherRow is populated based on the
   * aggregated data table used in the report. The parameter will be accurately
   * populated regardless of the filters and limits in the report.
   *
   * For example, the (other) row could be dropped from the report because the
   * request contains a filter on sessionSource = google. This parameter will
   * still be populated if data loss from other row was present in the input
   * aggregate data used to generate this report.
   *
   * To learn more, see [About the (other) row and data
   * sampling](https://support.google.com/analytics/answer/13208658#reports).
   */
  dataLossFromOtherRow: boolean;
  /**
   * Describes the schema restrictions actively enforced in creating this
   * report. To learn more, see [Access and data-restriction
   * management](https://support.google.com/analytics/answer/10851388).
   */
  schemaRestrictionResponse?:
    | ResponseMetaData_SchemaRestrictionResponse
    | undefined;
  /**
   * The currency code used in this report. Intended to be used in formatting
   * currency metrics like `purchaseRevenue` for visualization. If currency_code
   * was specified in the request, this response parameter will echo the request
   * parameter; otherwise, this response parameter is the property's current
   * currency_code.
   *
   * Currency codes are string encodings of currency types from the ISO 4217
   * standard (https://en.wikipedia.org/wiki/ISO_4217); for example "USD",
   * "EUR", "JPY". To learn more, see
   * https://support.google.com/analytics/answer/9796179.
   */
  currencyCode?:
    | string
    | undefined;
  /**
   * The property's current timezone. Intended to be used to interpret
   * time-based dimensions like `hour` and `minute`. Formatted as strings from
   * the IANA Time Zone database (https://www.iana.org/time-zones); for example
   * "America/New_York" or "Asia/Tokyo".
   */
  timeZone?:
    | string
    | undefined;
  /** If empty reason is specified, the report is empty for this reason. */
  emptyReason?:
    | string
    | undefined;
  /**
   * If `subjectToThresholding` is true, this report is subject to thresholding
   * and only returns data that meets the minimum aggregation thresholds. It is
   * possible for a request to be subject to thresholding thresholding and no
   * data is absent from the report, and this happens when all data is above the
   * thresholds. To learn more, see [Data
   * thresholds](https://support.google.com/analytics/answer/9383630).
   */
  subjectToThresholding?:
    | boolean
    | undefined;
  /**
   * If this report results is
   * [sampled](https://support.google.com/analytics/answer/13331292), this
   * describes the percentage of events used in this report. One
   * `samplingMetadatas` is populated for each date range. Each
   * `samplingMetadatas` corresponds to a date range in order that date ranges
   * were specified in the request.
   *
   * However if the results are not sampled, this field will not be defined.
   */
  samplingMetadatas: SamplingMetadata[];
}

/**
 * The schema restrictions actively enforced in creating this report. To learn
 * more, see [Access and data-restriction
 * management](https://support.google.com/analytics/answer/10851388).
 */
export interface ResponseMetaData_SchemaRestrictionResponse {
  /**
   * All restrictions actively enforced in creating the report. For example,
   * `purchaseRevenue` always has the restriction type `REVENUE_DATA`.
   * However, this active response restriction is only populated if the user's
   * custom role disallows access to `REVENUE_DATA`.
   */
  activeMetricRestrictions: ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction[];
}

/** A metric actively restricted in creating the report. */
export interface ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction {
  /** The name of the restricted metric. */
  metricName?:
    | string
    | undefined;
  /** The reason for this metric's restriction. */
  restrictedMetricTypes: RestrictedMetricType[];
}

/**
 * If this report results is
 * [sampled](https://support.google.com/analytics/answer/13331292), this
 * describes the percentage of events used in this report. Sampling is the
 * practice of analyzing a subset of all data in order to uncover the meaningful
 * information in the larger data set.
 */
export interface SamplingMetadata {
  /**
   * The total number of events read in this sampled report for a date range.
   * This is the size of the subset this property's data that was analyzed in
   * this report.
   */
  samplesReadCount: Long;
  /**
   * The total number of events present in this property's data that could
   * have been analyzed in this report for a date range. Sampling
   * uncovers the meaningful information about the larger data set, and this
   * is the size of the larger data set.
   *
   * To calculate the percentage of available data that was used in this
   * report, compute `samplesReadCount/samplingSpaceSize`.
   */
  samplingSpaceSize: Long;
}

/**
 * Describes a dimension column in the report. Dimensions requested in a report
 * produce column entries within rows and DimensionHeaders. However, dimensions
 * used exclusively within filters or expressions do not produce columns in a
 * report; correspondingly, those dimensions do not produce headers.
 */
export interface DimensionHeader {
  /** The dimension's name. */
  name: string;
}

/**
 * Describes a metric column in the report. Visible metrics requested in a
 * report produce column entries within rows and MetricHeaders. However,
 * metrics used exclusively within filters or expressions do not produce columns
 * in a report; correspondingly, those metrics do not produce headers.
 */
export interface MetricHeader {
  /** The metric's name. */
  name: string;
  /** The metric's data type. */
  type: MetricType;
}

/** Dimensions' values in a single pivot. */
export interface PivotHeader {
  /**
   * The size is the same as the cardinality of the corresponding dimension
   * combinations.
   */
  pivotDimensionHeaders: PivotDimensionHeader[];
  /**
   * The cardinality of the pivot. The total number of rows for this pivot's
   * fields regardless of how the parameters `offset` and `limit` are specified
   * in the request.
   */
  rowCount: number;
}

/** Summarizes dimension values from a row for this pivot. */
export interface PivotDimensionHeader {
  /** Values of multiple dimensions in a pivot. */
  dimensionValues: DimensionValue[];
}

/**
 * Report data for each row.
 * For example if RunReportRequest contains:
 *
 * ```none
 * "dimensions": [
 *   {
 *     "name": "eventName"
 *   },
 *   {
 *     "name": "countryId"
 *   }
 * ],
 * "metrics": [
 *   {
 *     "name": "eventCount"
 *   }
 * ]
 * ```
 *
 * One row with 'in_app_purchase' as the eventName, 'JP' as the countryId, and
 * 15 as the eventCount, would be:
 *
 * ```none
 * "dimensionValues": [
 *   {
 *     "value": "in_app_purchase"
 *   },
 *   {
 *     "value": "JP"
 *   }
 * ],
 * "metricValues": [
 *   {
 *     "value": "15"
 *   }
 * ]
 * ```
 */
export interface Row {
  /**
   * List of requested dimension values. In a PivotReport, dimension_values
   * are only listed for dimensions included in a pivot.
   */
  dimensionValues: DimensionValue[];
  /** List of requested visible metric values. */
  metricValues: MetricValue[];
}

/** The value of a dimension. */
export interface DimensionValue {
  /** Value as a string if the dimension type is a string. */
  value?: string | undefined;
}

/** The value of a metric. */
export interface MetricValue {
  /** Measurement value. See MetricHeader for type. */
  value?: string | undefined;
}

/** To represent a number. */
export interface NumericValue {
  /** Integer value */
  int64Value?:
    | Long
    | undefined;
  /** Double value */
  doubleValue?: number | undefined;
}

/**
 * Current state of all quotas for this Analytics Property. If any quota for a
 * property is exhausted, all requests to that property will return Resource
 * Exhausted errors.
 */
export interface PropertyQuota {
  /**
   * Standard Analytics Properties can use up to 200,000 tokens per day;
   * Analytics 360 Properties can use 2,000,000 tokens per day. Most requests
   * consume fewer than 10 tokens.
   */
  tokensPerDay:
    | QuotaStatus
    | undefined;
  /**
   * Standard Analytics Properties can use up to 40,000 tokens per hour;
   * Analytics 360 Properties can use 400,000 tokens per hour. An API request
   * consumes a single number of tokens, and that number is deducted from all of
   * the hourly, daily, and per project hourly quotas.
   */
  tokensPerHour:
    | QuotaStatus
    | undefined;
  /**
   * Standard Analytics Properties can send up to 10 concurrent requests;
   * Analytics 360 Properties can use up to 50 concurrent requests.
   */
  concurrentRequests:
    | QuotaStatus
    | undefined;
  /**
   * Standard Analytics Properties and cloud project pairs can have up to 10
   * server errors per hour; Analytics 360 Properties and cloud project pairs
   * can have up to 50 server errors per hour.
   */
  serverErrorsPerProjectPerHour:
    | QuotaStatus
    | undefined;
  /**
   * Analytics Properties can send up to 120 requests with potentially
   * thresholded dimensions per hour. In a batch request, each report request
   * is individually counted for this quota if the request contains potentially
   * thresholded dimensions.
   */
  potentiallyThresholdedRequestsPerHour:
    | QuotaStatus
    | undefined;
  /**
   * Analytics Properties can use up to 35% of their tokens per project per
   * hour. This amounts to standard Analytics Properties can use up to 14,000
   * tokens per project per hour, and Analytics 360 Properties can use 140,000
   * tokens per project per hour. An API request consumes a single number of
   * tokens, and that number is deducted from all of the hourly, daily, and per
   * project hourly quotas.
   */
  tokensPerProjectPerHour: QuotaStatus | undefined;
}

/** Current state for a particular quota group. */
export interface QuotaStatus {
  /** Quota consumed by this request. */
  consumed?:
    | number
    | undefined;
  /** Quota remaining after this request. */
  remaining?: number | undefined;
}

/** Explains a dimension. */
export interface DimensionMetadata {
  /**
   * This dimension's name. Useable in [Dimension](#Dimension)'s `name`. For
   * example, `eventName`.
   */
  apiName: string;
  /**
   * This dimension's name within the Google Analytics user interface. For
   * example, `Event name`.
   */
  uiName: string;
  /** Description of how this dimension is used and calculated. */
  description: string;
  /**
   * Still usable but deprecated names for this dimension. If populated, this
   * dimension is available by either `apiName` or one of `deprecatedApiNames`
   * for a period of time. After the deprecation period, the dimension will be
   * available only by `apiName`.
   */
  deprecatedApiNames: string[];
  /**
   * True if the dimension is custom to this property. This includes user,
   * event, & item scoped custom dimensions; to learn more about custom
   * dimensions, see https://support.google.com/analytics/answer/14240153. This
   * also include custom channel groups; to learn more about custom channel
   * groups, see https://support.google.com/analytics/answer/13051316.
   */
  customDefinition: boolean;
  /**
   * The display name of the category that this dimension belongs to. Similar
   * dimensions and metrics are categorized together.
   */
  category: string;
}

/** Explains a metric. */
export interface MetricMetadata {
  /**
   * A metric name. Useable in [Metric](#Metric)'s `name`. For example,
   * `eventCount`.
   */
  apiName: string;
  /**
   * This metric's name within the Google Analytics user interface. For example,
   * `Event count`.
   */
  uiName: string;
  /** Description of how this metric is used and calculated. */
  description: string;
  /**
   * Still usable but deprecated names for this metric. If populated, this
   * metric is available by either `apiName` or one of `deprecatedApiNames`
   * for a period of time. After the deprecation period, the metric will be
   * available only by `apiName`.
   */
  deprecatedApiNames: string[];
  /** The type of this metric. */
  type: MetricType;
  /**
   * The mathematical expression for this derived metric. Can be used in
   * [Metric](#Metric)'s `expression` field for equivalent reports. Most metrics
   * are not expressions, and for non-expressions, this field is empty.
   */
  expression: string;
  /** True if the metric is a custom metric for this property. */
  customDefinition: boolean;
  /**
   * If reasons are specified, your access is blocked to this metric for this
   * property. API requests from you to this property for this metric will
   * succeed; however, the report will contain only zeros for this metric. API
   * requests with metric filters on blocked metrics will fail. If reasons are
   * empty, you have access to this metric.
   *
   * To learn more, see [Access and data-restriction
   * management](https://support.google.com/analytics/answer/10851388).
   */
  blockedReasons: MetricMetadata_BlockedReason[];
  /**
   * The display name of the category that this metrics belongs to. Similar
   * dimensions and metrics are categorized together.
   */
  category: string;
}

/** Justifications for why this metric is blocked. */
export enum MetricMetadata_BlockedReason {
  /** BLOCKED_REASON_UNSPECIFIED - Will never be specified in API response. */
  BLOCKED_REASON_UNSPECIFIED = 0,
  /**
   * NO_REVENUE_METRICS - If present, your access is blocked to revenue related metrics for this
   * property, and this metric is revenue related.
   */
  NO_REVENUE_METRICS = 1,
  /**
   * NO_COST_METRICS - If present, your access is blocked to cost related metrics for this
   * property, and this metric is cost related.
   */
  NO_COST_METRICS = 2,
  UNRECOGNIZED = -1,
}

export function metricMetadata_BlockedReasonFromJSON(object: any): MetricMetadata_BlockedReason {
  switch (object) {
    case 0:
    case "BLOCKED_REASON_UNSPECIFIED":
      return MetricMetadata_BlockedReason.BLOCKED_REASON_UNSPECIFIED;
    case 1:
    case "NO_REVENUE_METRICS":
      return MetricMetadata_BlockedReason.NO_REVENUE_METRICS;
    case 2:
    case "NO_COST_METRICS":
      return MetricMetadata_BlockedReason.NO_COST_METRICS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetricMetadata_BlockedReason.UNRECOGNIZED;
  }
}

export function metricMetadata_BlockedReasonToJSON(object: MetricMetadata_BlockedReason): string {
  switch (object) {
    case MetricMetadata_BlockedReason.BLOCKED_REASON_UNSPECIFIED:
      return "BLOCKED_REASON_UNSPECIFIED";
    case MetricMetadata_BlockedReason.NO_REVENUE_METRICS:
      return "NO_REVENUE_METRICS";
    case MetricMetadata_BlockedReason.NO_COST_METRICS:
      return "NO_COST_METRICS";
    case MetricMetadata_BlockedReason.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The metadata for a single comparison. */
export interface ComparisonMetadata {
  /**
   * This comparison's resource name. Useable in [Comparison](#Comparison)'s
   * `comparison` field. For example, 'comparisons/1234'.
   */
  apiName: string;
  /** This comparison's name within the Google Analytics user interface. */
  uiName: string;
  /** This comparison's description. */
  description: string;
}

/** The compatibility for a single dimension. */
export interface DimensionCompatibility {
  /**
   * The dimension metadata contains the API name for this compatibility
   * information. The dimension metadata also contains other helpful information
   * like the UI name and description.
   */
  dimensionMetadata?:
    | DimensionMetadata
    | undefined;
  /**
   * The compatibility of this dimension. If the compatibility is COMPATIBLE,
   * this dimension can be successfully added to the report.
   */
  compatibility?: Compatibility | undefined;
}

/** The compatibility for a single metric. */
export interface MetricCompatibility {
  /**
   * The metric metadata contains the API name for this compatibility
   * information. The metric metadata also contains other helpful information
   * like the UI name and description.
   */
  metricMetadata?:
    | MetricMetadata
    | undefined;
  /**
   * The compatibility of this metric. If the compatibility is COMPATIBLE,
   * this metric can be successfully added to the report.
   */
  compatibility?: Compatibility | undefined;
}

function createBaseDateRange(): DateRange {
  return { startDate: "", endDate: "", name: "" };
}

export const DateRange: MessageFns<DateRange> = {
  encode(message: DateRange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startDate !== "") {
      writer.uint32(10).string(message.startDate);
    }
    if (message.endDate !== "") {
      writer.uint32(18).string(message.endDate);
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DateRange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDateRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startDate = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endDate = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DateRange {
    return {
      startDate: isSet(object.startDate) ? globalThis.String(object.startDate) : "",
      endDate: isSet(object.endDate) ? globalThis.String(object.endDate) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
    };
  },

  toJSON(message: DateRange): unknown {
    const obj: any = {};
    if (message.startDate !== "") {
      obj.startDate = message.startDate;
    }
    if (message.endDate !== "") {
      obj.endDate = message.endDate;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DateRange>): DateRange {
    return DateRange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DateRange>): DateRange {
    const message = createBaseDateRange();
    message.startDate = object.startDate ?? "";
    message.endDate = object.endDate ?? "";
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseMinuteRange(): MinuteRange {
  return { startMinutesAgo: undefined, endMinutesAgo: undefined, name: "" };
}

export const MinuteRange: MessageFns<MinuteRange> = {
  encode(message: MinuteRange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startMinutesAgo !== undefined) {
      writer.uint32(8).int32(message.startMinutesAgo);
    }
    if (message.endMinutesAgo !== undefined) {
      writer.uint32(16).int32(message.endMinutesAgo);
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MinuteRange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMinuteRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.startMinutesAgo = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.endMinutesAgo = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MinuteRange {
    return {
      startMinutesAgo: isSet(object.startMinutesAgo) ? globalThis.Number(object.startMinutesAgo) : undefined,
      endMinutesAgo: isSet(object.endMinutesAgo) ? globalThis.Number(object.endMinutesAgo) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
    };
  },

  toJSON(message: MinuteRange): unknown {
    const obj: any = {};
    if (message.startMinutesAgo !== undefined) {
      obj.startMinutesAgo = Math.round(message.startMinutesAgo);
    }
    if (message.endMinutesAgo !== undefined) {
      obj.endMinutesAgo = Math.round(message.endMinutesAgo);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<MinuteRange>): MinuteRange {
    return MinuteRange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MinuteRange>): MinuteRange {
    const message = createBaseMinuteRange();
    message.startMinutesAgo = object.startMinutesAgo ?? undefined;
    message.endMinutesAgo = object.endMinutesAgo ?? undefined;
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDimension(): Dimension {
  return { name: "", dimensionExpression: undefined };
}

export const Dimension: MessageFns<Dimension> = {
  encode(message: Dimension, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.dimensionExpression !== undefined) {
      DimensionExpression.encode(message.dimensionExpression, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Dimension {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimension();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dimensionExpression = DimensionExpression.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Dimension {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      dimensionExpression: isSet(object.dimensionExpression)
        ? DimensionExpression.fromJSON(object.dimensionExpression)
        : undefined,
    };
  },

  toJSON(message: Dimension): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.dimensionExpression !== undefined) {
      obj.dimensionExpression = DimensionExpression.toJSON(message.dimensionExpression);
    }
    return obj;
  },

  create(base?: DeepPartial<Dimension>): Dimension {
    return Dimension.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Dimension>): Dimension {
    const message = createBaseDimension();
    message.name = object.name ?? "";
    message.dimensionExpression = (object.dimensionExpression !== undefined && object.dimensionExpression !== null)
      ? DimensionExpression.fromPartial(object.dimensionExpression)
      : undefined;
    return message;
  },
};

function createBaseDimensionExpression(): DimensionExpression {
  return { lowerCase: undefined, upperCase: undefined, concatenate: undefined };
}

export const DimensionExpression: MessageFns<DimensionExpression> = {
  encode(message: DimensionExpression, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.lowerCase !== undefined) {
      DimensionExpression_CaseExpression.encode(message.lowerCase, writer.uint32(34).fork()).join();
    }
    if (message.upperCase !== undefined) {
      DimensionExpression_CaseExpression.encode(message.upperCase, writer.uint32(42).fork()).join();
    }
    if (message.concatenate !== undefined) {
      DimensionExpression_ConcatenateExpression.encode(message.concatenate, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionExpression {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionExpression();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lowerCase = DimensionExpression_CaseExpression.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.upperCase = DimensionExpression_CaseExpression.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.concatenate = DimensionExpression_ConcatenateExpression.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionExpression {
    return {
      lowerCase: isSet(object.lowerCase) ? DimensionExpression_CaseExpression.fromJSON(object.lowerCase) : undefined,
      upperCase: isSet(object.upperCase) ? DimensionExpression_CaseExpression.fromJSON(object.upperCase) : undefined,
      concatenate: isSet(object.concatenate)
        ? DimensionExpression_ConcatenateExpression.fromJSON(object.concatenate)
        : undefined,
    };
  },

  toJSON(message: DimensionExpression): unknown {
    const obj: any = {};
    if (message.lowerCase !== undefined) {
      obj.lowerCase = DimensionExpression_CaseExpression.toJSON(message.lowerCase);
    }
    if (message.upperCase !== undefined) {
      obj.upperCase = DimensionExpression_CaseExpression.toJSON(message.upperCase);
    }
    if (message.concatenate !== undefined) {
      obj.concatenate = DimensionExpression_ConcatenateExpression.toJSON(message.concatenate);
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionExpression>): DimensionExpression {
    return DimensionExpression.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DimensionExpression>): DimensionExpression {
    const message = createBaseDimensionExpression();
    message.lowerCase = (object.lowerCase !== undefined && object.lowerCase !== null)
      ? DimensionExpression_CaseExpression.fromPartial(object.lowerCase)
      : undefined;
    message.upperCase = (object.upperCase !== undefined && object.upperCase !== null)
      ? DimensionExpression_CaseExpression.fromPartial(object.upperCase)
      : undefined;
    message.concatenate = (object.concatenate !== undefined && object.concatenate !== null)
      ? DimensionExpression_ConcatenateExpression.fromPartial(object.concatenate)
      : undefined;
    return message;
  },
};

function createBaseDimensionExpression_CaseExpression(): DimensionExpression_CaseExpression {
  return { dimensionName: "" };
}

export const DimensionExpression_CaseExpression: MessageFns<DimensionExpression_CaseExpression> = {
  encode(message: DimensionExpression_CaseExpression, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dimensionName !== "") {
      writer.uint32(10).string(message.dimensionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionExpression_CaseExpression {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionExpression_CaseExpression();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionExpression_CaseExpression {
    return { dimensionName: isSet(object.dimensionName) ? globalThis.String(object.dimensionName) : "" };
  },

  toJSON(message: DimensionExpression_CaseExpression): unknown {
    const obj: any = {};
    if (message.dimensionName !== "") {
      obj.dimensionName = message.dimensionName;
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionExpression_CaseExpression>): DimensionExpression_CaseExpression {
    return DimensionExpression_CaseExpression.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DimensionExpression_CaseExpression>): DimensionExpression_CaseExpression {
    const message = createBaseDimensionExpression_CaseExpression();
    message.dimensionName = object.dimensionName ?? "";
    return message;
  },
};

function createBaseDimensionExpression_ConcatenateExpression(): DimensionExpression_ConcatenateExpression {
  return { dimensionNames: [], delimiter: "" };
}

export const DimensionExpression_ConcatenateExpression: MessageFns<DimensionExpression_ConcatenateExpression> = {
  encode(message: DimensionExpression_ConcatenateExpression, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dimensionNames) {
      writer.uint32(10).string(v!);
    }
    if (message.delimiter !== "") {
      writer.uint32(18).string(message.delimiter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionExpression_ConcatenateExpression {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionExpression_ConcatenateExpression();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionNames.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.delimiter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionExpression_ConcatenateExpression {
    return {
      dimensionNames: globalThis.Array.isArray(object?.dimensionNames)
        ? object.dimensionNames.map((e: any) => globalThis.String(e))
        : [],
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
    };
  },

  toJSON(message: DimensionExpression_ConcatenateExpression): unknown {
    const obj: any = {};
    if (message.dimensionNames?.length) {
      obj.dimensionNames = message.dimensionNames;
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionExpression_ConcatenateExpression>): DimensionExpression_ConcatenateExpression {
    return DimensionExpression_ConcatenateExpression.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DimensionExpression_ConcatenateExpression>,
  ): DimensionExpression_ConcatenateExpression {
    const message = createBaseDimensionExpression_ConcatenateExpression();
    message.dimensionNames = object.dimensionNames?.map((e) => e) || [];
    message.delimiter = object.delimiter ?? "";
    return message;
  },
};

function createBaseMetric(): Metric {
  return { name: "", expression: "", invisible: false };
}

export const Metric: MessageFns<Metric> = {
  encode(message: Metric, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.expression !== "") {
      writer.uint32(18).string(message.expression);
    }
    if (message.invisible !== false) {
      writer.uint32(24).bool(message.invisible);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Metric {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetric();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.expression = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.invisible = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Metric {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      expression: isSet(object.expression) ? globalThis.String(object.expression) : "",
      invisible: isSet(object.invisible) ? globalThis.Boolean(object.invisible) : false,
    };
  },

  toJSON(message: Metric): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.expression !== "") {
      obj.expression = message.expression;
    }
    if (message.invisible !== false) {
      obj.invisible = message.invisible;
    }
    return obj;
  },

  create(base?: DeepPartial<Metric>): Metric {
    return Metric.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Metric>): Metric {
    const message = createBaseMetric();
    message.name = object.name ?? "";
    message.expression = object.expression ?? "";
    message.invisible = object.invisible ?? false;
    return message;
  },
};

function createBaseComparison(): Comparison {
  return { name: undefined, dimensionFilter: undefined, comparison: undefined };
}

export const Comparison: MessageFns<Comparison> = {
  encode(message: Comparison, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== undefined) {
      writer.uint32(10).string(message.name);
    }
    if (message.dimensionFilter !== undefined) {
      FilterExpression.encode(message.dimensionFilter, writer.uint32(18).fork()).join();
    }
    if (message.comparison !== undefined) {
      writer.uint32(26).string(message.comparison);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Comparison {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComparison();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dimensionFilter = FilterExpression.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.comparison = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Comparison {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : undefined,
      dimensionFilter: isSet(object.dimensionFilter) ? FilterExpression.fromJSON(object.dimensionFilter) : undefined,
      comparison: isSet(object.comparison) ? globalThis.String(object.comparison) : undefined,
    };
  },

  toJSON(message: Comparison): unknown {
    const obj: any = {};
    if (message.name !== undefined) {
      obj.name = message.name;
    }
    if (message.dimensionFilter !== undefined) {
      obj.dimensionFilter = FilterExpression.toJSON(message.dimensionFilter);
    }
    if (message.comparison !== undefined) {
      obj.comparison = message.comparison;
    }
    return obj;
  },

  create(base?: DeepPartial<Comparison>): Comparison {
    return Comparison.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Comparison>): Comparison {
    const message = createBaseComparison();
    message.name = object.name ?? undefined;
    message.dimensionFilter = (object.dimensionFilter !== undefined && object.dimensionFilter !== null)
      ? FilterExpression.fromPartial(object.dimensionFilter)
      : undefined;
    message.comparison = object.comparison ?? undefined;
    return message;
  },
};

function createBaseFilterExpression(): FilterExpression {
  return { andGroup: undefined, orGroup: undefined, notExpression: undefined, filter: undefined };
}

export const FilterExpression: MessageFns<FilterExpression> = {
  encode(message: FilterExpression, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.andGroup !== undefined) {
      FilterExpressionList.encode(message.andGroup, writer.uint32(10).fork()).join();
    }
    if (message.orGroup !== undefined) {
      FilterExpressionList.encode(message.orGroup, writer.uint32(18).fork()).join();
    }
    if (message.notExpression !== undefined) {
      FilterExpression.encode(message.notExpression, writer.uint32(26).fork()).join();
    }
    if (message.filter !== undefined) {
      Filter.encode(message.filter, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FilterExpression {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilterExpression();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.andGroup = FilterExpressionList.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.orGroup = FilterExpressionList.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.notExpression = FilterExpression.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = Filter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FilterExpression {
    return {
      andGroup: isSet(object.andGroup) ? FilterExpressionList.fromJSON(object.andGroup) : undefined,
      orGroup: isSet(object.orGroup) ? FilterExpressionList.fromJSON(object.orGroup) : undefined,
      notExpression: isSet(object.notExpression) ? FilterExpression.fromJSON(object.notExpression) : undefined,
      filter: isSet(object.filter) ? Filter.fromJSON(object.filter) : undefined,
    };
  },

  toJSON(message: FilterExpression): unknown {
    const obj: any = {};
    if (message.andGroup !== undefined) {
      obj.andGroup = FilterExpressionList.toJSON(message.andGroup);
    }
    if (message.orGroup !== undefined) {
      obj.orGroup = FilterExpressionList.toJSON(message.orGroup);
    }
    if (message.notExpression !== undefined) {
      obj.notExpression = FilterExpression.toJSON(message.notExpression);
    }
    if (message.filter !== undefined) {
      obj.filter = Filter.toJSON(message.filter);
    }
    return obj;
  },

  create(base?: DeepPartial<FilterExpression>): FilterExpression {
    return FilterExpression.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FilterExpression>): FilterExpression {
    const message = createBaseFilterExpression();
    message.andGroup = (object.andGroup !== undefined && object.andGroup !== null)
      ? FilterExpressionList.fromPartial(object.andGroup)
      : undefined;
    message.orGroup = (object.orGroup !== undefined && object.orGroup !== null)
      ? FilterExpressionList.fromPartial(object.orGroup)
      : undefined;
    message.notExpression = (object.notExpression !== undefined && object.notExpression !== null)
      ? FilterExpression.fromPartial(object.notExpression)
      : undefined;
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? Filter.fromPartial(object.filter)
      : undefined;
    return message;
  },
};

function createBaseFilterExpressionList(): FilterExpressionList {
  return { expressions: [] };
}

export const FilterExpressionList: MessageFns<FilterExpressionList> = {
  encode(message: FilterExpressionList, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.expressions) {
      FilterExpression.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FilterExpressionList {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilterExpressionList();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.expressions.push(FilterExpression.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FilterExpressionList {
    return {
      expressions: globalThis.Array.isArray(object?.expressions)
        ? object.expressions.map((e: any) => FilterExpression.fromJSON(e))
        : [],
    };
  },

  toJSON(message: FilterExpressionList): unknown {
    const obj: any = {};
    if (message.expressions?.length) {
      obj.expressions = message.expressions.map((e) => FilterExpression.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<FilterExpressionList>): FilterExpressionList {
    return FilterExpressionList.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FilterExpressionList>): FilterExpressionList {
    const message = createBaseFilterExpressionList();
    message.expressions = object.expressions?.map((e) => FilterExpression.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFilter(): Filter {
  return {
    fieldName: "",
    stringFilter: undefined,
    inListFilter: undefined,
    numericFilter: undefined,
    betweenFilter: undefined,
  };
}

export const Filter: MessageFns<Filter> = {
  encode(message: Filter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fieldName !== "") {
      writer.uint32(10).string(message.fieldName);
    }
    if (message.stringFilter !== undefined) {
      Filter_StringFilter.encode(message.stringFilter, writer.uint32(26).fork()).join();
    }
    if (message.inListFilter !== undefined) {
      Filter_InListFilter.encode(message.inListFilter, writer.uint32(34).fork()).join();
    }
    if (message.numericFilter !== undefined) {
      Filter_NumericFilter.encode(message.numericFilter, writer.uint32(42).fork()).join();
    }
    if (message.betweenFilter !== undefined) {
      Filter_BetweenFilter.encode(message.betweenFilter, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Filter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fieldName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.stringFilter = Filter_StringFilter.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.inListFilter = Filter_InListFilter.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.numericFilter = Filter_NumericFilter.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.betweenFilter = Filter_BetweenFilter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Filter {
    return {
      fieldName: isSet(object.fieldName) ? globalThis.String(object.fieldName) : "",
      stringFilter: isSet(object.stringFilter) ? Filter_StringFilter.fromJSON(object.stringFilter) : undefined,
      inListFilter: isSet(object.inListFilter) ? Filter_InListFilter.fromJSON(object.inListFilter) : undefined,
      numericFilter: isSet(object.numericFilter) ? Filter_NumericFilter.fromJSON(object.numericFilter) : undefined,
      betweenFilter: isSet(object.betweenFilter) ? Filter_BetweenFilter.fromJSON(object.betweenFilter) : undefined,
    };
  },

  toJSON(message: Filter): unknown {
    const obj: any = {};
    if (message.fieldName !== "") {
      obj.fieldName = message.fieldName;
    }
    if (message.stringFilter !== undefined) {
      obj.stringFilter = Filter_StringFilter.toJSON(message.stringFilter);
    }
    if (message.inListFilter !== undefined) {
      obj.inListFilter = Filter_InListFilter.toJSON(message.inListFilter);
    }
    if (message.numericFilter !== undefined) {
      obj.numericFilter = Filter_NumericFilter.toJSON(message.numericFilter);
    }
    if (message.betweenFilter !== undefined) {
      obj.betweenFilter = Filter_BetweenFilter.toJSON(message.betweenFilter);
    }
    return obj;
  },

  create(base?: DeepPartial<Filter>): Filter {
    return Filter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Filter>): Filter {
    const message = createBaseFilter();
    message.fieldName = object.fieldName ?? "";
    message.stringFilter = (object.stringFilter !== undefined && object.stringFilter !== null)
      ? Filter_StringFilter.fromPartial(object.stringFilter)
      : undefined;
    message.inListFilter = (object.inListFilter !== undefined && object.inListFilter !== null)
      ? Filter_InListFilter.fromPartial(object.inListFilter)
      : undefined;
    message.numericFilter = (object.numericFilter !== undefined && object.numericFilter !== null)
      ? Filter_NumericFilter.fromPartial(object.numericFilter)
      : undefined;
    message.betweenFilter = (object.betweenFilter !== undefined && object.betweenFilter !== null)
      ? Filter_BetweenFilter.fromPartial(object.betweenFilter)
      : undefined;
    return message;
  },
};

function createBaseFilter_StringFilter(): Filter_StringFilter {
  return { matchType: 0, value: "", caseSensitive: false };
}

export const Filter_StringFilter: MessageFns<Filter_StringFilter> = {
  encode(message: Filter_StringFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.matchType !== 0) {
      writer.uint32(8).int32(message.matchType);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    if (message.caseSensitive !== false) {
      writer.uint32(24).bool(message.caseSensitive);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Filter_StringFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilter_StringFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.matchType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.caseSensitive = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Filter_StringFilter {
    return {
      matchType: isSet(object.matchType) ? filter_StringFilter_MatchTypeFromJSON(object.matchType) : 0,
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      caseSensitive: isSet(object.caseSensitive) ? globalThis.Boolean(object.caseSensitive) : false,
    };
  },

  toJSON(message: Filter_StringFilter): unknown {
    const obj: any = {};
    if (message.matchType !== 0) {
      obj.matchType = filter_StringFilter_MatchTypeToJSON(message.matchType);
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (message.caseSensitive !== false) {
      obj.caseSensitive = message.caseSensitive;
    }
    return obj;
  },

  create(base?: DeepPartial<Filter_StringFilter>): Filter_StringFilter {
    return Filter_StringFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Filter_StringFilter>): Filter_StringFilter {
    const message = createBaseFilter_StringFilter();
    message.matchType = object.matchType ?? 0;
    message.value = object.value ?? "";
    message.caseSensitive = object.caseSensitive ?? false;
    return message;
  },
};

function createBaseFilter_InListFilter(): Filter_InListFilter {
  return { values: [], caseSensitive: false };
}

export const Filter_InListFilter: MessageFns<Filter_InListFilter> = {
  encode(message: Filter_InListFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.values) {
      writer.uint32(10).string(v!);
    }
    if (message.caseSensitive !== false) {
      writer.uint32(16).bool(message.caseSensitive);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Filter_InListFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilter_InListFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.values.push(reader.string());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.caseSensitive = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Filter_InListFilter {
    return {
      values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => globalThis.String(e)) : [],
      caseSensitive: isSet(object.caseSensitive) ? globalThis.Boolean(object.caseSensitive) : false,
    };
  },

  toJSON(message: Filter_InListFilter): unknown {
    const obj: any = {};
    if (message.values?.length) {
      obj.values = message.values;
    }
    if (message.caseSensitive !== false) {
      obj.caseSensitive = message.caseSensitive;
    }
    return obj;
  },

  create(base?: DeepPartial<Filter_InListFilter>): Filter_InListFilter {
    return Filter_InListFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Filter_InListFilter>): Filter_InListFilter {
    const message = createBaseFilter_InListFilter();
    message.values = object.values?.map((e) => e) || [];
    message.caseSensitive = object.caseSensitive ?? false;
    return message;
  },
};

function createBaseFilter_NumericFilter(): Filter_NumericFilter {
  return { operation: 0, value: undefined };
}

export const Filter_NumericFilter: MessageFns<Filter_NumericFilter> = {
  encode(message: Filter_NumericFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operation !== 0) {
      writer.uint32(8).int32(message.operation);
    }
    if (message.value !== undefined) {
      NumericValue.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Filter_NumericFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilter_NumericFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.operation = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = NumericValue.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Filter_NumericFilter {
    return {
      operation: isSet(object.operation) ? filter_NumericFilter_OperationFromJSON(object.operation) : 0,
      value: isSet(object.value) ? NumericValue.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: Filter_NumericFilter): unknown {
    const obj: any = {};
    if (message.operation !== 0) {
      obj.operation = filter_NumericFilter_OperationToJSON(message.operation);
    }
    if (message.value !== undefined) {
      obj.value = NumericValue.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<Filter_NumericFilter>): Filter_NumericFilter {
    return Filter_NumericFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Filter_NumericFilter>): Filter_NumericFilter {
    const message = createBaseFilter_NumericFilter();
    message.operation = object.operation ?? 0;
    message.value = (object.value !== undefined && object.value !== null)
      ? NumericValue.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseFilter_BetweenFilter(): Filter_BetweenFilter {
  return { fromValue: undefined, toValue: undefined };
}

export const Filter_BetweenFilter: MessageFns<Filter_BetweenFilter> = {
  encode(message: Filter_BetweenFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fromValue !== undefined) {
      NumericValue.encode(message.fromValue, writer.uint32(10).fork()).join();
    }
    if (message.toValue !== undefined) {
      NumericValue.encode(message.toValue, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Filter_BetweenFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilter_BetweenFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fromValue = NumericValue.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.toValue = NumericValue.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Filter_BetweenFilter {
    return {
      fromValue: isSet(object.fromValue) ? NumericValue.fromJSON(object.fromValue) : undefined,
      toValue: isSet(object.toValue) ? NumericValue.fromJSON(object.toValue) : undefined,
    };
  },

  toJSON(message: Filter_BetweenFilter): unknown {
    const obj: any = {};
    if (message.fromValue !== undefined) {
      obj.fromValue = NumericValue.toJSON(message.fromValue);
    }
    if (message.toValue !== undefined) {
      obj.toValue = NumericValue.toJSON(message.toValue);
    }
    return obj;
  },

  create(base?: DeepPartial<Filter_BetweenFilter>): Filter_BetweenFilter {
    return Filter_BetweenFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Filter_BetweenFilter>): Filter_BetweenFilter {
    const message = createBaseFilter_BetweenFilter();
    message.fromValue = (object.fromValue !== undefined && object.fromValue !== null)
      ? NumericValue.fromPartial(object.fromValue)
      : undefined;
    message.toValue = (object.toValue !== undefined && object.toValue !== null)
      ? NumericValue.fromPartial(object.toValue)
      : undefined;
    return message;
  },
};

function createBaseOrderBy(): OrderBy {
  return { metric: undefined, dimension: undefined, pivot: undefined, desc: false };
}

export const OrderBy: MessageFns<OrderBy> = {
  encode(message: OrderBy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metric !== undefined) {
      OrderBy_MetricOrderBy.encode(message.metric, writer.uint32(10).fork()).join();
    }
    if (message.dimension !== undefined) {
      OrderBy_DimensionOrderBy.encode(message.dimension, writer.uint32(18).fork()).join();
    }
    if (message.pivot !== undefined) {
      OrderBy_PivotOrderBy.encode(message.pivot, writer.uint32(26).fork()).join();
    }
    if (message.desc !== false) {
      writer.uint32(32).bool(message.desc);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderBy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderBy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metric = OrderBy_MetricOrderBy.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dimension = OrderBy_DimensionOrderBy.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pivot = OrderBy_PivotOrderBy.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.desc = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderBy {
    return {
      metric: isSet(object.metric) ? OrderBy_MetricOrderBy.fromJSON(object.metric) : undefined,
      dimension: isSet(object.dimension) ? OrderBy_DimensionOrderBy.fromJSON(object.dimension) : undefined,
      pivot: isSet(object.pivot) ? OrderBy_PivotOrderBy.fromJSON(object.pivot) : undefined,
      desc: isSet(object.desc) ? globalThis.Boolean(object.desc) : false,
    };
  },

  toJSON(message: OrderBy): unknown {
    const obj: any = {};
    if (message.metric !== undefined) {
      obj.metric = OrderBy_MetricOrderBy.toJSON(message.metric);
    }
    if (message.dimension !== undefined) {
      obj.dimension = OrderBy_DimensionOrderBy.toJSON(message.dimension);
    }
    if (message.pivot !== undefined) {
      obj.pivot = OrderBy_PivotOrderBy.toJSON(message.pivot);
    }
    if (message.desc !== false) {
      obj.desc = message.desc;
    }
    return obj;
  },

  create(base?: DeepPartial<OrderBy>): OrderBy {
    return OrderBy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderBy>): OrderBy {
    const message = createBaseOrderBy();
    message.metric = (object.metric !== undefined && object.metric !== null)
      ? OrderBy_MetricOrderBy.fromPartial(object.metric)
      : undefined;
    message.dimension = (object.dimension !== undefined && object.dimension !== null)
      ? OrderBy_DimensionOrderBy.fromPartial(object.dimension)
      : undefined;
    message.pivot = (object.pivot !== undefined && object.pivot !== null)
      ? OrderBy_PivotOrderBy.fromPartial(object.pivot)
      : undefined;
    message.desc = object.desc ?? false;
    return message;
  },
};

function createBaseOrderBy_MetricOrderBy(): OrderBy_MetricOrderBy {
  return { metricName: "" };
}

export const OrderBy_MetricOrderBy: MessageFns<OrderBy_MetricOrderBy> = {
  encode(message: OrderBy_MetricOrderBy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metricName !== "") {
      writer.uint32(10).string(message.metricName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderBy_MetricOrderBy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderBy_MetricOrderBy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metricName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderBy_MetricOrderBy {
    return { metricName: isSet(object.metricName) ? globalThis.String(object.metricName) : "" };
  },

  toJSON(message: OrderBy_MetricOrderBy): unknown {
    const obj: any = {};
    if (message.metricName !== "") {
      obj.metricName = message.metricName;
    }
    return obj;
  },

  create(base?: DeepPartial<OrderBy_MetricOrderBy>): OrderBy_MetricOrderBy {
    return OrderBy_MetricOrderBy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderBy_MetricOrderBy>): OrderBy_MetricOrderBy {
    const message = createBaseOrderBy_MetricOrderBy();
    message.metricName = object.metricName ?? "";
    return message;
  },
};

function createBaseOrderBy_DimensionOrderBy(): OrderBy_DimensionOrderBy {
  return { dimensionName: "", orderType: 0 };
}

export const OrderBy_DimensionOrderBy: MessageFns<OrderBy_DimensionOrderBy> = {
  encode(message: OrderBy_DimensionOrderBy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dimensionName !== "") {
      writer.uint32(10).string(message.dimensionName);
    }
    if (message.orderType !== 0) {
      writer.uint32(16).int32(message.orderType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderBy_DimensionOrderBy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderBy_DimensionOrderBy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionName = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.orderType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderBy_DimensionOrderBy {
    return {
      dimensionName: isSet(object.dimensionName) ? globalThis.String(object.dimensionName) : "",
      orderType: isSet(object.orderType) ? orderBy_DimensionOrderBy_OrderTypeFromJSON(object.orderType) : 0,
    };
  },

  toJSON(message: OrderBy_DimensionOrderBy): unknown {
    const obj: any = {};
    if (message.dimensionName !== "") {
      obj.dimensionName = message.dimensionName;
    }
    if (message.orderType !== 0) {
      obj.orderType = orderBy_DimensionOrderBy_OrderTypeToJSON(message.orderType);
    }
    return obj;
  },

  create(base?: DeepPartial<OrderBy_DimensionOrderBy>): OrderBy_DimensionOrderBy {
    return OrderBy_DimensionOrderBy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderBy_DimensionOrderBy>): OrderBy_DimensionOrderBy {
    const message = createBaseOrderBy_DimensionOrderBy();
    message.dimensionName = object.dimensionName ?? "";
    message.orderType = object.orderType ?? 0;
    return message;
  },
};

function createBaseOrderBy_PivotOrderBy(): OrderBy_PivotOrderBy {
  return { metricName: "", pivotSelections: [] };
}

export const OrderBy_PivotOrderBy: MessageFns<OrderBy_PivotOrderBy> = {
  encode(message: OrderBy_PivotOrderBy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metricName !== "") {
      writer.uint32(10).string(message.metricName);
    }
    for (const v of message.pivotSelections) {
      OrderBy_PivotOrderBy_PivotSelection.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderBy_PivotOrderBy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderBy_PivotOrderBy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metricName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pivotSelections.push(OrderBy_PivotOrderBy_PivotSelection.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderBy_PivotOrderBy {
    return {
      metricName: isSet(object.metricName) ? globalThis.String(object.metricName) : "",
      pivotSelections: globalThis.Array.isArray(object?.pivotSelections)
        ? object.pivotSelections.map((e: any) => OrderBy_PivotOrderBy_PivotSelection.fromJSON(e))
        : [],
    };
  },

  toJSON(message: OrderBy_PivotOrderBy): unknown {
    const obj: any = {};
    if (message.metricName !== "") {
      obj.metricName = message.metricName;
    }
    if (message.pivotSelections?.length) {
      obj.pivotSelections = message.pivotSelections.map((e) => OrderBy_PivotOrderBy_PivotSelection.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<OrderBy_PivotOrderBy>): OrderBy_PivotOrderBy {
    return OrderBy_PivotOrderBy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderBy_PivotOrderBy>): OrderBy_PivotOrderBy {
    const message = createBaseOrderBy_PivotOrderBy();
    message.metricName = object.metricName ?? "";
    message.pivotSelections = object.pivotSelections?.map((e) => OrderBy_PivotOrderBy_PivotSelection.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseOrderBy_PivotOrderBy_PivotSelection(): OrderBy_PivotOrderBy_PivotSelection {
  return { dimensionName: "", dimensionValue: "" };
}

export const OrderBy_PivotOrderBy_PivotSelection: MessageFns<OrderBy_PivotOrderBy_PivotSelection> = {
  encode(message: OrderBy_PivotOrderBy_PivotSelection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dimensionName !== "") {
      writer.uint32(10).string(message.dimensionName);
    }
    if (message.dimensionValue !== "") {
      writer.uint32(18).string(message.dimensionValue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderBy_PivotOrderBy_PivotSelection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderBy_PivotOrderBy_PivotSelection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dimensionValue = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderBy_PivotOrderBy_PivotSelection {
    return {
      dimensionName: isSet(object.dimensionName) ? globalThis.String(object.dimensionName) : "",
      dimensionValue: isSet(object.dimensionValue) ? globalThis.String(object.dimensionValue) : "",
    };
  },

  toJSON(message: OrderBy_PivotOrderBy_PivotSelection): unknown {
    const obj: any = {};
    if (message.dimensionName !== "") {
      obj.dimensionName = message.dimensionName;
    }
    if (message.dimensionValue !== "") {
      obj.dimensionValue = message.dimensionValue;
    }
    return obj;
  },

  create(base?: DeepPartial<OrderBy_PivotOrderBy_PivotSelection>): OrderBy_PivotOrderBy_PivotSelection {
    return OrderBy_PivotOrderBy_PivotSelection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderBy_PivotOrderBy_PivotSelection>): OrderBy_PivotOrderBy_PivotSelection {
    const message = createBaseOrderBy_PivotOrderBy_PivotSelection();
    message.dimensionName = object.dimensionName ?? "";
    message.dimensionValue = object.dimensionValue ?? "";
    return message;
  },
};

function createBasePivot(): Pivot {
  return { fieldNames: [], orderBys: [], offset: Long.ZERO, limit: Long.ZERO, metricAggregations: [] };
}

export const Pivot: MessageFns<Pivot> = {
  encode(message: Pivot, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fieldNames) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.orderBys) {
      OrderBy.encode(v!, writer.uint32(18).fork()).join();
    }
    if (!message.offset.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.offset.toString());
    }
    if (!message.limit.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.limit.toString());
    }
    writer.uint32(42).fork();
    for (const v of message.metricAggregations) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Pivot {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePivot();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fieldNames.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.orderBys.push(OrderBy.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.offset = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.limit = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag === 40) {
            message.metricAggregations.push(reader.int32() as any);

            continue;
          }

          if (tag === 42) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.metricAggregations.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Pivot {
    return {
      fieldNames: globalThis.Array.isArray(object?.fieldNames)
        ? object.fieldNames.map((e: any) => globalThis.String(e))
        : [],
      orderBys: globalThis.Array.isArray(object?.orderBys) ? object.orderBys.map((e: any) => OrderBy.fromJSON(e)) : [],
      offset: isSet(object.offset) ? Long.fromValue(object.offset) : Long.ZERO,
      limit: isSet(object.limit) ? Long.fromValue(object.limit) : Long.ZERO,
      metricAggregations: globalThis.Array.isArray(object?.metricAggregations)
        ? object.metricAggregations.map((e: any) => metricAggregationFromJSON(e))
        : [],
    };
  },

  toJSON(message: Pivot): unknown {
    const obj: any = {};
    if (message.fieldNames?.length) {
      obj.fieldNames = message.fieldNames;
    }
    if (message.orderBys?.length) {
      obj.orderBys = message.orderBys.map((e) => OrderBy.toJSON(e));
    }
    if (!message.offset.equals(Long.ZERO)) {
      obj.offset = (message.offset || Long.ZERO).toString();
    }
    if (!message.limit.equals(Long.ZERO)) {
      obj.limit = (message.limit || Long.ZERO).toString();
    }
    if (message.metricAggregations?.length) {
      obj.metricAggregations = message.metricAggregations.map((e) => metricAggregationToJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Pivot>): Pivot {
    return Pivot.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Pivot>): Pivot {
    const message = createBasePivot();
    message.fieldNames = object.fieldNames?.map((e) => e) || [];
    message.orderBys = object.orderBys?.map((e) => OrderBy.fromPartial(e)) || [];
    message.offset = (object.offset !== undefined && object.offset !== null)
      ? Long.fromValue(object.offset)
      : Long.ZERO;
    message.limit = (object.limit !== undefined && object.limit !== null) ? Long.fromValue(object.limit) : Long.ZERO;
    message.metricAggregations = object.metricAggregations?.map((e) => e) || [];
    return message;
  },
};

function createBaseCohortSpec(): CohortSpec {
  return { cohorts: [], cohortsRange: undefined, cohortReportSettings: undefined };
}

export const CohortSpec: MessageFns<CohortSpec> = {
  encode(message: CohortSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.cohorts) {
      Cohort.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.cohortsRange !== undefined) {
      CohortsRange.encode(message.cohortsRange, writer.uint32(18).fork()).join();
    }
    if (message.cohortReportSettings !== undefined) {
      CohortReportSettings.encode(message.cohortReportSettings, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CohortSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCohortSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cohorts.push(Cohort.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cohortsRange = CohortsRange.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cohortReportSettings = CohortReportSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CohortSpec {
    return {
      cohorts: globalThis.Array.isArray(object?.cohorts) ? object.cohorts.map((e: any) => Cohort.fromJSON(e)) : [],
      cohortsRange: isSet(object.cohortsRange) ? CohortsRange.fromJSON(object.cohortsRange) : undefined,
      cohortReportSettings: isSet(object.cohortReportSettings)
        ? CohortReportSettings.fromJSON(object.cohortReportSettings)
        : undefined,
    };
  },

  toJSON(message: CohortSpec): unknown {
    const obj: any = {};
    if (message.cohorts?.length) {
      obj.cohorts = message.cohorts.map((e) => Cohort.toJSON(e));
    }
    if (message.cohortsRange !== undefined) {
      obj.cohortsRange = CohortsRange.toJSON(message.cohortsRange);
    }
    if (message.cohortReportSettings !== undefined) {
      obj.cohortReportSettings = CohortReportSettings.toJSON(message.cohortReportSettings);
    }
    return obj;
  },

  create(base?: DeepPartial<CohortSpec>): CohortSpec {
    return CohortSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CohortSpec>): CohortSpec {
    const message = createBaseCohortSpec();
    message.cohorts = object.cohorts?.map((e) => Cohort.fromPartial(e)) || [];
    message.cohortsRange = (object.cohortsRange !== undefined && object.cohortsRange !== null)
      ? CohortsRange.fromPartial(object.cohortsRange)
      : undefined;
    message.cohortReportSettings = (object.cohortReportSettings !== undefined && object.cohortReportSettings !== null)
      ? CohortReportSettings.fromPartial(object.cohortReportSettings)
      : undefined;
    return message;
  },
};

function createBaseCohort(): Cohort {
  return { name: "", dimension: "", dateRange: undefined };
}

export const Cohort: MessageFns<Cohort> = {
  encode(message: Cohort, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.dimension !== "") {
      writer.uint32(18).string(message.dimension);
    }
    if (message.dateRange !== undefined) {
      DateRange.encode(message.dateRange, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Cohort {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCohort();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dimension = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.dateRange = DateRange.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Cohort {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      dimension: isSet(object.dimension) ? globalThis.String(object.dimension) : "",
      dateRange: isSet(object.dateRange) ? DateRange.fromJSON(object.dateRange) : undefined,
    };
  },

  toJSON(message: Cohort): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.dimension !== "") {
      obj.dimension = message.dimension;
    }
    if (message.dateRange !== undefined) {
      obj.dateRange = DateRange.toJSON(message.dateRange);
    }
    return obj;
  },

  create(base?: DeepPartial<Cohort>): Cohort {
    return Cohort.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Cohort>): Cohort {
    const message = createBaseCohort();
    message.name = object.name ?? "";
    message.dimension = object.dimension ?? "";
    message.dateRange = (object.dateRange !== undefined && object.dateRange !== null)
      ? DateRange.fromPartial(object.dateRange)
      : undefined;
    return message;
  },
};

function createBaseCohortsRange(): CohortsRange {
  return { granularity: 0, startOffset: 0, endOffset: 0 };
}

export const CohortsRange: MessageFns<CohortsRange> = {
  encode(message: CohortsRange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.granularity !== 0) {
      writer.uint32(8).int32(message.granularity);
    }
    if (message.startOffset !== 0) {
      writer.uint32(16).int32(message.startOffset);
    }
    if (message.endOffset !== 0) {
      writer.uint32(24).int32(message.endOffset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CohortsRange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCohortsRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.granularity = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.startOffset = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.endOffset = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CohortsRange {
    return {
      granularity: isSet(object.granularity) ? cohortsRange_GranularityFromJSON(object.granularity) : 0,
      startOffset: isSet(object.startOffset) ? globalThis.Number(object.startOffset) : 0,
      endOffset: isSet(object.endOffset) ? globalThis.Number(object.endOffset) : 0,
    };
  },

  toJSON(message: CohortsRange): unknown {
    const obj: any = {};
    if (message.granularity !== 0) {
      obj.granularity = cohortsRange_GranularityToJSON(message.granularity);
    }
    if (message.startOffset !== 0) {
      obj.startOffset = Math.round(message.startOffset);
    }
    if (message.endOffset !== 0) {
      obj.endOffset = Math.round(message.endOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<CohortsRange>): CohortsRange {
    return CohortsRange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CohortsRange>): CohortsRange {
    const message = createBaseCohortsRange();
    message.granularity = object.granularity ?? 0;
    message.startOffset = object.startOffset ?? 0;
    message.endOffset = object.endOffset ?? 0;
    return message;
  },
};

function createBaseCohortReportSettings(): CohortReportSettings {
  return { accumulate: false };
}

export const CohortReportSettings: MessageFns<CohortReportSettings> = {
  encode(message: CohortReportSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accumulate !== false) {
      writer.uint32(8).bool(message.accumulate);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CohortReportSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCohortReportSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.accumulate = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CohortReportSettings {
    return { accumulate: isSet(object.accumulate) ? globalThis.Boolean(object.accumulate) : false };
  },

  toJSON(message: CohortReportSettings): unknown {
    const obj: any = {};
    if (message.accumulate !== false) {
      obj.accumulate = message.accumulate;
    }
    return obj;
  },

  create(base?: DeepPartial<CohortReportSettings>): CohortReportSettings {
    return CohortReportSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CohortReportSettings>): CohortReportSettings {
    const message = createBaseCohortReportSettings();
    message.accumulate = object.accumulate ?? false;
    return message;
  },
};

function createBaseResponseMetaData(): ResponseMetaData {
  return {
    dataLossFromOtherRow: false,
    schemaRestrictionResponse: undefined,
    currencyCode: undefined,
    timeZone: undefined,
    emptyReason: undefined,
    subjectToThresholding: undefined,
    samplingMetadatas: [],
  };
}

export const ResponseMetaData: MessageFns<ResponseMetaData> = {
  encode(message: ResponseMetaData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataLossFromOtherRow !== false) {
      writer.uint32(24).bool(message.dataLossFromOtherRow);
    }
    if (message.schemaRestrictionResponse !== undefined) {
      ResponseMetaData_SchemaRestrictionResponse.encode(message.schemaRestrictionResponse, writer.uint32(34).fork())
        .join();
    }
    if (message.currencyCode !== undefined) {
      writer.uint32(42).string(message.currencyCode);
    }
    if (message.timeZone !== undefined) {
      writer.uint32(50).string(message.timeZone);
    }
    if (message.emptyReason !== undefined) {
      writer.uint32(58).string(message.emptyReason);
    }
    if (message.subjectToThresholding !== undefined) {
      writer.uint32(64).bool(message.subjectToThresholding);
    }
    for (const v of message.samplingMetadatas) {
      SamplingMetadata.encode(v!, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ResponseMetaData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResponseMetaData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 24) {
            break;
          }

          message.dataLossFromOtherRow = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.schemaRestrictionResponse = ResponseMetaData_SchemaRestrictionResponse.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.currencyCode = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.timeZone = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.emptyReason = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.subjectToThresholding = reader.bool();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.samplingMetadatas.push(SamplingMetadata.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ResponseMetaData {
    return {
      dataLossFromOtherRow: isSet(object.dataLossFromOtherRow)
        ? globalThis.Boolean(object.dataLossFromOtherRow)
        : false,
      schemaRestrictionResponse: isSet(object.schemaRestrictionResponse)
        ? ResponseMetaData_SchemaRestrictionResponse.fromJSON(object.schemaRestrictionResponse)
        : undefined,
      currencyCode: isSet(object.currencyCode) ? globalThis.String(object.currencyCode) : undefined,
      timeZone: isSet(object.timeZone) ? globalThis.String(object.timeZone) : undefined,
      emptyReason: isSet(object.emptyReason) ? globalThis.String(object.emptyReason) : undefined,
      subjectToThresholding: isSet(object.subjectToThresholding)
        ? globalThis.Boolean(object.subjectToThresholding)
        : undefined,
      samplingMetadatas: globalThis.Array.isArray(object?.samplingMetadatas)
        ? object.samplingMetadatas.map((e: any) => SamplingMetadata.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ResponseMetaData): unknown {
    const obj: any = {};
    if (message.dataLossFromOtherRow !== false) {
      obj.dataLossFromOtherRow = message.dataLossFromOtherRow;
    }
    if (message.schemaRestrictionResponse !== undefined) {
      obj.schemaRestrictionResponse = ResponseMetaData_SchemaRestrictionResponse.toJSON(
        message.schemaRestrictionResponse,
      );
    }
    if (message.currencyCode !== undefined) {
      obj.currencyCode = message.currencyCode;
    }
    if (message.timeZone !== undefined) {
      obj.timeZone = message.timeZone;
    }
    if (message.emptyReason !== undefined) {
      obj.emptyReason = message.emptyReason;
    }
    if (message.subjectToThresholding !== undefined) {
      obj.subjectToThresholding = message.subjectToThresholding;
    }
    if (message.samplingMetadatas?.length) {
      obj.samplingMetadatas = message.samplingMetadatas.map((e) => SamplingMetadata.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ResponseMetaData>): ResponseMetaData {
    return ResponseMetaData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ResponseMetaData>): ResponseMetaData {
    const message = createBaseResponseMetaData();
    message.dataLossFromOtherRow = object.dataLossFromOtherRow ?? false;
    message.schemaRestrictionResponse =
      (object.schemaRestrictionResponse !== undefined && object.schemaRestrictionResponse !== null)
        ? ResponseMetaData_SchemaRestrictionResponse.fromPartial(object.schemaRestrictionResponse)
        : undefined;
    message.currencyCode = object.currencyCode ?? undefined;
    message.timeZone = object.timeZone ?? undefined;
    message.emptyReason = object.emptyReason ?? undefined;
    message.subjectToThresholding = object.subjectToThresholding ?? undefined;
    message.samplingMetadatas = object.samplingMetadatas?.map((e) => SamplingMetadata.fromPartial(e)) || [];
    return message;
  },
};

function createBaseResponseMetaData_SchemaRestrictionResponse(): ResponseMetaData_SchemaRestrictionResponse {
  return { activeMetricRestrictions: [] };
}

export const ResponseMetaData_SchemaRestrictionResponse: MessageFns<ResponseMetaData_SchemaRestrictionResponse> = {
  encode(message: ResponseMetaData_SchemaRestrictionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.activeMetricRestrictions) {
      ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ResponseMetaData_SchemaRestrictionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResponseMetaData_SchemaRestrictionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.activeMetricRestrictions.push(
            ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ResponseMetaData_SchemaRestrictionResponse {
    return {
      activeMetricRestrictions: globalThis.Array.isArray(object?.activeMetricRestrictions)
        ? object.activeMetricRestrictions.map((e: any) =>
          ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: ResponseMetaData_SchemaRestrictionResponse): unknown {
    const obj: any = {};
    if (message.activeMetricRestrictions?.length) {
      obj.activeMetricRestrictions = message.activeMetricRestrictions.map((e) =>
        ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<ResponseMetaData_SchemaRestrictionResponse>): ResponseMetaData_SchemaRestrictionResponse {
    return ResponseMetaData_SchemaRestrictionResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ResponseMetaData_SchemaRestrictionResponse>,
  ): ResponseMetaData_SchemaRestrictionResponse {
    const message = createBaseResponseMetaData_SchemaRestrictionResponse();
    message.activeMetricRestrictions =
      object.activeMetricRestrictions?.map((e) =>
        ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction.fromPartial(e)
      ) || [];
    return message;
  },
};

function createBaseResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction(): ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction {
  return { metricName: undefined, restrictedMetricTypes: [] };
}

export const ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction: MessageFns<
  ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction
> = {
  encode(
    message: ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.metricName !== undefined) {
      writer.uint32(10).string(message.metricName);
    }
    writer.uint32(18).fork();
    for (const v of message.restrictedMetricTypes) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metricName = reader.string();
          continue;
        case 2:
          if (tag === 16) {
            message.restrictedMetricTypes.push(reader.int32() as any);

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.restrictedMetricTypes.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction {
    return {
      metricName: isSet(object.metricName) ? globalThis.String(object.metricName) : undefined,
      restrictedMetricTypes: globalThis.Array.isArray(object?.restrictedMetricTypes)
        ? object.restrictedMetricTypes.map((e: any) => restrictedMetricTypeFromJSON(e))
        : [],
    };
  },

  toJSON(message: ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction): unknown {
    const obj: any = {};
    if (message.metricName !== undefined) {
      obj.metricName = message.metricName;
    }
    if (message.restrictedMetricTypes?.length) {
      obj.restrictedMetricTypes = message.restrictedMetricTypes.map((e) => restrictedMetricTypeToJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction>,
  ): ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction {
    return ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction>,
  ): ResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction {
    const message = createBaseResponseMetaData_SchemaRestrictionResponse_ActiveMetricRestriction();
    message.metricName = object.metricName ?? undefined;
    message.restrictedMetricTypes = object.restrictedMetricTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseSamplingMetadata(): SamplingMetadata {
  return { samplesReadCount: Long.ZERO, samplingSpaceSize: Long.ZERO };
}

export const SamplingMetadata: MessageFns<SamplingMetadata> = {
  encode(message: SamplingMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.samplesReadCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.samplesReadCount.toString());
    }
    if (!message.samplingSpaceSize.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.samplingSpaceSize.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SamplingMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSamplingMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.samplesReadCount = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.samplingSpaceSize = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SamplingMetadata {
    return {
      samplesReadCount: isSet(object.samplesReadCount) ? Long.fromValue(object.samplesReadCount) : Long.ZERO,
      samplingSpaceSize: isSet(object.samplingSpaceSize) ? Long.fromValue(object.samplingSpaceSize) : Long.ZERO,
    };
  },

  toJSON(message: SamplingMetadata): unknown {
    const obj: any = {};
    if (!message.samplesReadCount.equals(Long.ZERO)) {
      obj.samplesReadCount = (message.samplesReadCount || Long.ZERO).toString();
    }
    if (!message.samplingSpaceSize.equals(Long.ZERO)) {
      obj.samplingSpaceSize = (message.samplingSpaceSize || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<SamplingMetadata>): SamplingMetadata {
    return SamplingMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SamplingMetadata>): SamplingMetadata {
    const message = createBaseSamplingMetadata();
    message.samplesReadCount = (object.samplesReadCount !== undefined && object.samplesReadCount !== null)
      ? Long.fromValue(object.samplesReadCount)
      : Long.ZERO;
    message.samplingSpaceSize = (object.samplingSpaceSize !== undefined && object.samplingSpaceSize !== null)
      ? Long.fromValue(object.samplingSpaceSize)
      : Long.ZERO;
    return message;
  },
};

function createBaseDimensionHeader(): DimensionHeader {
  return { name: "" };
}

export const DimensionHeader: MessageFns<DimensionHeader> = {
  encode(message: DimensionHeader, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionHeader {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionHeader();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionHeader {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DimensionHeader): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionHeader>): DimensionHeader {
    return DimensionHeader.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DimensionHeader>): DimensionHeader {
    const message = createBaseDimensionHeader();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseMetricHeader(): MetricHeader {
  return { name: "", type: 0 };
}

export const MetricHeader: MessageFns<MetricHeader> = {
  encode(message: MetricHeader, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetricHeader {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetricHeader();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetricHeader {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? metricTypeFromJSON(object.type) : 0,
    };
  },

  toJSON(message: MetricHeader): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = metricTypeToJSON(message.type);
    }
    return obj;
  },

  create(base?: DeepPartial<MetricHeader>): MetricHeader {
    return MetricHeader.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetricHeader>): MetricHeader {
    const message = createBaseMetricHeader();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    return message;
  },
};

function createBasePivotHeader(): PivotHeader {
  return { pivotDimensionHeaders: [], rowCount: 0 };
}

export const PivotHeader: MessageFns<PivotHeader> = {
  encode(message: PivotHeader, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.pivotDimensionHeaders) {
      PivotDimensionHeader.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.rowCount !== 0) {
      writer.uint32(16).int32(message.rowCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PivotHeader {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePivotHeader();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pivotDimensionHeaders.push(PivotDimensionHeader.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.rowCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PivotHeader {
    return {
      pivotDimensionHeaders: globalThis.Array.isArray(object?.pivotDimensionHeaders)
        ? object.pivotDimensionHeaders.map((e: any) => PivotDimensionHeader.fromJSON(e))
        : [],
      rowCount: isSet(object.rowCount) ? globalThis.Number(object.rowCount) : 0,
    };
  },

  toJSON(message: PivotHeader): unknown {
    const obj: any = {};
    if (message.pivotDimensionHeaders?.length) {
      obj.pivotDimensionHeaders = message.pivotDimensionHeaders.map((e) => PivotDimensionHeader.toJSON(e));
    }
    if (message.rowCount !== 0) {
      obj.rowCount = Math.round(message.rowCount);
    }
    return obj;
  },

  create(base?: DeepPartial<PivotHeader>): PivotHeader {
    return PivotHeader.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PivotHeader>): PivotHeader {
    const message = createBasePivotHeader();
    message.pivotDimensionHeaders = object.pivotDimensionHeaders?.map((e) => PivotDimensionHeader.fromPartial(e)) || [];
    message.rowCount = object.rowCount ?? 0;
    return message;
  },
};

function createBasePivotDimensionHeader(): PivotDimensionHeader {
  return { dimensionValues: [] };
}

export const PivotDimensionHeader: MessageFns<PivotDimensionHeader> = {
  encode(message: PivotDimensionHeader, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dimensionValues) {
      DimensionValue.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PivotDimensionHeader {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePivotDimensionHeader();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionValues.push(DimensionValue.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PivotDimensionHeader {
    return {
      dimensionValues: globalThis.Array.isArray(object?.dimensionValues)
        ? object.dimensionValues.map((e: any) => DimensionValue.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PivotDimensionHeader): unknown {
    const obj: any = {};
    if (message.dimensionValues?.length) {
      obj.dimensionValues = message.dimensionValues.map((e) => DimensionValue.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PivotDimensionHeader>): PivotDimensionHeader {
    return PivotDimensionHeader.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PivotDimensionHeader>): PivotDimensionHeader {
    const message = createBasePivotDimensionHeader();
    message.dimensionValues = object.dimensionValues?.map((e) => DimensionValue.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRow(): Row {
  return { dimensionValues: [], metricValues: [] };
}

export const Row: MessageFns<Row> = {
  encode(message: Row, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dimensionValues) {
      DimensionValue.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.metricValues) {
      MetricValue.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Row {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRow();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionValues.push(DimensionValue.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metricValues.push(MetricValue.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Row {
    return {
      dimensionValues: globalThis.Array.isArray(object?.dimensionValues)
        ? object.dimensionValues.map((e: any) => DimensionValue.fromJSON(e))
        : [],
      metricValues: globalThis.Array.isArray(object?.metricValues)
        ? object.metricValues.map((e: any) => MetricValue.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Row): unknown {
    const obj: any = {};
    if (message.dimensionValues?.length) {
      obj.dimensionValues = message.dimensionValues.map((e) => DimensionValue.toJSON(e));
    }
    if (message.metricValues?.length) {
      obj.metricValues = message.metricValues.map((e) => MetricValue.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Row>): Row {
    return Row.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Row>): Row {
    const message = createBaseRow();
    message.dimensionValues = object.dimensionValues?.map((e) => DimensionValue.fromPartial(e)) || [];
    message.metricValues = object.metricValues?.map((e) => MetricValue.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDimensionValue(): DimensionValue {
  return { value: undefined };
}

export const DimensionValue: MessageFns<DimensionValue> = {
  encode(message: DimensionValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== undefined) {
      writer.uint32(10).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionValue {
    return { value: isSet(object.value) ? globalThis.String(object.value) : undefined };
  },

  toJSON(message: DimensionValue): unknown {
    const obj: any = {};
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionValue>): DimensionValue {
    return DimensionValue.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DimensionValue>): DimensionValue {
    const message = createBaseDimensionValue();
    message.value = object.value ?? undefined;
    return message;
  },
};

function createBaseMetricValue(): MetricValue {
  return { value: undefined };
}

export const MetricValue: MessageFns<MetricValue> = {
  encode(message: MetricValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== undefined) {
      writer.uint32(34).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetricValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetricValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetricValue {
    return { value: isSet(object.value) ? globalThis.String(object.value) : undefined };
  },

  toJSON(message: MetricValue): unknown {
    const obj: any = {};
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<MetricValue>): MetricValue {
    return MetricValue.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetricValue>): MetricValue {
    const message = createBaseMetricValue();
    message.value = object.value ?? undefined;
    return message;
  },
};

function createBaseNumericValue(): NumericValue {
  return { int64Value: undefined, doubleValue: undefined };
}

export const NumericValue: MessageFns<NumericValue> = {
  encode(message: NumericValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.int64Value !== undefined) {
      writer.uint32(8).int64(message.int64Value.toString());
    }
    if (message.doubleValue !== undefined) {
      writer.uint32(17).double(message.doubleValue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NumericValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNumericValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.int64Value = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.doubleValue = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NumericValue {
    return {
      int64Value: isSet(object.int64Value) ? Long.fromValue(object.int64Value) : undefined,
      doubleValue: isSet(object.doubleValue) ? globalThis.Number(object.doubleValue) : undefined,
    };
  },

  toJSON(message: NumericValue): unknown {
    const obj: any = {};
    if (message.int64Value !== undefined) {
      obj.int64Value = (message.int64Value || Long.ZERO).toString();
    }
    if (message.doubleValue !== undefined) {
      obj.doubleValue = message.doubleValue;
    }
    return obj;
  },

  create(base?: DeepPartial<NumericValue>): NumericValue {
    return NumericValue.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NumericValue>): NumericValue {
    const message = createBaseNumericValue();
    message.int64Value = (object.int64Value !== undefined && object.int64Value !== null)
      ? Long.fromValue(object.int64Value)
      : undefined;
    message.doubleValue = object.doubleValue ?? undefined;
    return message;
  },
};

function createBasePropertyQuota(): PropertyQuota {
  return {
    tokensPerDay: undefined,
    tokensPerHour: undefined,
    concurrentRequests: undefined,
    serverErrorsPerProjectPerHour: undefined,
    potentiallyThresholdedRequestsPerHour: undefined,
    tokensPerProjectPerHour: undefined,
  };
}

export const PropertyQuota: MessageFns<PropertyQuota> = {
  encode(message: PropertyQuota, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tokensPerDay !== undefined) {
      QuotaStatus.encode(message.tokensPerDay, writer.uint32(10).fork()).join();
    }
    if (message.tokensPerHour !== undefined) {
      QuotaStatus.encode(message.tokensPerHour, writer.uint32(18).fork()).join();
    }
    if (message.concurrentRequests !== undefined) {
      QuotaStatus.encode(message.concurrentRequests, writer.uint32(26).fork()).join();
    }
    if (message.serverErrorsPerProjectPerHour !== undefined) {
      QuotaStatus.encode(message.serverErrorsPerProjectPerHour, writer.uint32(34).fork()).join();
    }
    if (message.potentiallyThresholdedRequestsPerHour !== undefined) {
      QuotaStatus.encode(message.potentiallyThresholdedRequestsPerHour, writer.uint32(42).fork()).join();
    }
    if (message.tokensPerProjectPerHour !== undefined) {
      QuotaStatus.encode(message.tokensPerProjectPerHour, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PropertyQuota {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePropertyQuota();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tokensPerDay = QuotaStatus.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tokensPerHour = QuotaStatus.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.concurrentRequests = QuotaStatus.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.serverErrorsPerProjectPerHour = QuotaStatus.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.potentiallyThresholdedRequestsPerHour = QuotaStatus.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.tokensPerProjectPerHour = QuotaStatus.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PropertyQuota {
    return {
      tokensPerDay: isSet(object.tokensPerDay) ? QuotaStatus.fromJSON(object.tokensPerDay) : undefined,
      tokensPerHour: isSet(object.tokensPerHour) ? QuotaStatus.fromJSON(object.tokensPerHour) : undefined,
      concurrentRequests: isSet(object.concurrentRequests)
        ? QuotaStatus.fromJSON(object.concurrentRequests)
        : undefined,
      serverErrorsPerProjectPerHour: isSet(object.serverErrorsPerProjectPerHour)
        ? QuotaStatus.fromJSON(object.serverErrorsPerProjectPerHour)
        : undefined,
      potentiallyThresholdedRequestsPerHour: isSet(object.potentiallyThresholdedRequestsPerHour)
        ? QuotaStatus.fromJSON(object.potentiallyThresholdedRequestsPerHour)
        : undefined,
      tokensPerProjectPerHour: isSet(object.tokensPerProjectPerHour)
        ? QuotaStatus.fromJSON(object.tokensPerProjectPerHour)
        : undefined,
    };
  },

  toJSON(message: PropertyQuota): unknown {
    const obj: any = {};
    if (message.tokensPerDay !== undefined) {
      obj.tokensPerDay = QuotaStatus.toJSON(message.tokensPerDay);
    }
    if (message.tokensPerHour !== undefined) {
      obj.tokensPerHour = QuotaStatus.toJSON(message.tokensPerHour);
    }
    if (message.concurrentRequests !== undefined) {
      obj.concurrentRequests = QuotaStatus.toJSON(message.concurrentRequests);
    }
    if (message.serverErrorsPerProjectPerHour !== undefined) {
      obj.serverErrorsPerProjectPerHour = QuotaStatus.toJSON(message.serverErrorsPerProjectPerHour);
    }
    if (message.potentiallyThresholdedRequestsPerHour !== undefined) {
      obj.potentiallyThresholdedRequestsPerHour = QuotaStatus.toJSON(message.potentiallyThresholdedRequestsPerHour);
    }
    if (message.tokensPerProjectPerHour !== undefined) {
      obj.tokensPerProjectPerHour = QuotaStatus.toJSON(message.tokensPerProjectPerHour);
    }
    return obj;
  },

  create(base?: DeepPartial<PropertyQuota>): PropertyQuota {
    return PropertyQuota.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PropertyQuota>): PropertyQuota {
    const message = createBasePropertyQuota();
    message.tokensPerDay = (object.tokensPerDay !== undefined && object.tokensPerDay !== null)
      ? QuotaStatus.fromPartial(object.tokensPerDay)
      : undefined;
    message.tokensPerHour = (object.tokensPerHour !== undefined && object.tokensPerHour !== null)
      ? QuotaStatus.fromPartial(object.tokensPerHour)
      : undefined;
    message.concurrentRequests = (object.concurrentRequests !== undefined && object.concurrentRequests !== null)
      ? QuotaStatus.fromPartial(object.concurrentRequests)
      : undefined;
    message.serverErrorsPerProjectPerHour =
      (object.serverErrorsPerProjectPerHour !== undefined && object.serverErrorsPerProjectPerHour !== null)
        ? QuotaStatus.fromPartial(object.serverErrorsPerProjectPerHour)
        : undefined;
    message.potentiallyThresholdedRequestsPerHour =
      (object.potentiallyThresholdedRequestsPerHour !== undefined &&
          object.potentiallyThresholdedRequestsPerHour !== null)
        ? QuotaStatus.fromPartial(object.potentiallyThresholdedRequestsPerHour)
        : undefined;
    message.tokensPerProjectPerHour =
      (object.tokensPerProjectPerHour !== undefined && object.tokensPerProjectPerHour !== null)
        ? QuotaStatus.fromPartial(object.tokensPerProjectPerHour)
        : undefined;
    return message;
  },
};

function createBaseQuotaStatus(): QuotaStatus {
  return { consumed: undefined, remaining: undefined };
}

export const QuotaStatus: MessageFns<QuotaStatus> = {
  encode(message: QuotaStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.consumed !== undefined) {
      writer.uint32(8).int32(message.consumed);
    }
    if (message.remaining !== undefined) {
      writer.uint32(16).int32(message.remaining);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QuotaStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuotaStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.consumed = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.remaining = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QuotaStatus {
    return {
      consumed: isSet(object.consumed) ? globalThis.Number(object.consumed) : undefined,
      remaining: isSet(object.remaining) ? globalThis.Number(object.remaining) : undefined,
    };
  },

  toJSON(message: QuotaStatus): unknown {
    const obj: any = {};
    if (message.consumed !== undefined) {
      obj.consumed = Math.round(message.consumed);
    }
    if (message.remaining !== undefined) {
      obj.remaining = Math.round(message.remaining);
    }
    return obj;
  },

  create(base?: DeepPartial<QuotaStatus>): QuotaStatus {
    return QuotaStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QuotaStatus>): QuotaStatus {
    const message = createBaseQuotaStatus();
    message.consumed = object.consumed ?? undefined;
    message.remaining = object.remaining ?? undefined;
    return message;
  },
};

function createBaseDimensionMetadata(): DimensionMetadata {
  return { apiName: "", uiName: "", description: "", deprecatedApiNames: [], customDefinition: false, category: "" };
}

export const DimensionMetadata: MessageFns<DimensionMetadata> = {
  encode(message: DimensionMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.apiName !== "") {
      writer.uint32(10).string(message.apiName);
    }
    if (message.uiName !== "") {
      writer.uint32(18).string(message.uiName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    for (const v of message.deprecatedApiNames) {
      writer.uint32(34).string(v!);
    }
    if (message.customDefinition !== false) {
      writer.uint32(40).bool(message.customDefinition);
    }
    if (message.category !== "") {
      writer.uint32(58).string(message.category);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.apiName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uiName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.deprecatedApiNames.push(reader.string());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.customDefinition = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.category = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionMetadata {
    return {
      apiName: isSet(object.apiName) ? globalThis.String(object.apiName) : "",
      uiName: isSet(object.uiName) ? globalThis.String(object.uiName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      deprecatedApiNames: globalThis.Array.isArray(object?.deprecatedApiNames)
        ? object.deprecatedApiNames.map((e: any) => globalThis.String(e))
        : [],
      customDefinition: isSet(object.customDefinition) ? globalThis.Boolean(object.customDefinition) : false,
      category: isSet(object.category) ? globalThis.String(object.category) : "",
    };
  },

  toJSON(message: DimensionMetadata): unknown {
    const obj: any = {};
    if (message.apiName !== "") {
      obj.apiName = message.apiName;
    }
    if (message.uiName !== "") {
      obj.uiName = message.uiName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.deprecatedApiNames?.length) {
      obj.deprecatedApiNames = message.deprecatedApiNames;
    }
    if (message.customDefinition !== false) {
      obj.customDefinition = message.customDefinition;
    }
    if (message.category !== "") {
      obj.category = message.category;
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionMetadata>): DimensionMetadata {
    return DimensionMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DimensionMetadata>): DimensionMetadata {
    const message = createBaseDimensionMetadata();
    message.apiName = object.apiName ?? "";
    message.uiName = object.uiName ?? "";
    message.description = object.description ?? "";
    message.deprecatedApiNames = object.deprecatedApiNames?.map((e) => e) || [];
    message.customDefinition = object.customDefinition ?? false;
    message.category = object.category ?? "";
    return message;
  },
};

function createBaseMetricMetadata(): MetricMetadata {
  return {
    apiName: "",
    uiName: "",
    description: "",
    deprecatedApiNames: [],
    type: 0,
    expression: "",
    customDefinition: false,
    blockedReasons: [],
    category: "",
  };
}

export const MetricMetadata: MessageFns<MetricMetadata> = {
  encode(message: MetricMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.apiName !== "") {
      writer.uint32(10).string(message.apiName);
    }
    if (message.uiName !== "") {
      writer.uint32(18).string(message.uiName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    for (const v of message.deprecatedApiNames) {
      writer.uint32(34).string(v!);
    }
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.expression !== "") {
      writer.uint32(50).string(message.expression);
    }
    if (message.customDefinition !== false) {
      writer.uint32(56).bool(message.customDefinition);
    }
    writer.uint32(66).fork();
    for (const v of message.blockedReasons) {
      writer.int32(v);
    }
    writer.join();
    if (message.category !== "") {
      writer.uint32(82).string(message.category);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetricMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetricMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.apiName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uiName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.deprecatedApiNames.push(reader.string());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.expression = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.customDefinition = reader.bool();
          continue;
        case 8:
          if (tag === 64) {
            message.blockedReasons.push(reader.int32() as any);

            continue;
          }

          if (tag === 66) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.blockedReasons.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.category = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetricMetadata {
    return {
      apiName: isSet(object.apiName) ? globalThis.String(object.apiName) : "",
      uiName: isSet(object.uiName) ? globalThis.String(object.uiName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      deprecatedApiNames: globalThis.Array.isArray(object?.deprecatedApiNames)
        ? object.deprecatedApiNames.map((e: any) => globalThis.String(e))
        : [],
      type: isSet(object.type) ? metricTypeFromJSON(object.type) : 0,
      expression: isSet(object.expression) ? globalThis.String(object.expression) : "",
      customDefinition: isSet(object.customDefinition) ? globalThis.Boolean(object.customDefinition) : false,
      blockedReasons: globalThis.Array.isArray(object?.blockedReasons)
        ? object.blockedReasons.map((e: any) => metricMetadata_BlockedReasonFromJSON(e))
        : [],
      category: isSet(object.category) ? globalThis.String(object.category) : "",
    };
  },

  toJSON(message: MetricMetadata): unknown {
    const obj: any = {};
    if (message.apiName !== "") {
      obj.apiName = message.apiName;
    }
    if (message.uiName !== "") {
      obj.uiName = message.uiName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.deprecatedApiNames?.length) {
      obj.deprecatedApiNames = message.deprecatedApiNames;
    }
    if (message.type !== 0) {
      obj.type = metricTypeToJSON(message.type);
    }
    if (message.expression !== "") {
      obj.expression = message.expression;
    }
    if (message.customDefinition !== false) {
      obj.customDefinition = message.customDefinition;
    }
    if (message.blockedReasons?.length) {
      obj.blockedReasons = message.blockedReasons.map((e) => metricMetadata_BlockedReasonToJSON(e));
    }
    if (message.category !== "") {
      obj.category = message.category;
    }
    return obj;
  },

  create(base?: DeepPartial<MetricMetadata>): MetricMetadata {
    return MetricMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetricMetadata>): MetricMetadata {
    const message = createBaseMetricMetadata();
    message.apiName = object.apiName ?? "";
    message.uiName = object.uiName ?? "";
    message.description = object.description ?? "";
    message.deprecatedApiNames = object.deprecatedApiNames?.map((e) => e) || [];
    message.type = object.type ?? 0;
    message.expression = object.expression ?? "";
    message.customDefinition = object.customDefinition ?? false;
    message.blockedReasons = object.blockedReasons?.map((e) => e) || [];
    message.category = object.category ?? "";
    return message;
  },
};

function createBaseComparisonMetadata(): ComparisonMetadata {
  return { apiName: "", uiName: "", description: "" };
}

export const ComparisonMetadata: MessageFns<ComparisonMetadata> = {
  encode(message: ComparisonMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.apiName !== "") {
      writer.uint32(10).string(message.apiName);
    }
    if (message.uiName !== "") {
      writer.uint32(18).string(message.uiName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComparisonMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComparisonMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.apiName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uiName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComparisonMetadata {
    return {
      apiName: isSet(object.apiName) ? globalThis.String(object.apiName) : "",
      uiName: isSet(object.uiName) ? globalThis.String(object.uiName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: ComparisonMetadata): unknown {
    const obj: any = {};
    if (message.apiName !== "") {
      obj.apiName = message.apiName;
    }
    if (message.uiName !== "") {
      obj.uiName = message.uiName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create(base?: DeepPartial<ComparisonMetadata>): ComparisonMetadata {
    return ComparisonMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ComparisonMetadata>): ComparisonMetadata {
    const message = createBaseComparisonMetadata();
    message.apiName = object.apiName ?? "";
    message.uiName = object.uiName ?? "";
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseDimensionCompatibility(): DimensionCompatibility {
  return { dimensionMetadata: undefined, compatibility: undefined };
}

export const DimensionCompatibility: MessageFns<DimensionCompatibility> = {
  encode(message: DimensionCompatibility, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dimensionMetadata !== undefined) {
      DimensionMetadata.encode(message.dimensionMetadata, writer.uint32(10).fork()).join();
    }
    if (message.compatibility !== undefined) {
      writer.uint32(16).int32(message.compatibility);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DimensionCompatibility {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDimensionCompatibility();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dimensionMetadata = DimensionMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.compatibility = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DimensionCompatibility {
    return {
      dimensionMetadata: isSet(object.dimensionMetadata)
        ? DimensionMetadata.fromJSON(object.dimensionMetadata)
        : undefined,
      compatibility: isSet(object.compatibility) ? compatibilityFromJSON(object.compatibility) : undefined,
    };
  },

  toJSON(message: DimensionCompatibility): unknown {
    const obj: any = {};
    if (message.dimensionMetadata !== undefined) {
      obj.dimensionMetadata = DimensionMetadata.toJSON(message.dimensionMetadata);
    }
    if (message.compatibility !== undefined) {
      obj.compatibility = compatibilityToJSON(message.compatibility);
    }
    return obj;
  },

  create(base?: DeepPartial<DimensionCompatibility>): DimensionCompatibility {
    return DimensionCompatibility.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DimensionCompatibility>): DimensionCompatibility {
    const message = createBaseDimensionCompatibility();
    message.dimensionMetadata = (object.dimensionMetadata !== undefined && object.dimensionMetadata !== null)
      ? DimensionMetadata.fromPartial(object.dimensionMetadata)
      : undefined;
    message.compatibility = object.compatibility ?? undefined;
    return message;
  },
};

function createBaseMetricCompatibility(): MetricCompatibility {
  return { metricMetadata: undefined, compatibility: undefined };
}

export const MetricCompatibility: MessageFns<MetricCompatibility> = {
  encode(message: MetricCompatibility, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metricMetadata !== undefined) {
      MetricMetadata.encode(message.metricMetadata, writer.uint32(10).fork()).join();
    }
    if (message.compatibility !== undefined) {
      writer.uint32(16).int32(message.compatibility);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetricCompatibility {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetricCompatibility();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metricMetadata = MetricMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.compatibility = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetricCompatibility {
    return {
      metricMetadata: isSet(object.metricMetadata) ? MetricMetadata.fromJSON(object.metricMetadata) : undefined,
      compatibility: isSet(object.compatibility) ? compatibilityFromJSON(object.compatibility) : undefined,
    };
  },

  toJSON(message: MetricCompatibility): unknown {
    const obj: any = {};
    if (message.metricMetadata !== undefined) {
      obj.metricMetadata = MetricMetadata.toJSON(message.metricMetadata);
    }
    if (message.compatibility !== undefined) {
      obj.compatibility = compatibilityToJSON(message.compatibility);
    }
    return obj;
  },

  create(base?: DeepPartial<MetricCompatibility>): MetricCompatibility {
    return MetricCompatibility.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MetricCompatibility>): MetricCompatibility {
    const message = createBaseMetricCompatibility();
    message.metricMetadata = (object.metricMetadata !== undefined && object.metricMetadata !== null)
      ? MetricMetadata.fromPartial(object.metricMetadata)
      : undefined;
    message.compatibility = object.compatibility ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
