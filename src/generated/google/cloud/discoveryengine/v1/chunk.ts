// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/discoveryengine/v1/chunk.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Struct } from "../../../protobuf/struct.js";

export const protobufPackage = "google.cloud.discoveryengine.v1";

/**
 * Chunk captures all raw metadata information of items to be recommended or
 * searched in the chunk mode.
 */
export interface Chunk {
  /**
   * The full resource name of the chunk.
   * Format:
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/branches/{branch}/documents/{document_id}/chunks/{chunk_id}`.
   *
   * This field must be a UTF-8 encoded string with a length limit of 1024
   * characters.
   */
  name: string;
  /** Unique chunk ID of the current chunk. */
  id: string;
  /** Content is a string from a document (parsed content). */
  content: string;
  /**
   * Output only. Represents the relevance score based on similarity.
   * Higher score indicates higher chunk relevance.
   * The score is in range [-1.0, 1.0].
   * Only populated on [SearchService.SearchResponse][].
   */
  relevanceScore?:
    | number
    | undefined;
  /** Metadata of the document from the current chunk. */
  documentMetadata:
    | Chunk_DocumentMetadata
    | undefined;
  /**
   * Output only. This field is OUTPUT_ONLY.
   * It contains derived data that are not in the original input document.
   */
  derivedStructData:
    | { [key: string]: any }
    | undefined;
  /** Page span of the chunk. */
  pageSpan:
    | Chunk_PageSpan
    | undefined;
  /** Output only. Metadata of the current chunk. */
  chunkMetadata: Chunk_ChunkMetadata | undefined;
}

/**
 * Document metadata contains the information of the document of the current
 * chunk.
 */
export interface Chunk_DocumentMetadata {
  /** Uri of the document. */
  uri: string;
  /** Title of the document. */
  title: string;
  /**
   * Data representation.
   * The structured JSON data for the document. It should conform to the
   * registered [Schema][google.cloud.discoveryengine.v1.Schema] or an
   * `INVALID_ARGUMENT` error is thrown.
   */
  structData: { [key: string]: any } | undefined;
}

/** Page span of the chunk. */
export interface Chunk_PageSpan {
  /** The start page of the chunk. */
  pageStart: number;
  /** The end page of the chunk. */
  pageEnd: number;
}

/**
 * Metadata of the current chunk. This field is only populated on
 * [SearchService.Search][google.cloud.discoveryengine.v1.SearchService.Search]
 * API.
 */
export interface Chunk_ChunkMetadata {
  /**
   * The previous chunks of the current chunk. The number is controlled by
   * [SearchRequest.ContentSearchSpec.ChunkSpec.num_previous_chunks][google.cloud.discoveryengine.v1.SearchRequest.ContentSearchSpec.ChunkSpec.num_previous_chunks].
   * This field is only populated on
   * [SearchService.Search][google.cloud.discoveryengine.v1.SearchService.Search]
   * API.
   */
  previousChunks: Chunk[];
  /**
   * The next chunks of the current chunk. The number is controlled by
   * [SearchRequest.ContentSearchSpec.ChunkSpec.num_next_chunks][google.cloud.discoveryengine.v1.SearchRequest.ContentSearchSpec.ChunkSpec.num_next_chunks].
   * This field is only populated on
   * [SearchService.Search][google.cloud.discoveryengine.v1.SearchService.Search]
   * API.
   */
  nextChunks: Chunk[];
}

function createBaseChunk(): Chunk {
  return {
    name: "",
    id: "",
    content: "",
    relevanceScore: undefined,
    documentMetadata: undefined,
    derivedStructData: undefined,
    pageSpan: undefined,
    chunkMetadata: undefined,
  };
}

export const Chunk: MessageFns<Chunk> = {
  encode(message: Chunk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    if (message.content !== "") {
      writer.uint32(26).string(message.content);
    }
    if (message.relevanceScore !== undefined) {
      writer.uint32(65).double(message.relevanceScore);
    }
    if (message.documentMetadata !== undefined) {
      Chunk_DocumentMetadata.encode(message.documentMetadata, writer.uint32(42).fork()).join();
    }
    if (message.derivedStructData !== undefined) {
      Struct.encode(Struct.wrap(message.derivedStructData), writer.uint32(34).fork()).join();
    }
    if (message.pageSpan !== undefined) {
      Chunk_PageSpan.encode(message.pageSpan, writer.uint32(50).fork()).join();
    }
    if (message.chunkMetadata !== undefined) {
      Chunk_ChunkMetadata.encode(message.chunkMetadata, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Chunk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChunk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.content = reader.string();
          continue;
        case 8:
          if (tag !== 65) {
            break;
          }

          message.relevanceScore = reader.double();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.documentMetadata = Chunk_DocumentMetadata.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.derivedStructData = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.pageSpan = Chunk_PageSpan.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.chunkMetadata = Chunk_ChunkMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Chunk {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      content: isSet(object.content) ? globalThis.String(object.content) : "",
      relevanceScore: isSet(object.relevanceScore) ? globalThis.Number(object.relevanceScore) : undefined,
      documentMetadata: isSet(object.documentMetadata)
        ? Chunk_DocumentMetadata.fromJSON(object.documentMetadata)
        : undefined,
      derivedStructData: isObject(object.derivedStructData) ? object.derivedStructData : undefined,
      pageSpan: isSet(object.pageSpan) ? Chunk_PageSpan.fromJSON(object.pageSpan) : undefined,
      chunkMetadata: isSet(object.chunkMetadata) ? Chunk_ChunkMetadata.fromJSON(object.chunkMetadata) : undefined,
    };
  },

  toJSON(message: Chunk): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.content !== "") {
      obj.content = message.content;
    }
    if (message.relevanceScore !== undefined) {
      obj.relevanceScore = message.relevanceScore;
    }
    if (message.documentMetadata !== undefined) {
      obj.documentMetadata = Chunk_DocumentMetadata.toJSON(message.documentMetadata);
    }
    if (message.derivedStructData !== undefined) {
      obj.derivedStructData = message.derivedStructData;
    }
    if (message.pageSpan !== undefined) {
      obj.pageSpan = Chunk_PageSpan.toJSON(message.pageSpan);
    }
    if (message.chunkMetadata !== undefined) {
      obj.chunkMetadata = Chunk_ChunkMetadata.toJSON(message.chunkMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<Chunk>): Chunk {
    return Chunk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Chunk>): Chunk {
    const message = createBaseChunk();
    message.name = object.name ?? "";
    message.id = object.id ?? "";
    message.content = object.content ?? "";
    message.relevanceScore = object.relevanceScore ?? undefined;
    message.documentMetadata = (object.documentMetadata !== undefined && object.documentMetadata !== null)
      ? Chunk_DocumentMetadata.fromPartial(object.documentMetadata)
      : undefined;
    message.derivedStructData = object.derivedStructData ?? undefined;
    message.pageSpan = (object.pageSpan !== undefined && object.pageSpan !== null)
      ? Chunk_PageSpan.fromPartial(object.pageSpan)
      : undefined;
    message.chunkMetadata = (object.chunkMetadata !== undefined && object.chunkMetadata !== null)
      ? Chunk_ChunkMetadata.fromPartial(object.chunkMetadata)
      : undefined;
    return message;
  },
};

function createBaseChunk_DocumentMetadata(): Chunk_DocumentMetadata {
  return { uri: "", title: "", structData: undefined };
}

export const Chunk_DocumentMetadata: MessageFns<Chunk_DocumentMetadata> = {
  encode(message: Chunk_DocumentMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.title !== "") {
      writer.uint32(18).string(message.title);
    }
    if (message.structData !== undefined) {
      Struct.encode(Struct.wrap(message.structData), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Chunk_DocumentMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChunk_DocumentMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.title = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.structData = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Chunk_DocumentMetadata {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      title: isSet(object.title) ? globalThis.String(object.title) : "",
      structData: isObject(object.structData) ? object.structData : undefined,
    };
  },

  toJSON(message: Chunk_DocumentMetadata): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.title !== "") {
      obj.title = message.title;
    }
    if (message.structData !== undefined) {
      obj.structData = message.structData;
    }
    return obj;
  },

  create(base?: DeepPartial<Chunk_DocumentMetadata>): Chunk_DocumentMetadata {
    return Chunk_DocumentMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Chunk_DocumentMetadata>): Chunk_DocumentMetadata {
    const message = createBaseChunk_DocumentMetadata();
    message.uri = object.uri ?? "";
    message.title = object.title ?? "";
    message.structData = object.structData ?? undefined;
    return message;
  },
};

function createBaseChunk_PageSpan(): Chunk_PageSpan {
  return { pageStart: 0, pageEnd: 0 };
}

export const Chunk_PageSpan: MessageFns<Chunk_PageSpan> = {
  encode(message: Chunk_PageSpan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pageStart !== 0) {
      writer.uint32(8).int32(message.pageStart);
    }
    if (message.pageEnd !== 0) {
      writer.uint32(16).int32(message.pageEnd);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Chunk_PageSpan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChunk_PageSpan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.pageStart = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageEnd = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Chunk_PageSpan {
    return {
      pageStart: isSet(object.pageStart) ? globalThis.Number(object.pageStart) : 0,
      pageEnd: isSet(object.pageEnd) ? globalThis.Number(object.pageEnd) : 0,
    };
  },

  toJSON(message: Chunk_PageSpan): unknown {
    const obj: any = {};
    if (message.pageStart !== 0) {
      obj.pageStart = Math.round(message.pageStart);
    }
    if (message.pageEnd !== 0) {
      obj.pageEnd = Math.round(message.pageEnd);
    }
    return obj;
  },

  create(base?: DeepPartial<Chunk_PageSpan>): Chunk_PageSpan {
    return Chunk_PageSpan.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Chunk_PageSpan>): Chunk_PageSpan {
    const message = createBaseChunk_PageSpan();
    message.pageStart = object.pageStart ?? 0;
    message.pageEnd = object.pageEnd ?? 0;
    return message;
  },
};

function createBaseChunk_ChunkMetadata(): Chunk_ChunkMetadata {
  return { previousChunks: [], nextChunks: [] };
}

export const Chunk_ChunkMetadata: MessageFns<Chunk_ChunkMetadata> = {
  encode(message: Chunk_ChunkMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.previousChunks) {
      Chunk.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.nextChunks) {
      Chunk.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Chunk_ChunkMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChunk_ChunkMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.previousChunks.push(Chunk.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextChunks.push(Chunk.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Chunk_ChunkMetadata {
    return {
      previousChunks: globalThis.Array.isArray(object?.previousChunks)
        ? object.previousChunks.map((e: any) => Chunk.fromJSON(e))
        : [],
      nextChunks: globalThis.Array.isArray(object?.nextChunks)
        ? object.nextChunks.map((e: any) => Chunk.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Chunk_ChunkMetadata): unknown {
    const obj: any = {};
    if (message.previousChunks?.length) {
      obj.previousChunks = message.previousChunks.map((e) => Chunk.toJSON(e));
    }
    if (message.nextChunks?.length) {
      obj.nextChunks = message.nextChunks.map((e) => Chunk.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Chunk_ChunkMetadata>): Chunk_ChunkMetadata {
    return Chunk_ChunkMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Chunk_ChunkMetadata>): Chunk_ChunkMetadata {
    const message = createBaseChunk_ChunkMetadata();
    message.previousChunks = object.previousChunks?.map((e) => Chunk.fromPartial(e)) || [];
    message.nextChunks = object.nextChunks?.map((e) => Chunk.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
