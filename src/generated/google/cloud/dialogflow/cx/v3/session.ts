// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dialogflow/cx/v3/session.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Duration } from "../../../../protobuf/duration.js";
import { FieldMask } from "../../../../protobuf/field_mask.js";
import { Struct } from "../../../../protobuf/struct.js";
import { Status } from "../../../../rpc/status.js";
import { LatLng } from "../../../../type/latlng.js";
import { AdvancedSettings } from "./advanced_settings.js";
import { InputAudioConfig, OutputAudioConfig, SpeechWordInfo } from "./audio_config.js";
import { DataStoreConnectionSignals } from "./data_store_connection.js";
import { Flow } from "./flow.js";
import { Intent } from "./intent.js";
import { Page } from "./page.js";
import { ResponseMessage } from "./response_message.js";
import { SessionEntityType } from "./session_entity_type.js";

export const protobufPackage = "google.cloud.dialogflow.cx.v3";

/** Stores information about feedback provided by users about a response. */
export interface AnswerFeedback {
  /** Optional. Rating from user for the specific Dialogflow response. */
  rating: AnswerFeedback_Rating;
  /**
   * Optional. In case of thumbs down rating provided, users can optionally
   * provide context about the rating.
   */
  ratingReason:
    | AnswerFeedback_RatingReason
    | undefined;
  /**
   * Optional. Custom rating from the user about the provided answer, with
   * maximum length of 1024 characters. For example, client could use a
   * customized JSON object to indicate the rating.
   */
  customRating: string;
}

/** Represents thumbs up/down rating provided by user about a response. */
export enum AnswerFeedback_Rating {
  /** RATING_UNSPECIFIED - Rating not specified. */
  RATING_UNSPECIFIED = 0,
  /** THUMBS_UP - Thumbs up feedback from user. */
  THUMBS_UP = 1,
  /** THUMBS_DOWN - Thumbs down feedback from user. */
  THUMBS_DOWN = 2,
  UNRECOGNIZED = -1,
}

export function answerFeedback_RatingFromJSON(object: any): AnswerFeedback_Rating {
  switch (object) {
    case 0:
    case "RATING_UNSPECIFIED":
      return AnswerFeedback_Rating.RATING_UNSPECIFIED;
    case 1:
    case "THUMBS_UP":
      return AnswerFeedback_Rating.THUMBS_UP;
    case 2:
    case "THUMBS_DOWN":
      return AnswerFeedback_Rating.THUMBS_DOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AnswerFeedback_Rating.UNRECOGNIZED;
  }
}

export function answerFeedback_RatingToJSON(object: AnswerFeedback_Rating): string {
  switch (object) {
    case AnswerFeedback_Rating.RATING_UNSPECIFIED:
      return "RATING_UNSPECIFIED";
    case AnswerFeedback_Rating.THUMBS_UP:
      return "THUMBS_UP";
    case AnswerFeedback_Rating.THUMBS_DOWN:
      return "THUMBS_DOWN";
    case AnswerFeedback_Rating.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Stores extra information about why users provided thumbs down rating. */
export interface AnswerFeedback_RatingReason {
  /**
   * Optional. Custom reason labels for thumbs down rating provided by the
   * user. The maximum number of labels allowed is 10 and the maximum length
   * of a single label is 128 characters.
   */
  reasonLabels: string[];
  /**
   * Optional. Additional feedback about the rating.
   * This field can be populated without choosing a predefined `reason`.
   */
  feedback: string;
}

/** The request to set the feedback for a bot answer. */
export interface SubmitAnswerFeedbackRequest {
  /** Required. The name of the session the feedback was sent to. */
  session: string;
  /**
   * Required. ID of the response to update its feedback. This is the same as
   * DetectIntentResponse.response_id.
   */
  responseId: string;
  /** Required. Feedback provided for a bot answer. */
  answerFeedback:
    | AnswerFeedback
    | undefined;
  /**
   * Optional. The mask to control which fields to update. If the mask is not
   * present, all fields will be updated.
   */
  updateMask: string[] | undefined;
}

/** The request to detect user's intent. */
export interface DetectIntentRequest {
  /**
   * Required. The name of the session this query is sent to.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/sessions/<Session ID>` or `projects/<Project ID>/locations/<Location
   * ID>/agents/<Agent ID>/environments/<Environment ID>/sessions/<Session ID>`.
   * If `Environment ID` is not specified, we assume default 'draft'
   * environment.
   * It's up to the API caller to choose an appropriate `Session ID`. It can be
   * a random number or some type of session identifiers (preferably hashed).
   * The length of the `Session ID` must not exceed 36 characters.
   *
   * For more information, see the [sessions
   * guide](https://cloud.google.com/dialogflow/cx/docs/concept/session).
   *
   * Note: Always use agent versions for production traffic.
   * See [Versions and
   * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
   */
  session: string;
  /** The parameters of this query. */
  queryParams:
    | QueryParameters
    | undefined;
  /** Required. The input specification. */
  queryInput:
    | QueryInput
    | undefined;
  /** Instructs the speech synthesizer how to generate the output audio. */
  outputAudioConfig: OutputAudioConfig | undefined;
}

/** The message returned from the DetectIntent method. */
export interface DetectIntentResponse {
  /**
   * Output only. The unique identifier of the response. It can be used to
   * locate a response in the training example set or for reporting issues.
   */
  responseId: string;
  /** The result of the conversational query. */
  queryResult:
    | QueryResult
    | undefined;
  /**
   * The audio data bytes encoded as specified in the request.
   * Note: The output audio is generated based on the values of default platform
   * text responses found in the
   * [`query_result.response_messages`][google.cloud.dialogflow.cx.v3.QueryResult.response_messages]
   * field. If multiple default text responses exist, they will be concatenated
   * when generating audio. If no default platform text responses exist, the
   * generated audio content will be empty.
   *
   * In some scenarios, multiple output audio fields may be present in the
   * response structure. In these cases, only the top-most-level audio output
   * has content.
   */
  outputAudio: Buffer;
  /** The config used by the speech synthesizer to generate the output audio. */
  outputAudioConfig:
    | OutputAudioConfig
    | undefined;
  /** Response type. */
  responseType: DetectIntentResponse_ResponseType;
  /**
   * Indicates whether the partial response can be cancelled when a later
   * response arrives. e.g. if the agent specified some music as partial
   * response, it can be cancelled.
   */
  allowCancellation: boolean;
}

/** Represents different DetectIntentResponse types. */
export enum DetectIntentResponse_ResponseType {
  /** RESPONSE_TYPE_UNSPECIFIED - Not specified. This should never happen. */
  RESPONSE_TYPE_UNSPECIFIED = 0,
  /**
   * PARTIAL - Partial response. e.g. Aggregated responses in a Fulfillment that enables
   * `return_partial_response` can be returned as partial response.
   * WARNING: partial response is not eligible for barge-in.
   */
  PARTIAL = 1,
  /** FINAL - Final response. */
  FINAL = 2,
  UNRECOGNIZED = -1,
}

export function detectIntentResponse_ResponseTypeFromJSON(object: any): DetectIntentResponse_ResponseType {
  switch (object) {
    case 0:
    case "RESPONSE_TYPE_UNSPECIFIED":
      return DetectIntentResponse_ResponseType.RESPONSE_TYPE_UNSPECIFIED;
    case 1:
    case "PARTIAL":
      return DetectIntentResponse_ResponseType.PARTIAL;
    case 2:
    case "FINAL":
      return DetectIntentResponse_ResponseType.FINAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DetectIntentResponse_ResponseType.UNRECOGNIZED;
  }
}

export function detectIntentResponse_ResponseTypeToJSON(object: DetectIntentResponse_ResponseType): string {
  switch (object) {
    case DetectIntentResponse_ResponseType.RESPONSE_TYPE_UNSPECIFIED:
      return "RESPONSE_TYPE_UNSPECIFIED";
    case DetectIntentResponse_ResponseType.PARTIAL:
      return "PARTIAL";
    case DetectIntentResponse_ResponseType.FINAL:
      return "FINAL";
    case DetectIntentResponse_ResponseType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The top-level message sent by the client to the
 * [Sessions.StreamingDetectIntent][google.cloud.dialogflow.cx.v3.Sessions.StreamingDetectIntent]
 * method.
 *
 * Multiple request messages should be sent in order:
 *
 * 1.  The first message must contain
 *     [session][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.session],
 *     [query_input][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.query_input]
 *     plus optionally
 *     [query_params][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.query_params].
 *     If the client wants to receive an audio response, it should also contain
 *     [output_audio_config][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.output_audio_config].
 *
 * 2.  If
 * [query_input][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.query_input]
 * was set to
 *     [query_input.audio.config][google.cloud.dialogflow.cx.v3.AudioInput.config],
 *     all subsequent messages must contain
 *     [query_input.audio.audio][google.cloud.dialogflow.cx.v3.AudioInput.audio]
 *     to continue with Speech recognition. If you decide to rather detect an
 *     intent from text input after you already started Speech recognition,
 *     please send a message with
 *     [query_input.text][google.cloud.dialogflow.cx.v3.QueryInput.text].
 *
 *     However, note that:
 *
 *     * Dialogflow will bill you for the audio duration so far.
 *     * Dialogflow discards all Speech recognition results in favor of the
 *       input text.
 *     * Dialogflow will use the language code from the first message.
 *
 * After you sent all input, you must half-close or abort the request stream.
 */
export interface StreamingDetectIntentRequest {
  /**
   * The name of the session this query is sent to.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/sessions/<Session ID>` or `projects/<Project ID>/locations/<Location
   * ID>/agents/<Agent ID>/environments/<Environment ID>/sessions/<Session ID>`.
   * If `Environment ID` is not specified, we assume default 'draft'
   * environment.
   * It's up to the API caller to choose an appropriate `Session ID`. It can be
   * a random number or some type of session identifiers (preferably hashed).
   * The length of the `Session ID` must not exceed 36 characters.
   * Note: session must be set in the first request.
   *
   * For more information, see the [sessions
   * guide](https://cloud.google.com/dialogflow/cx/docs/concept/session).
   *
   * Note: Always use agent versions for production traffic.
   * See [Versions and
   * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
   */
  session: string;
  /** The parameters of this query. */
  queryParams:
    | QueryParameters
    | undefined;
  /** Required. The input specification. */
  queryInput:
    | QueryInput
    | undefined;
  /** Instructs the speech synthesizer how to generate the output audio. */
  outputAudioConfig:
    | OutputAudioConfig
    | undefined;
  /**
   * Enable partial detect intent response. If this flag is not enabled,
   * response stream still contains only one final `DetectIntentResponse` even
   * if some `Fulfillment`s in the agent have been configured to return partial
   * responses.
   */
  enablePartialResponse: boolean;
  /** If true, `StreamingDetectIntentResponse.debugging_info` will get populated. */
  enableDebuggingInfo: boolean;
}

/**
 * Cloud conversation info for easier debugging.
 * It will get populated in `StreamingDetectIntentResponse` or
 * `StreamingAnalyzeContentResponse` when the flag `enable_debugging_info` is
 * set to true in corresponding requests.
 */
export interface CloudConversationDebuggingInfo {
  /** Number of input audio data chunks in streaming requests. */
  audioDataChunks: number;
  /**
   * Time offset of the end of speech utterance relative to the
   * beginning of the first audio chunk.
   */
  resultEndTimeOffset:
    | Duration
    | undefined;
  /** Duration of first audio chunk. */
  firstAudioDuration:
    | Duration
    | undefined;
  /** Whether client used single utterance mode. */
  singleUtterance: boolean;
  /**
   * Time offsets of the speech partial results relative to the beginning of
   * the stream.
   */
  speechPartialResultsEndTimes: Duration[];
  /**
   * Time offsets of the speech final results (is_final=true) relative to the
   * beginning of the stream.
   */
  speechFinalResultsEndTimes: Duration[];
  /** Total number of partial responses. */
  partialResponses: number;
  /**
   * Time offset of Speaker ID stream close time relative to the Speech stream
   * close time in milliseconds. Only meaningful for conversations involving
   * passive verification.
   */
  speakerIdPassiveLatencyMsOffset: number;
  /** Whether a barge-in event is triggered in this request. */
  bargeinEventTriggered: boolean;
  /** Whether speech uses single utterance mode. */
  speechSingleUtterance: boolean;
  /**
   * Time offsets of the DTMF partial results relative to the beginning of
   * the stream.
   */
  dtmfPartialResultsTimes: Duration[];
  /**
   * Time offsets of the DTMF final results relative to the beginning of
   * the stream.
   */
  dtmfFinalResultsTimes: Duration[];
  /**
   * Time offset of the end-of-single-utterance signal relative to the
   * beginning of the stream.
   */
  singleUtteranceEndTimeOffset:
    | Duration
    | undefined;
  /** No speech timeout settings for the stream. */
  noSpeechTimeout:
    | Duration
    | undefined;
  /** Speech endpointing timeout settings for the stream. */
  endpointingTimeout:
    | Duration
    | undefined;
  /** Whether the streaming terminates with an injected text query. */
  isInputText: boolean;
  /** Client half close time in terms of input audio duration. */
  clientHalfCloseTimeOffset:
    | Duration
    | undefined;
  /** Client half close time in terms of API streaming duration. */
  clientHalfCloseStreamingTimeOffset: Duration | undefined;
}

/**
 * The top-level message returned from the
 * [StreamingDetectIntent][google.cloud.dialogflow.cx.v3.Sessions.StreamingDetectIntent]
 * method.
 *
 * Multiple response messages (N) can be returned in order.
 *
 * The first (N-1) responses set either the `recognition_result` or
 * `detect_intent_response` field, depending on the request:
 *
 * *   If the `StreamingDetectIntentRequest.query_input.audio` field was
 *     set, and the `StreamingDetectIntentRequest.enable_partial_response`
 *     field was false, the `recognition_result` field is populated for each
 *     of the (N-1) responses.
 *     See the
 *     [StreamingRecognitionResult][google.cloud.dialogflow.cx.v3.StreamingRecognitionResult]
 *     message for details about the result message sequence.
 *
 * *   If the `StreamingDetectIntentRequest.enable_partial_response` field was
 *     true, the `detect_intent_response` field is populated for each
 *     of the (N-1) responses, where 1 <= N <= 4.
 *     These responses set the
 *     [DetectIntentResponse.response_type][google.cloud.dialogflow.cx.v3.DetectIntentResponse.response_type]
 *     field to `PARTIAL`.
 *
 * For the final Nth response message, the `detect_intent_response` is fully
 * populated, and
 * [DetectIntentResponse.response_type][google.cloud.dialogflow.cx.v3.DetectIntentResponse.response_type]
 * is set to `FINAL`.
 */
export interface StreamingDetectIntentResponse {
  /** The result of speech recognition. */
  recognitionResult?:
    | StreamingRecognitionResult
    | undefined;
  /** The response from detect intent. */
  detectIntentResponse?:
    | DetectIntentResponse
    | undefined;
  /**
   * Debugging info that would get populated when
   * `StreamingDetectIntentRequest.enable_debugging_info` is set to true.
   */
  debuggingInfo: CloudConversationDebuggingInfo | undefined;
}

/**
 * Contains a speech recognition result corresponding to a portion of the audio
 * that is currently being processed or an indication that this is the end
 * of the single requested utterance.
 *
 * While end-user audio is being processed, Dialogflow sends a series of
 * results. Each result may contain a `transcript` value. A transcript
 * represents a portion of the utterance. While the recognizer is processing
 * audio, transcript values may be interim values or finalized values.
 * Once a transcript is finalized, the `is_final` value is set to true and
 * processing continues for the next transcript.
 *
 * If `StreamingDetectIntentRequest.query_input.audio.config.single_utterance`
 * was true, and the recognizer has completed processing audio,
 * the `message_type` value is set to `END_OF_SINGLE_UTTERANCE and the
 * following (last) result contains the last finalized transcript.
 *
 * The complete end-user utterance is determined by concatenating the
 * finalized transcript values received for the series of results.
 *
 * In the following example, single utterance is enabled. In the case where
 * single utterance is not enabled, result 7 would not occur.
 *
 * ```
 * Num | transcript              | message_type            | is_final
 * --- | ----------------------- | ----------------------- | --------
 * 1   | "tube"                  | TRANSCRIPT              | false
 * 2   | "to be a"               | TRANSCRIPT              | false
 * 3   | "to be"                 | TRANSCRIPT              | false
 * 4   | "to be or not to be"    | TRANSCRIPT              | true
 * 5   | "that's"                | TRANSCRIPT              | false
 * 6   | "that is                | TRANSCRIPT              | false
 * 7   | unset                   | END_OF_SINGLE_UTTERANCE | unset
 * 8   | " that is the question" | TRANSCRIPT              | true
 * ```
 *
 * Concatenating the finalized transcripts with `is_final` set to true,
 * the complete utterance becomes "to be or not to be that is the question".
 */
export interface StreamingRecognitionResult {
  /** Type of the result message. */
  messageType: StreamingRecognitionResult_MessageType;
  /**
   * Transcript text representing the words that the user spoke.
   * Populated if and only if `message_type` = `TRANSCRIPT`.
   */
  transcript: string;
  /**
   * If `false`, the `StreamingRecognitionResult` represents an
   * interim result that may change. If `true`, the recognizer will not return
   * any further hypotheses about this piece of the audio. May only be populated
   * for `message_type` = `TRANSCRIPT`.
   */
  isFinal: boolean;
  /**
   * The Speech confidence between 0.0 and 1.0 for the current portion of audio.
   * A higher number indicates an estimated greater likelihood that the
   * recognized words are correct. The default of 0.0 is a sentinel value
   * indicating that confidence was not set.
   *
   * This field is typically only provided if `is_final` is true and you should
   * not rely on it being accurate or even set.
   */
  confidence: number;
  /**
   * An estimate of the likelihood that the speech recognizer will
   * not change its guess about this interim recognition result:
   * * If the value is unspecified or 0.0, Dialogflow didn't compute the
   *   stability. In particular, Dialogflow will only provide stability for
   *   `TRANSCRIPT` results with `is_final = false`.
   * * Otherwise, the value is in (0.0, 1.0] where 0.0 means completely
   *   unstable and 1.0 means completely stable.
   */
  stability: number;
  /**
   * Word-specific information for the words recognized by Speech in
   * [transcript][google.cloud.dialogflow.cx.v3.StreamingRecognitionResult.transcript].
   * Populated if and only if `message_type` = `TRANSCRIPT` and
   * [InputAudioConfig.enable_word_info] is set.
   */
  speechWordInfo: SpeechWordInfo[];
  /**
   * Time offset of the end of this Speech recognition result relative to the
   * beginning of the audio. Only populated for `message_type` =
   * `TRANSCRIPT`.
   */
  speechEndOffset:
    | Duration
    | undefined;
  /** Detected language code for the transcript. */
  languageCode: string;
}

/** Type of the response message. */
export enum StreamingRecognitionResult_MessageType {
  /** MESSAGE_TYPE_UNSPECIFIED - Not specified. Should never be used. */
  MESSAGE_TYPE_UNSPECIFIED = 0,
  /** TRANSCRIPT - Message contains a (possibly partial) transcript. */
  TRANSCRIPT = 1,
  /**
   * END_OF_SINGLE_UTTERANCE - This event indicates that the server has detected the end of the user's
   * speech utterance and expects no additional speech. Therefore, the server
   * will not process additional audio (although it may subsequently return
   * additional results). The client should stop sending additional audio
   * data, half-close the gRPC connection, and wait for any additional results
   * until the server closes the gRPC connection. This message is only sent if
   * [`single_utterance`][google.cloud.dialogflow.cx.v3.InputAudioConfig.single_utterance]
   * was set to `true`, and is not used otherwise.
   */
  END_OF_SINGLE_UTTERANCE = 2,
  UNRECOGNIZED = -1,
}

export function streamingRecognitionResult_MessageTypeFromJSON(object: any): StreamingRecognitionResult_MessageType {
  switch (object) {
    case 0:
    case "MESSAGE_TYPE_UNSPECIFIED":
      return StreamingRecognitionResult_MessageType.MESSAGE_TYPE_UNSPECIFIED;
    case 1:
    case "TRANSCRIPT":
      return StreamingRecognitionResult_MessageType.TRANSCRIPT;
    case 2:
    case "END_OF_SINGLE_UTTERANCE":
      return StreamingRecognitionResult_MessageType.END_OF_SINGLE_UTTERANCE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StreamingRecognitionResult_MessageType.UNRECOGNIZED;
  }
}

export function streamingRecognitionResult_MessageTypeToJSON(object: StreamingRecognitionResult_MessageType): string {
  switch (object) {
    case StreamingRecognitionResult_MessageType.MESSAGE_TYPE_UNSPECIFIED:
      return "MESSAGE_TYPE_UNSPECIFIED";
    case StreamingRecognitionResult_MessageType.TRANSCRIPT:
      return "TRANSCRIPT";
    case StreamingRecognitionResult_MessageType.END_OF_SINGLE_UTTERANCE:
      return "END_OF_SINGLE_UTTERANCE";
    case StreamingRecognitionResult_MessageType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the parameters of a conversational query. */
export interface QueryParameters {
  /**
   * The time zone of this conversational query from the [time zone
   * database](https://www.iana.org/time-zones), e.g., America/New_York,
   * Europe/Paris. If not provided, the time zone specified in the agent is
   * used.
   */
  timeZone: string;
  /** The geo location of this conversational query. */
  geoLocation:
    | LatLng
    | undefined;
  /**
   * Additional session entity types to replace or extend developer entity types
   * with. The entity synonyms apply to all languages and persist for the
   * session of this query.
   */
  sessionEntityTypes: SessionEntityType[];
  /**
   * This field can be used to pass custom data into the webhook associated with
   * the agent. Arbitrary JSON objects are supported.
   * Some integrations that query a Dialogflow agent may provide additional
   * information in the payload.
   * In particular, for the Dialogflow Phone Gateway integration, this field has
   * the form:
   * ```
   * {
   *  "telephony": {
   *    "caller_id": "+18558363987"
   *  }
   * }
   * ```
   */
  payload:
    | { [key: string]: any }
    | undefined;
  /**
   * Additional parameters to be put into [session
   * parameters][SessionInfo.parameters]. To remove a
   * parameter from the session, clients should explicitly set the parameter
   * value to null.
   *
   * You can reference the session parameters in the agent with the following
   * format: $session.params.parameter-id.
   *
   * Depending on your protocol or client library language, this is a
   * map, associative array, symbol table, dictionary, or JSON object
   * composed of a collection of (MapKey, MapValue) pairs:
   *
   * * MapKey type: string
   * * MapKey value: parameter name
   * * MapValue type: If parameter's entity type is a composite entity then use
   * map, otherwise, depending on the parameter value type, it could be one of
   * string, number, boolean, null, list or map.
   * * MapValue value: If parameter's entity type is a composite entity then use
   * map from composite entity property names to property values, otherwise,
   * use parameter value.
   */
  parameters:
    | { [key: string]: any }
    | undefined;
  /**
   * The unique identifier of the [page][google.cloud.dialogflow.cx.v3.Page] to
   * override the [current page][QueryResult.current_page] in the session.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/flows/<Flow ID>/pages/<Page ID>`.
   *
   * If `current_page` is specified, the previous state of the session will be
   * ignored by Dialogflow, including the [previous
   * page][QueryResult.current_page] and the [previous session
   * parameters][QueryResult.parameters].
   * In most cases,
   * [current_page][google.cloud.dialogflow.cx.v3.QueryParameters.current_page]
   * and [parameters][google.cloud.dialogflow.cx.v3.QueryParameters.parameters]
   * should be configured together to direct a session to a specific state.
   */
  currentPage: string;
  /** Whether to disable webhook calls for this request. */
  disableWebhook: boolean;
  /**
   * Configures whether sentiment analysis should be performed. If not
   * provided, sentiment analysis is not performed.
   */
  analyzeQueryTextSentiment: boolean;
  /**
   * This field can be used to pass HTTP headers for a webhook
   * call. These headers will be sent to webhook along with the headers that
   * have been configured through Dialogflow web console. The headers defined
   * within this field will overwrite the headers configured through Dialogflow
   * console if there is a conflict. Header names are case-insensitive.
   * Google's specified headers are not allowed. Including: "Host",
   * "Content-Length", "Connection", "From", "User-Agent", "Accept-Encoding",
   * "If-Modified-Since", "If-None-Match", "X-Forwarded-For", etc.
   */
  webhookHeaders: { [key: string]: string };
  /**
   * A list of flow versions to override for the request.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/flows/<Flow ID>/versions/<Version ID>`.
   *
   * If version 1 of flow X is included in this list, the traffic of
   * flow X will go through version 1 regardless of the version configuration in
   * the environment. Each flow can have at most one version specified in this
   * list.
   */
  flowVersions: string[];
  /**
   * The channel which this query is for.
   *
   * If specified, only the
   * [ResponseMessage][google.cloud.dialogflow.cx.v3.ResponseMessage] associated
   * with the channel will be returned. If no
   * [ResponseMessage][google.cloud.dialogflow.cx.v3.ResponseMessage] is
   * associated with the channel, it falls back to the
   * [ResponseMessage][google.cloud.dialogflow.cx.v3.ResponseMessage] with
   * unspecified channel.
   *
   * If unspecified, the
   * [ResponseMessage][google.cloud.dialogflow.cx.v3.ResponseMessage] with
   * unspecified channel will be returned.
   */
  channel: string;
  /**
   * Optional. Configure lifetime of the Dialogflow session.
   * By default, a Dialogflow session remains active and its data is stored for
   * 30 minutes after the last request is sent for the session.
   * This value should be no longer than 1 day.
   */
  sessionTtl:
    | Duration
    | undefined;
  /**
   * Optional. Information about the end-user to improve the relevance and
   * accuracy of generative answers.
   *
   * This will be interpreted and used by a language model, so, for good
   * results, the data should be self-descriptive, and in a simple structure.
   *
   * Example:
   *
   * ```json
   * {
   *   "subscription plan": "Business Premium Plus",
   *   "devices owned": [
   *     {"model": "Google Pixel 7"},
   *     {"model": "Google Pixel Tablet"}
   *   ]
   * }
   * ```
   */
  endUserMetadata:
    | { [key: string]: any }
    | undefined;
  /** Optional. Search configuration for UCS search queries. */
  searchConfig:
    | SearchConfig
    | undefined;
  /**
   * Optional. If set to true and data stores are involved in serving the
   * request then
   * DetectIntentResponse.query_result.data_store_connection_signals
   * will be filled with data that can help evaluations.
   */
  populateDataStoreConnectionSignals: boolean;
}

export interface QueryParameters_WebhookHeadersEntry {
  key: string;
  value: string;
}

/** Search configuration for UCS search queries. */
export interface SearchConfig {
  /** Optional. Boosting configuration for the datastores. */
  boostSpecs: BoostSpecs[];
  /** Optional. Filter configuration for the datastores. */
  filterSpecs: FilterSpecs[];
}

/**
 * Boost specification to boost certain documents.
 * A copy of google.cloud.discoveryengine.v1main.BoostSpec, field documentation
 * is available at
 * https://cloud.google.com/generative-ai-app-builder/docs/reference/rest/v1alpha/BoostSpec
 */
export interface BoostSpec {
  /**
   * Optional. Condition boost specifications. If a document matches multiple
   * conditions in the specifictions, boost scores from these specifications are
   * all applied and combined in a non-linear way. Maximum number of
   * specifications is 20.
   */
  conditionBoostSpecs: BoostSpec_ConditionBoostSpec[];
}

/** Boost applies to documents which match a condition. */
export interface BoostSpec_ConditionBoostSpec {
  /**
   * Optional. An expression which specifies a boost condition. The syntax and
   * supported fields are the same as a filter expression.
   * Examples:
   *
   * * To boost documents with document ID "doc_1" or "doc_2", and
   * color
   *   "Red" or "Blue":
   *     * (id: ANY("doc_1", "doc_2")) AND (color: ANY("Red","Blue"))
   */
  condition: string;
  /**
   * Optional. Strength of the condition boost, which should be in [-1, 1].
   * Negative boost means demotion. Default is 0.0.
   *
   * Setting to 1.0 gives the document a big promotion. However, it does not
   * necessarily mean that the boosted document will be the top result at
   * all times, nor that other documents will be excluded. Results could
   * still be shown even when none of them matches the condition. And
   * results that are significantly more relevant to the search query can
   * still trump your heavily favored but irrelevant documents.
   *
   * Setting to -1.0 gives the document a big demotion. However, results
   * that are deeply relevant might still be shown. The document will have
   * an upstream battle to get a fairly high ranking, but it is not blocked
   * out completely.
   *
   * Setting to 0.0 means no boost applied. The boosting condition is
   * ignored.
   */
  boost: number;
}

/** Boost specifications for data stores. */
export interface BoostSpecs {
  /**
   * Optional. Data Stores where the boosting configuration is applied. The full
   * names of the referenced data stores. Formats:
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}`
   * `projects/{project}/locations/{location}/dataStores/{data_store}`
   */
  dataStores: string[];
  /** Optional. A list of boosting specifications. */
  spec: BoostSpec[];
}

/** Filter specifications for data stores. */
export interface FilterSpecs {
  /**
   * Optional. Data Stores where the boosting configuration is applied. The full
   * names of the referenced data stores. Formats:
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}`
   * `projects/{project}/locations/{location}/dataStores/{data_store}`
   */
  dataStores: string[];
  /**
   * Optional. The filter expression to be applied.
   * Expression syntax is documented at
   * https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata#filter-expression-syntax
   */
  filter: string;
}

/**
 * Represents the query input. It can contain one of:
 *
 * 1. A conversational query in the form of text.
 *
 * 2. An intent query that specifies which intent to trigger.
 *
 * 3. Natural language speech audio to be processed.
 *
 * 4. An event to be triggered.
 *
 * 5. DTMF digits to invoke an intent and fill in parameter value.
 *
 * 6. The results of a tool executed by the client.
 */
export interface QueryInput {
  /** The natural language text to be processed. */
  text?:
    | TextInput
    | undefined;
  /** The intent to be triggered. */
  intent?:
    | IntentInput
    | undefined;
  /** The natural language speech audio to be processed. */
  audio?:
    | AudioInput
    | undefined;
  /** The event to be triggered. */
  event?:
    | EventInput
    | undefined;
  /** The DTMF event to be handled. */
  dtmf?:
    | DtmfInput
    | undefined;
  /**
   * Required. The language of the input. See [Language
   * Support](https://cloud.google.com/dialogflow/cx/docs/reference/language)
   * for a list of the currently supported language codes. Note that queries in
   * the same session do not necessarily need to specify the same language.
   */
  languageCode: string;
}

/** Represents the result of a conversational query. */
export interface QueryResult {
  /**
   * If [natural language text][google.cloud.dialogflow.cx.v3.TextInput] was
   * provided as input, this field will contain a copy of the text.
   */
  text?:
    | string
    | undefined;
  /**
   * If an [intent][google.cloud.dialogflow.cx.v3.IntentInput] was provided as
   * input, this field will contain a copy of the intent identifier. Format:
   * `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/intents/<Intent ID>`.
   */
  triggerIntent?:
    | string
    | undefined;
  /**
   * If [natural language speech
   * audio][google.cloud.dialogflow.cx.v3.AudioInput] was provided as input,
   * this field will contain the transcript for the audio.
   */
  transcript?:
    | string
    | undefined;
  /**
   * If an [event][google.cloud.dialogflow.cx.v3.EventInput] was provided as
   * input, this field will contain the name of the event.
   */
  triggerEvent?:
    | string
    | undefined;
  /**
   * If a [DTMF][google.cloud.dialogflow.cx.v3.DtmfInput] was provided as
   * input, this field will contain a copy of the
   * [DtmfInput][google.cloud.dialogflow.cx.v3.DtmfInput].
   */
  dtmf?:
    | DtmfInput
    | undefined;
  /**
   * The language that was triggered during intent detection.
   * See [Language
   * Support](https://cloud.google.com/dialogflow/cx/docs/reference/language)
   * for a list of the currently supported language codes.
   */
  languageCode: string;
  /**
   * The collected [session
   * parameters][google.cloud.dialogflow.cx.v3.SessionInfo.parameters].
   *
   * Depending on your protocol or client library language, this is a
   * map, associative array, symbol table, dictionary, or JSON object
   * composed of a collection of (MapKey, MapValue) pairs:
   *
   * * MapKey type: string
   * * MapKey value: parameter name
   * * MapValue type: If parameter's entity type is a composite entity then use
   * map, otherwise, depending on the parameter value type, it could be one of
   * string, number, boolean, null, list or map.
   * * MapValue value: If parameter's entity type is a composite entity then use
   * map from composite entity property names to property values, otherwise,
   * use parameter value.
   */
  parameters:
    | { [key: string]: any }
    | undefined;
  /**
   * The list of rich messages returned to the client. Responses vary from
   * simple text messages to more sophisticated, structured payloads used
   * to drive complex logic.
   */
  responseMessages: ResponseMessage[];
  /** The list of webhook ids in the order of call sequence. */
  webhookIds: string[];
  /** The list of webhook display names in the order of call sequence. */
  webhookDisplayNames: string[];
  /** The list of webhook latencies in the order of call sequence. */
  webhookLatencies: Duration[];
  /** The list of webhook tags in the order of call sequence. */
  webhookTags: string[];
  /** The list of webhook call status in the order of call sequence. */
  webhookStatuses: Status[];
  /**
   * The list of webhook payload in
   * [WebhookResponse.payload][google.cloud.dialogflow.cx.v3.WebhookResponse.payload],
   * in the order of call sequence. If some webhook call fails or doesn't return
   * any payload, an empty `Struct` would be used instead.
   */
  webhookPayloads: { [key: string]: any }[];
  /**
   * The current [Page][google.cloud.dialogflow.cx.v3.Page]. Some, not all
   * fields are filled in this message, including but not limited to `name` and
   * `display_name`.
   */
  currentPage:
    | Page
    | undefined;
  /**
   * The current [Flow][google.cloud.dialogflow.cx.v3.Flow]. Some, not all
   * fields are filled in this message, including but not limited to `name` and
   * `display_name`.
   */
  currentFlow:
    | Flow
    | undefined;
  /**
   * The [Intent][google.cloud.dialogflow.cx.v3.Intent] that matched the
   * conversational query. Some, not all fields are filled in this message,
   * including but not limited to: `name` and `display_name`. This field is
   * deprecated, please use
   * [QueryResult.match][google.cloud.dialogflow.cx.v3.QueryResult.match]
   * instead.
   *
   * @deprecated
   */
  intent:
    | Intent
    | undefined;
  /**
   * The intent detection confidence. Values range from 0.0 (completely
   * uncertain) to 1.0 (completely certain).
   * This value is for informational purpose only and is only used to
   * help match the best intent within the classification threshold.
   * This value may change for the same end-user expression at any time due to a
   * model retraining or change in implementation.
   * This field is deprecated, please use
   * [QueryResult.match][google.cloud.dialogflow.cx.v3.QueryResult.match]
   * instead.
   *
   * @deprecated
   */
  intentDetectionConfidence: number;
  /** Intent match result, could be an intent or an event. */
  match:
    | Match
    | undefined;
  /**
   * The free-form diagnostic info. For example, this field could contain
   * webhook call latency. The fields of this data can change without notice,
   * so you should not write code that depends on its structure.
   *
   * One of the fields is called "Alternative Matched Intents", which may
   * aid with debugging. The following describes these intent results:
   *
   * - The list is empty if no intent was matched to end-user input.
   * - Only intents that are referenced in the currently active flow are
   *   included.
   * - The matched intent is included.
   * - Other intents that could have matched end-user input, but did not match
   *   because they are referenced by intent routes that are out of
   *   [scope](https://cloud.google.com/dialogflow/cx/docs/concept/handler#scope),
   *   are included.
   * - Other intents referenced by intent routes in scope that matched end-user
   *   input, but had a lower confidence score.
   */
  diagnosticInfo:
    | { [key: string]: any }
    | undefined;
  /**
   * The sentiment analyss result, which depends on
   * [`analyze_query_text_sentiment`]
   * [google.cloud.dialogflow.cx.v3.QueryParameters.analyze_query_text_sentiment],
   * specified in the request.
   */
  sentimentAnalysisResult:
    | SentimentAnalysisResult
    | undefined;
  /**
   * Returns the current advanced settings including IVR settings. Even though
   * the operations configured by these settings are performed by Dialogflow,
   * the client may need to perform special logic at the moment. For example, if
   * Dialogflow exports audio to Google Cloud Storage, then the client may need
   * to wait for the resulting object to appear in the bucket before proceeding.
   */
  advancedSettings:
    | AdvancedSettings
    | undefined;
  /**
   * Indicates whether the Thumbs up/Thumbs down rating controls are need to be
   * shown for the response in the Dialogflow Messenger widget.
   */
  allowAnswerFeedback: boolean;
  /**
   * Optional. Data store connection feature output signals.
   * Filled only when data stores are involved in serving the query and
   * DetectIntentRequest.populate data_store_connection_quality_signals is set
   * to true in the request.
   */
  dataStoreConnectionSignals: DataStoreConnectionSignals | undefined;
}

/** Represents the natural language text to be processed. */
export interface TextInput {
  /** Required. The UTF-8 encoded natural language text to be processed. */
  text: string;
}

/**
 * Represents the intent to trigger programmatically rather than as a result of
 * natural language processing.
 */
export interface IntentInput {
  /**
   * Required. The unique identifier of the intent.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/intents/<Intent ID>`.
   */
  intent: string;
}

/** Represents the natural speech audio to be processed. */
export interface AudioInput {
  /** Required. Instructs the speech recognizer how to process the speech audio. */
  config:
    | InputAudioConfig
    | undefined;
  /**
   * The natural language speech audio to be processed.
   * A single request can contain up to 2 minutes of speech audio data.
   * The [transcribed
   * text][google.cloud.dialogflow.cx.v3.QueryResult.transcript] cannot contain
   * more than 256 bytes.
   *
   * For non-streaming audio detect intent, both `config` and `audio` must be
   * provided.
   * For streaming audio detect intent, `config` must be provided in
   * the first request and `audio` must be provided in all following requests.
   */
  audio: Buffer;
}

/** Represents the event to trigger. */
export interface EventInput {
  /** Name of the event. */
  event: string;
}

/** Represents the input for dtmf event. */
export interface DtmfInput {
  /** The dtmf digits. */
  digits: string;
  /** The finish digit (if any). */
  finishDigit: string;
}

/** Represents one match result of [MatchIntent][]. */
export interface Match {
  /**
   * The [Intent][google.cloud.dialogflow.cx.v3.Intent] that matched the query.
   * Some, not all fields are filled in this message, including but not limited
   * to: `name` and `display_name`. Only filled for
   * [`INTENT`][google.cloud.dialogflow.cx.v3.Match.MatchType] match type.
   */
  intent:
    | Intent
    | undefined;
  /**
   * The event that matched the query. Filled for
   * [`EVENT`][google.cloud.dialogflow.cx.v3.Match.MatchType],
   * [`NO_MATCH`][google.cloud.dialogflow.cx.v3.Match.MatchType] and
   * [`NO_INPUT`][google.cloud.dialogflow.cx.v3.Match.MatchType] match types.
   */
  event: string;
  /**
   * The collection of parameters extracted from the query.
   *
   * Depending on your protocol or client library language, this is a
   * map, associative array, symbol table, dictionary, or JSON object
   * composed of a collection of (MapKey, MapValue) pairs:
   *
   * * MapKey type: string
   * * MapKey value: parameter name
   * * MapValue type: If parameter's entity type is a composite entity then use
   * map, otherwise, depending on the parameter value type, it could be one of
   * string, number, boolean, null, list or map.
   * * MapValue value: If parameter's entity type is a composite entity then use
   * map from composite entity property names to property values, otherwise,
   * use parameter value.
   */
  parameters:
    | { [key: string]: any }
    | undefined;
  /**
   * Final text input which was matched during MatchIntent. This value can be
   * different from original input sent in request because of spelling
   * correction or other processing.
   */
  resolvedInput: string;
  /** Type of this [Match][google.cloud.dialogflow.cx.v3.Match]. */
  matchType: Match_MatchType;
  /**
   * The confidence of this match. Values range from 0.0 (completely uncertain)
   * to 1.0 (completely certain).
   * This value is for informational purpose only and is only used to help match
   * the best intent within the classification threshold. This value may change
   * for the same end-user expression at any time due to a model retraining or
   * change in implementation.
   */
  confidence: number;
}

/** Type of a Match. */
export enum Match_MatchType {
  /** MATCH_TYPE_UNSPECIFIED - Not specified. Should never be used. */
  MATCH_TYPE_UNSPECIFIED = 0,
  /** INTENT - The query was matched to an intent. */
  INTENT = 1,
  /** DIRECT_INTENT - The query directly triggered an intent. */
  DIRECT_INTENT = 2,
  /** PARAMETER_FILLING - The query was used for parameter filling. */
  PARAMETER_FILLING = 3,
  /** NO_MATCH - No match was found for the query. */
  NO_MATCH = 4,
  /** NO_INPUT - Indicates an empty query. */
  NO_INPUT = 5,
  /** EVENT - The query directly triggered an event. */
  EVENT = 6,
  /** KNOWLEDGE_CONNECTOR - The query was matched to a Knowledge Connector answer. */
  KNOWLEDGE_CONNECTOR = 8,
  /** PLAYBOOK - The query was handled by a [`Playbook`][Playbook]. */
  PLAYBOOK = 9,
  UNRECOGNIZED = -1,
}

export function match_MatchTypeFromJSON(object: any): Match_MatchType {
  switch (object) {
    case 0:
    case "MATCH_TYPE_UNSPECIFIED":
      return Match_MatchType.MATCH_TYPE_UNSPECIFIED;
    case 1:
    case "INTENT":
      return Match_MatchType.INTENT;
    case 2:
    case "DIRECT_INTENT":
      return Match_MatchType.DIRECT_INTENT;
    case 3:
    case "PARAMETER_FILLING":
      return Match_MatchType.PARAMETER_FILLING;
    case 4:
    case "NO_MATCH":
      return Match_MatchType.NO_MATCH;
    case 5:
    case "NO_INPUT":
      return Match_MatchType.NO_INPUT;
    case 6:
    case "EVENT":
      return Match_MatchType.EVENT;
    case 8:
    case "KNOWLEDGE_CONNECTOR":
      return Match_MatchType.KNOWLEDGE_CONNECTOR;
    case 9:
    case "PLAYBOOK":
      return Match_MatchType.PLAYBOOK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Match_MatchType.UNRECOGNIZED;
  }
}

export function match_MatchTypeToJSON(object: Match_MatchType): string {
  switch (object) {
    case Match_MatchType.MATCH_TYPE_UNSPECIFIED:
      return "MATCH_TYPE_UNSPECIFIED";
    case Match_MatchType.INTENT:
      return "INTENT";
    case Match_MatchType.DIRECT_INTENT:
      return "DIRECT_INTENT";
    case Match_MatchType.PARAMETER_FILLING:
      return "PARAMETER_FILLING";
    case Match_MatchType.NO_MATCH:
      return "NO_MATCH";
    case Match_MatchType.NO_INPUT:
      return "NO_INPUT";
    case Match_MatchType.EVENT:
      return "EVENT";
    case Match_MatchType.KNOWLEDGE_CONNECTOR:
      return "KNOWLEDGE_CONNECTOR";
    case Match_MatchType.PLAYBOOK:
      return "PLAYBOOK";
    case Match_MatchType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Request of [MatchIntent][]. */
export interface MatchIntentRequest {
  /**
   * Required. The name of the session this query is sent to.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/sessions/<Session ID>` or `projects/<Project ID>/locations/<Location
   * ID>/agents/<Agent ID>/environments/<Environment ID>/sessions/<Session ID>`.
   * If `Environment ID` is not specified, we assume default 'draft'
   * environment.
   * It's up to the API caller to choose an appropriate `Session ID`. It can be
   * a random number or some type of session identifiers (preferably hashed).
   * The length of the `Session ID` must not exceed 36 characters.
   *
   * For more information, see the [sessions
   * guide](https://cloud.google.com/dialogflow/cx/docs/concept/session).
   */
  session: string;
  /** The parameters of this query. */
  queryParams:
    | QueryParameters
    | undefined;
  /** Required. The input specification. */
  queryInput:
    | QueryInput
    | undefined;
  /** Persist session parameter changes from `query_params`. */
  persistParameterChanges: boolean;
}

/** Response of [MatchIntent][]. */
export interface MatchIntentResponse {
  /**
   * If [natural language text][google.cloud.dialogflow.cx.v3.TextInput] was
   * provided as input, this field will contain a copy of the text.
   */
  text?:
    | string
    | undefined;
  /**
   * If an [intent][google.cloud.dialogflow.cx.v3.IntentInput] was provided as
   * input, this field will contain a copy of the intent identifier. Format:
   * `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/intents/<Intent ID>`.
   */
  triggerIntent?:
    | string
    | undefined;
  /**
   * If [natural language speech
   * audio][google.cloud.dialogflow.cx.v3.AudioInput] was provided as input,
   * this field will contain the transcript for the audio.
   */
  transcript?:
    | string
    | undefined;
  /**
   * If an [event][google.cloud.dialogflow.cx.v3.EventInput] was provided as
   * input, this field will contain a copy of the event name.
   */
  triggerEvent?:
    | string
    | undefined;
  /**
   * Match results, if more than one, ordered descendingly by the confidence
   * we have that the particular intent matches the query.
   */
  matches: Match[];
  /**
   * The current [Page][google.cloud.dialogflow.cx.v3.Page]. Some, not all
   * fields are filled in this message, including but not limited to `name` and
   * `display_name`.
   */
  currentPage: Page | undefined;
}

/** Request of [FulfillIntent][] */
export interface FulfillIntentRequest {
  /**
   * Must be same as the corresponding MatchIntent request, otherwise the
   * behavior is undefined.
   */
  matchIntentRequest:
    | MatchIntentRequest
    | undefined;
  /** The matched intent/event to fulfill. */
  match:
    | Match
    | undefined;
  /** Instructs the speech synthesizer how to generate output audio. */
  outputAudioConfig: OutputAudioConfig | undefined;
}

/** Response of [FulfillIntent][] */
export interface FulfillIntentResponse {
  /**
   * Output only. The unique identifier of the response. It can be used to
   * locate a response in the training example set or for reporting issues.
   */
  responseId: string;
  /** The result of the conversational query. */
  queryResult:
    | QueryResult
    | undefined;
  /**
   * The audio data bytes encoded as specified in the request.
   * Note: The output audio is generated based on the values of default platform
   * text responses found in the
   * [`query_result.response_messages`][google.cloud.dialogflow.cx.v3.QueryResult.response_messages]
   * field. If multiple default text responses exist, they will be concatenated
   * when generating audio. If no default platform text responses exist, the
   * generated audio content will be empty.
   *
   * In some scenarios, multiple output audio fields may be present in the
   * response structure. In these cases, only the top-most-level audio output
   * has content.
   */
  outputAudio: Buffer;
  /** The config used by the speech synthesizer to generate the output audio. */
  outputAudioConfig: OutputAudioConfig | undefined;
}

/**
 * The result of sentiment analysis. Sentiment analysis inspects user input
 * and identifies the prevailing subjective opinion, especially to determine a
 * user's attitude as positive, negative, or neutral.
 */
export interface SentimentAnalysisResult {
  /**
   * Sentiment score between -1.0 (negative sentiment) and 1.0 (positive
   * sentiment).
   */
  score: number;
  /**
   * A non-negative number in the [0, +inf) range, which represents the absolute
   * magnitude of sentiment, regardless of score (positive or negative).
   */
  magnitude: number;
}

function createBaseAnswerFeedback(): AnswerFeedback {
  return { rating: 0, ratingReason: undefined, customRating: "" };
}

export const AnswerFeedback: MessageFns<AnswerFeedback> = {
  encode(message: AnswerFeedback, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rating !== 0) {
      writer.uint32(8).int32(message.rating);
    }
    if (message.ratingReason !== undefined) {
      AnswerFeedback_RatingReason.encode(message.ratingReason, writer.uint32(18).fork()).join();
    }
    if (message.customRating !== "") {
      writer.uint32(26).string(message.customRating);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnswerFeedback {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnswerFeedback();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.rating = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.ratingReason = AnswerFeedback_RatingReason.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.customRating = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnswerFeedback {
    return {
      rating: isSet(object.rating) ? answerFeedback_RatingFromJSON(object.rating) : 0,
      ratingReason: isSet(object.ratingReason) ? AnswerFeedback_RatingReason.fromJSON(object.ratingReason) : undefined,
      customRating: isSet(object.customRating) ? globalThis.String(object.customRating) : "",
    };
  },

  toJSON(message: AnswerFeedback): unknown {
    const obj: any = {};
    if (message.rating !== 0) {
      obj.rating = answerFeedback_RatingToJSON(message.rating);
    }
    if (message.ratingReason !== undefined) {
      obj.ratingReason = AnswerFeedback_RatingReason.toJSON(message.ratingReason);
    }
    if (message.customRating !== "") {
      obj.customRating = message.customRating;
    }
    return obj;
  },

  create(base?: DeepPartial<AnswerFeedback>): AnswerFeedback {
    return AnswerFeedback.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnswerFeedback>): AnswerFeedback {
    const message = createBaseAnswerFeedback();
    message.rating = object.rating ?? 0;
    message.ratingReason = (object.ratingReason !== undefined && object.ratingReason !== null)
      ? AnswerFeedback_RatingReason.fromPartial(object.ratingReason)
      : undefined;
    message.customRating = object.customRating ?? "";
    return message;
  },
};

function createBaseAnswerFeedback_RatingReason(): AnswerFeedback_RatingReason {
  return { reasonLabels: [], feedback: "" };
}

export const AnswerFeedback_RatingReason: MessageFns<AnswerFeedback_RatingReason> = {
  encode(message: AnswerFeedback_RatingReason, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.reasonLabels) {
      writer.uint32(26).string(v!);
    }
    if (message.feedback !== "") {
      writer.uint32(18).string(message.feedback);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnswerFeedback_RatingReason {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnswerFeedback_RatingReason();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.reasonLabels.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.feedback = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnswerFeedback_RatingReason {
    return {
      reasonLabels: globalThis.Array.isArray(object?.reasonLabels)
        ? object.reasonLabels.map((e: any) => globalThis.String(e))
        : [],
      feedback: isSet(object.feedback) ? globalThis.String(object.feedback) : "",
    };
  },

  toJSON(message: AnswerFeedback_RatingReason): unknown {
    const obj: any = {};
    if (message.reasonLabels?.length) {
      obj.reasonLabels = message.reasonLabels;
    }
    if (message.feedback !== "") {
      obj.feedback = message.feedback;
    }
    return obj;
  },

  create(base?: DeepPartial<AnswerFeedback_RatingReason>): AnswerFeedback_RatingReason {
    return AnswerFeedback_RatingReason.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnswerFeedback_RatingReason>): AnswerFeedback_RatingReason {
    const message = createBaseAnswerFeedback_RatingReason();
    message.reasonLabels = object.reasonLabels?.map((e) => e) || [];
    message.feedback = object.feedback ?? "";
    return message;
  },
};

function createBaseSubmitAnswerFeedbackRequest(): SubmitAnswerFeedbackRequest {
  return { session: "", responseId: "", answerFeedback: undefined, updateMask: undefined };
}

export const SubmitAnswerFeedbackRequest: MessageFns<SubmitAnswerFeedbackRequest> = {
  encode(message: SubmitAnswerFeedbackRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.session !== "") {
      writer.uint32(10).string(message.session);
    }
    if (message.responseId !== "") {
      writer.uint32(18).string(message.responseId);
    }
    if (message.answerFeedback !== undefined) {
      AnswerFeedback.encode(message.answerFeedback, writer.uint32(26).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SubmitAnswerFeedbackRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSubmitAnswerFeedbackRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.session = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.responseId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.answerFeedback = AnswerFeedback.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SubmitAnswerFeedbackRequest {
    return {
      session: isSet(object.session) ? globalThis.String(object.session) : "",
      responseId: isSet(object.responseId) ? globalThis.String(object.responseId) : "",
      answerFeedback: isSet(object.answerFeedback) ? AnswerFeedback.fromJSON(object.answerFeedback) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: SubmitAnswerFeedbackRequest): unknown {
    const obj: any = {};
    if (message.session !== "") {
      obj.session = message.session;
    }
    if (message.responseId !== "") {
      obj.responseId = message.responseId;
    }
    if (message.answerFeedback !== undefined) {
      obj.answerFeedback = AnswerFeedback.toJSON(message.answerFeedback);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<SubmitAnswerFeedbackRequest>): SubmitAnswerFeedbackRequest {
    return SubmitAnswerFeedbackRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SubmitAnswerFeedbackRequest>): SubmitAnswerFeedbackRequest {
    const message = createBaseSubmitAnswerFeedbackRequest();
    message.session = object.session ?? "";
    message.responseId = object.responseId ?? "";
    message.answerFeedback = (object.answerFeedback !== undefined && object.answerFeedback !== null)
      ? AnswerFeedback.fromPartial(object.answerFeedback)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDetectIntentRequest(): DetectIntentRequest {
  return { session: "", queryParams: undefined, queryInput: undefined, outputAudioConfig: undefined };
}

export const DetectIntentRequest: MessageFns<DetectIntentRequest> = {
  encode(message: DetectIntentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.session !== "") {
      writer.uint32(10).string(message.session);
    }
    if (message.queryParams !== undefined) {
      QueryParameters.encode(message.queryParams, writer.uint32(18).fork()).join();
    }
    if (message.queryInput !== undefined) {
      QueryInput.encode(message.queryInput, writer.uint32(26).fork()).join();
    }
    if (message.outputAudioConfig !== undefined) {
      OutputAudioConfig.encode(message.outputAudioConfig, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DetectIntentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDetectIntentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.session = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryParams = QueryParameters.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.queryInput = QueryInput.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputAudioConfig = OutputAudioConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DetectIntentRequest {
    return {
      session: isSet(object.session) ? globalThis.String(object.session) : "",
      queryParams: isSet(object.queryParams) ? QueryParameters.fromJSON(object.queryParams) : undefined,
      queryInput: isSet(object.queryInput) ? QueryInput.fromJSON(object.queryInput) : undefined,
      outputAudioConfig: isSet(object.outputAudioConfig)
        ? OutputAudioConfig.fromJSON(object.outputAudioConfig)
        : undefined,
    };
  },

  toJSON(message: DetectIntentRequest): unknown {
    const obj: any = {};
    if (message.session !== "") {
      obj.session = message.session;
    }
    if (message.queryParams !== undefined) {
      obj.queryParams = QueryParameters.toJSON(message.queryParams);
    }
    if (message.queryInput !== undefined) {
      obj.queryInput = QueryInput.toJSON(message.queryInput);
    }
    if (message.outputAudioConfig !== undefined) {
      obj.outputAudioConfig = OutputAudioConfig.toJSON(message.outputAudioConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<DetectIntentRequest>): DetectIntentRequest {
    return DetectIntentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DetectIntentRequest>): DetectIntentRequest {
    const message = createBaseDetectIntentRequest();
    message.session = object.session ?? "";
    message.queryParams = (object.queryParams !== undefined && object.queryParams !== null)
      ? QueryParameters.fromPartial(object.queryParams)
      : undefined;
    message.queryInput = (object.queryInput !== undefined && object.queryInput !== null)
      ? QueryInput.fromPartial(object.queryInput)
      : undefined;
    message.outputAudioConfig = (object.outputAudioConfig !== undefined && object.outputAudioConfig !== null)
      ? OutputAudioConfig.fromPartial(object.outputAudioConfig)
      : undefined;
    return message;
  },
};

function createBaseDetectIntentResponse(): DetectIntentResponse {
  return {
    responseId: "",
    queryResult: undefined,
    outputAudio: Buffer.alloc(0),
    outputAudioConfig: undefined,
    responseType: 0,
    allowCancellation: false,
  };
}

export const DetectIntentResponse: MessageFns<DetectIntentResponse> = {
  encode(message: DetectIntentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.responseId !== "") {
      writer.uint32(10).string(message.responseId);
    }
    if (message.queryResult !== undefined) {
      QueryResult.encode(message.queryResult, writer.uint32(18).fork()).join();
    }
    if (message.outputAudio.length !== 0) {
      writer.uint32(34).bytes(message.outputAudio);
    }
    if (message.outputAudioConfig !== undefined) {
      OutputAudioConfig.encode(message.outputAudioConfig, writer.uint32(42).fork()).join();
    }
    if (message.responseType !== 0) {
      writer.uint32(48).int32(message.responseType);
    }
    if (message.allowCancellation !== false) {
      writer.uint32(56).bool(message.allowCancellation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DetectIntentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDetectIntentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.responseId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryResult = QueryResult.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputAudio = Buffer.from(reader.bytes());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.outputAudioConfig = OutputAudioConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.responseType = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.allowCancellation = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DetectIntentResponse {
    return {
      responseId: isSet(object.responseId) ? globalThis.String(object.responseId) : "",
      queryResult: isSet(object.queryResult) ? QueryResult.fromJSON(object.queryResult) : undefined,
      outputAudio: isSet(object.outputAudio) ? Buffer.from(bytesFromBase64(object.outputAudio)) : Buffer.alloc(0),
      outputAudioConfig: isSet(object.outputAudioConfig)
        ? OutputAudioConfig.fromJSON(object.outputAudioConfig)
        : undefined,
      responseType: isSet(object.responseType) ? detectIntentResponse_ResponseTypeFromJSON(object.responseType) : 0,
      allowCancellation: isSet(object.allowCancellation) ? globalThis.Boolean(object.allowCancellation) : false,
    };
  },

  toJSON(message: DetectIntentResponse): unknown {
    const obj: any = {};
    if (message.responseId !== "") {
      obj.responseId = message.responseId;
    }
    if (message.queryResult !== undefined) {
      obj.queryResult = QueryResult.toJSON(message.queryResult);
    }
    if (message.outputAudio.length !== 0) {
      obj.outputAudio = base64FromBytes(message.outputAudio);
    }
    if (message.outputAudioConfig !== undefined) {
      obj.outputAudioConfig = OutputAudioConfig.toJSON(message.outputAudioConfig);
    }
    if (message.responseType !== 0) {
      obj.responseType = detectIntentResponse_ResponseTypeToJSON(message.responseType);
    }
    if (message.allowCancellation !== false) {
      obj.allowCancellation = message.allowCancellation;
    }
    return obj;
  },

  create(base?: DeepPartial<DetectIntentResponse>): DetectIntentResponse {
    return DetectIntentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DetectIntentResponse>): DetectIntentResponse {
    const message = createBaseDetectIntentResponse();
    message.responseId = object.responseId ?? "";
    message.queryResult = (object.queryResult !== undefined && object.queryResult !== null)
      ? QueryResult.fromPartial(object.queryResult)
      : undefined;
    message.outputAudio = object.outputAudio ?? Buffer.alloc(0);
    message.outputAudioConfig = (object.outputAudioConfig !== undefined && object.outputAudioConfig !== null)
      ? OutputAudioConfig.fromPartial(object.outputAudioConfig)
      : undefined;
    message.responseType = object.responseType ?? 0;
    message.allowCancellation = object.allowCancellation ?? false;
    return message;
  },
};

function createBaseStreamingDetectIntentRequest(): StreamingDetectIntentRequest {
  return {
    session: "",
    queryParams: undefined,
    queryInput: undefined,
    outputAudioConfig: undefined,
    enablePartialResponse: false,
    enableDebuggingInfo: false,
  };
}

export const StreamingDetectIntentRequest: MessageFns<StreamingDetectIntentRequest> = {
  encode(message: StreamingDetectIntentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.session !== "") {
      writer.uint32(10).string(message.session);
    }
    if (message.queryParams !== undefined) {
      QueryParameters.encode(message.queryParams, writer.uint32(18).fork()).join();
    }
    if (message.queryInput !== undefined) {
      QueryInput.encode(message.queryInput, writer.uint32(26).fork()).join();
    }
    if (message.outputAudioConfig !== undefined) {
      OutputAudioConfig.encode(message.outputAudioConfig, writer.uint32(34).fork()).join();
    }
    if (message.enablePartialResponse !== false) {
      writer.uint32(40).bool(message.enablePartialResponse);
    }
    if (message.enableDebuggingInfo !== false) {
      writer.uint32(64).bool(message.enableDebuggingInfo);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingDetectIntentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingDetectIntentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.session = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryParams = QueryParameters.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.queryInput = QueryInput.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputAudioConfig = OutputAudioConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.enablePartialResponse = reader.bool();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.enableDebuggingInfo = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingDetectIntentRequest {
    return {
      session: isSet(object.session) ? globalThis.String(object.session) : "",
      queryParams: isSet(object.queryParams) ? QueryParameters.fromJSON(object.queryParams) : undefined,
      queryInput: isSet(object.queryInput) ? QueryInput.fromJSON(object.queryInput) : undefined,
      outputAudioConfig: isSet(object.outputAudioConfig)
        ? OutputAudioConfig.fromJSON(object.outputAudioConfig)
        : undefined,
      enablePartialResponse: isSet(object.enablePartialResponse)
        ? globalThis.Boolean(object.enablePartialResponse)
        : false,
      enableDebuggingInfo: isSet(object.enableDebuggingInfo) ? globalThis.Boolean(object.enableDebuggingInfo) : false,
    };
  },

  toJSON(message: StreamingDetectIntentRequest): unknown {
    const obj: any = {};
    if (message.session !== "") {
      obj.session = message.session;
    }
    if (message.queryParams !== undefined) {
      obj.queryParams = QueryParameters.toJSON(message.queryParams);
    }
    if (message.queryInput !== undefined) {
      obj.queryInput = QueryInput.toJSON(message.queryInput);
    }
    if (message.outputAudioConfig !== undefined) {
      obj.outputAudioConfig = OutputAudioConfig.toJSON(message.outputAudioConfig);
    }
    if (message.enablePartialResponse !== false) {
      obj.enablePartialResponse = message.enablePartialResponse;
    }
    if (message.enableDebuggingInfo !== false) {
      obj.enableDebuggingInfo = message.enableDebuggingInfo;
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingDetectIntentRequest>): StreamingDetectIntentRequest {
    return StreamingDetectIntentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingDetectIntentRequest>): StreamingDetectIntentRequest {
    const message = createBaseStreamingDetectIntentRequest();
    message.session = object.session ?? "";
    message.queryParams = (object.queryParams !== undefined && object.queryParams !== null)
      ? QueryParameters.fromPartial(object.queryParams)
      : undefined;
    message.queryInput = (object.queryInput !== undefined && object.queryInput !== null)
      ? QueryInput.fromPartial(object.queryInput)
      : undefined;
    message.outputAudioConfig = (object.outputAudioConfig !== undefined && object.outputAudioConfig !== null)
      ? OutputAudioConfig.fromPartial(object.outputAudioConfig)
      : undefined;
    message.enablePartialResponse = object.enablePartialResponse ?? false;
    message.enableDebuggingInfo = object.enableDebuggingInfo ?? false;
    return message;
  },
};

function createBaseCloudConversationDebuggingInfo(): CloudConversationDebuggingInfo {
  return {
    audioDataChunks: 0,
    resultEndTimeOffset: undefined,
    firstAudioDuration: undefined,
    singleUtterance: false,
    speechPartialResultsEndTimes: [],
    speechFinalResultsEndTimes: [],
    partialResponses: 0,
    speakerIdPassiveLatencyMsOffset: 0,
    bargeinEventTriggered: false,
    speechSingleUtterance: false,
    dtmfPartialResultsTimes: [],
    dtmfFinalResultsTimes: [],
    singleUtteranceEndTimeOffset: undefined,
    noSpeechTimeout: undefined,
    endpointingTimeout: undefined,
    isInputText: false,
    clientHalfCloseTimeOffset: undefined,
    clientHalfCloseStreamingTimeOffset: undefined,
  };
}

export const CloudConversationDebuggingInfo: MessageFns<CloudConversationDebuggingInfo> = {
  encode(message: CloudConversationDebuggingInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.audioDataChunks !== 0) {
      writer.uint32(8).int32(message.audioDataChunks);
    }
    if (message.resultEndTimeOffset !== undefined) {
      Duration.encode(message.resultEndTimeOffset, writer.uint32(18).fork()).join();
    }
    if (message.firstAudioDuration !== undefined) {
      Duration.encode(message.firstAudioDuration, writer.uint32(26).fork()).join();
    }
    if (message.singleUtterance !== false) {
      writer.uint32(40).bool(message.singleUtterance);
    }
    for (const v of message.speechPartialResultsEndTimes) {
      Duration.encode(v!, writer.uint32(50).fork()).join();
    }
    for (const v of message.speechFinalResultsEndTimes) {
      Duration.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.partialResponses !== 0) {
      writer.uint32(64).int32(message.partialResponses);
    }
    if (message.speakerIdPassiveLatencyMsOffset !== 0) {
      writer.uint32(72).int32(message.speakerIdPassiveLatencyMsOffset);
    }
    if (message.bargeinEventTriggered !== false) {
      writer.uint32(80).bool(message.bargeinEventTriggered);
    }
    if (message.speechSingleUtterance !== false) {
      writer.uint32(88).bool(message.speechSingleUtterance);
    }
    for (const v of message.dtmfPartialResultsTimes) {
      Duration.encode(v!, writer.uint32(98).fork()).join();
    }
    for (const v of message.dtmfFinalResultsTimes) {
      Duration.encode(v!, writer.uint32(106).fork()).join();
    }
    if (message.singleUtteranceEndTimeOffset !== undefined) {
      Duration.encode(message.singleUtteranceEndTimeOffset, writer.uint32(114).fork()).join();
    }
    if (message.noSpeechTimeout !== undefined) {
      Duration.encode(message.noSpeechTimeout, writer.uint32(122).fork()).join();
    }
    if (message.endpointingTimeout !== undefined) {
      Duration.encode(message.endpointingTimeout, writer.uint32(154).fork()).join();
    }
    if (message.isInputText !== false) {
      writer.uint32(128).bool(message.isInputText);
    }
    if (message.clientHalfCloseTimeOffset !== undefined) {
      Duration.encode(message.clientHalfCloseTimeOffset, writer.uint32(138).fork()).join();
    }
    if (message.clientHalfCloseStreamingTimeOffset !== undefined) {
      Duration.encode(message.clientHalfCloseStreamingTimeOffset, writer.uint32(146).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudConversationDebuggingInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudConversationDebuggingInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.audioDataChunks = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resultEndTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.firstAudioDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.singleUtterance = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.speechPartialResultsEndTimes.push(Duration.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.speechFinalResultsEndTimes.push(Duration.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.partialResponses = reader.int32();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.speakerIdPassiveLatencyMsOffset = reader.int32();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.bargeinEventTriggered = reader.bool();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.speechSingleUtterance = reader.bool();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.dtmfPartialResultsTimes.push(Duration.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.dtmfFinalResultsTimes.push(Duration.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.singleUtteranceEndTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.noSpeechTimeout = Duration.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.endpointingTimeout = Duration.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.isInputText = reader.bool();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.clientHalfCloseTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.clientHalfCloseStreamingTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudConversationDebuggingInfo {
    return {
      audioDataChunks: isSet(object.audioDataChunks) ? globalThis.Number(object.audioDataChunks) : 0,
      resultEndTimeOffset: isSet(object.resultEndTimeOffset)
        ? Duration.fromJSON(object.resultEndTimeOffset)
        : undefined,
      firstAudioDuration: isSet(object.firstAudioDuration) ? Duration.fromJSON(object.firstAudioDuration) : undefined,
      singleUtterance: isSet(object.singleUtterance) ? globalThis.Boolean(object.singleUtterance) : false,
      speechPartialResultsEndTimes: globalThis.Array.isArray(object?.speechPartialResultsEndTimes)
        ? object.speechPartialResultsEndTimes.map((e: any) => Duration.fromJSON(e))
        : [],
      speechFinalResultsEndTimes: globalThis.Array.isArray(object?.speechFinalResultsEndTimes)
        ? object.speechFinalResultsEndTimes.map((e: any) => Duration.fromJSON(e))
        : [],
      partialResponses: isSet(object.partialResponses) ? globalThis.Number(object.partialResponses) : 0,
      speakerIdPassiveLatencyMsOffset: isSet(object.speakerIdPassiveLatencyMsOffset)
        ? globalThis.Number(object.speakerIdPassiveLatencyMsOffset)
        : 0,
      bargeinEventTriggered: isSet(object.bargeinEventTriggered)
        ? globalThis.Boolean(object.bargeinEventTriggered)
        : false,
      speechSingleUtterance: isSet(object.speechSingleUtterance)
        ? globalThis.Boolean(object.speechSingleUtterance)
        : false,
      dtmfPartialResultsTimes: globalThis.Array.isArray(object?.dtmfPartialResultsTimes)
        ? object.dtmfPartialResultsTimes.map((e: any) => Duration.fromJSON(e))
        : [],
      dtmfFinalResultsTimes: globalThis.Array.isArray(object?.dtmfFinalResultsTimes)
        ? object.dtmfFinalResultsTimes.map((e: any) => Duration.fromJSON(e))
        : [],
      singleUtteranceEndTimeOffset: isSet(object.singleUtteranceEndTimeOffset)
        ? Duration.fromJSON(object.singleUtteranceEndTimeOffset)
        : undefined,
      noSpeechTimeout: isSet(object.noSpeechTimeout) ? Duration.fromJSON(object.noSpeechTimeout) : undefined,
      endpointingTimeout: isSet(object.endpointingTimeout) ? Duration.fromJSON(object.endpointingTimeout) : undefined,
      isInputText: isSet(object.isInputText) ? globalThis.Boolean(object.isInputText) : false,
      clientHalfCloseTimeOffset: isSet(object.clientHalfCloseTimeOffset)
        ? Duration.fromJSON(object.clientHalfCloseTimeOffset)
        : undefined,
      clientHalfCloseStreamingTimeOffset: isSet(object.clientHalfCloseStreamingTimeOffset)
        ? Duration.fromJSON(object.clientHalfCloseStreamingTimeOffset)
        : undefined,
    };
  },

  toJSON(message: CloudConversationDebuggingInfo): unknown {
    const obj: any = {};
    if (message.audioDataChunks !== 0) {
      obj.audioDataChunks = Math.round(message.audioDataChunks);
    }
    if (message.resultEndTimeOffset !== undefined) {
      obj.resultEndTimeOffset = Duration.toJSON(message.resultEndTimeOffset);
    }
    if (message.firstAudioDuration !== undefined) {
      obj.firstAudioDuration = Duration.toJSON(message.firstAudioDuration);
    }
    if (message.singleUtterance !== false) {
      obj.singleUtterance = message.singleUtterance;
    }
    if (message.speechPartialResultsEndTimes?.length) {
      obj.speechPartialResultsEndTimes = message.speechPartialResultsEndTimes.map((e) => Duration.toJSON(e));
    }
    if (message.speechFinalResultsEndTimes?.length) {
      obj.speechFinalResultsEndTimes = message.speechFinalResultsEndTimes.map((e) => Duration.toJSON(e));
    }
    if (message.partialResponses !== 0) {
      obj.partialResponses = Math.round(message.partialResponses);
    }
    if (message.speakerIdPassiveLatencyMsOffset !== 0) {
      obj.speakerIdPassiveLatencyMsOffset = Math.round(message.speakerIdPassiveLatencyMsOffset);
    }
    if (message.bargeinEventTriggered !== false) {
      obj.bargeinEventTriggered = message.bargeinEventTriggered;
    }
    if (message.speechSingleUtterance !== false) {
      obj.speechSingleUtterance = message.speechSingleUtterance;
    }
    if (message.dtmfPartialResultsTimes?.length) {
      obj.dtmfPartialResultsTimes = message.dtmfPartialResultsTimes.map((e) => Duration.toJSON(e));
    }
    if (message.dtmfFinalResultsTimes?.length) {
      obj.dtmfFinalResultsTimes = message.dtmfFinalResultsTimes.map((e) => Duration.toJSON(e));
    }
    if (message.singleUtteranceEndTimeOffset !== undefined) {
      obj.singleUtteranceEndTimeOffset = Duration.toJSON(message.singleUtteranceEndTimeOffset);
    }
    if (message.noSpeechTimeout !== undefined) {
      obj.noSpeechTimeout = Duration.toJSON(message.noSpeechTimeout);
    }
    if (message.endpointingTimeout !== undefined) {
      obj.endpointingTimeout = Duration.toJSON(message.endpointingTimeout);
    }
    if (message.isInputText !== false) {
      obj.isInputText = message.isInputText;
    }
    if (message.clientHalfCloseTimeOffset !== undefined) {
      obj.clientHalfCloseTimeOffset = Duration.toJSON(message.clientHalfCloseTimeOffset);
    }
    if (message.clientHalfCloseStreamingTimeOffset !== undefined) {
      obj.clientHalfCloseStreamingTimeOffset = Duration.toJSON(message.clientHalfCloseStreamingTimeOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<CloudConversationDebuggingInfo>): CloudConversationDebuggingInfo {
    return CloudConversationDebuggingInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudConversationDebuggingInfo>): CloudConversationDebuggingInfo {
    const message = createBaseCloudConversationDebuggingInfo();
    message.audioDataChunks = object.audioDataChunks ?? 0;
    message.resultEndTimeOffset = (object.resultEndTimeOffset !== undefined && object.resultEndTimeOffset !== null)
      ? Duration.fromPartial(object.resultEndTimeOffset)
      : undefined;
    message.firstAudioDuration = (object.firstAudioDuration !== undefined && object.firstAudioDuration !== null)
      ? Duration.fromPartial(object.firstAudioDuration)
      : undefined;
    message.singleUtterance = object.singleUtterance ?? false;
    message.speechPartialResultsEndTimes = object.speechPartialResultsEndTimes?.map((e) => Duration.fromPartial(e)) ||
      [];
    message.speechFinalResultsEndTimes = object.speechFinalResultsEndTimes?.map((e) => Duration.fromPartial(e)) || [];
    message.partialResponses = object.partialResponses ?? 0;
    message.speakerIdPassiveLatencyMsOffset = object.speakerIdPassiveLatencyMsOffset ?? 0;
    message.bargeinEventTriggered = object.bargeinEventTriggered ?? false;
    message.speechSingleUtterance = object.speechSingleUtterance ?? false;
    message.dtmfPartialResultsTimes = object.dtmfPartialResultsTimes?.map((e) => Duration.fromPartial(e)) || [];
    message.dtmfFinalResultsTimes = object.dtmfFinalResultsTimes?.map((e) => Duration.fromPartial(e)) || [];
    message.singleUtteranceEndTimeOffset =
      (object.singleUtteranceEndTimeOffset !== undefined && object.singleUtteranceEndTimeOffset !== null)
        ? Duration.fromPartial(object.singleUtteranceEndTimeOffset)
        : undefined;
    message.noSpeechTimeout = (object.noSpeechTimeout !== undefined && object.noSpeechTimeout !== null)
      ? Duration.fromPartial(object.noSpeechTimeout)
      : undefined;
    message.endpointingTimeout = (object.endpointingTimeout !== undefined && object.endpointingTimeout !== null)
      ? Duration.fromPartial(object.endpointingTimeout)
      : undefined;
    message.isInputText = object.isInputText ?? false;
    message.clientHalfCloseTimeOffset =
      (object.clientHalfCloseTimeOffset !== undefined && object.clientHalfCloseTimeOffset !== null)
        ? Duration.fromPartial(object.clientHalfCloseTimeOffset)
        : undefined;
    message.clientHalfCloseStreamingTimeOffset =
      (object.clientHalfCloseStreamingTimeOffset !== undefined && object.clientHalfCloseStreamingTimeOffset !== null)
        ? Duration.fromPartial(object.clientHalfCloseStreamingTimeOffset)
        : undefined;
    return message;
  },
};

function createBaseStreamingDetectIntentResponse(): StreamingDetectIntentResponse {
  return { recognitionResult: undefined, detectIntentResponse: undefined, debuggingInfo: undefined };
}

export const StreamingDetectIntentResponse: MessageFns<StreamingDetectIntentResponse> = {
  encode(message: StreamingDetectIntentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recognitionResult !== undefined) {
      StreamingRecognitionResult.encode(message.recognitionResult, writer.uint32(10).fork()).join();
    }
    if (message.detectIntentResponse !== undefined) {
      DetectIntentResponse.encode(message.detectIntentResponse, writer.uint32(18).fork()).join();
    }
    if (message.debuggingInfo !== undefined) {
      CloudConversationDebuggingInfo.encode(message.debuggingInfo, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingDetectIntentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingDetectIntentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.recognitionResult = StreamingRecognitionResult.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.detectIntentResponse = DetectIntentResponse.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.debuggingInfo = CloudConversationDebuggingInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingDetectIntentResponse {
    return {
      recognitionResult: isSet(object.recognitionResult)
        ? StreamingRecognitionResult.fromJSON(object.recognitionResult)
        : undefined,
      detectIntentResponse: isSet(object.detectIntentResponse)
        ? DetectIntentResponse.fromJSON(object.detectIntentResponse)
        : undefined,
      debuggingInfo: isSet(object.debuggingInfo)
        ? CloudConversationDebuggingInfo.fromJSON(object.debuggingInfo)
        : undefined,
    };
  },

  toJSON(message: StreamingDetectIntentResponse): unknown {
    const obj: any = {};
    if (message.recognitionResult !== undefined) {
      obj.recognitionResult = StreamingRecognitionResult.toJSON(message.recognitionResult);
    }
    if (message.detectIntentResponse !== undefined) {
      obj.detectIntentResponse = DetectIntentResponse.toJSON(message.detectIntentResponse);
    }
    if (message.debuggingInfo !== undefined) {
      obj.debuggingInfo = CloudConversationDebuggingInfo.toJSON(message.debuggingInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingDetectIntentResponse>): StreamingDetectIntentResponse {
    return StreamingDetectIntentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingDetectIntentResponse>): StreamingDetectIntentResponse {
    const message = createBaseStreamingDetectIntentResponse();
    message.recognitionResult = (object.recognitionResult !== undefined && object.recognitionResult !== null)
      ? StreamingRecognitionResult.fromPartial(object.recognitionResult)
      : undefined;
    message.detectIntentResponse = (object.detectIntentResponse !== undefined && object.detectIntentResponse !== null)
      ? DetectIntentResponse.fromPartial(object.detectIntentResponse)
      : undefined;
    message.debuggingInfo = (object.debuggingInfo !== undefined && object.debuggingInfo !== null)
      ? CloudConversationDebuggingInfo.fromPartial(object.debuggingInfo)
      : undefined;
    return message;
  },
};

function createBaseStreamingRecognitionResult(): StreamingRecognitionResult {
  return {
    messageType: 0,
    transcript: "",
    isFinal: false,
    confidence: 0,
    stability: 0,
    speechWordInfo: [],
    speechEndOffset: undefined,
    languageCode: "",
  };
}

export const StreamingRecognitionResult: MessageFns<StreamingRecognitionResult> = {
  encode(message: StreamingRecognitionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.messageType !== 0) {
      writer.uint32(8).int32(message.messageType);
    }
    if (message.transcript !== "") {
      writer.uint32(18).string(message.transcript);
    }
    if (message.isFinal !== false) {
      writer.uint32(24).bool(message.isFinal);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    if (message.stability !== 0) {
      writer.uint32(53).float(message.stability);
    }
    for (const v of message.speechWordInfo) {
      SpeechWordInfo.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.speechEndOffset !== undefined) {
      Duration.encode(message.speechEndOffset, writer.uint32(66).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(82).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.messageType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transcript = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.isFinal = reader.bool();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 6:
          if (tag !== 53) {
            break;
          }

          message.stability = reader.float();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.speechWordInfo.push(SpeechWordInfo.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.speechEndOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionResult {
    return {
      messageType: isSet(object.messageType) ? streamingRecognitionResult_MessageTypeFromJSON(object.messageType) : 0,
      transcript: isSet(object.transcript) ? globalThis.String(object.transcript) : "",
      isFinal: isSet(object.isFinal) ? globalThis.Boolean(object.isFinal) : false,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      stability: isSet(object.stability) ? globalThis.Number(object.stability) : 0,
      speechWordInfo: globalThis.Array.isArray(object?.speechWordInfo)
        ? object.speechWordInfo.map((e: any) => SpeechWordInfo.fromJSON(e))
        : [],
      speechEndOffset: isSet(object.speechEndOffset) ? Duration.fromJSON(object.speechEndOffset) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: StreamingRecognitionResult): unknown {
    const obj: any = {};
    if (message.messageType !== 0) {
      obj.messageType = streamingRecognitionResult_MessageTypeToJSON(message.messageType);
    }
    if (message.transcript !== "") {
      obj.transcript = message.transcript;
    }
    if (message.isFinal !== false) {
      obj.isFinal = message.isFinal;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.stability !== 0) {
      obj.stability = message.stability;
    }
    if (message.speechWordInfo?.length) {
      obj.speechWordInfo = message.speechWordInfo.map((e) => SpeechWordInfo.toJSON(e));
    }
    if (message.speechEndOffset !== undefined) {
      obj.speechEndOffset = Duration.toJSON(message.speechEndOffset);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingRecognitionResult>): StreamingRecognitionResult {
    return StreamingRecognitionResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingRecognitionResult>): StreamingRecognitionResult {
    const message = createBaseStreamingRecognitionResult();
    message.messageType = object.messageType ?? 0;
    message.transcript = object.transcript ?? "";
    message.isFinal = object.isFinal ?? false;
    message.confidence = object.confidence ?? 0;
    message.stability = object.stability ?? 0;
    message.speechWordInfo = object.speechWordInfo?.map((e) => SpeechWordInfo.fromPartial(e)) || [];
    message.speechEndOffset = (object.speechEndOffset !== undefined && object.speechEndOffset !== null)
      ? Duration.fromPartial(object.speechEndOffset)
      : undefined;
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseQueryParameters(): QueryParameters {
  return {
    timeZone: "",
    geoLocation: undefined,
    sessionEntityTypes: [],
    payload: undefined,
    parameters: undefined,
    currentPage: "",
    disableWebhook: false,
    analyzeQueryTextSentiment: false,
    webhookHeaders: {},
    flowVersions: [],
    channel: "",
    sessionTtl: undefined,
    endUserMetadata: undefined,
    searchConfig: undefined,
    populateDataStoreConnectionSignals: false,
  };
}

export const QueryParameters: MessageFns<QueryParameters> = {
  encode(message: QueryParameters, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeZone !== "") {
      writer.uint32(10).string(message.timeZone);
    }
    if (message.geoLocation !== undefined) {
      LatLng.encode(message.geoLocation, writer.uint32(18).fork()).join();
    }
    for (const v of message.sessionEntityTypes) {
      SessionEntityType.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.payload !== undefined) {
      Struct.encode(Struct.wrap(message.payload), writer.uint32(34).fork()).join();
    }
    if (message.parameters !== undefined) {
      Struct.encode(Struct.wrap(message.parameters), writer.uint32(42).fork()).join();
    }
    if (message.currentPage !== "") {
      writer.uint32(50).string(message.currentPage);
    }
    if (message.disableWebhook !== false) {
      writer.uint32(56).bool(message.disableWebhook);
    }
    if (message.analyzeQueryTextSentiment !== false) {
      writer.uint32(64).bool(message.analyzeQueryTextSentiment);
    }
    Object.entries(message.webhookHeaders).forEach(([key, value]) => {
      QueryParameters_WebhookHeadersEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    for (const v of message.flowVersions) {
      writer.uint32(114).string(v!);
    }
    if (message.channel !== "") {
      writer.uint32(122).string(message.channel);
    }
    if (message.sessionTtl !== undefined) {
      Duration.encode(message.sessionTtl, writer.uint32(130).fork()).join();
    }
    if (message.endUserMetadata !== undefined) {
      Struct.encode(Struct.wrap(message.endUserMetadata), writer.uint32(146).fork()).join();
    }
    if (message.searchConfig !== undefined) {
      SearchConfig.encode(message.searchConfig, writer.uint32(162).fork()).join();
    }
    if (message.populateDataStoreConnectionSignals !== false) {
      writer.uint32(200).bool(message.populateDataStoreConnectionSignals);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryParameters {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryParameters();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeZone = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.geoLocation = LatLng.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sessionEntityTypes.push(SessionEntityType.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.payload = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.parameters = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.currentPage = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.disableWebhook = reader.bool();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.analyzeQueryTextSentiment = reader.bool();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          const entry10 = QueryParameters_WebhookHeadersEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.webhookHeaders[entry10.key] = entry10.value;
          }
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.flowVersions.push(reader.string());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.channel = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.sessionTtl = Duration.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.endUserMetadata = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.searchConfig = SearchConfig.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 200) {
            break;
          }

          message.populateDataStoreConnectionSignals = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryParameters {
    return {
      timeZone: isSet(object.timeZone) ? globalThis.String(object.timeZone) : "",
      geoLocation: isSet(object.geoLocation) ? LatLng.fromJSON(object.geoLocation) : undefined,
      sessionEntityTypes: globalThis.Array.isArray(object?.sessionEntityTypes)
        ? object.sessionEntityTypes.map((e: any) => SessionEntityType.fromJSON(e))
        : [],
      payload: isObject(object.payload) ? object.payload : undefined,
      parameters: isObject(object.parameters) ? object.parameters : undefined,
      currentPage: isSet(object.currentPage) ? globalThis.String(object.currentPage) : "",
      disableWebhook: isSet(object.disableWebhook) ? globalThis.Boolean(object.disableWebhook) : false,
      analyzeQueryTextSentiment: isSet(object.analyzeQueryTextSentiment)
        ? globalThis.Boolean(object.analyzeQueryTextSentiment)
        : false,
      webhookHeaders: isObject(object.webhookHeaders)
        ? Object.entries(object.webhookHeaders).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      flowVersions: globalThis.Array.isArray(object?.flowVersions)
        ? object.flowVersions.map((e: any) => globalThis.String(e))
        : [],
      channel: isSet(object.channel) ? globalThis.String(object.channel) : "",
      sessionTtl: isSet(object.sessionTtl) ? Duration.fromJSON(object.sessionTtl) : undefined,
      endUserMetadata: isObject(object.endUserMetadata) ? object.endUserMetadata : undefined,
      searchConfig: isSet(object.searchConfig) ? SearchConfig.fromJSON(object.searchConfig) : undefined,
      populateDataStoreConnectionSignals: isSet(object.populateDataStoreConnectionSignals)
        ? globalThis.Boolean(object.populateDataStoreConnectionSignals)
        : false,
    };
  },

  toJSON(message: QueryParameters): unknown {
    const obj: any = {};
    if (message.timeZone !== "") {
      obj.timeZone = message.timeZone;
    }
    if (message.geoLocation !== undefined) {
      obj.geoLocation = LatLng.toJSON(message.geoLocation);
    }
    if (message.sessionEntityTypes?.length) {
      obj.sessionEntityTypes = message.sessionEntityTypes.map((e) => SessionEntityType.toJSON(e));
    }
    if (message.payload !== undefined) {
      obj.payload = message.payload;
    }
    if (message.parameters !== undefined) {
      obj.parameters = message.parameters;
    }
    if (message.currentPage !== "") {
      obj.currentPage = message.currentPage;
    }
    if (message.disableWebhook !== false) {
      obj.disableWebhook = message.disableWebhook;
    }
    if (message.analyzeQueryTextSentiment !== false) {
      obj.analyzeQueryTextSentiment = message.analyzeQueryTextSentiment;
    }
    if (message.webhookHeaders) {
      const entries = Object.entries(message.webhookHeaders);
      if (entries.length > 0) {
        obj.webhookHeaders = {};
        entries.forEach(([k, v]) => {
          obj.webhookHeaders[k] = v;
        });
      }
    }
    if (message.flowVersions?.length) {
      obj.flowVersions = message.flowVersions;
    }
    if (message.channel !== "") {
      obj.channel = message.channel;
    }
    if (message.sessionTtl !== undefined) {
      obj.sessionTtl = Duration.toJSON(message.sessionTtl);
    }
    if (message.endUserMetadata !== undefined) {
      obj.endUserMetadata = message.endUserMetadata;
    }
    if (message.searchConfig !== undefined) {
      obj.searchConfig = SearchConfig.toJSON(message.searchConfig);
    }
    if (message.populateDataStoreConnectionSignals !== false) {
      obj.populateDataStoreConnectionSignals = message.populateDataStoreConnectionSignals;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryParameters>): QueryParameters {
    return QueryParameters.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryParameters>): QueryParameters {
    const message = createBaseQueryParameters();
    message.timeZone = object.timeZone ?? "";
    message.geoLocation = (object.geoLocation !== undefined && object.geoLocation !== null)
      ? LatLng.fromPartial(object.geoLocation)
      : undefined;
    message.sessionEntityTypes = object.sessionEntityTypes?.map((e) => SessionEntityType.fromPartial(e)) || [];
    message.payload = object.payload ?? undefined;
    message.parameters = object.parameters ?? undefined;
    message.currentPage = object.currentPage ?? "";
    message.disableWebhook = object.disableWebhook ?? false;
    message.analyzeQueryTextSentiment = object.analyzeQueryTextSentiment ?? false;
    message.webhookHeaders = Object.entries(object.webhookHeaders ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.flowVersions = object.flowVersions?.map((e) => e) || [];
    message.channel = object.channel ?? "";
    message.sessionTtl = (object.sessionTtl !== undefined && object.sessionTtl !== null)
      ? Duration.fromPartial(object.sessionTtl)
      : undefined;
    message.endUserMetadata = object.endUserMetadata ?? undefined;
    message.searchConfig = (object.searchConfig !== undefined && object.searchConfig !== null)
      ? SearchConfig.fromPartial(object.searchConfig)
      : undefined;
    message.populateDataStoreConnectionSignals = object.populateDataStoreConnectionSignals ?? false;
    return message;
  },
};

function createBaseQueryParameters_WebhookHeadersEntry(): QueryParameters_WebhookHeadersEntry {
  return { key: "", value: "" };
}

export const QueryParameters_WebhookHeadersEntry: MessageFns<QueryParameters_WebhookHeadersEntry> = {
  encode(message: QueryParameters_WebhookHeadersEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryParameters_WebhookHeadersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryParameters_WebhookHeadersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryParameters_WebhookHeadersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: QueryParameters_WebhookHeadersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryParameters_WebhookHeadersEntry>): QueryParameters_WebhookHeadersEntry {
    return QueryParameters_WebhookHeadersEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryParameters_WebhookHeadersEntry>): QueryParameters_WebhookHeadersEntry {
    const message = createBaseQueryParameters_WebhookHeadersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSearchConfig(): SearchConfig {
  return { boostSpecs: [], filterSpecs: [] };
}

export const SearchConfig: MessageFns<SearchConfig> = {
  encode(message: SearchConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.boostSpecs) {
      BoostSpecs.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.filterSpecs) {
      FilterSpecs.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.boostSpecs.push(BoostSpecs.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filterSpecs.push(FilterSpecs.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchConfig {
    return {
      boostSpecs: globalThis.Array.isArray(object?.boostSpecs)
        ? object.boostSpecs.map((e: any) => BoostSpecs.fromJSON(e))
        : [],
      filterSpecs: globalThis.Array.isArray(object?.filterSpecs)
        ? object.filterSpecs.map((e: any) => FilterSpecs.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SearchConfig): unknown {
    const obj: any = {};
    if (message.boostSpecs?.length) {
      obj.boostSpecs = message.boostSpecs.map((e) => BoostSpecs.toJSON(e));
    }
    if (message.filterSpecs?.length) {
      obj.filterSpecs = message.filterSpecs.map((e) => FilterSpecs.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SearchConfig>): SearchConfig {
    return SearchConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchConfig>): SearchConfig {
    const message = createBaseSearchConfig();
    message.boostSpecs = object.boostSpecs?.map((e) => BoostSpecs.fromPartial(e)) || [];
    message.filterSpecs = object.filterSpecs?.map((e) => FilterSpecs.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBoostSpec(): BoostSpec {
  return { conditionBoostSpecs: [] };
}

export const BoostSpec: MessageFns<BoostSpec> = {
  encode(message: BoostSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.conditionBoostSpecs) {
      BoostSpec_ConditionBoostSpec.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoostSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoostSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conditionBoostSpecs.push(BoostSpec_ConditionBoostSpec.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoostSpec {
    return {
      conditionBoostSpecs: globalThis.Array.isArray(object?.conditionBoostSpecs)
        ? object.conditionBoostSpecs.map((e: any) => BoostSpec_ConditionBoostSpec.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BoostSpec): unknown {
    const obj: any = {};
    if (message.conditionBoostSpecs?.length) {
      obj.conditionBoostSpecs = message.conditionBoostSpecs.map((e) => BoostSpec_ConditionBoostSpec.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BoostSpec>): BoostSpec {
    return BoostSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BoostSpec>): BoostSpec {
    const message = createBaseBoostSpec();
    message.conditionBoostSpecs = object.conditionBoostSpecs?.map((e) => BoostSpec_ConditionBoostSpec.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseBoostSpec_ConditionBoostSpec(): BoostSpec_ConditionBoostSpec {
  return { condition: "", boost: 0 };
}

export const BoostSpec_ConditionBoostSpec: MessageFns<BoostSpec_ConditionBoostSpec> = {
  encode(message: BoostSpec_ConditionBoostSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.condition !== "") {
      writer.uint32(10).string(message.condition);
    }
    if (message.boost !== 0) {
      writer.uint32(21).float(message.boost);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoostSpec_ConditionBoostSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoostSpec_ConditionBoostSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.condition = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.boost = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoostSpec_ConditionBoostSpec {
    return {
      condition: isSet(object.condition) ? globalThis.String(object.condition) : "",
      boost: isSet(object.boost) ? globalThis.Number(object.boost) : 0,
    };
  },

  toJSON(message: BoostSpec_ConditionBoostSpec): unknown {
    const obj: any = {};
    if (message.condition !== "") {
      obj.condition = message.condition;
    }
    if (message.boost !== 0) {
      obj.boost = message.boost;
    }
    return obj;
  },

  create(base?: DeepPartial<BoostSpec_ConditionBoostSpec>): BoostSpec_ConditionBoostSpec {
    return BoostSpec_ConditionBoostSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BoostSpec_ConditionBoostSpec>): BoostSpec_ConditionBoostSpec {
    const message = createBaseBoostSpec_ConditionBoostSpec();
    message.condition = object.condition ?? "";
    message.boost = object.boost ?? 0;
    return message;
  },
};

function createBaseBoostSpecs(): BoostSpecs {
  return { dataStores: [], spec: [] };
}

export const BoostSpecs: MessageFns<BoostSpecs> = {
  encode(message: BoostSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dataStores) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.spec) {
      BoostSpec.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoostSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoostSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataStores.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.spec.push(BoostSpec.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoostSpecs {
    return {
      dataStores: globalThis.Array.isArray(object?.dataStores)
        ? object.dataStores.map((e: any) => globalThis.String(e))
        : [],
      spec: globalThis.Array.isArray(object?.spec) ? object.spec.map((e: any) => BoostSpec.fromJSON(e)) : [],
    };
  },

  toJSON(message: BoostSpecs): unknown {
    const obj: any = {};
    if (message.dataStores?.length) {
      obj.dataStores = message.dataStores;
    }
    if (message.spec?.length) {
      obj.spec = message.spec.map((e) => BoostSpec.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BoostSpecs>): BoostSpecs {
    return BoostSpecs.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BoostSpecs>): BoostSpecs {
    const message = createBaseBoostSpecs();
    message.dataStores = object.dataStores?.map((e) => e) || [];
    message.spec = object.spec?.map((e) => BoostSpec.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFilterSpecs(): FilterSpecs {
  return { dataStores: [], filter: "" };
}

export const FilterSpecs: MessageFns<FilterSpecs> = {
  encode(message: FilterSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dataStores) {
      writer.uint32(10).string(v!);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FilterSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFilterSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataStores.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FilterSpecs {
    return {
      dataStores: globalThis.Array.isArray(object?.dataStores)
        ? object.dataStores.map((e: any) => globalThis.String(e))
        : [],
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: FilterSpecs): unknown {
    const obj: any = {};
    if (message.dataStores?.length) {
      obj.dataStores = message.dataStores;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<FilterSpecs>): FilterSpecs {
    return FilterSpecs.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FilterSpecs>): FilterSpecs {
    const message = createBaseFilterSpecs();
    message.dataStores = object.dataStores?.map((e) => e) || [];
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseQueryInput(): QueryInput {
  return { text: undefined, intent: undefined, audio: undefined, event: undefined, dtmf: undefined, languageCode: "" };
}

export const QueryInput: MessageFns<QueryInput> = {
  encode(message: QueryInput, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      TextInput.encode(message.text, writer.uint32(18).fork()).join();
    }
    if (message.intent !== undefined) {
      IntentInput.encode(message.intent, writer.uint32(26).fork()).join();
    }
    if (message.audio !== undefined) {
      AudioInput.encode(message.audio, writer.uint32(42).fork()).join();
    }
    if (message.event !== undefined) {
      EventInput.encode(message.event, writer.uint32(50).fork()).join();
    }
    if (message.dtmf !== undefined) {
      DtmfInput.encode(message.dtmf, writer.uint32(58).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(34).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryInput {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryInput();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.text = TextInput.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.intent = IntentInput.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.audio = AudioInput.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.event = EventInput.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.dtmf = DtmfInput.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryInput {
    return {
      text: isSet(object.text) ? TextInput.fromJSON(object.text) : undefined,
      intent: isSet(object.intent) ? IntentInput.fromJSON(object.intent) : undefined,
      audio: isSet(object.audio) ? AudioInput.fromJSON(object.audio) : undefined,
      event: isSet(object.event) ? EventInput.fromJSON(object.event) : undefined,
      dtmf: isSet(object.dtmf) ? DtmfInput.fromJSON(object.dtmf) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: QueryInput): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = TextInput.toJSON(message.text);
    }
    if (message.intent !== undefined) {
      obj.intent = IntentInput.toJSON(message.intent);
    }
    if (message.audio !== undefined) {
      obj.audio = AudioInput.toJSON(message.audio);
    }
    if (message.event !== undefined) {
      obj.event = EventInput.toJSON(message.event);
    }
    if (message.dtmf !== undefined) {
      obj.dtmf = DtmfInput.toJSON(message.dtmf);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryInput>): QueryInput {
    return QueryInput.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryInput>): QueryInput {
    const message = createBaseQueryInput();
    message.text = (object.text !== undefined && object.text !== null) ? TextInput.fromPartial(object.text) : undefined;
    message.intent = (object.intent !== undefined && object.intent !== null)
      ? IntentInput.fromPartial(object.intent)
      : undefined;
    message.audio = (object.audio !== undefined && object.audio !== null)
      ? AudioInput.fromPartial(object.audio)
      : undefined;
    message.event = (object.event !== undefined && object.event !== null)
      ? EventInput.fromPartial(object.event)
      : undefined;
    message.dtmf = (object.dtmf !== undefined && object.dtmf !== null) ? DtmfInput.fromPartial(object.dtmf) : undefined;
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseQueryResult(): QueryResult {
  return {
    text: undefined,
    triggerIntent: undefined,
    transcript: undefined,
    triggerEvent: undefined,
    dtmf: undefined,
    languageCode: "",
    parameters: undefined,
    responseMessages: [],
    webhookIds: [],
    webhookDisplayNames: [],
    webhookLatencies: [],
    webhookTags: [],
    webhookStatuses: [],
    webhookPayloads: [],
    currentPage: undefined,
    currentFlow: undefined,
    intent: undefined,
    intentDetectionConfidence: 0,
    match: undefined,
    diagnosticInfo: undefined,
    sentimentAnalysisResult: undefined,
    advancedSettings: undefined,
    allowAnswerFeedback: false,
    dataStoreConnectionSignals: undefined,
  };
}

export const QueryResult: MessageFns<QueryResult> = {
  encode(message: QueryResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      writer.uint32(10).string(message.text);
    }
    if (message.triggerIntent !== undefined) {
      writer.uint32(90).string(message.triggerIntent);
    }
    if (message.transcript !== undefined) {
      writer.uint32(98).string(message.transcript);
    }
    if (message.triggerEvent !== undefined) {
      writer.uint32(114).string(message.triggerEvent);
    }
    if (message.dtmf !== undefined) {
      DtmfInput.encode(message.dtmf, writer.uint32(186).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(18).string(message.languageCode);
    }
    if (message.parameters !== undefined) {
      Struct.encode(Struct.wrap(message.parameters), writer.uint32(26).fork()).join();
    }
    for (const v of message.responseMessages) {
      ResponseMessage.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.webhookIds) {
      writer.uint32(202).string(v!);
    }
    for (const v of message.webhookDisplayNames) {
      writer.uint32(210).string(v!);
    }
    for (const v of message.webhookLatencies) {
      Duration.encode(v!, writer.uint32(218).fork()).join();
    }
    for (const v of message.webhookTags) {
      writer.uint32(234).string(v!);
    }
    for (const v of message.webhookStatuses) {
      Status.encode(v!, writer.uint32(106).fork()).join();
    }
    for (const v of message.webhookPayloads) {
      Struct.encode(Struct.wrap(v!), writer.uint32(50).fork()).join();
    }
    if (message.currentPage !== undefined) {
      Page.encode(message.currentPage, writer.uint32(58).fork()).join();
    }
    if (message.currentFlow !== undefined) {
      Flow.encode(message.currentFlow, writer.uint32(250).fork()).join();
    }
    if (message.intent !== undefined) {
      Intent.encode(message.intent, writer.uint32(66).fork()).join();
    }
    if (message.intentDetectionConfidence !== 0) {
      writer.uint32(77).float(message.intentDetectionConfidence);
    }
    if (message.match !== undefined) {
      Match.encode(message.match, writer.uint32(122).fork()).join();
    }
    if (message.diagnosticInfo !== undefined) {
      Struct.encode(Struct.wrap(message.diagnosticInfo), writer.uint32(82).fork()).join();
    }
    if (message.sentimentAnalysisResult !== undefined) {
      SentimentAnalysisResult.encode(message.sentimentAnalysisResult, writer.uint32(138).fork()).join();
    }
    if (message.advancedSettings !== undefined) {
      AdvancedSettings.encode(message.advancedSettings, writer.uint32(170).fork()).join();
    }
    if (message.allowAnswerFeedback !== false) {
      writer.uint32(256).bool(message.allowAnswerFeedback);
    }
    if (message.dataStoreConnectionSignals !== undefined) {
      DataStoreConnectionSignals.encode(message.dataStoreConnectionSignals, writer.uint32(282).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.triggerIntent = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.transcript = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.triggerEvent = reader.string();
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.dtmf = DtmfInput.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.parameters = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.responseMessages.push(ResponseMessage.decode(reader, reader.uint32()));
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.webhookIds.push(reader.string());
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.webhookDisplayNames.push(reader.string());
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.webhookLatencies.push(Duration.decode(reader, reader.uint32()));
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.webhookTags.push(reader.string());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.webhookStatuses.push(Status.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.webhookPayloads.push(Struct.unwrap(Struct.decode(reader, reader.uint32())));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.currentPage = Page.decode(reader, reader.uint32());
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.currentFlow = Flow.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.intent = Intent.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 77) {
            break;
          }

          message.intentDetectionConfidence = reader.float();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.match = Match.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.diagnosticInfo = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.sentimentAnalysisResult = SentimentAnalysisResult.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.advancedSettings = AdvancedSettings.decode(reader, reader.uint32());
          continue;
        case 32:
          if (tag !== 256) {
            break;
          }

          message.allowAnswerFeedback = reader.bool();
          continue;
        case 35:
          if (tag !== 282) {
            break;
          }

          message.dataStoreConnectionSignals = DataStoreConnectionSignals.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryResult {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : undefined,
      triggerIntent: isSet(object.triggerIntent) ? globalThis.String(object.triggerIntent) : undefined,
      transcript: isSet(object.transcript) ? globalThis.String(object.transcript) : undefined,
      triggerEvent: isSet(object.triggerEvent) ? globalThis.String(object.triggerEvent) : undefined,
      dtmf: isSet(object.dtmf) ? DtmfInput.fromJSON(object.dtmf) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      parameters: isObject(object.parameters) ? object.parameters : undefined,
      responseMessages: globalThis.Array.isArray(object?.responseMessages)
        ? object.responseMessages.map((e: any) => ResponseMessage.fromJSON(e))
        : [],
      webhookIds: globalThis.Array.isArray(object?.webhookIds)
        ? object.webhookIds.map((e: any) => globalThis.String(e))
        : [],
      webhookDisplayNames: globalThis.Array.isArray(object?.webhookDisplayNames)
        ? object.webhookDisplayNames.map((e: any) => globalThis.String(e))
        : [],
      webhookLatencies: globalThis.Array.isArray(object?.webhookLatencies)
        ? object.webhookLatencies.map((e: any) => Duration.fromJSON(e))
        : [],
      webhookTags: globalThis.Array.isArray(object?.webhookTags)
        ? object.webhookTags.map((e: any) => globalThis.String(e))
        : [],
      webhookStatuses: globalThis.Array.isArray(object?.webhookStatuses)
        ? object.webhookStatuses.map((e: any) => Status.fromJSON(e))
        : [],
      webhookPayloads: globalThis.Array.isArray(object?.webhookPayloads) ? [...object.webhookPayloads] : [],
      currentPage: isSet(object.currentPage) ? Page.fromJSON(object.currentPage) : undefined,
      currentFlow: isSet(object.currentFlow) ? Flow.fromJSON(object.currentFlow) : undefined,
      intent: isSet(object.intent) ? Intent.fromJSON(object.intent) : undefined,
      intentDetectionConfidence: isSet(object.intentDetectionConfidence)
        ? globalThis.Number(object.intentDetectionConfidence)
        : 0,
      match: isSet(object.match) ? Match.fromJSON(object.match) : undefined,
      diagnosticInfo: isObject(object.diagnosticInfo) ? object.diagnosticInfo : undefined,
      sentimentAnalysisResult: isSet(object.sentimentAnalysisResult)
        ? SentimentAnalysisResult.fromJSON(object.sentimentAnalysisResult)
        : undefined,
      advancedSettings: isSet(object.advancedSettings) ? AdvancedSettings.fromJSON(object.advancedSettings) : undefined,
      allowAnswerFeedback: isSet(object.allowAnswerFeedback) ? globalThis.Boolean(object.allowAnswerFeedback) : false,
      dataStoreConnectionSignals: isSet(object.dataStoreConnectionSignals)
        ? DataStoreConnectionSignals.fromJSON(object.dataStoreConnectionSignals)
        : undefined,
    };
  },

  toJSON(message: QueryResult): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = message.text;
    }
    if (message.triggerIntent !== undefined) {
      obj.triggerIntent = message.triggerIntent;
    }
    if (message.transcript !== undefined) {
      obj.transcript = message.transcript;
    }
    if (message.triggerEvent !== undefined) {
      obj.triggerEvent = message.triggerEvent;
    }
    if (message.dtmf !== undefined) {
      obj.dtmf = DtmfInput.toJSON(message.dtmf);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.parameters !== undefined) {
      obj.parameters = message.parameters;
    }
    if (message.responseMessages?.length) {
      obj.responseMessages = message.responseMessages.map((e) => ResponseMessage.toJSON(e));
    }
    if (message.webhookIds?.length) {
      obj.webhookIds = message.webhookIds;
    }
    if (message.webhookDisplayNames?.length) {
      obj.webhookDisplayNames = message.webhookDisplayNames;
    }
    if (message.webhookLatencies?.length) {
      obj.webhookLatencies = message.webhookLatencies.map((e) => Duration.toJSON(e));
    }
    if (message.webhookTags?.length) {
      obj.webhookTags = message.webhookTags;
    }
    if (message.webhookStatuses?.length) {
      obj.webhookStatuses = message.webhookStatuses.map((e) => Status.toJSON(e));
    }
    if (message.webhookPayloads?.length) {
      obj.webhookPayloads = message.webhookPayloads;
    }
    if (message.currentPage !== undefined) {
      obj.currentPage = Page.toJSON(message.currentPage);
    }
    if (message.currentFlow !== undefined) {
      obj.currentFlow = Flow.toJSON(message.currentFlow);
    }
    if (message.intent !== undefined) {
      obj.intent = Intent.toJSON(message.intent);
    }
    if (message.intentDetectionConfidence !== 0) {
      obj.intentDetectionConfidence = message.intentDetectionConfidence;
    }
    if (message.match !== undefined) {
      obj.match = Match.toJSON(message.match);
    }
    if (message.diagnosticInfo !== undefined) {
      obj.diagnosticInfo = message.diagnosticInfo;
    }
    if (message.sentimentAnalysisResult !== undefined) {
      obj.sentimentAnalysisResult = SentimentAnalysisResult.toJSON(message.sentimentAnalysisResult);
    }
    if (message.advancedSettings !== undefined) {
      obj.advancedSettings = AdvancedSettings.toJSON(message.advancedSettings);
    }
    if (message.allowAnswerFeedback !== false) {
      obj.allowAnswerFeedback = message.allowAnswerFeedback;
    }
    if (message.dataStoreConnectionSignals !== undefined) {
      obj.dataStoreConnectionSignals = DataStoreConnectionSignals.toJSON(message.dataStoreConnectionSignals);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryResult>): QueryResult {
    return QueryResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryResult>): QueryResult {
    const message = createBaseQueryResult();
    message.text = object.text ?? undefined;
    message.triggerIntent = object.triggerIntent ?? undefined;
    message.transcript = object.transcript ?? undefined;
    message.triggerEvent = object.triggerEvent ?? undefined;
    message.dtmf = (object.dtmf !== undefined && object.dtmf !== null) ? DtmfInput.fromPartial(object.dtmf) : undefined;
    message.languageCode = object.languageCode ?? "";
    message.parameters = object.parameters ?? undefined;
    message.responseMessages = object.responseMessages?.map((e) => ResponseMessage.fromPartial(e)) || [];
    message.webhookIds = object.webhookIds?.map((e) => e) || [];
    message.webhookDisplayNames = object.webhookDisplayNames?.map((e) => e) || [];
    message.webhookLatencies = object.webhookLatencies?.map((e) => Duration.fromPartial(e)) || [];
    message.webhookTags = object.webhookTags?.map((e) => e) || [];
    message.webhookStatuses = object.webhookStatuses?.map((e) => Status.fromPartial(e)) || [];
    message.webhookPayloads = object.webhookPayloads?.map((e) => e) || [];
    message.currentPage = (object.currentPage !== undefined && object.currentPage !== null)
      ? Page.fromPartial(object.currentPage)
      : undefined;
    message.currentFlow = (object.currentFlow !== undefined && object.currentFlow !== null)
      ? Flow.fromPartial(object.currentFlow)
      : undefined;
    message.intent = (object.intent !== undefined && object.intent !== null)
      ? Intent.fromPartial(object.intent)
      : undefined;
    message.intentDetectionConfidence = object.intentDetectionConfidence ?? 0;
    message.match = (object.match !== undefined && object.match !== null) ? Match.fromPartial(object.match) : undefined;
    message.diagnosticInfo = object.diagnosticInfo ?? undefined;
    message.sentimentAnalysisResult =
      (object.sentimentAnalysisResult !== undefined && object.sentimentAnalysisResult !== null)
        ? SentimentAnalysisResult.fromPartial(object.sentimentAnalysisResult)
        : undefined;
    message.advancedSettings = (object.advancedSettings !== undefined && object.advancedSettings !== null)
      ? AdvancedSettings.fromPartial(object.advancedSettings)
      : undefined;
    message.allowAnswerFeedback = object.allowAnswerFeedback ?? false;
    message.dataStoreConnectionSignals =
      (object.dataStoreConnectionSignals !== undefined && object.dataStoreConnectionSignals !== null)
        ? DataStoreConnectionSignals.fromPartial(object.dataStoreConnectionSignals)
        : undefined;
    return message;
  },
};

function createBaseTextInput(): TextInput {
  return { text: "" };
}

export const TextInput: MessageFns<TextInput> = {
  encode(message: TextInput, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextInput {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextInput();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextInput {
    return { text: isSet(object.text) ? globalThis.String(object.text) : "" };
  },

  toJSON(message: TextInput): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    return obj;
  },

  create(base?: DeepPartial<TextInput>): TextInput {
    return TextInput.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextInput>): TextInput {
    const message = createBaseTextInput();
    message.text = object.text ?? "";
    return message;
  },
};

function createBaseIntentInput(): IntentInput {
  return { intent: "" };
}

export const IntentInput: MessageFns<IntentInput> = {
  encode(message: IntentInput, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.intent !== "") {
      writer.uint32(10).string(message.intent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IntentInput {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIntentInput();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.intent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IntentInput {
    return { intent: isSet(object.intent) ? globalThis.String(object.intent) : "" };
  },

  toJSON(message: IntentInput): unknown {
    const obj: any = {};
    if (message.intent !== "") {
      obj.intent = message.intent;
    }
    return obj;
  },

  create(base?: DeepPartial<IntentInput>): IntentInput {
    return IntentInput.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IntentInput>): IntentInput {
    const message = createBaseIntentInput();
    message.intent = object.intent ?? "";
    return message;
  },
};

function createBaseAudioInput(): AudioInput {
  return { config: undefined, audio: Buffer.alloc(0) };
}

export const AudioInput: MessageFns<AudioInput> = {
  encode(message: AudioInput, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.config !== undefined) {
      InputAudioConfig.encode(message.config, writer.uint32(10).fork()).join();
    }
    if (message.audio.length !== 0) {
      writer.uint32(18).bytes(message.audio);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AudioInput {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioInput();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.config = InputAudioConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.audio = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioInput {
    return {
      config: isSet(object.config) ? InputAudioConfig.fromJSON(object.config) : undefined,
      audio: isSet(object.audio) ? Buffer.from(bytesFromBase64(object.audio)) : Buffer.alloc(0),
    };
  },

  toJSON(message: AudioInput): unknown {
    const obj: any = {};
    if (message.config !== undefined) {
      obj.config = InputAudioConfig.toJSON(message.config);
    }
    if (message.audio.length !== 0) {
      obj.audio = base64FromBytes(message.audio);
    }
    return obj;
  },

  create(base?: DeepPartial<AudioInput>): AudioInput {
    return AudioInput.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AudioInput>): AudioInput {
    const message = createBaseAudioInput();
    message.config = (object.config !== undefined && object.config !== null)
      ? InputAudioConfig.fromPartial(object.config)
      : undefined;
    message.audio = object.audio ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseEventInput(): EventInput {
  return { event: "" };
}

export const EventInput: MessageFns<EventInput> = {
  encode(message: EventInput, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.event !== "") {
      writer.uint32(10).string(message.event);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventInput {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventInput();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.event = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventInput {
    return { event: isSet(object.event) ? globalThis.String(object.event) : "" };
  },

  toJSON(message: EventInput): unknown {
    const obj: any = {};
    if (message.event !== "") {
      obj.event = message.event;
    }
    return obj;
  },

  create(base?: DeepPartial<EventInput>): EventInput {
    return EventInput.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EventInput>): EventInput {
    const message = createBaseEventInput();
    message.event = object.event ?? "";
    return message;
  },
};

function createBaseDtmfInput(): DtmfInput {
  return { digits: "", finishDigit: "" };
}

export const DtmfInput: MessageFns<DtmfInput> = {
  encode(message: DtmfInput, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.digits !== "") {
      writer.uint32(10).string(message.digits);
    }
    if (message.finishDigit !== "") {
      writer.uint32(18).string(message.finishDigit);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DtmfInput {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDtmfInput();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.digits = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.finishDigit = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DtmfInput {
    return {
      digits: isSet(object.digits) ? globalThis.String(object.digits) : "",
      finishDigit: isSet(object.finishDigit) ? globalThis.String(object.finishDigit) : "",
    };
  },

  toJSON(message: DtmfInput): unknown {
    const obj: any = {};
    if (message.digits !== "") {
      obj.digits = message.digits;
    }
    if (message.finishDigit !== "") {
      obj.finishDigit = message.finishDigit;
    }
    return obj;
  },

  create(base?: DeepPartial<DtmfInput>): DtmfInput {
    return DtmfInput.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DtmfInput>): DtmfInput {
    const message = createBaseDtmfInput();
    message.digits = object.digits ?? "";
    message.finishDigit = object.finishDigit ?? "";
    return message;
  },
};

function createBaseMatch(): Match {
  return { intent: undefined, event: "", parameters: undefined, resolvedInput: "", matchType: 0, confidence: 0 };
}

export const Match: MessageFns<Match> = {
  encode(message: Match, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.intent !== undefined) {
      Intent.encode(message.intent, writer.uint32(10).fork()).join();
    }
    if (message.event !== "") {
      writer.uint32(50).string(message.event);
    }
    if (message.parameters !== undefined) {
      Struct.encode(Struct.wrap(message.parameters), writer.uint32(18).fork()).join();
    }
    if (message.resolvedInput !== "") {
      writer.uint32(26).string(message.resolvedInput);
    }
    if (message.matchType !== 0) {
      writer.uint32(32).int32(message.matchType);
    }
    if (message.confidence !== 0) {
      writer.uint32(45).float(message.confidence);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Match {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMatch();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.intent = Intent.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.event = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.parameters = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.resolvedInput = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.matchType = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 45) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Match {
    return {
      intent: isSet(object.intent) ? Intent.fromJSON(object.intent) : undefined,
      event: isSet(object.event) ? globalThis.String(object.event) : "",
      parameters: isObject(object.parameters) ? object.parameters : undefined,
      resolvedInput: isSet(object.resolvedInput) ? globalThis.String(object.resolvedInput) : "",
      matchType: isSet(object.matchType) ? match_MatchTypeFromJSON(object.matchType) : 0,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: Match): unknown {
    const obj: any = {};
    if (message.intent !== undefined) {
      obj.intent = Intent.toJSON(message.intent);
    }
    if (message.event !== "") {
      obj.event = message.event;
    }
    if (message.parameters !== undefined) {
      obj.parameters = message.parameters;
    }
    if (message.resolvedInput !== "") {
      obj.resolvedInput = message.resolvedInput;
    }
    if (message.matchType !== 0) {
      obj.matchType = match_MatchTypeToJSON(message.matchType);
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create(base?: DeepPartial<Match>): Match {
    return Match.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Match>): Match {
    const message = createBaseMatch();
    message.intent = (object.intent !== undefined && object.intent !== null)
      ? Intent.fromPartial(object.intent)
      : undefined;
    message.event = object.event ?? "";
    message.parameters = object.parameters ?? undefined;
    message.resolvedInput = object.resolvedInput ?? "";
    message.matchType = object.matchType ?? 0;
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseMatchIntentRequest(): MatchIntentRequest {
  return { session: "", queryParams: undefined, queryInput: undefined, persistParameterChanges: false };
}

export const MatchIntentRequest: MessageFns<MatchIntentRequest> = {
  encode(message: MatchIntentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.session !== "") {
      writer.uint32(10).string(message.session);
    }
    if (message.queryParams !== undefined) {
      QueryParameters.encode(message.queryParams, writer.uint32(18).fork()).join();
    }
    if (message.queryInput !== undefined) {
      QueryInput.encode(message.queryInput, writer.uint32(26).fork()).join();
    }
    if (message.persistParameterChanges !== false) {
      writer.uint32(40).bool(message.persistParameterChanges);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MatchIntentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMatchIntentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.session = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryParams = QueryParameters.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.queryInput = QueryInput.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.persistParameterChanges = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MatchIntentRequest {
    return {
      session: isSet(object.session) ? globalThis.String(object.session) : "",
      queryParams: isSet(object.queryParams) ? QueryParameters.fromJSON(object.queryParams) : undefined,
      queryInput: isSet(object.queryInput) ? QueryInput.fromJSON(object.queryInput) : undefined,
      persistParameterChanges: isSet(object.persistParameterChanges)
        ? globalThis.Boolean(object.persistParameterChanges)
        : false,
    };
  },

  toJSON(message: MatchIntentRequest): unknown {
    const obj: any = {};
    if (message.session !== "") {
      obj.session = message.session;
    }
    if (message.queryParams !== undefined) {
      obj.queryParams = QueryParameters.toJSON(message.queryParams);
    }
    if (message.queryInput !== undefined) {
      obj.queryInput = QueryInput.toJSON(message.queryInput);
    }
    if (message.persistParameterChanges !== false) {
      obj.persistParameterChanges = message.persistParameterChanges;
    }
    return obj;
  },

  create(base?: DeepPartial<MatchIntentRequest>): MatchIntentRequest {
    return MatchIntentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MatchIntentRequest>): MatchIntentRequest {
    const message = createBaseMatchIntentRequest();
    message.session = object.session ?? "";
    message.queryParams = (object.queryParams !== undefined && object.queryParams !== null)
      ? QueryParameters.fromPartial(object.queryParams)
      : undefined;
    message.queryInput = (object.queryInput !== undefined && object.queryInput !== null)
      ? QueryInput.fromPartial(object.queryInput)
      : undefined;
    message.persistParameterChanges = object.persistParameterChanges ?? false;
    return message;
  },
};

function createBaseMatchIntentResponse(): MatchIntentResponse {
  return {
    text: undefined,
    triggerIntent: undefined,
    transcript: undefined,
    triggerEvent: undefined,
    matches: [],
    currentPage: undefined,
  };
}

export const MatchIntentResponse: MessageFns<MatchIntentResponse> = {
  encode(message: MatchIntentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      writer.uint32(10).string(message.text);
    }
    if (message.triggerIntent !== undefined) {
      writer.uint32(18).string(message.triggerIntent);
    }
    if (message.transcript !== undefined) {
      writer.uint32(26).string(message.transcript);
    }
    if (message.triggerEvent !== undefined) {
      writer.uint32(50).string(message.triggerEvent);
    }
    for (const v of message.matches) {
      Match.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.currentPage !== undefined) {
      Page.encode(message.currentPage, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MatchIntentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMatchIntentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.triggerIntent = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.transcript = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.triggerEvent = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.matches.push(Match.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.currentPage = Page.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MatchIntentResponse {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : undefined,
      triggerIntent: isSet(object.triggerIntent) ? globalThis.String(object.triggerIntent) : undefined,
      transcript: isSet(object.transcript) ? globalThis.String(object.transcript) : undefined,
      triggerEvent: isSet(object.triggerEvent) ? globalThis.String(object.triggerEvent) : undefined,
      matches: globalThis.Array.isArray(object?.matches) ? object.matches.map((e: any) => Match.fromJSON(e)) : [],
      currentPage: isSet(object.currentPage) ? Page.fromJSON(object.currentPage) : undefined,
    };
  },

  toJSON(message: MatchIntentResponse): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = message.text;
    }
    if (message.triggerIntent !== undefined) {
      obj.triggerIntent = message.triggerIntent;
    }
    if (message.transcript !== undefined) {
      obj.transcript = message.transcript;
    }
    if (message.triggerEvent !== undefined) {
      obj.triggerEvent = message.triggerEvent;
    }
    if (message.matches?.length) {
      obj.matches = message.matches.map((e) => Match.toJSON(e));
    }
    if (message.currentPage !== undefined) {
      obj.currentPage = Page.toJSON(message.currentPage);
    }
    return obj;
  },

  create(base?: DeepPartial<MatchIntentResponse>): MatchIntentResponse {
    return MatchIntentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MatchIntentResponse>): MatchIntentResponse {
    const message = createBaseMatchIntentResponse();
    message.text = object.text ?? undefined;
    message.triggerIntent = object.triggerIntent ?? undefined;
    message.transcript = object.transcript ?? undefined;
    message.triggerEvent = object.triggerEvent ?? undefined;
    message.matches = object.matches?.map((e) => Match.fromPartial(e)) || [];
    message.currentPage = (object.currentPage !== undefined && object.currentPage !== null)
      ? Page.fromPartial(object.currentPage)
      : undefined;
    return message;
  },
};

function createBaseFulfillIntentRequest(): FulfillIntentRequest {
  return { matchIntentRequest: undefined, match: undefined, outputAudioConfig: undefined };
}

export const FulfillIntentRequest: MessageFns<FulfillIntentRequest> = {
  encode(message: FulfillIntentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.matchIntentRequest !== undefined) {
      MatchIntentRequest.encode(message.matchIntentRequest, writer.uint32(10).fork()).join();
    }
    if (message.match !== undefined) {
      Match.encode(message.match, writer.uint32(18).fork()).join();
    }
    if (message.outputAudioConfig !== undefined) {
      OutputAudioConfig.encode(message.outputAudioConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FulfillIntentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFulfillIntentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.matchIntentRequest = MatchIntentRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.match = Match.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.outputAudioConfig = OutputAudioConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FulfillIntentRequest {
    return {
      matchIntentRequest: isSet(object.matchIntentRequest)
        ? MatchIntentRequest.fromJSON(object.matchIntentRequest)
        : undefined,
      match: isSet(object.match) ? Match.fromJSON(object.match) : undefined,
      outputAudioConfig: isSet(object.outputAudioConfig)
        ? OutputAudioConfig.fromJSON(object.outputAudioConfig)
        : undefined,
    };
  },

  toJSON(message: FulfillIntentRequest): unknown {
    const obj: any = {};
    if (message.matchIntentRequest !== undefined) {
      obj.matchIntentRequest = MatchIntentRequest.toJSON(message.matchIntentRequest);
    }
    if (message.match !== undefined) {
      obj.match = Match.toJSON(message.match);
    }
    if (message.outputAudioConfig !== undefined) {
      obj.outputAudioConfig = OutputAudioConfig.toJSON(message.outputAudioConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<FulfillIntentRequest>): FulfillIntentRequest {
    return FulfillIntentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FulfillIntentRequest>): FulfillIntentRequest {
    const message = createBaseFulfillIntentRequest();
    message.matchIntentRequest = (object.matchIntentRequest !== undefined && object.matchIntentRequest !== null)
      ? MatchIntentRequest.fromPartial(object.matchIntentRequest)
      : undefined;
    message.match = (object.match !== undefined && object.match !== null) ? Match.fromPartial(object.match) : undefined;
    message.outputAudioConfig = (object.outputAudioConfig !== undefined && object.outputAudioConfig !== null)
      ? OutputAudioConfig.fromPartial(object.outputAudioConfig)
      : undefined;
    return message;
  },
};

function createBaseFulfillIntentResponse(): FulfillIntentResponse {
  return { responseId: "", queryResult: undefined, outputAudio: Buffer.alloc(0), outputAudioConfig: undefined };
}

export const FulfillIntentResponse: MessageFns<FulfillIntentResponse> = {
  encode(message: FulfillIntentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.responseId !== "") {
      writer.uint32(10).string(message.responseId);
    }
    if (message.queryResult !== undefined) {
      QueryResult.encode(message.queryResult, writer.uint32(18).fork()).join();
    }
    if (message.outputAudio.length !== 0) {
      writer.uint32(26).bytes(message.outputAudio);
    }
    if (message.outputAudioConfig !== undefined) {
      OutputAudioConfig.encode(message.outputAudioConfig, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FulfillIntentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFulfillIntentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.responseId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.queryResult = QueryResult.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.outputAudio = Buffer.from(reader.bytes());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputAudioConfig = OutputAudioConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FulfillIntentResponse {
    return {
      responseId: isSet(object.responseId) ? globalThis.String(object.responseId) : "",
      queryResult: isSet(object.queryResult) ? QueryResult.fromJSON(object.queryResult) : undefined,
      outputAudio: isSet(object.outputAudio) ? Buffer.from(bytesFromBase64(object.outputAudio)) : Buffer.alloc(0),
      outputAudioConfig: isSet(object.outputAudioConfig)
        ? OutputAudioConfig.fromJSON(object.outputAudioConfig)
        : undefined,
    };
  },

  toJSON(message: FulfillIntentResponse): unknown {
    const obj: any = {};
    if (message.responseId !== "") {
      obj.responseId = message.responseId;
    }
    if (message.queryResult !== undefined) {
      obj.queryResult = QueryResult.toJSON(message.queryResult);
    }
    if (message.outputAudio.length !== 0) {
      obj.outputAudio = base64FromBytes(message.outputAudio);
    }
    if (message.outputAudioConfig !== undefined) {
      obj.outputAudioConfig = OutputAudioConfig.toJSON(message.outputAudioConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<FulfillIntentResponse>): FulfillIntentResponse {
    return FulfillIntentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FulfillIntentResponse>): FulfillIntentResponse {
    const message = createBaseFulfillIntentResponse();
    message.responseId = object.responseId ?? "";
    message.queryResult = (object.queryResult !== undefined && object.queryResult !== null)
      ? QueryResult.fromPartial(object.queryResult)
      : undefined;
    message.outputAudio = object.outputAudio ?? Buffer.alloc(0);
    message.outputAudioConfig = (object.outputAudioConfig !== undefined && object.outputAudioConfig !== null)
      ? OutputAudioConfig.fromPartial(object.outputAudioConfig)
      : undefined;
    return message;
  },
};

function createBaseSentimentAnalysisResult(): SentimentAnalysisResult {
  return { score: 0, magnitude: 0 };
}

export const SentimentAnalysisResult: MessageFns<SentimentAnalysisResult> = {
  encode(message: SentimentAnalysisResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.score !== 0) {
      writer.uint32(13).float(message.score);
    }
    if (message.magnitude !== 0) {
      writer.uint32(21).float(message.magnitude);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SentimentAnalysisResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSentimentAnalysisResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.score = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.magnitude = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SentimentAnalysisResult {
    return {
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
      magnitude: isSet(object.magnitude) ? globalThis.Number(object.magnitude) : 0,
    };
  },

  toJSON(message: SentimentAnalysisResult): unknown {
    const obj: any = {};
    if (message.score !== 0) {
      obj.score = message.score;
    }
    if (message.magnitude !== 0) {
      obj.magnitude = message.magnitude;
    }
    return obj;
  },

  create(base?: DeepPartial<SentimentAnalysisResult>): SentimentAnalysisResult {
    return SentimentAnalysisResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SentimentAnalysisResult>): SentimentAnalysisResult {
    const message = createBaseSentimentAnalysisResult();
    message.score = object.score ?? 0;
    message.magnitude = object.magnitude ?? 0;
    return message;
  },
};

/**
 * A session represents an interaction with a user. You retrieve user input
 * and pass it to the
 * [DetectIntent][google.cloud.dialogflow.cx.v3.Sessions.DetectIntent] method to
 * determine user intent and respond.
 */
export type SessionsDefinition = typeof SessionsDefinition;
export const SessionsDefinition = {
  name: "Sessions",
  fullName: "google.cloud.dialogflow.cx.v3.Sessions",
  methods: {
    /**
     * Processes a natural language query and returns structured, actionable data
     * as a result. This method is not idempotent, because it may cause session
     * entity types to be updated, which in turn might affect results of future
     * queries.
     *
     * Note: Always use agent versions for production traffic.
     * See [Versions and
     * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
     */
    detectIntent: {
      name: "DetectIntent",
      requestType: DetectIntentRequest,
      requestStream: false,
      responseType: DetectIntentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              165,
              1,
              58,
              1,
              42,
              90,
              89,
              58,
              1,
              42,
              34,
              84,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              101,
              110,
              118,
              105,
              114,
              111,
              110,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              116,
              101,
              99,
              116,
              73,
              110,
              116,
              101,
              110,
              116,
              34,
              69,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              116,
              101,
              99,
              116,
              73,
              110,
              116,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Processes a natural language query and returns structured, actionable data
     * as a result through server-side streaming. Server-side streaming allows
     * Dialogflow to send [partial
     * responses](https://cloud.google.com/dialogflow/cx/docs/concept/fulfillment#partial-response)
     * earlier in a single request.
     */
    serverStreamingDetectIntent: {
      name: "ServerStreamingDetectIntent",
      requestType: DetectIntentRequest,
      requestStream: false,
      responseType: DetectIntentResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              195,
              1,
              58,
              1,
              42,
              90,
              104,
              58,
              1,
              42,
              34,
              99,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              101,
              110,
              118,
              105,
              114,
              111,
              110,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              114,
              118,
              101,
              114,
              83,
              116,
              114,
              101,
              97,
              109,
              105,
              110,
              103,
              68,
              101,
              116,
              101,
              99,
              116,
              73,
              110,
              116,
              101,
              110,
              116,
              34,
              84,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              114,
              118,
              101,
              114,
              83,
              116,
              114,
              101,
              97,
              109,
              105,
              110,
              103,
              68,
              101,
              116,
              101,
              99,
              116,
              73,
              110,
              116,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Processes a natural language query in audio format in a streaming fashion
     * and returns structured, actionable data as a result. This method is only
     * available via the gRPC API (not REST).
     *
     * Note: Always use agent versions for production traffic.
     * See [Versions and
     * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
     */
    streamingDetectIntent: {
      name: "StreamingDetectIntent",
      requestType: StreamingDetectIntentRequest,
      requestStream: true,
      responseType: StreamingDetectIntentResponse,
      responseStream: true,
      options: {},
    },
    /**
     * Returns preliminary intent match results, doesn't change the session
     * status.
     */
    matchIntent: {
      name: "MatchIntent",
      requestType: MatchIntentRequest,
      requestStream: false,
      responseType: MatchIntentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              163,
              1,
              58,
              1,
              42,
              90,
              88,
              58,
              1,
              42,
              34,
              83,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              101,
              110,
              118,
              105,
              114,
              111,
              110,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              109,
              97,
              116,
              99,
              104,
              73,
              110,
              116,
              101,
              110,
              116,
              34,
              68,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              109,
              97,
              116,
              99,
              104,
              73,
              110,
              116,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Fulfills a matched intent returned by
     * [MatchIntent][google.cloud.dialogflow.cx.v3.Sessions.MatchIntent]. Must be
     * called after
     * [MatchIntent][google.cloud.dialogflow.cx.v3.Sessions.MatchIntent], with
     * input from
     * [MatchIntentResponse][google.cloud.dialogflow.cx.v3.MatchIntentResponse].
     * Otherwise, the behavior is undefined.
     */
    fulfillIntent: {
      name: "FulfillIntent",
      requestType: FulfillIntentRequest,
      requestStream: false,
      responseType: FulfillIntentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              209,
              1,
              58,
              1,
              42,
              90,
              111,
              58,
              1,
              42,
              34,
              106,
              47,
              118,
              51,
              47,
              123,
              109,
              97,
              116,
              99,
              104,
              95,
              105,
              110,
              116,
              101,
              110,
              116,
              95,
              114,
              101,
              113,
              117,
              101,
              115,
              116,
              46,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              101,
              110,
              118,
              105,
              114,
              111,
              110,
              109,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              102,
              117,
              108,
              102,
              105,
              108,
              108,
              73,
              110,
              116,
              101,
              110,
              116,
              34,
              91,
              47,
              118,
              51,
              47,
              123,
              109,
              97,
              116,
              99,
              104,
              95,
              105,
              110,
              116,
              101,
              110,
              116,
              95,
              114,
              101,
              113,
              117,
              101,
              115,
              116,
              46,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              102,
              117,
              108,
              102,
              105,
              108,
              108,
              73,
              110,
              116,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Updates the feedback received from the user for a single turn of the bot
     * response.
     */
    submitAnswerFeedback: {
      name: "SubmitAnswerFeedback",
      requestType: SubmitAnswerFeedbackRequest,
      requestStream: false,
      responseType: AnswerFeedback,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              82,
              58,
              1,
              42,
              34,
              77,
              47,
              118,
              51,
              47,
              123,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              97,
              103,
              101,
              110,
              116,
              115,
              47,
              42,
              47,
              115,
              101,
              115,
              115,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              115,
              117,
              98,
              109,
              105,
              116,
              65,
              110,
              115,
              119,
              101,
              114,
              70,
              101,
              101,
              100,
              98,
              97,
              99,
              107,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface SessionsServiceImplementation<CallContextExt = {}> {
  /**
   * Processes a natural language query and returns structured, actionable data
   * as a result. This method is not idempotent, because it may cause session
   * entity types to be updated, which in turn might affect results of future
   * queries.
   *
   * Note: Always use agent versions for production traffic.
   * See [Versions and
   * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
   */
  detectIntent(
    request: DetectIntentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<DetectIntentResponse>>;
  /**
   * Processes a natural language query and returns structured, actionable data
   * as a result through server-side streaming. Server-side streaming allows
   * Dialogflow to send [partial
   * responses](https://cloud.google.com/dialogflow/cx/docs/concept/fulfillment#partial-response)
   * earlier in a single request.
   */
  serverStreamingDetectIntent(
    request: DetectIntentRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<DetectIntentResponse>>;
  /**
   * Processes a natural language query in audio format in a streaming fashion
   * and returns structured, actionable data as a result. This method is only
   * available via the gRPC API (not REST).
   *
   * Note: Always use agent versions for production traffic.
   * See [Versions and
   * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
   */
  streamingDetectIntent(
    request: AsyncIterable<StreamingDetectIntentRequest>,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<StreamingDetectIntentResponse>>;
  /**
   * Returns preliminary intent match results, doesn't change the session
   * status.
   */
  matchIntent(
    request: MatchIntentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<MatchIntentResponse>>;
  /**
   * Fulfills a matched intent returned by
   * [MatchIntent][google.cloud.dialogflow.cx.v3.Sessions.MatchIntent]. Must be
   * called after
   * [MatchIntent][google.cloud.dialogflow.cx.v3.Sessions.MatchIntent], with
   * input from
   * [MatchIntentResponse][google.cloud.dialogflow.cx.v3.MatchIntentResponse].
   * Otherwise, the behavior is undefined.
   */
  fulfillIntent(
    request: FulfillIntentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FulfillIntentResponse>>;
  /**
   * Updates the feedback received from the user for a single turn of the bot
   * response.
   */
  submitAnswerFeedback(
    request: SubmitAnswerFeedbackRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnswerFeedback>>;
}

export interface SessionsClient<CallOptionsExt = {}> {
  /**
   * Processes a natural language query and returns structured, actionable data
   * as a result. This method is not idempotent, because it may cause session
   * entity types to be updated, which in turn might affect results of future
   * queries.
   *
   * Note: Always use agent versions for production traffic.
   * See [Versions and
   * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
   */
  detectIntent(
    request: DeepPartial<DetectIntentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<DetectIntentResponse>;
  /**
   * Processes a natural language query and returns structured, actionable data
   * as a result through server-side streaming. Server-side streaming allows
   * Dialogflow to send [partial
   * responses](https://cloud.google.com/dialogflow/cx/docs/concept/fulfillment#partial-response)
   * earlier in a single request.
   */
  serverStreamingDetectIntent(
    request: DeepPartial<DetectIntentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<DetectIntentResponse>;
  /**
   * Processes a natural language query in audio format in a streaming fashion
   * and returns structured, actionable data as a result. This method is only
   * available via the gRPC API (not REST).
   *
   * Note: Always use agent versions for production traffic.
   * See [Versions and
   * environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
   */
  streamingDetectIntent(
    request: AsyncIterable<DeepPartial<StreamingDetectIntentRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<StreamingDetectIntentResponse>;
  /**
   * Returns preliminary intent match results, doesn't change the session
   * status.
   */
  matchIntent(
    request: DeepPartial<MatchIntentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<MatchIntentResponse>;
  /**
   * Fulfills a matched intent returned by
   * [MatchIntent][google.cloud.dialogflow.cx.v3.Sessions.MatchIntent]. Must be
   * called after
   * [MatchIntent][google.cloud.dialogflow.cx.v3.Sessions.MatchIntent], with
   * input from
   * [MatchIntentResponse][google.cloud.dialogflow.cx.v3.MatchIntentResponse].
   * Otherwise, the behavior is undefined.
   */
  fulfillIntent(
    request: DeepPartial<FulfillIntentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FulfillIntentResponse>;
  /**
   * Updates the feedback received from the user for a single turn of the bot
   * response.
   */
  submitAnswerFeedback(
    request: DeepPartial<SubmitAnswerFeedbackRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnswerFeedback>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export type ServerStreamingMethodResult<Response> = { [Symbol.asyncIterator](): AsyncIterator<Response, void> };

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
