// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dialogflow/v2/conversation_dataset.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { GcsSources } from "./gcs.js";

export const protobufPackage = "google.cloud.dialogflow.v2";

/** Represents metadata of a conversation. */
export interface ConversationInfo {
  /**
   * Optional. The language code of the conversation data within this dataset.
   * See https://cloud.google.com/apis/design/standard_fields for more
   * information. Supports all UTF-8 languages.
   */
  languageCode: string;
}

/**
 * Represents the configuration of importing a set of conversation files in
 * Google Cloud Storage.
 */
export interface InputConfig {
  /**
   * The Cloud Storage URI has the form gs://<Google Cloud Storage bucket
   * name>//agent*.json. Wildcards are allowed and will be expanded into all
   * matched JSON files, which will be read as one conversation per file.
   */
  gcsSource?: GcsSources | undefined;
}

/**
 * Represents a conversation dataset that a user imports raw data into.
 * The data inside ConversationDataset can not be changed after
 * ImportConversationData finishes (and calling ImportConversationData on a
 * dataset that already has data is not allowed).
 */
export interface ConversationDataset {
  /**
   * Output only. ConversationDataset resource name. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset ID>`
   */
  name: string;
  /** Required. The display name of the dataset. Maximum of 64 bytes. */
  displayName: string;
  /** Optional. The description of the dataset. Maximum of 10000 bytes. */
  description: string;
  /** Output only. Creation time of this dataset. */
  createTime:
    | Date
    | undefined;
  /** Output only. Input configurations set during conversation data import. */
  inputConfig:
    | InputConfig
    | undefined;
  /** Output only. Metadata set during conversation data import. */
  conversationInfo:
    | ConversationInfo
    | undefined;
  /**
   * Output only. The number of conversations this conversation dataset
   * contains.
   */
  conversationCount: Long;
  /**
   * Output only. A read only boolean field reflecting Zone Isolation status of
   * the dataset.
   */
  satisfiesPzi?:
    | boolean
    | undefined;
  /**
   * Output only. A read only boolean field reflecting Zone Separation status of
   * the dataset.
   */
  satisfiesPzs?: boolean | undefined;
}

/**
 * The request message for
 * [ConversationDatasets.CreateConversationDataset][google.cloud.dialogflow.v2.ConversationDatasets.CreateConversationDataset].
 */
export interface CreateConversationDatasetRequest {
  /**
   * Required. The project to create conversation dataset for. Format:
   * `projects/<Project ID>/locations/<Location ID>`
   */
  parent: string;
  /** Required. The conversation dataset to create. */
  conversationDataset: ConversationDataset | undefined;
}

/**
 * The request message for
 * [ConversationDatasets.GetConversationDataset][google.cloud.dialogflow.v2.ConversationDatasets.GetConversationDataset].
 */
export interface GetConversationDatasetRequest {
  /**
   * Required. The conversation dataset to retrieve. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationDatasets.ListConversationDatasets][google.cloud.dialogflow.v2.ConversationDatasets.ListConversationDatasets].
 */
export interface ListConversationDatasetsRequest {
  /**
   * Required. The project and location name to list all conversation datasets
   * for. Format: `projects/<Project ID>/locations/<Location ID>`
   */
  parent: string;
  /**
   * Optional. Maximum number of conversation datasets to return in a single
   * page. By default 100 and at most 1000.
   */
  pageSize: number;
  /** Optional. The next_page_token value returned from a previous list request. */
  pageToken: string;
}

/**
 * The response message for
 * [ConversationDatasets.ListConversationDatasets][google.cloud.dialogflow.v2.ConversationDatasets.ListConversationDatasets].
 */
export interface ListConversationDatasetsResponse {
  /** The list of datasets to return. */
  conversationDatasets: ConversationDataset[];
  /**
   * The token to use to retrieve the next page of results, or empty if there
   * are no more results in the list.
   */
  nextPageToken: string;
}

/**
 * The request message for
 * [ConversationDatasets.DeleteConversationDataset][google.cloud.dialogflow.v2.ConversationDatasets.DeleteConversationDataset].
 */
export interface DeleteConversationDatasetRequest {
  /**
   * Required. The conversation dataset to delete. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset ID>`
   */
  name: string;
}

/**
 * The request message for
 * [ConversationDatasets.ImportConversationData][google.cloud.dialogflow.v2.ConversationDatasets.ImportConversationData].
 */
export interface ImportConversationDataRequest {
  /**
   * Required. Dataset resource name. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset ID>`
   */
  name: string;
  /** Required. Configuration describing where to import data from. */
  inputConfig: InputConfig | undefined;
}

/**
 * Metadata for a
 * [ConversationDatasets.ImportConversationData][google.cloud.dialogflow.v2.ConversationDatasets.ImportConversationData]
 * operation.
 */
export interface ImportConversationDataOperationMetadata {
  /**
   * The resource name of the imported conversation dataset. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset Id>`
   */
  conversationDataset: string;
  /**
   * Partial failures are failures that don't fail the whole long running
   * operation, e.g. single files that couldn't be read.
   */
  partialFailures: Status[];
  /**
   * Timestamp when import conversation data request was created. The time is
   * measured on server side.
   */
  createTime: Date | undefined;
}

/**
 * Response used for
 * [ConversationDatasets.ImportConversationData][google.cloud.dialogflow.v2.ConversationDatasets.ImportConversationData]
 * long running operation.
 */
export interface ImportConversationDataOperationResponse {
  /**
   * The resource name of the imported conversation dataset. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset Id>`
   */
  conversationDataset: string;
  /** Number of conversations imported successfully. */
  importCount: number;
}

/** Metadata for [ConversationDatasets][CreateConversationDataset]. */
export interface CreateConversationDatasetOperationMetadata {
  /**
   * The resource name of the conversation dataset that will be created. Format:
   * `projects/<Project ID>/locations/<Location
   * ID>/conversationDatasets/<Conversation Dataset Id>`
   */
  conversationDataset: string;
}

/** Metadata for [ConversationDatasets][DeleteConversationDataset]. */
export interface DeleteConversationDatasetOperationMetadata {
}

function createBaseConversationInfo(): ConversationInfo {
  return { languageCode: "" };
}

export const ConversationInfo: MessageFns<ConversationInfo> = {
  encode(message: ConversationInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.languageCode !== "") {
      writer.uint32(10).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConversationInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConversationInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConversationInfo {
    return { languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "" };
  },

  toJSON(message: ConversationInfo): unknown {
    const obj: any = {};
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<ConversationInfo>): ConversationInfo {
    return ConversationInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConversationInfo>): ConversationInfo {
    const message = createBaseConversationInfo();
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseInputConfig(): InputConfig {
  return { gcsSource: undefined };
}

export const InputConfig: MessageFns<InputConfig> = {
  encode(message: InputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsSource !== undefined) {
      GcsSources.encode(message.gcsSource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsSource = GcsSources.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InputConfig {
    return { gcsSource: isSet(object.gcsSource) ? GcsSources.fromJSON(object.gcsSource) : undefined };
  },

  toJSON(message: InputConfig): unknown {
    const obj: any = {};
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSources.toJSON(message.gcsSource);
    }
    return obj;
  },

  create(base?: DeepPartial<InputConfig>): InputConfig {
    return InputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InputConfig>): InputConfig {
    const message = createBaseInputConfig();
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSources.fromPartial(object.gcsSource)
      : undefined;
    return message;
  },
};

function createBaseConversationDataset(): ConversationDataset {
  return {
    name: "",
    displayName: "",
    description: "",
    createTime: undefined,
    inputConfig: undefined,
    conversationInfo: undefined,
    conversationCount: Long.ZERO,
    satisfiesPzi: undefined,
    satisfiesPzs: undefined,
  };
}

export const ConversationDataset: MessageFns<ConversationDataset> = {
  encode(message: ConversationDataset, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.inputConfig !== undefined) {
      InputConfig.encode(message.inputConfig, writer.uint32(42).fork()).join();
    }
    if (message.conversationInfo !== undefined) {
      ConversationInfo.encode(message.conversationInfo, writer.uint32(50).fork()).join();
    }
    if (!message.conversationCount.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.conversationCount.toString());
    }
    if (message.satisfiesPzi !== undefined) {
      writer.uint32(64).bool(message.satisfiesPzi);
    }
    if (message.satisfiesPzs !== undefined) {
      writer.uint32(72).bool(message.satisfiesPzs);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConversationDataset {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConversationDataset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.inputConfig = InputConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.conversationInfo = ConversationInfo.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.conversationCount = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.satisfiesPzi = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConversationDataset {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      inputConfig: isSet(object.inputConfig) ? InputConfig.fromJSON(object.inputConfig) : undefined,
      conversationInfo: isSet(object.conversationInfo) ? ConversationInfo.fromJSON(object.conversationInfo) : undefined,
      conversationCount: isSet(object.conversationCount) ? Long.fromValue(object.conversationCount) : Long.ZERO,
      satisfiesPzi: isSet(object.satisfiesPzi) ? globalThis.Boolean(object.satisfiesPzi) : undefined,
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : undefined,
    };
  },

  toJSON(message: ConversationDataset): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.inputConfig !== undefined) {
      obj.inputConfig = InputConfig.toJSON(message.inputConfig);
    }
    if (message.conversationInfo !== undefined) {
      obj.conversationInfo = ConversationInfo.toJSON(message.conversationInfo);
    }
    if (!message.conversationCount.equals(Long.ZERO)) {
      obj.conversationCount = (message.conversationCount || Long.ZERO).toString();
    }
    if (message.satisfiesPzi !== undefined) {
      obj.satisfiesPzi = message.satisfiesPzi;
    }
    if (message.satisfiesPzs !== undefined) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    return obj;
  },

  create(base?: DeepPartial<ConversationDataset>): ConversationDataset {
    return ConversationDataset.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConversationDataset>): ConversationDataset {
    const message = createBaseConversationDataset();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.inputConfig = (object.inputConfig !== undefined && object.inputConfig !== null)
      ? InputConfig.fromPartial(object.inputConfig)
      : undefined;
    message.conversationInfo = (object.conversationInfo !== undefined && object.conversationInfo !== null)
      ? ConversationInfo.fromPartial(object.conversationInfo)
      : undefined;
    message.conversationCount = (object.conversationCount !== undefined && object.conversationCount !== null)
      ? Long.fromValue(object.conversationCount)
      : Long.ZERO;
    message.satisfiesPzi = object.satisfiesPzi ?? undefined;
    message.satisfiesPzs = object.satisfiesPzs ?? undefined;
    return message;
  },
};

function createBaseCreateConversationDatasetRequest(): CreateConversationDatasetRequest {
  return { parent: "", conversationDataset: undefined };
}

export const CreateConversationDatasetRequest: MessageFns<CreateConversationDatasetRequest> = {
  encode(message: CreateConversationDatasetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.conversationDataset !== undefined) {
      ConversationDataset.encode(message.conversationDataset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConversationDatasetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConversationDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.conversationDataset = ConversationDataset.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConversationDatasetRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      conversationDataset: isSet(object.conversationDataset)
        ? ConversationDataset.fromJSON(object.conversationDataset)
        : undefined,
    };
  },

  toJSON(message: CreateConversationDatasetRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.conversationDataset !== undefined) {
      obj.conversationDataset = ConversationDataset.toJSON(message.conversationDataset);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateConversationDatasetRequest>): CreateConversationDatasetRequest {
    return CreateConversationDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateConversationDatasetRequest>): CreateConversationDatasetRequest {
    const message = createBaseCreateConversationDatasetRequest();
    message.parent = object.parent ?? "";
    message.conversationDataset = (object.conversationDataset !== undefined && object.conversationDataset !== null)
      ? ConversationDataset.fromPartial(object.conversationDataset)
      : undefined;
    return message;
  },
};

function createBaseGetConversationDatasetRequest(): GetConversationDatasetRequest {
  return { name: "" };
}

export const GetConversationDatasetRequest: MessageFns<GetConversationDatasetRequest> = {
  encode(message: GetConversationDatasetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetConversationDatasetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetConversationDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetConversationDatasetRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetConversationDatasetRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetConversationDatasetRequest>): GetConversationDatasetRequest {
    return GetConversationDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetConversationDatasetRequest>): GetConversationDatasetRequest {
    const message = createBaseGetConversationDatasetRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListConversationDatasetsRequest(): ListConversationDatasetsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListConversationDatasetsRequest: MessageFns<ListConversationDatasetsRequest> = {
  encode(message: ListConversationDatasetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConversationDatasetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConversationDatasetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConversationDatasetsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListConversationDatasetsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConversationDatasetsRequest>): ListConversationDatasetsRequest {
    return ListConversationDatasetsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConversationDatasetsRequest>): ListConversationDatasetsRequest {
    const message = createBaseListConversationDatasetsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListConversationDatasetsResponse(): ListConversationDatasetsResponse {
  return { conversationDatasets: [], nextPageToken: "" };
}

export const ListConversationDatasetsResponse: MessageFns<ListConversationDatasetsResponse> = {
  encode(message: ListConversationDatasetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.conversationDatasets) {
      ConversationDataset.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListConversationDatasetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListConversationDatasetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationDatasets.push(ConversationDataset.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListConversationDatasetsResponse {
    return {
      conversationDatasets: globalThis.Array.isArray(object?.conversationDatasets)
        ? object.conversationDatasets.map((e: any) => ConversationDataset.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListConversationDatasetsResponse): unknown {
    const obj: any = {};
    if (message.conversationDatasets?.length) {
      obj.conversationDatasets = message.conversationDatasets.map((e) => ConversationDataset.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListConversationDatasetsResponse>): ListConversationDatasetsResponse {
    return ListConversationDatasetsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListConversationDatasetsResponse>): ListConversationDatasetsResponse {
    const message = createBaseListConversationDatasetsResponse();
    message.conversationDatasets = object.conversationDatasets?.map((e) => ConversationDataset.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteConversationDatasetRequest(): DeleteConversationDatasetRequest {
  return { name: "" };
}

export const DeleteConversationDatasetRequest: MessageFns<DeleteConversationDatasetRequest> = {
  encode(message: DeleteConversationDatasetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteConversationDatasetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteConversationDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteConversationDatasetRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteConversationDatasetRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteConversationDatasetRequest>): DeleteConversationDatasetRequest {
    return DeleteConversationDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteConversationDatasetRequest>): DeleteConversationDatasetRequest {
    const message = createBaseDeleteConversationDatasetRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseImportConversationDataRequest(): ImportConversationDataRequest {
  return { name: "", inputConfig: undefined };
}

export const ImportConversationDataRequest: MessageFns<ImportConversationDataRequest> = {
  encode(message: ImportConversationDataRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.inputConfig !== undefined) {
      InputConfig.encode(message.inputConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportConversationDataRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportConversationDataRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inputConfig = InputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportConversationDataRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      inputConfig: isSet(object.inputConfig) ? InputConfig.fromJSON(object.inputConfig) : undefined,
    };
  },

  toJSON(message: ImportConversationDataRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.inputConfig !== undefined) {
      obj.inputConfig = InputConfig.toJSON(message.inputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<ImportConversationDataRequest>): ImportConversationDataRequest {
    return ImportConversationDataRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportConversationDataRequest>): ImportConversationDataRequest {
    const message = createBaseImportConversationDataRequest();
    message.name = object.name ?? "";
    message.inputConfig = (object.inputConfig !== undefined && object.inputConfig !== null)
      ? InputConfig.fromPartial(object.inputConfig)
      : undefined;
    return message;
  },
};

function createBaseImportConversationDataOperationMetadata(): ImportConversationDataOperationMetadata {
  return { conversationDataset: "", partialFailures: [], createTime: undefined };
}

export const ImportConversationDataOperationMetadata: MessageFns<ImportConversationDataOperationMetadata> = {
  encode(message: ImportConversationDataOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationDataset !== "") {
      writer.uint32(10).string(message.conversationDataset);
    }
    for (const v of message.partialFailures) {
      Status.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportConversationDataOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportConversationDataOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationDataset = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partialFailures.push(Status.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportConversationDataOperationMetadata {
    return {
      conversationDataset: isSet(object.conversationDataset) ? globalThis.String(object.conversationDataset) : "",
      partialFailures: globalThis.Array.isArray(object?.partialFailures)
        ? object.partialFailures.map((e: any) => Status.fromJSON(e))
        : [],
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
    };
  },

  toJSON(message: ImportConversationDataOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationDataset !== "") {
      obj.conversationDataset = message.conversationDataset;
    }
    if (message.partialFailures?.length) {
      obj.partialFailures = message.partialFailures.map((e) => Status.toJSON(e));
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ImportConversationDataOperationMetadata>): ImportConversationDataOperationMetadata {
    return ImportConversationDataOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportConversationDataOperationMetadata>): ImportConversationDataOperationMetadata {
    const message = createBaseImportConversationDataOperationMetadata();
    message.conversationDataset = object.conversationDataset ?? "";
    message.partialFailures = object.partialFailures?.map((e) => Status.fromPartial(e)) || [];
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseImportConversationDataOperationResponse(): ImportConversationDataOperationResponse {
  return { conversationDataset: "", importCount: 0 };
}

export const ImportConversationDataOperationResponse: MessageFns<ImportConversationDataOperationResponse> = {
  encode(message: ImportConversationDataOperationResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationDataset !== "") {
      writer.uint32(10).string(message.conversationDataset);
    }
    if (message.importCount !== 0) {
      writer.uint32(24).int32(message.importCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportConversationDataOperationResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportConversationDataOperationResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationDataset = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.importCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportConversationDataOperationResponse {
    return {
      conversationDataset: isSet(object.conversationDataset) ? globalThis.String(object.conversationDataset) : "",
      importCount: isSet(object.importCount) ? globalThis.Number(object.importCount) : 0,
    };
  },

  toJSON(message: ImportConversationDataOperationResponse): unknown {
    const obj: any = {};
    if (message.conversationDataset !== "") {
      obj.conversationDataset = message.conversationDataset;
    }
    if (message.importCount !== 0) {
      obj.importCount = Math.round(message.importCount);
    }
    return obj;
  },

  create(base?: DeepPartial<ImportConversationDataOperationResponse>): ImportConversationDataOperationResponse {
    return ImportConversationDataOperationResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportConversationDataOperationResponse>): ImportConversationDataOperationResponse {
    const message = createBaseImportConversationDataOperationResponse();
    message.conversationDataset = object.conversationDataset ?? "";
    message.importCount = object.importCount ?? 0;
    return message;
  },
};

function createBaseCreateConversationDatasetOperationMetadata(): CreateConversationDatasetOperationMetadata {
  return { conversationDataset: "" };
}

export const CreateConversationDatasetOperationMetadata: MessageFns<CreateConversationDatasetOperationMetadata> = {
  encode(message: CreateConversationDatasetOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.conversationDataset !== "") {
      writer.uint32(10).string(message.conversationDataset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateConversationDatasetOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateConversationDatasetOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.conversationDataset = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateConversationDatasetOperationMetadata {
    return {
      conversationDataset: isSet(object.conversationDataset) ? globalThis.String(object.conversationDataset) : "",
    };
  },

  toJSON(message: CreateConversationDatasetOperationMetadata): unknown {
    const obj: any = {};
    if (message.conversationDataset !== "") {
      obj.conversationDataset = message.conversationDataset;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateConversationDatasetOperationMetadata>): CreateConversationDatasetOperationMetadata {
    return CreateConversationDatasetOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CreateConversationDatasetOperationMetadata>,
  ): CreateConversationDatasetOperationMetadata {
    const message = createBaseCreateConversationDatasetOperationMetadata();
    message.conversationDataset = object.conversationDataset ?? "";
    return message;
  },
};

function createBaseDeleteConversationDatasetOperationMetadata(): DeleteConversationDatasetOperationMetadata {
  return {};
}

export const DeleteConversationDatasetOperationMetadata: MessageFns<DeleteConversationDatasetOperationMetadata> = {
  encode(_: DeleteConversationDatasetOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteConversationDatasetOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteConversationDatasetOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DeleteConversationDatasetOperationMetadata {
    return {};
  },

  toJSON(_: DeleteConversationDatasetOperationMetadata): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DeleteConversationDatasetOperationMetadata>): DeleteConversationDatasetOperationMetadata {
    return DeleteConversationDatasetOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DeleteConversationDatasetOperationMetadata>): DeleteConversationDatasetOperationMetadata {
    const message = createBaseDeleteConversationDatasetOperationMetadata();
    return message;
  },
};

/**
 * Conversation datasets.
 *
 * Conversation datasets contain raw conversation files and their
 * customizable metadata that can be used for model training.
 */
export type ConversationDatasetsDefinition = typeof ConversationDatasetsDefinition;
export const ConversationDatasetsDefinition = {
  name: "ConversationDatasets",
  fullName: "google.cloud.dialogflow.v2.ConversationDatasets",
  methods: {
    /**
     * Creates a new conversation dataset.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [CreateConversationDatasetOperationMetadata][google.cloud.dialogflow.v2.CreateConversationDatasetOperationMetadata]
     * - `response`:
     * [ConversationDataset][google.cloud.dialogflow.v2.ConversationDataset]
     */
    createConversationDataset: {
      name: "CreateConversationDataset",
      requestType: CreateConversationDatasetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              65,
              10,
              19,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              18,
              42,
              67,
              114,
              101,
              97,
              116,
              101,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              95,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
            ]),
          ],
          578365826: [
            Buffer.from([
              80,
              58,
              20,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              95,
              100,
              97,
              116,
              97,
              115,
              101,
              116,
              34,
              56,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Retrieves the specified conversation dataset. */
    getConversationDataset: {
      name: "GetConversationDataset",
      requestType: GetConversationDatasetRequest,
      requestStream: false,
      responseType: ConversationDataset,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              106,
              90,
              58,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              42,
              125,
              18,
              44,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the list of all conversation datasets in the specified
     * project and location.
     */
    listConversationDatasets: {
      name: "ListConversationDatasets",
      requestType: ListConversationDatasetsRequest,
      requestStream: false,
      responseType: ListConversationDatasetsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              106,
              90,
              58,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              18,
              44,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes the specified conversation dataset.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [DeleteConversationDatasetOperationMetadata][google.cloud.dialogflow.v2.DeleteConversationDatasetOperationMetadata]
     * - `response`: An [Empty
     *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
     */
    deleteConversationDataset: {
      name: "DeleteConversationDataset",
      requestType: DeleteConversationDatasetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              67,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              42,
              68,
              101,
              108,
              101,
              116,
              101,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              58,
              42,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Import data into the specified conversation dataset. Note that it
     * is not allowed to import data to a conversation dataset that
     * already has data in it.
     *
     * This method is a [long-running
     * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
     * The returned `Operation` type has the following method-specific fields:
     *
     * - `metadata`:
     * [ImportConversationDataOperationMetadata][google.cloud.dialogflow.v2.ImportConversationDataOperationMetadata]
     * - `response`:
     * [ImportConversationDataOperationResponse][google.cloud.dialogflow.v2.ImportConversationDataOperationResponse]
     */
    importConversationData: {
      name: "ImportConversationData",
      requestType: ImportConversationDataRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              82,
              10,
              39,
              73,
              109,
              112,
              111,
              114,
              116,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              39,
              73,
              109,
              112,
              111,
              114,
              116,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              158,
              1,
              58,
              1,
              42,
              90,
              84,
              58,
              1,
              42,
              34,
              79,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              34,
              67,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              99,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
              67,
              111,
              110,
              118,
              101,
              114,
              115,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface ConversationDatasetsServiceImplementation<CallContextExt = {}> {
  /**
   * Creates a new conversation dataset.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [CreateConversationDatasetOperationMetadata][google.cloud.dialogflow.v2.CreateConversationDatasetOperationMetadata]
   * - `response`:
   * [ConversationDataset][google.cloud.dialogflow.v2.ConversationDataset]
   */
  createConversationDataset(
    request: CreateConversationDatasetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Retrieves the specified conversation dataset. */
  getConversationDataset(
    request: GetConversationDatasetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ConversationDataset>>;
  /**
   * Returns the list of all conversation datasets in the specified
   * project and location.
   */
  listConversationDatasets(
    request: ListConversationDatasetsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListConversationDatasetsResponse>>;
  /**
   * Deletes the specified conversation dataset.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [DeleteConversationDatasetOperationMetadata][google.cloud.dialogflow.v2.DeleteConversationDatasetOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  deleteConversationDataset(
    request: DeleteConversationDatasetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Import data into the specified conversation dataset. Note that it
   * is not allowed to import data to a conversation dataset that
   * already has data in it.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [ImportConversationDataOperationMetadata][google.cloud.dialogflow.v2.ImportConversationDataOperationMetadata]
   * - `response`:
   * [ImportConversationDataOperationResponse][google.cloud.dialogflow.v2.ImportConversationDataOperationResponse]
   */
  importConversationData(
    request: ImportConversationDataRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface ConversationDatasetsClient<CallOptionsExt = {}> {
  /**
   * Creates a new conversation dataset.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [CreateConversationDatasetOperationMetadata][google.cloud.dialogflow.v2.CreateConversationDatasetOperationMetadata]
   * - `response`:
   * [ConversationDataset][google.cloud.dialogflow.v2.ConversationDataset]
   */
  createConversationDataset(
    request: DeepPartial<CreateConversationDatasetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Retrieves the specified conversation dataset. */
  getConversationDataset(
    request: DeepPartial<GetConversationDatasetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ConversationDataset>;
  /**
   * Returns the list of all conversation datasets in the specified
   * project and location.
   */
  listConversationDatasets(
    request: DeepPartial<ListConversationDatasetsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListConversationDatasetsResponse>;
  /**
   * Deletes the specified conversation dataset.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [DeleteConversationDatasetOperationMetadata][google.cloud.dialogflow.v2.DeleteConversationDatasetOperationMetadata]
   * - `response`: An [Empty
   *   message](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty)
   */
  deleteConversationDataset(
    request: DeepPartial<DeleteConversationDatasetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Import data into the specified conversation dataset. Note that it
   * is not allowed to import data to a conversation dataset that
   * already has data in it.
   *
   * This method is a [long-running
   * operation](https://cloud.google.com/dialogflow/es/docs/how/long-running-operations).
   * The returned `Operation` type has the following method-specific fields:
   *
   * - `metadata`:
   * [ImportConversationDataOperationMetadata][google.cloud.dialogflow.v2.ImportConversationDataOperationMetadata]
   * - `response`:
   * [ImportConversationDataOperationResponse][google.cloud.dialogflow.v2.ImportConversationDataOperationResponse]
   */
  importConversationData(
    request: DeepPartial<ImportConversationDataRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
