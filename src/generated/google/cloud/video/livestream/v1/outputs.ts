// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/video/livestream/v1/outputs.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../protobuf/duration.js";
import { TimeZone } from "../../../../type/datetime.js";

export const protobufPackage = "google.cloud.video.livestream.v1";

/**
 * Encoding of an input element such as an audio, video, or text track.
 * Elementary streams must be packaged before mapping and sharing between
 * different output formats.
 */
export interface ElementaryStream {
  /**
   * A unique key for this elementary stream. The key must be 1-63
   * characters in length. The key must begin and end with a letter (regardless
   * of case) or a number, but can contain dashes or underscores in between.
   */
  key: string;
  /** Encoding of a video stream. */
  videoStream?:
    | VideoStream
    | undefined;
  /** Encoding of an audio stream. */
  audioStream?:
    | AudioStream
    | undefined;
  /** Encoding of a text stream. For example, closed captions or subtitles. */
  textStream?: TextStream | undefined;
}

/** Multiplexing settings for output stream. */
export interface MuxStream {
  /**
   * A unique key for this multiplexed stream. The key must be 1-63
   * characters in length. The key must begin and end with a letter (regardless
   * of case) or a number, but can contain dashes or underscores in between.
   */
  key: string;
  /**
   * The container format. The default is `fmp4`.
   *
   * Supported container formats:
   *
   * - `fmp4` - the corresponding file extension is `.m4s`
   * - `ts` - the corresponding file extension is `.ts`
   */
  container: string;
  /**
   * List of `ElementaryStream`
   * [key][google.cloud.video.livestream.v1.ElementaryStream.key]s multiplexed
   * in this stream.
   *
   * - For `fmp4` container, must contain either one video or one audio stream.
   * - For `ts` container, must contain exactly one audio stream and up to one
   * video stream.
   */
  elementaryStreams: string[];
  /** Segment settings for `fmp4` and `ts`. */
  segmentSettings:
    | SegmentSettings
    | undefined;
  /**
   * Identifier of the encryption configuration to use. If omitted, output
   * will be unencrypted.
   */
  encryptionId: string;
}

/** Manifest configuration. */
export interface Manifest {
  /**
   * The name of the generated file. The default is `manifest` with the
   * extension suffix corresponding to the `Manifest`
   * [type][google.cloud.video.livestream.v1.Manifest.type]. If multiple
   * manifests are added to the channel, each must have a unique file name.
   */
  fileName: string;
  /** Required. Type of the manifest, can be `HLS` or `DASH`. */
  type: Manifest_ManifestType;
  /**
   * Required. List of `MuxStream`
   * [key][google.cloud.video.livestream.v1.MuxStream.key]s that should appear
   * in this manifest.
   *
   * - For HLS, either `fmp4` or `ts` mux streams can be specified but not
   * mixed.
   * - For DASH, only `fmp4` mux streams can be specified.
   */
  muxStreams: string[];
  /**
   * Maximum number of segments that this manifest holds. Once the manifest
   * reaches this maximum number of segments, whenever a new segment is added to
   * the manifest, the oldest segment will be removed from the manifest.
   * The minimum value is 3 and the default value is 5.
   */
  maxSegmentCount: number;
  /**
   * How long to keep a segment on the output Google Cloud Storage bucket after
   * it is removed from the manifest. This field should be large enough to cover
   * the manifest propagation delay. Otherwise, a player could receive 404
   * errors while accessing segments which are listed in the manifest that the
   * player has, but were already deleted from the output Google Cloud Storage
   * bucket. Default value is `60s`.
   *
   * If both segment_keep_duration and
   * [RetentionConfig.retention_window_duration][google.cloud.video.livestream.v1.RetentionConfig.retention_window_duration]
   * are set,
   * [RetentionConfig.retention_window_duration][google.cloud.video.livestream.v1.RetentionConfig.retention_window_duration]
   * is used and segment_keep_duration is ignored.
   */
  segmentKeepDuration:
    | Duration
    | undefined;
  /**
   * Whether to use the timecode, as specified in timecode config, when setting:
   *
   * - `availabilityStartTime` attribute in DASH manifests.
   * - `#EXT-X-PROGRAM-DATE-TIME` tag in HLS manifests.
   *
   * If false, ignore the input timecode and use the time from system clock
   * when the manifest is first generated. This is the default behavior.
   */
  useTimecodeAsTimeline: boolean;
  /** Optional. A unique key for this manifest. */
  key: string;
}

/** The manifest type can be either `HLS` or `DASH`. */
export enum Manifest_ManifestType {
  /** MANIFEST_TYPE_UNSPECIFIED - The manifest type is not specified. */
  MANIFEST_TYPE_UNSPECIFIED = 0,
  /** HLS - Create an `HLS` manifest. The corresponding file extension is `.m3u8`. */
  HLS = 1,
  /** DASH - Create a `DASH` manifest. The corresponding file extension is `.mpd`. */
  DASH = 2,
  UNRECOGNIZED = -1,
}

export function manifest_ManifestTypeFromJSON(object: any): Manifest_ManifestType {
  switch (object) {
    case 0:
    case "MANIFEST_TYPE_UNSPECIFIED":
      return Manifest_ManifestType.MANIFEST_TYPE_UNSPECIFIED;
    case 1:
    case "HLS":
      return Manifest_ManifestType.HLS;
    case 2:
    case "DASH":
      return Manifest_ManifestType.DASH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Manifest_ManifestType.UNRECOGNIZED;
  }
}

export function manifest_ManifestTypeToJSON(object: Manifest_ManifestType): string {
  switch (object) {
    case Manifest_ManifestType.MANIFEST_TYPE_UNSPECIFIED:
      return "MANIFEST_TYPE_UNSPECIFIED";
    case Manifest_ManifestType.HLS:
      return "HLS";
    case Manifest_ManifestType.DASH:
      return "DASH";
    case Manifest_ManifestType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Sprite sheet configuration. */
export interface SpriteSheet {
  /**
   * Format type. The default is `jpeg`.
   *
   * Supported formats:
   *
   * - `jpeg`
   */
  format: string;
  /**
   * Required. File name prefix for the generated sprite sheets. If multiple
   * sprite sheets are added to the channel, each must have a unique file
   * prefix.
   * Each sprite sheet has an incremental 10-digit zero-padded suffix starting
   * from 0 before the extension, such as `sprite_sheet0000000123.jpeg`.
   */
  filePrefix: string;
  /** Required. The width of the sprite in pixels. Must be an even integer. */
  spriteWidthPixels: number;
  /** Required. The height of the sprite in pixels. Must be an even integer. */
  spriteHeightPixels: number;
  /**
   * The maximum number of sprites per row in a sprite sheet. Valid range is
   * [1, 10] and the default value is 1.
   */
  columnCount: number;
  /**
   * The maximum number of rows per sprite sheet. When the sprite sheet is full,
   * a new sprite sheet is created. Valid range is [1, 10] and the default value
   * is 1.
   */
  rowCount: number;
  /**
   * Create sprites at regular intervals. Valid range is [1 second, 1 hour] and
   * the default value is `10s`.
   */
  interval:
    | Duration
    | undefined;
  /**
   * The quality of the generated sprite sheet. Enter a value between 1
   * and 100, where 1 is the lowest quality and 100 is the highest quality.
   * The default is 100. A high quality value corresponds to a low image data
   * compression ratio.
   */
  quality: number;
}

/** Preprocessing configurations. */
export interface PreprocessingConfig {
  /** Audio preprocessing configuration. */
  audio:
    | PreprocessingConfig_Audio
    | undefined;
  /** Specify the video cropping configuration. */
  crop:
    | PreprocessingConfig_Crop
    | undefined;
  /** Specify the video pad filter configuration. */
  pad: PreprocessingConfig_Pad | undefined;
}

/** Audio preprocessing configuration. */
export interface PreprocessingConfig_Audio {
  /**
   * Specify audio loudness normalization in loudness units relative to full
   * scale (LUFS). Enter a value between -24 and 0 according to the following:
   *
   * - -24 is the Advanced Television Systems Committee (ATSC A/85)
   * - -23 is the EU R128 broadcast standard
   * - -19 is the prior standard for online mono audio
   * - -18 is the ReplayGain standard
   * - -16 is the prior standard for stereo audio
   * - -14 is the new online audio standard recommended by Spotify, as well as
   * Amazon Echo
   * - 0 disables normalization. The default is 0.
   */
  lufs: number;
}

/**
 * Video cropping configuration for the input video. The cropped input video
 * is scaled to match the output resolution.
 */
export interface PreprocessingConfig_Crop {
  /** The number of pixels to crop from the top. The default is 0. */
  topPixels: number;
  /** The number of pixels to crop from the bottom. The default is 0. */
  bottomPixels: number;
  /** The number of pixels to crop from the left. The default is 0. */
  leftPixels: number;
  /** The number of pixels to crop from the right. The default is 0. */
  rightPixels: number;
}

/**
 * Pad filter configuration for the input video. The padded input video
 * is scaled after padding with black to match the output resolution.
 */
export interface PreprocessingConfig_Pad {
  /** The number of pixels to add to the top. The default is 0. */
  topPixels: number;
  /** The number of pixels to add to the bottom. The default is 0. */
  bottomPixels: number;
  /** The number of pixels to add to the left. The default is 0. */
  leftPixels: number;
  /** The number of pixels to add to the right. The default is 0. */
  rightPixels: number;
}

/** Video stream resource. */
export interface VideoStream {
  /** H264 codec settings. */
  h264?: VideoStream_H264CodecSettings | undefined;
}

/** H264 codec settings. */
export interface VideoStream_H264CodecSettings {
  /**
   * Required. The width of the video in pixels. Must be an even integer.
   * Valid range is [320, 1920].
   */
  widthPixels: number;
  /**
   * Required. The height of the video in pixels. Must be an even integer.
   * Valid range is [180, 1080].
   */
  heightPixels: number;
  /**
   * Required. The target video frame rate in frames per second (FPS). Must be
   * less than or equal to 60. Will default to the input frame rate if larger
   * than the input frame rate. The API will generate an output FPS that is
   * divisible by the input FPS, and smaller or equal to the target FPS. See
   * [Calculating frame
   * rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
   * more information.
   */
  frameRate: number;
  /**
   * Required. The video bitrate in bits per second. Minimum value is 10,000.
   *
   * - For SD resolution (< 720p), must be <= 3,000,000 (3 Mbps).
   * - For HD resolution (<= 1080p), must be <= 15,000,000 (15 Mbps).
   */
  bitrateBps: number;
  /**
   * Specifies whether an open Group of Pictures (GOP) structure should be
   * allowed or not. The default is `false`.
   */
  allowOpenGop: boolean;
  /**
   * Select the GOP size based on the specified frame count.
   * If GOP frame count is set instead of GOP duration, GOP duration will be
   * calculated by `gopFrameCount`/`frameRate`. The calculated GOP duration
   * must satisfy the limitations on `gopDuration` as well.
   * Valid range is [60, 600].
   */
  gopFrameCount?:
    | number
    | undefined;
  /**
   * Select the GOP size based on the specified duration. The default is
   * `2s`. Note that `gopDuration` must be less than or equal to
   * [segment_duration][google.cloud.video.livestream.v1.SegmentSettings.segment_duration],
   * and
   * [segment_duration][google.cloud.video.livestream.v1.SegmentSettings.segment_duration]
   * must be divisible by `gopDuration`. Valid range is [2s, 20s].
   *
   * All video streams in the same channel must have the same GOP size.
   */
  gopDuration?:
    | Duration
    | undefined;
  /**
   * Size of the Video Buffering Verifier (VBV) buffer in bits. Must be
   * greater than zero. The default is equal to
   * [bitrate_bps][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings.bitrate_bps].
   */
  vbvSizeBits: number;
  /**
   * Initial fullness of the Video Buffering Verifier (VBV) buffer in bits.
   * Must be greater than zero. The default is equal to 90% of
   * [vbv_size_bits][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings.vbv_size_bits].
   */
  vbvFullnessBits: number;
  /**
   * The entropy coder to use. The default is `cabac`.
   *
   * Supported entropy coders:
   *
   * - `cavlc`
   * - `cabac`
   */
  entropyCoder: string;
  /**
   * Allow B-pyramid for reference frame selection. This may not be supported
   * on all decoders. The default is `false`.
   */
  bPyramid: boolean;
  /**
   * The number of consecutive B-frames. Must be greater than or equal to
   * zero. Must be less than
   * [gop_frame_count][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings.gop_frame_count]
   * if set. The default is 0.
   */
  bFrameCount: number;
  /**
   * Specify the intensity of the adaptive quantizer (AQ). Must be between 0
   * and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A
   * higher value equals a lower bitrate but smoother image. The default is 0.
   */
  aqStrength: number;
  /**
   * Enforces the specified codec profile. The following profiles are
   * supported:
   *
   * *   `baseline`
   * *   `main` (default)
   * *   `high`
   *
   * The available options are [FFmpeg-compatible Profile
   * Options](https://trac.ffmpeg.org/wiki/Encode/H.264#Profile).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the
   * [H264CodecSettings][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings]
   * message.
   */
  profile: string;
  /**
   * Enforces the specified codec tune. The available options are
   * [FFmpeg-compatible Encode
   * Options](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune)
   * Note that certain values for this field may cause the transcoder to
   * override other fields you set in the
   * [H264CodecSettings][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings]
   * message.
   */
  tune: string;
}

/** Audio stream resource. */
export interface AudioStream {
  /**
   * Specifies whether pass through (transmuxing) is enabled or not.
   * If set to `true`, the rest of the settings, other than `mapping`, will be
   * ignored. The default is `false`.
   */
  transmux: boolean;
  /**
   * The codec for this audio stream. The default is `aac`.
   *
   * Supported audio codecs:
   *
   * - `aac`
   */
  codec: string;
  /**
   * Required. Audio bitrate in bits per second. Must be between 1 and
   * 10,000,000.
   */
  bitrateBps: number;
  /** Number of audio channels. Must be between 1 and 6. The default is 2. */
  channelCount: number;
  /**
   * A list of channel names specifying layout of the audio channels.
   * This only affects the metadata embedded in the container headers, if
   * supported by the specified format. The default is `[fl, fr]`.
   *
   * Supported channel names:
   *
   * - `fl` - Front left channel
   * - `fr` - Front right channel
   * - `sl` - Side left channel
   * - `sr` - Side right channel
   * - `fc` - Front center channel
   * - `lfe` - Low frequency
   */
  channelLayout: string[];
  /** The mapping for the input streams and audio channels. */
  mapping: AudioStream_AudioMapping[];
  /** The audio sample rate in Hertz. The default is 48000 Hertz. */
  sampleRateHertz: number;
}

/** The mapping for the input streams and audio channels. */
export interface AudioStream_AudioMapping {
  /**
   * Required. The `Channel`
   * [InputAttachment.key][google.cloud.video.livestream.v1.InputAttachment.key]
   * that identifies the input that this audio mapping applies to. If an
   * active input doesn't have an audio mapping, the primary audio track in
   * the input stream will be selected.
   */
  inputKey: string;
  /**
   * Required. The zero-based index of the track in the input stream.
   * All [mapping][google.cloud.video.livestream.v1.AudioStream.mapping]s in
   * the same [AudioStream][google.cloud.video.livestream.v1.AudioStream] must
   * have the same input track.
   */
  inputTrack: number;
  /** Required. The zero-based index of the channel in the input stream. */
  inputChannel: number;
  /**
   * Required. The zero-based index of the channel in the output audio stream.
   * Must be consistent with the
   * [input_channel][google.cloud.video.livestream.v1.AudioStream.AudioMapping.input_channel].
   */
  outputChannel: number;
  /**
   * Audio volume control in dB. Negative values decrease volume,
   * positive values increase. The default is 0.
   */
  gainDb: number;
}

/** Encoding of a text stream. For example, closed captions or subtitles. */
export interface TextStream {
  /**
   * Required. The codec for this text stream.
   *
   * Supported text codecs:
   *
   * - `cea608`
   * - `cea708`
   */
  codec: string;
}

/** Segment settings for `fmp4` and `ts`. */
export interface SegmentSettings {
  /**
   * Duration of the segments in seconds. The default is `6s`. Note that
   * `segmentDuration` must be greater than or equal to
   * [gop_duration][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings.gop_duration],
   * and `segmentDuration` must be divisible by
   * [gop_duration][google.cloud.video.livestream.v1.VideoStream.H264CodecSettings.gop_duration].
   * Valid range is [2s, 20s].
   *
   * All [mux_streams][google.cloud.video.livestream.v1.Manifest.mux_streams] in
   * the same manifest must have the same segment duration.
   */
  segmentDuration: Duration | undefined;
}

/** Timecode configuration. */
export interface TimecodeConfig {
  /**
   * The source of the timecode that will later be used in outputs/manifests.
   * It determines the initial timecode/timestamp (first frame) of output
   * streams.
   */
  source: TimecodeConfig_TimecodeSource;
  /** UTC offset. Must be whole seconds, between -18 hours and +18 hours. */
  utcOffset?:
    | Duration
    | undefined;
  /** Time zone e.g. "America/Los_Angeles". */
  timeZone?: TimeZone | undefined;
}

/** The source of timecode. */
export enum TimecodeConfig_TimecodeSource {
  /** TIMECODE_SOURCE_UNSPECIFIED - The timecode source is not specified. */
  TIMECODE_SOURCE_UNSPECIFIED = 0,
  /** MEDIA_TIMESTAMP - Use input media timestamp. */
  MEDIA_TIMESTAMP = 1,
  /** EMBEDDED_TIMECODE - Use input embedded timecode e.g. picture timing SEI message. */
  EMBEDDED_TIMECODE = 2,
  UNRECOGNIZED = -1,
}

export function timecodeConfig_TimecodeSourceFromJSON(object: any): TimecodeConfig_TimecodeSource {
  switch (object) {
    case 0:
    case "TIMECODE_SOURCE_UNSPECIFIED":
      return TimecodeConfig_TimecodeSource.TIMECODE_SOURCE_UNSPECIFIED;
    case 1:
    case "MEDIA_TIMESTAMP":
      return TimecodeConfig_TimecodeSource.MEDIA_TIMESTAMP;
    case 2:
    case "EMBEDDED_TIMECODE":
      return TimecodeConfig_TimecodeSource.EMBEDDED_TIMECODE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TimecodeConfig_TimecodeSource.UNRECOGNIZED;
  }
}

export function timecodeConfig_TimecodeSourceToJSON(object: TimecodeConfig_TimecodeSource): string {
  switch (object) {
    case TimecodeConfig_TimecodeSource.TIMECODE_SOURCE_UNSPECIFIED:
      return "TIMECODE_SOURCE_UNSPECIFIED";
    case TimecodeConfig_TimecodeSource.MEDIA_TIMESTAMP:
      return "MEDIA_TIMESTAMP";
    case TimecodeConfig_TimecodeSource.EMBEDDED_TIMECODE:
      return "EMBEDDED_TIMECODE";
    case TimecodeConfig_TimecodeSource.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseElementaryStream(): ElementaryStream {
  return { key: "", videoStream: undefined, audioStream: undefined, textStream: undefined };
}

export const ElementaryStream: MessageFns<ElementaryStream> = {
  encode(message: ElementaryStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(34).string(message.key);
    }
    if (message.videoStream !== undefined) {
      VideoStream.encode(message.videoStream, writer.uint32(10).fork()).join();
    }
    if (message.audioStream !== undefined) {
      AudioStream.encode(message.audioStream, writer.uint32(18).fork()).join();
    }
    if (message.textStream !== undefined) {
      TextStream.encode(message.textStream, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ElementaryStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseElementaryStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.key = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.videoStream = VideoStream.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.audioStream = AudioStream.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.textStream = TextStream.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ElementaryStream {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      videoStream: isSet(object.videoStream) ? VideoStream.fromJSON(object.videoStream) : undefined,
      audioStream: isSet(object.audioStream) ? AudioStream.fromJSON(object.audioStream) : undefined,
      textStream: isSet(object.textStream) ? TextStream.fromJSON(object.textStream) : undefined,
    };
  },

  toJSON(message: ElementaryStream): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.videoStream !== undefined) {
      obj.videoStream = VideoStream.toJSON(message.videoStream);
    }
    if (message.audioStream !== undefined) {
      obj.audioStream = AudioStream.toJSON(message.audioStream);
    }
    if (message.textStream !== undefined) {
      obj.textStream = TextStream.toJSON(message.textStream);
    }
    return obj;
  },

  create(base?: DeepPartial<ElementaryStream>): ElementaryStream {
    return ElementaryStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ElementaryStream>): ElementaryStream {
    const message = createBaseElementaryStream();
    message.key = object.key ?? "";
    message.videoStream = (object.videoStream !== undefined && object.videoStream !== null)
      ? VideoStream.fromPartial(object.videoStream)
      : undefined;
    message.audioStream = (object.audioStream !== undefined && object.audioStream !== null)
      ? AudioStream.fromPartial(object.audioStream)
      : undefined;
    message.textStream = (object.textStream !== undefined && object.textStream !== null)
      ? TextStream.fromPartial(object.textStream)
      : undefined;
    return message;
  },
};

function createBaseMuxStream(): MuxStream {
  return { key: "", container: "", elementaryStreams: [], segmentSettings: undefined, encryptionId: "" };
}

export const MuxStream: MessageFns<MuxStream> = {
  encode(message: MuxStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.container !== "") {
      writer.uint32(26).string(message.container);
    }
    for (const v of message.elementaryStreams) {
      writer.uint32(34).string(v!);
    }
    if (message.segmentSettings !== undefined) {
      SegmentSettings.encode(message.segmentSettings, writer.uint32(42).fork()).join();
    }
    if (message.encryptionId !== "") {
      writer.uint32(50).string(message.encryptionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MuxStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMuxStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.container = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.elementaryStreams.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.segmentSettings = SegmentSettings.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.encryptionId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MuxStream {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      container: isSet(object.container) ? globalThis.String(object.container) : "",
      elementaryStreams: globalThis.Array.isArray(object?.elementaryStreams)
        ? object.elementaryStreams.map((e: any) => globalThis.String(e))
        : [],
      segmentSettings: isSet(object.segmentSettings) ? SegmentSettings.fromJSON(object.segmentSettings) : undefined,
      encryptionId: isSet(object.encryptionId) ? globalThis.String(object.encryptionId) : "",
    };
  },

  toJSON(message: MuxStream): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.container !== "") {
      obj.container = message.container;
    }
    if (message.elementaryStreams?.length) {
      obj.elementaryStreams = message.elementaryStreams;
    }
    if (message.segmentSettings !== undefined) {
      obj.segmentSettings = SegmentSettings.toJSON(message.segmentSettings);
    }
    if (message.encryptionId !== "") {
      obj.encryptionId = message.encryptionId;
    }
    return obj;
  },

  create(base?: DeepPartial<MuxStream>): MuxStream {
    return MuxStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MuxStream>): MuxStream {
    const message = createBaseMuxStream();
    message.key = object.key ?? "";
    message.container = object.container ?? "";
    message.elementaryStreams = object.elementaryStreams?.map((e) => e) || [];
    message.segmentSettings = (object.segmentSettings !== undefined && object.segmentSettings !== null)
      ? SegmentSettings.fromPartial(object.segmentSettings)
      : undefined;
    message.encryptionId = object.encryptionId ?? "";
    return message;
  },
};

function createBaseManifest(): Manifest {
  return {
    fileName: "",
    type: 0,
    muxStreams: [],
    maxSegmentCount: 0,
    segmentKeepDuration: undefined,
    useTimecodeAsTimeline: false,
    key: "",
  };
}

export const Manifest: MessageFns<Manifest> = {
  encode(message: Manifest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fileName !== "") {
      writer.uint32(10).string(message.fileName);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    for (const v of message.muxStreams) {
      writer.uint32(26).string(v!);
    }
    if (message.maxSegmentCount !== 0) {
      writer.uint32(32).int32(message.maxSegmentCount);
    }
    if (message.segmentKeepDuration !== undefined) {
      Duration.encode(message.segmentKeepDuration, writer.uint32(42).fork()).join();
    }
    if (message.useTimecodeAsTimeline !== false) {
      writer.uint32(48).bool(message.useTimecodeAsTimeline);
    }
    if (message.key !== "") {
      writer.uint32(58).string(message.key);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Manifest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseManifest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fileName = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.muxStreams.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.maxSegmentCount = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.segmentKeepDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.useTimecodeAsTimeline = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.key = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Manifest {
    return {
      fileName: isSet(object.fileName) ? globalThis.String(object.fileName) : "",
      type: isSet(object.type) ? manifest_ManifestTypeFromJSON(object.type) : 0,
      muxStreams: globalThis.Array.isArray(object?.muxStreams)
        ? object.muxStreams.map((e: any) => globalThis.String(e))
        : [],
      maxSegmentCount: isSet(object.maxSegmentCount) ? globalThis.Number(object.maxSegmentCount) : 0,
      segmentKeepDuration: isSet(object.segmentKeepDuration)
        ? Duration.fromJSON(object.segmentKeepDuration)
        : undefined,
      useTimecodeAsTimeline: isSet(object.useTimecodeAsTimeline)
        ? globalThis.Boolean(object.useTimecodeAsTimeline)
        : false,
      key: isSet(object.key) ? globalThis.String(object.key) : "",
    };
  },

  toJSON(message: Manifest): unknown {
    const obj: any = {};
    if (message.fileName !== "") {
      obj.fileName = message.fileName;
    }
    if (message.type !== 0) {
      obj.type = manifest_ManifestTypeToJSON(message.type);
    }
    if (message.muxStreams?.length) {
      obj.muxStreams = message.muxStreams;
    }
    if (message.maxSegmentCount !== 0) {
      obj.maxSegmentCount = Math.round(message.maxSegmentCount);
    }
    if (message.segmentKeepDuration !== undefined) {
      obj.segmentKeepDuration = Duration.toJSON(message.segmentKeepDuration);
    }
    if (message.useTimecodeAsTimeline !== false) {
      obj.useTimecodeAsTimeline = message.useTimecodeAsTimeline;
    }
    if (message.key !== "") {
      obj.key = message.key;
    }
    return obj;
  },

  create(base?: DeepPartial<Manifest>): Manifest {
    return Manifest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Manifest>): Manifest {
    const message = createBaseManifest();
    message.fileName = object.fileName ?? "";
    message.type = object.type ?? 0;
    message.muxStreams = object.muxStreams?.map((e) => e) || [];
    message.maxSegmentCount = object.maxSegmentCount ?? 0;
    message.segmentKeepDuration = (object.segmentKeepDuration !== undefined && object.segmentKeepDuration !== null)
      ? Duration.fromPartial(object.segmentKeepDuration)
      : undefined;
    message.useTimecodeAsTimeline = object.useTimecodeAsTimeline ?? false;
    message.key = object.key ?? "";
    return message;
  },
};

function createBaseSpriteSheet(): SpriteSheet {
  return {
    format: "",
    filePrefix: "",
    spriteWidthPixels: 0,
    spriteHeightPixels: 0,
    columnCount: 0,
    rowCount: 0,
    interval: undefined,
    quality: 0,
  };
}

export const SpriteSheet: MessageFns<SpriteSheet> = {
  encode(message: SpriteSheet, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.format !== "") {
      writer.uint32(10).string(message.format);
    }
    if (message.filePrefix !== "") {
      writer.uint32(18).string(message.filePrefix);
    }
    if (message.spriteWidthPixels !== 0) {
      writer.uint32(24).int32(message.spriteWidthPixels);
    }
    if (message.spriteHeightPixels !== 0) {
      writer.uint32(32).int32(message.spriteHeightPixels);
    }
    if (message.columnCount !== 0) {
      writer.uint32(40).int32(message.columnCount);
    }
    if (message.rowCount !== 0) {
      writer.uint32(48).int32(message.rowCount);
    }
    if (message.interval !== undefined) {
      Duration.encode(message.interval, writer.uint32(58).fork()).join();
    }
    if (message.quality !== 0) {
      writer.uint32(64).int32(message.quality);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpriteSheet {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpriteSheet();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.format = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filePrefix = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.spriteWidthPixels = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.spriteHeightPixels = reader.int32();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.columnCount = reader.int32();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.rowCount = reader.int32();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.interval = Duration.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.quality = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpriteSheet {
    return {
      format: isSet(object.format) ? globalThis.String(object.format) : "",
      filePrefix: isSet(object.filePrefix) ? globalThis.String(object.filePrefix) : "",
      spriteWidthPixels: isSet(object.spriteWidthPixels) ? globalThis.Number(object.spriteWidthPixels) : 0,
      spriteHeightPixels: isSet(object.spriteHeightPixels) ? globalThis.Number(object.spriteHeightPixels) : 0,
      columnCount: isSet(object.columnCount) ? globalThis.Number(object.columnCount) : 0,
      rowCount: isSet(object.rowCount) ? globalThis.Number(object.rowCount) : 0,
      interval: isSet(object.interval) ? Duration.fromJSON(object.interval) : undefined,
      quality: isSet(object.quality) ? globalThis.Number(object.quality) : 0,
    };
  },

  toJSON(message: SpriteSheet): unknown {
    const obj: any = {};
    if (message.format !== "") {
      obj.format = message.format;
    }
    if (message.filePrefix !== "") {
      obj.filePrefix = message.filePrefix;
    }
    if (message.spriteWidthPixels !== 0) {
      obj.spriteWidthPixels = Math.round(message.spriteWidthPixels);
    }
    if (message.spriteHeightPixels !== 0) {
      obj.spriteHeightPixels = Math.round(message.spriteHeightPixels);
    }
    if (message.columnCount !== 0) {
      obj.columnCount = Math.round(message.columnCount);
    }
    if (message.rowCount !== 0) {
      obj.rowCount = Math.round(message.rowCount);
    }
    if (message.interval !== undefined) {
      obj.interval = Duration.toJSON(message.interval);
    }
    if (message.quality !== 0) {
      obj.quality = Math.round(message.quality);
    }
    return obj;
  },

  create(base?: DeepPartial<SpriteSheet>): SpriteSheet {
    return SpriteSheet.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpriteSheet>): SpriteSheet {
    const message = createBaseSpriteSheet();
    message.format = object.format ?? "";
    message.filePrefix = object.filePrefix ?? "";
    message.spriteWidthPixels = object.spriteWidthPixels ?? 0;
    message.spriteHeightPixels = object.spriteHeightPixels ?? 0;
    message.columnCount = object.columnCount ?? 0;
    message.rowCount = object.rowCount ?? 0;
    message.interval = (object.interval !== undefined && object.interval !== null)
      ? Duration.fromPartial(object.interval)
      : undefined;
    message.quality = object.quality ?? 0;
    return message;
  },
};

function createBasePreprocessingConfig(): PreprocessingConfig {
  return { audio: undefined, crop: undefined, pad: undefined };
}

export const PreprocessingConfig: MessageFns<PreprocessingConfig> = {
  encode(message: PreprocessingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.audio !== undefined) {
      PreprocessingConfig_Audio.encode(message.audio, writer.uint32(10).fork()).join();
    }
    if (message.crop !== undefined) {
      PreprocessingConfig_Crop.encode(message.crop, writer.uint32(18).fork()).join();
    }
    if (message.pad !== undefined) {
      PreprocessingConfig_Pad.encode(message.pad, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PreprocessingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePreprocessingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.audio = PreprocessingConfig_Audio.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.crop = PreprocessingConfig_Crop.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pad = PreprocessingConfig_Pad.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PreprocessingConfig {
    return {
      audio: isSet(object.audio) ? PreprocessingConfig_Audio.fromJSON(object.audio) : undefined,
      crop: isSet(object.crop) ? PreprocessingConfig_Crop.fromJSON(object.crop) : undefined,
      pad: isSet(object.pad) ? PreprocessingConfig_Pad.fromJSON(object.pad) : undefined,
    };
  },

  toJSON(message: PreprocessingConfig): unknown {
    const obj: any = {};
    if (message.audio !== undefined) {
      obj.audio = PreprocessingConfig_Audio.toJSON(message.audio);
    }
    if (message.crop !== undefined) {
      obj.crop = PreprocessingConfig_Crop.toJSON(message.crop);
    }
    if (message.pad !== undefined) {
      obj.pad = PreprocessingConfig_Pad.toJSON(message.pad);
    }
    return obj;
  },

  create(base?: DeepPartial<PreprocessingConfig>): PreprocessingConfig {
    return PreprocessingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PreprocessingConfig>): PreprocessingConfig {
    const message = createBasePreprocessingConfig();
    message.audio = (object.audio !== undefined && object.audio !== null)
      ? PreprocessingConfig_Audio.fromPartial(object.audio)
      : undefined;
    message.crop = (object.crop !== undefined && object.crop !== null)
      ? PreprocessingConfig_Crop.fromPartial(object.crop)
      : undefined;
    message.pad = (object.pad !== undefined && object.pad !== null)
      ? PreprocessingConfig_Pad.fromPartial(object.pad)
      : undefined;
    return message;
  },
};

function createBasePreprocessingConfig_Audio(): PreprocessingConfig_Audio {
  return { lufs: 0 };
}

export const PreprocessingConfig_Audio: MessageFns<PreprocessingConfig_Audio> = {
  encode(message: PreprocessingConfig_Audio, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.lufs !== 0) {
      writer.uint32(9).double(message.lufs);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PreprocessingConfig_Audio {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePreprocessingConfig_Audio();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 9) {
            break;
          }

          message.lufs = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PreprocessingConfig_Audio {
    return { lufs: isSet(object.lufs) ? globalThis.Number(object.lufs) : 0 };
  },

  toJSON(message: PreprocessingConfig_Audio): unknown {
    const obj: any = {};
    if (message.lufs !== 0) {
      obj.lufs = message.lufs;
    }
    return obj;
  },

  create(base?: DeepPartial<PreprocessingConfig_Audio>): PreprocessingConfig_Audio {
    return PreprocessingConfig_Audio.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PreprocessingConfig_Audio>): PreprocessingConfig_Audio {
    const message = createBasePreprocessingConfig_Audio();
    message.lufs = object.lufs ?? 0;
    return message;
  },
};

function createBasePreprocessingConfig_Crop(): PreprocessingConfig_Crop {
  return { topPixels: 0, bottomPixels: 0, leftPixels: 0, rightPixels: 0 };
}

export const PreprocessingConfig_Crop: MessageFns<PreprocessingConfig_Crop> = {
  encode(message: PreprocessingConfig_Crop, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topPixels !== 0) {
      writer.uint32(8).int32(message.topPixels);
    }
    if (message.bottomPixels !== 0) {
      writer.uint32(16).int32(message.bottomPixels);
    }
    if (message.leftPixels !== 0) {
      writer.uint32(24).int32(message.leftPixels);
    }
    if (message.rightPixels !== 0) {
      writer.uint32(32).int32(message.rightPixels);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PreprocessingConfig_Crop {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePreprocessingConfig_Crop();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.topPixels = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.bottomPixels = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.leftPixels = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.rightPixels = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PreprocessingConfig_Crop {
    return {
      topPixels: isSet(object.topPixels) ? globalThis.Number(object.topPixels) : 0,
      bottomPixels: isSet(object.bottomPixels) ? globalThis.Number(object.bottomPixels) : 0,
      leftPixels: isSet(object.leftPixels) ? globalThis.Number(object.leftPixels) : 0,
      rightPixels: isSet(object.rightPixels) ? globalThis.Number(object.rightPixels) : 0,
    };
  },

  toJSON(message: PreprocessingConfig_Crop): unknown {
    const obj: any = {};
    if (message.topPixels !== 0) {
      obj.topPixels = Math.round(message.topPixels);
    }
    if (message.bottomPixels !== 0) {
      obj.bottomPixels = Math.round(message.bottomPixels);
    }
    if (message.leftPixels !== 0) {
      obj.leftPixels = Math.round(message.leftPixels);
    }
    if (message.rightPixels !== 0) {
      obj.rightPixels = Math.round(message.rightPixels);
    }
    return obj;
  },

  create(base?: DeepPartial<PreprocessingConfig_Crop>): PreprocessingConfig_Crop {
    return PreprocessingConfig_Crop.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PreprocessingConfig_Crop>): PreprocessingConfig_Crop {
    const message = createBasePreprocessingConfig_Crop();
    message.topPixels = object.topPixels ?? 0;
    message.bottomPixels = object.bottomPixels ?? 0;
    message.leftPixels = object.leftPixels ?? 0;
    message.rightPixels = object.rightPixels ?? 0;
    return message;
  },
};

function createBasePreprocessingConfig_Pad(): PreprocessingConfig_Pad {
  return { topPixels: 0, bottomPixels: 0, leftPixels: 0, rightPixels: 0 };
}

export const PreprocessingConfig_Pad: MessageFns<PreprocessingConfig_Pad> = {
  encode(message: PreprocessingConfig_Pad, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topPixels !== 0) {
      writer.uint32(8).int32(message.topPixels);
    }
    if (message.bottomPixels !== 0) {
      writer.uint32(16).int32(message.bottomPixels);
    }
    if (message.leftPixels !== 0) {
      writer.uint32(24).int32(message.leftPixels);
    }
    if (message.rightPixels !== 0) {
      writer.uint32(32).int32(message.rightPixels);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PreprocessingConfig_Pad {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePreprocessingConfig_Pad();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.topPixels = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.bottomPixels = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.leftPixels = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.rightPixels = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PreprocessingConfig_Pad {
    return {
      topPixels: isSet(object.topPixels) ? globalThis.Number(object.topPixels) : 0,
      bottomPixels: isSet(object.bottomPixels) ? globalThis.Number(object.bottomPixels) : 0,
      leftPixels: isSet(object.leftPixels) ? globalThis.Number(object.leftPixels) : 0,
      rightPixels: isSet(object.rightPixels) ? globalThis.Number(object.rightPixels) : 0,
    };
  },

  toJSON(message: PreprocessingConfig_Pad): unknown {
    const obj: any = {};
    if (message.topPixels !== 0) {
      obj.topPixels = Math.round(message.topPixels);
    }
    if (message.bottomPixels !== 0) {
      obj.bottomPixels = Math.round(message.bottomPixels);
    }
    if (message.leftPixels !== 0) {
      obj.leftPixels = Math.round(message.leftPixels);
    }
    if (message.rightPixels !== 0) {
      obj.rightPixels = Math.round(message.rightPixels);
    }
    return obj;
  },

  create(base?: DeepPartial<PreprocessingConfig_Pad>): PreprocessingConfig_Pad {
    return PreprocessingConfig_Pad.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PreprocessingConfig_Pad>): PreprocessingConfig_Pad {
    const message = createBasePreprocessingConfig_Pad();
    message.topPixels = object.topPixels ?? 0;
    message.bottomPixels = object.bottomPixels ?? 0;
    message.leftPixels = object.leftPixels ?? 0;
    message.rightPixels = object.rightPixels ?? 0;
    return message;
  },
};

function createBaseVideoStream(): VideoStream {
  return { h264: undefined };
}

export const VideoStream: MessageFns<VideoStream> = {
  encode(message: VideoStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.h264 !== undefined) {
      VideoStream_H264CodecSettings.encode(message.h264, writer.uint32(162).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 20:
          if (tag !== 162) {
            break;
          }

          message.h264 = VideoStream_H264CodecSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoStream {
    return { h264: isSet(object.h264) ? VideoStream_H264CodecSettings.fromJSON(object.h264) : undefined };
  },

  toJSON(message: VideoStream): unknown {
    const obj: any = {};
    if (message.h264 !== undefined) {
      obj.h264 = VideoStream_H264CodecSettings.toJSON(message.h264);
    }
    return obj;
  },

  create(base?: DeepPartial<VideoStream>): VideoStream {
    return VideoStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoStream>): VideoStream {
    const message = createBaseVideoStream();
    message.h264 = (object.h264 !== undefined && object.h264 !== null)
      ? VideoStream_H264CodecSettings.fromPartial(object.h264)
      : undefined;
    return message;
  },
};

function createBaseVideoStream_H264CodecSettings(): VideoStream_H264CodecSettings {
  return {
    widthPixels: 0,
    heightPixels: 0,
    frameRate: 0,
    bitrateBps: 0,
    allowOpenGop: false,
    gopFrameCount: undefined,
    gopDuration: undefined,
    vbvSizeBits: 0,
    vbvFullnessBits: 0,
    entropyCoder: "",
    bPyramid: false,
    bFrameCount: 0,
    aqStrength: 0,
    profile: "",
    tune: "",
  };
}

export const VideoStream_H264CodecSettings: MessageFns<VideoStream_H264CodecSettings> = {
  encode(message: VideoStream_H264CodecSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.widthPixels !== 0) {
      writer.uint32(8).int32(message.widthPixels);
    }
    if (message.heightPixels !== 0) {
      writer.uint32(16).int32(message.heightPixels);
    }
    if (message.frameRate !== 0) {
      writer.uint32(25).double(message.frameRate);
    }
    if (message.bitrateBps !== 0) {
      writer.uint32(32).int32(message.bitrateBps);
    }
    if (message.allowOpenGop !== false) {
      writer.uint32(48).bool(message.allowOpenGop);
    }
    if (message.gopFrameCount !== undefined) {
      writer.uint32(56).int32(message.gopFrameCount);
    }
    if (message.gopDuration !== undefined) {
      Duration.encode(message.gopDuration, writer.uint32(66).fork()).join();
    }
    if (message.vbvSizeBits !== 0) {
      writer.uint32(72).int32(message.vbvSizeBits);
    }
    if (message.vbvFullnessBits !== 0) {
      writer.uint32(80).int32(message.vbvFullnessBits);
    }
    if (message.entropyCoder !== "") {
      writer.uint32(90).string(message.entropyCoder);
    }
    if (message.bPyramid !== false) {
      writer.uint32(96).bool(message.bPyramid);
    }
    if (message.bFrameCount !== 0) {
      writer.uint32(104).int32(message.bFrameCount);
    }
    if (message.aqStrength !== 0) {
      writer.uint32(113).double(message.aqStrength);
    }
    if (message.profile !== "") {
      writer.uint32(122).string(message.profile);
    }
    if (message.tune !== "") {
      writer.uint32(130).string(message.tune);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoStream_H264CodecSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoStream_H264CodecSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.widthPixels = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.heightPixels = reader.int32();
          continue;
        case 3:
          if (tag !== 25) {
            break;
          }

          message.frameRate = reader.double();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.bitrateBps = reader.int32();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.allowOpenGop = reader.bool();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.gopFrameCount = reader.int32();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.gopDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.vbvSizeBits = reader.int32();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.vbvFullnessBits = reader.int32();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.entropyCoder = reader.string();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.bPyramid = reader.bool();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.bFrameCount = reader.int32();
          continue;
        case 14:
          if (tag !== 113) {
            break;
          }

          message.aqStrength = reader.double();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.profile = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.tune = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoStream_H264CodecSettings {
    return {
      widthPixels: isSet(object.widthPixels) ? globalThis.Number(object.widthPixels) : 0,
      heightPixels: isSet(object.heightPixels) ? globalThis.Number(object.heightPixels) : 0,
      frameRate: isSet(object.frameRate) ? globalThis.Number(object.frameRate) : 0,
      bitrateBps: isSet(object.bitrateBps) ? globalThis.Number(object.bitrateBps) : 0,
      allowOpenGop: isSet(object.allowOpenGop) ? globalThis.Boolean(object.allowOpenGop) : false,
      gopFrameCount: isSet(object.gopFrameCount) ? globalThis.Number(object.gopFrameCount) : undefined,
      gopDuration: isSet(object.gopDuration) ? Duration.fromJSON(object.gopDuration) : undefined,
      vbvSizeBits: isSet(object.vbvSizeBits) ? globalThis.Number(object.vbvSizeBits) : 0,
      vbvFullnessBits: isSet(object.vbvFullnessBits) ? globalThis.Number(object.vbvFullnessBits) : 0,
      entropyCoder: isSet(object.entropyCoder) ? globalThis.String(object.entropyCoder) : "",
      bPyramid: isSet(object.bPyramid) ? globalThis.Boolean(object.bPyramid) : false,
      bFrameCount: isSet(object.bFrameCount) ? globalThis.Number(object.bFrameCount) : 0,
      aqStrength: isSet(object.aqStrength) ? globalThis.Number(object.aqStrength) : 0,
      profile: isSet(object.profile) ? globalThis.String(object.profile) : "",
      tune: isSet(object.tune) ? globalThis.String(object.tune) : "",
    };
  },

  toJSON(message: VideoStream_H264CodecSettings): unknown {
    const obj: any = {};
    if (message.widthPixels !== 0) {
      obj.widthPixels = Math.round(message.widthPixels);
    }
    if (message.heightPixels !== 0) {
      obj.heightPixels = Math.round(message.heightPixels);
    }
    if (message.frameRate !== 0) {
      obj.frameRate = message.frameRate;
    }
    if (message.bitrateBps !== 0) {
      obj.bitrateBps = Math.round(message.bitrateBps);
    }
    if (message.allowOpenGop !== false) {
      obj.allowOpenGop = message.allowOpenGop;
    }
    if (message.gopFrameCount !== undefined) {
      obj.gopFrameCount = Math.round(message.gopFrameCount);
    }
    if (message.gopDuration !== undefined) {
      obj.gopDuration = Duration.toJSON(message.gopDuration);
    }
    if (message.vbvSizeBits !== 0) {
      obj.vbvSizeBits = Math.round(message.vbvSizeBits);
    }
    if (message.vbvFullnessBits !== 0) {
      obj.vbvFullnessBits = Math.round(message.vbvFullnessBits);
    }
    if (message.entropyCoder !== "") {
      obj.entropyCoder = message.entropyCoder;
    }
    if (message.bPyramid !== false) {
      obj.bPyramid = message.bPyramid;
    }
    if (message.bFrameCount !== 0) {
      obj.bFrameCount = Math.round(message.bFrameCount);
    }
    if (message.aqStrength !== 0) {
      obj.aqStrength = message.aqStrength;
    }
    if (message.profile !== "") {
      obj.profile = message.profile;
    }
    if (message.tune !== "") {
      obj.tune = message.tune;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoStream_H264CodecSettings>): VideoStream_H264CodecSettings {
    return VideoStream_H264CodecSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoStream_H264CodecSettings>): VideoStream_H264CodecSettings {
    const message = createBaseVideoStream_H264CodecSettings();
    message.widthPixels = object.widthPixels ?? 0;
    message.heightPixels = object.heightPixels ?? 0;
    message.frameRate = object.frameRate ?? 0;
    message.bitrateBps = object.bitrateBps ?? 0;
    message.allowOpenGop = object.allowOpenGop ?? false;
    message.gopFrameCount = object.gopFrameCount ?? undefined;
    message.gopDuration = (object.gopDuration !== undefined && object.gopDuration !== null)
      ? Duration.fromPartial(object.gopDuration)
      : undefined;
    message.vbvSizeBits = object.vbvSizeBits ?? 0;
    message.vbvFullnessBits = object.vbvFullnessBits ?? 0;
    message.entropyCoder = object.entropyCoder ?? "";
    message.bPyramid = object.bPyramid ?? false;
    message.bFrameCount = object.bFrameCount ?? 0;
    message.aqStrength = object.aqStrength ?? 0;
    message.profile = object.profile ?? "";
    message.tune = object.tune ?? "";
    return message;
  },
};

function createBaseAudioStream(): AudioStream {
  return {
    transmux: false,
    codec: "",
    bitrateBps: 0,
    channelCount: 0,
    channelLayout: [],
    mapping: [],
    sampleRateHertz: 0,
  };
}

export const AudioStream: MessageFns<AudioStream> = {
  encode(message: AudioStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transmux !== false) {
      writer.uint32(64).bool(message.transmux);
    }
    if (message.codec !== "") {
      writer.uint32(10).string(message.codec);
    }
    if (message.bitrateBps !== 0) {
      writer.uint32(16).int32(message.bitrateBps);
    }
    if (message.channelCount !== 0) {
      writer.uint32(24).int32(message.channelCount);
    }
    for (const v of message.channelLayout) {
      writer.uint32(34).string(v!);
    }
    for (const v of message.mapping) {
      AudioStream_AudioMapping.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.sampleRateHertz !== 0) {
      writer.uint32(48).int32(message.sampleRateHertz);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AudioStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8:
          if (tag !== 64) {
            break;
          }

          message.transmux = reader.bool();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.codec = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.bitrateBps = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.channelCount = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.channelLayout.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.mapping.push(AudioStream_AudioMapping.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.sampleRateHertz = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioStream {
    return {
      transmux: isSet(object.transmux) ? globalThis.Boolean(object.transmux) : false,
      codec: isSet(object.codec) ? globalThis.String(object.codec) : "",
      bitrateBps: isSet(object.bitrateBps) ? globalThis.Number(object.bitrateBps) : 0,
      channelCount: isSet(object.channelCount) ? globalThis.Number(object.channelCount) : 0,
      channelLayout: globalThis.Array.isArray(object?.channelLayout)
        ? object.channelLayout.map((e: any) => globalThis.String(e))
        : [],
      mapping: globalThis.Array.isArray(object?.mapping)
        ? object.mapping.map((e: any) => AudioStream_AudioMapping.fromJSON(e))
        : [],
      sampleRateHertz: isSet(object.sampleRateHertz) ? globalThis.Number(object.sampleRateHertz) : 0,
    };
  },

  toJSON(message: AudioStream): unknown {
    const obj: any = {};
    if (message.transmux !== false) {
      obj.transmux = message.transmux;
    }
    if (message.codec !== "") {
      obj.codec = message.codec;
    }
    if (message.bitrateBps !== 0) {
      obj.bitrateBps = Math.round(message.bitrateBps);
    }
    if (message.channelCount !== 0) {
      obj.channelCount = Math.round(message.channelCount);
    }
    if (message.channelLayout?.length) {
      obj.channelLayout = message.channelLayout;
    }
    if (message.mapping?.length) {
      obj.mapping = message.mapping.map((e) => AudioStream_AudioMapping.toJSON(e));
    }
    if (message.sampleRateHertz !== 0) {
      obj.sampleRateHertz = Math.round(message.sampleRateHertz);
    }
    return obj;
  },

  create(base?: DeepPartial<AudioStream>): AudioStream {
    return AudioStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AudioStream>): AudioStream {
    const message = createBaseAudioStream();
    message.transmux = object.transmux ?? false;
    message.codec = object.codec ?? "";
    message.bitrateBps = object.bitrateBps ?? 0;
    message.channelCount = object.channelCount ?? 0;
    message.channelLayout = object.channelLayout?.map((e) => e) || [];
    message.mapping = object.mapping?.map((e) => AudioStream_AudioMapping.fromPartial(e)) || [];
    message.sampleRateHertz = object.sampleRateHertz ?? 0;
    return message;
  },
};

function createBaseAudioStream_AudioMapping(): AudioStream_AudioMapping {
  return { inputKey: "", inputTrack: 0, inputChannel: 0, outputChannel: 0, gainDb: 0 };
}

export const AudioStream_AudioMapping: MessageFns<AudioStream_AudioMapping> = {
  encode(message: AudioStream_AudioMapping, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.inputKey !== "") {
      writer.uint32(50).string(message.inputKey);
    }
    if (message.inputTrack !== 0) {
      writer.uint32(16).int32(message.inputTrack);
    }
    if (message.inputChannel !== 0) {
      writer.uint32(24).int32(message.inputChannel);
    }
    if (message.outputChannel !== 0) {
      writer.uint32(32).int32(message.outputChannel);
    }
    if (message.gainDb !== 0) {
      writer.uint32(41).double(message.gainDb);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AudioStream_AudioMapping {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioStream_AudioMapping();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 50) {
            break;
          }

          message.inputKey = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.inputTrack = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.inputChannel = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.outputChannel = reader.int32();
          continue;
        case 5:
          if (tag !== 41) {
            break;
          }

          message.gainDb = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioStream_AudioMapping {
    return {
      inputKey: isSet(object.inputKey) ? globalThis.String(object.inputKey) : "",
      inputTrack: isSet(object.inputTrack) ? globalThis.Number(object.inputTrack) : 0,
      inputChannel: isSet(object.inputChannel) ? globalThis.Number(object.inputChannel) : 0,
      outputChannel: isSet(object.outputChannel) ? globalThis.Number(object.outputChannel) : 0,
      gainDb: isSet(object.gainDb) ? globalThis.Number(object.gainDb) : 0,
    };
  },

  toJSON(message: AudioStream_AudioMapping): unknown {
    const obj: any = {};
    if (message.inputKey !== "") {
      obj.inputKey = message.inputKey;
    }
    if (message.inputTrack !== 0) {
      obj.inputTrack = Math.round(message.inputTrack);
    }
    if (message.inputChannel !== 0) {
      obj.inputChannel = Math.round(message.inputChannel);
    }
    if (message.outputChannel !== 0) {
      obj.outputChannel = Math.round(message.outputChannel);
    }
    if (message.gainDb !== 0) {
      obj.gainDb = message.gainDb;
    }
    return obj;
  },

  create(base?: DeepPartial<AudioStream_AudioMapping>): AudioStream_AudioMapping {
    return AudioStream_AudioMapping.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AudioStream_AudioMapping>): AudioStream_AudioMapping {
    const message = createBaseAudioStream_AudioMapping();
    message.inputKey = object.inputKey ?? "";
    message.inputTrack = object.inputTrack ?? 0;
    message.inputChannel = object.inputChannel ?? 0;
    message.outputChannel = object.outputChannel ?? 0;
    message.gainDb = object.gainDb ?? 0;
    return message;
  },
};

function createBaseTextStream(): TextStream {
  return { codec: "" };
}

export const TextStream: MessageFns<TextStream> = {
  encode(message: TextStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.codec !== "") {
      writer.uint32(10).string(message.codec);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.codec = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextStream {
    return { codec: isSet(object.codec) ? globalThis.String(object.codec) : "" };
  },

  toJSON(message: TextStream): unknown {
    const obj: any = {};
    if (message.codec !== "") {
      obj.codec = message.codec;
    }
    return obj;
  },

  create(base?: DeepPartial<TextStream>): TextStream {
    return TextStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextStream>): TextStream {
    const message = createBaseTextStream();
    message.codec = object.codec ?? "";
    return message;
  },
};

function createBaseSegmentSettings(): SegmentSettings {
  return { segmentDuration: undefined };
}

export const SegmentSettings: MessageFns<SegmentSettings> = {
  encode(message: SegmentSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.segmentDuration !== undefined) {
      Duration.encode(message.segmentDuration, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SegmentSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSegmentSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.segmentDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SegmentSettings {
    return { segmentDuration: isSet(object.segmentDuration) ? Duration.fromJSON(object.segmentDuration) : undefined };
  },

  toJSON(message: SegmentSettings): unknown {
    const obj: any = {};
    if (message.segmentDuration !== undefined) {
      obj.segmentDuration = Duration.toJSON(message.segmentDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<SegmentSettings>): SegmentSettings {
    return SegmentSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SegmentSettings>): SegmentSettings {
    const message = createBaseSegmentSettings();
    message.segmentDuration = (object.segmentDuration !== undefined && object.segmentDuration !== null)
      ? Duration.fromPartial(object.segmentDuration)
      : undefined;
    return message;
  },
};

function createBaseTimecodeConfig(): TimecodeConfig {
  return { source: 0, utcOffset: undefined, timeZone: undefined };
}

export const TimecodeConfig: MessageFns<TimecodeConfig> = {
  encode(message: TimecodeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.source !== 0) {
      writer.uint32(8).int32(message.source);
    }
    if (message.utcOffset !== undefined) {
      Duration.encode(message.utcOffset, writer.uint32(18).fork()).join();
    }
    if (message.timeZone !== undefined) {
      TimeZone.encode(message.timeZone, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TimecodeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTimecodeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.source = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.utcOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timeZone = TimeZone.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TimecodeConfig {
    return {
      source: isSet(object.source) ? timecodeConfig_TimecodeSourceFromJSON(object.source) : 0,
      utcOffset: isSet(object.utcOffset) ? Duration.fromJSON(object.utcOffset) : undefined,
      timeZone: isSet(object.timeZone) ? TimeZone.fromJSON(object.timeZone) : undefined,
    };
  },

  toJSON(message: TimecodeConfig): unknown {
    const obj: any = {};
    if (message.source !== 0) {
      obj.source = timecodeConfig_TimecodeSourceToJSON(message.source);
    }
    if (message.utcOffset !== undefined) {
      obj.utcOffset = Duration.toJSON(message.utcOffset);
    }
    if (message.timeZone !== undefined) {
      obj.timeZone = TimeZone.toJSON(message.timeZone);
    }
    return obj;
  },

  create(base?: DeepPartial<TimecodeConfig>): TimecodeConfig {
    return TimecodeConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TimecodeConfig>): TimecodeConfig {
    const message = createBaseTimecodeConfig();
    message.source = object.source ?? 0;
    message.utcOffset = (object.utcOffset !== undefined && object.utcOffset !== null)
      ? Duration.fromPartial(object.utcOffset)
      : undefined;
    message.timeZone = (object.timeZone !== undefined && object.timeZone !== null)
      ? TimeZone.fromPartial(object.timeZone)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
