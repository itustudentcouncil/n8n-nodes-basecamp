// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/clouddms/v1/clouddms_resources.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { BoolValue, Int64Value } from "../../../protobuf/wrappers.js";
import { Status } from "../../../rpc/status.js";

export const protobufPackage = "google.cloud.clouddms.v1";

export enum NetworkArchitecture {
  NETWORK_ARCHITECTURE_UNSPECIFIED = 0,
  /** NETWORK_ARCHITECTURE_OLD_CSQL_PRODUCER - Instance is in Cloud SQL's old producer network architecture. */
  NETWORK_ARCHITECTURE_OLD_CSQL_PRODUCER = 1,
  /** NETWORK_ARCHITECTURE_NEW_CSQL_PRODUCER - Instance is in Cloud SQL's new producer network architecture. */
  NETWORK_ARCHITECTURE_NEW_CSQL_PRODUCER = 2,
  UNRECOGNIZED = -1,
}

export function networkArchitectureFromJSON(object: any): NetworkArchitecture {
  switch (object) {
    case 0:
    case "NETWORK_ARCHITECTURE_UNSPECIFIED":
      return NetworkArchitecture.NETWORK_ARCHITECTURE_UNSPECIFIED;
    case 1:
    case "NETWORK_ARCHITECTURE_OLD_CSQL_PRODUCER":
      return NetworkArchitecture.NETWORK_ARCHITECTURE_OLD_CSQL_PRODUCER;
    case 2:
    case "NETWORK_ARCHITECTURE_NEW_CSQL_PRODUCER":
      return NetworkArchitecture.NETWORK_ARCHITECTURE_NEW_CSQL_PRODUCER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return NetworkArchitecture.UNRECOGNIZED;
  }
}

export function networkArchitectureToJSON(object: NetworkArchitecture): string {
  switch (object) {
    case NetworkArchitecture.NETWORK_ARCHITECTURE_UNSPECIFIED:
      return "NETWORK_ARCHITECTURE_UNSPECIFIED";
    case NetworkArchitecture.NETWORK_ARCHITECTURE_OLD_CSQL_PRODUCER:
      return "NETWORK_ARCHITECTURE_OLD_CSQL_PRODUCER";
    case NetworkArchitecture.NETWORK_ARCHITECTURE_NEW_CSQL_PRODUCER:
      return "NETWORK_ARCHITECTURE_NEW_CSQL_PRODUCER";
    case NetworkArchitecture.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The database engine types. */
export enum DatabaseEngine {
  /** DATABASE_ENGINE_UNSPECIFIED - The source database engine of the migration job is unknown. */
  DATABASE_ENGINE_UNSPECIFIED = 0,
  /** MYSQL - The source engine is MySQL. */
  MYSQL = 1,
  /** POSTGRESQL - The source engine is PostgreSQL. */
  POSTGRESQL = 2,
  /** ORACLE - The source engine is Oracle. */
  ORACLE = 4,
  UNRECOGNIZED = -1,
}

export function databaseEngineFromJSON(object: any): DatabaseEngine {
  switch (object) {
    case 0:
    case "DATABASE_ENGINE_UNSPECIFIED":
      return DatabaseEngine.DATABASE_ENGINE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return DatabaseEngine.MYSQL;
    case 2:
    case "POSTGRESQL":
      return DatabaseEngine.POSTGRESQL;
    case 4:
    case "ORACLE":
      return DatabaseEngine.ORACLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseEngine.UNRECOGNIZED;
  }
}

export function databaseEngineToJSON(object: DatabaseEngine): string {
  switch (object) {
    case DatabaseEngine.DATABASE_ENGINE_UNSPECIFIED:
      return "DATABASE_ENGINE_UNSPECIFIED";
    case DatabaseEngine.MYSQL:
      return "MYSQL";
    case DatabaseEngine.POSTGRESQL:
      return "POSTGRESQL";
    case DatabaseEngine.ORACLE:
      return "ORACLE";
    case DatabaseEngine.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The database providers. */
export enum DatabaseProvider {
  /** DATABASE_PROVIDER_UNSPECIFIED - The database provider is unknown. */
  DATABASE_PROVIDER_UNSPECIFIED = 0,
  /** CLOUDSQL - CloudSQL runs the database. */
  CLOUDSQL = 1,
  /** RDS - RDS runs the database. */
  RDS = 2,
  /** AURORA - Amazon Aurora. */
  AURORA = 3,
  /** ALLOYDB - AlloyDB. */
  ALLOYDB = 4,
  UNRECOGNIZED = -1,
}

export function databaseProviderFromJSON(object: any): DatabaseProvider {
  switch (object) {
    case 0:
    case "DATABASE_PROVIDER_UNSPECIFIED":
      return DatabaseProvider.DATABASE_PROVIDER_UNSPECIFIED;
    case 1:
    case "CLOUDSQL":
      return DatabaseProvider.CLOUDSQL;
    case 2:
    case "RDS":
      return DatabaseProvider.RDS;
    case 3:
    case "AURORA":
      return DatabaseProvider.AURORA;
    case 4:
    case "ALLOYDB":
      return DatabaseProvider.ALLOYDB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseProvider.UNRECOGNIZED;
  }
}

export function databaseProviderToJSON(object: DatabaseProvider): string {
  switch (object) {
    case DatabaseProvider.DATABASE_PROVIDER_UNSPECIFIED:
      return "DATABASE_PROVIDER_UNSPECIFIED";
    case DatabaseProvider.CLOUDSQL:
      return "CLOUDSQL";
    case DatabaseProvider.RDS:
      return "RDS";
    case DatabaseProvider.AURORA:
      return "AURORA";
    case DatabaseProvider.ALLOYDB:
      return "ALLOYDB";
    case DatabaseProvider.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** SSL configuration information. */
export interface SslConfig {
  /**
   * Output only. The ssl config type according to 'client_key',
   * 'client_certificate' and 'ca_certificate'.
   */
  type: SslConfig_SslType;
  /**
   * Input only. The unencrypted PKCS#1 or PKCS#8 PEM-encoded private key
   * associated with the Client Certificate. If this field is used then the
   * 'client_certificate' field is mandatory.
   */
  clientKey: string;
  /**
   * Input only. The x509 PEM-encoded certificate that will be used by the
   * replica to authenticate against the source database server.If this field is
   * used then the 'client_key' field is mandatory.
   */
  clientCertificate: string;
  /**
   * Required. Input only. The x509 PEM-encoded certificate of the CA that
   * signed the source database server's certificate. The replica will use this
   * certificate to verify it's connecting to the right host.
   */
  caCertificate: string;
}

/** Specifies The kind of ssl configuration used. */
export enum SslConfig_SslType {
  /** SSL_TYPE_UNSPECIFIED - Unspecified. */
  SSL_TYPE_UNSPECIFIED = 0,
  /** SERVER_ONLY - Only 'ca_certificate' specified. */
  SERVER_ONLY = 1,
  /**
   * SERVER_CLIENT - Both server ('ca_certificate'), and client ('client_key',
   * 'client_certificate') specified.
   */
  SERVER_CLIENT = 2,
  UNRECOGNIZED = -1,
}

export function sslConfig_SslTypeFromJSON(object: any): SslConfig_SslType {
  switch (object) {
    case 0:
    case "SSL_TYPE_UNSPECIFIED":
      return SslConfig_SslType.SSL_TYPE_UNSPECIFIED;
    case 1:
    case "SERVER_ONLY":
      return SslConfig_SslType.SERVER_ONLY;
    case 2:
    case "SERVER_CLIENT":
      return SslConfig_SslType.SERVER_CLIENT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SslConfig_SslType.UNRECOGNIZED;
  }
}

export function sslConfig_SslTypeToJSON(object: SslConfig_SslType): string {
  switch (object) {
    case SslConfig_SslType.SSL_TYPE_UNSPECIFIED:
      return "SSL_TYPE_UNSPECIFIED";
    case SslConfig_SslType.SERVER_ONLY:
      return "SERVER_ONLY";
    case SslConfig_SslType.SERVER_CLIENT:
      return "SERVER_CLIENT";
    case SslConfig_SslType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Specifies connection parameters required specifically for MySQL databases. */
export interface MySqlConnectionProfile {
  /** Required. The IP or hostname of the source MySQL database. */
  host: string;
  /** Required. The network port of the source MySQL database. */
  port: number;
  /**
   * Required. The username that Database Migration Service will use to connect
   * to the database. The value is encrypted when stored in Database Migration
   * Service.
   */
  username: string;
  /**
   * Required. Input only. The password for the user that Database Migration
   * Service will be using to connect to the database. This field is not
   * returned on request, and the value is encrypted when stored in Database
   * Migration Service.
   */
  password: string;
  /** Output only. Indicates If this connection profile password is stored. */
  passwordSet: boolean;
  /** SSL configuration for the destination to connect to the source database. */
  ssl:
    | SslConfig
    | undefined;
  /**
   * If the source is a Cloud SQL database, use this field to
   * provide the Cloud SQL instance ID of the source.
   */
  cloudSqlId: string;
}

/**
 * Specifies connection parameters required specifically for PostgreSQL
 * databases.
 */
export interface PostgreSqlConnectionProfile {
  /** Required. The IP or hostname of the source PostgreSQL database. */
  host: string;
  /** Required. The network port of the source PostgreSQL database. */
  port: number;
  /**
   * Required. The username that Database Migration Service will use to connect
   * to the database. The value is encrypted when stored in Database Migration
   * Service.
   */
  username: string;
  /**
   * Required. Input only. The password for the user that Database Migration
   * Service will be using to connect to the database. This field is not
   * returned on request, and the value is encrypted when stored in Database
   * Migration Service.
   */
  password: string;
  /** Output only. Indicates If this connection profile password is stored. */
  passwordSet: boolean;
  /** SSL configuration for the destination to connect to the source database. */
  ssl:
    | SslConfig
    | undefined;
  /**
   * If the source is a Cloud SQL database, use this field to
   * provide the Cloud SQL instance ID of the source.
   */
  cloudSqlId: string;
  /**
   * Output only. If the source is a Cloud SQL database, this field indicates
   * the network architecture it's associated with.
   */
  networkArchitecture: NetworkArchitecture;
  /** Static ip connectivity data (default, no additional details needed). */
  staticIpConnectivity?:
    | StaticIpConnectivity
    | undefined;
  /** Private service connect connectivity. */
  privateServiceConnectConnectivity?: PrivateServiceConnectConnectivity | undefined;
}

/**
 * Specifies connection parameters required specifically for Oracle
 * databases.
 */
export interface OracleConnectionProfile {
  /** Required. The IP or hostname of the source Oracle database. */
  host: string;
  /** Required. The network port of the source Oracle database. */
  port: number;
  /**
   * Required. The username that Database Migration Service will use to connect
   * to the database. The value is encrypted when stored in Database Migration
   * Service.
   */
  username: string;
  /**
   * Required. Input only. The password for the user that Database Migration
   * Service will be using to connect to the database. This field is not
   * returned on request, and the value is encrypted when stored in Database
   * Migration Service.
   */
  password: string;
  /** Output only. Indicates whether a new password is included in the request. */
  passwordSet: boolean;
  /** Required. Database service for the Oracle connection. */
  databaseService: string;
  /**
   * SSL configuration for the connection to the source Oracle database.
   *
   *  * Only `SERVER_ONLY` configuration is supported for Oracle SSL.
   *  * SSL is supported for Oracle versions 12 and above.
   */
  ssl:
    | SslConfig
    | undefined;
  /** Static Service IP connectivity. */
  staticServiceIpConnectivity?:
    | StaticServiceIpConnectivity
    | undefined;
  /** Forward SSH tunnel connectivity. */
  forwardSshConnectivity?:
    | ForwardSshTunnelConnectivity
    | undefined;
  /** Private connectivity. */
  privateConnectivity?: PrivateConnectivity | undefined;
}

/**
 * Specifies required connection parameters, and, optionally, the parameters
 * required to create a Cloud SQL destination database instance.
 */
export interface CloudSqlConnectionProfile {
  /**
   * Output only. The Cloud SQL instance ID that this connection profile is
   * associated with.
   */
  cloudSqlId: string;
  /** Immutable. Metadata used to create the destination Cloud SQL database. */
  settings:
    | CloudSqlSettings
    | undefined;
  /** Output only. The Cloud SQL database instance's private IP. */
  privateIp: string;
  /** Output only. The Cloud SQL database instance's public IP. */
  publicIp: string;
  /**
   * Output only. The Cloud SQL database instance's additional (outgoing) public
   * IP. Used when the Cloud SQL database availability type is REGIONAL (i.e.
   * multiple zones / highly available).
   */
  additionalPublicIp: string;
}

/**
 * Specifies required connection parameters, and the parameters
 * required to create an AlloyDB destination cluster.
 */
export interface AlloyDbConnectionProfile {
  /**
   * Required. The AlloyDB cluster ID that this connection profile is associated
   * with.
   */
  clusterId: string;
  /** Immutable. Metadata used to create the destination AlloyDB cluster. */
  settings: AlloyDbSettings | undefined;
}

/** An entry for an Access Control list. */
export interface SqlAclEntry {
  /** The allowlisted value for the access control list. */
  value: string;
  /**
   * The time when this access control entry expires in
   * [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example:
   * `2012-11-15T16:19:00.094Z`.
   */
  expireTime?:
    | Date
    | undefined;
  /** Input only. The time-to-leave of this access control entry. */
  ttl?:
    | Duration
    | undefined;
  /** A label to identify this entry. */
  label: string;
}

/** IP Management configuration. */
export interface SqlIpConfig {
  /** Whether the instance should be assigned an IPv4 address or not. */
  enableIpv4:
    | boolean
    | undefined;
  /**
   * The resource link for the VPC network from which the Cloud SQL instance is
   * accessible for private IP. For example,
   * `projects/myProject/global/networks/default`. This setting can
   * be updated, but it cannot be removed after it is set.
   */
  privateNetwork: string;
  /**
   * Optional. The name of the allocated IP address range for the private IP
   * Cloud SQL instance. This name refers to an already allocated IP range
   * address. If set, the instance IP address will be created in the allocated
   * range. Note that this IP address range can't be modified after the instance
   * is created. If you change the VPC when configuring connectivity settings
   * for the migration job, this field is not relevant.
   */
  allocatedIpRange: string;
  /** Whether SSL connections over IP should be enforced or not. */
  requireSsl:
    | boolean
    | undefined;
  /**
   * The list of external networks that are allowed to connect to the instance
   * using the IP. See
   * https://en.wikipedia.org/wiki/CIDR_notation#CIDR_notation, also known as
   * 'slash' notation (e.g. `192.168.100.0/24`).
   */
  authorizedNetworks: SqlAclEntry[];
}

/** Settings for creating a Cloud SQL database instance. */
export interface CloudSqlSettings {
  /** The database engine type and version. */
  databaseVersion: CloudSqlSettings_SqlDatabaseVersion;
  /**
   * The resource labels for a Cloud SQL instance to use to annotate any related
   * underlying resources such as Compute Engine VMs.
   * An object containing a list of "key": "value" pairs.
   *
   * Example: `{ "name": "wrench", "mass": "18kg", "count": "3" }`.
   */
  userLabels: { [key: string]: string };
  /**
   * The tier (or machine type) for this instance, for example:
   * `db-n1-standard-1` (MySQL instances) or
   * `db-custom-1-3840` (PostgreSQL instances).
   * For more information, see
   * [Cloud SQL Instance
   * Settings](https://cloud.google.com/sql/docs/mysql/instance-settings).
   */
  tier: string;
  /**
   * The maximum size to which storage capacity can be automatically increased.
   * The default value is 0, which specifies that there is no limit.
   */
  storageAutoResizeLimit:
    | Long
    | undefined;
  /**
   * The activation policy specifies when the instance is activated; it is
   * applicable only when the instance state is 'RUNNABLE'. Valid values:
   *
   * 'ALWAYS': The instance is on, and remains so even in
   * the absence of connection requests.
   *
   * `NEVER`: The instance is off; it is not activated, even if a
   * connection request arrives.
   */
  activationPolicy: CloudSqlSettings_SqlActivationPolicy;
  /**
   * The settings for IP Management. This allows to enable or disable the
   * instance IP and manage which external networks can connect to the instance.
   * The IPv4 address cannot be disabled.
   */
  ipConfig:
    | SqlIpConfig
    | undefined;
  /**
   * [default: ON] If you enable this setting, Cloud SQL checks your available
   * storage every 30 seconds. If the available storage falls below a threshold
   * size, Cloud SQL automatically adds additional storage capacity. If the
   * available storage repeatedly falls below the threshold size, Cloud SQL
   * continues to add storage until it reaches the maximum of 30 TB.
   */
  autoStorageIncrease:
    | boolean
    | undefined;
  /**
   * The database flags passed to the Cloud SQL instance at startup.
   * An object containing a list of "key": value pairs.
   * Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
   */
  databaseFlags: { [key: string]: string };
  /** The type of storage: `PD_SSD` (default) or `PD_HDD`. */
  dataDiskType: CloudSqlSettings_SqlDataDiskType;
  /**
   * The storage capacity available to the database, in GB.
   * The minimum (and default) size is 10GB.
   */
  dataDiskSizeGb:
    | Long
    | undefined;
  /**
   * The Google Cloud Platform zone where your Cloud SQL database instance is
   * located.
   */
  zone: string;
  /**
   * Optional. The Google Cloud Platform zone where the failover Cloud SQL
   * database instance is located. Used when the Cloud SQL database availability
   * type is REGIONAL (i.e. multiple zones / highly available).
   */
  secondaryZone: string;
  /**
   * The Database Migration Service source connection profile ID,
   * in the format:
   * `projects/my_project_name/locations/us-central1/connectionProfiles/connection_profile_ID`
   */
  sourceId: string;
  /** Input only. Initial root password. */
  rootPassword: string;
  /** Output only. Indicates If this connection profile root password is stored. */
  rootPasswordSet: boolean;
  /** The Cloud SQL default instance level collation. */
  collation: string;
  /** The KMS key name used for the csql instance. */
  cmekKeyName: string;
  /**
   * Optional. Availability type. Potential values:
   * *  `ZONAL`: The instance serves data from only one zone. Outages in that
   * zone affect data availability.
   * *  `REGIONAL`: The instance can serve data from more than one zone in a
   * region (it is highly available).
   */
  availabilityType: CloudSqlSettings_SqlAvailabilityType;
  /** Optional. The edition of the given Cloud SQL instance. */
  edition: CloudSqlSettings_Edition;
}

/** Specifies when the instance should be activated. */
export enum CloudSqlSettings_SqlActivationPolicy {
  /** SQL_ACTIVATION_POLICY_UNSPECIFIED - unspecified policy. */
  SQL_ACTIVATION_POLICY_UNSPECIFIED = 0,
  /** ALWAYS - The instance is always up and running. */
  ALWAYS = 1,
  /** NEVER - The instance should never spin up. */
  NEVER = 2,
  UNRECOGNIZED = -1,
}

export function cloudSqlSettings_SqlActivationPolicyFromJSON(object: any): CloudSqlSettings_SqlActivationPolicy {
  switch (object) {
    case 0:
    case "SQL_ACTIVATION_POLICY_UNSPECIFIED":
      return CloudSqlSettings_SqlActivationPolicy.SQL_ACTIVATION_POLICY_UNSPECIFIED;
    case 1:
    case "ALWAYS":
      return CloudSqlSettings_SqlActivationPolicy.ALWAYS;
    case 2:
    case "NEVER":
      return CloudSqlSettings_SqlActivationPolicy.NEVER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudSqlSettings_SqlActivationPolicy.UNRECOGNIZED;
  }
}

export function cloudSqlSettings_SqlActivationPolicyToJSON(object: CloudSqlSettings_SqlActivationPolicy): string {
  switch (object) {
    case CloudSqlSettings_SqlActivationPolicy.SQL_ACTIVATION_POLICY_UNSPECIFIED:
      return "SQL_ACTIVATION_POLICY_UNSPECIFIED";
    case CloudSqlSettings_SqlActivationPolicy.ALWAYS:
      return "ALWAYS";
    case CloudSqlSettings_SqlActivationPolicy.NEVER:
      return "NEVER";
    case CloudSqlSettings_SqlActivationPolicy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The storage options for Cloud SQL databases. */
export enum CloudSqlSettings_SqlDataDiskType {
  /** SQL_DATA_DISK_TYPE_UNSPECIFIED - Unspecified. */
  SQL_DATA_DISK_TYPE_UNSPECIFIED = 0,
  /** PD_SSD - SSD disk. */
  PD_SSD = 1,
  /** PD_HDD - HDD disk. */
  PD_HDD = 2,
  UNRECOGNIZED = -1,
}

export function cloudSqlSettings_SqlDataDiskTypeFromJSON(object: any): CloudSqlSettings_SqlDataDiskType {
  switch (object) {
    case 0:
    case "SQL_DATA_DISK_TYPE_UNSPECIFIED":
      return CloudSqlSettings_SqlDataDiskType.SQL_DATA_DISK_TYPE_UNSPECIFIED;
    case 1:
    case "PD_SSD":
      return CloudSqlSettings_SqlDataDiskType.PD_SSD;
    case 2:
    case "PD_HDD":
      return CloudSqlSettings_SqlDataDiskType.PD_HDD;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudSqlSettings_SqlDataDiskType.UNRECOGNIZED;
  }
}

export function cloudSqlSettings_SqlDataDiskTypeToJSON(object: CloudSqlSettings_SqlDataDiskType): string {
  switch (object) {
    case CloudSqlSettings_SqlDataDiskType.SQL_DATA_DISK_TYPE_UNSPECIFIED:
      return "SQL_DATA_DISK_TYPE_UNSPECIFIED";
    case CloudSqlSettings_SqlDataDiskType.PD_SSD:
      return "PD_SSD";
    case CloudSqlSettings_SqlDataDiskType.PD_HDD:
      return "PD_HDD";
    case CloudSqlSettings_SqlDataDiskType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The database engine type and version. */
export enum CloudSqlSettings_SqlDatabaseVersion {
  /** SQL_DATABASE_VERSION_UNSPECIFIED - Unspecified version. */
  SQL_DATABASE_VERSION_UNSPECIFIED = 0,
  /** MYSQL_5_6 - MySQL 5.6. */
  MYSQL_5_6 = 1,
  /** MYSQL_5_7 - MySQL 5.7. */
  MYSQL_5_7 = 2,
  /** POSTGRES_9_6 - PostgreSQL 9.6. */
  POSTGRES_9_6 = 3,
  /** POSTGRES_11 - PostgreSQL 11. */
  POSTGRES_11 = 4,
  /** POSTGRES_10 - PostgreSQL 10. */
  POSTGRES_10 = 5,
  /** MYSQL_8_0 - MySQL 8.0. */
  MYSQL_8_0 = 6,
  /** POSTGRES_12 - PostgreSQL 12. */
  POSTGRES_12 = 7,
  /** POSTGRES_13 - PostgreSQL 13. */
  POSTGRES_13 = 8,
  /** POSTGRES_14 - PostgreSQL 14. */
  POSTGRES_14 = 17,
  /** POSTGRES_15 - PostgreSQL 15. */
  POSTGRES_15 = 18,
  UNRECOGNIZED = -1,
}

export function cloudSqlSettings_SqlDatabaseVersionFromJSON(object: any): CloudSqlSettings_SqlDatabaseVersion {
  switch (object) {
    case 0:
    case "SQL_DATABASE_VERSION_UNSPECIFIED":
      return CloudSqlSettings_SqlDatabaseVersion.SQL_DATABASE_VERSION_UNSPECIFIED;
    case 1:
    case "MYSQL_5_6":
      return CloudSqlSettings_SqlDatabaseVersion.MYSQL_5_6;
    case 2:
    case "MYSQL_5_7":
      return CloudSqlSettings_SqlDatabaseVersion.MYSQL_5_7;
    case 3:
    case "POSTGRES_9_6":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_9_6;
    case 4:
    case "POSTGRES_11":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_11;
    case 5:
    case "POSTGRES_10":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_10;
    case 6:
    case "MYSQL_8_0":
      return CloudSqlSettings_SqlDatabaseVersion.MYSQL_8_0;
    case 7:
    case "POSTGRES_12":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_12;
    case 8:
    case "POSTGRES_13":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_13;
    case 17:
    case "POSTGRES_14":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_14;
    case 18:
    case "POSTGRES_15":
      return CloudSqlSettings_SqlDatabaseVersion.POSTGRES_15;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudSqlSettings_SqlDatabaseVersion.UNRECOGNIZED;
  }
}

export function cloudSqlSettings_SqlDatabaseVersionToJSON(object: CloudSqlSettings_SqlDatabaseVersion): string {
  switch (object) {
    case CloudSqlSettings_SqlDatabaseVersion.SQL_DATABASE_VERSION_UNSPECIFIED:
      return "SQL_DATABASE_VERSION_UNSPECIFIED";
    case CloudSqlSettings_SqlDatabaseVersion.MYSQL_5_6:
      return "MYSQL_5_6";
    case CloudSqlSettings_SqlDatabaseVersion.MYSQL_5_7:
      return "MYSQL_5_7";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_9_6:
      return "POSTGRES_9_6";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_11:
      return "POSTGRES_11";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_10:
      return "POSTGRES_10";
    case CloudSqlSettings_SqlDatabaseVersion.MYSQL_8_0:
      return "MYSQL_8_0";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_12:
      return "POSTGRES_12";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_13:
      return "POSTGRES_13";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_14:
      return "POSTGRES_14";
    case CloudSqlSettings_SqlDatabaseVersion.POSTGRES_15:
      return "POSTGRES_15";
    case CloudSqlSettings_SqlDatabaseVersion.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The availability type of the given Cloud SQL instance. */
export enum CloudSqlSettings_SqlAvailabilityType {
  /** SQL_AVAILABILITY_TYPE_UNSPECIFIED - This is an unknown Availability type. */
  SQL_AVAILABILITY_TYPE_UNSPECIFIED = 0,
  /** ZONAL - Zonal availablility instance. */
  ZONAL = 1,
  /** REGIONAL - Regional availability instance. */
  REGIONAL = 2,
  UNRECOGNIZED = -1,
}

export function cloudSqlSettings_SqlAvailabilityTypeFromJSON(object: any): CloudSqlSettings_SqlAvailabilityType {
  switch (object) {
    case 0:
    case "SQL_AVAILABILITY_TYPE_UNSPECIFIED":
      return CloudSqlSettings_SqlAvailabilityType.SQL_AVAILABILITY_TYPE_UNSPECIFIED;
    case 1:
    case "ZONAL":
      return CloudSqlSettings_SqlAvailabilityType.ZONAL;
    case 2:
    case "REGIONAL":
      return CloudSqlSettings_SqlAvailabilityType.REGIONAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudSqlSettings_SqlAvailabilityType.UNRECOGNIZED;
  }
}

export function cloudSqlSettings_SqlAvailabilityTypeToJSON(object: CloudSqlSettings_SqlAvailabilityType): string {
  switch (object) {
    case CloudSqlSettings_SqlAvailabilityType.SQL_AVAILABILITY_TYPE_UNSPECIFIED:
      return "SQL_AVAILABILITY_TYPE_UNSPECIFIED";
    case CloudSqlSettings_SqlAvailabilityType.ZONAL:
      return "ZONAL";
    case CloudSqlSettings_SqlAvailabilityType.REGIONAL:
      return "REGIONAL";
    case CloudSqlSettings_SqlAvailabilityType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The edition of the given Cloud SQL instance.
 * Can be ENTERPRISE or ENTERPRISE_PLUS.
 */
export enum CloudSqlSettings_Edition {
  /** EDITION_UNSPECIFIED - The instance did not specify the edition. */
  EDITION_UNSPECIFIED = 0,
  /** ENTERPRISE - The instance is an enterprise edition. */
  ENTERPRISE = 2,
  /** ENTERPRISE_PLUS - The instance is an enterprise plus edition. */
  ENTERPRISE_PLUS = 3,
  UNRECOGNIZED = -1,
}

export function cloudSqlSettings_EditionFromJSON(object: any): CloudSqlSettings_Edition {
  switch (object) {
    case 0:
    case "EDITION_UNSPECIFIED":
      return CloudSqlSettings_Edition.EDITION_UNSPECIFIED;
    case 2:
    case "ENTERPRISE":
      return CloudSqlSettings_Edition.ENTERPRISE;
    case 3:
    case "ENTERPRISE_PLUS":
      return CloudSqlSettings_Edition.ENTERPRISE_PLUS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloudSqlSettings_Edition.UNRECOGNIZED;
  }
}

export function cloudSqlSettings_EditionToJSON(object: CloudSqlSettings_Edition): string {
  switch (object) {
    case CloudSqlSettings_Edition.EDITION_UNSPECIFIED:
      return "EDITION_UNSPECIFIED";
    case CloudSqlSettings_Edition.ENTERPRISE:
      return "ENTERPRISE";
    case CloudSqlSettings_Edition.ENTERPRISE_PLUS:
      return "ENTERPRISE_PLUS";
    case CloudSqlSettings_Edition.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface CloudSqlSettings_UserLabelsEntry {
  key: string;
  value: string;
}

export interface CloudSqlSettings_DatabaseFlagsEntry {
  key: string;
  value: string;
}

/** Settings for creating an AlloyDB cluster. */
export interface AlloyDbSettings {
  /**
   * Required. Input only. Initial user to setup during cluster creation.
   * Required.
   */
  initialUser:
    | AlloyDbSettings_UserPassword
    | undefined;
  /**
   * Required. The resource link for the VPC network in which cluster resources
   * are created and from which they are accessible via Private IP. The network
   * must belong to the same project as the cluster. It is specified in the
   * form: "projects/{project_number}/global/networks/{network_id}". This is
   * required to create a cluster.
   */
  vpcNetwork: string;
  /**
   * Labels for the AlloyDB cluster created by DMS. An object containing a list
   * of 'key', 'value' pairs.
   */
  labels: { [key: string]: string };
  primaryInstanceSettings:
    | AlloyDbSettings_PrimaryInstanceSettings
    | undefined;
  /**
   * Optional. The encryption config can be specified to encrypt the data disks
   * and other persistent data resources of a cluster with a
   * customer-managed encryption key (CMEK). When this field is not
   * specified, the cluster will then use default encryption scheme to
   * protect the user data.
   */
  encryptionConfig: AlloyDbSettings_EncryptionConfig | undefined;
}

/**
 * The username/password for a database user. Used for specifying initial
 * users at cluster creation time.
 */
export interface AlloyDbSettings_UserPassword {
  /** The database username. */
  user: string;
  /** The initial password for the user. */
  password: string;
  /** Output only. Indicates if the initial_user.password field has been set. */
  passwordSet: boolean;
}

/** Settings for the cluster's primary instance */
export interface AlloyDbSettings_PrimaryInstanceSettings {
  /**
   * Required. The ID of the AlloyDB primary instance. The ID must satisfy the
   * regex expression "[a-z0-9-]+".
   */
  id: string;
  /**
   * Configuration for the machines that host the underlying
   * database engine.
   */
  machineConfig:
    | AlloyDbSettings_PrimaryInstanceSettings_MachineConfig
    | undefined;
  /**
   * Database flags to pass to AlloyDB when DMS is creating the AlloyDB
   * cluster and instances. See the AlloyDB documentation for how these can be
   * used.
   */
  databaseFlags: { [key: string]: string };
  /**
   * Labels for the AlloyDB primary instance created by DMS. An object
   * containing a list of 'key', 'value' pairs.
   */
  labels: { [key: string]: string };
  /**
   * Output only. The private IP address for the Instance.
   * This is the connection endpoint for an end-user application.
   */
  privateIp: string;
}

/** MachineConfig describes the configuration of a machine. */
export interface AlloyDbSettings_PrimaryInstanceSettings_MachineConfig {
  /** The number of CPU's in the VM instance. */
  cpuCount: number;
}

export interface AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry {
  key: string;
  value: string;
}

export interface AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry {
  key: string;
  value: string;
}

/**
 * EncryptionConfig describes the encryption config of a cluster that is
 * encrypted with a CMEK (customer-managed encryption key).
 */
export interface AlloyDbSettings_EncryptionConfig {
  /**
   * The fully-qualified resource name of the KMS key.
   * Each Cloud KMS key is regionalized and has the following format:
   * projects/[PROJECT]/locations/[REGION]/keyRings/[RING]/cryptoKeys/[KEY_NAME]
   */
  kmsKeyName: string;
}

export interface AlloyDbSettings_LabelsEntry {
  key: string;
  value: string;
}

/**
 * The source database will allow incoming connections from the public IP of the
 * destination database. You can retrieve the public IP of the Cloud SQL
 * instance from the Cloud SQL console or using Cloud SQL APIs. No additional
 * configuration is required.
 */
export interface StaticIpConnectivity {
}

/**
 * [Private Service Connect
 * connectivity](https://cloud.google.com/vpc/docs/private-service-connect#service-attachments)
 */
export interface PrivateServiceConnectConnectivity {
  /**
   * Required. A service attachment that exposes a database, and has the
   * following format:
   * projects/{project}/regions/{region}/serviceAttachments/{service_attachment_name}
   */
  serviceAttachment: string;
}

/**
 * The details needed to configure a reverse SSH tunnel between the source and
 * destination databases. These details will be used when calling the
 * generateSshScript method (see
 * https://cloud.google.com/database-migration/docs/reference/rest/v1/projects.locations.migrationJobs/generateSshScript)
 * to produce the script that will help set up the reverse SSH tunnel, and to
 * set up the VPC peering between the Cloud SQL private network and the VPC.
 */
export interface ReverseSshConnectivity {
  /**
   * Required. The IP of the virtual machine (Compute Engine) used as the
   * bastion server for the SSH tunnel.
   */
  vmIp: string;
  /**
   * Required. The forwarding port of the virtual machine (Compute Engine) used
   * as the bastion server for the SSH tunnel.
   */
  vmPort: number;
  /**
   * The name of the virtual machine (Compute Engine) used as the bastion server
   * for the SSH tunnel.
   */
  vm: string;
  /** The name of the VPC to peer with the Cloud SQL private network. */
  vpc: string;
}

/**
 * The details of the VPC where the source database is located in Google Cloud.
 * We will use this information to set up the VPC peering connection between
 * Cloud SQL and this VPC.
 */
export interface VpcPeeringConnectivity {
  /** The name of the VPC network to peer with the Cloud SQL private network. */
  vpc: string;
}

/** Forward SSH Tunnel connectivity. */
export interface ForwardSshTunnelConnectivity {
  /** Required. Hostname for the SSH tunnel. */
  hostname: string;
  /** Required. Username for the SSH tunnel. */
  username: string;
  /** Port for the SSH tunnel, default value is 22. */
  port: number;
  /** Input only. SSH password. */
  password?:
    | string
    | undefined;
  /** Input only. SSH private key. */
  privateKey?: string | undefined;
}

/** Static IP address connectivity configured on service project. */
export interface StaticServiceIpConnectivity {
}

/** Private Connectivity. */
export interface PrivateConnectivity {
  /** Required. The resource name (URI) of the private connection. */
  privateConnection: string;
}

/** A message defining the database engine and provider. */
export interface DatabaseType {
  /** The database provider. */
  provider: DatabaseProvider;
  /** The database engine. */
  engine: DatabaseEngine;
}

/** Represents a Database Migration Service migration job object. */
export interface MigrationJob {
  /**
   * The name (URI) of this migration job resource, in the form of:
   * projects/{project}/locations/{location}/migrationJobs/{migrationJob}.
   */
  name: string;
  /**
   * Output only. The timestamp when the migration job resource was created.
   * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
   * Example: "2014-10-02T15:01:23.045123456Z".
   */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. The timestamp when the migration job resource was last
   * updated. A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
   * Example: "2014-10-02T15:01:23.045123456Z".
   */
  updateTime:
    | Date
    | undefined;
  /**
   * The resource labels for migration job to use to annotate any related
   * underlying resources such as Compute Engine VMs. An object containing a
   * list of "key": "value" pairs.
   *
   * Example: `{ "name": "wrench", "mass": "1.3kg", "count": "3" }`.
   */
  labels: { [key: string]: string };
  /** The migration job display name. */
  displayName: string;
  /** The current migration job state. */
  state: MigrationJob_State;
  /** Output only. The current migration job phase. */
  phase: MigrationJob_Phase;
  /** Required. The migration job type. */
  type: MigrationJob_Type;
  /**
   * The path to the dump file in Google Cloud Storage,
   * in the format: (gs://[BUCKET_NAME]/[OBJECT_NAME]).
   * This field and the "dump_flags" field are mutually exclusive.
   */
  dumpPath: string;
  /**
   * The initial dump flags.
   * This field and the "dump_path" field are mutually exclusive.
   */
  dumpFlags:
    | MigrationJob_DumpFlags
    | undefined;
  /** Required. The resource name (URI) of the source connection profile. */
  source: string;
  /** Required. The resource name (URI) of the destination connection profile. */
  destination: string;
  /**
   * The details needed to communicate to the source over Reverse SSH
   * tunnel connectivity.
   */
  reverseSshConnectivity?:
    | ReverseSshConnectivity
    | undefined;
  /** The details of the VPC network that the source database is located in. */
  vpcPeeringConnectivity?:
    | VpcPeeringConnectivity
    | undefined;
  /** static ip connectivity data (default, no additional details needed). */
  staticIpConnectivity?:
    | StaticIpConnectivity
    | undefined;
  /**
   * Output only. The duration of the migration job (in seconds). A duration in
   * seconds with up to nine fractional digits, terminated by 's'. Example:
   * "3.5s".
   */
  duration:
    | Duration
    | undefined;
  /** Output only. The error details in case of state FAILED. */
  error:
    | Status
    | undefined;
  /** The database engine type and provider of the source. */
  sourceDatabase:
    | DatabaseType
    | undefined;
  /** The database engine type and provider of the destination. */
  destinationDatabase:
    | DatabaseType
    | undefined;
  /**
   * Output only. If the migration job is completed, the time when it was
   * completed.
   */
  endTime:
    | Date
    | undefined;
  /** The conversion workspace used by the migration. */
  conversionWorkspace:
    | ConversionWorkspaceInfo
    | undefined;
  /**
   * This field can be used to select the entities to migrate as part of
   * the migration job. It uses AIP-160 notation to select a subset of the
   * entities configured on the associated conversion-workspace. This field
   * should not be set on migration-jobs that are not associated with a
   * conversion workspace.
   */
  filter: string;
  /**
   * The CMEK (customer-managed encryption key) fully qualified key name used
   * for the migration job.
   * This field supports all migration jobs types except for:
   * * Mysql to Mysql (use the cmek field in the cloudsql connection profile
   * instead).
   * * PostrgeSQL to PostgreSQL (use the cmek field in the cloudsql
   * connection profile instead).
   * * PostgreSQL to AlloyDB (use the kms_key_name field in the alloydb
   * connection profile instead).
   * Each Cloud CMEK key has the following format:
   * projects/[PROJECT]/locations/[REGION]/keyRings/[RING]/cryptoKeys/[KEY_NAME]
   */
  cmekKeyName: string;
  /**
   * Optional. Data dump parallelism settings used by the migration.
   * Currently applicable only for MySQL to Cloud SQL for MySQL migrations only.
   */
  performanceConfig: MigrationJob_PerformanceConfig | undefined;
}

/** The current migration job states. */
export enum MigrationJob_State {
  /** STATE_UNSPECIFIED - The state of the migration job is unknown. */
  STATE_UNSPECIFIED = 0,
  /** MAINTENANCE - The migration job is down for maintenance. */
  MAINTENANCE = 1,
  /** DRAFT - The migration job is in draft mode and no resources are created. */
  DRAFT = 2,
  /** CREATING - The migration job is being created. */
  CREATING = 3,
  /** NOT_STARTED - The migration job is created and not started. */
  NOT_STARTED = 4,
  /** RUNNING - The migration job is running. */
  RUNNING = 5,
  /** FAILED - The migration job failed. */
  FAILED = 6,
  /** COMPLETED - The migration job has been completed. */
  COMPLETED = 7,
  /** DELETING - The migration job is being deleted. */
  DELETING = 8,
  /** STOPPING - The migration job is being stopped. */
  STOPPING = 9,
  /** STOPPED - The migration job is currently stopped. */
  STOPPED = 10,
  /** DELETED - The migration job has been deleted. */
  DELETED = 11,
  /** UPDATING - The migration job is being updated. */
  UPDATING = 12,
  /** STARTING - The migration job is starting. */
  STARTING = 13,
  /** RESTARTING - The migration job is restarting. */
  RESTARTING = 14,
  /** RESUMING - The migration job is resuming. */
  RESUMING = 15,
  UNRECOGNIZED = -1,
}

export function migrationJob_StateFromJSON(object: any): MigrationJob_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MigrationJob_State.STATE_UNSPECIFIED;
    case 1:
    case "MAINTENANCE":
      return MigrationJob_State.MAINTENANCE;
    case 2:
    case "DRAFT":
      return MigrationJob_State.DRAFT;
    case 3:
    case "CREATING":
      return MigrationJob_State.CREATING;
    case 4:
    case "NOT_STARTED":
      return MigrationJob_State.NOT_STARTED;
    case 5:
    case "RUNNING":
      return MigrationJob_State.RUNNING;
    case 6:
    case "FAILED":
      return MigrationJob_State.FAILED;
    case 7:
    case "COMPLETED":
      return MigrationJob_State.COMPLETED;
    case 8:
    case "DELETING":
      return MigrationJob_State.DELETING;
    case 9:
    case "STOPPING":
      return MigrationJob_State.STOPPING;
    case 10:
    case "STOPPED":
      return MigrationJob_State.STOPPED;
    case 11:
    case "DELETED":
      return MigrationJob_State.DELETED;
    case 12:
    case "UPDATING":
      return MigrationJob_State.UPDATING;
    case 13:
    case "STARTING":
      return MigrationJob_State.STARTING;
    case 14:
    case "RESTARTING":
      return MigrationJob_State.RESTARTING;
    case 15:
    case "RESUMING":
      return MigrationJob_State.RESUMING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationJob_State.UNRECOGNIZED;
  }
}

export function migrationJob_StateToJSON(object: MigrationJob_State): string {
  switch (object) {
    case MigrationJob_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MigrationJob_State.MAINTENANCE:
      return "MAINTENANCE";
    case MigrationJob_State.DRAFT:
      return "DRAFT";
    case MigrationJob_State.CREATING:
      return "CREATING";
    case MigrationJob_State.NOT_STARTED:
      return "NOT_STARTED";
    case MigrationJob_State.RUNNING:
      return "RUNNING";
    case MigrationJob_State.FAILED:
      return "FAILED";
    case MigrationJob_State.COMPLETED:
      return "COMPLETED";
    case MigrationJob_State.DELETING:
      return "DELETING";
    case MigrationJob_State.STOPPING:
      return "STOPPING";
    case MigrationJob_State.STOPPED:
      return "STOPPED";
    case MigrationJob_State.DELETED:
      return "DELETED";
    case MigrationJob_State.UPDATING:
      return "UPDATING";
    case MigrationJob_State.STARTING:
      return "STARTING";
    case MigrationJob_State.RESTARTING:
      return "RESTARTING";
    case MigrationJob_State.RESUMING:
      return "RESUMING";
    case MigrationJob_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The current migration job phase. */
export enum MigrationJob_Phase {
  /** PHASE_UNSPECIFIED - The phase of the migration job is unknown. */
  PHASE_UNSPECIFIED = 0,
  /** FULL_DUMP - The migration job is in the full dump phase. */
  FULL_DUMP = 1,
  /** CDC - The migration job is CDC phase. */
  CDC = 2,
  /** PROMOTE_IN_PROGRESS - The migration job is running the promote phase. */
  PROMOTE_IN_PROGRESS = 3,
  /** WAITING_FOR_SOURCE_WRITES_TO_STOP - Only RDS flow - waiting for source writes to stop */
  WAITING_FOR_SOURCE_WRITES_TO_STOP = 4,
  /** PREPARING_THE_DUMP - Only RDS flow - the sources writes stopped, waiting for dump to begin */
  PREPARING_THE_DUMP = 5,
  UNRECOGNIZED = -1,
}

export function migrationJob_PhaseFromJSON(object: any): MigrationJob_Phase {
  switch (object) {
    case 0:
    case "PHASE_UNSPECIFIED":
      return MigrationJob_Phase.PHASE_UNSPECIFIED;
    case 1:
    case "FULL_DUMP":
      return MigrationJob_Phase.FULL_DUMP;
    case 2:
    case "CDC":
      return MigrationJob_Phase.CDC;
    case 3:
    case "PROMOTE_IN_PROGRESS":
      return MigrationJob_Phase.PROMOTE_IN_PROGRESS;
    case 4:
    case "WAITING_FOR_SOURCE_WRITES_TO_STOP":
      return MigrationJob_Phase.WAITING_FOR_SOURCE_WRITES_TO_STOP;
    case 5:
    case "PREPARING_THE_DUMP":
      return MigrationJob_Phase.PREPARING_THE_DUMP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationJob_Phase.UNRECOGNIZED;
  }
}

export function migrationJob_PhaseToJSON(object: MigrationJob_Phase): string {
  switch (object) {
    case MigrationJob_Phase.PHASE_UNSPECIFIED:
      return "PHASE_UNSPECIFIED";
    case MigrationJob_Phase.FULL_DUMP:
      return "FULL_DUMP";
    case MigrationJob_Phase.CDC:
      return "CDC";
    case MigrationJob_Phase.PROMOTE_IN_PROGRESS:
      return "PROMOTE_IN_PROGRESS";
    case MigrationJob_Phase.WAITING_FOR_SOURCE_WRITES_TO_STOP:
      return "WAITING_FOR_SOURCE_WRITES_TO_STOP";
    case MigrationJob_Phase.PREPARING_THE_DUMP:
      return "PREPARING_THE_DUMP";
    case MigrationJob_Phase.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The type of migration job (one-time or continuous). */
export enum MigrationJob_Type {
  /** TYPE_UNSPECIFIED - The type of the migration job is unknown. */
  TYPE_UNSPECIFIED = 0,
  /** ONE_TIME - The migration job is a one time migration. */
  ONE_TIME = 1,
  /** CONTINUOUS - The migration job is a continuous migration. */
  CONTINUOUS = 2,
  UNRECOGNIZED = -1,
}

export function migrationJob_TypeFromJSON(object: any): MigrationJob_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return MigrationJob_Type.TYPE_UNSPECIFIED;
    case 1:
    case "ONE_TIME":
      return MigrationJob_Type.ONE_TIME;
    case 2:
    case "CONTINUOUS":
      return MigrationJob_Type.CONTINUOUS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationJob_Type.UNRECOGNIZED;
  }
}

export function migrationJob_TypeToJSON(object: MigrationJob_Type): string {
  switch (object) {
    case MigrationJob_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case MigrationJob_Type.ONE_TIME:
      return "ONE_TIME";
    case MigrationJob_Type.CONTINUOUS:
      return "CONTINUOUS";
    case MigrationJob_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Dump flag definition. */
export interface MigrationJob_DumpFlag {
  /** The name of the flag */
  name: string;
  /** The value of the flag. */
  value: string;
}

/** Dump flags definition. */
export interface MigrationJob_DumpFlags {
  /** The flags for the initial dump. */
  dumpFlags: MigrationJob_DumpFlag[];
}

/** Performance configuration definition. */
export interface MigrationJob_PerformanceConfig {
  /** Initial dump parallelism level. */
  dumpParallelLevel: MigrationJob_PerformanceConfig_DumpParallelLevel;
}

/** Describes the parallelism level during initial dump. */
export enum MigrationJob_PerformanceConfig_DumpParallelLevel {
  /** DUMP_PARALLEL_LEVEL_UNSPECIFIED - Unknown dump parallel level. Will be defaulted to OPTIMAL. */
  DUMP_PARALLEL_LEVEL_UNSPECIFIED = 0,
  /** MIN - Minimal parallel level. */
  MIN = 1,
  /** OPTIMAL - Optimal parallel level. */
  OPTIMAL = 2,
  /** MAX - Maximum parallel level. */
  MAX = 3,
  UNRECOGNIZED = -1,
}

export function migrationJob_PerformanceConfig_DumpParallelLevelFromJSON(
  object: any,
): MigrationJob_PerformanceConfig_DumpParallelLevel {
  switch (object) {
    case 0:
    case "DUMP_PARALLEL_LEVEL_UNSPECIFIED":
      return MigrationJob_PerformanceConfig_DumpParallelLevel.DUMP_PARALLEL_LEVEL_UNSPECIFIED;
    case 1:
    case "MIN":
      return MigrationJob_PerformanceConfig_DumpParallelLevel.MIN;
    case 2:
    case "OPTIMAL":
      return MigrationJob_PerformanceConfig_DumpParallelLevel.OPTIMAL;
    case 3:
    case "MAX":
      return MigrationJob_PerformanceConfig_DumpParallelLevel.MAX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationJob_PerformanceConfig_DumpParallelLevel.UNRECOGNIZED;
  }
}

export function migrationJob_PerformanceConfig_DumpParallelLevelToJSON(
  object: MigrationJob_PerformanceConfig_DumpParallelLevel,
): string {
  switch (object) {
    case MigrationJob_PerformanceConfig_DumpParallelLevel.DUMP_PARALLEL_LEVEL_UNSPECIFIED:
      return "DUMP_PARALLEL_LEVEL_UNSPECIFIED";
    case MigrationJob_PerformanceConfig_DumpParallelLevel.MIN:
      return "MIN";
    case MigrationJob_PerformanceConfig_DumpParallelLevel.OPTIMAL:
      return "OPTIMAL";
    case MigrationJob_PerformanceConfig_DumpParallelLevel.MAX:
      return "MAX";
    case MigrationJob_PerformanceConfig_DumpParallelLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface MigrationJob_LabelsEntry {
  key: string;
  value: string;
}

/** A conversion workspace's version. */
export interface ConversionWorkspaceInfo {
  /** The resource name (URI) of the conversion workspace. */
  name: string;
  /** The commit ID of the conversion workspace. */
  commitId: string;
}

/** A connection profile definition. */
export interface ConnectionProfile {
  /**
   * The name of this connection profile resource in the form of
   * projects/{project}/locations/{location}/connectionProfiles/{connectionProfile}.
   */
  name: string;
  /**
   * Output only. The timestamp when the resource was created.
   * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
   * Example: "2014-10-02T15:01:23.045123456Z".
   */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. The timestamp when the resource was last updated.
   * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
   * Example: "2014-10-02T15:01:23.045123456Z".
   */
  updateTime:
    | Date
    | undefined;
  /**
   * The resource labels for connection profile to use to annotate any related
   * underlying resources such as Compute Engine VMs. An object containing a
   * list of "key": "value" pairs.
   *
   * Example: `{ "name": "wrench", "mass": "1.3kg", "count": "3" }`.
   */
  labels: { [key: string]: string };
  /** The current connection profile state (e.g. DRAFT, READY, or FAILED). */
  state: ConnectionProfile_State;
  /** The connection profile display name. */
  displayName: string;
  /** A MySQL database connection profile. */
  mysql?:
    | MySqlConnectionProfile
    | undefined;
  /** A PostgreSQL database connection profile. */
  postgresql?:
    | PostgreSqlConnectionProfile
    | undefined;
  /** An Oracle database connection profile. */
  oracle?:
    | OracleConnectionProfile
    | undefined;
  /** A CloudSQL database connection profile. */
  cloudsql?:
    | CloudSqlConnectionProfile
    | undefined;
  /** An AlloyDB cluster connection profile. */
  alloydb?:
    | AlloyDbConnectionProfile
    | undefined;
  /** Output only. The error details in case of state FAILED. */
  error:
    | Status
    | undefined;
  /** The database provider. */
  provider: DatabaseProvider;
}

/** The current connection profile state (e.g. DRAFT, READY, or FAILED). */
export enum ConnectionProfile_State {
  /** STATE_UNSPECIFIED - The state of the connection profile is unknown. */
  STATE_UNSPECIFIED = 0,
  /** DRAFT - The connection profile is in draft mode and fully editable. */
  DRAFT = 1,
  /** CREATING - The connection profile is being created. */
  CREATING = 2,
  /** READY - The connection profile is ready. */
  READY = 3,
  /** UPDATING - The connection profile is being updated. */
  UPDATING = 4,
  /** DELETING - The connection profile is being deleted. */
  DELETING = 5,
  /** DELETED - The connection profile has been deleted. */
  DELETED = 6,
  /** FAILED - The last action on the connection profile failed. */
  FAILED = 7,
  UNRECOGNIZED = -1,
}

export function connectionProfile_StateFromJSON(object: any): ConnectionProfile_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return ConnectionProfile_State.STATE_UNSPECIFIED;
    case 1:
    case "DRAFT":
      return ConnectionProfile_State.DRAFT;
    case 2:
    case "CREATING":
      return ConnectionProfile_State.CREATING;
    case 3:
    case "READY":
      return ConnectionProfile_State.READY;
    case 4:
    case "UPDATING":
      return ConnectionProfile_State.UPDATING;
    case 5:
    case "DELETING":
      return ConnectionProfile_State.DELETING;
    case 6:
    case "DELETED":
      return ConnectionProfile_State.DELETED;
    case 7:
    case "FAILED":
      return ConnectionProfile_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ConnectionProfile_State.UNRECOGNIZED;
  }
}

export function connectionProfile_StateToJSON(object: ConnectionProfile_State): string {
  switch (object) {
    case ConnectionProfile_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case ConnectionProfile_State.DRAFT:
      return "DRAFT";
    case ConnectionProfile_State.CREATING:
      return "CREATING";
    case ConnectionProfile_State.READY:
      return "READY";
    case ConnectionProfile_State.UPDATING:
      return "UPDATING";
    case ConnectionProfile_State.DELETING:
      return "DELETING";
    case ConnectionProfile_State.DELETED:
      return "DELETED";
    case ConnectionProfile_State.FAILED:
      return "FAILED";
    case ConnectionProfile_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface ConnectionProfile_LabelsEntry {
  key: string;
  value: string;
}

/** Error message of a verification Migration job. */
export interface MigrationJobVerificationError {
  /** Output only. An instance of ErrorCode specifying the error that occurred. */
  errorCode: MigrationJobVerificationError_ErrorCode;
  /**
   * Output only. A formatted message with further details about the error and a
   * CTA.
   */
  errorMessage: string;
  /** Output only. A specific detailed error message, if supplied by the engine. */
  errorDetailMessage: string;
}

/** A general error code describing the type of error that occurred. */
export enum MigrationJobVerificationError_ErrorCode {
  /** ERROR_CODE_UNSPECIFIED - An unknown error occurred */
  ERROR_CODE_UNSPECIFIED = 0,
  /** CONNECTION_FAILURE - We failed to connect to one of the connection profile. */
  CONNECTION_FAILURE = 1,
  /** AUTHENTICATION_FAILURE - We failed to authenticate to one of the connection profile. */
  AUTHENTICATION_FAILURE = 2,
  /** INVALID_CONNECTION_PROFILE_CONFIG - One of the involved connection profiles has an invalid configuration. */
  INVALID_CONNECTION_PROFILE_CONFIG = 3,
  /** VERSION_INCOMPATIBILITY - The versions of the source and the destination are incompatible. */
  VERSION_INCOMPATIBILITY = 4,
  /** CONNECTION_PROFILE_TYPES_INCOMPATIBILITY - The types of the source and the destination are incompatible. */
  CONNECTION_PROFILE_TYPES_INCOMPATIBILITY = 5,
  /** NO_PGLOGICAL_INSTALLED - No pglogical extension installed on databases, applicable for postgres. */
  NO_PGLOGICAL_INSTALLED = 7,
  /** PGLOGICAL_NODE_ALREADY_EXISTS - pglogical node already exists on databases, applicable for postgres. */
  PGLOGICAL_NODE_ALREADY_EXISTS = 8,
  /** INVALID_WAL_LEVEL - The value of parameter wal_level is not set to logical. */
  INVALID_WAL_LEVEL = 9,
  /**
   * INVALID_SHARED_PRELOAD_LIBRARY - The value of parameter shared_preload_libraries does not include
   * pglogical.
   */
  INVALID_SHARED_PRELOAD_LIBRARY = 10,
  /** INSUFFICIENT_MAX_REPLICATION_SLOTS - The value of parameter max_replication_slots is not sufficient. */
  INSUFFICIENT_MAX_REPLICATION_SLOTS = 11,
  /** INSUFFICIENT_MAX_WAL_SENDERS - The value of parameter max_wal_senders is not sufficient. */
  INSUFFICIENT_MAX_WAL_SENDERS = 12,
  /** INSUFFICIENT_MAX_WORKER_PROCESSES - The value of parameter max_worker_processes is not sufficient. */
  INSUFFICIENT_MAX_WORKER_PROCESSES = 13,
  /**
   * UNSUPPORTED_EXTENSIONS - Extensions installed are either not supported or having unsupported
   * versions.
   */
  UNSUPPORTED_EXTENSIONS = 14,
  /** UNSUPPORTED_MIGRATION_TYPE - Unsupported migration type. */
  UNSUPPORTED_MIGRATION_TYPE = 15,
  /** INVALID_RDS_LOGICAL_REPLICATION - Invalid RDS logical replication. */
  INVALID_RDS_LOGICAL_REPLICATION = 16,
  /** UNSUPPORTED_GTID_MODE - The gtid_mode is not supported, applicable for MySQL. */
  UNSUPPORTED_GTID_MODE = 17,
  /**
   * UNSUPPORTED_TABLE_DEFINITION - The table definition is not support due to missing primary key or replica
   * identity.
   */
  UNSUPPORTED_TABLE_DEFINITION = 18,
  /** UNSUPPORTED_DEFINER - The definer is not supported. */
  UNSUPPORTED_DEFINER = 19,
  /** CANT_RESTART_RUNNING_MIGRATION - Migration is already running at the time of restart request. */
  CANT_RESTART_RUNNING_MIGRATION = 21,
  /** SOURCE_ALREADY_SETUP - The source already has a replication setup. */
  SOURCE_ALREADY_SETUP = 23,
  /**
   * TABLES_WITH_LIMITED_SUPPORT - The source has tables with limited support.
   * E.g. PostgreSQL tables without primary keys.
   */
  TABLES_WITH_LIMITED_SUPPORT = 24,
  /** UNSUPPORTED_DATABASE_LOCALE - The source uses an unsupported locale. */
  UNSUPPORTED_DATABASE_LOCALE = 25,
  /** UNSUPPORTED_DATABASE_FDW_CONFIG - The source uses an unsupported Foreign Data Wrapper configuration. */
  UNSUPPORTED_DATABASE_FDW_CONFIG = 26,
  /** ERROR_RDBMS - There was an underlying RDBMS error. */
  ERROR_RDBMS = 27,
  /**
   * SOURCE_SIZE_EXCEEDS_THRESHOLD - The source DB size in Bytes exceeds a certain threshold. The migration
   * might require an increase of quota, or might not be supported.
   */
  SOURCE_SIZE_EXCEEDS_THRESHOLD = 28,
  /**
   * EXISTING_CONFLICTING_DATABASES - The destination DB contains existing databases that are conflicting with
   * those in the source DB.
   */
  EXISTING_CONFLICTING_DATABASES = 29,
  /** PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE - Insufficient privilege to enable the parallelism configuration. */
  PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE = 30,
  UNRECOGNIZED = -1,
}

export function migrationJobVerificationError_ErrorCodeFromJSON(object: any): MigrationJobVerificationError_ErrorCode {
  switch (object) {
    case 0:
    case "ERROR_CODE_UNSPECIFIED":
      return MigrationJobVerificationError_ErrorCode.ERROR_CODE_UNSPECIFIED;
    case 1:
    case "CONNECTION_FAILURE":
      return MigrationJobVerificationError_ErrorCode.CONNECTION_FAILURE;
    case 2:
    case "AUTHENTICATION_FAILURE":
      return MigrationJobVerificationError_ErrorCode.AUTHENTICATION_FAILURE;
    case 3:
    case "INVALID_CONNECTION_PROFILE_CONFIG":
      return MigrationJobVerificationError_ErrorCode.INVALID_CONNECTION_PROFILE_CONFIG;
    case 4:
    case "VERSION_INCOMPATIBILITY":
      return MigrationJobVerificationError_ErrorCode.VERSION_INCOMPATIBILITY;
    case 5:
    case "CONNECTION_PROFILE_TYPES_INCOMPATIBILITY":
      return MigrationJobVerificationError_ErrorCode.CONNECTION_PROFILE_TYPES_INCOMPATIBILITY;
    case 7:
    case "NO_PGLOGICAL_INSTALLED":
      return MigrationJobVerificationError_ErrorCode.NO_PGLOGICAL_INSTALLED;
    case 8:
    case "PGLOGICAL_NODE_ALREADY_EXISTS":
      return MigrationJobVerificationError_ErrorCode.PGLOGICAL_NODE_ALREADY_EXISTS;
    case 9:
    case "INVALID_WAL_LEVEL":
      return MigrationJobVerificationError_ErrorCode.INVALID_WAL_LEVEL;
    case 10:
    case "INVALID_SHARED_PRELOAD_LIBRARY":
      return MigrationJobVerificationError_ErrorCode.INVALID_SHARED_PRELOAD_LIBRARY;
    case 11:
    case "INSUFFICIENT_MAX_REPLICATION_SLOTS":
      return MigrationJobVerificationError_ErrorCode.INSUFFICIENT_MAX_REPLICATION_SLOTS;
    case 12:
    case "INSUFFICIENT_MAX_WAL_SENDERS":
      return MigrationJobVerificationError_ErrorCode.INSUFFICIENT_MAX_WAL_SENDERS;
    case 13:
    case "INSUFFICIENT_MAX_WORKER_PROCESSES":
      return MigrationJobVerificationError_ErrorCode.INSUFFICIENT_MAX_WORKER_PROCESSES;
    case 14:
    case "UNSUPPORTED_EXTENSIONS":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_EXTENSIONS;
    case 15:
    case "UNSUPPORTED_MIGRATION_TYPE":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_MIGRATION_TYPE;
    case 16:
    case "INVALID_RDS_LOGICAL_REPLICATION":
      return MigrationJobVerificationError_ErrorCode.INVALID_RDS_LOGICAL_REPLICATION;
    case 17:
    case "UNSUPPORTED_GTID_MODE":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_GTID_MODE;
    case 18:
    case "UNSUPPORTED_TABLE_DEFINITION":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_TABLE_DEFINITION;
    case 19:
    case "UNSUPPORTED_DEFINER":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_DEFINER;
    case 21:
    case "CANT_RESTART_RUNNING_MIGRATION":
      return MigrationJobVerificationError_ErrorCode.CANT_RESTART_RUNNING_MIGRATION;
    case 23:
    case "SOURCE_ALREADY_SETUP":
      return MigrationJobVerificationError_ErrorCode.SOURCE_ALREADY_SETUP;
    case 24:
    case "TABLES_WITH_LIMITED_SUPPORT":
      return MigrationJobVerificationError_ErrorCode.TABLES_WITH_LIMITED_SUPPORT;
    case 25:
    case "UNSUPPORTED_DATABASE_LOCALE":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_DATABASE_LOCALE;
    case 26:
    case "UNSUPPORTED_DATABASE_FDW_CONFIG":
      return MigrationJobVerificationError_ErrorCode.UNSUPPORTED_DATABASE_FDW_CONFIG;
    case 27:
    case "ERROR_RDBMS":
      return MigrationJobVerificationError_ErrorCode.ERROR_RDBMS;
    case 28:
    case "SOURCE_SIZE_EXCEEDS_THRESHOLD":
      return MigrationJobVerificationError_ErrorCode.SOURCE_SIZE_EXCEEDS_THRESHOLD;
    case 29:
    case "EXISTING_CONFLICTING_DATABASES":
      return MigrationJobVerificationError_ErrorCode.EXISTING_CONFLICTING_DATABASES;
    case 30:
    case "PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE":
      return MigrationJobVerificationError_ErrorCode.PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationJobVerificationError_ErrorCode.UNRECOGNIZED;
  }
}

export function migrationJobVerificationError_ErrorCodeToJSON(object: MigrationJobVerificationError_ErrorCode): string {
  switch (object) {
    case MigrationJobVerificationError_ErrorCode.ERROR_CODE_UNSPECIFIED:
      return "ERROR_CODE_UNSPECIFIED";
    case MigrationJobVerificationError_ErrorCode.CONNECTION_FAILURE:
      return "CONNECTION_FAILURE";
    case MigrationJobVerificationError_ErrorCode.AUTHENTICATION_FAILURE:
      return "AUTHENTICATION_FAILURE";
    case MigrationJobVerificationError_ErrorCode.INVALID_CONNECTION_PROFILE_CONFIG:
      return "INVALID_CONNECTION_PROFILE_CONFIG";
    case MigrationJobVerificationError_ErrorCode.VERSION_INCOMPATIBILITY:
      return "VERSION_INCOMPATIBILITY";
    case MigrationJobVerificationError_ErrorCode.CONNECTION_PROFILE_TYPES_INCOMPATIBILITY:
      return "CONNECTION_PROFILE_TYPES_INCOMPATIBILITY";
    case MigrationJobVerificationError_ErrorCode.NO_PGLOGICAL_INSTALLED:
      return "NO_PGLOGICAL_INSTALLED";
    case MigrationJobVerificationError_ErrorCode.PGLOGICAL_NODE_ALREADY_EXISTS:
      return "PGLOGICAL_NODE_ALREADY_EXISTS";
    case MigrationJobVerificationError_ErrorCode.INVALID_WAL_LEVEL:
      return "INVALID_WAL_LEVEL";
    case MigrationJobVerificationError_ErrorCode.INVALID_SHARED_PRELOAD_LIBRARY:
      return "INVALID_SHARED_PRELOAD_LIBRARY";
    case MigrationJobVerificationError_ErrorCode.INSUFFICIENT_MAX_REPLICATION_SLOTS:
      return "INSUFFICIENT_MAX_REPLICATION_SLOTS";
    case MigrationJobVerificationError_ErrorCode.INSUFFICIENT_MAX_WAL_SENDERS:
      return "INSUFFICIENT_MAX_WAL_SENDERS";
    case MigrationJobVerificationError_ErrorCode.INSUFFICIENT_MAX_WORKER_PROCESSES:
      return "INSUFFICIENT_MAX_WORKER_PROCESSES";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_EXTENSIONS:
      return "UNSUPPORTED_EXTENSIONS";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_MIGRATION_TYPE:
      return "UNSUPPORTED_MIGRATION_TYPE";
    case MigrationJobVerificationError_ErrorCode.INVALID_RDS_LOGICAL_REPLICATION:
      return "INVALID_RDS_LOGICAL_REPLICATION";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_GTID_MODE:
      return "UNSUPPORTED_GTID_MODE";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_TABLE_DEFINITION:
      return "UNSUPPORTED_TABLE_DEFINITION";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_DEFINER:
      return "UNSUPPORTED_DEFINER";
    case MigrationJobVerificationError_ErrorCode.CANT_RESTART_RUNNING_MIGRATION:
      return "CANT_RESTART_RUNNING_MIGRATION";
    case MigrationJobVerificationError_ErrorCode.SOURCE_ALREADY_SETUP:
      return "SOURCE_ALREADY_SETUP";
    case MigrationJobVerificationError_ErrorCode.TABLES_WITH_LIMITED_SUPPORT:
      return "TABLES_WITH_LIMITED_SUPPORT";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_DATABASE_LOCALE:
      return "UNSUPPORTED_DATABASE_LOCALE";
    case MigrationJobVerificationError_ErrorCode.UNSUPPORTED_DATABASE_FDW_CONFIG:
      return "UNSUPPORTED_DATABASE_FDW_CONFIG";
    case MigrationJobVerificationError_ErrorCode.ERROR_RDBMS:
      return "ERROR_RDBMS";
    case MigrationJobVerificationError_ErrorCode.SOURCE_SIZE_EXCEEDS_THRESHOLD:
      return "SOURCE_SIZE_EXCEEDS_THRESHOLD";
    case MigrationJobVerificationError_ErrorCode.EXISTING_CONFLICTING_DATABASES:
      return "EXISTING_CONFLICTING_DATABASES";
    case MigrationJobVerificationError_ErrorCode.PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE:
      return "PARALLEL_IMPORT_INSUFFICIENT_PRIVILEGE";
    case MigrationJobVerificationError_ErrorCode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The PrivateConnection resource is used to establish private connectivity
 * with the customer's network.
 */
export interface PrivateConnection {
  /** The name of the resource. */
  name: string;
  /** Output only. The create time of the resource. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update time of the resource. */
  updateTime:
    | Date
    | undefined;
  /**
   * The resource labels for private connections to use to annotate any related
   * underlying resources such as Compute Engine VMs. An object containing a
   * list of "key": "value" pairs.
   *
   * Example: `{ "name": "wrench", "mass": "1.3kg", "count": "3" }`.
   */
  labels: { [key: string]: string };
  /** The private connection display name. */
  displayName: string;
  /** Output only. The state of the private connection. */
  state: PrivateConnection_State;
  /** Output only. The error details in case of state FAILED. */
  error:
    | Status
    | undefined;
  /** VPC peering configuration. */
  vpcPeeringConfig?: VpcPeeringConfig | undefined;
}

/** Private Connection state. */
export enum PrivateConnection_State {
  STATE_UNSPECIFIED = 0,
  /** CREATING - The private connection is in creation state - creating resources. */
  CREATING = 1,
  /** CREATED - The private connection has been created with all of its resources. */
  CREATED = 2,
  /** FAILED - The private connection creation has failed. */
  FAILED = 3,
  /** DELETING - The private connection is being deleted. */
  DELETING = 4,
  /** FAILED_TO_DELETE - Delete request has failed, resource is in invalid state. */
  FAILED_TO_DELETE = 5,
  /** DELETED - The private connection has been deleted. */
  DELETED = 6,
  UNRECOGNIZED = -1,
}

export function privateConnection_StateFromJSON(object: any): PrivateConnection_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return PrivateConnection_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return PrivateConnection_State.CREATING;
    case 2:
    case "CREATED":
      return PrivateConnection_State.CREATED;
    case 3:
    case "FAILED":
      return PrivateConnection_State.FAILED;
    case 4:
    case "DELETING":
      return PrivateConnection_State.DELETING;
    case 5:
    case "FAILED_TO_DELETE":
      return PrivateConnection_State.FAILED_TO_DELETE;
    case 6:
    case "DELETED":
      return PrivateConnection_State.DELETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PrivateConnection_State.UNRECOGNIZED;
  }
}

export function privateConnection_StateToJSON(object: PrivateConnection_State): string {
  switch (object) {
    case PrivateConnection_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case PrivateConnection_State.CREATING:
      return "CREATING";
    case PrivateConnection_State.CREATED:
      return "CREATED";
    case PrivateConnection_State.FAILED:
      return "FAILED";
    case PrivateConnection_State.DELETING:
      return "DELETING";
    case PrivateConnection_State.FAILED_TO_DELETE:
      return "FAILED_TO_DELETE";
    case PrivateConnection_State.DELETED:
      return "DELETED";
    case PrivateConnection_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface PrivateConnection_LabelsEntry {
  key: string;
  value: string;
}

/**
 * The VPC peering configuration is used to create VPC peering with the
 * consumer's VPC.
 */
export interface VpcPeeringConfig {
  /**
   * Required. Fully qualified name of the VPC that Database Migration Service
   * will peer to.
   */
  vpcName: string;
  /** Required. A free subnet for peering. (CIDR of /29) */
  subnet: string;
}

function createBaseSslConfig(): SslConfig {
  return { type: 0, clientKey: "", clientCertificate: "", caCertificate: "" };
}

export const SslConfig: MessageFns<SslConfig> = {
  encode(message: SslConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.clientKey !== "") {
      writer.uint32(18).string(message.clientKey);
    }
    if (message.clientCertificate !== "") {
      writer.uint32(26).string(message.clientCertificate);
    }
    if (message.caCertificate !== "") {
      writer.uint32(34).string(message.caCertificate);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SslConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSslConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.clientKey = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.clientCertificate = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.caCertificate = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SslConfig {
    return {
      type: isSet(object.type) ? sslConfig_SslTypeFromJSON(object.type) : 0,
      clientKey: isSet(object.clientKey) ? globalThis.String(object.clientKey) : "",
      clientCertificate: isSet(object.clientCertificate) ? globalThis.String(object.clientCertificate) : "",
      caCertificate: isSet(object.caCertificate) ? globalThis.String(object.caCertificate) : "",
    };
  },

  toJSON(message: SslConfig): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = sslConfig_SslTypeToJSON(message.type);
    }
    if (message.clientKey !== "") {
      obj.clientKey = message.clientKey;
    }
    if (message.clientCertificate !== "") {
      obj.clientCertificate = message.clientCertificate;
    }
    if (message.caCertificate !== "") {
      obj.caCertificate = message.caCertificate;
    }
    return obj;
  },

  create(base?: DeepPartial<SslConfig>): SslConfig {
    return SslConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SslConfig>): SslConfig {
    const message = createBaseSslConfig();
    message.type = object.type ?? 0;
    message.clientKey = object.clientKey ?? "";
    message.clientCertificate = object.clientCertificate ?? "";
    message.caCertificate = object.caCertificate ?? "";
    return message;
  },
};

function createBaseMySqlConnectionProfile(): MySqlConnectionProfile {
  return { host: "", port: 0, username: "", password: "", passwordSet: false, ssl: undefined, cloudSqlId: "" };
}

export const MySqlConnectionProfile: MessageFns<MySqlConnectionProfile> = {
  encode(message: MySqlConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.host !== "") {
      writer.uint32(10).string(message.host);
    }
    if (message.port !== 0) {
      writer.uint32(16).int32(message.port);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.passwordSet !== false) {
      writer.uint32(40).bool(message.passwordSet);
    }
    if (message.ssl !== undefined) {
      SslConfig.encode(message.ssl, writer.uint32(50).fork()).join();
    }
    if (message.cloudSqlId !== "") {
      writer.uint32(58).string(message.cloudSqlId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MySqlConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMySqlConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.host = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.passwordSet = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.ssl = SslConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.cloudSqlId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MySqlConnectionProfile {
    return {
      host: isSet(object.host) ? globalThis.String(object.host) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      passwordSet: isSet(object.passwordSet) ? globalThis.Boolean(object.passwordSet) : false,
      ssl: isSet(object.ssl) ? SslConfig.fromJSON(object.ssl) : undefined,
      cloudSqlId: isSet(object.cloudSqlId) ? globalThis.String(object.cloudSqlId) : "",
    };
  },

  toJSON(message: MySqlConnectionProfile): unknown {
    const obj: any = {};
    if (message.host !== "") {
      obj.host = message.host;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.passwordSet !== false) {
      obj.passwordSet = message.passwordSet;
    }
    if (message.ssl !== undefined) {
      obj.ssl = SslConfig.toJSON(message.ssl);
    }
    if (message.cloudSqlId !== "") {
      obj.cloudSqlId = message.cloudSqlId;
    }
    return obj;
  },

  create(base?: DeepPartial<MySqlConnectionProfile>): MySqlConnectionProfile {
    return MySqlConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MySqlConnectionProfile>): MySqlConnectionProfile {
    const message = createBaseMySqlConnectionProfile();
    message.host = object.host ?? "";
    message.port = object.port ?? 0;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.passwordSet = object.passwordSet ?? false;
    message.ssl = (object.ssl !== undefined && object.ssl !== null) ? SslConfig.fromPartial(object.ssl) : undefined;
    message.cloudSqlId = object.cloudSqlId ?? "";
    return message;
  },
};

function createBasePostgreSqlConnectionProfile(): PostgreSqlConnectionProfile {
  return {
    host: "",
    port: 0,
    username: "",
    password: "",
    passwordSet: false,
    ssl: undefined,
    cloudSqlId: "",
    networkArchitecture: 0,
    staticIpConnectivity: undefined,
    privateServiceConnectConnectivity: undefined,
  };
}

export const PostgreSqlConnectionProfile: MessageFns<PostgreSqlConnectionProfile> = {
  encode(message: PostgreSqlConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.host !== "") {
      writer.uint32(10).string(message.host);
    }
    if (message.port !== 0) {
      writer.uint32(16).int32(message.port);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.passwordSet !== false) {
      writer.uint32(40).bool(message.passwordSet);
    }
    if (message.ssl !== undefined) {
      SslConfig.encode(message.ssl, writer.uint32(50).fork()).join();
    }
    if (message.cloudSqlId !== "") {
      writer.uint32(58).string(message.cloudSqlId);
    }
    if (message.networkArchitecture !== 0) {
      writer.uint32(64).int32(message.networkArchitecture);
    }
    if (message.staticIpConnectivity !== undefined) {
      StaticIpConnectivity.encode(message.staticIpConnectivity, writer.uint32(802).fork()).join();
    }
    if (message.privateServiceConnectConnectivity !== undefined) {
      PrivateServiceConnectConnectivity.encode(message.privateServiceConnectConnectivity, writer.uint32(810).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgreSqlConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgreSqlConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.host = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.passwordSet = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.ssl = SslConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.cloudSqlId = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.networkArchitecture = reader.int32() as any;
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.staticIpConnectivity = StaticIpConnectivity.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.privateServiceConnectConnectivity = PrivateServiceConnectConnectivity.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgreSqlConnectionProfile {
    return {
      host: isSet(object.host) ? globalThis.String(object.host) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      passwordSet: isSet(object.passwordSet) ? globalThis.Boolean(object.passwordSet) : false,
      ssl: isSet(object.ssl) ? SslConfig.fromJSON(object.ssl) : undefined,
      cloudSqlId: isSet(object.cloudSqlId) ? globalThis.String(object.cloudSqlId) : "",
      networkArchitecture: isSet(object.networkArchitecture)
        ? networkArchitectureFromJSON(object.networkArchitecture)
        : 0,
      staticIpConnectivity: isSet(object.staticIpConnectivity)
        ? StaticIpConnectivity.fromJSON(object.staticIpConnectivity)
        : undefined,
      privateServiceConnectConnectivity: isSet(object.privateServiceConnectConnectivity)
        ? PrivateServiceConnectConnectivity.fromJSON(object.privateServiceConnectConnectivity)
        : undefined,
    };
  },

  toJSON(message: PostgreSqlConnectionProfile): unknown {
    const obj: any = {};
    if (message.host !== "") {
      obj.host = message.host;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.passwordSet !== false) {
      obj.passwordSet = message.passwordSet;
    }
    if (message.ssl !== undefined) {
      obj.ssl = SslConfig.toJSON(message.ssl);
    }
    if (message.cloudSqlId !== "") {
      obj.cloudSqlId = message.cloudSqlId;
    }
    if (message.networkArchitecture !== 0) {
      obj.networkArchitecture = networkArchitectureToJSON(message.networkArchitecture);
    }
    if (message.staticIpConnectivity !== undefined) {
      obj.staticIpConnectivity = StaticIpConnectivity.toJSON(message.staticIpConnectivity);
    }
    if (message.privateServiceConnectConnectivity !== undefined) {
      obj.privateServiceConnectConnectivity = PrivateServiceConnectConnectivity.toJSON(
        message.privateServiceConnectConnectivity,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<PostgreSqlConnectionProfile>): PostgreSqlConnectionProfile {
    return PostgreSqlConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgreSqlConnectionProfile>): PostgreSqlConnectionProfile {
    const message = createBasePostgreSqlConnectionProfile();
    message.host = object.host ?? "";
    message.port = object.port ?? 0;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.passwordSet = object.passwordSet ?? false;
    message.ssl = (object.ssl !== undefined && object.ssl !== null) ? SslConfig.fromPartial(object.ssl) : undefined;
    message.cloudSqlId = object.cloudSqlId ?? "";
    message.networkArchitecture = object.networkArchitecture ?? 0;
    message.staticIpConnectivity = (object.staticIpConnectivity !== undefined && object.staticIpConnectivity !== null)
      ? StaticIpConnectivity.fromPartial(object.staticIpConnectivity)
      : undefined;
    message.privateServiceConnectConnectivity =
      (object.privateServiceConnectConnectivity !== undefined && object.privateServiceConnectConnectivity !== null)
        ? PrivateServiceConnectConnectivity.fromPartial(object.privateServiceConnectConnectivity)
        : undefined;
    return message;
  },
};

function createBaseOracleConnectionProfile(): OracleConnectionProfile {
  return {
    host: "",
    port: 0,
    username: "",
    password: "",
    passwordSet: false,
    databaseService: "",
    ssl: undefined,
    staticServiceIpConnectivity: undefined,
    forwardSshConnectivity: undefined,
    privateConnectivity: undefined,
  };
}

export const OracleConnectionProfile: MessageFns<OracleConnectionProfile> = {
  encode(message: OracleConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.host !== "") {
      writer.uint32(10).string(message.host);
    }
    if (message.port !== 0) {
      writer.uint32(16).int32(message.port);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.passwordSet !== false) {
      writer.uint32(40).bool(message.passwordSet);
    }
    if (message.databaseService !== "") {
      writer.uint32(50).string(message.databaseService);
    }
    if (message.ssl !== undefined) {
      SslConfig.encode(message.ssl, writer.uint32(58).fork()).join();
    }
    if (message.staticServiceIpConnectivity !== undefined) {
      StaticServiceIpConnectivity.encode(message.staticServiceIpConnectivity, writer.uint32(802).fork()).join();
    }
    if (message.forwardSshConnectivity !== undefined) {
      ForwardSshTunnelConnectivity.encode(message.forwardSshConnectivity, writer.uint32(810).fork()).join();
    }
    if (message.privateConnectivity !== undefined) {
      PrivateConnectivity.encode(message.privateConnectivity, writer.uint32(818).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.host = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.passwordSet = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.databaseService = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.ssl = SslConfig.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.staticServiceIpConnectivity = StaticServiceIpConnectivity.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.forwardSshConnectivity = ForwardSshTunnelConnectivity.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.privateConnectivity = PrivateConnectivity.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleConnectionProfile {
    return {
      host: isSet(object.host) ? globalThis.String(object.host) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      passwordSet: isSet(object.passwordSet) ? globalThis.Boolean(object.passwordSet) : false,
      databaseService: isSet(object.databaseService) ? globalThis.String(object.databaseService) : "",
      ssl: isSet(object.ssl) ? SslConfig.fromJSON(object.ssl) : undefined,
      staticServiceIpConnectivity: isSet(object.staticServiceIpConnectivity)
        ? StaticServiceIpConnectivity.fromJSON(object.staticServiceIpConnectivity)
        : undefined,
      forwardSshConnectivity: isSet(object.forwardSshConnectivity)
        ? ForwardSshTunnelConnectivity.fromJSON(object.forwardSshConnectivity)
        : undefined,
      privateConnectivity: isSet(object.privateConnectivity)
        ? PrivateConnectivity.fromJSON(object.privateConnectivity)
        : undefined,
    };
  },

  toJSON(message: OracleConnectionProfile): unknown {
    const obj: any = {};
    if (message.host !== "") {
      obj.host = message.host;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.passwordSet !== false) {
      obj.passwordSet = message.passwordSet;
    }
    if (message.databaseService !== "") {
      obj.databaseService = message.databaseService;
    }
    if (message.ssl !== undefined) {
      obj.ssl = SslConfig.toJSON(message.ssl);
    }
    if (message.staticServiceIpConnectivity !== undefined) {
      obj.staticServiceIpConnectivity = StaticServiceIpConnectivity.toJSON(message.staticServiceIpConnectivity);
    }
    if (message.forwardSshConnectivity !== undefined) {
      obj.forwardSshConnectivity = ForwardSshTunnelConnectivity.toJSON(message.forwardSshConnectivity);
    }
    if (message.privateConnectivity !== undefined) {
      obj.privateConnectivity = PrivateConnectivity.toJSON(message.privateConnectivity);
    }
    return obj;
  },

  create(base?: DeepPartial<OracleConnectionProfile>): OracleConnectionProfile {
    return OracleConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleConnectionProfile>): OracleConnectionProfile {
    const message = createBaseOracleConnectionProfile();
    message.host = object.host ?? "";
    message.port = object.port ?? 0;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.passwordSet = object.passwordSet ?? false;
    message.databaseService = object.databaseService ?? "";
    message.ssl = (object.ssl !== undefined && object.ssl !== null) ? SslConfig.fromPartial(object.ssl) : undefined;
    message.staticServiceIpConnectivity =
      (object.staticServiceIpConnectivity !== undefined && object.staticServiceIpConnectivity !== null)
        ? StaticServiceIpConnectivity.fromPartial(object.staticServiceIpConnectivity)
        : undefined;
    message.forwardSshConnectivity =
      (object.forwardSshConnectivity !== undefined && object.forwardSshConnectivity !== null)
        ? ForwardSshTunnelConnectivity.fromPartial(object.forwardSshConnectivity)
        : undefined;
    message.privateConnectivity = (object.privateConnectivity !== undefined && object.privateConnectivity !== null)
      ? PrivateConnectivity.fromPartial(object.privateConnectivity)
      : undefined;
    return message;
  },
};

function createBaseCloudSqlConnectionProfile(): CloudSqlConnectionProfile {
  return { cloudSqlId: "", settings: undefined, privateIp: "", publicIp: "", additionalPublicIp: "" };
}

export const CloudSqlConnectionProfile: MessageFns<CloudSqlConnectionProfile> = {
  encode(message: CloudSqlConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloudSqlId !== "") {
      writer.uint32(10).string(message.cloudSqlId);
    }
    if (message.settings !== undefined) {
      CloudSqlSettings.encode(message.settings, writer.uint32(18).fork()).join();
    }
    if (message.privateIp !== "") {
      writer.uint32(26).string(message.privateIp);
    }
    if (message.publicIp !== "") {
      writer.uint32(34).string(message.publicIp);
    }
    if (message.additionalPublicIp !== "") {
      writer.uint32(42).string(message.additionalPublicIp);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.cloudSqlId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.settings = CloudSqlSettings.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.privateIp = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.publicIp = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.additionalPublicIp = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlConnectionProfile {
    return {
      cloudSqlId: isSet(object.cloudSqlId) ? globalThis.String(object.cloudSqlId) : "",
      settings: isSet(object.settings) ? CloudSqlSettings.fromJSON(object.settings) : undefined,
      privateIp: isSet(object.privateIp) ? globalThis.String(object.privateIp) : "",
      publicIp: isSet(object.publicIp) ? globalThis.String(object.publicIp) : "",
      additionalPublicIp: isSet(object.additionalPublicIp) ? globalThis.String(object.additionalPublicIp) : "",
    };
  },

  toJSON(message: CloudSqlConnectionProfile): unknown {
    const obj: any = {};
    if (message.cloudSqlId !== "") {
      obj.cloudSqlId = message.cloudSqlId;
    }
    if (message.settings !== undefined) {
      obj.settings = CloudSqlSettings.toJSON(message.settings);
    }
    if (message.privateIp !== "") {
      obj.privateIp = message.privateIp;
    }
    if (message.publicIp !== "") {
      obj.publicIp = message.publicIp;
    }
    if (message.additionalPublicIp !== "") {
      obj.additionalPublicIp = message.additionalPublicIp;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudSqlConnectionProfile>): CloudSqlConnectionProfile {
    return CloudSqlConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudSqlConnectionProfile>): CloudSqlConnectionProfile {
    const message = createBaseCloudSqlConnectionProfile();
    message.cloudSqlId = object.cloudSqlId ?? "";
    message.settings = (object.settings !== undefined && object.settings !== null)
      ? CloudSqlSettings.fromPartial(object.settings)
      : undefined;
    message.privateIp = object.privateIp ?? "";
    message.publicIp = object.publicIp ?? "";
    message.additionalPublicIp = object.additionalPublicIp ?? "";
    return message;
  },
};

function createBaseAlloyDbConnectionProfile(): AlloyDbConnectionProfile {
  return { clusterId: "", settings: undefined };
}

export const AlloyDbConnectionProfile: MessageFns<AlloyDbConnectionProfile> = {
  encode(message: AlloyDbConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.clusterId !== "") {
      writer.uint32(10).string(message.clusterId);
    }
    if (message.settings !== undefined) {
      AlloyDbSettings.encode(message.settings, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.clusterId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.settings = AlloyDbSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbConnectionProfile {
    return {
      clusterId: isSet(object.clusterId) ? globalThis.String(object.clusterId) : "",
      settings: isSet(object.settings) ? AlloyDbSettings.fromJSON(object.settings) : undefined,
    };
  },

  toJSON(message: AlloyDbConnectionProfile): unknown {
    const obj: any = {};
    if (message.clusterId !== "") {
      obj.clusterId = message.clusterId;
    }
    if (message.settings !== undefined) {
      obj.settings = AlloyDbSettings.toJSON(message.settings);
    }
    return obj;
  },

  create(base?: DeepPartial<AlloyDbConnectionProfile>): AlloyDbConnectionProfile {
    return AlloyDbConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlloyDbConnectionProfile>): AlloyDbConnectionProfile {
    const message = createBaseAlloyDbConnectionProfile();
    message.clusterId = object.clusterId ?? "";
    message.settings = (object.settings !== undefined && object.settings !== null)
      ? AlloyDbSettings.fromPartial(object.settings)
      : undefined;
    return message;
  },
};

function createBaseSqlAclEntry(): SqlAclEntry {
  return { value: "", expireTime: undefined, ttl: undefined, label: "" };
}

export const SqlAclEntry: MessageFns<SqlAclEntry> = {
  encode(message: SqlAclEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== "") {
      writer.uint32(10).string(message.value);
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(82).fork()).join();
    }
    if (message.ttl !== undefined) {
      Duration.encode(message.ttl, writer.uint32(90).fork()).join();
    }
    if (message.label !== "") {
      writer.uint32(26).string(message.label);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlAclEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlAclEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.value = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.ttl = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.label = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlAclEntry {
    return {
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      ttl: isSet(object.ttl) ? Duration.fromJSON(object.ttl) : undefined,
      label: isSet(object.label) ? globalThis.String(object.label) : "",
    };
  },

  toJSON(message: SqlAclEntry): unknown {
    const obj: any = {};
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.ttl !== undefined) {
      obj.ttl = Duration.toJSON(message.ttl);
    }
    if (message.label !== "") {
      obj.label = message.label;
    }
    return obj;
  },

  create(base?: DeepPartial<SqlAclEntry>): SqlAclEntry {
    return SqlAclEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlAclEntry>): SqlAclEntry {
    const message = createBaseSqlAclEntry();
    message.value = object.value ?? "";
    message.expireTime = object.expireTime ?? undefined;
    message.ttl = (object.ttl !== undefined && object.ttl !== null) ? Duration.fromPartial(object.ttl) : undefined;
    message.label = object.label ?? "";
    return message;
  },
};

function createBaseSqlIpConfig(): SqlIpConfig {
  return {
    enableIpv4: undefined,
    privateNetwork: "",
    allocatedIpRange: "",
    requireSsl: undefined,
    authorizedNetworks: [],
  };
}

export const SqlIpConfig: MessageFns<SqlIpConfig> = {
  encode(message: SqlIpConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enableIpv4 !== undefined) {
      BoolValue.encode({ value: message.enableIpv4! }, writer.uint32(10).fork()).join();
    }
    if (message.privateNetwork !== "") {
      writer.uint32(18).string(message.privateNetwork);
    }
    if (message.allocatedIpRange !== "") {
      writer.uint32(42).string(message.allocatedIpRange);
    }
    if (message.requireSsl !== undefined) {
      BoolValue.encode({ value: message.requireSsl! }, writer.uint32(26).fork()).join();
    }
    for (const v of message.authorizedNetworks) {
      SqlAclEntry.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SqlIpConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSqlIpConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.enableIpv4 = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.privateNetwork = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.allocatedIpRange = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requireSsl = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.authorizedNetworks.push(SqlAclEntry.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SqlIpConfig {
    return {
      enableIpv4: isSet(object.enableIpv4) ? Boolean(object.enableIpv4) : undefined,
      privateNetwork: isSet(object.privateNetwork) ? globalThis.String(object.privateNetwork) : "",
      allocatedIpRange: isSet(object.allocatedIpRange) ? globalThis.String(object.allocatedIpRange) : "",
      requireSsl: isSet(object.requireSsl) ? Boolean(object.requireSsl) : undefined,
      authorizedNetworks: globalThis.Array.isArray(object?.authorizedNetworks)
        ? object.authorizedNetworks.map((e: any) => SqlAclEntry.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SqlIpConfig): unknown {
    const obj: any = {};
    if (message.enableIpv4 !== undefined) {
      obj.enableIpv4 = message.enableIpv4;
    }
    if (message.privateNetwork !== "") {
      obj.privateNetwork = message.privateNetwork;
    }
    if (message.allocatedIpRange !== "") {
      obj.allocatedIpRange = message.allocatedIpRange;
    }
    if (message.requireSsl !== undefined) {
      obj.requireSsl = message.requireSsl;
    }
    if (message.authorizedNetworks?.length) {
      obj.authorizedNetworks = message.authorizedNetworks.map((e) => SqlAclEntry.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SqlIpConfig>): SqlIpConfig {
    return SqlIpConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SqlIpConfig>): SqlIpConfig {
    const message = createBaseSqlIpConfig();
    message.enableIpv4 = object.enableIpv4 ?? undefined;
    message.privateNetwork = object.privateNetwork ?? "";
    message.allocatedIpRange = object.allocatedIpRange ?? "";
    message.requireSsl = object.requireSsl ?? undefined;
    message.authorizedNetworks = object.authorizedNetworks?.map((e) => SqlAclEntry.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCloudSqlSettings(): CloudSqlSettings {
  return {
    databaseVersion: 0,
    userLabels: {},
    tier: "",
    storageAutoResizeLimit: undefined,
    activationPolicy: 0,
    ipConfig: undefined,
    autoStorageIncrease: undefined,
    databaseFlags: {},
    dataDiskType: 0,
    dataDiskSizeGb: undefined,
    zone: "",
    secondaryZone: "",
    sourceId: "",
    rootPassword: "",
    rootPasswordSet: false,
    collation: "",
    cmekKeyName: "",
    availabilityType: 0,
    edition: 0,
  };
}

export const CloudSqlSettings: MessageFns<CloudSqlSettings> = {
  encode(message: CloudSqlSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.databaseVersion !== 0) {
      writer.uint32(8).int32(message.databaseVersion);
    }
    Object.entries(message.userLabels).forEach(([key, value]) => {
      CloudSqlSettings_UserLabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.tier !== "") {
      writer.uint32(26).string(message.tier);
    }
    if (message.storageAutoResizeLimit !== undefined) {
      Int64Value.encode({ value: message.storageAutoResizeLimit! }, writer.uint32(34).fork()).join();
    }
    if (message.activationPolicy !== 0) {
      writer.uint32(40).int32(message.activationPolicy);
    }
    if (message.ipConfig !== undefined) {
      SqlIpConfig.encode(message.ipConfig, writer.uint32(50).fork()).join();
    }
    if (message.autoStorageIncrease !== undefined) {
      BoolValue.encode({ value: message.autoStorageIncrease! }, writer.uint32(58).fork()).join();
    }
    Object.entries(message.databaseFlags).forEach(([key, value]) => {
      CloudSqlSettings_DatabaseFlagsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.dataDiskType !== 0) {
      writer.uint32(72).int32(message.dataDiskType);
    }
    if (message.dataDiskSizeGb !== undefined) {
      Int64Value.encode({ value: message.dataDiskSizeGb! }, writer.uint32(82).fork()).join();
    }
    if (message.zone !== "") {
      writer.uint32(90).string(message.zone);
    }
    if (message.secondaryZone !== "") {
      writer.uint32(146).string(message.secondaryZone);
    }
    if (message.sourceId !== "") {
      writer.uint32(98).string(message.sourceId);
    }
    if (message.rootPassword !== "") {
      writer.uint32(106).string(message.rootPassword);
    }
    if (message.rootPasswordSet !== false) {
      writer.uint32(112).bool(message.rootPasswordSet);
    }
    if (message.collation !== "") {
      writer.uint32(122).string(message.collation);
    }
    if (message.cmekKeyName !== "") {
      writer.uint32(130).string(message.cmekKeyName);
    }
    if (message.availabilityType !== 0) {
      writer.uint32(136).int32(message.availabilityType);
    }
    if (message.edition !== 0) {
      writer.uint32(152).int32(message.edition);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.databaseVersion = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = CloudSqlSettings_UserLabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.userLabels[entry2.key] = entry2.value;
          }
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tier = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.storageAutoResizeLimit = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.activationPolicy = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.ipConfig = SqlIpConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.autoStorageIncrease = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = CloudSqlSettings_DatabaseFlagsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.databaseFlags[entry8.key] = entry8.value;
          }
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.dataDiskType = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.dataDiskSizeGb = Int64Value.decode(reader, reader.uint32()).value;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.zone = reader.string();
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.secondaryZone = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.sourceId = reader.string();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.rootPassword = reader.string();
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.rootPasswordSet = reader.bool();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.collation = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.cmekKeyName = reader.string();
          continue;
        case 17:
          if (tag !== 136) {
            break;
          }

          message.availabilityType = reader.int32() as any;
          continue;
        case 19:
          if (tag !== 152) {
            break;
          }

          message.edition = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlSettings {
    return {
      databaseVersion: isSet(object.databaseVersion)
        ? cloudSqlSettings_SqlDatabaseVersionFromJSON(object.databaseVersion)
        : 0,
      userLabels: isObject(object.userLabels)
        ? Object.entries(object.userLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      tier: isSet(object.tier) ? globalThis.String(object.tier) : "",
      storageAutoResizeLimit: isSet(object.storageAutoResizeLimit)
        ? Long.fromValue(object.storageAutoResizeLimit)
        : undefined,
      activationPolicy: isSet(object.activationPolicy)
        ? cloudSqlSettings_SqlActivationPolicyFromJSON(object.activationPolicy)
        : 0,
      ipConfig: isSet(object.ipConfig) ? SqlIpConfig.fromJSON(object.ipConfig) : undefined,
      autoStorageIncrease: isSet(object.autoStorageIncrease) ? Boolean(object.autoStorageIncrease) : undefined,
      databaseFlags: isObject(object.databaseFlags)
        ? Object.entries(object.databaseFlags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      dataDiskType: isSet(object.dataDiskType) ? cloudSqlSettings_SqlDataDiskTypeFromJSON(object.dataDiskType) : 0,
      dataDiskSizeGb: isSet(object.dataDiskSizeGb) ? Long.fromValue(object.dataDiskSizeGb) : undefined,
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      secondaryZone: isSet(object.secondaryZone) ? globalThis.String(object.secondaryZone) : "",
      sourceId: isSet(object.sourceId) ? globalThis.String(object.sourceId) : "",
      rootPassword: isSet(object.rootPassword) ? globalThis.String(object.rootPassword) : "",
      rootPasswordSet: isSet(object.rootPasswordSet) ? globalThis.Boolean(object.rootPasswordSet) : false,
      collation: isSet(object.collation) ? globalThis.String(object.collation) : "",
      cmekKeyName: isSet(object.cmekKeyName) ? globalThis.String(object.cmekKeyName) : "",
      availabilityType: isSet(object.availabilityType)
        ? cloudSqlSettings_SqlAvailabilityTypeFromJSON(object.availabilityType)
        : 0,
      edition: isSet(object.edition) ? cloudSqlSettings_EditionFromJSON(object.edition) : 0,
    };
  },

  toJSON(message: CloudSqlSettings): unknown {
    const obj: any = {};
    if (message.databaseVersion !== 0) {
      obj.databaseVersion = cloudSqlSettings_SqlDatabaseVersionToJSON(message.databaseVersion);
    }
    if (message.userLabels) {
      const entries = Object.entries(message.userLabels);
      if (entries.length > 0) {
        obj.userLabels = {};
        entries.forEach(([k, v]) => {
          obj.userLabels[k] = v;
        });
      }
    }
    if (message.tier !== "") {
      obj.tier = message.tier;
    }
    if (message.storageAutoResizeLimit !== undefined) {
      obj.storageAutoResizeLimit = message.storageAutoResizeLimit;
    }
    if (message.activationPolicy !== 0) {
      obj.activationPolicy = cloudSqlSettings_SqlActivationPolicyToJSON(message.activationPolicy);
    }
    if (message.ipConfig !== undefined) {
      obj.ipConfig = SqlIpConfig.toJSON(message.ipConfig);
    }
    if (message.autoStorageIncrease !== undefined) {
      obj.autoStorageIncrease = message.autoStorageIncrease;
    }
    if (message.databaseFlags) {
      const entries = Object.entries(message.databaseFlags);
      if (entries.length > 0) {
        obj.databaseFlags = {};
        entries.forEach(([k, v]) => {
          obj.databaseFlags[k] = v;
        });
      }
    }
    if (message.dataDiskType !== 0) {
      obj.dataDiskType = cloudSqlSettings_SqlDataDiskTypeToJSON(message.dataDiskType);
    }
    if (message.dataDiskSizeGb !== undefined) {
      obj.dataDiskSizeGb = message.dataDiskSizeGb;
    }
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.secondaryZone !== "") {
      obj.secondaryZone = message.secondaryZone;
    }
    if (message.sourceId !== "") {
      obj.sourceId = message.sourceId;
    }
    if (message.rootPassword !== "") {
      obj.rootPassword = message.rootPassword;
    }
    if (message.rootPasswordSet !== false) {
      obj.rootPasswordSet = message.rootPasswordSet;
    }
    if (message.collation !== "") {
      obj.collation = message.collation;
    }
    if (message.cmekKeyName !== "") {
      obj.cmekKeyName = message.cmekKeyName;
    }
    if (message.availabilityType !== 0) {
      obj.availabilityType = cloudSqlSettings_SqlAvailabilityTypeToJSON(message.availabilityType);
    }
    if (message.edition !== 0) {
      obj.edition = cloudSqlSettings_EditionToJSON(message.edition);
    }
    return obj;
  },

  create(base?: DeepPartial<CloudSqlSettings>): CloudSqlSettings {
    return CloudSqlSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudSqlSettings>): CloudSqlSettings {
    const message = createBaseCloudSqlSettings();
    message.databaseVersion = object.databaseVersion ?? 0;
    message.userLabels = Object.entries(object.userLabels ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.tier = object.tier ?? "";
    message.storageAutoResizeLimit =
      (object.storageAutoResizeLimit !== undefined && object.storageAutoResizeLimit !== null)
        ? Long.fromValue(object.storageAutoResizeLimit)
        : undefined;
    message.activationPolicy = object.activationPolicy ?? 0;
    message.ipConfig = (object.ipConfig !== undefined && object.ipConfig !== null)
      ? SqlIpConfig.fromPartial(object.ipConfig)
      : undefined;
    message.autoStorageIncrease = object.autoStorageIncrease ?? undefined;
    message.databaseFlags = Object.entries(object.databaseFlags ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.dataDiskType = object.dataDiskType ?? 0;
    message.dataDiskSizeGb = (object.dataDiskSizeGb !== undefined && object.dataDiskSizeGb !== null)
      ? Long.fromValue(object.dataDiskSizeGb)
      : undefined;
    message.zone = object.zone ?? "";
    message.secondaryZone = object.secondaryZone ?? "";
    message.sourceId = object.sourceId ?? "";
    message.rootPassword = object.rootPassword ?? "";
    message.rootPasswordSet = object.rootPasswordSet ?? false;
    message.collation = object.collation ?? "";
    message.cmekKeyName = object.cmekKeyName ?? "";
    message.availabilityType = object.availabilityType ?? 0;
    message.edition = object.edition ?? 0;
    return message;
  },
};

function createBaseCloudSqlSettings_UserLabelsEntry(): CloudSqlSettings_UserLabelsEntry {
  return { key: "", value: "" };
}

export const CloudSqlSettings_UserLabelsEntry: MessageFns<CloudSqlSettings_UserLabelsEntry> = {
  encode(message: CloudSqlSettings_UserLabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlSettings_UserLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlSettings_UserLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlSettings_UserLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CloudSqlSettings_UserLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudSqlSettings_UserLabelsEntry>): CloudSqlSettings_UserLabelsEntry {
    return CloudSqlSettings_UserLabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudSqlSettings_UserLabelsEntry>): CloudSqlSettings_UserLabelsEntry {
    const message = createBaseCloudSqlSettings_UserLabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCloudSqlSettings_DatabaseFlagsEntry(): CloudSqlSettings_DatabaseFlagsEntry {
  return { key: "", value: "" };
}

export const CloudSqlSettings_DatabaseFlagsEntry: MessageFns<CloudSqlSettings_DatabaseFlagsEntry> = {
  encode(message: CloudSqlSettings_DatabaseFlagsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlSettings_DatabaseFlagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlSettings_DatabaseFlagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlSettings_DatabaseFlagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CloudSqlSettings_DatabaseFlagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CloudSqlSettings_DatabaseFlagsEntry>): CloudSqlSettings_DatabaseFlagsEntry {
    return CloudSqlSettings_DatabaseFlagsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CloudSqlSettings_DatabaseFlagsEntry>): CloudSqlSettings_DatabaseFlagsEntry {
    const message = createBaseCloudSqlSettings_DatabaseFlagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAlloyDbSettings(): AlloyDbSettings {
  return {
    initialUser: undefined,
    vpcNetwork: "",
    labels: {},
    primaryInstanceSettings: undefined,
    encryptionConfig: undefined,
  };
}

export const AlloyDbSettings: MessageFns<AlloyDbSettings> = {
  encode(message: AlloyDbSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.initialUser !== undefined) {
      AlloyDbSettings_UserPassword.encode(message.initialUser, writer.uint32(10).fork()).join();
    }
    if (message.vpcNetwork !== "") {
      writer.uint32(18).string(message.vpcNetwork);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      AlloyDbSettings_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.primaryInstanceSettings !== undefined) {
      AlloyDbSettings_PrimaryInstanceSettings.encode(message.primaryInstanceSettings, writer.uint32(34).fork()).join();
    }
    if (message.encryptionConfig !== undefined) {
      AlloyDbSettings_EncryptionConfig.encode(message.encryptionConfig, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.initialUser = AlloyDbSettings_UserPassword.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.vpcNetwork = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = AlloyDbSettings_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.primaryInstanceSettings = AlloyDbSettings_PrimaryInstanceSettings.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.encryptionConfig = AlloyDbSettings_EncryptionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings {
    return {
      initialUser: isSet(object.initialUser) ? AlloyDbSettings_UserPassword.fromJSON(object.initialUser) : undefined,
      vpcNetwork: isSet(object.vpcNetwork) ? globalThis.String(object.vpcNetwork) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      primaryInstanceSettings: isSet(object.primaryInstanceSettings)
        ? AlloyDbSettings_PrimaryInstanceSettings.fromJSON(object.primaryInstanceSettings)
        : undefined,
      encryptionConfig: isSet(object.encryptionConfig)
        ? AlloyDbSettings_EncryptionConfig.fromJSON(object.encryptionConfig)
        : undefined,
    };
  },

  toJSON(message: AlloyDbSettings): unknown {
    const obj: any = {};
    if (message.initialUser !== undefined) {
      obj.initialUser = AlloyDbSettings_UserPassword.toJSON(message.initialUser);
    }
    if (message.vpcNetwork !== "") {
      obj.vpcNetwork = message.vpcNetwork;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.primaryInstanceSettings !== undefined) {
      obj.primaryInstanceSettings = AlloyDbSettings_PrimaryInstanceSettings.toJSON(message.primaryInstanceSettings);
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = AlloyDbSettings_EncryptionConfig.toJSON(message.encryptionConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<AlloyDbSettings>): AlloyDbSettings {
    return AlloyDbSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlloyDbSettings>): AlloyDbSettings {
    const message = createBaseAlloyDbSettings();
    message.initialUser = (object.initialUser !== undefined && object.initialUser !== null)
      ? AlloyDbSettings_UserPassword.fromPartial(object.initialUser)
      : undefined;
    message.vpcNetwork = object.vpcNetwork ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.primaryInstanceSettings =
      (object.primaryInstanceSettings !== undefined && object.primaryInstanceSettings !== null)
        ? AlloyDbSettings_PrimaryInstanceSettings.fromPartial(object.primaryInstanceSettings)
        : undefined;
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? AlloyDbSettings_EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    return message;
  },
};

function createBaseAlloyDbSettings_UserPassword(): AlloyDbSettings_UserPassword {
  return { user: "", password: "", passwordSet: false };
}

export const AlloyDbSettings_UserPassword: MessageFns<AlloyDbSettings_UserPassword> = {
  encode(message: AlloyDbSettings_UserPassword, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.user !== "") {
      writer.uint32(10).string(message.user);
    }
    if (message.password !== "") {
      writer.uint32(18).string(message.password);
    }
    if (message.passwordSet !== false) {
      writer.uint32(24).bool(message.passwordSet);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings_UserPassword {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_UserPassword();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.user = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.password = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.passwordSet = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_UserPassword {
    return {
      user: isSet(object.user) ? globalThis.String(object.user) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      passwordSet: isSet(object.passwordSet) ? globalThis.Boolean(object.passwordSet) : false,
    };
  },

  toJSON(message: AlloyDbSettings_UserPassword): unknown {
    const obj: any = {};
    if (message.user !== "") {
      obj.user = message.user;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.passwordSet !== false) {
      obj.passwordSet = message.passwordSet;
    }
    return obj;
  },

  create(base?: DeepPartial<AlloyDbSettings_UserPassword>): AlloyDbSettings_UserPassword {
    return AlloyDbSettings_UserPassword.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlloyDbSettings_UserPassword>): AlloyDbSettings_UserPassword {
    const message = createBaseAlloyDbSettings_UserPassword();
    message.user = object.user ?? "";
    message.password = object.password ?? "";
    message.passwordSet = object.passwordSet ?? false;
    return message;
  },
};

function createBaseAlloyDbSettings_PrimaryInstanceSettings(): AlloyDbSettings_PrimaryInstanceSettings {
  return { id: "", machineConfig: undefined, databaseFlags: {}, labels: {}, privateIp: "" };
}

export const AlloyDbSettings_PrimaryInstanceSettings: MessageFns<AlloyDbSettings_PrimaryInstanceSettings> = {
  encode(message: AlloyDbSettings_PrimaryInstanceSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.machineConfig !== undefined) {
      AlloyDbSettings_PrimaryInstanceSettings_MachineConfig.encode(message.machineConfig, writer.uint32(18).fork())
        .join();
    }
    Object.entries(message.databaseFlags).forEach(([key, value]) => {
      AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry.encode(
        { key: key as any, value },
        writer.uint32(50).fork(),
      ).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry.encode({ key: key as any, value }, writer.uint32(58).fork())
        .join();
    });
    if (message.privateIp !== "") {
      writer.uint32(66).string(message.privateIp);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings_PrimaryInstanceSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.machineConfig = AlloyDbSettings_PrimaryInstanceSettings_MachineConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.databaseFlags[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.labels[entry7.key] = entry7.value;
          }
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.privateIp = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_PrimaryInstanceSettings {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      machineConfig: isSet(object.machineConfig)
        ? AlloyDbSettings_PrimaryInstanceSettings_MachineConfig.fromJSON(object.machineConfig)
        : undefined,
      databaseFlags: isObject(object.databaseFlags)
        ? Object.entries(object.databaseFlags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      privateIp: isSet(object.privateIp) ? globalThis.String(object.privateIp) : "",
    };
  },

  toJSON(message: AlloyDbSettings_PrimaryInstanceSettings): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.machineConfig !== undefined) {
      obj.machineConfig = AlloyDbSettings_PrimaryInstanceSettings_MachineConfig.toJSON(message.machineConfig);
    }
    if (message.databaseFlags) {
      const entries = Object.entries(message.databaseFlags);
      if (entries.length > 0) {
        obj.databaseFlags = {};
        entries.forEach(([k, v]) => {
          obj.databaseFlags[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.privateIp !== "") {
      obj.privateIp = message.privateIp;
    }
    return obj;
  },

  create(base?: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings>): AlloyDbSettings_PrimaryInstanceSettings {
    return AlloyDbSettings_PrimaryInstanceSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings>): AlloyDbSettings_PrimaryInstanceSettings {
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings();
    message.id = object.id ?? "";
    message.machineConfig = (object.machineConfig !== undefined && object.machineConfig !== null)
      ? AlloyDbSettings_PrimaryInstanceSettings_MachineConfig.fromPartial(object.machineConfig)
      : undefined;
    message.databaseFlags = Object.entries(object.databaseFlags ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.privateIp = object.privateIp ?? "";
    return message;
  },
};

function createBaseAlloyDbSettings_PrimaryInstanceSettings_MachineConfig(): AlloyDbSettings_PrimaryInstanceSettings_MachineConfig {
  return { cpuCount: 0 };
}

export const AlloyDbSettings_PrimaryInstanceSettings_MachineConfig: MessageFns<
  AlloyDbSettings_PrimaryInstanceSettings_MachineConfig
> = {
  encode(
    message: AlloyDbSettings_PrimaryInstanceSettings_MachineConfig,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.cpuCount !== 0) {
      writer.uint32(8).int32(message.cpuCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings_PrimaryInstanceSettings_MachineConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings_MachineConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.cpuCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_PrimaryInstanceSettings_MachineConfig {
    return { cpuCount: isSet(object.cpuCount) ? globalThis.Number(object.cpuCount) : 0 };
  },

  toJSON(message: AlloyDbSettings_PrimaryInstanceSettings_MachineConfig): unknown {
    const obj: any = {};
    if (message.cpuCount !== 0) {
      obj.cpuCount = Math.round(message.cpuCount);
    }
    return obj;
  },

  create(
    base?: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings_MachineConfig>,
  ): AlloyDbSettings_PrimaryInstanceSettings_MachineConfig {
    return AlloyDbSettings_PrimaryInstanceSettings_MachineConfig.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings_MachineConfig>,
  ): AlloyDbSettings_PrimaryInstanceSettings_MachineConfig {
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings_MachineConfig();
    message.cpuCount = object.cpuCount ?? 0;
    return message;
  },
};

function createBaseAlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry(): AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry {
  return { key: "", value: "" };
}

export const AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry: MessageFns<
  AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry
> = {
  encode(
    message: AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry>,
  ): AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry {
    return AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry>,
  ): AlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry {
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings_DatabaseFlagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAlloyDbSettings_PrimaryInstanceSettings_LabelsEntry(): AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry {
  return { key: "", value: "" };
}

export const AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry: MessageFns<
  AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry
> = {
  encode(
    message: AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry>,
  ): AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry {
    return AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry>,
  ): AlloyDbSettings_PrimaryInstanceSettings_LabelsEntry {
    const message = createBaseAlloyDbSettings_PrimaryInstanceSettings_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAlloyDbSettings_EncryptionConfig(): AlloyDbSettings_EncryptionConfig {
  return { kmsKeyName: "" };
}

export const AlloyDbSettings_EncryptionConfig: MessageFns<AlloyDbSettings_EncryptionConfig> = {
  encode(message: AlloyDbSettings_EncryptionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKeyName !== "") {
      writer.uint32(10).string(message.kmsKeyName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings_EncryptionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_EncryptionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_EncryptionConfig {
    return { kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "" };
  },

  toJSON(message: AlloyDbSettings_EncryptionConfig): unknown {
    const obj: any = {};
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    return obj;
  },

  create(base?: DeepPartial<AlloyDbSettings_EncryptionConfig>): AlloyDbSettings_EncryptionConfig {
    return AlloyDbSettings_EncryptionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlloyDbSettings_EncryptionConfig>): AlloyDbSettings_EncryptionConfig {
    const message = createBaseAlloyDbSettings_EncryptionConfig();
    message.kmsKeyName = object.kmsKeyName ?? "";
    return message;
  },
};

function createBaseAlloyDbSettings_LabelsEntry(): AlloyDbSettings_LabelsEntry {
  return { key: "", value: "" };
}

export const AlloyDbSettings_LabelsEntry: MessageFns<AlloyDbSettings_LabelsEntry> = {
  encode(message: AlloyDbSettings_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AlloyDbSettings_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAlloyDbSettings_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AlloyDbSettings_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AlloyDbSettings_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AlloyDbSettings_LabelsEntry>): AlloyDbSettings_LabelsEntry {
    return AlloyDbSettings_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AlloyDbSettings_LabelsEntry>): AlloyDbSettings_LabelsEntry {
    const message = createBaseAlloyDbSettings_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseStaticIpConnectivity(): StaticIpConnectivity {
  return {};
}

export const StaticIpConnectivity: MessageFns<StaticIpConnectivity> = {
  encode(_: StaticIpConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StaticIpConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStaticIpConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): StaticIpConnectivity {
    return {};
  },

  toJSON(_: StaticIpConnectivity): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<StaticIpConnectivity>): StaticIpConnectivity {
    return StaticIpConnectivity.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<StaticIpConnectivity>): StaticIpConnectivity {
    const message = createBaseStaticIpConnectivity();
    return message;
  },
};

function createBasePrivateServiceConnectConnectivity(): PrivateServiceConnectConnectivity {
  return { serviceAttachment: "" };
}

export const PrivateServiceConnectConnectivity: MessageFns<PrivateServiceConnectConnectivity> = {
  encode(message: PrivateServiceConnectConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serviceAttachment !== "") {
      writer.uint32(10).string(message.serviceAttachment);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateServiceConnectConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateServiceConnectConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.serviceAttachment = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateServiceConnectConnectivity {
    return { serviceAttachment: isSet(object.serviceAttachment) ? globalThis.String(object.serviceAttachment) : "" };
  },

  toJSON(message: PrivateServiceConnectConnectivity): unknown {
    const obj: any = {};
    if (message.serviceAttachment !== "") {
      obj.serviceAttachment = message.serviceAttachment;
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateServiceConnectConnectivity>): PrivateServiceConnectConnectivity {
    return PrivateServiceConnectConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateServiceConnectConnectivity>): PrivateServiceConnectConnectivity {
    const message = createBasePrivateServiceConnectConnectivity();
    message.serviceAttachment = object.serviceAttachment ?? "";
    return message;
  },
};

function createBaseReverseSshConnectivity(): ReverseSshConnectivity {
  return { vmIp: "", vmPort: 0, vm: "", vpc: "" };
}

export const ReverseSshConnectivity: MessageFns<ReverseSshConnectivity> = {
  encode(message: ReverseSshConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmIp !== "") {
      writer.uint32(10).string(message.vmIp);
    }
    if (message.vmPort !== 0) {
      writer.uint32(16).int32(message.vmPort);
    }
    if (message.vm !== "") {
      writer.uint32(26).string(message.vm);
    }
    if (message.vpc !== "") {
      writer.uint32(34).string(message.vpc);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReverseSshConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReverseSshConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vmIp = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.vmPort = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.vm = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.vpc = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReverseSshConnectivity {
    return {
      vmIp: isSet(object.vmIp) ? globalThis.String(object.vmIp) : "",
      vmPort: isSet(object.vmPort) ? globalThis.Number(object.vmPort) : 0,
      vm: isSet(object.vm) ? globalThis.String(object.vm) : "",
      vpc: isSet(object.vpc) ? globalThis.String(object.vpc) : "",
    };
  },

  toJSON(message: ReverseSshConnectivity): unknown {
    const obj: any = {};
    if (message.vmIp !== "") {
      obj.vmIp = message.vmIp;
    }
    if (message.vmPort !== 0) {
      obj.vmPort = Math.round(message.vmPort);
    }
    if (message.vm !== "") {
      obj.vm = message.vm;
    }
    if (message.vpc !== "") {
      obj.vpc = message.vpc;
    }
    return obj;
  },

  create(base?: DeepPartial<ReverseSshConnectivity>): ReverseSshConnectivity {
    return ReverseSshConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReverseSshConnectivity>): ReverseSshConnectivity {
    const message = createBaseReverseSshConnectivity();
    message.vmIp = object.vmIp ?? "";
    message.vmPort = object.vmPort ?? 0;
    message.vm = object.vm ?? "";
    message.vpc = object.vpc ?? "";
    return message;
  },
};

function createBaseVpcPeeringConnectivity(): VpcPeeringConnectivity {
  return { vpc: "" };
}

export const VpcPeeringConnectivity: MessageFns<VpcPeeringConnectivity> = {
  encode(message: VpcPeeringConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vpc !== "") {
      writer.uint32(10).string(message.vpc);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VpcPeeringConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVpcPeeringConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vpc = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VpcPeeringConnectivity {
    return { vpc: isSet(object.vpc) ? globalThis.String(object.vpc) : "" };
  },

  toJSON(message: VpcPeeringConnectivity): unknown {
    const obj: any = {};
    if (message.vpc !== "") {
      obj.vpc = message.vpc;
    }
    return obj;
  },

  create(base?: DeepPartial<VpcPeeringConnectivity>): VpcPeeringConnectivity {
    return VpcPeeringConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VpcPeeringConnectivity>): VpcPeeringConnectivity {
    const message = createBaseVpcPeeringConnectivity();
    message.vpc = object.vpc ?? "";
    return message;
  },
};

function createBaseForwardSshTunnelConnectivity(): ForwardSshTunnelConnectivity {
  return { hostname: "", username: "", port: 0, password: undefined, privateKey: undefined };
}

export const ForwardSshTunnelConnectivity: MessageFns<ForwardSshTunnelConnectivity> = {
  encode(message: ForwardSshTunnelConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hostname !== "") {
      writer.uint32(10).string(message.hostname);
    }
    if (message.username !== "") {
      writer.uint32(18).string(message.username);
    }
    if (message.port !== 0) {
      writer.uint32(24).int32(message.port);
    }
    if (message.password !== undefined) {
      writer.uint32(802).string(message.password);
    }
    if (message.privateKey !== undefined) {
      writer.uint32(810).string(message.privateKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ForwardSshTunnelConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseForwardSshTunnelConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hostname = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.username = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.password = reader.string();
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.privateKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ForwardSshTunnelConnectivity {
    return {
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      password: isSet(object.password) ? globalThis.String(object.password) : undefined,
      privateKey: isSet(object.privateKey) ? globalThis.String(object.privateKey) : undefined,
    };
  },

  toJSON(message: ForwardSshTunnelConnectivity): unknown {
    const obj: any = {};
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.password !== undefined) {
      obj.password = message.password;
    }
    if (message.privateKey !== undefined) {
      obj.privateKey = message.privateKey;
    }
    return obj;
  },

  create(base?: DeepPartial<ForwardSshTunnelConnectivity>): ForwardSshTunnelConnectivity {
    return ForwardSshTunnelConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ForwardSshTunnelConnectivity>): ForwardSshTunnelConnectivity {
    const message = createBaseForwardSshTunnelConnectivity();
    message.hostname = object.hostname ?? "";
    message.username = object.username ?? "";
    message.port = object.port ?? 0;
    message.password = object.password ?? undefined;
    message.privateKey = object.privateKey ?? undefined;
    return message;
  },
};

function createBaseStaticServiceIpConnectivity(): StaticServiceIpConnectivity {
  return {};
}

export const StaticServiceIpConnectivity: MessageFns<StaticServiceIpConnectivity> = {
  encode(_: StaticServiceIpConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StaticServiceIpConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStaticServiceIpConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): StaticServiceIpConnectivity {
    return {};
  },

  toJSON(_: StaticServiceIpConnectivity): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<StaticServiceIpConnectivity>): StaticServiceIpConnectivity {
    return StaticServiceIpConnectivity.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<StaticServiceIpConnectivity>): StaticServiceIpConnectivity {
    const message = createBaseStaticServiceIpConnectivity();
    return message;
  },
};

function createBasePrivateConnectivity(): PrivateConnectivity {
  return { privateConnection: "" };
}

export const PrivateConnectivity: MessageFns<PrivateConnectivity> = {
  encode(message: PrivateConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.privateConnection !== "") {
      writer.uint32(10).string(message.privateConnection);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.privateConnection = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateConnectivity {
    return { privateConnection: isSet(object.privateConnection) ? globalThis.String(object.privateConnection) : "" };
  },

  toJSON(message: PrivateConnectivity): unknown {
    const obj: any = {};
    if (message.privateConnection !== "") {
      obj.privateConnection = message.privateConnection;
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateConnectivity>): PrivateConnectivity {
    return PrivateConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateConnectivity>): PrivateConnectivity {
    const message = createBasePrivateConnectivity();
    message.privateConnection = object.privateConnection ?? "";
    return message;
  },
};

function createBaseDatabaseType(): DatabaseType {
  return { provider: 0, engine: 0 };
}

export const DatabaseType: MessageFns<DatabaseType> = {
  encode(message: DatabaseType, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.provider !== 0) {
      writer.uint32(8).int32(message.provider);
    }
    if (message.engine !== 0) {
      writer.uint32(16).int32(message.engine);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseType {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseType();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.provider = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.engine = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseType {
    return {
      provider: isSet(object.provider) ? databaseProviderFromJSON(object.provider) : 0,
      engine: isSet(object.engine) ? databaseEngineFromJSON(object.engine) : 0,
    };
  },

  toJSON(message: DatabaseType): unknown {
    const obj: any = {};
    if (message.provider !== 0) {
      obj.provider = databaseProviderToJSON(message.provider);
    }
    if (message.engine !== 0) {
      obj.engine = databaseEngineToJSON(message.engine);
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseType>): DatabaseType {
    return DatabaseType.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseType>): DatabaseType {
    const message = createBaseDatabaseType();
    message.provider = object.provider ?? 0;
    message.engine = object.engine ?? 0;
    return message;
  },
};

function createBaseMigrationJob(): MigrationJob {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    displayName: "",
    state: 0,
    phase: 0,
    type: 0,
    dumpPath: "",
    dumpFlags: undefined,
    source: "",
    destination: "",
    reverseSshConnectivity: undefined,
    vpcPeeringConnectivity: undefined,
    staticIpConnectivity: undefined,
    duration: undefined,
    error: undefined,
    sourceDatabase: undefined,
    destinationDatabase: undefined,
    endTime: undefined,
    conversionWorkspace: undefined,
    filter: "",
    cmekKeyName: "",
    performanceConfig: undefined,
  };
}

export const MigrationJob: MessageFns<MigrationJob> = {
  encode(message: MigrationJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      MigrationJob_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.phase !== 0) {
      writer.uint32(56).int32(message.phase);
    }
    if (message.type !== 0) {
      writer.uint32(64).int32(message.type);
    }
    if (message.dumpPath !== "") {
      writer.uint32(74).string(message.dumpPath);
    }
    if (message.dumpFlags !== undefined) {
      MigrationJob_DumpFlags.encode(message.dumpFlags, writer.uint32(138).fork()).join();
    }
    if (message.source !== "") {
      writer.uint32(82).string(message.source);
    }
    if (message.destination !== "") {
      writer.uint32(90).string(message.destination);
    }
    if (message.reverseSshConnectivity !== undefined) {
      ReverseSshConnectivity.encode(message.reverseSshConnectivity, writer.uint32(810).fork()).join();
    }
    if (message.vpcPeeringConnectivity !== undefined) {
      VpcPeeringConnectivity.encode(message.vpcPeeringConnectivity, writer.uint32(818).fork()).join();
    }
    if (message.staticIpConnectivity !== undefined) {
      StaticIpConnectivity.encode(message.staticIpConnectivity, writer.uint32(826).fork()).join();
    }
    if (message.duration !== undefined) {
      Duration.encode(message.duration, writer.uint32(98).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(106).fork()).join();
    }
    if (message.sourceDatabase !== undefined) {
      DatabaseType.encode(message.sourceDatabase, writer.uint32(114).fork()).join();
    }
    if (message.destinationDatabase !== undefined) {
      DatabaseType.encode(message.destinationDatabase, writer.uint32(122).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(130).fork()).join();
    }
    if (message.conversionWorkspace !== undefined) {
      ConversionWorkspaceInfo.encode(message.conversionWorkspace, writer.uint32(146).fork()).join();
    }
    if (message.filter !== "") {
      writer.uint32(162).string(message.filter);
    }
    if (message.cmekKeyName !== "") {
      writer.uint32(170).string(message.cmekKeyName);
    }
    if (message.performanceConfig !== undefined) {
      MigrationJob_PerformanceConfig.encode(message.performanceConfig, writer.uint32(178).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = MigrationJob_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.phase = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.dumpPath = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.dumpFlags = MigrationJob_DumpFlags.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.source = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.destination = reader.string();
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.reverseSshConnectivity = ReverseSshConnectivity.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.vpcPeeringConnectivity = VpcPeeringConnectivity.decode(reader, reader.uint32());
          continue;
        case 103:
          if (tag !== 826) {
            break;
          }

          message.staticIpConnectivity = StaticIpConnectivity.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.duration = Duration.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.sourceDatabase = DatabaseType.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.destinationDatabase = DatabaseType.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.conversionWorkspace = ConversionWorkspaceInfo.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.cmekKeyName = reader.string();
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.performanceConfig = MigrationJob_PerformanceConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationJob {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? migrationJob_StateFromJSON(object.state) : 0,
      phase: isSet(object.phase) ? migrationJob_PhaseFromJSON(object.phase) : 0,
      type: isSet(object.type) ? migrationJob_TypeFromJSON(object.type) : 0,
      dumpPath: isSet(object.dumpPath) ? globalThis.String(object.dumpPath) : "",
      dumpFlags: isSet(object.dumpFlags) ? MigrationJob_DumpFlags.fromJSON(object.dumpFlags) : undefined,
      source: isSet(object.source) ? globalThis.String(object.source) : "",
      destination: isSet(object.destination) ? globalThis.String(object.destination) : "",
      reverseSshConnectivity: isSet(object.reverseSshConnectivity)
        ? ReverseSshConnectivity.fromJSON(object.reverseSshConnectivity)
        : undefined,
      vpcPeeringConnectivity: isSet(object.vpcPeeringConnectivity)
        ? VpcPeeringConnectivity.fromJSON(object.vpcPeeringConnectivity)
        : undefined,
      staticIpConnectivity: isSet(object.staticIpConnectivity)
        ? StaticIpConnectivity.fromJSON(object.staticIpConnectivity)
        : undefined,
      duration: isSet(object.duration) ? Duration.fromJSON(object.duration) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      sourceDatabase: isSet(object.sourceDatabase) ? DatabaseType.fromJSON(object.sourceDatabase) : undefined,
      destinationDatabase: isSet(object.destinationDatabase)
        ? DatabaseType.fromJSON(object.destinationDatabase)
        : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      conversionWorkspace: isSet(object.conversionWorkspace)
        ? ConversionWorkspaceInfo.fromJSON(object.conversionWorkspace)
        : undefined,
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      cmekKeyName: isSet(object.cmekKeyName) ? globalThis.String(object.cmekKeyName) : "",
      performanceConfig: isSet(object.performanceConfig)
        ? MigrationJob_PerformanceConfig.fromJSON(object.performanceConfig)
        : undefined,
    };
  },

  toJSON(message: MigrationJob): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = migrationJob_StateToJSON(message.state);
    }
    if (message.phase !== 0) {
      obj.phase = migrationJob_PhaseToJSON(message.phase);
    }
    if (message.type !== 0) {
      obj.type = migrationJob_TypeToJSON(message.type);
    }
    if (message.dumpPath !== "") {
      obj.dumpPath = message.dumpPath;
    }
    if (message.dumpFlags !== undefined) {
      obj.dumpFlags = MigrationJob_DumpFlags.toJSON(message.dumpFlags);
    }
    if (message.source !== "") {
      obj.source = message.source;
    }
    if (message.destination !== "") {
      obj.destination = message.destination;
    }
    if (message.reverseSshConnectivity !== undefined) {
      obj.reverseSshConnectivity = ReverseSshConnectivity.toJSON(message.reverseSshConnectivity);
    }
    if (message.vpcPeeringConnectivity !== undefined) {
      obj.vpcPeeringConnectivity = VpcPeeringConnectivity.toJSON(message.vpcPeeringConnectivity);
    }
    if (message.staticIpConnectivity !== undefined) {
      obj.staticIpConnectivity = StaticIpConnectivity.toJSON(message.staticIpConnectivity);
    }
    if (message.duration !== undefined) {
      obj.duration = Duration.toJSON(message.duration);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.sourceDatabase !== undefined) {
      obj.sourceDatabase = DatabaseType.toJSON(message.sourceDatabase);
    }
    if (message.destinationDatabase !== undefined) {
      obj.destinationDatabase = DatabaseType.toJSON(message.destinationDatabase);
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.conversionWorkspace !== undefined) {
      obj.conversionWorkspace = ConversionWorkspaceInfo.toJSON(message.conversionWorkspace);
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.cmekKeyName !== "") {
      obj.cmekKeyName = message.cmekKeyName;
    }
    if (message.performanceConfig !== undefined) {
      obj.performanceConfig = MigrationJob_PerformanceConfig.toJSON(message.performanceConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationJob>): MigrationJob {
    return MigrationJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationJob>): MigrationJob {
    const message = createBaseMigrationJob();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.phase = object.phase ?? 0;
    message.type = object.type ?? 0;
    message.dumpPath = object.dumpPath ?? "";
    message.dumpFlags = (object.dumpFlags !== undefined && object.dumpFlags !== null)
      ? MigrationJob_DumpFlags.fromPartial(object.dumpFlags)
      : undefined;
    message.source = object.source ?? "";
    message.destination = object.destination ?? "";
    message.reverseSshConnectivity =
      (object.reverseSshConnectivity !== undefined && object.reverseSshConnectivity !== null)
        ? ReverseSshConnectivity.fromPartial(object.reverseSshConnectivity)
        : undefined;
    message.vpcPeeringConnectivity =
      (object.vpcPeeringConnectivity !== undefined && object.vpcPeeringConnectivity !== null)
        ? VpcPeeringConnectivity.fromPartial(object.vpcPeeringConnectivity)
        : undefined;
    message.staticIpConnectivity = (object.staticIpConnectivity !== undefined && object.staticIpConnectivity !== null)
      ? StaticIpConnectivity.fromPartial(object.staticIpConnectivity)
      : undefined;
    message.duration = (object.duration !== undefined && object.duration !== null)
      ? Duration.fromPartial(object.duration)
      : undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.sourceDatabase = (object.sourceDatabase !== undefined && object.sourceDatabase !== null)
      ? DatabaseType.fromPartial(object.sourceDatabase)
      : undefined;
    message.destinationDatabase = (object.destinationDatabase !== undefined && object.destinationDatabase !== null)
      ? DatabaseType.fromPartial(object.destinationDatabase)
      : undefined;
    message.endTime = object.endTime ?? undefined;
    message.conversionWorkspace = (object.conversionWorkspace !== undefined && object.conversionWorkspace !== null)
      ? ConversionWorkspaceInfo.fromPartial(object.conversionWorkspace)
      : undefined;
    message.filter = object.filter ?? "";
    message.cmekKeyName = object.cmekKeyName ?? "";
    message.performanceConfig = (object.performanceConfig !== undefined && object.performanceConfig !== null)
      ? MigrationJob_PerformanceConfig.fromPartial(object.performanceConfig)
      : undefined;
    return message;
  },
};

function createBaseMigrationJob_DumpFlag(): MigrationJob_DumpFlag {
  return { name: "", value: "" };
}

export const MigrationJob_DumpFlag: MessageFns<MigrationJob_DumpFlag> = {
  encode(message: MigrationJob_DumpFlag, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationJob_DumpFlag {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationJob_DumpFlag();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationJob_DumpFlag {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: MigrationJob_DumpFlag): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationJob_DumpFlag>): MigrationJob_DumpFlag {
    return MigrationJob_DumpFlag.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationJob_DumpFlag>): MigrationJob_DumpFlag {
    const message = createBaseMigrationJob_DumpFlag();
    message.name = object.name ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMigrationJob_DumpFlags(): MigrationJob_DumpFlags {
  return { dumpFlags: [] };
}

export const MigrationJob_DumpFlags: MessageFns<MigrationJob_DumpFlags> = {
  encode(message: MigrationJob_DumpFlags, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dumpFlags) {
      MigrationJob_DumpFlag.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationJob_DumpFlags {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationJob_DumpFlags();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dumpFlags.push(MigrationJob_DumpFlag.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationJob_DumpFlags {
    return {
      dumpFlags: globalThis.Array.isArray(object?.dumpFlags)
        ? object.dumpFlags.map((e: any) => MigrationJob_DumpFlag.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MigrationJob_DumpFlags): unknown {
    const obj: any = {};
    if (message.dumpFlags?.length) {
      obj.dumpFlags = message.dumpFlags.map((e) => MigrationJob_DumpFlag.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationJob_DumpFlags>): MigrationJob_DumpFlags {
    return MigrationJob_DumpFlags.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationJob_DumpFlags>): MigrationJob_DumpFlags {
    const message = createBaseMigrationJob_DumpFlags();
    message.dumpFlags = object.dumpFlags?.map((e) => MigrationJob_DumpFlag.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMigrationJob_PerformanceConfig(): MigrationJob_PerformanceConfig {
  return { dumpParallelLevel: 0 };
}

export const MigrationJob_PerformanceConfig: MessageFns<MigrationJob_PerformanceConfig> = {
  encode(message: MigrationJob_PerformanceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dumpParallelLevel !== 0) {
      writer.uint32(8).int32(message.dumpParallelLevel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationJob_PerformanceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationJob_PerformanceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.dumpParallelLevel = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationJob_PerformanceConfig {
    return {
      dumpParallelLevel: isSet(object.dumpParallelLevel)
        ? migrationJob_PerformanceConfig_DumpParallelLevelFromJSON(object.dumpParallelLevel)
        : 0,
    };
  },

  toJSON(message: MigrationJob_PerformanceConfig): unknown {
    const obj: any = {};
    if (message.dumpParallelLevel !== 0) {
      obj.dumpParallelLevel = migrationJob_PerformanceConfig_DumpParallelLevelToJSON(message.dumpParallelLevel);
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationJob_PerformanceConfig>): MigrationJob_PerformanceConfig {
    return MigrationJob_PerformanceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationJob_PerformanceConfig>): MigrationJob_PerformanceConfig {
    const message = createBaseMigrationJob_PerformanceConfig();
    message.dumpParallelLevel = object.dumpParallelLevel ?? 0;
    return message;
  },
};

function createBaseMigrationJob_LabelsEntry(): MigrationJob_LabelsEntry {
  return { key: "", value: "" };
}

export const MigrationJob_LabelsEntry: MessageFns<MigrationJob_LabelsEntry> = {
  encode(message: MigrationJob_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationJob_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationJob_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationJob_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: MigrationJob_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationJob_LabelsEntry>): MigrationJob_LabelsEntry {
    return MigrationJob_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationJob_LabelsEntry>): MigrationJob_LabelsEntry {
    const message = createBaseMigrationJob_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseConversionWorkspaceInfo(): ConversionWorkspaceInfo {
  return { name: "", commitId: "" };
}

export const ConversionWorkspaceInfo: MessageFns<ConversionWorkspaceInfo> = {
  encode(message: ConversionWorkspaceInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.commitId !== "") {
      writer.uint32(18).string(message.commitId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConversionWorkspaceInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConversionWorkspaceInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConversionWorkspaceInfo {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      commitId: isSet(object.commitId) ? globalThis.String(object.commitId) : "",
    };
  },

  toJSON(message: ConversionWorkspaceInfo): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.commitId !== "") {
      obj.commitId = message.commitId;
    }
    return obj;
  },

  create(base?: DeepPartial<ConversionWorkspaceInfo>): ConversionWorkspaceInfo {
    return ConversionWorkspaceInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConversionWorkspaceInfo>): ConversionWorkspaceInfo {
    const message = createBaseConversionWorkspaceInfo();
    message.name = object.name ?? "";
    message.commitId = object.commitId ?? "";
    return message;
  },
};

function createBaseConnectionProfile(): ConnectionProfile {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    state: 0,
    displayName: "",
    mysql: undefined,
    postgresql: undefined,
    oracle: undefined,
    cloudsql: undefined,
    alloydb: undefined,
    error: undefined,
    provider: 0,
  };
}

export const ConnectionProfile: MessageFns<ConnectionProfile> = {
  encode(message: ConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ConnectionProfile_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    if (message.mysql !== undefined) {
      MySqlConnectionProfile.encode(message.mysql, writer.uint32(802).fork()).join();
    }
    if (message.postgresql !== undefined) {
      PostgreSqlConnectionProfile.encode(message.postgresql, writer.uint32(810).fork()).join();
    }
    if (message.oracle !== undefined) {
      OracleConnectionProfile.encode(message.oracle, writer.uint32(834).fork()).join();
    }
    if (message.cloudsql !== undefined) {
      CloudSqlConnectionProfile.encode(message.cloudsql, writer.uint32(818).fork()).join();
    }
    if (message.alloydb !== undefined) {
      AlloyDbConnectionProfile.encode(message.alloydb, writer.uint32(842).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(58).fork()).join();
    }
    if (message.provider !== 0) {
      writer.uint32(64).int32(message.provider);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = ConnectionProfile_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.mysql = MySqlConnectionProfile.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.postgresql = PostgreSqlConnectionProfile.decode(reader, reader.uint32());
          continue;
        case 104:
          if (tag !== 834) {
            break;
          }

          message.oracle = OracleConnectionProfile.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.cloudsql = CloudSqlConnectionProfile.decode(reader, reader.uint32());
          continue;
        case 105:
          if (tag !== 842) {
            break;
          }

          message.alloydb = AlloyDbConnectionProfile.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.provider = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConnectionProfile {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      state: isSet(object.state) ? connectionProfile_StateFromJSON(object.state) : 0,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      mysql: isSet(object.mysql) ? MySqlConnectionProfile.fromJSON(object.mysql) : undefined,
      postgresql: isSet(object.postgresql) ? PostgreSqlConnectionProfile.fromJSON(object.postgresql) : undefined,
      oracle: isSet(object.oracle) ? OracleConnectionProfile.fromJSON(object.oracle) : undefined,
      cloudsql: isSet(object.cloudsql) ? CloudSqlConnectionProfile.fromJSON(object.cloudsql) : undefined,
      alloydb: isSet(object.alloydb) ? AlloyDbConnectionProfile.fromJSON(object.alloydb) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      provider: isSet(object.provider) ? databaseProviderFromJSON(object.provider) : 0,
    };
  },

  toJSON(message: ConnectionProfile): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.state !== 0) {
      obj.state = connectionProfile_StateToJSON(message.state);
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.mysql !== undefined) {
      obj.mysql = MySqlConnectionProfile.toJSON(message.mysql);
    }
    if (message.postgresql !== undefined) {
      obj.postgresql = PostgreSqlConnectionProfile.toJSON(message.postgresql);
    }
    if (message.oracle !== undefined) {
      obj.oracle = OracleConnectionProfile.toJSON(message.oracle);
    }
    if (message.cloudsql !== undefined) {
      obj.cloudsql = CloudSqlConnectionProfile.toJSON(message.cloudsql);
    }
    if (message.alloydb !== undefined) {
      obj.alloydb = AlloyDbConnectionProfile.toJSON(message.alloydb);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.provider !== 0) {
      obj.provider = databaseProviderToJSON(message.provider);
    }
    return obj;
  },

  create(base?: DeepPartial<ConnectionProfile>): ConnectionProfile {
    return ConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConnectionProfile>): ConnectionProfile {
    const message = createBaseConnectionProfile();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.state = object.state ?? 0;
    message.displayName = object.displayName ?? "";
    message.mysql = (object.mysql !== undefined && object.mysql !== null)
      ? MySqlConnectionProfile.fromPartial(object.mysql)
      : undefined;
    message.postgresql = (object.postgresql !== undefined && object.postgresql !== null)
      ? PostgreSqlConnectionProfile.fromPartial(object.postgresql)
      : undefined;
    message.oracle = (object.oracle !== undefined && object.oracle !== null)
      ? OracleConnectionProfile.fromPartial(object.oracle)
      : undefined;
    message.cloudsql = (object.cloudsql !== undefined && object.cloudsql !== null)
      ? CloudSqlConnectionProfile.fromPartial(object.cloudsql)
      : undefined;
    message.alloydb = (object.alloydb !== undefined && object.alloydb !== null)
      ? AlloyDbConnectionProfile.fromPartial(object.alloydb)
      : undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.provider = object.provider ?? 0;
    return message;
  },
};

function createBaseConnectionProfile_LabelsEntry(): ConnectionProfile_LabelsEntry {
  return { key: "", value: "" };
}

export const ConnectionProfile_LabelsEntry: MessageFns<ConnectionProfile_LabelsEntry> = {
  encode(message: ConnectionProfile_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConnectionProfile_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnectionProfile_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConnectionProfile_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ConnectionProfile_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ConnectionProfile_LabelsEntry>): ConnectionProfile_LabelsEntry {
    return ConnectionProfile_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConnectionProfile_LabelsEntry>): ConnectionProfile_LabelsEntry {
    const message = createBaseConnectionProfile_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMigrationJobVerificationError(): MigrationJobVerificationError {
  return { errorCode: 0, errorMessage: "", errorDetailMessage: "" };
}

export const MigrationJobVerificationError: MessageFns<MigrationJobVerificationError> = {
  encode(message: MigrationJobVerificationError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.errorCode !== 0) {
      writer.uint32(8).int32(message.errorCode);
    }
    if (message.errorMessage !== "") {
      writer.uint32(18).string(message.errorMessage);
    }
    if (message.errorDetailMessage !== "") {
      writer.uint32(26).string(message.errorDetailMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationJobVerificationError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationJobVerificationError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.errorCode = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.errorMessage = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.errorDetailMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationJobVerificationError {
    return {
      errorCode: isSet(object.errorCode) ? migrationJobVerificationError_ErrorCodeFromJSON(object.errorCode) : 0,
      errorMessage: isSet(object.errorMessage) ? globalThis.String(object.errorMessage) : "",
      errorDetailMessage: isSet(object.errorDetailMessage) ? globalThis.String(object.errorDetailMessage) : "",
    };
  },

  toJSON(message: MigrationJobVerificationError): unknown {
    const obj: any = {};
    if (message.errorCode !== 0) {
      obj.errorCode = migrationJobVerificationError_ErrorCodeToJSON(message.errorCode);
    }
    if (message.errorMessage !== "") {
      obj.errorMessage = message.errorMessage;
    }
    if (message.errorDetailMessage !== "") {
      obj.errorDetailMessage = message.errorDetailMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<MigrationJobVerificationError>): MigrationJobVerificationError {
    return MigrationJobVerificationError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MigrationJobVerificationError>): MigrationJobVerificationError {
    const message = createBaseMigrationJobVerificationError();
    message.errorCode = object.errorCode ?? 0;
    message.errorMessage = object.errorMessage ?? "";
    message.errorDetailMessage = object.errorDetailMessage ?? "";
    return message;
  },
};

function createBasePrivateConnection(): PrivateConnection {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    displayName: "",
    state: 0,
    error: undefined,
    vpcPeeringConfig: undefined,
  };
}

export const PrivateConnection: MessageFns<PrivateConnection> = {
  encode(message: PrivateConnection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      PrivateConnection_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(58).fork()).join();
    }
    if (message.vpcPeeringConfig !== undefined) {
      VpcPeeringConfig.encode(message.vpcPeeringConfig, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateConnection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateConnection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = PrivateConnection_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.vpcPeeringConfig = VpcPeeringConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateConnection {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? privateConnection_StateFromJSON(object.state) : 0,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      vpcPeeringConfig: isSet(object.vpcPeeringConfig) ? VpcPeeringConfig.fromJSON(object.vpcPeeringConfig) : undefined,
    };
  },

  toJSON(message: PrivateConnection): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = privateConnection_StateToJSON(message.state);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.vpcPeeringConfig !== undefined) {
      obj.vpcPeeringConfig = VpcPeeringConfig.toJSON(message.vpcPeeringConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateConnection>): PrivateConnection {
    return PrivateConnection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateConnection>): PrivateConnection {
    const message = createBasePrivateConnection();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.vpcPeeringConfig = (object.vpcPeeringConfig !== undefined && object.vpcPeeringConfig !== null)
      ? VpcPeeringConfig.fromPartial(object.vpcPeeringConfig)
      : undefined;
    return message;
  },
};

function createBasePrivateConnection_LabelsEntry(): PrivateConnection_LabelsEntry {
  return { key: "", value: "" };
}

export const PrivateConnection_LabelsEntry: MessageFns<PrivateConnection_LabelsEntry> = {
  encode(message: PrivateConnection_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateConnection_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateConnection_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateConnection_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PrivateConnection_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateConnection_LabelsEntry>): PrivateConnection_LabelsEntry {
    return PrivateConnection_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateConnection_LabelsEntry>): PrivateConnection_LabelsEntry {
    const message = createBasePrivateConnection_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseVpcPeeringConfig(): VpcPeeringConfig {
  return { vpcName: "", subnet: "" };
}

export const VpcPeeringConfig: MessageFns<VpcPeeringConfig> = {
  encode(message: VpcPeeringConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vpcName !== "") {
      writer.uint32(10).string(message.vpcName);
    }
    if (message.subnet !== "") {
      writer.uint32(18).string(message.subnet);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VpcPeeringConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVpcPeeringConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vpcName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subnet = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VpcPeeringConfig {
    return {
      vpcName: isSet(object.vpcName) ? globalThis.String(object.vpcName) : "",
      subnet: isSet(object.subnet) ? globalThis.String(object.subnet) : "",
    };
  },

  toJSON(message: VpcPeeringConfig): unknown {
    const obj: any = {};
    if (message.vpcName !== "") {
      obj.vpcName = message.vpcName;
    }
    if (message.subnet !== "") {
      obj.subnet = message.subnet;
    }
    return obj;
  },

  create(base?: DeepPartial<VpcPeeringConfig>): VpcPeeringConfig {
    return VpcPeeringConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VpcPeeringConfig>): VpcPeeringConfig {
    const message = createBaseVpcPeeringConfig();
    message.vpcName = object.vpcName ?? "";
    message.subnet = object.subnet ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
