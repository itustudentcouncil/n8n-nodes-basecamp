// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/datacatalog/v1beta1/table_spec.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.cloud.datacatalog.v1beta1";

/** Table source type. */
export enum TableSourceType {
  /** TABLE_SOURCE_TYPE_UNSPECIFIED - Default unknown type. */
  TABLE_SOURCE_TYPE_UNSPECIFIED = 0,
  /** BIGQUERY_VIEW - Table view. */
  BIGQUERY_VIEW = 2,
  /** BIGQUERY_TABLE - BigQuery native table. */
  BIGQUERY_TABLE = 5,
  /** BIGQUERY_MATERIALIZED_VIEW - BigQuery materialized view. */
  BIGQUERY_MATERIALIZED_VIEW = 7,
  UNRECOGNIZED = -1,
}

export function tableSourceTypeFromJSON(object: any): TableSourceType {
  switch (object) {
    case 0:
    case "TABLE_SOURCE_TYPE_UNSPECIFIED":
      return TableSourceType.TABLE_SOURCE_TYPE_UNSPECIFIED;
    case 2:
    case "BIGQUERY_VIEW":
      return TableSourceType.BIGQUERY_VIEW;
    case 5:
    case "BIGQUERY_TABLE":
      return TableSourceType.BIGQUERY_TABLE;
    case 7:
    case "BIGQUERY_MATERIALIZED_VIEW":
      return TableSourceType.BIGQUERY_MATERIALIZED_VIEW;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TableSourceType.UNRECOGNIZED;
  }
}

export function tableSourceTypeToJSON(object: TableSourceType): string {
  switch (object) {
    case TableSourceType.TABLE_SOURCE_TYPE_UNSPECIFIED:
      return "TABLE_SOURCE_TYPE_UNSPECIFIED";
    case TableSourceType.BIGQUERY_VIEW:
      return "BIGQUERY_VIEW";
    case TableSourceType.BIGQUERY_TABLE:
      return "BIGQUERY_TABLE";
    case TableSourceType.BIGQUERY_MATERIALIZED_VIEW:
      return "BIGQUERY_MATERIALIZED_VIEW";
    case TableSourceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Describes a BigQuery table. */
export interface BigQueryTableSpec {
  /** Output only. The table source type. */
  tableSourceType: TableSourceType;
  /**
   * Table view specification. This field should only be populated if
   * `table_source_type` is `BIGQUERY_VIEW`.
   */
  viewSpec?:
    | ViewSpec
    | undefined;
  /**
   * Spec of a BigQuery table. This field should only be populated if
   * `table_source_type` is `BIGQUERY_TABLE`.
   */
  tableSpec?: TableSpec | undefined;
}

/** Table view specification. */
export interface ViewSpec {
  /** Output only. The query that defines the table view. */
  viewQuery: string;
}

/** Normal BigQuery table spec. */
export interface TableSpec {
  /**
   * Output only. If the table is a dated shard, i.e., with name pattern
   * `[prefix]YYYYMMDD`, `grouped_entry` is the Data Catalog resource name of
   * the date sharded grouped entry, for example,
   * `projects/{project_id}/locations/{location}/entrygroups/{entry_group_id}/entries/{entry_id}`.
   * Otherwise, `grouped_entry` is empty.
   */
  groupedEntry: string;
}

/**
 * Spec for a group of BigQuery tables with name pattern `[prefix]YYYYMMDD`.
 * Context:
 * https://cloud.google.com/bigquery/docs/partitioned-tables#partitioning_versus_sharding
 */
export interface BigQueryDateShardedSpec {
  /**
   * Output only. The Data Catalog resource name of the dataset entry the
   * current table belongs to, for example,
   * `projects/{project_id}/locations/{location}/entrygroups/{entry_group_id}/entries/{entry_id}`.
   */
  dataset: string;
  /**
   * Output only. The table name prefix of the shards. The name of any given
   * shard is
   * `[table_prefix]YYYYMMDD`, for example, for shard `MyTable20180101`, the
   * `table_prefix` is `MyTable`.
   */
  tablePrefix: string;
  /** Output only. Total number of shards. */
  shardCount: Long;
}

function createBaseBigQueryTableSpec(): BigQueryTableSpec {
  return { tableSourceType: 0, viewSpec: undefined, tableSpec: undefined };
}

export const BigQueryTableSpec: MessageFns<BigQueryTableSpec> = {
  encode(message: BigQueryTableSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableSourceType !== 0) {
      writer.uint32(8).int32(message.tableSourceType);
    }
    if (message.viewSpec !== undefined) {
      ViewSpec.encode(message.viewSpec, writer.uint32(18).fork()).join();
    }
    if (message.tableSpec !== undefined) {
      TableSpec.encode(message.tableSpec, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryTableSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryTableSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.tableSourceType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.viewSpec = ViewSpec.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tableSpec = TableSpec.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryTableSpec {
    return {
      tableSourceType: isSet(object.tableSourceType) ? tableSourceTypeFromJSON(object.tableSourceType) : 0,
      viewSpec: isSet(object.viewSpec) ? ViewSpec.fromJSON(object.viewSpec) : undefined,
      tableSpec: isSet(object.tableSpec) ? TableSpec.fromJSON(object.tableSpec) : undefined,
    };
  },

  toJSON(message: BigQueryTableSpec): unknown {
    const obj: any = {};
    if (message.tableSourceType !== 0) {
      obj.tableSourceType = tableSourceTypeToJSON(message.tableSourceType);
    }
    if (message.viewSpec !== undefined) {
      obj.viewSpec = ViewSpec.toJSON(message.viewSpec);
    }
    if (message.tableSpec !== undefined) {
      obj.tableSpec = TableSpec.toJSON(message.tableSpec);
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryTableSpec>): BigQueryTableSpec {
    return BigQueryTableSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryTableSpec>): BigQueryTableSpec {
    const message = createBaseBigQueryTableSpec();
    message.tableSourceType = object.tableSourceType ?? 0;
    message.viewSpec = (object.viewSpec !== undefined && object.viewSpec !== null)
      ? ViewSpec.fromPartial(object.viewSpec)
      : undefined;
    message.tableSpec = (object.tableSpec !== undefined && object.tableSpec !== null)
      ? TableSpec.fromPartial(object.tableSpec)
      : undefined;
    return message;
  },
};

function createBaseViewSpec(): ViewSpec {
  return { viewQuery: "" };
}

export const ViewSpec: MessageFns<ViewSpec> = {
  encode(message: ViewSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.viewQuery !== "") {
      writer.uint32(10).string(message.viewQuery);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ViewSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseViewSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.viewQuery = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ViewSpec {
    return { viewQuery: isSet(object.viewQuery) ? globalThis.String(object.viewQuery) : "" };
  },

  toJSON(message: ViewSpec): unknown {
    const obj: any = {};
    if (message.viewQuery !== "") {
      obj.viewQuery = message.viewQuery;
    }
    return obj;
  },

  create(base?: DeepPartial<ViewSpec>): ViewSpec {
    return ViewSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ViewSpec>): ViewSpec {
    const message = createBaseViewSpec();
    message.viewQuery = object.viewQuery ?? "";
    return message;
  },
};

function createBaseTableSpec(): TableSpec {
  return { groupedEntry: "" };
}

export const TableSpec: MessageFns<TableSpec> = {
  encode(message: TableSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.groupedEntry !== "") {
      writer.uint32(10).string(message.groupedEntry);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.groupedEntry = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableSpec {
    return { groupedEntry: isSet(object.groupedEntry) ? globalThis.String(object.groupedEntry) : "" };
  },

  toJSON(message: TableSpec): unknown {
    const obj: any = {};
    if (message.groupedEntry !== "") {
      obj.groupedEntry = message.groupedEntry;
    }
    return obj;
  },

  create(base?: DeepPartial<TableSpec>): TableSpec {
    return TableSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableSpec>): TableSpec {
    const message = createBaseTableSpec();
    message.groupedEntry = object.groupedEntry ?? "";
    return message;
  },
};

function createBaseBigQueryDateShardedSpec(): BigQueryDateShardedSpec {
  return { dataset: "", tablePrefix: "", shardCount: Long.ZERO };
}

export const BigQueryDateShardedSpec: MessageFns<BigQueryDateShardedSpec> = {
  encode(message: BigQueryDateShardedSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataset !== "") {
      writer.uint32(10).string(message.dataset);
    }
    if (message.tablePrefix !== "") {
      writer.uint32(18).string(message.tablePrefix);
    }
    if (!message.shardCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.shardCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDateShardedSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDateShardedSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataset = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tablePrefix = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.shardCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDateShardedSpec {
    return {
      dataset: isSet(object.dataset) ? globalThis.String(object.dataset) : "",
      tablePrefix: isSet(object.tablePrefix) ? globalThis.String(object.tablePrefix) : "",
      shardCount: isSet(object.shardCount) ? Long.fromValue(object.shardCount) : Long.ZERO,
    };
  },

  toJSON(message: BigQueryDateShardedSpec): unknown {
    const obj: any = {};
    if (message.dataset !== "") {
      obj.dataset = message.dataset;
    }
    if (message.tablePrefix !== "") {
      obj.tablePrefix = message.tablePrefix;
    }
    if (!message.shardCount.equals(Long.ZERO)) {
      obj.shardCount = (message.shardCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryDateShardedSpec>): BigQueryDateShardedSpec {
    return BigQueryDateShardedSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryDateShardedSpec>): BigQueryDateShardedSpec {
    const message = createBaseBigQueryDateShardedSpec();
    message.dataset = object.dataset ?? "";
    message.tablePrefix = object.tablePrefix ?? "";
    message.shardCount = (object.shardCount !== undefined && object.shardCount !== null)
      ? Long.fromValue(object.shardCount)
      : Long.ZERO;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
