// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataplex/v1/metadata.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Empty } from "../../../protobuf/empty.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.dataplex.v1";

/** Identifies the cloud system that manages the data storage. */
export enum StorageSystem {
  /** STORAGE_SYSTEM_UNSPECIFIED - Storage system unspecified. */
  STORAGE_SYSTEM_UNSPECIFIED = 0,
  /** CLOUD_STORAGE - The entity data is contained within a Cloud Storage bucket. */
  CLOUD_STORAGE = 1,
  /** BIGQUERY - The entity data is contained within a BigQuery dataset. */
  BIGQUERY = 2,
  UNRECOGNIZED = -1,
}

export function storageSystemFromJSON(object: any): StorageSystem {
  switch (object) {
    case 0:
    case "STORAGE_SYSTEM_UNSPECIFIED":
      return StorageSystem.STORAGE_SYSTEM_UNSPECIFIED;
    case 1:
    case "CLOUD_STORAGE":
      return StorageSystem.CLOUD_STORAGE;
    case 2:
    case "BIGQUERY":
      return StorageSystem.BIGQUERY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StorageSystem.UNRECOGNIZED;
  }
}

export function storageSystemToJSON(object: StorageSystem): string {
  switch (object) {
    case StorageSystem.STORAGE_SYSTEM_UNSPECIFIED:
      return "STORAGE_SYSTEM_UNSPECIFIED";
    case StorageSystem.CLOUD_STORAGE:
      return "CLOUD_STORAGE";
    case StorageSystem.BIGQUERY:
      return "BIGQUERY";
    case StorageSystem.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Create a metadata entity request. */
export interface CreateEntityRequest {
  /**
   * Required. The resource name of the parent zone:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}`.
   */
  parent: string;
  /** Required. Entity resource. */
  entity:
    | Entity
    | undefined;
  /**
   * Optional. Only validate the request, but do not perform mutations.
   * The default is false.
   */
  validateOnly: boolean;
}

/**
 * Update a metadata entity request.
 * The exiting entity will be fully replaced by the entity in the request.
 * The entity ID is mutable. To modify the ID, use the current entity ID in the
 * request URL and specify the new ID in the request body.
 */
export interface UpdateEntityRequest {
  /** Required. Update description. */
  entity:
    | Entity
    | undefined;
  /**
   * Optional. Only validate the request, but do not perform mutations.
   * The default is false.
   */
  validateOnly: boolean;
}

/** Delete a metadata entity request. */
export interface DeleteEntityRequest {
  /**
   * Required. The resource name of the entity:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`.
   */
  name: string;
  /**
   * Required. The etag associated with the entity, which can be retrieved with
   * a [GetEntity][] request.
   */
  etag: string;
}

/** List metadata entities request. */
export interface ListEntitiesRequest {
  /**
   * Required. The resource name of the parent zone:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}`.
   */
  parent: string;
  /** Required. Specify the entity view to make a partial list request. */
  view: ListEntitiesRequest_EntityView;
  /**
   * Optional. Maximum number of entities to return. The service may return
   * fewer than this value. If unspecified, 100 entities will be returned by
   * default. The maximum value is 500; larger values will will be truncated to
   * 500.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListEntities` call. Provide
   * this to retrieve the subsequent page. When paginating, all other parameters
   * provided to `ListEntities` must match the call that provided the
   * page token.
   */
  pageToken: string;
  /**
   * Optional. The following filter parameters can be added to the URL to limit
   * the entities returned by the API:
   *
   * - Entity ID: ?filter="id=entityID"
   * - Asset ID: ?filter="asset=assetID"
   * - Data path ?filter="data_path=gs://my-bucket"
   * - Is HIVE compatible: ?filter="hive_compatible=true"
   * - Is BigQuery compatible: ?filter="bigquery_compatible=true"
   */
  filter: string;
}

/** Entity views. */
export enum ListEntitiesRequest_EntityView {
  /**
   * ENTITY_VIEW_UNSPECIFIED - The default unset value. Return both table and fileset entities
   * if unspecified.
   */
  ENTITY_VIEW_UNSPECIFIED = 0,
  /** TABLES - Only list table entities. */
  TABLES = 1,
  /** FILESETS - Only list fileset entities. */
  FILESETS = 2,
  UNRECOGNIZED = -1,
}

export function listEntitiesRequest_EntityViewFromJSON(object: any): ListEntitiesRequest_EntityView {
  switch (object) {
    case 0:
    case "ENTITY_VIEW_UNSPECIFIED":
      return ListEntitiesRequest_EntityView.ENTITY_VIEW_UNSPECIFIED;
    case 1:
    case "TABLES":
      return ListEntitiesRequest_EntityView.TABLES;
    case 2:
    case "FILESETS":
      return ListEntitiesRequest_EntityView.FILESETS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ListEntitiesRequest_EntityView.UNRECOGNIZED;
  }
}

export function listEntitiesRequest_EntityViewToJSON(object: ListEntitiesRequest_EntityView): string {
  switch (object) {
    case ListEntitiesRequest_EntityView.ENTITY_VIEW_UNSPECIFIED:
      return "ENTITY_VIEW_UNSPECIFIED";
    case ListEntitiesRequest_EntityView.TABLES:
      return "TABLES";
    case ListEntitiesRequest_EntityView.FILESETS:
      return "FILESETS";
    case ListEntitiesRequest_EntityView.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** List metadata entities response. */
export interface ListEntitiesResponse {
  /** Entities in the specified parent zone. */
  entities: Entity[];
  /**
   * Token to retrieve the next page of results, or empty if there are no
   * remaining results in the list.
   */
  nextPageToken: string;
}

/** Get metadata entity request. */
export interface GetEntityRequest {
  /**
   * Required. The resource name of the entity:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}.`
   */
  name: string;
  /**
   * Optional. Used to select the subset of entity information to return.
   * Defaults to `BASIC`.
   */
  view: GetEntityRequest_EntityView;
}

/** Entity views for get entity partial result. */
export enum GetEntityRequest_EntityView {
  /** ENTITY_VIEW_UNSPECIFIED - The API will default to the `BASIC` view. */
  ENTITY_VIEW_UNSPECIFIED = 0,
  /** BASIC - Minimal view that does not include the schema. */
  BASIC = 1,
  /** SCHEMA - Include basic information and schema. */
  SCHEMA = 2,
  /** FULL - Include everything. Currently, this is the same as the SCHEMA view. */
  FULL = 4,
  UNRECOGNIZED = -1,
}

export function getEntityRequest_EntityViewFromJSON(object: any): GetEntityRequest_EntityView {
  switch (object) {
    case 0:
    case "ENTITY_VIEW_UNSPECIFIED":
      return GetEntityRequest_EntityView.ENTITY_VIEW_UNSPECIFIED;
    case 1:
    case "BASIC":
      return GetEntityRequest_EntityView.BASIC;
    case 2:
    case "SCHEMA":
      return GetEntityRequest_EntityView.SCHEMA;
    case 4:
    case "FULL":
      return GetEntityRequest_EntityView.FULL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return GetEntityRequest_EntityView.UNRECOGNIZED;
  }
}

export function getEntityRequest_EntityViewToJSON(object: GetEntityRequest_EntityView): string {
  switch (object) {
    case GetEntityRequest_EntityView.ENTITY_VIEW_UNSPECIFIED:
      return "ENTITY_VIEW_UNSPECIFIED";
    case GetEntityRequest_EntityView.BASIC:
      return "BASIC";
    case GetEntityRequest_EntityView.SCHEMA:
      return "SCHEMA";
    case GetEntityRequest_EntityView.FULL:
      return "FULL";
    case GetEntityRequest_EntityView.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** List metadata partitions request. */
export interface ListPartitionsRequest {
  /**
   * Required. The resource name of the parent entity:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`.
   */
  parent: string;
  /**
   * Optional. Maximum number of partitions to return. The service may return
   * fewer than this value. If unspecified, 100 partitions will be returned by
   * default. The maximum page size is 500; larger values will will be truncated
   * to 500.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListPartitions` call.
   * Provide this to retrieve the subsequent page. When paginating, all other
   * parameters provided to `ListPartitions` must match the call that provided
   * the page token.
   */
  pageToken: string;
  /**
   * Optional. Filter the partitions returned to the caller using a key value
   * pair expression. Supported operators and syntax:
   *
   * - logic operators: AND, OR
   * - comparison operators: <, >, >=, <= ,=, !=
   * - LIKE operators:
   *   - The right hand of a LIKE operator supports "." and
   *     "*" for wildcard searches, for example "value1 LIKE ".*oo.*"
   * - parenthetical grouping: ( )
   *
   * Sample filter expression: `?filter="key1 < value1 OR key2 > value2"
   *
   * **Notes:**
   *
   * - Keys to the left of operators are case insensitive.
   * - Partition results are sorted first by creation time, then by
   *   lexicographic order.
   * - Up to 20 key value filter pairs are allowed, but due to performance
   *   considerations, only the first 10 will be used as a filter.
   */
  filter: string;
}

/** Create metadata partition request. */
export interface CreatePartitionRequest {
  /**
   * Required. The resource name of the parent zone:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`.
   */
  parent: string;
  /** Required. Partition resource. */
  partition:
    | Partition
    | undefined;
  /**
   * Optional. Only validate the request, but do not perform mutations.
   * The default is false.
   */
  validateOnly: boolean;
}

/** Delete metadata partition request. */
export interface DeletePartitionRequest {
  /**
   * Required. The resource name of the partition.
   * format:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}/partitions/{partition_value_path}`.
   * The {partition_value_path} segment consists of an ordered sequence of
   * partition values separated by "/". All values must be provided.
   */
  name: string;
  /**
   * Optional. The etag associated with the partition.
   *
   * @deprecated
   */
  etag: string;
}

/** List metadata partitions response. */
export interface ListPartitionsResponse {
  /** Partitions under the specified parent entity. */
  partitions: Partition[];
  /**
   * Token to retrieve the next page of results, or empty if there are no
   * remaining results in the list.
   */
  nextPageToken: string;
}

/** Get metadata partition request. */
export interface GetPartitionRequest {
  /**
   * Required. The resource name of the partition:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}/partitions/{partition_value_path}`.
   * The {partition_value_path} segment consists of an ordered sequence of
   * partition values separated by "/". All values must be provided.
   */
  name: string;
}

/** Represents tables and fileset metadata contained within a zone. */
export interface Entity {
  /**
   * Output only. The resource name of the entity, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{id}`.
   */
  name: string;
  /** Optional. Display name must be shorter than or equal to 256 characters. */
  displayName: string;
  /**
   * Optional. User friendly longer description text. Must be shorter than or
   * equal to 1024 characters.
   */
  description: string;
  /** Output only. The time when the entity was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the entity was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Required. A user-provided entity ID. It is mutable, and will be used as the
   * published table name. Specifying a new ID in an update entity
   * request will override the existing value.
   * The ID must contain only letters (a-z, A-Z), numbers (0-9), and
   * underscores, and consist of 256 or fewer characters.
   */
  id: string;
  /**
   * Optional. The etag associated with the entity, which can be retrieved with
   * a [GetEntity][] request. Required for update and delete requests.
   */
  etag: string;
  /** Required. Immutable. The type of entity. */
  type: Entity_Type;
  /**
   * Required. Immutable. The ID of the asset associated with the storage
   * location containing the entity data. The entity must be with in the same
   * zone with the asset.
   */
  asset: string;
  /**
   * Required. Immutable. The storage path of the entity data.
   * For Cloud Storage data, this is the fully-qualified path to the entity,
   * such as `gs://bucket/path/to/data`. For BigQuery data, this is the name of
   * the table resource, such as
   * `projects/project_id/datasets/dataset_id/tables/table_id`.
   */
  dataPath: string;
  /**
   * Optional. The set of items within the data path constituting the data in
   * the entity, represented as a glob path. Example:
   * `gs://bucket/path/to/data/** /*.csv`.
   */
  dataPathPattern: string;
  /** Output only. The name of the associated Data Catalog entry. */
  catalogEntry: string;
  /** Required. Immutable. Identifies the storage system of the entity data. */
  system: StorageSystem;
  /**
   * Required. Identifies the storage format of the entity data.
   * It does not apply to entities with data stored in BigQuery.
   */
  format:
    | StorageFormat
    | undefined;
  /** Output only. Metadata stores that the entity is compatible with. */
  compatibility:
    | Entity_CompatibilityStatus
    | undefined;
  /**
   * Output only. Identifies the access mechanism to the entity. Not user
   * settable.
   */
  access:
    | StorageAccess
    | undefined;
  /**
   * Output only. System generated unique ID for the Entity. This ID will be
   * different if the Entity is deleted and re-created with the same name.
   */
  uid: string;
  /**
   * Required. The description of the data structure and layout.
   * The schema is not included in list responses. It is only included in
   * `SCHEMA` and `FULL` entity views of a `GetEntity` response.
   */
  schema: Schema | undefined;
}

/** The type of entity. */
export enum Entity_Type {
  /** TYPE_UNSPECIFIED - Type unspecified. */
  TYPE_UNSPECIFIED = 0,
  /** TABLE - Structured and semi-structured data. */
  TABLE = 1,
  /** FILESET - Unstructured data. */
  FILESET = 2,
  UNRECOGNIZED = -1,
}

export function entity_TypeFromJSON(object: any): Entity_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Entity_Type.TYPE_UNSPECIFIED;
    case 1:
    case "TABLE":
      return Entity_Type.TABLE;
    case 2:
    case "FILESET":
      return Entity_Type.FILESET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Entity_Type.UNRECOGNIZED;
  }
}

export function entity_TypeToJSON(object: Entity_Type): string {
  switch (object) {
    case Entity_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Entity_Type.TABLE:
      return "TABLE";
    case Entity_Type.FILESET:
      return "FILESET";
    case Entity_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Provides compatibility information for various metadata stores. */
export interface Entity_CompatibilityStatus {
  /** Output only. Whether this entity is compatible with Hive Metastore. */
  hiveMetastore:
    | Entity_CompatibilityStatus_Compatibility
    | undefined;
  /** Output only. Whether this entity is compatible with BigQuery. */
  bigquery: Entity_CompatibilityStatus_Compatibility | undefined;
}

/** Provides compatibility information for a specific metadata store. */
export interface Entity_CompatibilityStatus_Compatibility {
  /**
   * Output only. Whether the entity is compatible and can be represented in
   * the metadata store.
   */
  compatible: boolean;
  /**
   * Output only. Provides additional detail if the entity is incompatible
   * with the metadata store.
   */
  reason: string;
}

/** Represents partition metadata contained within entity instances. */
export interface Partition {
  /**
   * Output only. Partition values used in the HTTP URL must be
   * double encoded. For example, `url_encode(url_encode(value))` can be used
   * to encode "US:CA/CA#Sunnyvale so that the request URL ends
   * with "/partitions/US%253ACA/CA%2523Sunnyvale".
   * The name field in the response retains the encoded format.
   */
  name: string;
  /**
   * Required. Immutable. The set of values representing the partition, which
   * correspond to the partition schema defined in the parent entity.
   */
  values: string[];
  /**
   * Required. Immutable. The location of the entity data within the partition,
   * for example, `gs://bucket/path/to/entity/key1=value1/key2=value2`. Or
   * `projects/<project_id>/datasets/<dataset_id>/tables/<table_id>`
   */
  location: string;
  /**
   * Optional. The etag for this partition.
   *
   * @deprecated
   */
  etag: string;
}

/** Schema information describing the structure and layout of the data. */
export interface Schema {
  /**
   * Required. Set to `true` if user-managed or `false` if managed by Dataplex.
   * The default is `false` (managed by Dataplex).
   *
   * - Set to `false`to enable Dataplex discovery to update the schema.
   *   including new data discovery, schema inference, and schema evolution.
   *   Users retain the ability to input and edit the schema. Dataplex
   *   treats schema input by the user as though produced
   *   by a previous Dataplex discovery operation, and it will
   *   evolve the schema and take action based on that treatment.
   *
   * - Set to `true` to fully manage the entity
   *   schema. This setting guarantees that Dataplex will not
   *   change schema fields.
   */
  userManaged: boolean;
  /**
   * Optional. The sequence of fields describing data in table entities.
   * **Note:** BigQuery SchemaFields are immutable.
   */
  fields: Schema_SchemaField[];
  /**
   * Optional. The sequence of fields describing the partition structure in
   * entities. If this field is empty, there are no partitions within the data.
   */
  partitionFields: Schema_PartitionField[];
  /**
   * Optional. The structure of paths containing partition data within the
   * entity.
   */
  partitionStyle: Schema_PartitionStyle;
}

/** Type information for fields in schemas and partition schemas. */
export enum Schema_Type {
  /** TYPE_UNSPECIFIED - SchemaType unspecified. */
  TYPE_UNSPECIFIED = 0,
  /** BOOLEAN - Boolean field. */
  BOOLEAN = 1,
  /** BYTE - Single byte numeric field. */
  BYTE = 2,
  /** INT16 - 16-bit numeric field. */
  INT16 = 3,
  /** INT32 - 32-bit numeric field. */
  INT32 = 4,
  /** INT64 - 64-bit numeric field. */
  INT64 = 5,
  /** FLOAT - Floating point numeric field. */
  FLOAT = 6,
  /** DOUBLE - Double precision numeric field. */
  DOUBLE = 7,
  /** DECIMAL - Real value numeric field. */
  DECIMAL = 8,
  /** STRING - Sequence of characters field. */
  STRING = 9,
  /** BINARY - Sequence of bytes field. */
  BINARY = 10,
  /** TIMESTAMP - Date and time field. */
  TIMESTAMP = 11,
  /** DATE - Date field. */
  DATE = 12,
  /** TIME - Time field. */
  TIME = 13,
  /**
   * RECORD - Structured field. Nested fields that define the structure of the map.
   * If all nested fields are nullable, this field represents a union.
   */
  RECORD = 14,
  /** NULL - Null field that does not have values. */
  NULL = 100,
  UNRECOGNIZED = -1,
}

export function schema_TypeFromJSON(object: any): Schema_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Schema_Type.TYPE_UNSPECIFIED;
    case 1:
    case "BOOLEAN":
      return Schema_Type.BOOLEAN;
    case 2:
    case "BYTE":
      return Schema_Type.BYTE;
    case 3:
    case "INT16":
      return Schema_Type.INT16;
    case 4:
    case "INT32":
      return Schema_Type.INT32;
    case 5:
    case "INT64":
      return Schema_Type.INT64;
    case 6:
    case "FLOAT":
      return Schema_Type.FLOAT;
    case 7:
    case "DOUBLE":
      return Schema_Type.DOUBLE;
    case 8:
    case "DECIMAL":
      return Schema_Type.DECIMAL;
    case 9:
    case "STRING":
      return Schema_Type.STRING;
    case 10:
    case "BINARY":
      return Schema_Type.BINARY;
    case 11:
    case "TIMESTAMP":
      return Schema_Type.TIMESTAMP;
    case 12:
    case "DATE":
      return Schema_Type.DATE;
    case 13:
    case "TIME":
      return Schema_Type.TIME;
    case 14:
    case "RECORD":
      return Schema_Type.RECORD;
    case 100:
    case "NULL":
      return Schema_Type.NULL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Schema_Type.UNRECOGNIZED;
  }
}

export function schema_TypeToJSON(object: Schema_Type): string {
  switch (object) {
    case Schema_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Schema_Type.BOOLEAN:
      return "BOOLEAN";
    case Schema_Type.BYTE:
      return "BYTE";
    case Schema_Type.INT16:
      return "INT16";
    case Schema_Type.INT32:
      return "INT32";
    case Schema_Type.INT64:
      return "INT64";
    case Schema_Type.FLOAT:
      return "FLOAT";
    case Schema_Type.DOUBLE:
      return "DOUBLE";
    case Schema_Type.DECIMAL:
      return "DECIMAL";
    case Schema_Type.STRING:
      return "STRING";
    case Schema_Type.BINARY:
      return "BINARY";
    case Schema_Type.TIMESTAMP:
      return "TIMESTAMP";
    case Schema_Type.DATE:
      return "DATE";
    case Schema_Type.TIME:
      return "TIME";
    case Schema_Type.RECORD:
      return "RECORD";
    case Schema_Type.NULL:
      return "NULL";
    case Schema_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Additional qualifiers to define field semantics. */
export enum Schema_Mode {
  /** MODE_UNSPECIFIED - Mode unspecified. */
  MODE_UNSPECIFIED = 0,
  /** REQUIRED - The field has required semantics. */
  REQUIRED = 1,
  /** NULLABLE - The field has optional semantics, and may be null. */
  NULLABLE = 2,
  /** REPEATED - The field has repeated (0 or more) semantics, and is a list of values. */
  REPEATED = 3,
  UNRECOGNIZED = -1,
}

export function schema_ModeFromJSON(object: any): Schema_Mode {
  switch (object) {
    case 0:
    case "MODE_UNSPECIFIED":
      return Schema_Mode.MODE_UNSPECIFIED;
    case 1:
    case "REQUIRED":
      return Schema_Mode.REQUIRED;
    case 2:
    case "NULLABLE":
      return Schema_Mode.NULLABLE;
    case 3:
    case "REPEATED":
      return Schema_Mode.REPEATED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Schema_Mode.UNRECOGNIZED;
  }
}

export function schema_ModeToJSON(object: Schema_Mode): string {
  switch (object) {
    case Schema_Mode.MODE_UNSPECIFIED:
      return "MODE_UNSPECIFIED";
    case Schema_Mode.REQUIRED:
      return "REQUIRED";
    case Schema_Mode.NULLABLE:
      return "NULLABLE";
    case Schema_Mode.REPEATED:
      return "REPEATED";
    case Schema_Mode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The structure of paths within the entity, which represent partitions. */
export enum Schema_PartitionStyle {
  /** PARTITION_STYLE_UNSPECIFIED - PartitionStyle unspecified */
  PARTITION_STYLE_UNSPECIFIED = 0,
  /**
   * HIVE_COMPATIBLE - Partitions are hive-compatible.
   * Examples: `gs://bucket/path/to/table/dt=2019-10-31/lang=en`,
   * `gs://bucket/path/to/table/dt=2019-10-31/lang=en/late`.
   */
  HIVE_COMPATIBLE = 1,
  UNRECOGNIZED = -1,
}

export function schema_PartitionStyleFromJSON(object: any): Schema_PartitionStyle {
  switch (object) {
    case 0:
    case "PARTITION_STYLE_UNSPECIFIED":
      return Schema_PartitionStyle.PARTITION_STYLE_UNSPECIFIED;
    case 1:
    case "HIVE_COMPATIBLE":
      return Schema_PartitionStyle.HIVE_COMPATIBLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Schema_PartitionStyle.UNRECOGNIZED;
  }
}

export function schema_PartitionStyleToJSON(object: Schema_PartitionStyle): string {
  switch (object) {
    case Schema_PartitionStyle.PARTITION_STYLE_UNSPECIFIED:
      return "PARTITION_STYLE_UNSPECIFIED";
    case Schema_PartitionStyle.HIVE_COMPATIBLE:
      return "HIVE_COMPATIBLE";
    case Schema_PartitionStyle.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents a column field within a table schema. */
export interface Schema_SchemaField {
  /**
   * Required. The name of the field. Must contain only letters, numbers and
   * underscores, with a maximum length of 767 characters,
   * and must begin with a letter or underscore.
   */
  name: string;
  /**
   * Optional. User friendly field description. Must be less than or equal to
   * 1024 characters.
   */
  description: string;
  /** Required. The type of field. */
  type: Schema_Type;
  /** Required. Additional field semantics. */
  mode: Schema_Mode;
  /** Optional. Any nested field for complex types. */
  fields: Schema_SchemaField[];
}

/**
 * Represents a key field within the entity's partition structure. You could
 * have up to 20 partition fields, but only the first 10 partitions have the
 * filtering ability due to performance consideration. **Note:**
 * Partition fields are immutable.
 */
export interface Schema_PartitionField {
  /**
   * Required. Partition field name must consist of letters, numbers, and
   * underscores only, with a maximum of length of 256 characters, and must
   * begin with a letter or underscore..
   */
  name: string;
  /** Required. Immutable. The type of field. */
  type: Schema_Type;
}

/** Describes the format of the data within its storage location. */
export interface StorageFormat {
  /**
   * Output only. The data format associated with the stored data, which
   * represents content type values. The value is inferred from mime type.
   */
  format: StorageFormat_Format;
  /**
   * Optional. The compression type associated with the stored data.
   * If unspecified, the data is uncompressed.
   */
  compressionFormat: StorageFormat_CompressionFormat;
  /**
   * Required. The mime type descriptor for the data. Must match the pattern
   * {type}/{subtype}. Supported values:
   *
   * - application/x-parquet
   * - application/x-avro
   * - application/x-orc
   * - application/x-tfrecord
   * - application/x-parquet+iceberg
   * - application/x-avro+iceberg
   * - application/x-orc+iceberg
   * - application/json
   * - application/{subtypes}
   * - text/csv
   * - text/<subtypes>
   * - image/{image subtype}
   * - video/{video subtype}
   * - audio/{audio subtype}
   */
  mimeType: string;
  /** Optional. Additional information about CSV formatted data. */
  csv?:
    | StorageFormat_CsvOptions
    | undefined;
  /** Optional. Additional information about CSV formatted data. */
  json?:
    | StorageFormat_JsonOptions
    | undefined;
  /** Optional. Additional information about iceberg tables. */
  iceberg?: StorageFormat_IcebergOptions | undefined;
}

/** The specific file format of the data. */
export enum StorageFormat_Format {
  /** FORMAT_UNSPECIFIED - Format unspecified. */
  FORMAT_UNSPECIFIED = 0,
  /** PARQUET - Parquet-formatted structured data. */
  PARQUET = 1,
  /** AVRO - Avro-formatted structured data. */
  AVRO = 2,
  /** ORC - Orc-formatted structured data. */
  ORC = 3,
  /** CSV - Csv-formatted semi-structured data. */
  CSV = 100,
  /** JSON - Json-formatted semi-structured data. */
  JSON = 101,
  /** IMAGE - Image data formats (such as jpg and png). */
  IMAGE = 200,
  /** AUDIO - Audio data formats (such as mp3, and wav). */
  AUDIO = 201,
  /** VIDEO - Video data formats (such as mp4 and mpg). */
  VIDEO = 202,
  /** TEXT - Textual data formats (such as txt and xml). */
  TEXT = 203,
  /** TFRECORD - TensorFlow record format. */
  TFRECORD = 204,
  /** OTHER - Data that doesn't match a specific format. */
  OTHER = 1000,
  /** UNKNOWN - Data of an unknown format. */
  UNKNOWN = 1001,
  UNRECOGNIZED = -1,
}

export function storageFormat_FormatFromJSON(object: any): StorageFormat_Format {
  switch (object) {
    case 0:
    case "FORMAT_UNSPECIFIED":
      return StorageFormat_Format.FORMAT_UNSPECIFIED;
    case 1:
    case "PARQUET":
      return StorageFormat_Format.PARQUET;
    case 2:
    case "AVRO":
      return StorageFormat_Format.AVRO;
    case 3:
    case "ORC":
      return StorageFormat_Format.ORC;
    case 100:
    case "CSV":
      return StorageFormat_Format.CSV;
    case 101:
    case "JSON":
      return StorageFormat_Format.JSON;
    case 200:
    case "IMAGE":
      return StorageFormat_Format.IMAGE;
    case 201:
    case "AUDIO":
      return StorageFormat_Format.AUDIO;
    case 202:
    case "VIDEO":
      return StorageFormat_Format.VIDEO;
    case 203:
    case "TEXT":
      return StorageFormat_Format.TEXT;
    case 204:
    case "TFRECORD":
      return StorageFormat_Format.TFRECORD;
    case 1000:
    case "OTHER":
      return StorageFormat_Format.OTHER;
    case 1001:
    case "UNKNOWN":
      return StorageFormat_Format.UNKNOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StorageFormat_Format.UNRECOGNIZED;
  }
}

export function storageFormat_FormatToJSON(object: StorageFormat_Format): string {
  switch (object) {
    case StorageFormat_Format.FORMAT_UNSPECIFIED:
      return "FORMAT_UNSPECIFIED";
    case StorageFormat_Format.PARQUET:
      return "PARQUET";
    case StorageFormat_Format.AVRO:
      return "AVRO";
    case StorageFormat_Format.ORC:
      return "ORC";
    case StorageFormat_Format.CSV:
      return "CSV";
    case StorageFormat_Format.JSON:
      return "JSON";
    case StorageFormat_Format.IMAGE:
      return "IMAGE";
    case StorageFormat_Format.AUDIO:
      return "AUDIO";
    case StorageFormat_Format.VIDEO:
      return "VIDEO";
    case StorageFormat_Format.TEXT:
      return "TEXT";
    case StorageFormat_Format.TFRECORD:
      return "TFRECORD";
    case StorageFormat_Format.OTHER:
      return "OTHER";
    case StorageFormat_Format.UNKNOWN:
      return "UNKNOWN";
    case StorageFormat_Format.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The specific compressed file format of the data. */
export enum StorageFormat_CompressionFormat {
  /** COMPRESSION_FORMAT_UNSPECIFIED - CompressionFormat unspecified. Implies uncompressed data. */
  COMPRESSION_FORMAT_UNSPECIFIED = 0,
  /** GZIP - GZip compressed set of files. */
  GZIP = 2,
  /** BZIP2 - BZip2 compressed set of files. */
  BZIP2 = 3,
  UNRECOGNIZED = -1,
}

export function storageFormat_CompressionFormatFromJSON(object: any): StorageFormat_CompressionFormat {
  switch (object) {
    case 0:
    case "COMPRESSION_FORMAT_UNSPECIFIED":
      return StorageFormat_CompressionFormat.COMPRESSION_FORMAT_UNSPECIFIED;
    case 2:
    case "GZIP":
      return StorageFormat_CompressionFormat.GZIP;
    case 3:
    case "BZIP2":
      return StorageFormat_CompressionFormat.BZIP2;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StorageFormat_CompressionFormat.UNRECOGNIZED;
  }
}

export function storageFormat_CompressionFormatToJSON(object: StorageFormat_CompressionFormat): string {
  switch (object) {
    case StorageFormat_CompressionFormat.COMPRESSION_FORMAT_UNSPECIFIED:
      return "COMPRESSION_FORMAT_UNSPECIFIED";
    case StorageFormat_CompressionFormat.GZIP:
      return "GZIP";
    case StorageFormat_CompressionFormat.BZIP2:
      return "BZIP2";
    case StorageFormat_CompressionFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Describes CSV and similar semi-structured data formats. */
export interface StorageFormat_CsvOptions {
  /**
   * Optional. The character encoding of the data. Accepts "US-ASCII",
   * "UTF-8", and "ISO-8859-1". Defaults to UTF-8 if unspecified.
   */
  encoding: string;
  /**
   * Optional. The number of rows to interpret as header rows that should be
   * skipped when reading data rows. Defaults to 0.
   */
  headerRows: number;
  /** Optional. The delimiter used to separate values. Defaults to ','. */
  delimiter: string;
  /**
   * Optional. The character used to quote column values. Accepts '"'
   * (double quotation mark) or ''' (single quotation mark). Defaults to
   * '"' (double quotation mark) if unspecified.
   */
  quote: string;
}

/** Describes JSON data format. */
export interface StorageFormat_JsonOptions {
  /**
   * Optional. The character encoding of the data. Accepts "US-ASCII", "UTF-8"
   * and "ISO-8859-1". Defaults to UTF-8 if not specified.
   */
  encoding: string;
}

/** Describes Iceberg data format. */
export interface StorageFormat_IcebergOptions {
  /**
   * Optional. The location of where the iceberg metadata is present, must be
   * within the table path
   */
  metadataLocation: string;
}

/** Describes the access mechanism of the data within its storage location. */
export interface StorageAccess {
  /**
   * Output only. Describes the read access mechanism of the data. Not user
   * settable.
   */
  read: StorageAccess_AccessMode;
}

/** Access Mode determines how data stored within the Entity is read. */
export enum StorageAccess_AccessMode {
  /** ACCESS_MODE_UNSPECIFIED - Access mode unspecified. */
  ACCESS_MODE_UNSPECIFIED = 0,
  /** DIRECT - Default. Data is accessed directly using storage APIs. */
  DIRECT = 1,
  /** MANAGED - Data is accessed through a managed interface using BigQuery APIs. */
  MANAGED = 2,
  UNRECOGNIZED = -1,
}

export function storageAccess_AccessModeFromJSON(object: any): StorageAccess_AccessMode {
  switch (object) {
    case 0:
    case "ACCESS_MODE_UNSPECIFIED":
      return StorageAccess_AccessMode.ACCESS_MODE_UNSPECIFIED;
    case 1:
    case "DIRECT":
      return StorageAccess_AccessMode.DIRECT;
    case 2:
    case "MANAGED":
      return StorageAccess_AccessMode.MANAGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StorageAccess_AccessMode.UNRECOGNIZED;
  }
}

export function storageAccess_AccessModeToJSON(object: StorageAccess_AccessMode): string {
  switch (object) {
    case StorageAccess_AccessMode.ACCESS_MODE_UNSPECIFIED:
      return "ACCESS_MODE_UNSPECIFIED";
    case StorageAccess_AccessMode.DIRECT:
      return "DIRECT";
    case StorageAccess_AccessMode.MANAGED:
      return "MANAGED";
    case StorageAccess_AccessMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseCreateEntityRequest(): CreateEntityRequest {
  return { parent: "", entity: undefined, validateOnly: false };
}

export const CreateEntityRequest: MessageFns<CreateEntityRequest> = {
  encode(message: CreateEntityRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.entity !== undefined) {
      Entity.encode(message.entity, writer.uint32(26).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateEntityRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateEntityRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entity = Entity.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateEntityRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      entity: isSet(object.entity) ? Entity.fromJSON(object.entity) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: CreateEntityRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.entity !== undefined) {
      obj.entity = Entity.toJSON(message.entity);
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateEntityRequest>): CreateEntityRequest {
    return CreateEntityRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateEntityRequest>): CreateEntityRequest {
    const message = createBaseCreateEntityRequest();
    message.parent = object.parent ?? "";
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? Entity.fromPartial(object.entity)
      : undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseUpdateEntityRequest(): UpdateEntityRequest {
  return { entity: undefined, validateOnly: false };
}

export const UpdateEntityRequest: MessageFns<UpdateEntityRequest> = {
  encode(message: UpdateEntityRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== undefined) {
      Entity.encode(message.entity, writer.uint32(18).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(24).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateEntityRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateEntityRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entity = Entity.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateEntityRequest {
    return {
      entity: isSet(object.entity) ? Entity.fromJSON(object.entity) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: UpdateEntityRequest): unknown {
    const obj: any = {};
    if (message.entity !== undefined) {
      obj.entity = Entity.toJSON(message.entity);
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateEntityRequest>): UpdateEntityRequest {
    return UpdateEntityRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateEntityRequest>): UpdateEntityRequest {
    const message = createBaseUpdateEntityRequest();
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? Entity.fromPartial(object.entity)
      : undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseDeleteEntityRequest(): DeleteEntityRequest {
  return { name: "", etag: "" };
}

export const DeleteEntityRequest: MessageFns<DeleteEntityRequest> = {
  encode(message: DeleteEntityRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.etag !== "") {
      writer.uint32(18).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteEntityRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteEntityRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteEntityRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeleteEntityRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteEntityRequest>): DeleteEntityRequest {
    return DeleteEntityRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteEntityRequest>): DeleteEntityRequest {
    const message = createBaseDeleteEntityRequest();
    message.name = object.name ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseListEntitiesRequest(): ListEntitiesRequest {
  return { parent: "", view: 0, pageSize: 0, pageToken: "", filter: "" };
}

export const ListEntitiesRequest: MessageFns<ListEntitiesRequest> = {
  encode(message: ListEntitiesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.view !== 0) {
      writer.uint32(16).int32(message.view);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListEntitiesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListEntitiesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListEntitiesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      view: isSet(object.view) ? listEntitiesRequest_EntityViewFromJSON(object.view) : 0,
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListEntitiesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.view !== 0) {
      obj.view = listEntitiesRequest_EntityViewToJSON(message.view);
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListEntitiesRequest>): ListEntitiesRequest {
    return ListEntitiesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListEntitiesRequest>): ListEntitiesRequest {
    const message = createBaseListEntitiesRequest();
    message.parent = object.parent ?? "";
    message.view = object.view ?? 0;
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListEntitiesResponse(): ListEntitiesResponse {
  return { entities: [], nextPageToken: "" };
}

export const ListEntitiesResponse: MessageFns<ListEntitiesResponse> = {
  encode(message: ListEntitiesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entities) {
      Entity.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListEntitiesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListEntitiesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListEntitiesResponse {
    return {
      entities: globalThis.Array.isArray(object?.entities) ? object.entities.map((e: any) => Entity.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListEntitiesResponse): unknown {
    const obj: any = {};
    if (message.entities?.length) {
      obj.entities = message.entities.map((e) => Entity.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListEntitiesResponse>): ListEntitiesResponse {
    return ListEntitiesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListEntitiesResponse>): ListEntitiesResponse {
    const message = createBaseListEntitiesResponse();
    message.entities = object.entities?.map((e) => Entity.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetEntityRequest(): GetEntityRequest {
  return { name: "", view: 0 };
}

export const GetEntityRequest: MessageFns<GetEntityRequest> = {
  encode(message: GetEntityRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.view !== 0) {
      writer.uint32(16).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetEntityRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetEntityRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetEntityRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      view: isSet(object.view) ? getEntityRequest_EntityViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: GetEntityRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.view !== 0) {
      obj.view = getEntityRequest_EntityViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<GetEntityRequest>): GetEntityRequest {
    return GetEntityRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetEntityRequest>): GetEntityRequest {
    const message = createBaseGetEntityRequest();
    message.name = object.name ?? "";
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseListPartitionsRequest(): ListPartitionsRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "" };
}

export const ListPartitionsRequest: MessageFns<ListPartitionsRequest> = {
  encode(message: ListPartitionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListPartitionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListPartitionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListPartitionsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListPartitionsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListPartitionsRequest>): ListPartitionsRequest {
    return ListPartitionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListPartitionsRequest>): ListPartitionsRequest {
    const message = createBaseListPartitionsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseCreatePartitionRequest(): CreatePartitionRequest {
  return { parent: "", partition: undefined, validateOnly: false };
}

export const CreatePartitionRequest: MessageFns<CreatePartitionRequest> = {
  encode(message: CreatePartitionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.partition !== undefined) {
      Partition.encode(message.partition, writer.uint32(26).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreatePartitionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreatePartitionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.partition = Partition.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreatePartitionRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      partition: isSet(object.partition) ? Partition.fromJSON(object.partition) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: CreatePartitionRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.partition !== undefined) {
      obj.partition = Partition.toJSON(message.partition);
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<CreatePartitionRequest>): CreatePartitionRequest {
    return CreatePartitionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreatePartitionRequest>): CreatePartitionRequest {
    const message = createBaseCreatePartitionRequest();
    message.parent = object.parent ?? "";
    message.partition = (object.partition !== undefined && object.partition !== null)
      ? Partition.fromPartial(object.partition)
      : undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseDeletePartitionRequest(): DeletePartitionRequest {
  return { name: "", etag: "" };
}

export const DeletePartitionRequest: MessageFns<DeletePartitionRequest> = {
  encode(message: DeletePartitionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.etag !== "") {
      writer.uint32(18).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeletePartitionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeletePartitionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeletePartitionRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeletePartitionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeletePartitionRequest>): DeletePartitionRequest {
    return DeletePartitionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeletePartitionRequest>): DeletePartitionRequest {
    const message = createBaseDeletePartitionRequest();
    message.name = object.name ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseListPartitionsResponse(): ListPartitionsResponse {
  return { partitions: [], nextPageToken: "" };
}

export const ListPartitionsResponse: MessageFns<ListPartitionsResponse> = {
  encode(message: ListPartitionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.partitions) {
      Partition.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListPartitionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListPartitionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.partitions.push(Partition.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListPartitionsResponse {
    return {
      partitions: globalThis.Array.isArray(object?.partitions)
        ? object.partitions.map((e: any) => Partition.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListPartitionsResponse): unknown {
    const obj: any = {};
    if (message.partitions?.length) {
      obj.partitions = message.partitions.map((e) => Partition.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListPartitionsResponse>): ListPartitionsResponse {
    return ListPartitionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListPartitionsResponse>): ListPartitionsResponse {
    const message = createBaseListPartitionsResponse();
    message.partitions = object.partitions?.map((e) => Partition.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetPartitionRequest(): GetPartitionRequest {
  return { name: "" };
}

export const GetPartitionRequest: MessageFns<GetPartitionRequest> = {
  encode(message: GetPartitionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetPartitionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetPartitionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetPartitionRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetPartitionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetPartitionRequest>): GetPartitionRequest {
    return GetPartitionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetPartitionRequest>): GetPartitionRequest {
    const message = createBaseGetPartitionRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseEntity(): Entity {
  return {
    name: "",
    displayName: "",
    description: "",
    createTime: undefined,
    updateTime: undefined,
    id: "",
    etag: "",
    type: 0,
    asset: "",
    dataPath: "",
    dataPathPattern: "",
    catalogEntry: "",
    system: 0,
    format: undefined,
    compatibility: undefined,
    access: undefined,
    uid: "",
    schema: undefined,
  };
}

export const Entity: MessageFns<Entity> = {
  encode(message: Entity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(42).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(50).fork()).join();
    }
    if (message.id !== "") {
      writer.uint32(58).string(message.id);
    }
    if (message.etag !== "") {
      writer.uint32(66).string(message.etag);
    }
    if (message.type !== 0) {
      writer.uint32(80).int32(message.type);
    }
    if (message.asset !== "") {
      writer.uint32(90).string(message.asset);
    }
    if (message.dataPath !== "") {
      writer.uint32(98).string(message.dataPath);
    }
    if (message.dataPathPattern !== "") {
      writer.uint32(106).string(message.dataPathPattern);
    }
    if (message.catalogEntry !== "") {
      writer.uint32(114).string(message.catalogEntry);
    }
    if (message.system !== 0) {
      writer.uint32(120).int32(message.system);
    }
    if (message.format !== undefined) {
      StorageFormat.encode(message.format, writer.uint32(130).fork()).join();
    }
    if (message.compatibility !== undefined) {
      Entity_CompatibilityStatus.encode(message.compatibility, writer.uint32(154).fork()).join();
    }
    if (message.access !== undefined) {
      StorageAccess.encode(message.access, writer.uint32(170).fork()).join();
    }
    if (message.uid !== "") {
      writer.uint32(178).string(message.uid);
    }
    if (message.schema !== undefined) {
      Schema.encode(message.schema, writer.uint32(402).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.id = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.asset = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.dataPath = reader.string();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.dataPathPattern = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.catalogEntry = reader.string();
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.system = reader.int32() as any;
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.format = StorageFormat.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.compatibility = Entity_CompatibilityStatus.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.access = StorageAccess.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 50:
          if (tag !== 402) {
            break;
          }

          message.schema = Schema.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      type: isSet(object.type) ? entity_TypeFromJSON(object.type) : 0,
      asset: isSet(object.asset) ? globalThis.String(object.asset) : "",
      dataPath: isSet(object.dataPath) ? globalThis.String(object.dataPath) : "",
      dataPathPattern: isSet(object.dataPathPattern) ? globalThis.String(object.dataPathPattern) : "",
      catalogEntry: isSet(object.catalogEntry) ? globalThis.String(object.catalogEntry) : "",
      system: isSet(object.system) ? storageSystemFromJSON(object.system) : 0,
      format: isSet(object.format) ? StorageFormat.fromJSON(object.format) : undefined,
      compatibility: isSet(object.compatibility)
        ? Entity_CompatibilityStatus.fromJSON(object.compatibility)
        : undefined,
      access: isSet(object.access) ? StorageAccess.fromJSON(object.access) : undefined,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      schema: isSet(object.schema) ? Schema.fromJSON(object.schema) : undefined,
    };
  },

  toJSON(message: Entity): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.type !== 0) {
      obj.type = entity_TypeToJSON(message.type);
    }
    if (message.asset !== "") {
      obj.asset = message.asset;
    }
    if (message.dataPath !== "") {
      obj.dataPath = message.dataPath;
    }
    if (message.dataPathPattern !== "") {
      obj.dataPathPattern = message.dataPathPattern;
    }
    if (message.catalogEntry !== "") {
      obj.catalogEntry = message.catalogEntry;
    }
    if (message.system !== 0) {
      obj.system = storageSystemToJSON(message.system);
    }
    if (message.format !== undefined) {
      obj.format = StorageFormat.toJSON(message.format);
    }
    if (message.compatibility !== undefined) {
      obj.compatibility = Entity_CompatibilityStatus.toJSON(message.compatibility);
    }
    if (message.access !== undefined) {
      obj.access = StorageAccess.toJSON(message.access);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.schema !== undefined) {
      obj.schema = Schema.toJSON(message.schema);
    }
    return obj;
  },

  create(base?: DeepPartial<Entity>): Entity {
    return Entity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity>): Entity {
    const message = createBaseEntity();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.id = object.id ?? "";
    message.etag = object.etag ?? "";
    message.type = object.type ?? 0;
    message.asset = object.asset ?? "";
    message.dataPath = object.dataPath ?? "";
    message.dataPathPattern = object.dataPathPattern ?? "";
    message.catalogEntry = object.catalogEntry ?? "";
    message.system = object.system ?? 0;
    message.format = (object.format !== undefined && object.format !== null)
      ? StorageFormat.fromPartial(object.format)
      : undefined;
    message.compatibility = (object.compatibility !== undefined && object.compatibility !== null)
      ? Entity_CompatibilityStatus.fromPartial(object.compatibility)
      : undefined;
    message.access = (object.access !== undefined && object.access !== null)
      ? StorageAccess.fromPartial(object.access)
      : undefined;
    message.uid = object.uid ?? "";
    message.schema = (object.schema !== undefined && object.schema !== null)
      ? Schema.fromPartial(object.schema)
      : undefined;
    return message;
  },
};

function createBaseEntity_CompatibilityStatus(): Entity_CompatibilityStatus {
  return { hiveMetastore: undefined, bigquery: undefined };
}

export const Entity_CompatibilityStatus: MessageFns<Entity_CompatibilityStatus> = {
  encode(message: Entity_CompatibilityStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hiveMetastore !== undefined) {
      Entity_CompatibilityStatus_Compatibility.encode(message.hiveMetastore, writer.uint32(10).fork()).join();
    }
    if (message.bigquery !== undefined) {
      Entity_CompatibilityStatus_Compatibility.encode(message.bigquery, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity_CompatibilityStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity_CompatibilityStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hiveMetastore = Entity_CompatibilityStatus_Compatibility.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bigquery = Entity_CompatibilityStatus_Compatibility.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity_CompatibilityStatus {
    return {
      hiveMetastore: isSet(object.hiveMetastore)
        ? Entity_CompatibilityStatus_Compatibility.fromJSON(object.hiveMetastore)
        : undefined,
      bigquery: isSet(object.bigquery) ? Entity_CompatibilityStatus_Compatibility.fromJSON(object.bigquery) : undefined,
    };
  },

  toJSON(message: Entity_CompatibilityStatus): unknown {
    const obj: any = {};
    if (message.hiveMetastore !== undefined) {
      obj.hiveMetastore = Entity_CompatibilityStatus_Compatibility.toJSON(message.hiveMetastore);
    }
    if (message.bigquery !== undefined) {
      obj.bigquery = Entity_CompatibilityStatus_Compatibility.toJSON(message.bigquery);
    }
    return obj;
  },

  create(base?: DeepPartial<Entity_CompatibilityStatus>): Entity_CompatibilityStatus {
    return Entity_CompatibilityStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity_CompatibilityStatus>): Entity_CompatibilityStatus {
    const message = createBaseEntity_CompatibilityStatus();
    message.hiveMetastore = (object.hiveMetastore !== undefined && object.hiveMetastore !== null)
      ? Entity_CompatibilityStatus_Compatibility.fromPartial(object.hiveMetastore)
      : undefined;
    message.bigquery = (object.bigquery !== undefined && object.bigquery !== null)
      ? Entity_CompatibilityStatus_Compatibility.fromPartial(object.bigquery)
      : undefined;
    return message;
  },
};

function createBaseEntity_CompatibilityStatus_Compatibility(): Entity_CompatibilityStatus_Compatibility {
  return { compatible: false, reason: "" };
}

export const Entity_CompatibilityStatus_Compatibility: MessageFns<Entity_CompatibilityStatus_Compatibility> = {
  encode(message: Entity_CompatibilityStatus_Compatibility, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.compatible !== false) {
      writer.uint32(8).bool(message.compatible);
    }
    if (message.reason !== "") {
      writer.uint32(18).string(message.reason);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity_CompatibilityStatus_Compatibility {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity_CompatibilityStatus_Compatibility();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.compatible = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.reason = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity_CompatibilityStatus_Compatibility {
    return {
      compatible: isSet(object.compatible) ? globalThis.Boolean(object.compatible) : false,
      reason: isSet(object.reason) ? globalThis.String(object.reason) : "",
    };
  },

  toJSON(message: Entity_CompatibilityStatus_Compatibility): unknown {
    const obj: any = {};
    if (message.compatible !== false) {
      obj.compatible = message.compatible;
    }
    if (message.reason !== "") {
      obj.reason = message.reason;
    }
    return obj;
  },

  create(base?: DeepPartial<Entity_CompatibilityStatus_Compatibility>): Entity_CompatibilityStatus_Compatibility {
    return Entity_CompatibilityStatus_Compatibility.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity_CompatibilityStatus_Compatibility>): Entity_CompatibilityStatus_Compatibility {
    const message = createBaseEntity_CompatibilityStatus_Compatibility();
    message.compatible = object.compatible ?? false;
    message.reason = object.reason ?? "";
    return message;
  },
};

function createBasePartition(): Partition {
  return { name: "", values: [], location: "", etag: "" };
}

export const Partition: MessageFns<Partition> = {
  encode(message: Partition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.values) {
      writer.uint32(18).string(v!);
    }
    if (message.location !== "") {
      writer.uint32(26).string(message.location);
    }
    if (message.etag !== "") {
      writer.uint32(34).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Partition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.values.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.location = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Partition {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => globalThis.String(e)) : [],
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: Partition): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.values?.length) {
      obj.values = message.values;
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<Partition>): Partition {
    return Partition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Partition>): Partition {
    const message = createBasePartition();
    message.name = object.name ?? "";
    message.values = object.values?.map((e) => e) || [];
    message.location = object.location ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseSchema(): Schema {
  return { userManaged: false, fields: [], partitionFields: [], partitionStyle: 0 };
}

export const Schema: MessageFns<Schema> = {
  encode(message: Schema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.userManaged !== false) {
      writer.uint32(8).bool(message.userManaged);
    }
    for (const v of message.fields) {
      Schema_SchemaField.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.partitionFields) {
      Schema_PartitionField.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.partitionStyle !== 0) {
      writer.uint32(32).int32(message.partitionStyle);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.userManaged = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fields.push(Schema_SchemaField.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.partitionFields.push(Schema_PartitionField.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.partitionStyle = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schema {
    return {
      userManaged: isSet(object.userManaged) ? globalThis.Boolean(object.userManaged) : false,
      fields: globalThis.Array.isArray(object?.fields)
        ? object.fields.map((e: any) => Schema_SchemaField.fromJSON(e))
        : [],
      partitionFields: globalThis.Array.isArray(object?.partitionFields)
        ? object.partitionFields.map((e: any) => Schema_PartitionField.fromJSON(e))
        : [],
      partitionStyle: isSet(object.partitionStyle) ? schema_PartitionStyleFromJSON(object.partitionStyle) : 0,
    };
  },

  toJSON(message: Schema): unknown {
    const obj: any = {};
    if (message.userManaged !== false) {
      obj.userManaged = message.userManaged;
    }
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => Schema_SchemaField.toJSON(e));
    }
    if (message.partitionFields?.length) {
      obj.partitionFields = message.partitionFields.map((e) => Schema_PartitionField.toJSON(e));
    }
    if (message.partitionStyle !== 0) {
      obj.partitionStyle = schema_PartitionStyleToJSON(message.partitionStyle);
    }
    return obj;
  },

  create(base?: DeepPartial<Schema>): Schema {
    return Schema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Schema>): Schema {
    const message = createBaseSchema();
    message.userManaged = object.userManaged ?? false;
    message.fields = object.fields?.map((e) => Schema_SchemaField.fromPartial(e)) || [];
    message.partitionFields = object.partitionFields?.map((e) => Schema_PartitionField.fromPartial(e)) || [];
    message.partitionStyle = object.partitionStyle ?? 0;
    return message;
  },
};

function createBaseSchema_SchemaField(): Schema_SchemaField {
  return { name: "", description: "", type: 0, mode: 0, fields: [] };
}

export const Schema_SchemaField: MessageFns<Schema_SchemaField> = {
  encode(message: Schema_SchemaField, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.type !== 0) {
      writer.uint32(24).int32(message.type);
    }
    if (message.mode !== 0) {
      writer.uint32(32).int32(message.mode);
    }
    for (const v of message.fields) {
      Schema_SchemaField.encode(v!, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schema_SchemaField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchema_SchemaField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.mode = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.fields.push(Schema_SchemaField.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schema_SchemaField {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      type: isSet(object.type) ? schema_TypeFromJSON(object.type) : 0,
      mode: isSet(object.mode) ? schema_ModeFromJSON(object.mode) : 0,
      fields: globalThis.Array.isArray(object?.fields)
        ? object.fields.map((e: any) => Schema_SchemaField.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Schema_SchemaField): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.type !== 0) {
      obj.type = schema_TypeToJSON(message.type);
    }
    if (message.mode !== 0) {
      obj.mode = schema_ModeToJSON(message.mode);
    }
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => Schema_SchemaField.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Schema_SchemaField>): Schema_SchemaField {
    return Schema_SchemaField.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Schema_SchemaField>): Schema_SchemaField {
    const message = createBaseSchema_SchemaField();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.type = object.type ?? 0;
    message.mode = object.mode ?? 0;
    message.fields = object.fields?.map((e) => Schema_SchemaField.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSchema_PartitionField(): Schema_PartitionField {
  return { name: "", type: 0 };
}

export const Schema_PartitionField: MessageFns<Schema_PartitionField> = {
  encode(message: Schema_PartitionField, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schema_PartitionField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchema_PartitionField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schema_PartitionField {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? schema_TypeFromJSON(object.type) : 0,
    };
  },

  toJSON(message: Schema_PartitionField): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = schema_TypeToJSON(message.type);
    }
    return obj;
  },

  create(base?: DeepPartial<Schema_PartitionField>): Schema_PartitionField {
    return Schema_PartitionField.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Schema_PartitionField>): Schema_PartitionField {
    const message = createBaseSchema_PartitionField();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    return message;
  },
};

function createBaseStorageFormat(): StorageFormat {
  return { format: 0, compressionFormat: 0, mimeType: "", csv: undefined, json: undefined, iceberg: undefined };
}

export const StorageFormat: MessageFns<StorageFormat> = {
  encode(message: StorageFormat, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.format !== 0) {
      writer.uint32(8).int32(message.format);
    }
    if (message.compressionFormat !== 0) {
      writer.uint32(16).int32(message.compressionFormat);
    }
    if (message.mimeType !== "") {
      writer.uint32(26).string(message.mimeType);
    }
    if (message.csv !== undefined) {
      StorageFormat_CsvOptions.encode(message.csv, writer.uint32(82).fork()).join();
    }
    if (message.json !== undefined) {
      StorageFormat_JsonOptions.encode(message.json, writer.uint32(90).fork()).join();
    }
    if (message.iceberg !== undefined) {
      StorageFormat_IcebergOptions.encode(message.iceberg, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.format = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.compressionFormat = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mimeType = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.csv = StorageFormat_CsvOptions.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.json = StorageFormat_JsonOptions.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.iceberg = StorageFormat_IcebergOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageFormat {
    return {
      format: isSet(object.format) ? storageFormat_FormatFromJSON(object.format) : 0,
      compressionFormat: isSet(object.compressionFormat)
        ? storageFormat_CompressionFormatFromJSON(object.compressionFormat)
        : 0,
      mimeType: isSet(object.mimeType) ? globalThis.String(object.mimeType) : "",
      csv: isSet(object.csv) ? StorageFormat_CsvOptions.fromJSON(object.csv) : undefined,
      json: isSet(object.json) ? StorageFormat_JsonOptions.fromJSON(object.json) : undefined,
      iceberg: isSet(object.iceberg) ? StorageFormat_IcebergOptions.fromJSON(object.iceberg) : undefined,
    };
  },

  toJSON(message: StorageFormat): unknown {
    const obj: any = {};
    if (message.format !== 0) {
      obj.format = storageFormat_FormatToJSON(message.format);
    }
    if (message.compressionFormat !== 0) {
      obj.compressionFormat = storageFormat_CompressionFormatToJSON(message.compressionFormat);
    }
    if (message.mimeType !== "") {
      obj.mimeType = message.mimeType;
    }
    if (message.csv !== undefined) {
      obj.csv = StorageFormat_CsvOptions.toJSON(message.csv);
    }
    if (message.json !== undefined) {
      obj.json = StorageFormat_JsonOptions.toJSON(message.json);
    }
    if (message.iceberg !== undefined) {
      obj.iceberg = StorageFormat_IcebergOptions.toJSON(message.iceberg);
    }
    return obj;
  },

  create(base?: DeepPartial<StorageFormat>): StorageFormat {
    return StorageFormat.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageFormat>): StorageFormat {
    const message = createBaseStorageFormat();
    message.format = object.format ?? 0;
    message.compressionFormat = object.compressionFormat ?? 0;
    message.mimeType = object.mimeType ?? "";
    message.csv = (object.csv !== undefined && object.csv !== null)
      ? StorageFormat_CsvOptions.fromPartial(object.csv)
      : undefined;
    message.json = (object.json !== undefined && object.json !== null)
      ? StorageFormat_JsonOptions.fromPartial(object.json)
      : undefined;
    message.iceberg = (object.iceberg !== undefined && object.iceberg !== null)
      ? StorageFormat_IcebergOptions.fromPartial(object.iceberg)
      : undefined;
    return message;
  },
};

function createBaseStorageFormat_CsvOptions(): StorageFormat_CsvOptions {
  return { encoding: "", headerRows: 0, delimiter: "", quote: "" };
}

export const StorageFormat_CsvOptions: MessageFns<StorageFormat_CsvOptions> = {
  encode(message: StorageFormat_CsvOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== "") {
      writer.uint32(10).string(message.encoding);
    }
    if (message.headerRows !== 0) {
      writer.uint32(16).int32(message.headerRows);
    }
    if (message.delimiter !== "") {
      writer.uint32(26).string(message.delimiter);
    }
    if (message.quote !== "") {
      writer.uint32(34).string(message.quote);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageFormat_CsvOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageFormat_CsvOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.encoding = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.headerRows = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.delimiter = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.quote = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageFormat_CsvOptions {
    return {
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      headerRows: isSet(object.headerRows) ? globalThis.Number(object.headerRows) : 0,
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
      quote: isSet(object.quote) ? globalThis.String(object.quote) : "",
    };
  },

  toJSON(message: StorageFormat_CsvOptions): unknown {
    const obj: any = {};
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.headerRows !== 0) {
      obj.headerRows = Math.round(message.headerRows);
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    if (message.quote !== "") {
      obj.quote = message.quote;
    }
    return obj;
  },

  create(base?: DeepPartial<StorageFormat_CsvOptions>): StorageFormat_CsvOptions {
    return StorageFormat_CsvOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageFormat_CsvOptions>): StorageFormat_CsvOptions {
    const message = createBaseStorageFormat_CsvOptions();
    message.encoding = object.encoding ?? "";
    message.headerRows = object.headerRows ?? 0;
    message.delimiter = object.delimiter ?? "";
    message.quote = object.quote ?? "";
    return message;
  },
};

function createBaseStorageFormat_JsonOptions(): StorageFormat_JsonOptions {
  return { encoding: "" };
}

export const StorageFormat_JsonOptions: MessageFns<StorageFormat_JsonOptions> = {
  encode(message: StorageFormat_JsonOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== "") {
      writer.uint32(10).string(message.encoding);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageFormat_JsonOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageFormat_JsonOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.encoding = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageFormat_JsonOptions {
    return { encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "" };
  },

  toJSON(message: StorageFormat_JsonOptions): unknown {
    const obj: any = {};
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    return obj;
  },

  create(base?: DeepPartial<StorageFormat_JsonOptions>): StorageFormat_JsonOptions {
    return StorageFormat_JsonOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageFormat_JsonOptions>): StorageFormat_JsonOptions {
    const message = createBaseStorageFormat_JsonOptions();
    message.encoding = object.encoding ?? "";
    return message;
  },
};

function createBaseStorageFormat_IcebergOptions(): StorageFormat_IcebergOptions {
  return { metadataLocation: "" };
}

export const StorageFormat_IcebergOptions: MessageFns<StorageFormat_IcebergOptions> = {
  encode(message: StorageFormat_IcebergOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metadataLocation !== "") {
      writer.uint32(10).string(message.metadataLocation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageFormat_IcebergOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageFormat_IcebergOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metadataLocation = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageFormat_IcebergOptions {
    return { metadataLocation: isSet(object.metadataLocation) ? globalThis.String(object.metadataLocation) : "" };
  },

  toJSON(message: StorageFormat_IcebergOptions): unknown {
    const obj: any = {};
    if (message.metadataLocation !== "") {
      obj.metadataLocation = message.metadataLocation;
    }
    return obj;
  },

  create(base?: DeepPartial<StorageFormat_IcebergOptions>): StorageFormat_IcebergOptions {
    return StorageFormat_IcebergOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageFormat_IcebergOptions>): StorageFormat_IcebergOptions {
    const message = createBaseStorageFormat_IcebergOptions();
    message.metadataLocation = object.metadataLocation ?? "";
    return message;
  },
};

function createBaseStorageAccess(): StorageAccess {
  return { read: 0 };
}

export const StorageAccess: MessageFns<StorageAccess> = {
  encode(message: StorageAccess, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.read !== 0) {
      writer.uint32(168).int32(message.read);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageAccess {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageAccess();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 21:
          if (tag !== 168) {
            break;
          }

          message.read = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageAccess {
    return { read: isSet(object.read) ? storageAccess_AccessModeFromJSON(object.read) : 0 };
  },

  toJSON(message: StorageAccess): unknown {
    const obj: any = {};
    if (message.read !== 0) {
      obj.read = storageAccess_AccessModeToJSON(message.read);
    }
    return obj;
  },

  create(base?: DeepPartial<StorageAccess>): StorageAccess {
    return StorageAccess.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageAccess>): StorageAccess {
    const message = createBaseStorageAccess();
    message.read = object.read ?? 0;
    return message;
  },
};

/**
 * Metadata service manages metadata resources such as tables, filesets and
 * partitions.
 */
export type MetadataServiceDefinition = typeof MetadataServiceDefinition;
export const MetadataServiceDefinition = {
  name: "MetadataService",
  fullName: "google.cloud.dataplex.v1.MetadataService",
  methods: {
    /** Create a metadata entity. */
    createEntity: {
      name: "CreateEntity",
      requestType: CreateEntityRequest,
      requestStream: false,
      responseType: Entity,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([13, 112, 97, 114, 101, 110, 116, 44, 101, 110, 116, 105, 116, 121])],
          578365826: [
            Buffer.from([
              70,
              58,
              6,
              101,
              110,
              116,
              105,
              116,
              121,
              34,
              60,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              125,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Update a metadata entity. Only supports full resource update. */
    updateEntity: {
      name: "UpdateEntity",
      requestType: UpdateEntityRequest,
      requestStream: false,
      responseType: Entity,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              77,
              58,
              6,
              101,
              110,
              116,
              105,
              116,
              121,
              26,
              67,
              47,
              118,
              49,
              47,
              123,
              101,
              110,
              116,
              105,
              116,
              121,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Delete a metadata entity. */
    deleteEntity: {
      name: "DeleteEntity",
      requestType: DeleteEntityRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              62,
              42,
              60,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Get a metadata entity. */
    getEntity: {
      name: "GetEntity",
      requestType: GetEntityRequest,
      requestStream: false,
      responseType: Entity,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              62,
              18,
              60,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** List metadata entities in a zone. */
    listEntities: {
      name: "ListEntities",
      requestType: ListEntitiesRequest,
      requestStream: false,
      responseType: ListEntitiesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              62,
              18,
              60,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              125,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Create a metadata partition. */
    createPartition: {
      name: "CreatePartition",
      requestType: CreatePartitionRequest,
      requestStream: false,
      responseType: Partition,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([16, 112, 97, 114, 101, 110, 116, 44, 112, 97, 114, 116, 105, 116, 105, 111, 110])],
          578365826: [
            Buffer.from([
              86,
              58,
              9,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              34,
              73,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Delete a metadata partition. */
    deletePartition: {
      name: "DeletePartition",
      requestType: DeletePartitionRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              76,
              42,
              74,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              47,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Get a metadata partition of an entity. */
    getPartition: {
      name: "GetPartition",
      requestType: GetPartitionRequest,
      requestStream: false,
      responseType: Partition,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              76,
              18,
              74,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              47,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** List metadata partitions of an entity. */
    listPartitions: {
      name: "ListPartitions",
      requestType: ListPartitionsRequest,
      requestStream: false,
      responseType: ListPartitionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              75,
              18,
              73,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              108,
              97,
              107,
              101,
              115,
              47,
              42,
              47,
              122,
              111,
              110,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              112,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface MetadataServiceImplementation<CallContextExt = {}> {
  /** Create a metadata entity. */
  createEntity(request: CreateEntityRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Entity>>;
  /** Update a metadata entity. Only supports full resource update. */
  updateEntity(request: UpdateEntityRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Entity>>;
  /** Delete a metadata entity. */
  deleteEntity(request: DeleteEntityRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Get a metadata entity. */
  getEntity(request: GetEntityRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Entity>>;
  /** List metadata entities in a zone. */
  listEntities(
    request: ListEntitiesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListEntitiesResponse>>;
  /** Create a metadata partition. */
  createPartition(
    request: CreatePartitionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Partition>>;
  /** Delete a metadata partition. */
  deletePartition(request: DeletePartitionRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Get a metadata partition of an entity. */
  getPartition(request: GetPartitionRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Partition>>;
  /** List metadata partitions of an entity. */
  listPartitions(
    request: ListPartitionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListPartitionsResponse>>;
}

export interface MetadataServiceClient<CallOptionsExt = {}> {
  /** Create a metadata entity. */
  createEntity(request: DeepPartial<CreateEntityRequest>, options?: CallOptions & CallOptionsExt): Promise<Entity>;
  /** Update a metadata entity. Only supports full resource update. */
  updateEntity(request: DeepPartial<UpdateEntityRequest>, options?: CallOptions & CallOptionsExt): Promise<Entity>;
  /** Delete a metadata entity. */
  deleteEntity(request: DeepPartial<DeleteEntityRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Get a metadata entity. */
  getEntity(request: DeepPartial<GetEntityRequest>, options?: CallOptions & CallOptionsExt): Promise<Entity>;
  /** List metadata entities in a zone. */
  listEntities(
    request: DeepPartial<ListEntitiesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListEntitiesResponse>;
  /** Create a metadata partition. */
  createPartition(
    request: DeepPartial<CreatePartitionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Partition>;
  /** Delete a metadata partition. */
  deletePartition(request: DeepPartial<DeletePartitionRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Get a metadata partition of an entity. */
  getPartition(request: DeepPartial<GetPartitionRequest>, options?: CallOptions & CallOptionsExt): Promise<Partition>;
  /** List metadata partitions of an entity. */
  listPartitions(
    request: DeepPartial<ListPartitionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListPartitionsResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
