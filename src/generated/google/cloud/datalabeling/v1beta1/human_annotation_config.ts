// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/datalabeling/v1beta1/human_annotation_config.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";

export const protobufPackage = "google.cloud.datalabeling.v1beta1";

export enum StringAggregationType {
  STRING_AGGREGATION_TYPE_UNSPECIFIED = 0,
  /** MAJORITY_VOTE - Majority vote to aggregate answers. */
  MAJORITY_VOTE = 1,
  /** UNANIMOUS_VOTE - Unanimous answers will be adopted. */
  UNANIMOUS_VOTE = 2,
  /** NO_AGGREGATION - Preserve all answers by crowd compute. */
  NO_AGGREGATION = 3,
  UNRECOGNIZED = -1,
}

export function stringAggregationTypeFromJSON(object: any): StringAggregationType {
  switch (object) {
    case 0:
    case "STRING_AGGREGATION_TYPE_UNSPECIFIED":
      return StringAggregationType.STRING_AGGREGATION_TYPE_UNSPECIFIED;
    case 1:
    case "MAJORITY_VOTE":
      return StringAggregationType.MAJORITY_VOTE;
    case 2:
    case "UNANIMOUS_VOTE":
      return StringAggregationType.UNANIMOUS_VOTE;
    case 3:
    case "NO_AGGREGATION":
      return StringAggregationType.NO_AGGREGATION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StringAggregationType.UNRECOGNIZED;
  }
}

export function stringAggregationTypeToJSON(object: StringAggregationType): string {
  switch (object) {
    case StringAggregationType.STRING_AGGREGATION_TYPE_UNSPECIFIED:
      return "STRING_AGGREGATION_TYPE_UNSPECIFIED";
    case StringAggregationType.MAJORITY_VOTE:
      return "MAJORITY_VOTE";
    case StringAggregationType.UNANIMOUS_VOTE:
      return "UNANIMOUS_VOTE";
    case StringAggregationType.NO_AGGREGATION:
      return "NO_AGGREGATION";
    case StringAggregationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Configuration for how human labeling task should be done. */
export interface HumanAnnotationConfig {
  /** Required. Instruction resource name. */
  instruction: string;
  /**
   * Required. A human-readable name for AnnotatedDataset defined by
   * users. Maximum of 64 characters
   * .
   */
  annotatedDatasetDisplayName: string;
  /**
   * Optional. A human-readable description for AnnotatedDataset.
   * The description can be up to 10000 characters long.
   */
  annotatedDatasetDescription: string;
  /**
   * Optional. A human-readable label used to logically group labeling tasks.
   * This string must match the regular expression `[a-zA-Z\\d_-]{0,128}`.
   */
  labelGroup: string;
  /**
   * Optional. The Language of this question, as a
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt).
   * Default value is en-US.
   * Only need to set this when task is language related. For example, French
   * text classification.
   */
  languageCode: string;
  /**
   * Optional. Replication of questions. Each question will be sent to up to
   * this number of contributors to label. Aggregated answers will be returned.
   * Default is set to 1.
   * For image related labeling, valid values are 1, 3, 5.
   */
  replicaCount: number;
  /**
   * Optional. Maximum duration for contributors to answer a question. Maximum
   * is 3600 seconds. Default is 3600 seconds.
   */
  questionDuration:
    | Duration
    | undefined;
  /**
   * Optional. If you want your own labeling contributors to manage and work on
   * this labeling request, you can set these contributors here. We will give
   * them access to the question types in crowdcompute. Note that these
   * emails must be registered in crowdcompute worker UI:
   * https://crowd-compute.appspot.com/
   */
  contributorEmails: string[];
  /**
   * Email of the user who started the labeling task and should be notified by
   * email. If empty no notification will be sent.
   */
  userEmailAddress: string;
}

/** Config for image classification human labeling task. */
export interface ImageClassificationConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
  /**
   * Optional. If allow_multi_label is true, contributors are able to choose
   * multiple labels for one image.
   */
  allowMultiLabel: boolean;
  /** Optional. The type of how to aggregate answers. */
  answerAggregationType: StringAggregationType;
}

/** Config for image bounding poly (and bounding box) human labeling task. */
export interface BoundingPolyConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
  /** Optional. Instruction message showed on contributors UI. */
  instructionMessage: string;
}

/** Config for image polyline human labeling task. */
export interface PolylineConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
  /** Optional. Instruction message showed on contributors UI. */
  instructionMessage: string;
}

/** Config for image segmentation */
export interface SegmentationConfig {
  /**
   * Required. Annotation spec set resource name. format:
   * projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}
   */
  annotationSpecSet: string;
  /** Instruction message showed on labelers UI. */
  instructionMessage: string;
}

/**
 * Config for video classification human labeling task.
 * Currently two types of video classification are supported:
 * 1. Assign labels on the entire video.
 * 2. Split the video into multiple video clips based on camera shot, and
 * assign labels on each video clip.
 */
export interface VideoClassificationConfig {
  /**
   * Required. The list of annotation spec set configs.
   * Since watching a video clip takes much longer time than an image, we
   * support label with multiple AnnotationSpecSet at the same time. Labels
   * in each AnnotationSpecSet will be shown in a group to contributors.
   * Contributors can select one or more (depending on whether to allow multi
   * label) from each group.
   */
  annotationSpecSetConfigs: VideoClassificationConfig_AnnotationSpecSetConfig[];
  /** Optional. Option to apply shot detection on the video. */
  applyShotDetection: boolean;
}

/** Annotation spec set with the setting of allowing multi labels or not. */
export interface VideoClassificationConfig_AnnotationSpecSetConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
  /**
   * Optional. If allow_multi_label is true, contributors are able to
   * choose multiple labels from one annotation spec set.
   */
  allowMultiLabel: boolean;
}

/**
 * Config for video object detection human labeling task.
 * Object detection will be conducted on the images extracted from the video,
 * and those objects will be labeled with bounding boxes.
 * User need to specify the number of images to be extracted per second as the
 * extraction frame rate.
 */
export interface ObjectDetectionConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
  /** Required. Number of frames per second to be extracted from the video. */
  extractionFrameRate: number;
}

/** Config for video object tracking human labeling task. */
export interface ObjectTrackingConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
}

/** Config for video event human labeling task. */
export interface EventConfig {
  /**
   * Required. The list of annotation spec set resource name. Similar to video
   * classification, we support selecting event from multiple AnnotationSpecSet
   * at the same time.
   */
  annotationSpecSets: string[];
}

/** Config for text classification human labeling task. */
export interface TextClassificationConfig {
  /**
   * Optional. If allow_multi_label is true, contributors are able to choose
   * multiple labels for one text segment.
   */
  allowMultiLabel: boolean;
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
  /** Optional. Configs for sentiment selection. */
  sentimentConfig: SentimentConfig | undefined;
}

/** Config for setting up sentiments. */
export interface SentimentConfig {
  /**
   * If set to true, contributors will have the option to select sentiment of
   * the label they selected, to mark it as negative or positive label. Default
   * is false.
   */
  enableLabelSentimentSelection: boolean;
}

/** Config for text entity extraction human labeling task. */
export interface TextEntityExtractionConfig {
  /** Required. Annotation spec set resource name. */
  annotationSpecSet: string;
}

function createBaseHumanAnnotationConfig(): HumanAnnotationConfig {
  return {
    instruction: "",
    annotatedDatasetDisplayName: "",
    annotatedDatasetDescription: "",
    labelGroup: "",
    languageCode: "",
    replicaCount: 0,
    questionDuration: undefined,
    contributorEmails: [],
    userEmailAddress: "",
  };
}

export const HumanAnnotationConfig: MessageFns<HumanAnnotationConfig> = {
  encode(message: HumanAnnotationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instruction !== "") {
      writer.uint32(10).string(message.instruction);
    }
    if (message.annotatedDatasetDisplayName !== "") {
      writer.uint32(18).string(message.annotatedDatasetDisplayName);
    }
    if (message.annotatedDatasetDescription !== "") {
      writer.uint32(26).string(message.annotatedDatasetDescription);
    }
    if (message.labelGroup !== "") {
      writer.uint32(34).string(message.labelGroup);
    }
    if (message.languageCode !== "") {
      writer.uint32(42).string(message.languageCode);
    }
    if (message.replicaCount !== 0) {
      writer.uint32(48).int32(message.replicaCount);
    }
    if (message.questionDuration !== undefined) {
      Duration.encode(message.questionDuration, writer.uint32(58).fork()).join();
    }
    for (const v of message.contributorEmails) {
      writer.uint32(74).string(v!);
    }
    if (message.userEmailAddress !== "") {
      writer.uint32(82).string(message.userEmailAddress);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HumanAnnotationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHumanAnnotationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instruction = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotatedDatasetDisplayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.annotatedDatasetDescription = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.labelGroup = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.replicaCount = reader.int32();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.questionDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.contributorEmails.push(reader.string());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.userEmailAddress = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HumanAnnotationConfig {
    return {
      instruction: isSet(object.instruction) ? globalThis.String(object.instruction) : "",
      annotatedDatasetDisplayName: isSet(object.annotatedDatasetDisplayName)
        ? globalThis.String(object.annotatedDatasetDisplayName)
        : "",
      annotatedDatasetDescription: isSet(object.annotatedDatasetDescription)
        ? globalThis.String(object.annotatedDatasetDescription)
        : "",
      labelGroup: isSet(object.labelGroup) ? globalThis.String(object.labelGroup) : "",
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      replicaCount: isSet(object.replicaCount) ? globalThis.Number(object.replicaCount) : 0,
      questionDuration: isSet(object.questionDuration) ? Duration.fromJSON(object.questionDuration) : undefined,
      contributorEmails: globalThis.Array.isArray(object?.contributorEmails)
        ? object.contributorEmails.map((e: any) => globalThis.String(e))
        : [],
      userEmailAddress: isSet(object.userEmailAddress) ? globalThis.String(object.userEmailAddress) : "",
    };
  },

  toJSON(message: HumanAnnotationConfig): unknown {
    const obj: any = {};
    if (message.instruction !== "") {
      obj.instruction = message.instruction;
    }
    if (message.annotatedDatasetDisplayName !== "") {
      obj.annotatedDatasetDisplayName = message.annotatedDatasetDisplayName;
    }
    if (message.annotatedDatasetDescription !== "") {
      obj.annotatedDatasetDescription = message.annotatedDatasetDescription;
    }
    if (message.labelGroup !== "") {
      obj.labelGroup = message.labelGroup;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.replicaCount !== 0) {
      obj.replicaCount = Math.round(message.replicaCount);
    }
    if (message.questionDuration !== undefined) {
      obj.questionDuration = Duration.toJSON(message.questionDuration);
    }
    if (message.contributorEmails?.length) {
      obj.contributorEmails = message.contributorEmails;
    }
    if (message.userEmailAddress !== "") {
      obj.userEmailAddress = message.userEmailAddress;
    }
    return obj;
  },

  create(base?: DeepPartial<HumanAnnotationConfig>): HumanAnnotationConfig {
    return HumanAnnotationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HumanAnnotationConfig>): HumanAnnotationConfig {
    const message = createBaseHumanAnnotationConfig();
    message.instruction = object.instruction ?? "";
    message.annotatedDatasetDisplayName = object.annotatedDatasetDisplayName ?? "";
    message.annotatedDatasetDescription = object.annotatedDatasetDescription ?? "";
    message.labelGroup = object.labelGroup ?? "";
    message.languageCode = object.languageCode ?? "";
    message.replicaCount = object.replicaCount ?? 0;
    message.questionDuration = (object.questionDuration !== undefined && object.questionDuration !== null)
      ? Duration.fromPartial(object.questionDuration)
      : undefined;
    message.contributorEmails = object.contributorEmails?.map((e) => e) || [];
    message.userEmailAddress = object.userEmailAddress ?? "";
    return message;
  },
};

function createBaseImageClassificationConfig(): ImageClassificationConfig {
  return { annotationSpecSet: "", allowMultiLabel: false, answerAggregationType: 0 };
}

export const ImageClassificationConfig: MessageFns<ImageClassificationConfig> = {
  encode(message: ImageClassificationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    if (message.allowMultiLabel !== false) {
      writer.uint32(16).bool(message.allowMultiLabel);
    }
    if (message.answerAggregationType !== 0) {
      writer.uint32(24).int32(message.answerAggregationType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageClassificationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageClassificationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.allowMultiLabel = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.answerAggregationType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageClassificationConfig {
    return {
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      allowMultiLabel: isSet(object.allowMultiLabel) ? globalThis.Boolean(object.allowMultiLabel) : false,
      answerAggregationType: isSet(object.answerAggregationType)
        ? stringAggregationTypeFromJSON(object.answerAggregationType)
        : 0,
    };
  },

  toJSON(message: ImageClassificationConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.allowMultiLabel !== false) {
      obj.allowMultiLabel = message.allowMultiLabel;
    }
    if (message.answerAggregationType !== 0) {
      obj.answerAggregationType = stringAggregationTypeToJSON(message.answerAggregationType);
    }
    return obj;
  },

  create(base?: DeepPartial<ImageClassificationConfig>): ImageClassificationConfig {
    return ImageClassificationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageClassificationConfig>): ImageClassificationConfig {
    const message = createBaseImageClassificationConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.allowMultiLabel = object.allowMultiLabel ?? false;
    message.answerAggregationType = object.answerAggregationType ?? 0;
    return message;
  },
};

function createBaseBoundingPolyConfig(): BoundingPolyConfig {
  return { annotationSpecSet: "", instructionMessage: "" };
}

export const BoundingPolyConfig: MessageFns<BoundingPolyConfig> = {
  encode(message: BoundingPolyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    if (message.instructionMessage !== "") {
      writer.uint32(18).string(message.instructionMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoundingPolyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoundingPolyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instructionMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoundingPolyConfig {
    return {
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      instructionMessage: isSet(object.instructionMessage) ? globalThis.String(object.instructionMessage) : "",
    };
  },

  toJSON(message: BoundingPolyConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.instructionMessage !== "") {
      obj.instructionMessage = message.instructionMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<BoundingPolyConfig>): BoundingPolyConfig {
    return BoundingPolyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BoundingPolyConfig>): BoundingPolyConfig {
    const message = createBaseBoundingPolyConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.instructionMessage = object.instructionMessage ?? "";
    return message;
  },
};

function createBasePolylineConfig(): PolylineConfig {
  return { annotationSpecSet: "", instructionMessage: "" };
}

export const PolylineConfig: MessageFns<PolylineConfig> = {
  encode(message: PolylineConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    if (message.instructionMessage !== "") {
      writer.uint32(18).string(message.instructionMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PolylineConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePolylineConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instructionMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PolylineConfig {
    return {
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      instructionMessage: isSet(object.instructionMessage) ? globalThis.String(object.instructionMessage) : "",
    };
  },

  toJSON(message: PolylineConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.instructionMessage !== "") {
      obj.instructionMessage = message.instructionMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<PolylineConfig>): PolylineConfig {
    return PolylineConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PolylineConfig>): PolylineConfig {
    const message = createBasePolylineConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.instructionMessage = object.instructionMessage ?? "";
    return message;
  },
};

function createBaseSegmentationConfig(): SegmentationConfig {
  return { annotationSpecSet: "", instructionMessage: "" };
}

export const SegmentationConfig: MessageFns<SegmentationConfig> = {
  encode(message: SegmentationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    if (message.instructionMessage !== "") {
      writer.uint32(18).string(message.instructionMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SegmentationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSegmentationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instructionMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SegmentationConfig {
    return {
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      instructionMessage: isSet(object.instructionMessage) ? globalThis.String(object.instructionMessage) : "",
    };
  },

  toJSON(message: SegmentationConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.instructionMessage !== "") {
      obj.instructionMessage = message.instructionMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<SegmentationConfig>): SegmentationConfig {
    return SegmentationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SegmentationConfig>): SegmentationConfig {
    const message = createBaseSegmentationConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.instructionMessage = object.instructionMessage ?? "";
    return message;
  },
};

function createBaseVideoClassificationConfig(): VideoClassificationConfig {
  return { annotationSpecSetConfigs: [], applyShotDetection: false };
}

export const VideoClassificationConfig: MessageFns<VideoClassificationConfig> = {
  encode(message: VideoClassificationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.annotationSpecSetConfigs) {
      VideoClassificationConfig_AnnotationSpecSetConfig.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.applyShotDetection !== false) {
      writer.uint32(16).bool(message.applyShotDetection);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoClassificationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoClassificationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSetConfigs.push(
            VideoClassificationConfig_AnnotationSpecSetConfig.decode(reader, reader.uint32()),
          );
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.applyShotDetection = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoClassificationConfig {
    return {
      annotationSpecSetConfigs: globalThis.Array.isArray(object?.annotationSpecSetConfigs)
        ? object.annotationSpecSetConfigs.map((e: any) => VideoClassificationConfig_AnnotationSpecSetConfig.fromJSON(e))
        : [],
      applyShotDetection: isSet(object.applyShotDetection) ? globalThis.Boolean(object.applyShotDetection) : false,
    };
  },

  toJSON(message: VideoClassificationConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSetConfigs?.length) {
      obj.annotationSpecSetConfigs = message.annotationSpecSetConfigs.map((e) =>
        VideoClassificationConfig_AnnotationSpecSetConfig.toJSON(e)
      );
    }
    if (message.applyShotDetection !== false) {
      obj.applyShotDetection = message.applyShotDetection;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoClassificationConfig>): VideoClassificationConfig {
    return VideoClassificationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoClassificationConfig>): VideoClassificationConfig {
    const message = createBaseVideoClassificationConfig();
    message.annotationSpecSetConfigs =
      object.annotationSpecSetConfigs?.map((e) => VideoClassificationConfig_AnnotationSpecSetConfig.fromPartial(e)) ||
      [];
    message.applyShotDetection = object.applyShotDetection ?? false;
    return message;
  },
};

function createBaseVideoClassificationConfig_AnnotationSpecSetConfig(): VideoClassificationConfig_AnnotationSpecSetConfig {
  return { annotationSpecSet: "", allowMultiLabel: false };
}

export const VideoClassificationConfig_AnnotationSpecSetConfig: MessageFns<
  VideoClassificationConfig_AnnotationSpecSetConfig
> = {
  encode(
    message: VideoClassificationConfig_AnnotationSpecSetConfig,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    if (message.allowMultiLabel !== false) {
      writer.uint32(16).bool(message.allowMultiLabel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoClassificationConfig_AnnotationSpecSetConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoClassificationConfig_AnnotationSpecSetConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.allowMultiLabel = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoClassificationConfig_AnnotationSpecSetConfig {
    return {
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      allowMultiLabel: isSet(object.allowMultiLabel) ? globalThis.Boolean(object.allowMultiLabel) : false,
    };
  },

  toJSON(message: VideoClassificationConfig_AnnotationSpecSetConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.allowMultiLabel !== false) {
      obj.allowMultiLabel = message.allowMultiLabel;
    }
    return obj;
  },

  create(
    base?: DeepPartial<VideoClassificationConfig_AnnotationSpecSetConfig>,
  ): VideoClassificationConfig_AnnotationSpecSetConfig {
    return VideoClassificationConfig_AnnotationSpecSetConfig.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<VideoClassificationConfig_AnnotationSpecSetConfig>,
  ): VideoClassificationConfig_AnnotationSpecSetConfig {
    const message = createBaseVideoClassificationConfig_AnnotationSpecSetConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.allowMultiLabel = object.allowMultiLabel ?? false;
    return message;
  },
};

function createBaseObjectDetectionConfig(): ObjectDetectionConfig {
  return { annotationSpecSet: "", extractionFrameRate: 0 };
}

export const ObjectDetectionConfig: MessageFns<ObjectDetectionConfig> = {
  encode(message: ObjectDetectionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    if (message.extractionFrameRate !== 0) {
      writer.uint32(25).double(message.extractionFrameRate);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectDetectionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectDetectionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 3:
          if (tag !== 25) {
            break;
          }

          message.extractionFrameRate = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectDetectionConfig {
    return {
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      extractionFrameRate: isSet(object.extractionFrameRate) ? globalThis.Number(object.extractionFrameRate) : 0,
    };
  },

  toJSON(message: ObjectDetectionConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.extractionFrameRate !== 0) {
      obj.extractionFrameRate = message.extractionFrameRate;
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectDetectionConfig>): ObjectDetectionConfig {
    return ObjectDetectionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectDetectionConfig>): ObjectDetectionConfig {
    const message = createBaseObjectDetectionConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.extractionFrameRate = object.extractionFrameRate ?? 0;
    return message;
  },
};

function createBaseObjectTrackingConfig(): ObjectTrackingConfig {
  return { annotationSpecSet: "" };
}

export const ObjectTrackingConfig: MessageFns<ObjectTrackingConfig> = {
  encode(message: ObjectTrackingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectTrackingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectTrackingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectTrackingConfig {
    return { annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "" };
  },

  toJSON(message: ObjectTrackingConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectTrackingConfig>): ObjectTrackingConfig {
    return ObjectTrackingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectTrackingConfig>): ObjectTrackingConfig {
    const message = createBaseObjectTrackingConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    return message;
  },
};

function createBaseEventConfig(): EventConfig {
  return { annotationSpecSets: [] };
}

export const EventConfig: MessageFns<EventConfig> = {
  encode(message: EventConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.annotationSpecSets) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSets.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventConfig {
    return {
      annotationSpecSets: globalThis.Array.isArray(object?.annotationSpecSets)
        ? object.annotationSpecSets.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: EventConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSets?.length) {
      obj.annotationSpecSets = message.annotationSpecSets;
    }
    return obj;
  },

  create(base?: DeepPartial<EventConfig>): EventConfig {
    return EventConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EventConfig>): EventConfig {
    const message = createBaseEventConfig();
    message.annotationSpecSets = object.annotationSpecSets?.map((e) => e) || [];
    return message;
  },
};

function createBaseTextClassificationConfig(): TextClassificationConfig {
  return { allowMultiLabel: false, annotationSpecSet: "", sentimentConfig: undefined };
}

export const TextClassificationConfig: MessageFns<TextClassificationConfig> = {
  encode(message: TextClassificationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.allowMultiLabel !== false) {
      writer.uint32(8).bool(message.allowMultiLabel);
    }
    if (message.annotationSpecSet !== "") {
      writer.uint32(18).string(message.annotationSpecSet);
    }
    if (message.sentimentConfig !== undefined) {
      SentimentConfig.encode(message.sentimentConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextClassificationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextClassificationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.allowMultiLabel = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sentimentConfig = SentimentConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextClassificationConfig {
    return {
      allowMultiLabel: isSet(object.allowMultiLabel) ? globalThis.Boolean(object.allowMultiLabel) : false,
      annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "",
      sentimentConfig: isSet(object.sentimentConfig) ? SentimentConfig.fromJSON(object.sentimentConfig) : undefined,
    };
  },

  toJSON(message: TextClassificationConfig): unknown {
    const obj: any = {};
    if (message.allowMultiLabel !== false) {
      obj.allowMultiLabel = message.allowMultiLabel;
    }
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    if (message.sentimentConfig !== undefined) {
      obj.sentimentConfig = SentimentConfig.toJSON(message.sentimentConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<TextClassificationConfig>): TextClassificationConfig {
    return TextClassificationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextClassificationConfig>): TextClassificationConfig {
    const message = createBaseTextClassificationConfig();
    message.allowMultiLabel = object.allowMultiLabel ?? false;
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    message.sentimentConfig = (object.sentimentConfig !== undefined && object.sentimentConfig !== null)
      ? SentimentConfig.fromPartial(object.sentimentConfig)
      : undefined;
    return message;
  },
};

function createBaseSentimentConfig(): SentimentConfig {
  return { enableLabelSentimentSelection: false };
}

export const SentimentConfig: MessageFns<SentimentConfig> = {
  encode(message: SentimentConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enableLabelSentimentSelection !== false) {
      writer.uint32(8).bool(message.enableLabelSentimentSelection);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SentimentConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSentimentConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enableLabelSentimentSelection = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SentimentConfig {
    return {
      enableLabelSentimentSelection: isSet(object.enableLabelSentimentSelection)
        ? globalThis.Boolean(object.enableLabelSentimentSelection)
        : false,
    };
  },

  toJSON(message: SentimentConfig): unknown {
    const obj: any = {};
    if (message.enableLabelSentimentSelection !== false) {
      obj.enableLabelSentimentSelection = message.enableLabelSentimentSelection;
    }
    return obj;
  },

  create(base?: DeepPartial<SentimentConfig>): SentimentConfig {
    return SentimentConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SentimentConfig>): SentimentConfig {
    const message = createBaseSentimentConfig();
    message.enableLabelSentimentSelection = object.enableLabelSentimentSelection ?? false;
    return message;
  },
};

function createBaseTextEntityExtractionConfig(): TextEntityExtractionConfig {
  return { annotationSpecSet: "" };
}

export const TextEntityExtractionConfig: MessageFns<TextEntityExtractionConfig> = {
  encode(message: TextEntityExtractionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecSet !== "") {
      writer.uint32(10).string(message.annotationSpecSet);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextEntityExtractionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextEntityExtractionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecSet = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextEntityExtractionConfig {
    return { annotationSpecSet: isSet(object.annotationSpecSet) ? globalThis.String(object.annotationSpecSet) : "" };
  },

  toJSON(message: TextEntityExtractionConfig): unknown {
    const obj: any = {};
    if (message.annotationSpecSet !== "") {
      obj.annotationSpecSet = message.annotationSpecSet;
    }
    return obj;
  },

  create(base?: DeepPartial<TextEntityExtractionConfig>): TextEntityExtractionConfig {
    return TextEntityExtractionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextEntityExtractionConfig>): TextEntityExtractionConfig {
    const message = createBaseTextEntityExtractionConfig();
    message.annotationSpecSet = object.annotationSpecSet ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
