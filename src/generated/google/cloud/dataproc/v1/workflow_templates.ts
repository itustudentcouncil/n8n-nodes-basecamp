// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataproc/v1/workflow_templates.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { Empty } from "../../../protobuf/empty.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { ClusterConfig } from "./clusters.js";
import {
  FlinkJob,
  HadoopJob,
  HiveJob,
  JobScheduling,
  PigJob,
  PrestoJob,
  PySparkJob,
  SparkJob,
  SparkRJob,
  SparkSqlJob,
  TrinoJob,
} from "./jobs.js";

export const protobufPackage = "google.cloud.dataproc.v1";

/** A Dataproc workflow template resource. */
export interface WorkflowTemplate {
  id: string;
  /**
   * Output only. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   */
  name: string;
  /**
   * Optional. Used to perform a consistent read-modify-write.
   *
   * This field should be left blank for a `CreateWorkflowTemplate` request. It
   * is required for an `UpdateWorkflowTemplate` request, and must match the
   * current server version. A typical update template flow would fetch the
   * current template with a `GetWorkflowTemplate` request, which will return
   * the current template with the `version` field filled in with the
   * current server version. The user updates other fields in the template,
   * then returns it as part of the `UpdateWorkflowTemplate` request.
   */
  version: number;
  /** Output only. The time template was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time template was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Optional. The labels to associate with this template. These labels
   * will be propagated to all jobs and clusters created by the workflow
   * instance.
   *
   * Label **keys** must contain 1 to 63 characters, and must conform to
   * [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).
   *
   * Label **values** may be empty, but, if present, must contain 1 to 63
   * characters, and must conform to
   * [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).
   *
   * No more than 32 labels can be associated with a template.
   */
  labels: { [key: string]: string };
  /** Required. WorkflowTemplate scheduling information. */
  placement:
    | WorkflowTemplatePlacement
    | undefined;
  /** Required. The Directed Acyclic Graph of Jobs to submit. */
  jobs: OrderedJob[];
  /**
   * Optional. Template parameters whose values are substituted into the
   * template. Values for parameters must be provided when the template is
   * instantiated.
   */
  parameters: TemplateParameter[];
  /**
   * Optional. Timeout duration for the DAG of jobs, expressed in seconds (see
   * [JSON representation of
   * duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
   * The timeout duration must be from 10 minutes ("600s") to 24 hours
   * ("86400s"). The timer begins when the first job is submitted. If the
   * workflow is running at the end of the timeout period, any remaining jobs
   * are cancelled, the workflow is ended, and if the workflow was running on a
   * [managed
   * cluster](/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
   * the cluster is deleted.
   */
  dagTimeout:
    | Duration
    | undefined;
  /**
   * Optional. Encryption settings for encrypting workflow template job
   * arguments.
   */
  encryptionConfig: WorkflowTemplate_EncryptionConfig | undefined;
}

/** Encryption settings for encrypting workflow template job arguments. */
export interface WorkflowTemplate_EncryptionConfig {
  /**
   * Optional. The Cloud KMS key name to use for encrypting
   * workflow template job arguments.
   *
   * When this this key is provided, the following workflow template
   * [job arguments]
   * (https://cloud.google.com/dataproc/docs/concepts/workflows/use-workflows#adding_jobs_to_a_template),
   * if present, are
   * [CMEK
   * encrypted](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_workflow_template_data):
   *
   * * [FlinkJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/FlinkJob)
   * * [HadoopJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/HadoopJob)
   * * [SparkJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkJob)
   * * [SparkRJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkRJob)
   * * [PySparkJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/PySparkJob)
   * * [SparkSqlJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkSqlJob)
   *   scriptVariables and queryList.queries
   * * [HiveJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/HiveJob)
   *   scriptVariables and queryList.queries
   * * [PigJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PigJob)
   *   scriptVariables and queryList.queries
   * * [PrestoJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PrestoJob)
   *   scriptVariables and queryList.queries
   */
  kmsKey: string;
}

export interface WorkflowTemplate_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Specifies workflow execution target.
 *
 * Either `managed_cluster` or `cluster_selector` is required.
 */
export interface WorkflowTemplatePlacement {
  /** A cluster that is managed by the workflow. */
  managedCluster?:
    | ManagedCluster
    | undefined;
  /**
   * Optional. A selector that chooses target cluster for jobs based
   * on metadata.
   *
   * The selector is evaluated at the time each job is submitted.
   */
  clusterSelector?: ClusterSelector | undefined;
}

/** Cluster that is managed by the workflow. */
export interface ManagedCluster {
  /**
   * Required. The cluster name prefix. A unique cluster name will be formed by
   * appending a random suffix.
   *
   * The name must contain only lower-case letters (a-z), numbers (0-9),
   * and hyphens (-). Must begin with a letter. Cannot begin or end with
   * hyphen. Must consist of between 2 and 35 characters.
   */
  clusterName: string;
  /** Required. The cluster configuration. */
  config:
    | ClusterConfig
    | undefined;
  /**
   * Optional. The labels to associate with this cluster.
   *
   * Label keys must be between 1 and 63 characters long, and must conform to
   * the following PCRE regular expression:
   * [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}
   *
   * Label values must be between 1 and 63 characters long, and must conform to
   * the following PCRE regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}
   *
   * No more than 32 labels can be associated with a given cluster.
   */
  labels: { [key: string]: string };
}

export interface ManagedCluster_LabelsEntry {
  key: string;
  value: string;
}

/** A selector that chooses target cluster for jobs based on metadata. */
export interface ClusterSelector {
  /**
   * Optional. The zone where workflow process executes. This parameter does not
   * affect the selection of the cluster.
   *
   * If unspecified, the zone of the first cluster matching the selector
   * is used.
   */
  zone: string;
  /**
   * Required. The cluster labels. Cluster must have all labels
   * to match.
   */
  clusterLabels: { [key: string]: string };
}

export interface ClusterSelector_ClusterLabelsEntry {
  key: string;
  value: string;
}

/** A job executed by the workflow. */
export interface OrderedJob {
  /**
   * Required. The step id. The id must be unique among all jobs
   * within the template.
   *
   * The step id is used as prefix for job id, as job
   * `goog-dataproc-workflow-step-id` label, and in
   * [prerequisiteStepIds][google.cloud.dataproc.v1.OrderedJob.prerequisite_step_ids]
   * field from other steps.
   *
   * The id must contain only letters (a-z, A-Z), numbers (0-9),
   * underscores (_), and hyphens (-). Cannot begin or end with underscore
   * or hyphen. Must consist of between 3 and 50 characters.
   */
  stepId: string;
  /** Optional. Job is a Hadoop job. */
  hadoopJob?:
    | HadoopJob
    | undefined;
  /** Optional. Job is a Spark job. */
  sparkJob?:
    | SparkJob
    | undefined;
  /** Optional. Job is a PySpark job. */
  pysparkJob?:
    | PySparkJob
    | undefined;
  /** Optional. Job is a Hive job. */
  hiveJob?:
    | HiveJob
    | undefined;
  /** Optional. Job is a Pig job. */
  pigJob?:
    | PigJob
    | undefined;
  /** Optional. Job is a SparkR job. */
  sparkRJob?:
    | SparkRJob
    | undefined;
  /** Optional. Job is a SparkSql job. */
  sparkSqlJob?:
    | SparkSqlJob
    | undefined;
  /** Optional. Job is a Presto job. */
  prestoJob?:
    | PrestoJob
    | undefined;
  /** Optional. Job is a Trino job. */
  trinoJob?:
    | TrinoJob
    | undefined;
  /** Optional. Job is a Flink job. */
  flinkJob?:
    | FlinkJob
    | undefined;
  /**
   * Optional. The labels to associate with this job.
   *
   * Label keys must be between 1 and 63 characters long, and must conform to
   * the following regular expression:
   * [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}
   *
   * Label values must be between 1 and 63 characters long, and must conform to
   * the following regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}
   *
   * No more than 32 labels can be associated with a given job.
   */
  labels: { [key: string]: string };
  /** Optional. Job scheduling configuration. */
  scheduling:
    | JobScheduling
    | undefined;
  /**
   * Optional. The optional list of prerequisite job step_ids.
   * If not specified, the job will start at the beginning of workflow.
   */
  prerequisiteStepIds: string[];
}

export interface OrderedJob_LabelsEntry {
  key: string;
  value: string;
}

/**
 * A configurable parameter that replaces one or more fields in the template.
 * Parameterizable fields:
 * - Labels
 * - File uris
 * - Job properties
 * - Job arguments
 * - Script variables
 * - Main class (in HadoopJob and SparkJob)
 * - Zone (in ClusterSelector)
 */
export interface TemplateParameter {
  /**
   * Required. Parameter name.
   * The parameter name is used as the key, and paired with the
   * parameter value, which are passed to the template when the template
   * is instantiated.
   * The name must contain only capital letters (A-Z), numbers (0-9), and
   * underscores (_), and must not start with a number. The maximum length is
   * 40 characters.
   */
  name: string;
  /**
   * Required. Paths to all fields that the parameter replaces.
   * A field is allowed to appear in at most one parameter's list of field
   * paths.
   *
   * A field path is similar in syntax to a
   * [google.protobuf.FieldMask][google.protobuf.FieldMask]. For example, a
   * field path that references the zone field of a workflow template's cluster
   * selector would be specified as `placement.clusterSelector.zone`.
   *
   * Also, field paths can reference fields using the following syntax:
   *
   * * Values in maps can be referenced by key:
   *     * labels['key']
   *     * placement.clusterSelector.clusterLabels['key']
   *     * placement.managedCluster.labels['key']
   *     * placement.clusterSelector.clusterLabels['key']
   *     * jobs['step-id'].labels['key']
   *
   * * Jobs in the jobs list can be referenced by step-id:
   *     * jobs['step-id'].hadoopJob.mainJarFileUri
   *     * jobs['step-id'].hiveJob.queryFileUri
   *     * jobs['step-id'].pySparkJob.mainPythonFileUri
   *     * jobs['step-id'].hadoopJob.jarFileUris[0]
   *     * jobs['step-id'].hadoopJob.archiveUris[0]
   *     * jobs['step-id'].hadoopJob.fileUris[0]
   *     * jobs['step-id'].pySparkJob.pythonFileUris[0]
   *
   * * Items in repeated fields can be referenced by a zero-based index:
   *     * jobs['step-id'].sparkJob.args[0]
   *
   * * Other examples:
   *     * jobs['step-id'].hadoopJob.properties['key']
   *     * jobs['step-id'].hadoopJob.args[0]
   *     * jobs['step-id'].hiveJob.scriptVariables['key']
   *     * jobs['step-id'].hadoopJob.mainJarFileUri
   *     * placement.clusterSelector.zone
   *
   * It may not be possible to parameterize maps and repeated fields in their
   * entirety since only individual map values and individual items in repeated
   * fields can be referenced. For example, the following field paths are
   * invalid:
   *
   * - placement.clusterSelector.clusterLabels
   * - jobs['step-id'].sparkJob.args
   */
  fields: string[];
  /**
   * Optional. Brief description of the parameter.
   * Must not exceed 1024 characters.
   */
  description: string;
  /** Optional. Validation rules to be applied to this parameter's value. */
  validation: ParameterValidation | undefined;
}

/** Configuration for parameter validation. */
export interface ParameterValidation {
  /** Validation based on regular expressions. */
  regex?:
    | RegexValidation
    | undefined;
  /** Validation based on a list of allowed values. */
  values?: ValueValidation | undefined;
}

/** Validation based on regular expressions. */
export interface RegexValidation {
  /**
   * Required. RE2 regular expressions used to validate the parameter's value.
   * The value must match the regex in its entirety (substring
   * matches are not sufficient).
   */
  regexes: string[];
}

/** Validation based on a list of allowed values. */
export interface ValueValidation {
  /** Required. List of allowed values for the parameter. */
  values: string[];
}

/** A Dataproc workflow template resource. */
export interface WorkflowMetadata {
  /**
   * Output only. The resource name of the workflow template as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   */
  template: string;
  /**
   * Output only. The version of template at the time of
   * workflow instantiation.
   */
  version: number;
  /** Output only. The create cluster operation metadata. */
  createCluster:
    | ClusterOperation
    | undefined;
  /** Output only. The workflow graph. */
  graph:
    | WorkflowGraph
    | undefined;
  /** Output only. The delete cluster operation metadata. */
  deleteCluster:
    | ClusterOperation
    | undefined;
  /** Output only. The workflow state. */
  state: WorkflowMetadata_State;
  /** Output only. The name of the target cluster. */
  clusterName: string;
  /** Map from parameter names to values that were used for those parameters. */
  parameters: { [key: string]: string };
  /** Output only. Workflow start time. */
  startTime:
    | Date
    | undefined;
  /** Output only. Workflow end time. */
  endTime:
    | Date
    | undefined;
  /** Output only. The UUID of target cluster. */
  clusterUuid: string;
  /**
   * Output only. The timeout duration for the DAG of jobs, expressed in seconds
   * (see [JSON representation of
   * duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
   */
  dagTimeout:
    | Duration
    | undefined;
  /**
   * Output only. DAG start time, only set for workflows with
   * [dag_timeout][google.cloud.dataproc.v1.WorkflowMetadata.dag_timeout] when
   * DAG begins.
   */
  dagStartTime:
    | Date
    | undefined;
  /**
   * Output only. DAG end time, only set for workflows with
   * [dag_timeout][google.cloud.dataproc.v1.WorkflowMetadata.dag_timeout] when
   * DAG ends.
   */
  dagEndTime: Date | undefined;
}

/** The operation state. */
export enum WorkflowMetadata_State {
  /** UNKNOWN - Unused. */
  UNKNOWN = 0,
  /** PENDING - The operation has been created. */
  PENDING = 1,
  /** RUNNING - The operation is running. */
  RUNNING = 2,
  /** DONE - The operation is done; either cancelled or completed. */
  DONE = 3,
  UNRECOGNIZED = -1,
}

export function workflowMetadata_StateFromJSON(object: any): WorkflowMetadata_State {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return WorkflowMetadata_State.UNKNOWN;
    case 1:
    case "PENDING":
      return WorkflowMetadata_State.PENDING;
    case 2:
    case "RUNNING":
      return WorkflowMetadata_State.RUNNING;
    case 3:
    case "DONE":
      return WorkflowMetadata_State.DONE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WorkflowMetadata_State.UNRECOGNIZED;
  }
}

export function workflowMetadata_StateToJSON(object: WorkflowMetadata_State): string {
  switch (object) {
    case WorkflowMetadata_State.UNKNOWN:
      return "UNKNOWN";
    case WorkflowMetadata_State.PENDING:
      return "PENDING";
    case WorkflowMetadata_State.RUNNING:
      return "RUNNING";
    case WorkflowMetadata_State.DONE:
      return "DONE";
    case WorkflowMetadata_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface WorkflowMetadata_ParametersEntry {
  key: string;
  value: string;
}

/** The cluster operation triggered by a workflow. */
export interface ClusterOperation {
  /** Output only. The id of the cluster operation. */
  operationId: string;
  /** Output only. Error, if operation failed. */
  error: string;
  /** Output only. Indicates the operation is done. */
  done: boolean;
}

/** The workflow graph. */
export interface WorkflowGraph {
  /** Output only. The workflow nodes. */
  nodes: WorkflowNode[];
}

/** The workflow node. */
export interface WorkflowNode {
  /** Output only. The name of the node. */
  stepId: string;
  /** Output only. Node's prerequisite nodes. */
  prerequisiteStepIds: string[];
  /** Output only. The job id; populated after the node enters RUNNING state. */
  jobId: string;
  /** Output only. The node state. */
  state: WorkflowNode_NodeState;
  /** Output only. The error detail. */
  error: string;
}

/** The workflow node state. */
export enum WorkflowNode_NodeState {
  /** NODE_STATE_UNSPECIFIED - State is unspecified. */
  NODE_STATE_UNSPECIFIED = 0,
  /** BLOCKED - The node is awaiting prerequisite node to finish. */
  BLOCKED = 1,
  /** RUNNABLE - The node is runnable but not running. */
  RUNNABLE = 2,
  /** RUNNING - The node is running. */
  RUNNING = 3,
  /** COMPLETED - The node completed successfully. */
  COMPLETED = 4,
  /**
   * FAILED - The node failed. A node can be marked FAILED because
   * its ancestor or peer failed.
   */
  FAILED = 5,
  UNRECOGNIZED = -1,
}

export function workflowNode_NodeStateFromJSON(object: any): WorkflowNode_NodeState {
  switch (object) {
    case 0:
    case "NODE_STATE_UNSPECIFIED":
      return WorkflowNode_NodeState.NODE_STATE_UNSPECIFIED;
    case 1:
    case "BLOCKED":
      return WorkflowNode_NodeState.BLOCKED;
    case 2:
    case "RUNNABLE":
      return WorkflowNode_NodeState.RUNNABLE;
    case 3:
    case "RUNNING":
      return WorkflowNode_NodeState.RUNNING;
    case 4:
    case "COMPLETED":
      return WorkflowNode_NodeState.COMPLETED;
    case 5:
    case "FAILED":
      return WorkflowNode_NodeState.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WorkflowNode_NodeState.UNRECOGNIZED;
  }
}

export function workflowNode_NodeStateToJSON(object: WorkflowNode_NodeState): string {
  switch (object) {
    case WorkflowNode_NodeState.NODE_STATE_UNSPECIFIED:
      return "NODE_STATE_UNSPECIFIED";
    case WorkflowNode_NodeState.BLOCKED:
      return "BLOCKED";
    case WorkflowNode_NodeState.RUNNABLE:
      return "RUNNABLE";
    case WorkflowNode_NodeState.RUNNING:
      return "RUNNING";
    case WorkflowNode_NodeState.COMPLETED:
      return "COMPLETED";
    case WorkflowNode_NodeState.FAILED:
      return "FAILED";
    case WorkflowNode_NodeState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A request to create a workflow template. */
export interface CreateWorkflowTemplateRequest {
  /**
   * Required. The resource name of the region or location, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.create`, the resource name of the
   *   region has the following format:
   *   `projects/{project_id}/regions/{region}`
   *
   * * For `projects.locations.workflowTemplates.create`, the resource name of
   *   the location has the following format:
   *   `projects/{project_id}/locations/{location}`
   */
  parent: string;
  /** Required. The Dataproc workflow template to create. */
  template: WorkflowTemplate | undefined;
}

/** A request to fetch a workflow template. */
export interface GetWorkflowTemplateRequest {
  /**
   * Required. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.get`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates.get`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   */
  name: string;
  /**
   * Optional. The version of workflow template to retrieve. Only previously
   * instantiated versions can be retrieved.
   *
   * If unspecified, retrieves the current version.
   */
  version: number;
}

/** A request to instantiate a workflow template. */
export interface InstantiateWorkflowTemplateRequest {
  /**
   * Required. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.instantiate`, the resource name
   * of the template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates.instantiate`, the resource name
   *   of the template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   */
  name: string;
  /**
   * Optional. The version of workflow template to instantiate. If specified,
   * the workflow will be instantiated only if the current version of
   * the workflow template has the supplied version.
   *
   * This option cannot be used to instantiate a previous version of
   * workflow template.
   */
  version: number;
  /**
   * Optional. A tag that prevents multiple concurrent workflow
   * instances with the same tag from running. This mitigates risk of
   * concurrent instances started due to retries.
   *
   * It is recommended to always set this value to a
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier).
   *
   * The tag must contain only letters (a-z, A-Z), numbers (0-9),
   * underscores (_), and hyphens (-). The maximum length is 40 characters.
   */
  requestId: string;
  /**
   * Optional. Map from parameter names to values that should be used for those
   * parameters. Values may not exceed 1000 characters.
   */
  parameters: { [key: string]: string };
}

export interface InstantiateWorkflowTemplateRequest_ParametersEntry {
  key: string;
  value: string;
}

/** A request to instantiate an inline workflow template. */
export interface InstantiateInlineWorkflowTemplateRequest {
  /**
   * Required. The resource name of the region or location, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates,instantiateinline`, the resource
   *   name of the region has the following format:
   *   `projects/{project_id}/regions/{region}`
   *
   * * For `projects.locations.workflowTemplates.instantiateinline`, the
   *   resource name of the location has the following format:
   *   `projects/{project_id}/locations/{location}`
   */
  parent: string;
  /** Required. The workflow template to instantiate. */
  template:
    | WorkflowTemplate
    | undefined;
  /**
   * Optional. A tag that prevents multiple concurrent workflow
   * instances with the same tag from running. This mitigates risk of
   * concurrent instances started due to retries.
   *
   * It is recommended to always set this value to a
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier).
   *
   * The tag must contain only letters (a-z, A-Z), numbers (0-9),
   * underscores (_), and hyphens (-). The maximum length is 40 characters.
   */
  requestId: string;
}

/** A request to update a workflow template. */
export interface UpdateWorkflowTemplateRequest {
  /**
   * Required. The updated workflow template.
   *
   * The `template.version` field must match the current version.
   */
  template: WorkflowTemplate | undefined;
}

/** A request to list workflow templates in a project. */
export interface ListWorkflowTemplatesRequest {
  /**
   * Required. The resource name of the region or location, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates,list`, the resource
   *   name of the region has the following format:
   *   `projects/{project_id}/regions/{region}`
   *
   * * For `projects.locations.workflowTemplates.list`, the
   *   resource name of the location has the following format:
   *   `projects/{project_id}/locations/{location}`
   */
  parent: string;
  /** Optional. The maximum number of results to return in each response. */
  pageSize: number;
  /**
   * Optional. The page token, returned by a previous call, to request the
   * next page of results.
   */
  pageToken: string;
}

/** A response to a request to list workflow templates in a project. */
export interface ListWorkflowTemplatesResponse {
  /** Output only. WorkflowTemplates list. */
  templates: WorkflowTemplate[];
  /**
   * Output only. This token is included in the response if there are more
   * results to fetch. To fetch additional results, provide this value as the
   * page_token in a subsequent <code>ListWorkflowTemplatesRequest</code>.
   */
  nextPageToken: string;
  /**
   * Output only. List of workflow templates that could not be included in the
   * response. Attempting to get one of these resources may indicate why it was
   * not included in the list response.
   */
  unreachable: string[];
}

/**
 * A request to delete a workflow template.
 *
 * Currently started workflows will remain running.
 */
export interface DeleteWorkflowTemplateRequest {
  /**
   * Required. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.delete`, the resource name
   * of the template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates.instantiate`, the resource name
   *   of the template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   */
  name: string;
  /**
   * Optional. The version of workflow template to delete. If specified,
   * will only delete the template if the current server version matches
   * specified version.
   */
  version: number;
}

function createBaseWorkflowTemplate(): WorkflowTemplate {
  return {
    id: "",
    name: "",
    version: 0,
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    placement: undefined,
    jobs: [],
    parameters: [],
    dagTimeout: undefined,
    encryptionConfig: undefined,
  };
}

export const WorkflowTemplate: MessageFns<WorkflowTemplate> = {
  encode(message: WorkflowTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.version !== 0) {
      writer.uint32(24).int32(message.version);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      WorkflowTemplate_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.placement !== undefined) {
      WorkflowTemplatePlacement.encode(message.placement, writer.uint32(58).fork()).join();
    }
    for (const v of message.jobs) {
      OrderedJob.encode(v!, writer.uint32(66).fork()).join();
    }
    for (const v of message.parameters) {
      TemplateParameter.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.dagTimeout !== undefined) {
      Duration.encode(message.dagTimeout, writer.uint32(82).fork()).join();
    }
    if (message.encryptionConfig !== undefined) {
      WorkflowTemplate_EncryptionConfig.encode(message.encryptionConfig, writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.version = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = WorkflowTemplate_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.placement = WorkflowTemplatePlacement.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.jobs.push(OrderedJob.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.parameters.push(TemplateParameter.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.dagTimeout = Duration.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.encryptionConfig = WorkflowTemplate_EncryptionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowTemplate {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      placement: isSet(object.placement) ? WorkflowTemplatePlacement.fromJSON(object.placement) : undefined,
      jobs: globalThis.Array.isArray(object?.jobs) ? object.jobs.map((e: any) => OrderedJob.fromJSON(e)) : [],
      parameters: globalThis.Array.isArray(object?.parameters)
        ? object.parameters.map((e: any) => TemplateParameter.fromJSON(e))
        : [],
      dagTimeout: isSet(object.dagTimeout) ? Duration.fromJSON(object.dagTimeout) : undefined,
      encryptionConfig: isSet(object.encryptionConfig)
        ? WorkflowTemplate_EncryptionConfig.fromJSON(object.encryptionConfig)
        : undefined,
    };
  },

  toJSON(message: WorkflowTemplate): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.placement !== undefined) {
      obj.placement = WorkflowTemplatePlacement.toJSON(message.placement);
    }
    if (message.jobs?.length) {
      obj.jobs = message.jobs.map((e) => OrderedJob.toJSON(e));
    }
    if (message.parameters?.length) {
      obj.parameters = message.parameters.map((e) => TemplateParameter.toJSON(e));
    }
    if (message.dagTimeout !== undefined) {
      obj.dagTimeout = Duration.toJSON(message.dagTimeout);
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = WorkflowTemplate_EncryptionConfig.toJSON(message.encryptionConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowTemplate>): WorkflowTemplate {
    return WorkflowTemplate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowTemplate>): WorkflowTemplate {
    const message = createBaseWorkflowTemplate();
    message.id = object.id ?? "";
    message.name = object.name ?? "";
    message.version = object.version ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.placement = (object.placement !== undefined && object.placement !== null)
      ? WorkflowTemplatePlacement.fromPartial(object.placement)
      : undefined;
    message.jobs = object.jobs?.map((e) => OrderedJob.fromPartial(e)) || [];
    message.parameters = object.parameters?.map((e) => TemplateParameter.fromPartial(e)) || [];
    message.dagTimeout = (object.dagTimeout !== undefined && object.dagTimeout !== null)
      ? Duration.fromPartial(object.dagTimeout)
      : undefined;
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? WorkflowTemplate_EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    return message;
  },
};

function createBaseWorkflowTemplate_EncryptionConfig(): WorkflowTemplate_EncryptionConfig {
  return { kmsKey: "" };
}

export const WorkflowTemplate_EncryptionConfig: MessageFns<WorkflowTemplate_EncryptionConfig> = {
  encode(message: WorkflowTemplate_EncryptionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKey !== "") {
      writer.uint32(10).string(message.kmsKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowTemplate_EncryptionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowTemplate_EncryptionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowTemplate_EncryptionConfig {
    return { kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "" };
  },

  toJSON(message: WorkflowTemplate_EncryptionConfig): unknown {
    const obj: any = {};
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowTemplate_EncryptionConfig>): WorkflowTemplate_EncryptionConfig {
    return WorkflowTemplate_EncryptionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowTemplate_EncryptionConfig>): WorkflowTemplate_EncryptionConfig {
    const message = createBaseWorkflowTemplate_EncryptionConfig();
    message.kmsKey = object.kmsKey ?? "";
    return message;
  },
};

function createBaseWorkflowTemplate_LabelsEntry(): WorkflowTemplate_LabelsEntry {
  return { key: "", value: "" };
}

export const WorkflowTemplate_LabelsEntry: MessageFns<WorkflowTemplate_LabelsEntry> = {
  encode(message: WorkflowTemplate_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowTemplate_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowTemplate_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowTemplate_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: WorkflowTemplate_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowTemplate_LabelsEntry>): WorkflowTemplate_LabelsEntry {
    return WorkflowTemplate_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowTemplate_LabelsEntry>): WorkflowTemplate_LabelsEntry {
    const message = createBaseWorkflowTemplate_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseWorkflowTemplatePlacement(): WorkflowTemplatePlacement {
  return { managedCluster: undefined, clusterSelector: undefined };
}

export const WorkflowTemplatePlacement: MessageFns<WorkflowTemplatePlacement> = {
  encode(message: WorkflowTemplatePlacement, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.managedCluster !== undefined) {
      ManagedCluster.encode(message.managedCluster, writer.uint32(10).fork()).join();
    }
    if (message.clusterSelector !== undefined) {
      ClusterSelector.encode(message.clusterSelector, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowTemplatePlacement {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowTemplatePlacement();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.managedCluster = ManagedCluster.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.clusterSelector = ClusterSelector.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowTemplatePlacement {
    return {
      managedCluster: isSet(object.managedCluster) ? ManagedCluster.fromJSON(object.managedCluster) : undefined,
      clusterSelector: isSet(object.clusterSelector) ? ClusterSelector.fromJSON(object.clusterSelector) : undefined,
    };
  },

  toJSON(message: WorkflowTemplatePlacement): unknown {
    const obj: any = {};
    if (message.managedCluster !== undefined) {
      obj.managedCluster = ManagedCluster.toJSON(message.managedCluster);
    }
    if (message.clusterSelector !== undefined) {
      obj.clusterSelector = ClusterSelector.toJSON(message.clusterSelector);
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowTemplatePlacement>): WorkflowTemplatePlacement {
    return WorkflowTemplatePlacement.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowTemplatePlacement>): WorkflowTemplatePlacement {
    const message = createBaseWorkflowTemplatePlacement();
    message.managedCluster = (object.managedCluster !== undefined && object.managedCluster !== null)
      ? ManagedCluster.fromPartial(object.managedCluster)
      : undefined;
    message.clusterSelector = (object.clusterSelector !== undefined && object.clusterSelector !== null)
      ? ClusterSelector.fromPartial(object.clusterSelector)
      : undefined;
    return message;
  },
};

function createBaseManagedCluster(): ManagedCluster {
  return { clusterName: "", config: undefined, labels: {} };
}

export const ManagedCluster: MessageFns<ManagedCluster> = {
  encode(message: ManagedCluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.clusterName !== "") {
      writer.uint32(18).string(message.clusterName);
    }
    if (message.config !== undefined) {
      ClusterConfig.encode(message.config, writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ManagedCluster_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ManagedCluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseManagedCluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.clusterName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.config = ClusterConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = ManagedCluster_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ManagedCluster {
    return {
      clusterName: isSet(object.clusterName) ? globalThis.String(object.clusterName) : "",
      config: isSet(object.config) ? ClusterConfig.fromJSON(object.config) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: ManagedCluster): unknown {
    const obj: any = {};
    if (message.clusterName !== "") {
      obj.clusterName = message.clusterName;
    }
    if (message.config !== undefined) {
      obj.config = ClusterConfig.toJSON(message.config);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ManagedCluster>): ManagedCluster {
    return ManagedCluster.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ManagedCluster>): ManagedCluster {
    const message = createBaseManagedCluster();
    message.clusterName = object.clusterName ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? ClusterConfig.fromPartial(object.config)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseManagedCluster_LabelsEntry(): ManagedCluster_LabelsEntry {
  return { key: "", value: "" };
}

export const ManagedCluster_LabelsEntry: MessageFns<ManagedCluster_LabelsEntry> = {
  encode(message: ManagedCluster_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ManagedCluster_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseManagedCluster_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ManagedCluster_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ManagedCluster_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ManagedCluster_LabelsEntry>): ManagedCluster_LabelsEntry {
    return ManagedCluster_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ManagedCluster_LabelsEntry>): ManagedCluster_LabelsEntry {
    const message = createBaseManagedCluster_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseClusterSelector(): ClusterSelector {
  return { zone: "", clusterLabels: {} };
}

export const ClusterSelector: MessageFns<ClusterSelector> = {
  encode(message: ClusterSelector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.zone !== "") {
      writer.uint32(10).string(message.zone);
    }
    Object.entries(message.clusterLabels).forEach(([key, value]) => {
      ClusterSelector_ClusterLabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterSelector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterSelector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.zone = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = ClusterSelector_ClusterLabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.clusterLabels[entry2.key] = entry2.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterSelector {
    return {
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      clusterLabels: isObject(object.clusterLabels)
        ? Object.entries(object.clusterLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: ClusterSelector): unknown {
    const obj: any = {};
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.clusterLabels) {
      const entries = Object.entries(message.clusterLabels);
      if (entries.length > 0) {
        obj.clusterLabels = {};
        entries.forEach(([k, v]) => {
          obj.clusterLabels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ClusterSelector>): ClusterSelector {
    return ClusterSelector.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClusterSelector>): ClusterSelector {
    const message = createBaseClusterSelector();
    message.zone = object.zone ?? "";
    message.clusterLabels = Object.entries(object.clusterLabels ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseClusterSelector_ClusterLabelsEntry(): ClusterSelector_ClusterLabelsEntry {
  return { key: "", value: "" };
}

export const ClusterSelector_ClusterLabelsEntry: MessageFns<ClusterSelector_ClusterLabelsEntry> = {
  encode(message: ClusterSelector_ClusterLabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterSelector_ClusterLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterSelector_ClusterLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterSelector_ClusterLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ClusterSelector_ClusterLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ClusterSelector_ClusterLabelsEntry>): ClusterSelector_ClusterLabelsEntry {
    return ClusterSelector_ClusterLabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClusterSelector_ClusterLabelsEntry>): ClusterSelector_ClusterLabelsEntry {
    const message = createBaseClusterSelector_ClusterLabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseOrderedJob(): OrderedJob {
  return {
    stepId: "",
    hadoopJob: undefined,
    sparkJob: undefined,
    pysparkJob: undefined,
    hiveJob: undefined,
    pigJob: undefined,
    sparkRJob: undefined,
    sparkSqlJob: undefined,
    prestoJob: undefined,
    trinoJob: undefined,
    flinkJob: undefined,
    labels: {},
    scheduling: undefined,
    prerequisiteStepIds: [],
  };
}

export const OrderedJob: MessageFns<OrderedJob> = {
  encode(message: OrderedJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stepId !== "") {
      writer.uint32(10).string(message.stepId);
    }
    if (message.hadoopJob !== undefined) {
      HadoopJob.encode(message.hadoopJob, writer.uint32(18).fork()).join();
    }
    if (message.sparkJob !== undefined) {
      SparkJob.encode(message.sparkJob, writer.uint32(26).fork()).join();
    }
    if (message.pysparkJob !== undefined) {
      PySparkJob.encode(message.pysparkJob, writer.uint32(34).fork()).join();
    }
    if (message.hiveJob !== undefined) {
      HiveJob.encode(message.hiveJob, writer.uint32(42).fork()).join();
    }
    if (message.pigJob !== undefined) {
      PigJob.encode(message.pigJob, writer.uint32(50).fork()).join();
    }
    if (message.sparkRJob !== undefined) {
      SparkRJob.encode(message.sparkRJob, writer.uint32(90).fork()).join();
    }
    if (message.sparkSqlJob !== undefined) {
      SparkSqlJob.encode(message.sparkSqlJob, writer.uint32(58).fork()).join();
    }
    if (message.prestoJob !== undefined) {
      PrestoJob.encode(message.prestoJob, writer.uint32(98).fork()).join();
    }
    if (message.trinoJob !== undefined) {
      TrinoJob.encode(message.trinoJob, writer.uint32(106).fork()).join();
    }
    if (message.flinkJob !== undefined) {
      FlinkJob.encode(message.flinkJob, writer.uint32(114).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      OrderedJob_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.scheduling !== undefined) {
      JobScheduling.encode(message.scheduling, writer.uint32(74).fork()).join();
    }
    for (const v of message.prerequisiteStepIds) {
      writer.uint32(82).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderedJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderedJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.stepId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.hadoopJob = HadoopJob.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sparkJob = SparkJob.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pysparkJob = PySparkJob.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.hiveJob = HiveJob.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.pigJob = PigJob.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.sparkRJob = SparkRJob.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.sparkSqlJob = SparkSqlJob.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.prestoJob = PrestoJob.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.trinoJob = TrinoJob.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.flinkJob = FlinkJob.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = OrderedJob_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.scheduling = JobScheduling.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.prerequisiteStepIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderedJob {
    return {
      stepId: isSet(object.stepId) ? globalThis.String(object.stepId) : "",
      hadoopJob: isSet(object.hadoopJob) ? HadoopJob.fromJSON(object.hadoopJob) : undefined,
      sparkJob: isSet(object.sparkJob) ? SparkJob.fromJSON(object.sparkJob) : undefined,
      pysparkJob: isSet(object.pysparkJob) ? PySparkJob.fromJSON(object.pysparkJob) : undefined,
      hiveJob: isSet(object.hiveJob) ? HiveJob.fromJSON(object.hiveJob) : undefined,
      pigJob: isSet(object.pigJob) ? PigJob.fromJSON(object.pigJob) : undefined,
      sparkRJob: isSet(object.sparkRJob) ? SparkRJob.fromJSON(object.sparkRJob) : undefined,
      sparkSqlJob: isSet(object.sparkSqlJob) ? SparkSqlJob.fromJSON(object.sparkSqlJob) : undefined,
      prestoJob: isSet(object.prestoJob) ? PrestoJob.fromJSON(object.prestoJob) : undefined,
      trinoJob: isSet(object.trinoJob) ? TrinoJob.fromJSON(object.trinoJob) : undefined,
      flinkJob: isSet(object.flinkJob) ? FlinkJob.fromJSON(object.flinkJob) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      scheduling: isSet(object.scheduling) ? JobScheduling.fromJSON(object.scheduling) : undefined,
      prerequisiteStepIds: globalThis.Array.isArray(object?.prerequisiteStepIds)
        ? object.prerequisiteStepIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: OrderedJob): unknown {
    const obj: any = {};
    if (message.stepId !== "") {
      obj.stepId = message.stepId;
    }
    if (message.hadoopJob !== undefined) {
      obj.hadoopJob = HadoopJob.toJSON(message.hadoopJob);
    }
    if (message.sparkJob !== undefined) {
      obj.sparkJob = SparkJob.toJSON(message.sparkJob);
    }
    if (message.pysparkJob !== undefined) {
      obj.pysparkJob = PySparkJob.toJSON(message.pysparkJob);
    }
    if (message.hiveJob !== undefined) {
      obj.hiveJob = HiveJob.toJSON(message.hiveJob);
    }
    if (message.pigJob !== undefined) {
      obj.pigJob = PigJob.toJSON(message.pigJob);
    }
    if (message.sparkRJob !== undefined) {
      obj.sparkRJob = SparkRJob.toJSON(message.sparkRJob);
    }
    if (message.sparkSqlJob !== undefined) {
      obj.sparkSqlJob = SparkSqlJob.toJSON(message.sparkSqlJob);
    }
    if (message.prestoJob !== undefined) {
      obj.prestoJob = PrestoJob.toJSON(message.prestoJob);
    }
    if (message.trinoJob !== undefined) {
      obj.trinoJob = TrinoJob.toJSON(message.trinoJob);
    }
    if (message.flinkJob !== undefined) {
      obj.flinkJob = FlinkJob.toJSON(message.flinkJob);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.scheduling !== undefined) {
      obj.scheduling = JobScheduling.toJSON(message.scheduling);
    }
    if (message.prerequisiteStepIds?.length) {
      obj.prerequisiteStepIds = message.prerequisiteStepIds;
    }
    return obj;
  },

  create(base?: DeepPartial<OrderedJob>): OrderedJob {
    return OrderedJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderedJob>): OrderedJob {
    const message = createBaseOrderedJob();
    message.stepId = object.stepId ?? "";
    message.hadoopJob = (object.hadoopJob !== undefined && object.hadoopJob !== null)
      ? HadoopJob.fromPartial(object.hadoopJob)
      : undefined;
    message.sparkJob = (object.sparkJob !== undefined && object.sparkJob !== null)
      ? SparkJob.fromPartial(object.sparkJob)
      : undefined;
    message.pysparkJob = (object.pysparkJob !== undefined && object.pysparkJob !== null)
      ? PySparkJob.fromPartial(object.pysparkJob)
      : undefined;
    message.hiveJob = (object.hiveJob !== undefined && object.hiveJob !== null)
      ? HiveJob.fromPartial(object.hiveJob)
      : undefined;
    message.pigJob = (object.pigJob !== undefined && object.pigJob !== null)
      ? PigJob.fromPartial(object.pigJob)
      : undefined;
    message.sparkRJob = (object.sparkRJob !== undefined && object.sparkRJob !== null)
      ? SparkRJob.fromPartial(object.sparkRJob)
      : undefined;
    message.sparkSqlJob = (object.sparkSqlJob !== undefined && object.sparkSqlJob !== null)
      ? SparkSqlJob.fromPartial(object.sparkSqlJob)
      : undefined;
    message.prestoJob = (object.prestoJob !== undefined && object.prestoJob !== null)
      ? PrestoJob.fromPartial(object.prestoJob)
      : undefined;
    message.trinoJob = (object.trinoJob !== undefined && object.trinoJob !== null)
      ? TrinoJob.fromPartial(object.trinoJob)
      : undefined;
    message.flinkJob = (object.flinkJob !== undefined && object.flinkJob !== null)
      ? FlinkJob.fromPartial(object.flinkJob)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.scheduling = (object.scheduling !== undefined && object.scheduling !== null)
      ? JobScheduling.fromPartial(object.scheduling)
      : undefined;
    message.prerequisiteStepIds = object.prerequisiteStepIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseOrderedJob_LabelsEntry(): OrderedJob_LabelsEntry {
  return { key: "", value: "" };
}

export const OrderedJob_LabelsEntry: MessageFns<OrderedJob_LabelsEntry> = {
  encode(message: OrderedJob_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OrderedJob_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOrderedJob_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OrderedJob_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: OrderedJob_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<OrderedJob_LabelsEntry>): OrderedJob_LabelsEntry {
    return OrderedJob_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OrderedJob_LabelsEntry>): OrderedJob_LabelsEntry {
    const message = createBaseOrderedJob_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTemplateParameter(): TemplateParameter {
  return { name: "", fields: [], description: "", validation: undefined };
}

export const TemplateParameter: MessageFns<TemplateParameter> = {
  encode(message: TemplateParameter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.fields) {
      writer.uint32(18).string(v!);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.validation !== undefined) {
      ParameterValidation.encode(message.validation, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TemplateParameter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTemplateParameter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fields.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.validation = ParameterValidation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TemplateParameter {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      fields: globalThis.Array.isArray(object?.fields) ? object.fields.map((e: any) => globalThis.String(e)) : [],
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      validation: isSet(object.validation) ? ParameterValidation.fromJSON(object.validation) : undefined,
    };
  },

  toJSON(message: TemplateParameter): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.fields?.length) {
      obj.fields = message.fields;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.validation !== undefined) {
      obj.validation = ParameterValidation.toJSON(message.validation);
    }
    return obj;
  },

  create(base?: DeepPartial<TemplateParameter>): TemplateParameter {
    return TemplateParameter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TemplateParameter>): TemplateParameter {
    const message = createBaseTemplateParameter();
    message.name = object.name ?? "";
    message.fields = object.fields?.map((e) => e) || [];
    message.description = object.description ?? "";
    message.validation = (object.validation !== undefined && object.validation !== null)
      ? ParameterValidation.fromPartial(object.validation)
      : undefined;
    return message;
  },
};

function createBaseParameterValidation(): ParameterValidation {
  return { regex: undefined, values: undefined };
}

export const ParameterValidation: MessageFns<ParameterValidation> = {
  encode(message: ParameterValidation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.regex !== undefined) {
      RegexValidation.encode(message.regex, writer.uint32(10).fork()).join();
    }
    if (message.values !== undefined) {
      ValueValidation.encode(message.values, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ParameterValidation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseParameterValidation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.regex = RegexValidation.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.values = ValueValidation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ParameterValidation {
    return {
      regex: isSet(object.regex) ? RegexValidation.fromJSON(object.regex) : undefined,
      values: isSet(object.values) ? ValueValidation.fromJSON(object.values) : undefined,
    };
  },

  toJSON(message: ParameterValidation): unknown {
    const obj: any = {};
    if (message.regex !== undefined) {
      obj.regex = RegexValidation.toJSON(message.regex);
    }
    if (message.values !== undefined) {
      obj.values = ValueValidation.toJSON(message.values);
    }
    return obj;
  },

  create(base?: DeepPartial<ParameterValidation>): ParameterValidation {
    return ParameterValidation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ParameterValidation>): ParameterValidation {
    const message = createBaseParameterValidation();
    message.regex = (object.regex !== undefined && object.regex !== null)
      ? RegexValidation.fromPartial(object.regex)
      : undefined;
    message.values = (object.values !== undefined && object.values !== null)
      ? ValueValidation.fromPartial(object.values)
      : undefined;
    return message;
  },
};

function createBaseRegexValidation(): RegexValidation {
  return { regexes: [] };
}

export const RegexValidation: MessageFns<RegexValidation> = {
  encode(message: RegexValidation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.regexes) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RegexValidation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRegexValidation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.regexes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RegexValidation {
    return {
      regexes: globalThis.Array.isArray(object?.regexes) ? object.regexes.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: RegexValidation): unknown {
    const obj: any = {};
    if (message.regexes?.length) {
      obj.regexes = message.regexes;
    }
    return obj;
  },

  create(base?: DeepPartial<RegexValidation>): RegexValidation {
    return RegexValidation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RegexValidation>): RegexValidation {
    const message = createBaseRegexValidation();
    message.regexes = object.regexes?.map((e) => e) || [];
    return message;
  },
};

function createBaseValueValidation(): ValueValidation {
  return { values: [] };
}

export const ValueValidation: MessageFns<ValueValidation> = {
  encode(message: ValueValidation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.values) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ValueValidation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValueValidation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.values.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ValueValidation {
    return {
      values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: ValueValidation): unknown {
    const obj: any = {};
    if (message.values?.length) {
      obj.values = message.values;
    }
    return obj;
  },

  create(base?: DeepPartial<ValueValidation>): ValueValidation {
    return ValueValidation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ValueValidation>): ValueValidation {
    const message = createBaseValueValidation();
    message.values = object.values?.map((e) => e) || [];
    return message;
  },
};

function createBaseWorkflowMetadata(): WorkflowMetadata {
  return {
    template: "",
    version: 0,
    createCluster: undefined,
    graph: undefined,
    deleteCluster: undefined,
    state: 0,
    clusterName: "",
    parameters: {},
    startTime: undefined,
    endTime: undefined,
    clusterUuid: "",
    dagTimeout: undefined,
    dagStartTime: undefined,
    dagEndTime: undefined,
  };
}

export const WorkflowMetadata: MessageFns<WorkflowMetadata> = {
  encode(message: WorkflowMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.template !== "") {
      writer.uint32(10).string(message.template);
    }
    if (message.version !== 0) {
      writer.uint32(16).int32(message.version);
    }
    if (message.createCluster !== undefined) {
      ClusterOperation.encode(message.createCluster, writer.uint32(26).fork()).join();
    }
    if (message.graph !== undefined) {
      WorkflowGraph.encode(message.graph, writer.uint32(34).fork()).join();
    }
    if (message.deleteCluster !== undefined) {
      ClusterOperation.encode(message.deleteCluster, writer.uint32(42).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.clusterName !== "") {
      writer.uint32(58).string(message.clusterName);
    }
    Object.entries(message.parameters).forEach(([key, value]) => {
      WorkflowMetadata_ParametersEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(74).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(82).fork()).join();
    }
    if (message.clusterUuid !== "") {
      writer.uint32(90).string(message.clusterUuid);
    }
    if (message.dagTimeout !== undefined) {
      Duration.encode(message.dagTimeout, writer.uint32(98).fork()).join();
    }
    if (message.dagStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.dagStartTime), writer.uint32(106).fork()).join();
    }
    if (message.dagEndTime !== undefined) {
      Timestamp.encode(toTimestamp(message.dagEndTime), writer.uint32(114).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.template = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.version = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createCluster = ClusterOperation.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.graph = WorkflowGraph.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.deleteCluster = ClusterOperation.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.clusterName = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = WorkflowMetadata_ParametersEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.parameters[entry8.key] = entry8.value;
          }
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.clusterUuid = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.dagTimeout = Duration.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.dagStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.dagEndTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowMetadata {
    return {
      template: isSet(object.template) ? globalThis.String(object.template) : "",
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
      createCluster: isSet(object.createCluster) ? ClusterOperation.fromJSON(object.createCluster) : undefined,
      graph: isSet(object.graph) ? WorkflowGraph.fromJSON(object.graph) : undefined,
      deleteCluster: isSet(object.deleteCluster) ? ClusterOperation.fromJSON(object.deleteCluster) : undefined,
      state: isSet(object.state) ? workflowMetadata_StateFromJSON(object.state) : 0,
      clusterName: isSet(object.clusterName) ? globalThis.String(object.clusterName) : "",
      parameters: isObject(object.parameters)
        ? Object.entries(object.parameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      clusterUuid: isSet(object.clusterUuid) ? globalThis.String(object.clusterUuid) : "",
      dagTimeout: isSet(object.dagTimeout) ? Duration.fromJSON(object.dagTimeout) : undefined,
      dagStartTime: isSet(object.dagStartTime) ? fromJsonTimestamp(object.dagStartTime) : undefined,
      dagEndTime: isSet(object.dagEndTime) ? fromJsonTimestamp(object.dagEndTime) : undefined,
    };
  },

  toJSON(message: WorkflowMetadata): unknown {
    const obj: any = {};
    if (message.template !== "") {
      obj.template = message.template;
    }
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    if (message.createCluster !== undefined) {
      obj.createCluster = ClusterOperation.toJSON(message.createCluster);
    }
    if (message.graph !== undefined) {
      obj.graph = WorkflowGraph.toJSON(message.graph);
    }
    if (message.deleteCluster !== undefined) {
      obj.deleteCluster = ClusterOperation.toJSON(message.deleteCluster);
    }
    if (message.state !== 0) {
      obj.state = workflowMetadata_StateToJSON(message.state);
    }
    if (message.clusterName !== "") {
      obj.clusterName = message.clusterName;
    }
    if (message.parameters) {
      const entries = Object.entries(message.parameters);
      if (entries.length > 0) {
        obj.parameters = {};
        entries.forEach(([k, v]) => {
          obj.parameters[k] = v;
        });
      }
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.clusterUuid !== "") {
      obj.clusterUuid = message.clusterUuid;
    }
    if (message.dagTimeout !== undefined) {
      obj.dagTimeout = Duration.toJSON(message.dagTimeout);
    }
    if (message.dagStartTime !== undefined) {
      obj.dagStartTime = message.dagStartTime.toISOString();
    }
    if (message.dagEndTime !== undefined) {
      obj.dagEndTime = message.dagEndTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowMetadata>): WorkflowMetadata {
    return WorkflowMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowMetadata>): WorkflowMetadata {
    const message = createBaseWorkflowMetadata();
    message.template = object.template ?? "";
    message.version = object.version ?? 0;
    message.createCluster = (object.createCluster !== undefined && object.createCluster !== null)
      ? ClusterOperation.fromPartial(object.createCluster)
      : undefined;
    message.graph = (object.graph !== undefined && object.graph !== null)
      ? WorkflowGraph.fromPartial(object.graph)
      : undefined;
    message.deleteCluster = (object.deleteCluster !== undefined && object.deleteCluster !== null)
      ? ClusterOperation.fromPartial(object.deleteCluster)
      : undefined;
    message.state = object.state ?? 0;
    message.clusterName = object.clusterName ?? "";
    message.parameters = Object.entries(object.parameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.clusterUuid = object.clusterUuid ?? "";
    message.dagTimeout = (object.dagTimeout !== undefined && object.dagTimeout !== null)
      ? Duration.fromPartial(object.dagTimeout)
      : undefined;
    message.dagStartTime = object.dagStartTime ?? undefined;
    message.dagEndTime = object.dagEndTime ?? undefined;
    return message;
  },
};

function createBaseWorkflowMetadata_ParametersEntry(): WorkflowMetadata_ParametersEntry {
  return { key: "", value: "" };
}

export const WorkflowMetadata_ParametersEntry: MessageFns<WorkflowMetadata_ParametersEntry> = {
  encode(message: WorkflowMetadata_ParametersEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowMetadata_ParametersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowMetadata_ParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowMetadata_ParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: WorkflowMetadata_ParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowMetadata_ParametersEntry>): WorkflowMetadata_ParametersEntry {
    return WorkflowMetadata_ParametersEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowMetadata_ParametersEntry>): WorkflowMetadata_ParametersEntry {
    const message = createBaseWorkflowMetadata_ParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseClusterOperation(): ClusterOperation {
  return { operationId: "", error: "", done: false };
}

export const ClusterOperation: MessageFns<ClusterOperation> = {
  encode(message: ClusterOperation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operationId !== "") {
      writer.uint32(10).string(message.operationId);
    }
    if (message.error !== "") {
      writer.uint32(18).string(message.error);
    }
    if (message.done !== false) {
      writer.uint32(24).bool(message.done);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterOperation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterOperation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operationId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.error = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.done = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterOperation {
    return {
      operationId: isSet(object.operationId) ? globalThis.String(object.operationId) : "",
      error: isSet(object.error) ? globalThis.String(object.error) : "",
      done: isSet(object.done) ? globalThis.Boolean(object.done) : false,
    };
  },

  toJSON(message: ClusterOperation): unknown {
    const obj: any = {};
    if (message.operationId !== "") {
      obj.operationId = message.operationId;
    }
    if (message.error !== "") {
      obj.error = message.error;
    }
    if (message.done !== false) {
      obj.done = message.done;
    }
    return obj;
  },

  create(base?: DeepPartial<ClusterOperation>): ClusterOperation {
    return ClusterOperation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClusterOperation>): ClusterOperation {
    const message = createBaseClusterOperation();
    message.operationId = object.operationId ?? "";
    message.error = object.error ?? "";
    message.done = object.done ?? false;
    return message;
  },
};

function createBaseWorkflowGraph(): WorkflowGraph {
  return { nodes: [] };
}

export const WorkflowGraph: MessageFns<WorkflowGraph> = {
  encode(message: WorkflowGraph, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.nodes) {
      WorkflowNode.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowGraph {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowGraph();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.nodes.push(WorkflowNode.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowGraph {
    return {
      nodes: globalThis.Array.isArray(object?.nodes) ? object.nodes.map((e: any) => WorkflowNode.fromJSON(e)) : [],
    };
  },

  toJSON(message: WorkflowGraph): unknown {
    const obj: any = {};
    if (message.nodes?.length) {
      obj.nodes = message.nodes.map((e) => WorkflowNode.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowGraph>): WorkflowGraph {
    return WorkflowGraph.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowGraph>): WorkflowGraph {
    const message = createBaseWorkflowGraph();
    message.nodes = object.nodes?.map((e) => WorkflowNode.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWorkflowNode(): WorkflowNode {
  return { stepId: "", prerequisiteStepIds: [], jobId: "", state: 0, error: "" };
}

export const WorkflowNode: MessageFns<WorkflowNode> = {
  encode(message: WorkflowNode, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stepId !== "") {
      writer.uint32(10).string(message.stepId);
    }
    for (const v of message.prerequisiteStepIds) {
      writer.uint32(18).string(v!);
    }
    if (message.jobId !== "") {
      writer.uint32(26).string(message.jobId);
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.error !== "") {
      writer.uint32(50).string(message.error);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowNode {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowNode();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.stepId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.prerequisiteStepIds.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.error = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowNode {
    return {
      stepId: isSet(object.stepId) ? globalThis.String(object.stepId) : "",
      prerequisiteStepIds: globalThis.Array.isArray(object?.prerequisiteStepIds)
        ? object.prerequisiteStepIds.map((e: any) => globalThis.String(e))
        : [],
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      state: isSet(object.state) ? workflowNode_NodeStateFromJSON(object.state) : 0,
      error: isSet(object.error) ? globalThis.String(object.error) : "",
    };
  },

  toJSON(message: WorkflowNode): unknown {
    const obj: any = {};
    if (message.stepId !== "") {
      obj.stepId = message.stepId;
    }
    if (message.prerequisiteStepIds?.length) {
      obj.prerequisiteStepIds = message.prerequisiteStepIds;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.state !== 0) {
      obj.state = workflowNode_NodeStateToJSON(message.state);
    }
    if (message.error !== "") {
      obj.error = message.error;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowNode>): WorkflowNode {
    return WorkflowNode.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowNode>): WorkflowNode {
    const message = createBaseWorkflowNode();
    message.stepId = object.stepId ?? "";
    message.prerequisiteStepIds = object.prerequisiteStepIds?.map((e) => e) || [];
    message.jobId = object.jobId ?? "";
    message.state = object.state ?? 0;
    message.error = object.error ?? "";
    return message;
  },
};

function createBaseCreateWorkflowTemplateRequest(): CreateWorkflowTemplateRequest {
  return { parent: "", template: undefined };
}

export const CreateWorkflowTemplateRequest: MessageFns<CreateWorkflowTemplateRequest> = {
  encode(message: CreateWorkflowTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.template !== undefined) {
      WorkflowTemplate.encode(message.template, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateWorkflowTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateWorkflowTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.template = WorkflowTemplate.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateWorkflowTemplateRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      template: isSet(object.template) ? WorkflowTemplate.fromJSON(object.template) : undefined,
    };
  },

  toJSON(message: CreateWorkflowTemplateRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.template !== undefined) {
      obj.template = WorkflowTemplate.toJSON(message.template);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateWorkflowTemplateRequest>): CreateWorkflowTemplateRequest {
    return CreateWorkflowTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateWorkflowTemplateRequest>): CreateWorkflowTemplateRequest {
    const message = createBaseCreateWorkflowTemplateRequest();
    message.parent = object.parent ?? "";
    message.template = (object.template !== undefined && object.template !== null)
      ? WorkflowTemplate.fromPartial(object.template)
      : undefined;
    return message;
  },
};

function createBaseGetWorkflowTemplateRequest(): GetWorkflowTemplateRequest {
  return { name: "", version: 0 };
}

export const GetWorkflowTemplateRequest: MessageFns<GetWorkflowTemplateRequest> = {
  encode(message: GetWorkflowTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.version !== 0) {
      writer.uint32(16).int32(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetWorkflowTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetWorkflowTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.version = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetWorkflowTemplateRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
    };
  },

  toJSON(message: GetWorkflowTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    return obj;
  },

  create(base?: DeepPartial<GetWorkflowTemplateRequest>): GetWorkflowTemplateRequest {
    return GetWorkflowTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetWorkflowTemplateRequest>): GetWorkflowTemplateRequest {
    const message = createBaseGetWorkflowTemplateRequest();
    message.name = object.name ?? "";
    message.version = object.version ?? 0;
    return message;
  },
};

function createBaseInstantiateWorkflowTemplateRequest(): InstantiateWorkflowTemplateRequest {
  return { name: "", version: 0, requestId: "", parameters: {} };
}

export const InstantiateWorkflowTemplateRequest: MessageFns<InstantiateWorkflowTemplateRequest> = {
  encode(message: InstantiateWorkflowTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.version !== 0) {
      writer.uint32(16).int32(message.version);
    }
    if (message.requestId !== "") {
      writer.uint32(42).string(message.requestId);
    }
    Object.entries(message.parameters).forEach(([key, value]) => {
      InstantiateWorkflowTemplateRequest_ParametersEntry.encode({ key: key as any, value }, writer.uint32(50).fork())
        .join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstantiateWorkflowTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstantiateWorkflowTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.version = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.requestId = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = InstantiateWorkflowTemplateRequest_ParametersEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.parameters[entry6.key] = entry6.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstantiateWorkflowTemplateRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
      parameters: isObject(object.parameters)
        ? Object.entries(object.parameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: InstantiateWorkflowTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    if (message.parameters) {
      const entries = Object.entries(message.parameters);
      if (entries.length > 0) {
        obj.parameters = {};
        entries.forEach(([k, v]) => {
          obj.parameters[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<InstantiateWorkflowTemplateRequest>): InstantiateWorkflowTemplateRequest {
    return InstantiateWorkflowTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstantiateWorkflowTemplateRequest>): InstantiateWorkflowTemplateRequest {
    const message = createBaseInstantiateWorkflowTemplateRequest();
    message.name = object.name ?? "";
    message.version = object.version ?? 0;
    message.requestId = object.requestId ?? "";
    message.parameters = Object.entries(object.parameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseInstantiateWorkflowTemplateRequest_ParametersEntry(): InstantiateWorkflowTemplateRequest_ParametersEntry {
  return { key: "", value: "" };
}

export const InstantiateWorkflowTemplateRequest_ParametersEntry: MessageFns<
  InstantiateWorkflowTemplateRequest_ParametersEntry
> = {
  encode(
    message: InstantiateWorkflowTemplateRequest_ParametersEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstantiateWorkflowTemplateRequest_ParametersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstantiateWorkflowTemplateRequest_ParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstantiateWorkflowTemplateRequest_ParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: InstantiateWorkflowTemplateRequest_ParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<InstantiateWorkflowTemplateRequest_ParametersEntry>,
  ): InstantiateWorkflowTemplateRequest_ParametersEntry {
    return InstantiateWorkflowTemplateRequest_ParametersEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<InstantiateWorkflowTemplateRequest_ParametersEntry>,
  ): InstantiateWorkflowTemplateRequest_ParametersEntry {
    const message = createBaseInstantiateWorkflowTemplateRequest_ParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseInstantiateInlineWorkflowTemplateRequest(): InstantiateInlineWorkflowTemplateRequest {
  return { parent: "", template: undefined, requestId: "" };
}

export const InstantiateInlineWorkflowTemplateRequest: MessageFns<InstantiateInlineWorkflowTemplateRequest> = {
  encode(message: InstantiateInlineWorkflowTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.template !== undefined) {
      WorkflowTemplate.encode(message.template, writer.uint32(18).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(26).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstantiateInlineWorkflowTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstantiateInlineWorkflowTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.template = WorkflowTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstantiateInlineWorkflowTemplateRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      template: isSet(object.template) ? WorkflowTemplate.fromJSON(object.template) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: InstantiateInlineWorkflowTemplateRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.template !== undefined) {
      obj.template = WorkflowTemplate.toJSON(message.template);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<InstantiateInlineWorkflowTemplateRequest>): InstantiateInlineWorkflowTemplateRequest {
    return InstantiateInlineWorkflowTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstantiateInlineWorkflowTemplateRequest>): InstantiateInlineWorkflowTemplateRequest {
    const message = createBaseInstantiateInlineWorkflowTemplateRequest();
    message.parent = object.parent ?? "";
    message.template = (object.template !== undefined && object.template !== null)
      ? WorkflowTemplate.fromPartial(object.template)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseUpdateWorkflowTemplateRequest(): UpdateWorkflowTemplateRequest {
  return { template: undefined };
}

export const UpdateWorkflowTemplateRequest: MessageFns<UpdateWorkflowTemplateRequest> = {
  encode(message: UpdateWorkflowTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.template !== undefined) {
      WorkflowTemplate.encode(message.template, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateWorkflowTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateWorkflowTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.template = WorkflowTemplate.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateWorkflowTemplateRequest {
    return { template: isSet(object.template) ? WorkflowTemplate.fromJSON(object.template) : undefined };
  },

  toJSON(message: UpdateWorkflowTemplateRequest): unknown {
    const obj: any = {};
    if (message.template !== undefined) {
      obj.template = WorkflowTemplate.toJSON(message.template);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateWorkflowTemplateRequest>): UpdateWorkflowTemplateRequest {
    return UpdateWorkflowTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateWorkflowTemplateRequest>): UpdateWorkflowTemplateRequest {
    const message = createBaseUpdateWorkflowTemplateRequest();
    message.template = (object.template !== undefined && object.template !== null)
      ? WorkflowTemplate.fromPartial(object.template)
      : undefined;
    return message;
  },
};

function createBaseListWorkflowTemplatesRequest(): ListWorkflowTemplatesRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListWorkflowTemplatesRequest: MessageFns<ListWorkflowTemplatesRequest> = {
  encode(message: ListWorkflowTemplatesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkflowTemplatesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkflowTemplatesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkflowTemplatesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListWorkflowTemplatesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkflowTemplatesRequest>): ListWorkflowTemplatesRequest {
    return ListWorkflowTemplatesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkflowTemplatesRequest>): ListWorkflowTemplatesRequest {
    const message = createBaseListWorkflowTemplatesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListWorkflowTemplatesResponse(): ListWorkflowTemplatesResponse {
  return { templates: [], nextPageToken: "", unreachable: [] };
}

export const ListWorkflowTemplatesResponse: MessageFns<ListWorkflowTemplatesResponse> = {
  encode(message: ListWorkflowTemplatesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.templates) {
      WorkflowTemplate.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkflowTemplatesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkflowTemplatesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.templates.push(WorkflowTemplate.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkflowTemplatesResponse {
    return {
      templates: globalThis.Array.isArray(object?.templates)
        ? object.templates.map((e: any) => WorkflowTemplate.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListWorkflowTemplatesResponse): unknown {
    const obj: any = {};
    if (message.templates?.length) {
      obj.templates = message.templates.map((e) => WorkflowTemplate.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkflowTemplatesResponse>): ListWorkflowTemplatesResponse {
    return ListWorkflowTemplatesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkflowTemplatesResponse>): ListWorkflowTemplatesResponse {
    const message = createBaseListWorkflowTemplatesResponse();
    message.templates = object.templates?.map((e) => WorkflowTemplate.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseDeleteWorkflowTemplateRequest(): DeleteWorkflowTemplateRequest {
  return { name: "", version: 0 };
}

export const DeleteWorkflowTemplateRequest: MessageFns<DeleteWorkflowTemplateRequest> = {
  encode(message: DeleteWorkflowTemplateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.version !== 0) {
      writer.uint32(16).int32(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteWorkflowTemplateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteWorkflowTemplateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.version = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteWorkflowTemplateRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
    };
  },

  toJSON(message: DeleteWorkflowTemplateRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteWorkflowTemplateRequest>): DeleteWorkflowTemplateRequest {
    return DeleteWorkflowTemplateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteWorkflowTemplateRequest>): DeleteWorkflowTemplateRequest {
    const message = createBaseDeleteWorkflowTemplateRequest();
    message.name = object.name ?? "";
    message.version = object.version ?? 0;
    return message;
  },
};

/**
 * The API interface for managing Workflow Templates in the
 * Dataproc API.
 */
export type WorkflowTemplateServiceDefinition = typeof WorkflowTemplateServiceDefinition;
export const WorkflowTemplateServiceDefinition = {
  name: "WorkflowTemplateService",
  fullName: "google.cloud.dataproc.v1.WorkflowTemplateService",
  methods: {
    /** Creates new workflow template. */
    createWorkflowTemplate: {
      name: "CreateWorkflowTemplate",
      requestType: CreateWorkflowTemplateRequest,
      requestStream: false,
      responseType: WorkflowTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 112, 97, 114, 101, 110, 116, 44, 116, 101, 109, 112, 108, 97, 116, 101])],
          578365826: [
            Buffer.from([
              130,
              1,
              58,
              8,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              90,
              63,
              58,
              8,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              34,
              51,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              34,
              53,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Retrieves the latest workflow template.
     *
     * Can retrieve previously instantiated template by specifying optional
     * version parameter.
     */
    getWorkflowTemplate: {
      name: "GetWorkflowTemplate",
      requestType: GetWorkflowTemplateRequest,
      requestStream: false,
      responseType: WorkflowTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              110,
              90,
              53,
              18,
              51,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              18,
              53,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Instantiates a template and begins execution.
     *
     * The returned Operation can be used to track execution of
     * workflow by polling
     * [operations.get][google.longrunning.Operations.GetOperation].
     * The Operation will complete when entire workflow is finished.
     *
     * The running workflow can be aborted via
     * [operations.cancel][google.longrunning.Operations.CancelOperation].
     * This will cause any inflight jobs to be cancelled and workflow-owned
     * clusters to be deleted.
     *
     * The [Operation.metadata][google.longrunning.Operation.metadata] will be
     * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
     * Also see [Using
     * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
     *
     * On successful completion,
     * [Operation.response][google.longrunning.Operation.response] will be
     * [Empty][google.protobuf.Empty].
     */
    instantiateWorkflowTemplate: {
      name: "InstantiateWorkflowTemplate",
      requestType: InstantiateWorkflowTemplateRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              41,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              16,
              87,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([4, 110, 97, 109, 101]),
            Buffer.from([15, 110, 97, 109, 101, 44, 112, 97, 114, 97, 109, 101, 116, 101, 114, 115]),
          ],
          578365826: [
            Buffer.from([
              140,
              1,
              58,
              1,
              42,
              90,
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              110,
              115,
              116,
              97,
              110,
              116,
              105,
              97,
              116,
              101,
              34,
              65,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              110,
              115,
              116,
              97,
              110,
              116,
              105,
              97,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Instantiates a template and begins execution.
     *
     * This method is equivalent to executing the sequence
     * [CreateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.CreateWorkflowTemplate],
     * [InstantiateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.InstantiateWorkflowTemplate],
     * [DeleteWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.DeleteWorkflowTemplate].
     *
     * The returned Operation can be used to track execution of
     * workflow by polling
     * [operations.get][google.longrunning.Operations.GetOperation].
     * The Operation will complete when entire workflow is finished.
     *
     * The running workflow can be aborted via
     * [operations.cancel][google.longrunning.Operations.CancelOperation].
     * This will cause any inflight jobs to be cancelled and workflow-owned
     * clusters to be deleted.
     *
     * The [Operation.metadata][google.longrunning.Operation.metadata] will be
     * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
     * Also see [Using
     * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
     *
     * On successful completion,
     * [Operation.response][google.longrunning.Operation.response] will be
     * [Empty][google.protobuf.Empty].
     */
    instantiateInlineWorkflowTemplate: {
      name: "InstantiateInlineWorkflowTemplate",
      requestType: InstantiateInlineWorkflowTemplateRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              41,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              16,
              87,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([15, 112, 97, 114, 101, 110, 116, 44, 116, 101, 109, 112, 108, 97, 116, 101])],
          578365826: [
            Buffer.from([
              166,
              1,
              58,
              8,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              90,
              81,
              58,
              8,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              34,
              69,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              58,
              105,
              110,
              115,
              116,
              97,
              110,
              116,
              105,
              97,
              116,
              101,
              73,
              110,
              108,
              105,
              110,
              101,
              34,
              71,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              58,
              105,
              110,
              115,
              116,
              97,
              110,
              116,
              105,
              97,
              116,
              101,
              73,
              110,
              108,
              105,
              110,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Updates (replaces) workflow template. The updated template
     * must contain version that matches the current server version.
     */
    updateWorkflowTemplate: {
      name: "UpdateWorkflowTemplate",
      requestType: UpdateWorkflowTemplateRequest,
      requestStream: false,
      responseType: WorkflowTemplate,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 116, 101, 109, 112, 108, 97, 116, 101])],
          578365826: [
            Buffer.from([
              148,
              1,
              58,
              8,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              90,
              72,
              58,
              8,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              26,
              60,
              47,
              118,
              49,
              47,
              123,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              26,
              62,
              47,
              118,
              49,
              47,
              123,
              116,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists workflows that match the specified filter in the request. */
    listWorkflowTemplates: {
      name: "ListWorkflowTemplates",
      requestType: ListWorkflowTemplatesRequest,
      requestStream: false,
      responseType: ListWorkflowTemplatesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              110,
              90,
              53,
              18,
              51,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              18,
              53,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a workflow template. It does not cancel in-progress workflows. */
    deleteWorkflowTemplate: {
      name: "DeleteWorkflowTemplate",
      requestType: DeleteWorkflowTemplateRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              110,
              90,
              53,
              42,
              51,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              114,
              101,
              103,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
              42,
              53,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              84,
              101,
              109,
              112,
              108,
              97,
              116,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface WorkflowTemplateServiceImplementation<CallContextExt = {}> {
  /** Creates new workflow template. */
  createWorkflowTemplate(
    request: CreateWorkflowTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowTemplate>>;
  /**
   * Retrieves the latest workflow template.
   *
   * Can retrieve previously instantiated template by specifying optional
   * version parameter.
   */
  getWorkflowTemplate(
    request: GetWorkflowTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowTemplate>>;
  /**
   * Instantiates a template and begins execution.
   *
   * The returned Operation can be used to track execution of
   * workflow by polling
   * [operations.get][google.longrunning.Operations.GetOperation].
   * The Operation will complete when entire workflow is finished.
   *
   * The running workflow can be aborted via
   * [operations.cancel][google.longrunning.Operations.CancelOperation].
   * This will cause any inflight jobs to be cancelled and workflow-owned
   * clusters to be deleted.
   *
   * The [Operation.metadata][google.longrunning.Operation.metadata] will be
   * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
   * Also see [Using
   * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
   *
   * On successful completion,
   * [Operation.response][google.longrunning.Operation.response] will be
   * [Empty][google.protobuf.Empty].
   */
  instantiateWorkflowTemplate(
    request: InstantiateWorkflowTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Instantiates a template and begins execution.
   *
   * This method is equivalent to executing the sequence
   * [CreateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.CreateWorkflowTemplate],
   * [InstantiateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.InstantiateWorkflowTemplate],
   * [DeleteWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.DeleteWorkflowTemplate].
   *
   * The returned Operation can be used to track execution of
   * workflow by polling
   * [operations.get][google.longrunning.Operations.GetOperation].
   * The Operation will complete when entire workflow is finished.
   *
   * The running workflow can be aborted via
   * [operations.cancel][google.longrunning.Operations.CancelOperation].
   * This will cause any inflight jobs to be cancelled and workflow-owned
   * clusters to be deleted.
   *
   * The [Operation.metadata][google.longrunning.Operation.metadata] will be
   * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
   * Also see [Using
   * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
   *
   * On successful completion,
   * [Operation.response][google.longrunning.Operation.response] will be
   * [Empty][google.protobuf.Empty].
   */
  instantiateInlineWorkflowTemplate(
    request: InstantiateInlineWorkflowTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Updates (replaces) workflow template. The updated template
   * must contain version that matches the current server version.
   */
  updateWorkflowTemplate(
    request: UpdateWorkflowTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowTemplate>>;
  /** Lists workflows that match the specified filter in the request. */
  listWorkflowTemplates(
    request: ListWorkflowTemplatesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListWorkflowTemplatesResponse>>;
  /** Deletes a workflow template. It does not cancel in-progress workflows. */
  deleteWorkflowTemplate(
    request: DeleteWorkflowTemplateRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
}

export interface WorkflowTemplateServiceClient<CallOptionsExt = {}> {
  /** Creates new workflow template. */
  createWorkflowTemplate(
    request: DeepPartial<CreateWorkflowTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowTemplate>;
  /**
   * Retrieves the latest workflow template.
   *
   * Can retrieve previously instantiated template by specifying optional
   * version parameter.
   */
  getWorkflowTemplate(
    request: DeepPartial<GetWorkflowTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowTemplate>;
  /**
   * Instantiates a template and begins execution.
   *
   * The returned Operation can be used to track execution of
   * workflow by polling
   * [operations.get][google.longrunning.Operations.GetOperation].
   * The Operation will complete when entire workflow is finished.
   *
   * The running workflow can be aborted via
   * [operations.cancel][google.longrunning.Operations.CancelOperation].
   * This will cause any inflight jobs to be cancelled and workflow-owned
   * clusters to be deleted.
   *
   * The [Operation.metadata][google.longrunning.Operation.metadata] will be
   * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
   * Also see [Using
   * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
   *
   * On successful completion,
   * [Operation.response][google.longrunning.Operation.response] will be
   * [Empty][google.protobuf.Empty].
   */
  instantiateWorkflowTemplate(
    request: DeepPartial<InstantiateWorkflowTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Instantiates a template and begins execution.
   *
   * This method is equivalent to executing the sequence
   * [CreateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.CreateWorkflowTemplate],
   * [InstantiateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.InstantiateWorkflowTemplate],
   * [DeleteWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.DeleteWorkflowTemplate].
   *
   * The returned Operation can be used to track execution of
   * workflow by polling
   * [operations.get][google.longrunning.Operations.GetOperation].
   * The Operation will complete when entire workflow is finished.
   *
   * The running workflow can be aborted via
   * [operations.cancel][google.longrunning.Operations.CancelOperation].
   * This will cause any inflight jobs to be cancelled and workflow-owned
   * clusters to be deleted.
   *
   * The [Operation.metadata][google.longrunning.Operation.metadata] will be
   * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
   * Also see [Using
   * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
   *
   * On successful completion,
   * [Operation.response][google.longrunning.Operation.response] will be
   * [Empty][google.protobuf.Empty].
   */
  instantiateInlineWorkflowTemplate(
    request: DeepPartial<InstantiateInlineWorkflowTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Updates (replaces) workflow template. The updated template
   * must contain version that matches the current server version.
   */
  updateWorkflowTemplate(
    request: DeepPartial<UpdateWorkflowTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowTemplate>;
  /** Lists workflows that match the specified filter in the request. */
  listWorkflowTemplates(
    request: DeepPartial<ListWorkflowTemplatesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListWorkflowTemplatesResponse>;
  /** Deletes a workflow template. It does not cancel in-progress workflows. */
  deleteWorkflowTemplate(
    request: DeepPartial<DeleteWorkflowTemplateRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
