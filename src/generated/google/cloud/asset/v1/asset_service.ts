// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/asset/v1/asset_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Policy } from "../../../iam/v1/policy.js";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Struct } from "../../../protobuf/struct.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { Expr } from "../../../type/expr.js";
import {
  Asset,
  ConditionEvaluation,
  EffectiveTagDetails,
  IamPolicyAnalysisResult,
  IamPolicyAnalysisState,
  IamPolicySearchResult,
  ResourceSearchResult,
  TemporalAsset,
  TimeWindow,
} from "./assets.js";

export const protobufPackage = "google.cloud.asset.v1";

/** Asset content type. */
export enum ContentType {
  /** CONTENT_TYPE_UNSPECIFIED - Unspecified content type. */
  CONTENT_TYPE_UNSPECIFIED = 0,
  /** RESOURCE - Resource metadata. */
  RESOURCE = 1,
  /** IAM_POLICY - The actual IAM policy set on a resource. */
  IAM_POLICY = 2,
  /** ORG_POLICY - The organization policy set on an asset. */
  ORG_POLICY = 4,
  /** ACCESS_POLICY - The Access Context Manager policy set on an asset. */
  ACCESS_POLICY = 5,
  /** OS_INVENTORY - The runtime OS Inventory information. */
  OS_INVENTORY = 6,
  /** RELATIONSHIP - The related resources. */
  RELATIONSHIP = 7,
  UNRECOGNIZED = -1,
}

export function contentTypeFromJSON(object: any): ContentType {
  switch (object) {
    case 0:
    case "CONTENT_TYPE_UNSPECIFIED":
      return ContentType.CONTENT_TYPE_UNSPECIFIED;
    case 1:
    case "RESOURCE":
      return ContentType.RESOURCE;
    case 2:
    case "IAM_POLICY":
      return ContentType.IAM_POLICY;
    case 4:
    case "ORG_POLICY":
      return ContentType.ORG_POLICY;
    case 5:
    case "ACCESS_POLICY":
      return ContentType.ACCESS_POLICY;
    case 6:
    case "OS_INVENTORY":
      return ContentType.OS_INVENTORY;
    case 7:
    case "RELATIONSHIP":
      return ContentType.RELATIONSHIP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ContentType.UNRECOGNIZED;
  }
}

export function contentTypeToJSON(object: ContentType): string {
  switch (object) {
    case ContentType.CONTENT_TYPE_UNSPECIFIED:
      return "CONTENT_TYPE_UNSPECIFIED";
    case ContentType.RESOURCE:
      return "RESOURCE";
    case ContentType.IAM_POLICY:
      return "IAM_POLICY";
    case ContentType.ORG_POLICY:
      return "ORG_POLICY";
    case ContentType.ACCESS_POLICY:
      return "ACCESS_POLICY";
    case ContentType.OS_INVENTORY:
      return "OS_INVENTORY";
    case ContentType.RELATIONSHIP:
      return "RELATIONSHIP";
    case ContentType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Represents the metadata of the longrunning operation for the
 * AnalyzeIamPolicyLongrunning RPC.
 */
export interface AnalyzeIamPolicyLongrunningMetadata {
  /** Output only. The time the operation was created. */
  createTime: Date | undefined;
}

/** Export asset request. */
export interface ExportAssetsRequest {
  /**
   * Required. The relative name of the root asset. This can only be an
   * organization number (such as "organizations/123"), a project ID (such as
   * "projects/my-project-id"), or a project number (such as "projects/12345"),
   * or a folder number (such as "folders/123").
   */
  parent: string;
  /**
   * Timestamp to take an asset snapshot. This can only be set to a timestamp
   * between the current time and the current time minus 35 days (inclusive).
   * If not specified, the current time will be used. Due to delays in resource
   * data collection and indexing, there is a volatile window during which
   * running the same query may get different results.
   */
  readTime:
    | Date
    | undefined;
  /**
   * A list of asset types to take a snapshot for. For example:
   * "compute.googleapis.com/Disk".
   *
   * Regular expressions are also supported. For example:
   *
   * * "compute.googleapis.com.*" snapshots resources whose asset type starts
   * with "compute.googleapis.com".
   * * ".*Instance" snapshots resources whose asset type ends with "Instance".
   * * ".*Instance.*" snapshots resources whose asset type contains "Instance".
   *
   * See [RE2](https://github.com/google/re2/wiki/Syntax) for all supported
   * regular expression syntax. If the regular expression does not match any
   * supported asset type, an INVALID_ARGUMENT error will be returned.
   *
   * If specified, only matching assets will be returned, otherwise, it will
   * snapshot all asset types. See [Introduction to Cloud Asset
   * Inventory](https://cloud.google.com/asset-inventory/docs/overview)
   * for all supported asset types.
   */
  assetTypes: string[];
  /**
   * Asset content type. If not specified, no content but the asset name will be
   * returned.
   */
  contentType: ContentType;
  /**
   * Required. Output configuration indicating where the results will be output
   * to.
   */
  outputConfig:
    | OutputConfig
    | undefined;
  /**
   * A list of relationship types to export, for example:
   * `INSTANCE_TO_INSTANCEGROUP`. This field should only be specified if
   * content_type=RELATIONSHIP.
   * * If specified:
   * it snapshots specified relationships. It returns an error if
   * any of the [relationship_types] doesn't belong to the supported
   * relationship types of the [asset_types] or if any of the [asset_types]
   * doesn't belong to the source types of the [relationship_types].
   * * Otherwise:
   * it snapshots the supported relationships for all [asset_types] or returns
   * an error if any of the [asset_types] has no relationship support.
   * An unspecified asset types field means all supported asset_types.
   * See [Introduction to Cloud Asset
   * Inventory](https://cloud.google.com/asset-inventory/docs/overview) for all
   * supported asset types and relationship types.
   */
  relationshipTypes: string[];
}

/**
 * The export asset response. This message is returned by the
 * [google.longrunning.Operations.GetOperation][google.longrunning.Operations.GetOperation]
 * method in the returned
 * [google.longrunning.Operation.response][google.longrunning.Operation.response]
 * field.
 */
export interface ExportAssetsResponse {
  /** Time the snapshot was taken. */
  readTime:
    | Date
    | undefined;
  /** Output configuration indicating where the results were output to. */
  outputConfig:
    | OutputConfig
    | undefined;
  /**
   * Output result indicating where the assets were exported to. For example, a
   * set of actual Cloud Storage object URIs where the assets are exported to.
   * The URIs can be different from what [output_config] has specified, as the
   * service will split the output object into multiple ones once it exceeds a
   * single Cloud Storage object limit.
   */
  outputResult: OutputResult | undefined;
}

/** ListAssets request. */
export interface ListAssetsRequest {
  /**
   * Required. Name of the organization, folder, or project the assets belong
   * to. Format: "organizations/[organization-number]" (such as
   * "organizations/123"), "projects/[project-id]" (such as
   * "projects/my-project-id"), "projects/[project-number]" (such as
   * "projects/12345"), or "folders/[folder-number]" (such as "folders/12345").
   */
  parent: string;
  /**
   * Timestamp to take an asset snapshot. This can only be set to a timestamp
   * between the current time and the current time minus 35 days (inclusive).
   * If not specified, the current time will be used. Due to delays in resource
   * data collection and indexing, there is a volatile window during which
   * running the same query may get different results.
   */
  readTime:
    | Date
    | undefined;
  /**
   * A list of asset types to take a snapshot for. For example:
   * "compute.googleapis.com/Disk".
   *
   * Regular expression is also supported. For example:
   *
   * * "compute.googleapis.com.*" snapshots resources whose asset type starts
   * with "compute.googleapis.com".
   * * ".*Instance" snapshots resources whose asset type ends with "Instance".
   * * ".*Instance.*" snapshots resources whose asset type contains "Instance".
   *
   * See [RE2](https://github.com/google/re2/wiki/Syntax) for all supported
   * regular expression syntax. If the regular expression does not match any
   * supported asset type, an INVALID_ARGUMENT error will be returned.
   *
   * If specified, only matching assets will be returned, otherwise, it will
   * snapshot all asset types. See [Introduction to Cloud Asset
   * Inventory](https://cloud.google.com/asset-inventory/docs/overview)
   * for all supported asset types.
   */
  assetTypes: string[];
  /**
   * Asset content type. If not specified, no content but the asset name will
   * be returned.
   */
  contentType: ContentType;
  /**
   * The maximum number of assets to be returned in a single response. Default
   * is 100, minimum is 1, and maximum is 1000.
   */
  pageSize: number;
  /**
   * The `next_page_token` returned from the previous `ListAssetsResponse`, or
   * unspecified for the first `ListAssetsRequest`. It is a continuation of a
   * prior `ListAssets` call, and the API should return the next page of assets.
   */
  pageToken: string;
  /**
   * A list of relationship types to output, for example:
   * `INSTANCE_TO_INSTANCEGROUP`. This field should only be specified if
   * content_type=RELATIONSHIP.
   * * If specified:
   * it snapshots specified relationships. It returns an error if
   * any of the [relationship_types] doesn't belong to the supported
   * relationship types of the [asset_types] or if any of the [asset_types]
   * doesn't belong to the source types of the [relationship_types].
   * * Otherwise:
   * it snapshots the supported relationships for all [asset_types] or returns
   * an error if any of the [asset_types] has no relationship support.
   * An unspecified asset types field means all supported asset_types.
   * See [Introduction to Cloud Asset
   * Inventory](https://cloud.google.com/asset-inventory/docs/overview)
   * for all supported asset types and relationship types.
   */
  relationshipTypes: string[];
}

/** ListAssets response. */
export interface ListAssetsResponse {
  /** Time the snapshot was taken. */
  readTime:
    | Date
    | undefined;
  /** Assets. */
  assets: Asset[];
  /**
   * Token to retrieve the next page of results. It expires 72 hours after the
   * page token for the first page is generated. Set to empty if there are no
   * remaining results.
   */
  nextPageToken: string;
}

/** Batch get assets history request. */
export interface BatchGetAssetsHistoryRequest {
  /**
   * Required. The relative name of the root asset. It can only be an
   * organization number (such as "organizations/123"), a project ID (such as
   * "projects/my-project-id")", or a project number (such as "projects/12345").
   */
  parent: string;
  /**
   * A list of the full names of the assets.
   * See: https://cloud.google.com/asset-inventory/docs/resource-name-format
   * Example:
   *
   * `//compute.googleapis.com/projects/my_project_123/zones/zone1/instances/instance1`.
   *
   * The request becomes a no-op if the asset name list is empty, and the max
   * size of the asset name list is 100 in one request.
   */
  assetNames: string[];
  /** Optional. The content type. */
  contentType: ContentType;
  /**
   * Optional. The time window for the asset history. Both start_time and
   * end_time are optional and if set, it must be after the current time minus
   * 35 days. If end_time is not set, it is default to current timestamp.
   * If start_time is not set, the snapshot of the assets at end_time will be
   * returned. The returned results contain all temporal assets whose time
   * window overlap with read_time_window.
   */
  readTimeWindow:
    | TimeWindow
    | undefined;
  /**
   * Optional. A list of relationship types to output, for example:
   * `INSTANCE_TO_INSTANCEGROUP`. This field should only be specified if
   * content_type=RELATIONSHIP.
   * * If specified:
   * it outputs specified relationships' history on the [asset_names]. It
   * returns an error if any of the [relationship_types] doesn't belong to the
   * supported relationship types of the [asset_names] or if any of the
   * [asset_names]'s types doesn't belong to the source types of the
   * [relationship_types].
   * * Otherwise:
   * it outputs the supported relationships' history on the [asset_names] or
   * returns an error if any of the [asset_names]'s types has no relationship
   * support.
   * See [Introduction to Cloud Asset
   * Inventory](https://cloud.google.com/asset-inventory/docs/overview) for all
   * supported asset types and relationship types.
   */
  relationshipTypes: string[];
}

/** Batch get assets history response. */
export interface BatchGetAssetsHistoryResponse {
  /** A list of assets with valid time windows. */
  assets: TemporalAsset[];
}

/** Create asset feed request. */
export interface CreateFeedRequest {
  /**
   * Required. The name of the project/folder/organization where this feed
   * should be created in. It can only be an organization number (such as
   * "organizations/123"), a folder number (such as "folders/123"), a project ID
   * (such as "projects/my-project-id"), or a project number (such as
   * "projects/12345").
   */
  parent: string;
  /**
   * Required. This is the client-assigned asset feed identifier and it needs to
   * be unique under a specific parent project/folder/organization.
   */
  feedId: string;
  /**
   * Required. The feed details. The field `name` must be empty and it will be
   * generated in the format of: projects/project_number/feeds/feed_id
   * folders/folder_number/feeds/feed_id
   * organizations/organization_number/feeds/feed_id
   */
  feed: Feed | undefined;
}

/** Get asset feed request. */
export interface GetFeedRequest {
  /**
   * Required. The name of the Feed and it must be in the format of:
   * projects/project_number/feeds/feed_id
   * folders/folder_number/feeds/feed_id
   * organizations/organization_number/feeds/feed_id
   */
  name: string;
}

/** List asset feeds request. */
export interface ListFeedsRequest {
  /**
   * Required. The parent project/folder/organization whose feeds are to be
   * listed. It can only be using project/folder/organization number (such as
   * "folders/12345")", or a project ID (such as "projects/my-project-id").
   */
  parent: string;
}

export interface ListFeedsResponse {
  /** A list of feeds. */
  feeds: Feed[];
}

/** Update asset feed request. */
export interface UpdateFeedRequest {
  /**
   * Required. The new values of feed details. It must match an existing feed
   * and the field `name` must be in the format of:
   * projects/project_number/feeds/feed_id or
   * folders/folder_number/feeds/feed_id or
   * organizations/organization_number/feeds/feed_id.
   */
  feed:
    | Feed
    | undefined;
  /**
   * Required. Only updates the `feed` fields indicated by this mask.
   * The field mask must not be empty, and it must not contain fields that
   * are immutable or only set by the server.
   */
  updateMask: string[] | undefined;
}

export interface DeleteFeedRequest {
  /**
   * Required. The name of the feed and it must be in the format of:
   * projects/project_number/feeds/feed_id
   * folders/folder_number/feeds/feed_id
   * organizations/organization_number/feeds/feed_id
   */
  name: string;
}

/** Output configuration for export assets destination. */
export interface OutputConfig {
  /** Destination on Cloud Storage. */
  gcsDestination?:
    | GcsDestination
    | undefined;
  /**
   * Destination on BigQuery. The output table stores the fields in asset
   * Protobuf as columns in BigQuery.
   */
  bigqueryDestination?: BigQueryDestination | undefined;
}

/** Output result of export assets. */
export interface OutputResult {
  /** Export result on Cloud Storage. */
  gcsResult?: GcsOutputResult | undefined;
}

/** A Cloud Storage output result. */
export interface GcsOutputResult {
  /**
   * List of URIs of the Cloud Storage objects. Example:
   * "gs://bucket_name/object_name".
   */
  uris: string[];
}

/** A Cloud Storage location. */
export interface GcsDestination {
  /**
   * The URI of the Cloud Storage object. It's the same URI that is used by
   * gsutil. Example: "gs://bucket_name/object_name". See [Viewing and
   * Editing Object
   * Metadata](https://cloud.google.com/storage/docs/viewing-editing-metadata)
   * for more information.
   *
   * If the specified Cloud Storage object already exists and there is no
   * [hold](https://cloud.google.com/storage/docs/object-holds), it will be
   * overwritten with the exported result.
   */
  uri?:
    | string
    | undefined;
  /**
   * The URI prefix of all generated Cloud Storage objects. Example:
   * "gs://bucket_name/object_name_prefix". Each object URI is in format:
   * "gs://bucket_name/object_name_prefix/<asset type>/<shard number> and only
   * contains assets for that type. <shard number> starts from 0. Example:
   * "gs://bucket_name/object_name_prefix/compute.googleapis.com/Disk/0" is
   * the first shard of output objects containing all
   * compute.googleapis.com/Disk assets. An INVALID_ARGUMENT error will be
   * returned if file with the same name "gs://bucket_name/object_name_prefix"
   * already exists.
   */
  uriPrefix?: string | undefined;
}

/** A BigQuery destination for exporting assets to. */
export interface BigQueryDestination {
  /**
   * Required. The BigQuery dataset in format
   * "projects/projectId/datasets/datasetId", to which the snapshot result
   * should be exported. If this dataset does not exist, the export call returns
   * an INVALID_ARGUMENT error. Setting the `contentType` for `exportAssets`
   * determines the
   * [schema](/asset-inventory/docs/exporting-to-bigquery#bigquery-schema)
   * of the BigQuery table. Setting `separateTablesPerAssetType` to `TRUE` also
   * influences the schema.
   */
  dataset: string;
  /**
   * Required. The BigQuery table to which the snapshot result should be
   * written. If this table does not exist, a new table with the given name
   * will be created.
   */
  table: string;
  /**
   * If the destination table already exists and this flag is `TRUE`, the
   * table will be overwritten by the contents of assets snapshot. If the flag
   * is `FALSE` or unset and the destination table already exists, the export
   * call returns an INVALID_ARGUMEMT error.
   */
  force: boolean;
  /**
   * [partition_spec] determines whether to export to partitioned table(s) and
   * how to partition the data.
   *
   * If [partition_spec] is unset or [partition_spec.partition_key] is unset or
   * `PARTITION_KEY_UNSPECIFIED`, the snapshot results will be exported to
   * non-partitioned table(s). [force] will decide whether to overwrite existing
   * table(s).
   *
   * If [partition_spec] is specified. First, the snapshot results will be
   * written to partitioned table(s) with two additional timestamp columns,
   * readTime and requestTime, one of which will be the partition key. Secondly,
   * in the case when any destination table already exists, it will first try to
   * update existing table's schema as necessary by appending additional
   * columns. Then, if [force] is `TRUE`, the corresponding partition will be
   * overwritten by the snapshot results (data in different partitions will
   * remain intact); if [force] is unset or `FALSE`, it will append the data. An
   * error will be returned if the schema update or data appension fails.
   */
  partitionSpec:
    | PartitionSpec
    | undefined;
  /**
   * If this flag is `TRUE`, the snapshot results will be written to one or
   * multiple tables, each of which contains results of one asset type. The
   * [force] and [partition_spec] fields will apply to each of them.
   *
   * Field [table] will be concatenated with "_" and the asset type names (see
   * https://cloud.google.com/asset-inventory/docs/supported-asset-types for
   * supported asset types) to construct per-asset-type table names, in which
   * all non-alphanumeric characters like "." and "/" will be substituted by
   * "_". Example: if field [table] is "mytable" and snapshot results
   * contain "storage.googleapis.com/Bucket" assets, the corresponding table
   * name will be "mytable_storage_googleapis_com_Bucket". If any of these
   * tables does not exist, a new table with the concatenated name will be
   * created.
   *
   * When [content_type] in the ExportAssetsRequest is `RESOURCE`, the schema of
   * each table will include RECORD-type columns mapped to the nested fields in
   * the Asset.resource.data field of that asset type (up to the 15 nested level
   * BigQuery supports
   * (https://cloud.google.com/bigquery/docs/nested-repeated#limitations)). The
   * fields in >15 nested levels will be stored in JSON format string as a child
   * column of its parent RECORD column.
   *
   * If error occurs when exporting to any table, the whole export call will
   * return an error but the export results that already succeed will persist.
   * Example: if exporting to table_type_A succeeds when exporting to
   * table_type_B fails during one export call, the results in table_type_A will
   * persist and there will not be partial results persisting in a table.
   */
  separateTablesPerAssetType: boolean;
}

/** Specifications of BigQuery partitioned table as export destination. */
export interface PartitionSpec {
  /** The partition key for BigQuery partitioned table. */
  partitionKey: PartitionSpec_PartitionKey;
}

/**
 * This enum is used to determine the partition key column when exporting
 * assets to BigQuery partitioned table(s). Note that, if the partition key is
 * a timestamp column, the actual partition is based on its date value
 * (expressed in UTC. see details in
 * https://cloud.google.com/bigquery/docs/partitioned-tables#date_timestamp_partitioned_tables).
 */
export enum PartitionSpec_PartitionKey {
  /** PARTITION_KEY_UNSPECIFIED - Unspecified partition key. If used, it means using non-partitioned table. */
  PARTITION_KEY_UNSPECIFIED = 0,
  /**
   * READ_TIME - The time when the snapshot is taken. If specified as partition key, the
   * result table(s) is partitoned by the additional timestamp column,
   * readTime. If [read_time] in ExportAssetsRequest is specified, the
   * readTime column's value will be the same as it. Otherwise, its value will
   * be the current time that is used to take the snapshot.
   */
  READ_TIME = 1,
  /**
   * REQUEST_TIME - The time when the request is received and started to be processed. If
   * specified as partition key, the result table(s) is partitoned by the
   * requestTime column, an additional timestamp column representing when the
   * request was received.
   */
  REQUEST_TIME = 2,
  UNRECOGNIZED = -1,
}

export function partitionSpec_PartitionKeyFromJSON(object: any): PartitionSpec_PartitionKey {
  switch (object) {
    case 0:
    case "PARTITION_KEY_UNSPECIFIED":
      return PartitionSpec_PartitionKey.PARTITION_KEY_UNSPECIFIED;
    case 1:
    case "READ_TIME":
      return PartitionSpec_PartitionKey.READ_TIME;
    case 2:
    case "REQUEST_TIME":
      return PartitionSpec_PartitionKey.REQUEST_TIME;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartitionSpec_PartitionKey.UNRECOGNIZED;
  }
}

export function partitionSpec_PartitionKeyToJSON(object: PartitionSpec_PartitionKey): string {
  switch (object) {
    case PartitionSpec_PartitionKey.PARTITION_KEY_UNSPECIFIED:
      return "PARTITION_KEY_UNSPECIFIED";
    case PartitionSpec_PartitionKey.READ_TIME:
      return "READ_TIME";
    case PartitionSpec_PartitionKey.REQUEST_TIME:
      return "REQUEST_TIME";
    case PartitionSpec_PartitionKey.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A Pub/Sub destination. */
export interface PubsubDestination {
  /**
   * The name of the Pub/Sub topic to publish to.
   * Example: `projects/PROJECT_ID/topics/TOPIC_ID`.
   */
  topic: string;
}

/** Output configuration for asset feed destination. */
export interface FeedOutputConfig {
  /** Destination on Pub/Sub. */
  pubsubDestination?: PubsubDestination | undefined;
}

/**
 * An asset feed used to export asset updates to a destinations.
 * An asset feed filter controls what updates are exported.
 * The asset feed must be created within a project, organization, or
 * folder. Supported destinations are:
 * Pub/Sub topics.
 */
export interface Feed {
  /**
   * Required. The format will be
   * projects/{project_number}/feeds/{client-assigned_feed_identifier} or
   * folders/{folder_number}/feeds/{client-assigned_feed_identifier} or
   * organizations/{organization_number}/feeds/{client-assigned_feed_identifier}
   *
   * The client-assigned feed identifier must be unique within the parent
   * project/folder/organization.
   */
  name: string;
  /**
   * A list of the full names of the assets to receive updates. You must specify
   * either or both of asset_names and asset_types. Only asset updates matching
   * specified asset_names or asset_types are exported to the feed.
   * Example:
   * `//compute.googleapis.com/projects/my_project_123/zones/zone1/instances/instance1`.
   * For a list of the full names for supported asset types, see [Resource
   * name format](/asset-inventory/docs/resource-name-format).
   */
  assetNames: string[];
  /**
   * A list of types of the assets to receive updates. You must specify either
   * or both of asset_names and asset_types. Only asset updates matching
   * specified asset_names or asset_types are exported to the feed.
   * Example: `"compute.googleapis.com/Disk"`
   *
   * For a list of all supported asset types, see
   * [Supported asset types](/asset-inventory/docs/supported-asset-types).
   */
  assetTypes: string[];
  /**
   * Asset content type. If not specified, no content but the asset name and
   * type will be returned.
   */
  contentType: ContentType;
  /**
   * Required. Feed output configuration defining where the asset updates are
   * published to.
   */
  feedOutputConfig:
    | FeedOutputConfig
    | undefined;
  /**
   * A condition which determines whether an asset update should be published.
   * If specified, an asset will be returned only when the expression evaluates
   * to true.
   * When set, `expression` field in the `Expr` must be a valid [CEL expression]
   * (https://github.com/google/cel-spec) on a TemporalAsset with name
   * `temporal_asset`. Example: a Feed with expression ("temporal_asset.deleted
   * == true") will only publish Asset deletions. Other fields of `Expr` are
   * optional.
   *
   * See our [user
   * guide](https://cloud.google.com/asset-inventory/docs/monitoring-asset-changes-with-condition)
   * for detailed instructions.
   */
  condition:
    | Expr
    | undefined;
  /**
   * A list of relationship types to output, for example:
   * `INSTANCE_TO_INSTANCEGROUP`. This field should only be specified if
   * content_type=RELATIONSHIP.
   * * If specified:
   * it outputs specified relationship updates on the [asset_names] or the
   * [asset_types]. It returns an error if any of the [relationship_types]
   * doesn't belong to the supported relationship types of the [asset_names] or
   * [asset_types], or any of the [asset_names] or the [asset_types] doesn't
   * belong to the source types of the [relationship_types].
   * * Otherwise:
   * it outputs the supported relationships of the types of [asset_names] and
   * [asset_types] or returns an error if any of the [asset_names] or the
   * [asset_types] has no replationship support.
   * See [Introduction to Cloud Asset
   * Inventory](https://cloud.google.com/asset-inventory/docs/overview)
   * for all supported asset types and relationship types.
   */
  relationshipTypes: string[];
}

/** Search all resources request. */
export interface SearchAllResourcesRequest {
  /**
   * Required. A scope can be a project, a folder, or an organization. The
   * search is limited to the resources within the `scope`. The caller must be
   * granted the
   * [`cloudasset.assets.searchAllResources`](https://cloud.google.com/asset-inventory/docs/access-control#required_permissions)
   * permission on the desired scope.
   *
   * The allowed values are:
   *
   * * projects/{PROJECT_ID} (e.g., "projects/foo-bar")
   * * projects/{PROJECT_NUMBER} (e.g., "projects/12345678")
   * * folders/{FOLDER_NUMBER} (e.g., "folders/1234567")
   * * organizations/{ORGANIZATION_NUMBER} (e.g., "organizations/123456")
   */
  scope: string;
  /**
   * Optional. The query statement. See [how to construct a
   * query](https://cloud.google.com/asset-inventory/docs/searching-resources#how_to_construct_a_query)
   * for more information. If not specified or empty, it will search all the
   * resources within the specified `scope`.
   *
   * Examples:
   *
   * * `name:Important` to find Google Cloud resources whose name contains
   *   `Important` as a word.
   * * `name=Important` to find the Google Cloud resource whose name is exactly
   *   `Important`.
   * * `displayName:Impor*` to find Google Cloud resources whose display name
   *   contains `Impor` as a prefix of any word in the field.
   * * `location:us-west*` to find Google Cloud resources whose location
   *   contains both `us` and `west` as prefixes.
   * * `labels:prod` to find Google Cloud resources whose labels contain `prod`
   *   as a key or value.
   * * `labels.env:prod` to find Google Cloud resources that have a label `env`
   *   and its value is `prod`.
   * * `labels.env:*` to find Google Cloud resources that have a label `env`.
   * * `tagKeys:env` to find Google Cloud resources that have directly
   *   attached tags where the
   *   [`TagKey.namespacedName`](https://cloud.google.com/resource-manager/reference/rest/v3/tagKeys#resource:-tagkey)
   *   contains `env`.
   * * `tagValues:prod*` to find Google Cloud resources that have directly
   *   attached tags where the
   *   [`TagValue.namespacedName`](https://cloud.google.com/resource-manager/reference/rest/v3/tagValues#resource:-tagvalue)
   *   contains a word prefixed by `prod`.
   * * `tagValueIds=tagValues/123` to find Google Cloud resources that have
   *   directly attached tags where the
   *   [`TagValue.name`](https://cloud.google.com/resource-manager/reference/rest/v3/tagValues#resource:-tagvalue)
   *   is exactly `tagValues/123`.
   * * `effectiveTagKeys:env` to find Google Cloud resources that have
   *   directly attached or inherited tags where the
   *   [`TagKey.namespacedName`](https://cloud.google.com/resource-manager/reference/rest/v3/tagKeys#resource:-tagkey)
   *   contains `env`.
   * * `effectiveTagValues:prod*` to find Google Cloud resources that have
   *   directly attached or inherited tags where the
   *   [`TagValue.namespacedName`](https://cloud.google.com/resource-manager/reference/rest/v3/tagValues#resource:-tagvalue)
   *   contains a word prefixed by `prod`.
   * * `effectiveTagValueIds=tagValues/123` to find Google Cloud resources that
   *    have directly attached or inherited tags where the
   *   [`TagValue.name`](https://cloud.google.com/resource-manager/reference/rest/v3/tagValues#resource:-tagvalue)
   *   is exactly `tagValues/123`.
   * * `kmsKey:key` to find Google Cloud resources encrypted with a
   *   customer-managed encryption key whose name contains `key` as a word. This
   *   field is deprecated. Use the `kmsKeys` field to retrieve Cloud KMS
   *   key information.
   * * `kmsKeys:key` to find Google Cloud resources encrypted with
   *   customer-managed encryption keys whose name contains the word `key`.
   * * `relationships:instance-group-1` to find Google Cloud resources that have
   *   relationships with `instance-group-1` in the related resource name.
   * * `relationships:INSTANCE_TO_INSTANCEGROUP` to find Compute Engine
   *   instances that have relationships of type `INSTANCE_TO_INSTANCEGROUP`.
   * * `relationships.INSTANCE_TO_INSTANCEGROUP:instance-group-1` to find
   *   Compute Engine instances that have relationships with `instance-group-1`
   *   in the Compute Engine instance group resource name, for relationship type
   *   `INSTANCE_TO_INSTANCEGROUP`.
   * * `sccSecurityMarks.key=value` to find Cloud resources that are attached
   *   with security marks whose key is `key` and value is `value`.
   * * `sccSecurityMarks.key:*` to find Cloud resources that are attached with
   *   security marks whose key is `key`.
   * * `state:ACTIVE` to find Google Cloud resources whose state contains
   *   `ACTIVE` as a word.
   * * `NOT state:ACTIVE` to find Google Cloud resources whose state doesn't
   *   contain `ACTIVE` as a word.
   * * `createTime<1609459200` to find Google Cloud resources that were created
   *   before `2021-01-01 00:00:00 UTC`. `1609459200` is the epoch timestamp of
   *   `2021-01-01 00:00:00 UTC` in seconds.
   * * `updateTime>1609459200` to find Google Cloud resources that were updated
   *   after `2021-01-01 00:00:00 UTC`. `1609459200` is the epoch timestamp of
   *   `2021-01-01 00:00:00 UTC` in seconds.
   * * `Important` to find Google Cloud resources that contain `Important` as a
   *   word in any of the searchable fields.
   * * `Impor*` to find Google Cloud resources that contain `Impor` as a prefix
   *   of any word in any of the searchable fields.
   * * `Important location:(us-west1 OR global)` to find Google Cloud
   *   resources that contain `Important` as a word in any of the searchable
   *   fields and are also located in the `us-west1` region or the `global`
   *   location.
   */
  query: string;
  /**
   * Optional. A list of asset types that this request searches for. If empty,
   * it will search all the asset types [supported by search
   * APIs](https://cloud.google.com/asset-inventory/docs/supported-asset-types).
   *
   * Regular expressions are also supported. For example:
   *
   * * "compute.googleapis.com.*" snapshots resources whose asset type starts
   * with "compute.googleapis.com".
   * * ".*Instance" snapshots resources whose asset type ends with "Instance".
   * * ".*Instance.*" snapshots resources whose asset type contains "Instance".
   *
   * See [RE2](https://github.com/google/re2/wiki/Syntax) for all supported
   * regular expression syntax. If the regular expression does not match any
   * supported asset type, an INVALID_ARGUMENT error will be returned.
   */
  assetTypes: string[];
  /**
   * Optional. The page size for search result pagination. Page size is capped
   * at 500 even if a larger value is given. If set to zero or a negative value,
   * server will pick an appropriate default. Returned results may be fewer than
   * requested. When this happens, there could be more results as long as
   * `next_page_token` is returned.
   */
  pageSize: number;
  /**
   * Optional. If present, then retrieve the next batch of results from the
   * preceding call to this method. `page_token` must be the value of
   * `next_page_token` from the previous response. The values of all other
   * method parameters, must be identical to those in the previous call.
   */
  pageToken: string;
  /**
   * Optional. A comma-separated list of fields specifying the sorting order of
   * the results. The default order is ascending. Add " DESC" after the field
   * name to indicate descending order. Redundant space characters are ignored.
   * Example: "location DESC, name".
   * Only the following fields in the response are sortable:
   *
   *   * name
   *   * assetType
   *   * project
   *   * displayName
   *   * description
   *   * location
   *   * createTime
   *   * updateTime
   *   * state
   *   * parentFullResourceName
   *   * parentAssetType
   */
  orderBy: string;
  /**
   * Optional. A comma-separated list of fields that you want returned in the
   * results. The following fields are returned by default if not specified:
   *
   *   * `name`
   *   * `assetType`
   *   * `project`
   *   * `folders`
   *   * `organization`
   *   * `displayName`
   *   * `description`
   *   * `location`
   *   * `labels`
   *   * `tags`
   *   * `effectiveTags`
   *   * `networkTags`
   *   * `kmsKeys`
   *   * `createTime`
   *   * `updateTime`
   *   * `state`
   *   * `additionalAttributes`
   *   * `parentFullResourceName`
   *   * `parentAssetType`
   *
   * Some fields of large size, such as `versionedResources`,
   * `attachedResources`, `effectiveTags` etc., are not returned by default, but
   * you can specify them in the `read_mask` parameter if you want to include
   * them. If `"*"` is specified, all [available
   * fields](https://cloud.google.com/asset-inventory/docs/reference/rest/v1/TopLevel/searchAllResources#resourcesearchresult)
   * are returned.
   * Examples: `"name,location"`, `"name,versionedResources"`, `"*"`.
   * Any invalid field path will trigger INVALID_ARGUMENT error.
   */
  readMask: string[] | undefined;
}

/** Search all resources response. */
export interface SearchAllResourcesResponse {
  /**
   * A list of Resources that match the search query. It contains the resource
   * standard metadata information.
   */
  results: ResourceSearchResult[];
  /**
   * If there are more results than those appearing in this response, then
   * `next_page_token` is included. To get the next set of results, call this
   * method again using the value of `next_page_token` as `page_token`.
   */
  nextPageToken: string;
}

/** Search all IAM policies request. */
export interface SearchAllIamPoliciesRequest {
  /**
   * Required. A scope can be a project, a folder, or an organization. The
   * search is limited to the IAM policies within the `scope`. The caller must
   * be granted the
   * [`cloudasset.assets.searchAllIamPolicies`](https://cloud.google.com/asset-inventory/docs/access-control#required_permissions)
   * permission on the desired scope.
   *
   * The allowed values are:
   *
   * * projects/{PROJECT_ID} (e.g., "projects/foo-bar")
   * * projects/{PROJECT_NUMBER} (e.g., "projects/12345678")
   * * folders/{FOLDER_NUMBER} (e.g., "folders/1234567")
   * * organizations/{ORGANIZATION_NUMBER} (e.g., "organizations/123456")
   */
  scope: string;
  /**
   * Optional. The query statement. See [how to construct a
   * query](https://cloud.google.com/asset-inventory/docs/searching-iam-policies#how_to_construct_a_query)
   * for more information. If not specified or empty, it will search all the
   * IAM policies within the specified `scope`. Note that the query string is
   * compared against each IAM policy binding, including its principals,
   * roles, and IAM conditions. The returned IAM policies will only
   * contain the bindings that match your query. To learn more about the IAM
   * policy structure, see the [IAM policy
   * documentation](https://cloud.google.com/iam/help/allow-policies/structure).
   *
   * Examples:
   *
   * * `policy:amy@gmail.com` to find IAM policy bindings that specify user
   *   "amy@gmail.com".
   * * `policy:roles/compute.admin` to find IAM policy bindings that specify
   *   the Compute Admin role.
   * * `policy:comp*` to find IAM policy bindings that contain "comp" as a
   *   prefix of any word in the binding.
   * * `policy.role.permissions:storage.buckets.update` to find IAM policy
   *   bindings that specify a role containing "storage.buckets.update"
   *   permission. Note that if callers don't have `iam.roles.get` access to a
   *   role's included permissions, policy bindings that specify this role will
   *   be dropped from the search results.
   * * `policy.role.permissions:upd*` to find IAM policy bindings that specify a
   *   role containing "upd" as a prefix of any word in the role permission.
   *   Note that if callers don't have `iam.roles.get` access to a role's
   *   included permissions, policy bindings that specify this role will be
   *   dropped from the search results.
   * * `resource:organizations/123456` to find IAM policy bindings
   *   that are set on "organizations/123456".
   * * `resource=//cloudresourcemanager.googleapis.com/projects/myproject` to
   *   find IAM policy bindings that are set on the project named "myproject".
   * * `Important` to find IAM policy bindings that contain "Important" as a
   *   word in any of the searchable fields (except for the included
   *   permissions).
   * * `resource:(instance1 OR instance2) policy:amy` to find
   *   IAM policy bindings that are set on resources "instance1" or
   *   "instance2" and also specify user "amy".
   * * `roles:roles/compute.admin` to find IAM policy bindings that specify the
   *   Compute Admin role.
   * * `memberTypes:user` to find IAM policy bindings that contain the
   *   principal type "user".
   */
  query: string;
  /**
   * Optional. The page size for search result pagination. Page size is capped
   * at 500 even if a larger value is given. If set to zero or a negative value,
   * server will pick an appropriate default. Returned results may be fewer than
   * requested. When this happens, there could be more results as long as
   * `next_page_token` is returned.
   */
  pageSize: number;
  /**
   * Optional. If present, retrieve the next batch of results from the preceding
   * call to this method. `page_token` must be the value of `next_page_token`
   * from the previous response. The values of all other method parameters must
   * be identical to those in the previous call.
   */
  pageToken: string;
  /**
   * Optional. A list of asset types that the IAM policies are attached to. If
   * empty, it will search the IAM policies that are attached to all the asset
   * types [supported by search
   * APIs](https://cloud.google.com/asset-inventory/docs/supported-asset-types)
   *
   * Regular expressions are also supported. For example:
   *
   * * "compute.googleapis.com.*" snapshots IAM policies attached to asset type
   * starts with "compute.googleapis.com".
   * * ".*Instance" snapshots IAM policies attached to asset type ends with
   * "Instance".
   * * ".*Instance.*" snapshots IAM policies attached to asset type contains
   * "Instance".
   *
   * See [RE2](https://github.com/google/re2/wiki/Syntax) for all supported
   * regular expression syntax. If the regular expression does not match any
   * supported asset type, an INVALID_ARGUMENT error will be returned.
   */
  assetTypes: string[];
  /**
   * Optional. A comma-separated list of fields specifying the sorting order of
   * the results. The default order is ascending. Add " DESC" after the field
   * name to indicate descending order. Redundant space characters are ignored.
   * Example: "assetType DESC, resource".
   * Only singular primitive fields in the response are sortable:
   *   * resource
   *   * assetType
   *   * project
   * All the other fields such as repeated fields (e.g., `folders`) and
   * non-primitive fields (e.g., `policy`) are not supported.
   */
  orderBy: string;
}

/** Search all IAM policies response. */
export interface SearchAllIamPoliciesResponse {
  /**
   * A list of IAM policies that match the search query. Related information
   * such as the associated resource is returned along with the policy.
   */
  results: IamPolicySearchResult[];
  /**
   * Set if there are more results than those appearing in this response; to get
   * the next set of results, call this method again, using this value as the
   * `page_token`.
   */
  nextPageToken: string;
}

/** IAM policy analysis query message. */
export interface IamPolicyAnalysisQuery {
  /**
   * Required. The relative name of the root asset. Only resources and IAM
   * policies within the scope will be analyzed.
   *
   * This can only be an organization number (such as "organizations/123"), a
   * folder number (such as "folders/123"), a project ID (such as
   * "projects/my-project-id"), or a project number (such as "projects/12345").
   *
   * To know how to get organization ID, visit [here
   * ](https://cloud.google.com/resource-manager/docs/creating-managing-organization#retrieving_your_organization_id).
   *
   * To know how to get folder or project ID, visit [here
   * ](https://cloud.google.com/resource-manager/docs/creating-managing-folders#viewing_or_listing_folders_and_projects).
   */
  scope: string;
  /** Optional. Specifies a resource for analysis. */
  resourceSelector:
    | IamPolicyAnalysisQuery_ResourceSelector
    | undefined;
  /** Optional. Specifies an identity for analysis. */
  identitySelector:
    | IamPolicyAnalysisQuery_IdentitySelector
    | undefined;
  /** Optional. Specifies roles or permissions for analysis. This is optional. */
  accessSelector:
    | IamPolicyAnalysisQuery_AccessSelector
    | undefined;
  /** Optional. The query options. */
  options:
    | IamPolicyAnalysisQuery_Options
    | undefined;
  /** Optional. The hypothetical context for IAM conditions evaluation. */
  conditionContext: IamPolicyAnalysisQuery_ConditionContext | undefined;
}

/**
 * Specifies the resource to analyze for access policies, which may be set
 * directly on the resource, or on ancestors such as organizations, folders or
 * projects.
 */
export interface IamPolicyAnalysisQuery_ResourceSelector {
  /**
   * Required. The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format)
   * of a resource of [supported resource
   * types](https://cloud.google.com/asset-inventory/docs/supported-asset-types#analyzable_asset_types).
   */
  fullResourceName: string;
}

/**
 * Specifies an identity for which to determine resource access, based on
 * roles assigned either directly to them or to the groups they belong to,
 * directly or indirectly.
 */
export interface IamPolicyAnalysisQuery_IdentitySelector {
  /**
   * Required. The identity appear in the form of principals in
   * [IAM policy
   * binding](https://cloud.google.com/iam/reference/rest/v1/Binding).
   *
   * The examples of supported forms are:
   * "user:mike@example.com",
   * "group:admins@example.com",
   * "domain:google.com",
   * "serviceAccount:my-project-id@appspot.gserviceaccount.com".
   *
   * Notice that wildcard characters (such as * and ?) are not supported.
   * You must give a specific identity.
   */
  identity: string;
}

/**
 * Specifies roles and/or permissions to analyze, to determine both the
 * identities possessing them and the resources they control. If multiple
 * values are specified, results will include roles or permissions matching
 * any of them. The total number of roles and permissions should be equal or
 * less than 10.
 */
export interface IamPolicyAnalysisQuery_AccessSelector {
  /** Optional. The roles to appear in result. */
  roles: string[];
  /** Optional. The permissions to appear in result. */
  permissions: string[];
}

/** Contains query options. */
export interface IamPolicyAnalysisQuery_Options {
  /**
   * Optional. If true, the identities section of the result will expand any
   * Google groups appearing in an IAM policy binding.
   *
   * If
   * [IamPolicyAnalysisQuery.identity_selector][google.cloud.asset.v1.IamPolicyAnalysisQuery.identity_selector]
   * is specified, the identity in the result will be determined by the
   * selector, and this flag is not allowed to set.
   *
   * If true, the default max expansion per group is 1000 for
   * AssetService.AnalyzeIamPolicy][].
   *
   * Default is false.
   */
  expandGroups: boolean;
  /**
   * Optional. If true, the access section of result will expand any roles
   * appearing in IAM policy bindings to include their permissions.
   *
   * If
   * [IamPolicyAnalysisQuery.access_selector][google.cloud.asset.v1.IamPolicyAnalysisQuery.access_selector]
   * is specified, the access section of the result will be determined by the
   * selector, and this flag is not allowed to set.
   *
   * Default is false.
   */
  expandRoles: boolean;
  /**
   * Optional. If true and
   * [IamPolicyAnalysisQuery.resource_selector][google.cloud.asset.v1.IamPolicyAnalysisQuery.resource_selector]
   * is not specified, the resource section of the result will expand any
   * resource attached to an IAM policy to include resources lower in the
   * resource hierarchy.
   *
   * For example, if the request analyzes for which resources user A has
   * permission P, and the results include an IAM policy with P on a Google
   * Cloud folder, the results will also include resources in that folder with
   * permission P.
   *
   * If true and
   * [IamPolicyAnalysisQuery.resource_selector][google.cloud.asset.v1.IamPolicyAnalysisQuery.resource_selector]
   * is specified, the resource section of the result will expand the
   * specified resource to include resources lower in the resource hierarchy.
   * Only project or lower resources are supported. Folder and organization
   * resources cannot be used together with this option.
   *
   * For example, if the request analyzes for which users have permission P on
   * a Google Cloud project with this option enabled, the results will include
   * all users who have permission P on that project or any lower resource.
   *
   * If true, the default max expansion per resource is 1000 for
   * AssetService.AnalyzeIamPolicy][] and 100000 for
   * AssetService.AnalyzeIamPolicyLongrunning][].
   *
   * Default is false.
   */
  expandResources: boolean;
  /**
   * Optional. If true, the result will output the relevant parent/child
   * relationships between resources. Default is false.
   */
  outputResourceEdges: boolean;
  /**
   * Optional. If true, the result will output the relevant membership
   * relationships between groups and other groups, and between groups and
   * principals. Default is false.
   */
  outputGroupEdges: boolean;
  /**
   * Optional. If true, the response will include access analysis from
   * identities to resources via service account impersonation. This is a very
   * expensive operation, because many derived queries will be executed. We
   * highly recommend you use
   * [AssetService.AnalyzeIamPolicyLongrunning][google.cloud.asset.v1.AssetService.AnalyzeIamPolicyLongrunning]
   * RPC instead.
   *
   * For example, if the request analyzes for which resources user A has
   * permission P, and there's an IAM policy states user A has
   * iam.serviceAccounts.getAccessToken permission to a service account SA,
   * and there's another IAM policy states service account SA has permission P
   * to a Google Cloud folder F, then user A potentially has access to the
   * Google Cloud folder F. And those advanced analysis results will be
   * included in
   * [AnalyzeIamPolicyResponse.service_account_impersonation_analysis][google.cloud.asset.v1.AnalyzeIamPolicyResponse.service_account_impersonation_analysis].
   *
   * Another example, if the request analyzes for who has
   * permission P to a Google Cloud folder F, and there's an IAM policy states
   * user A has iam.serviceAccounts.actAs permission to a service account SA,
   * and there's another IAM policy states service account SA has permission P
   * to the Google Cloud folder F, then user A potentially has access to the
   * Google Cloud folder F. And those advanced analysis results will be
   * included in
   * [AnalyzeIamPolicyResponse.service_account_impersonation_analysis][google.cloud.asset.v1.AnalyzeIamPolicyResponse.service_account_impersonation_analysis].
   *
   * Only the following permissions are considered in this analysis:
   *
   * * `iam.serviceAccounts.actAs`
   * * `iam.serviceAccounts.signBlob`
   * * `iam.serviceAccounts.signJwt`
   * * `iam.serviceAccounts.getAccessToken`
   * * `iam.serviceAccounts.getOpenIdToken`
   * * `iam.serviceAccounts.implicitDelegation`
   *
   * Default is false.
   */
  analyzeServiceAccountImpersonation: boolean;
}

/** The IAM conditions context. */
export interface IamPolicyAnalysisQuery_ConditionContext {
  /**
   * The hypothetical access timestamp to evaluate IAM conditions. Note that
   * this value must not be earlier than the current time; otherwise, an
   * INVALID_ARGUMENT error will be returned.
   */
  accessTime?: Date | undefined;
}

/**
 * A request message for
 * [AssetService.AnalyzeIamPolicy][google.cloud.asset.v1.AssetService.AnalyzeIamPolicy].
 */
export interface AnalyzeIamPolicyRequest {
  /** Required. The request query. */
  analysisQuery:
    | IamPolicyAnalysisQuery
    | undefined;
  /**
   * Optional. The name of a saved query, which must be in the format of:
   *
   * * projects/project_number/savedQueries/saved_query_id
   * * folders/folder_number/savedQueries/saved_query_id
   * * organizations/organization_number/savedQueries/saved_query_id
   *
   * If both `analysis_query` and `saved_analysis_query` are provided, they
   * will be merged together with the `saved_analysis_query` as base and
   * the `analysis_query` as overrides. For more details of the merge behavior,
   * refer to the
   * [MergeFrom](https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.message#Message.MergeFrom.details)
   * page.
   *
   * Note that you cannot override primitive fields with default value, such as
   * 0 or empty string, etc., because we use proto3, which doesn't support field
   * presence yet.
   */
  savedAnalysisQuery: string;
  /**
   * Optional. Amount of time executable has to complete.  See JSON
   * representation of
   * [Duration](https://developers.google.com/protocol-buffers/docs/proto3#json).
   *
   * If this field is set with a value less than the RPC deadline, and the
   * execution of your query hasn't finished in the specified
   * execution timeout,  you will get a response with partial result.
   * Otherwise, your query's execution will continue until the RPC deadline.
   * If it's not finished until then, you will get a  DEADLINE_EXCEEDED error.
   *
   * Default is empty.
   */
  executionTimeout: Duration | undefined;
}

/**
 * A response message for
 * [AssetService.AnalyzeIamPolicy][google.cloud.asset.v1.AssetService.AnalyzeIamPolicy].
 */
export interface AnalyzeIamPolicyResponse {
  /** The main analysis that matches the original request. */
  mainAnalysis:
    | AnalyzeIamPolicyResponse_IamPolicyAnalysis
    | undefined;
  /**
   * The service account impersonation analysis if
   * [AnalyzeIamPolicyRequest.analyze_service_account_impersonation][] is
   * enabled.
   */
  serviceAccountImpersonationAnalysis: AnalyzeIamPolicyResponse_IamPolicyAnalysis[];
  /**
   * Represents whether all entries in the
   * [main_analysis][google.cloud.asset.v1.AnalyzeIamPolicyResponse.main_analysis]
   * and
   * [service_account_impersonation_analysis][google.cloud.asset.v1.AnalyzeIamPolicyResponse.service_account_impersonation_analysis]
   * have been fully explored to answer the query in the request.
   */
  fullyExplored: boolean;
}

/** An analysis message to group the query and results. */
export interface AnalyzeIamPolicyResponse_IamPolicyAnalysis {
  /** The analysis query. */
  analysisQuery:
    | IamPolicyAnalysisQuery
    | undefined;
  /**
   * A list of
   * [IamPolicyAnalysisResult][google.cloud.asset.v1.IamPolicyAnalysisResult]
   * that matches the analysis query, or empty if no result is found.
   */
  analysisResults: IamPolicyAnalysisResult[];
  /**
   * Represents whether all entries in the
   * [analysis_results][google.cloud.asset.v1.AnalyzeIamPolicyResponse.IamPolicyAnalysis.analysis_results]
   * have been fully explored to answer the query.
   */
  fullyExplored: boolean;
  /** A list of non-critical errors happened during the query handling. */
  nonCriticalErrors: IamPolicyAnalysisState[];
}

/** Output configuration for export IAM policy analysis destination. */
export interface IamPolicyAnalysisOutputConfig {
  /** Destination on Cloud Storage. */
  gcsDestination?:
    | IamPolicyAnalysisOutputConfig_GcsDestination
    | undefined;
  /** Destination on BigQuery. */
  bigqueryDestination?: IamPolicyAnalysisOutputConfig_BigQueryDestination | undefined;
}

/** A Cloud Storage location. */
export interface IamPolicyAnalysisOutputConfig_GcsDestination {
  /**
   * Required. The URI of the Cloud Storage object. It's the same URI that is
   * used by gsutil. Example: "gs://bucket_name/object_name". See [Viewing and
   * Editing Object
   * Metadata](https://cloud.google.com/storage/docs/viewing-editing-metadata)
   * for more information.
   *
   * If the specified Cloud Storage object already exists and there is no
   * [hold](https://cloud.google.com/storage/docs/object-holds), it will be
   * overwritten with the analysis result.
   */
  uri: string;
}

/** A BigQuery destination. */
export interface IamPolicyAnalysisOutputConfig_BigQueryDestination {
  /**
   * Required. The BigQuery dataset in format
   * "projects/projectId/datasets/datasetId", to which the analysis results
   * should be exported. If this dataset does not exist, the export call will
   * return an INVALID_ARGUMENT error.
   */
  dataset: string;
  /**
   * Required. The prefix of the BigQuery tables to which the analysis results
   * will be written. Tables will be created based on this table_prefix if not
   * exist:
   * * <table_prefix>_analysis table will contain export operation's metadata.
   * * <table_prefix>_analysis_result will contain all the
   *   [IamPolicyAnalysisResult][google.cloud.asset.v1.IamPolicyAnalysisResult].
   * When [partition_key] is specified, both tables will be partitioned based
   * on the [partition_key].
   */
  tablePrefix: string;
  /** The partition key for BigQuery partitioned table. */
  partitionKey: IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey;
  /**
   * Optional. Specifies the action that occurs if the destination table or
   * partition already exists. The following values are supported:
   *
   * * WRITE_TRUNCATE: If the table or partition already exists, BigQuery
   * overwrites the entire table or all the partitions data.
   * * WRITE_APPEND: If the table or partition already exists, BigQuery
   * appends the data to the table or the latest partition.
   * * WRITE_EMPTY: If the table already exists and contains data, an error is
   * returned.
   *
   * The default value is WRITE_APPEND. Each action is atomic and only occurs
   * if BigQuery is able to complete the job successfully. Details are at
   * https://cloud.google.com/bigquery/docs/loading-data-local#appending_to_or_overwriting_a_table_using_a_local_file.
   */
  writeDisposition: string;
}

/**
 * This enum determines the partition key column for the bigquery tables.
 * Partitioning can improve query performance and reduce query cost by
 * filtering partitions. Refer to
 * https://cloud.google.com/bigquery/docs/partitioned-tables for details.
 */
export enum IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey {
  /**
   * PARTITION_KEY_UNSPECIFIED - Unspecified partition key. Tables won't be partitioned using this
   * option.
   */
  PARTITION_KEY_UNSPECIFIED = 0,
  /**
   * REQUEST_TIME - The time when the request is received. If specified as partition key,
   * the result table(s) is partitoned by the RequestTime column, an
   * additional timestamp column representing when the request was received.
   */
  REQUEST_TIME = 1,
  UNRECOGNIZED = -1,
}

export function iamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKeyFromJSON(
  object: any,
): IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey {
  switch (object) {
    case 0:
    case "PARTITION_KEY_UNSPECIFIED":
      return IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey.PARTITION_KEY_UNSPECIFIED;
    case 1:
    case "REQUEST_TIME":
      return IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey.REQUEST_TIME;
    case -1:
    case "UNRECOGNIZED":
    default:
      return IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey.UNRECOGNIZED;
  }
}

export function iamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKeyToJSON(
  object: IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey,
): string {
  switch (object) {
    case IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey.PARTITION_KEY_UNSPECIFIED:
      return "PARTITION_KEY_UNSPECIFIED";
    case IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey.REQUEST_TIME:
      return "REQUEST_TIME";
    case IamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKey.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A request message for
 * [AssetService.AnalyzeIamPolicyLongrunning][google.cloud.asset.v1.AssetService.AnalyzeIamPolicyLongrunning].
 */
export interface AnalyzeIamPolicyLongrunningRequest {
  /** Required. The request query. */
  analysisQuery:
    | IamPolicyAnalysisQuery
    | undefined;
  /**
   * Optional. The name of a saved query, which must be in the format of:
   *
   * * projects/project_number/savedQueries/saved_query_id
   * * folders/folder_number/savedQueries/saved_query_id
   * * organizations/organization_number/savedQueries/saved_query_id
   *
   * If both `analysis_query` and `saved_analysis_query` are provided, they
   * will be merged together with the `saved_analysis_query` as base and
   * the `analysis_query` as overrides. For more details of the merge behavior,
   * refer to the
   * [MergeFrom](https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.message#Message.MergeFrom.details)
   * doc.
   *
   * Note that you cannot override primitive fields with default value, such as
   * 0 or empty string, etc., because we use proto3, which doesn't support field
   * presence yet.
   */
  savedAnalysisQuery: string;
  /**
   * Required. Output configuration indicating where the results will be output
   * to.
   */
  outputConfig: IamPolicyAnalysisOutputConfig | undefined;
}

/**
 * A response message for
 * [AssetService.AnalyzeIamPolicyLongrunning][google.cloud.asset.v1.AssetService.AnalyzeIamPolicyLongrunning].
 */
export interface AnalyzeIamPolicyLongrunningResponse {
}

/** A saved query which can be shared with others or used later. */
export interface SavedQuery {
  /**
   * The resource name of the saved query. The format must be:
   *
   * * projects/project_number/savedQueries/saved_query_id
   * * folders/folder_number/savedQueries/saved_query_id
   * * organizations/organization_number/savedQueries/saved_query_id
   */
  name: string;
  /**
   * The description of this saved query. This value should be fewer than 255
   * characters.
   */
  description: string;
  /** Output only. The create time of this saved query. */
  createTime:
    | Date
    | undefined;
  /** Output only. The account's email address who has created this saved query. */
  creator: string;
  /** Output only. The last update time of this saved query. */
  lastUpdateTime:
    | Date
    | undefined;
  /**
   * Output only. The account's email address who has updated this saved query
   * most recently.
   */
  lastUpdater: string;
  /**
   * Labels applied on the resource.
   * This value should not contain more than 10 entries. The key and value of
   * each entry must be non-empty and fewer than 64 characters.
   */
  labels: { [key: string]: string };
  /** The query content. */
  content: SavedQuery_QueryContent | undefined;
}

/** The query content. */
export interface SavedQuery_QueryContent {
  /**
   * An IAM Policy Analysis query, which could be used in
   * the
   * [AssetService.AnalyzeIamPolicy][google.cloud.asset.v1.AssetService.AnalyzeIamPolicy]
   * RPC or the
   * [AssetService.AnalyzeIamPolicyLongrunning][google.cloud.asset.v1.AssetService.AnalyzeIamPolicyLongrunning]
   * RPC.
   */
  iamPolicyAnalysisQuery?: IamPolicyAnalysisQuery | undefined;
}

export interface SavedQuery_LabelsEntry {
  key: string;
  value: string;
}

/** Request to create a saved query. */
export interface CreateSavedQueryRequest {
  /**
   * Required. The name of the project/folder/organization where this
   * saved_query should be created in. It can only be an organization number
   * (such as "organizations/123"), a folder number (such as "folders/123"), a
   * project ID (such as "projects/my-project-id"), or a project number (such as
   * "projects/12345").
   */
  parent: string;
  /**
   * Required. The saved_query details. The `name` field must be empty as it
   * will be generated based on the parent and saved_query_id.
   */
  savedQuery:
    | SavedQuery
    | undefined;
  /**
   * Required. The ID to use for the saved query, which must be unique in the
   * specified parent. It will become the final component of the saved query's
   * resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are `[a-z][0-9]-`.
   *
   * Notice that this field is required in the saved query creation, and the
   * `name` field of the `saved_query` will be ignored.
   */
  savedQueryId: string;
}

/** Request to get a saved query. */
export interface GetSavedQueryRequest {
  /**
   * Required. The name of the saved query and it must be in the format of:
   *
   * * projects/project_number/savedQueries/saved_query_id
   * * folders/folder_number/savedQueries/saved_query_id
   * * organizations/organization_number/savedQueries/saved_query_id
   */
  name: string;
}

/** Request to list saved queries. */
export interface ListSavedQueriesRequest {
  /**
   * Required. The parent project/folder/organization whose savedQueries are to
   * be listed. It can only be using project/folder/organization number (such as
   * "folders/12345")", or a project ID (such as "projects/my-project-id").
   */
  parent: string;
  /**
   * Optional. The expression to filter resources.
   * The expression is a list of zero or more restrictions combined via logical
   * operators `AND` and `OR`. When `AND` and `OR` are both used in the
   * expression, parentheses must be appropriately used to group the
   * combinations. The expression may also contain regular expressions.
   *
   * See https://google.aip.dev/160 for more information on the grammar.
   */
  filter: string;
  /**
   * Optional. The maximum number of saved queries to return per page. The
   * service may return fewer than this value. If unspecified, at most 50 will
   * be returned. The maximum value is 1000; values above 1000 will be coerced
   * to 1000.
   */
  pageSize: number;
  /**
   * Optional. A page token, received from a previous `ListSavedQueries` call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListSavedQueries` must
   * match the call that provided the page token.
   */
  pageToken: string;
}

/** Response of listing saved queries. */
export interface ListSavedQueriesResponse {
  /** A list of savedQueries. */
  savedQueries: SavedQuery[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

/** Request to update a saved query. */
export interface UpdateSavedQueryRequest {
  /**
   * Required. The saved query to update.
   *
   * The saved query's `name` field is used to identify the one to update,
   * which has format as below:
   *
   * * projects/project_number/savedQueries/saved_query_id
   * * folders/folder_number/savedQueries/saved_query_id
   * * organizations/organization_number/savedQueries/saved_query_id
   */
  savedQuery:
    | SavedQuery
    | undefined;
  /** Required. The list of fields to update. */
  updateMask: string[] | undefined;
}

/** Request to delete a saved query. */
export interface DeleteSavedQueryRequest {
  /**
   * Required. The name of the saved query to delete. It must be in the format
   * of:
   *
   * * projects/project_number/savedQueries/saved_query_id
   * * folders/folder_number/savedQueries/saved_query_id
   * * organizations/organization_number/savedQueries/saved_query_id
   */
  name: string;
}

/** The request message for performing resource move analysis. */
export interface AnalyzeMoveRequest {
  /**
   * Required. Name of the resource to perform the analysis against.
   * Only Google Cloud projects are supported as of today. Hence, this can only
   * be a project ID (such as "projects/my-project-id") or a project number
   * (such as "projects/12345").
   */
  resource: string;
  /**
   * Required. Name of the Google Cloud folder or organization to reparent the
   * target resource. The analysis will be performed against hypothetically
   * moving the resource to this specified desitination parent. This can only be
   * a folder number (such as "folders/123") or an organization number (such as
   * "organizations/123").
   */
  destinationParent: string;
  /**
   * Analysis view indicating what information should be included in the
   * analysis response. If unspecified, the default view is FULL.
   */
  view: AnalyzeMoveRequest_AnalysisView;
}

/** View enum for supporting partial analysis responses. */
export enum AnalyzeMoveRequest_AnalysisView {
  /**
   * ANALYSIS_VIEW_UNSPECIFIED - The default/unset value.
   * The API will default to the FULL view.
   */
  ANALYSIS_VIEW_UNSPECIFIED = 0,
  /**
   * FULL - Full analysis including all level of impacts of the specified resource
   * move.
   */
  FULL = 1,
  /**
   * BASIC - Basic analysis only including blockers which will prevent the specified
   * resource move at runtime.
   */
  BASIC = 2,
  UNRECOGNIZED = -1,
}

export function analyzeMoveRequest_AnalysisViewFromJSON(object: any): AnalyzeMoveRequest_AnalysisView {
  switch (object) {
    case 0:
    case "ANALYSIS_VIEW_UNSPECIFIED":
      return AnalyzeMoveRequest_AnalysisView.ANALYSIS_VIEW_UNSPECIFIED;
    case 1:
    case "FULL":
      return AnalyzeMoveRequest_AnalysisView.FULL;
    case 2:
    case "BASIC":
      return AnalyzeMoveRequest_AnalysisView.BASIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AnalyzeMoveRequest_AnalysisView.UNRECOGNIZED;
  }
}

export function analyzeMoveRequest_AnalysisViewToJSON(object: AnalyzeMoveRequest_AnalysisView): string {
  switch (object) {
    case AnalyzeMoveRequest_AnalysisView.ANALYSIS_VIEW_UNSPECIFIED:
      return "ANALYSIS_VIEW_UNSPECIFIED";
    case AnalyzeMoveRequest_AnalysisView.FULL:
      return "FULL";
    case AnalyzeMoveRequest_AnalysisView.BASIC:
      return "BASIC";
    case AnalyzeMoveRequest_AnalysisView.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The response message for resource move analysis. */
export interface AnalyzeMoveResponse {
  /**
   * The list of analyses returned from performing the intended resource move
   * analysis. The analysis is grouped by different Google Cloud services.
   */
  moveAnalysis: MoveAnalysis[];
}

/** A message to group the analysis information. */
export interface MoveAnalysis {
  /**
   * The user friendly display name of the analysis. E.g. IAM, organization
   * policy etc.
   */
  displayName: string;
  /** Analysis result of moving the target resource. */
  analysis?:
    | MoveAnalysisResult
    | undefined;
  /** Description of error encountered when performing the analysis. */
  error?: Status | undefined;
}

/** An analysis result including blockers and warnings. */
export interface MoveAnalysisResult {
  /**
   * Blocking information that would prevent the target resource from moving
   * to the specified destination at runtime.
   */
  blockers: MoveImpact[];
  /**
   * Warning information indicating that moving the target resource to the
   * specified destination might be unsafe. This can include important policy
   * information and configuration changes, but will not block moves at runtime.
   */
  warnings: MoveImpact[];
}

/** A message to group impacts of moving the target resource. */
export interface MoveImpact {
  /** User friendly impact detail in a free form message. */
  detail: string;
}

/** Output configuration query assets. */
export interface QueryAssetsOutputConfig {
  /** BigQuery destination where the query results will be saved. */
  bigqueryDestination: QueryAssetsOutputConfig_BigQueryDestination | undefined;
}

/** BigQuery destination. */
export interface QueryAssetsOutputConfig_BigQueryDestination {
  /**
   * Required. The BigQuery dataset where the query results will be saved. It
   * has the format of "projects/{projectId}/datasets/{datasetId}".
   */
  dataset: string;
  /**
   * Required. The BigQuery table where the query results will be saved. If
   * this table does not exist, a new table with the given name will be
   * created.
   */
  table: string;
  /**
   * Specifies the action that occurs if the destination table or partition
   * already exists. The following values are supported:
   *
   * * WRITE_TRUNCATE: If the table or partition already exists, BigQuery
   * overwrites the entire table or all the partitions data.
   * * WRITE_APPEND: If the table or partition already exists, BigQuery
   * appends the data to the table or the latest partition.
   * * WRITE_EMPTY: If the table already exists and contains data, a
   * 'duplicate' error is returned in the job result.
   *
   * The default value is WRITE_EMPTY.
   */
  writeDisposition: string;
}

/** QueryAssets request. */
export interface QueryAssetsRequest {
  /**
   * Required. The relative name of the root asset. This can only be an
   * organization number (such as "organizations/123"), a project ID (such as
   * "projects/my-project-id"), or a project number (such as "projects/12345"),
   * or a folder number (such as "folders/123").
   *
   * Only assets belonging to the `parent` will be returned.
   */
  parent: string;
  /**
   * Optional. A SQL statement that's compatible with [BigQuery
   * SQL](https://cloud.google.com/bigquery/docs/introduction-sql).
   */
  statement?:
    | string
    | undefined;
  /**
   * Optional. Reference to the query job, which is from the
   * `QueryAssetsResponse` of previous `QueryAssets` call.
   */
  jobReference?:
    | string
    | undefined;
  /**
   * Optional. The maximum number of rows to return in the results. Responses
   * are limited to 10 MB and 1000 rows.
   *
   * By default, the maximum row count is 1000. When the byte or row count limit
   * is reached, the rest of the query results will be paginated.
   *
   * The field will be ignored when [output_config] is specified.
   */
  pageSize: number;
  /**
   * Optional. A page token received from previous `QueryAssets`.
   *
   * The field will be ignored when [output_config] is specified.
   */
  pageToken: string;
  /**
   * Optional. Specifies the maximum amount of time that the client is willing
   * to wait for the query to complete. By default, this limit is 5 min for the
   * first query, and 1 minute for the following queries. If the query is
   * complete, the `done` field in the `QueryAssetsResponse` is true, otherwise
   * false.
   *
   * Like BigQuery [jobs.query
   * API](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query#queryrequest)
   * The call is not guaranteed to wait for the specified timeout; it typically
   * returns after around 200 seconds (200,000 milliseconds), even if the query
   * is not complete.
   *
   * The field will be ignored when [output_config] is specified.
   */
  timeout:
    | Duration
    | undefined;
  /**
   * Optional. [start_time] is required. [start_time] must be less than
   * [end_time] Defaults [end_time] to now if [start_time] is set and
   * [end_time] isn't. Maximum permitted time range is 7 days.
   */
  readTimeWindow?:
    | TimeWindow
    | undefined;
  /**
   * Optional. Queries cloud assets as they appeared at the specified point in
   * time.
   */
  readTime?:
    | Date
    | undefined;
  /**
   * Optional. Destination where the query results will be saved.
   *
   * When this field is specified, the query results won't be saved in the
   * [QueryAssetsResponse.query_result]. Instead
   * [QueryAssetsResponse.output_config] will be set.
   *
   * Meanwhile, [QueryAssetsResponse.job_reference] will be set and can be used
   * to check the status of the query job when passed to a following
   * [QueryAssets] API call.
   */
  outputConfig: QueryAssetsOutputConfig | undefined;
}

/** QueryAssets response. */
export interface QueryAssetsResponse {
  /** Reference to a query job. */
  jobReference: string;
  /**
   * The query response, which can be either an `error` or a valid `response`.
   *
   * If `done` == `false` and the query result is being saved in an output, the
   * output_config field will be set.
   * If `done` == `true`, exactly one of
   * `error`, `query_result` or `output_config` will be set.
   * [done] is unset unless the [QueryAssetsResponse] contains a
   * [QueryAssetsResponse.job_reference].
   */
  done: boolean;
  /** Error status. */
  error?:
    | Status
    | undefined;
  /** Result of the query. */
  queryResult?:
    | QueryResult
    | undefined;
  /**
   * Output configuration, which indicates that instead of being returned in
   * an API response on the fly, the query result will be saved in a specific
   * output.
   */
  outputConfig?: QueryAssetsOutputConfig | undefined;
}

/**
 * Execution results of the query.
 *
 * The result is formatted as rows represented by BigQuery compatible [schema].
 * When pagination is necessary, it will contains the page token to retrieve
 * the results of following pages.
 */
export interface QueryResult {
  /** Each row hold a query result in the format of `Struct`. */
  rows: { [key: string]: any }[];
  /** Describes the format of the [rows]. */
  schema:
    | TableSchema
    | undefined;
  /** Token to retrieve the next page of the results. */
  nextPageToken: string;
  /** Total rows of the whole query results. */
  totalRows: Long;
}

/** BigQuery Compatible table schema. */
export interface TableSchema {
  /** Describes the fields in a table. */
  fields: TableFieldSchema[];
}

/** A field in TableSchema. */
export interface TableFieldSchema {
  /**
   * The field name. The name must contain only letters (a-z, A-Z),
   * numbers (0-9), or underscores (_), and must start with a letter or
   * underscore. The maximum length is 128 characters.
   */
  field: string;
  /**
   * The field data type. Possible values include
   * * STRING
   * * BYTES
   * * INTEGER
   * * FLOAT
   * * BOOLEAN
   * * TIMESTAMP
   * * DATE
   * * TIME
   * * DATETIME
   * * GEOGRAPHY,
   * * NUMERIC,
   * * BIGNUMERIC,
   * * RECORD
   * (where RECORD indicates that the field contains a nested schema).
   */
  type: string;
  /**
   * The field mode. Possible values include NULLABLE, REQUIRED and
   * REPEATED. The default value is NULLABLE.
   */
  mode: string;
  /**
   * Describes the nested schema fields if the type property is set
   * to RECORD.
   */
  fields: TableFieldSchema[];
}

/**
 * A request message for
 * [AssetService.BatchGetEffectiveIamPolicies][google.cloud.asset.v1.AssetService.BatchGetEffectiveIamPolicies].
 */
export interface BatchGetEffectiveIamPoliciesRequest {
  /**
   * Required. Only IAM policies on or below the scope will be returned.
   *
   * This can only be an organization number (such as "organizations/123"), a
   * folder number (such as "folders/123"), a project ID (such as
   * "projects/my-project-id"), or a project number (such as "projects/12345").
   *
   * To know how to get organization ID, visit [here
   * ](https://cloud.google.com/resource-manager/docs/creating-managing-organization#retrieving_your_organization_id).
   *
   * To know how to get folder or project ID, visit [here
   * ](https://cloud.google.com/resource-manager/docs/creating-managing-folders#viewing_or_listing_folders_and_projects).
   */
  scope: string;
  /**
   * Required. The names refer to the [full_resource_names]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format)
   * of the asset types [supported by search
   * APIs](https://cloud.google.com/asset-inventory/docs/supported-asset-types).
   * A maximum of 20 resources' effective policies can be retrieved in a batch.
   */
  names: string[];
}

/**
 * A response message for
 * [AssetService.BatchGetEffectiveIamPolicies][google.cloud.asset.v1.AssetService.BatchGetEffectiveIamPolicies].
 */
export interface BatchGetEffectiveIamPoliciesResponse {
  /**
   * The effective policies for a batch of resources. Note that the results
   * order is the same as the order of
   * [BatchGetEffectiveIamPoliciesRequest.names][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesRequest.names].
   * When a resource does not have any effective IAM policies, its corresponding
   * policy_result will contain empty
   * [EffectiveIamPolicy.policies][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.policies].
   */
  policyResults: BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy[];
}

/** The effective IAM policies on one resource. */
export interface BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy {
  /**
   * The [full_resource_name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format)
   * for which the
   * [policies][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.policies]
   * are computed. This is one of the
   * [BatchGetEffectiveIamPoliciesRequest.names][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesRequest.names]
   * the caller provides in the request.
   */
  fullResourceName: string;
  /**
   * The effective policies for the
   * [full_resource_name][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.full_resource_name].
   *
   * These policies include the policy set on the
   * [full_resource_name][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.full_resource_name]
   * and those set on its parents and ancestors up to the
   * [BatchGetEffectiveIamPoliciesRequest.scope][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesRequest.scope].
   * Note that these policies are not filtered according to the resource type
   * of the
   * [full_resource_name][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.full_resource_name].
   *
   * These policies are hierarchically ordered by
   * [PolicyInfo.attached_resource][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.PolicyInfo.attached_resource]
   * starting from
   * [full_resource_name][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.full_resource_name]
   * itself to its parents and ancestors, such that policies[i]'s
   * [PolicyInfo.attached_resource][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.PolicyInfo.attached_resource]
   * is the child of policies[i+1]'s
   * [PolicyInfo.attached_resource][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.PolicyInfo.attached_resource],
   * if policies[i+1] exists.
   */
  policies: BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo[];
}

/** The IAM policy and its attached resource. */
export interface BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo {
  /**
   * The full resource name the
   * [policy][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.PolicyInfo.policy]
   * is directly attached to.
   */
  attachedResource: string;
  /**
   * The IAM policy that's directly attached to the
   * [attached_resource][google.cloud.asset.v1.BatchGetEffectiveIamPoliciesResponse.EffectiveIamPolicy.PolicyInfo.attached_resource].
   */
  policy: Policy | undefined;
}

/**
 * This organization policy message is a modified version of the one defined in
 * the Organization Policy system. This message contains several fields defined
 * in the original organization policy with some new fields for analysis
 * purpose.
 */
export interface AnalyzerOrgPolicy {
  /**
   * The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format) of
   * an organization/folder/project resource where this organization policy is
   * set.
   *
   * Notice that some type of constraints are defined with default policy. This
   * field will be empty for them.
   */
  attachedResource: string;
  /**
   * The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format) of
   * an organization/folder/project resource where this organization policy
   * applies to.
   *
   * For any user defined org policies, this field has the same value as
   * the [attached_resource] field. Only for default policy, this field has
   * the different value.
   */
  appliedResource: string;
  /** List of rules for this organization policy. */
  rules: AnalyzerOrgPolicy_Rule[];
  /**
   * If `inherit_from_parent` is true, Rules set higher up in the
   * hierarchy (up to the closest root) are inherited and present in the
   * effective policy. If it is false, then no rules are inherited, and this
   * policy becomes the effective root for evaluation.
   */
  inheritFromParent: boolean;
  /**
   * Ignores policies set above this resource and restores the default behavior
   * of the constraint at this resource.
   * This field can be set in policies for either list or boolean
   * constraints. If set, `rules` must be empty and `inherit_from_parent`
   * must be set to false.
   */
  reset: boolean;
}

/**
 * This rule message is a customized version of the one defined in the
 * Organization Policy system. In addition to the fields defined in the
 * original organization policy, it contains additional field(s) under
 * specific circumstances to support analysis results.
 */
export interface AnalyzerOrgPolicy_Rule {
  /**
   * List of values to be used for this policy rule. This field can be set
   * only in policies for list constraints.
   */
  values?:
    | AnalyzerOrgPolicy_Rule_StringValues
    | undefined;
  /**
   * Setting this to true means that all values are allowed. This field can
   * be set only in Policies for list constraints.
   */
  allowAll?:
    | boolean
    | undefined;
  /**
   * Setting this to true means that all values are denied. This field can
   * be set only in Policies for list constraints.
   */
  denyAll?:
    | boolean
    | undefined;
  /**
   * If `true`, then the `Policy` is enforced. If `false`, then any
   * configuration is acceptable.
   * This field can be set only in Policies for boolean constraints.
   */
  enforce?:
    | boolean
    | undefined;
  /** The evaluating condition for this rule. */
  condition:
    | Expr
    | undefined;
  /**
   * The condition evaluation result for this rule.
   * Only populated if it meets all the following criteria:
   *
   * * There is a
   * [condition][google.cloud.asset.v1.AnalyzerOrgPolicy.Rule.condition]
   * defined for this rule.
   * * This rule is within
   *   [AnalyzeOrgPolicyGovernedContainersResponse.GovernedContainer.consolidated_policy][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersResponse.GovernedContainer.consolidated_policy],
   *   or
   *   [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset.consolidated_policy][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset.consolidated_policy]
   *   when the
   *   [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset]
   *   has
   *   [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset.governed_resource][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset.governed_resource].
   */
  conditionEvaluation: ConditionEvaluation | undefined;
}

/** The string values for the list constraints. */
export interface AnalyzerOrgPolicy_Rule_StringValues {
  /** List of values allowed at this resource. */
  allowedValues: string[];
  /** List of values denied at this resource. */
  deniedValues: string[];
}

/** The organization policy constraint definition. */
export interface AnalyzerOrgPolicyConstraint {
  /** The definition of the canned constraint defined by Google. */
  googleDefinedConstraint?:
    | AnalyzerOrgPolicyConstraint_Constraint
    | undefined;
  /** The definition of the custom constraint. */
  customConstraint?: AnalyzerOrgPolicyConstraint_CustomConstraint | undefined;
}

/** The definition of a constraint. */
export interface AnalyzerOrgPolicyConstraint_Constraint {
  /**
   * The unique name of the constraint. Format of the name should be
   * * `constraints/{constraint_name}`
   *
   * For example, `constraints/compute.disableSerialPortAccess`.
   */
  name: string;
  /** The human readable name of the constraint. */
  displayName: string;
  /**
   * Detailed description of what this `Constraint` controls as well as how
   * and where it is enforced.
   */
  description: string;
  /** The evaluation behavior of this constraint in the absence of 'Policy'. */
  constraintDefault: AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault;
  /** Defines this constraint as being a ListConstraint. */
  listConstraint?:
    | AnalyzerOrgPolicyConstraint_Constraint_ListConstraint
    | undefined;
  /** Defines this constraint as being a BooleanConstraint. */
  booleanConstraint?: AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint | undefined;
}

/**
 * Specifies the default behavior in the absence of any `Policy` for the
 * `Constraint`. This must not be `CONSTRAINT_DEFAULT_UNSPECIFIED`.
 */
export enum AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault {
  /**
   * CONSTRAINT_DEFAULT_UNSPECIFIED - This is only used for distinguishing unset values and should never be
   * used.
   */
  CONSTRAINT_DEFAULT_UNSPECIFIED = 0,
  /**
   * ALLOW - Indicate that all values are allowed for list constraints.
   * Indicate that enforcement is off for boolean constraints.
   */
  ALLOW = 1,
  /**
   * DENY - Indicate that all values are denied for list constraints.
   * Indicate that enforcement is on for boolean constraints.
   */
  DENY = 2,
  UNRECOGNIZED = -1,
}

export function analyzerOrgPolicyConstraint_Constraint_ConstraintDefaultFromJSON(
  object: any,
): AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault {
  switch (object) {
    case 0:
    case "CONSTRAINT_DEFAULT_UNSPECIFIED":
      return AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.CONSTRAINT_DEFAULT_UNSPECIFIED;
    case 1:
    case "ALLOW":
      return AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.ALLOW;
    case 2:
    case "DENY":
      return AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.DENY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.UNRECOGNIZED;
  }
}

export function analyzerOrgPolicyConstraint_Constraint_ConstraintDefaultToJSON(
  object: AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault,
): string {
  switch (object) {
    case AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.CONSTRAINT_DEFAULT_UNSPECIFIED:
      return "CONSTRAINT_DEFAULT_UNSPECIFIED";
    case AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.ALLOW:
      return "ALLOW";
    case AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.DENY:
      return "DENY";
    case AnalyzerOrgPolicyConstraint_Constraint_ConstraintDefault.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A `Constraint` that allows or disallows a list of string values, which
 * are configured by an organization's policy administrator with a `Policy`.
 */
export interface AnalyzerOrgPolicyConstraint_Constraint_ListConstraint {
  /**
   * Indicates whether values grouped into categories can be used in
   * `Policy.allowed_values` and `Policy.denied_values`. For example,
   * `"in:Python"` would match any value in the 'Python' group.
   */
  supportsIn: boolean;
  /**
   * Indicates whether subtrees of Cloud Resource Manager resource hierarchy
   * can be used in `Policy.allowed_values` and `Policy.denied_values`. For
   * example, `"under:folders/123"` would match any resource under the
   * 'folders/123' folder.
   */
  supportsUnder: boolean;
}

/**
 * A `Constraint` that is either enforced or not.
 *
 * For example a constraint `constraints/compute.disableSerialPortAccess`.
 * If it is enforced on a VM instance, serial port connections will not be
 * opened to that instance.
 */
export interface AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint {
}

/** The definition of a custom constraint. */
export interface AnalyzerOrgPolicyConstraint_CustomConstraint {
  /**
   * Name of the constraint. This is unique within the organization. Format of
   * the name should be
   * * `organizations/{organization_id}/customConstraints/{custom_constraint_id}`
   *
   * Example :
   * "organizations/123/customConstraints/custom.createOnlyE2TypeVms"
   */
  name: string;
  /**
   * The Resource Instance type on which this policy applies to. Format will
   * be of the form : "<canonical service name>/<type>" Example:
   *  * `compute.googleapis.com/Instance`.
   */
  resourceTypes: string[];
  /** All the operations being applied for this constraint. */
  methodTypes: AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType[];
  /**
   * Organization Policy condition/expression. For example:
   * `resource.instanceName.matches("[production|test]_.*_(\d)+")'` or,
   * `resource.management.auto_upgrade == true`
   */
  condition: string;
  /** Allow or deny type. */
  actionType: AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType;
  /** One line display name for the UI. */
  displayName: string;
  /** Detailed information about this custom policy constraint. */
  description: string;
}

/**
 * The operation in which this constraint will be applied. For example:
 * If the constraint applies only when create VMs, the method_types will be
 * "CREATE" only. If the constraint applied when create or delete VMs, the
 * method_types will be "CREATE" and "DELETE".
 */
export enum AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType {
  /** METHOD_TYPE_UNSPECIFIED - Unspecified. Will results in user error. */
  METHOD_TYPE_UNSPECIFIED = 0,
  /** CREATE - Constraint applied when creating the resource. */
  CREATE = 1,
  /** UPDATE - Constraint applied when updating the resource. */
  UPDATE = 2,
  /** DELETE - Constraint applied when deleting the resource. */
  DELETE = 3,
  UNRECOGNIZED = -1,
}

export function analyzerOrgPolicyConstraint_CustomConstraint_MethodTypeFromJSON(
  object: any,
): AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType {
  switch (object) {
    case 0:
    case "METHOD_TYPE_UNSPECIFIED":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.METHOD_TYPE_UNSPECIFIED;
    case 1:
    case "CREATE":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.CREATE;
    case 2:
    case "UPDATE":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.UPDATE;
    case 3:
    case "DELETE":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.DELETE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.UNRECOGNIZED;
  }
}

export function analyzerOrgPolicyConstraint_CustomConstraint_MethodTypeToJSON(
  object: AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType,
): string {
  switch (object) {
    case AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.METHOD_TYPE_UNSPECIFIED:
      return "METHOD_TYPE_UNSPECIFIED";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.CREATE:
      return "CREATE";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.UPDATE:
      return "UPDATE";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.DELETE:
      return "DELETE";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_MethodType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Allow or deny type. */
export enum AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType {
  /** ACTION_TYPE_UNSPECIFIED - Unspecified. Will results in user error. */
  ACTION_TYPE_UNSPECIFIED = 0,
  /** ALLOW - Allowed action type. */
  ALLOW = 1,
  /** DENY - Deny action type. */
  DENY = 2,
  UNRECOGNIZED = -1,
}

export function analyzerOrgPolicyConstraint_CustomConstraint_ActionTypeFromJSON(
  object: any,
): AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType {
  switch (object) {
    case 0:
    case "ACTION_TYPE_UNSPECIFIED":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.ACTION_TYPE_UNSPECIFIED;
    case 1:
    case "ALLOW":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.ALLOW;
    case 2:
    case "DENY":
      return AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.DENY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.UNRECOGNIZED;
  }
}

export function analyzerOrgPolicyConstraint_CustomConstraint_ActionTypeToJSON(
  object: AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType,
): string {
  switch (object) {
    case AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.ACTION_TYPE_UNSPECIFIED:
      return "ACTION_TYPE_UNSPECIFIED";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.ALLOW:
      return "ALLOW";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.DENY:
      return "DENY";
    case AnalyzerOrgPolicyConstraint_CustomConstraint_ActionType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A request message for
 * [AssetService.AnalyzeOrgPolicies][google.cloud.asset.v1.AssetService.AnalyzeOrgPolicies].
 */
export interface AnalyzeOrgPoliciesRequest {
  /**
   * Required. The organization to scope the request. Only organization
   * policies within the scope will be analyzed.
   *
   * * organizations/{ORGANIZATION_NUMBER} (e.g., "organizations/123456")
   */
  scope: string;
  /**
   * Required. The name of the constraint to analyze organization policies for.
   * The response only contains analyzed organization policies for the provided
   * constraint.
   */
  constraint: string;
  /**
   * The expression to filter
   * [AnalyzeOrgPoliciesResponse.org_policy_results][google.cloud.asset.v1.AnalyzeOrgPoliciesResponse.org_policy_results].
   * Filtering is currently available for bare literal values and the following
   * fields:
   * * consolidated_policy.attached_resource
   * * consolidated_policy.rules.enforce
   *
   * When filtering by a specific field, the only supported operator is `=`.
   * For example, filtering by
   * consolidated_policy.attached_resource="//cloudresourcemanager.googleapis.com/folders/001"
   * will return all the Organization Policy results attached to "folders/001".
   */
  filter: string;
  /**
   * The maximum number of items to return per page. If unspecified,
   * [AnalyzeOrgPoliciesResponse.org_policy_results][google.cloud.asset.v1.AnalyzeOrgPoliciesResponse.org_policy_results]
   * will contain 20 items with a maximum of 200.
   */
  pageSize?:
    | number
    | undefined;
  /** The pagination token to retrieve the next page. */
  pageToken: string;
}

/**
 * The response message for
 * [AssetService.AnalyzeOrgPolicies][google.cloud.asset.v1.AssetService.AnalyzeOrgPolicies].
 */
export interface AnalyzeOrgPoliciesResponse {
  /**
   * The organization policies under the
   * [AnalyzeOrgPoliciesRequest.scope][google.cloud.asset.v1.AnalyzeOrgPoliciesRequest.scope]
   * with the
   * [AnalyzeOrgPoliciesRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPoliciesRequest.constraint].
   */
  orgPolicyResults: AnalyzeOrgPoliciesResponse_OrgPolicyResult[];
  /** The definition of the constraint in the request. */
  constraint:
    | AnalyzerOrgPolicyConstraint
    | undefined;
  /**
   * The page token to fetch the next page for
   * [AnalyzeOrgPoliciesResponse.org_policy_results][google.cloud.asset.v1.AnalyzeOrgPoliciesResponse.org_policy_results].
   */
  nextPageToken: string;
}

/** The organization policy result to the query. */
export interface AnalyzeOrgPoliciesResponse_OrgPolicyResult {
  /**
   * The consolidated organization policy for the analyzed resource. The
   * consolidated organization policy is computed by merging and evaluating
   * [AnalyzeOrgPoliciesResponse.policy_bundle][].
   * The evaluation will respect the organization policy [hierarchy
   * rules](https://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy).
   */
  consolidatedPolicy:
    | AnalyzerOrgPolicy
    | undefined;
  /**
   * The ordered list of all organization policies from the
   * [AnalyzeOrgPoliciesResponse.OrgPolicyResult.consolidated_policy.attached_resource][].
   * to the scope specified in the request.
   *
   * If the constraint is defined with default policy, it will also appear in
   * the list.
   */
  policyBundle: AnalyzerOrgPolicy[];
  /**
   * The project that this consolidated policy belongs to, in the format of
   * projects/{PROJECT_NUMBER}. This field is available when the consolidated
   * policy belongs to a project.
   */
  project: string;
  /**
   * The folder(s) that this consolidated policy belongs to, in the format of
   * folders/{FOLDER_NUMBER}. This field is available when the consolidated
   * policy belongs (directly or cascadingly) to one or more folders.
   */
  folders: string[];
  /**
   * The organization that this consolidated policy belongs to, in the format
   * of organizations/{ORGANIZATION_NUMBER}. This field is available when the
   * consolidated policy belongs (directly or cascadingly) to an organization.
   */
  organization: string;
}

/**
 * A request message for
 * [AssetService.AnalyzeOrgPolicyGovernedContainers][google.cloud.asset.v1.AssetService.AnalyzeOrgPolicyGovernedContainers].
 */
export interface AnalyzeOrgPolicyGovernedContainersRequest {
  /**
   * Required. The organization to scope the request. Only organization
   * policies within the scope will be analyzed. The output containers will
   * also be limited to the ones governed by those in-scope organization
   * policies.
   *
   * * organizations/{ORGANIZATION_NUMBER} (e.g., "organizations/123456")
   */
  scope: string;
  /**
   * Required. The name of the constraint to analyze governed containers for.
   * The analysis only contains organization policies for the provided
   * constraint.
   */
  constraint: string;
  /**
   * The expression to filter
   * [AnalyzeOrgPolicyGovernedContainersResponse.governed_containers][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersResponse.governed_containers].
   * Filtering is currently available for bare literal values and the following
   * fields:
   * * parent
   * * consolidated_policy.rules.enforce
   *
   * When filtering by a specific field, the only supported operator is `=`.
   * For example, filtering by
   * parent="//cloudresourcemanager.googleapis.com/folders/001"
   * will return all the containers under "folders/001".
   */
  filter: string;
  /**
   * The maximum number of items to return per page. If unspecified,
   * [AnalyzeOrgPolicyGovernedContainersResponse.governed_containers][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersResponse.governed_containers]
   * will contain 100 items with a maximum of 200.
   */
  pageSize?:
    | number
    | undefined;
  /** The pagination token to retrieve the next page. */
  pageToken: string;
}

/**
 * The response message for
 * [AssetService.AnalyzeOrgPolicyGovernedContainers][google.cloud.asset.v1.AssetService.AnalyzeOrgPolicyGovernedContainers].
 */
export interface AnalyzeOrgPolicyGovernedContainersResponse {
  /** The list of the analyzed governed containers. */
  governedContainers: AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer[];
  /** The definition of the constraint in the request. */
  constraint:
    | AnalyzerOrgPolicyConstraint
    | undefined;
  /**
   * The page token to fetch the next page for
   * [AnalyzeOrgPolicyGovernedContainersResponse.governed_containers][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersResponse.governed_containers].
   */
  nextPageToken: string;
}

/**
 * The organization/folder/project resource governed by organization policies
 * of
 * [AnalyzeOrgPolicyGovernedContainersRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersRequest.constraint].
 */
export interface AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer {
  /**
   * The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format) of
   * an organization/folder/project resource.
   */
  fullResourceName: string;
  /**
   * The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format) of
   * the parent of
   * [AnalyzeOrgPolicyGovernedContainersResponse.GovernedContainer.full_resource_name][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersResponse.GovernedContainer.full_resource_name].
   */
  parent: string;
  /**
   * The consolidated organization policy for the analyzed resource. The
   * consolidated organization policy is computed by merging and evaluating
   * [AnalyzeOrgPolicyGovernedContainersResponse.GovernedContainer.policy_bundle][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedContainersResponse.GovernedContainer.policy_bundle].
   * The evaluation will respect the organization policy [hierarchy
   * rules](https://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy).
   */
  consolidatedPolicy:
    | AnalyzerOrgPolicy
    | undefined;
  /**
   * The ordered list of all organization policies from the
   * [AnalyzeOrgPoliciesResponse.OrgPolicyResult.consolidated_policy.attached_resource][].
   * to the scope specified in the request.
   *
   * If the constraint is defined with default policy, it will also appear in
   * the list.
   */
  policyBundle: AnalyzerOrgPolicy[];
  /**
   * The project that this resource belongs to, in the format of
   * projects/{PROJECT_NUMBER}. This field is available when the resource
   * belongs to a project.
   */
  project: string;
  /**
   * The folder(s) that this resource belongs to, in the format of
   * folders/{FOLDER_NUMBER}. This field is available when the resource
   * belongs (directly or cascadingly) to one or more folders.
   */
  folders: string[];
  /**
   * The organization that this resource belongs to, in the format of
   * organizations/{ORGANIZATION_NUMBER}. This field is available when the
   * resource belongs (directly or cascadingly) to an organization.
   */
  organization: string;
  /** The effective tags on this resource. */
  effectiveTags: EffectiveTagDetails[];
}

/**
 * A request message for
 * [AssetService.AnalyzeOrgPolicyGovernedAssets][google.cloud.asset.v1.AssetService.AnalyzeOrgPolicyGovernedAssets].
 */
export interface AnalyzeOrgPolicyGovernedAssetsRequest {
  /**
   * Required. The organization to scope the request. Only organization
   * policies within the scope will be analyzed. The output assets will
   * also be limited to the ones governed by those in-scope organization
   * policies.
   *
   * * organizations/{ORGANIZATION_NUMBER} (e.g., "organizations/123456")
   */
  scope: string;
  /**
   * Required. The name of the constraint to analyze governed assets for. The
   * analysis only contains analyzed organization policies for the provided
   * constraint.
   */
  constraint: string;
  /**
   * The expression to filter
   * [AnalyzeOrgPolicyGovernedAssetsResponse.governed_assets][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.governed_assets].
   *
   * For governed resources, filtering is currently available for bare literal
   * values and the following fields:
   * * governed_resource.project
   * * governed_resource.folders
   * * consolidated_policy.rules.enforce
   * When filtering by `governed_resource.project` or
   * `consolidated_policy.rules.enforce`, the only supported operator is `=`.
   * When filtering by `governed_resource.folders`, the supported operators
   * are `=` and `:`.
   * For example, filtering by `governed_resource.project="projects/12345678"`
   * will return all the governed resources under "projects/12345678",
   * including the project itself if applicable.
   *
   * For governed IAM policies, filtering is currently available for bare
   * literal values and the following fields:
   * * governed_iam_policy.project
   * * governed_iam_policy.folders
   * * consolidated_policy.rules.enforce
   * When filtering by `governed_iam_policy.project` or
   * `consolidated_policy.rules.enforce`, the only supported operator is `=`.
   * When filtering by `governed_iam_policy.folders`, the supported operators
   * are `=` and `:`.
   * For example, filtering by `governed_iam_policy.folders:"folders/12345678"`
   * will return all the governed IAM policies under "folders/001".
   */
  filter: string;
  /**
   * The maximum number of items to return per page. If unspecified,
   * [AnalyzeOrgPolicyGovernedAssetsResponse.governed_assets][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.governed_assets]
   * will contain 100 items with a maximum of 200.
   */
  pageSize?:
    | number
    | undefined;
  /** The pagination token to retrieve the next page. */
  pageToken: string;
}

/**
 * The response message for
 * [AssetService.AnalyzeOrgPolicyGovernedAssets][google.cloud.asset.v1.AssetService.AnalyzeOrgPolicyGovernedAssets].
 */
export interface AnalyzeOrgPolicyGovernedAssetsResponse {
  /** The list of the analyzed governed assets. */
  governedAssets: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset[];
  /** The definition of the constraint in the request. */
  constraint:
    | AnalyzerOrgPolicyConstraint
    | undefined;
  /**
   * The page token to fetch the next page for
   * [AnalyzeOrgPolicyGovernedAssetsResponse.governed_assets][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.governed_assets].
   */
  nextPageToken: string;
}

/**
 * The Google Cloud resources governed by the organization policies of the
 * [AnalyzeOrgPolicyGovernedAssetsRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsRequest.constraint].
 */
export interface AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource {
  /**
   * The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format) of
   * the Google Cloud resource.
   */
  fullResourceName: string;
  /**
   * The [full resource name]
   * (https://cloud.google.com/asset-inventory/docs/resource-name-format) of
   * the parent of
   * [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedResource.full_resource_name][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedResource.full_resource_name].
   */
  parent: string;
  /**
   * The project that this resource belongs to, in the format of
   * projects/{PROJECT_NUMBER}. This field is available when the resource
   * belongs to a project.
   */
  project: string;
  /**
   * The folder(s) that this resource belongs to, in the format of
   * folders/{FOLDER_NUMBER}. This field is available when the resource
   * belongs (directly or cascadingly) to one or more folders.
   */
  folders: string[];
  /**
   * The organization that this resource belongs to, in the format of
   * organizations/{ORGANIZATION_NUMBER}. This field is available when the
   * resource belongs (directly or cascadingly) to an organization.
   */
  organization: string;
  /**
   * The asset type of the
   * [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedResource.full_resource_name][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedResource.full_resource_name]
   * Example:
   * `cloudresourcemanager.googleapis.com/Project`
   * See [Cloud Asset Inventory Supported Asset
   * Types](https://cloud.google.com/asset-inventory/docs/supported-asset-types)
   * for all supported asset types.
   */
  assetType: string;
  /** The effective tags on this resource. */
  effectiveTags: EffectiveTagDetails[];
}

/**
 * The IAM policies governed by the organization policies of the
 * [AnalyzeOrgPolicyGovernedAssetsRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsRequest.constraint].
 */
export interface AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy {
  /**
   * The full resource name of the resource on which this IAM policy is set.
   * Example:
   * `//compute.googleapis.com/projects/my_project_123/zones/zone1/instances/instance1`.
   * See [Cloud Asset Inventory Resource Name
   * Format](https://cloud.google.com/asset-inventory/docs/resource-name-format)
   * for more information.
   */
  attachedResource: string;
  /** The IAM policy directly set on the given resource. */
  policy:
    | Policy
    | undefined;
  /**
   * The project that this IAM policy belongs to, in the format of
   * projects/{PROJECT_NUMBER}. This field is available when the IAM policy
   * belongs to a project.
   */
  project: string;
  /**
   * The folder(s) that this IAM policy belongs to, in the format of
   * folders/{FOLDER_NUMBER}. This field is available when the IAM policy
   * belongs (directly or cascadingly) to one or more folders.
   */
  folders: string[];
  /**
   * The organization that this IAM policy belongs to, in the format of
   * organizations/{ORGANIZATION_NUMBER}. This field is available when the
   * IAM policy belongs (directly or cascadingly) to an organization.
   */
  organization: string;
  /**
   * The asset type of the
   * [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedIamPolicy.attached_resource][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedIamPolicy.attached_resource].
   * Example:
   * `cloudresourcemanager.googleapis.com/Project`
   * See [Cloud Asset Inventory Supported Asset
   * Types](https://cloud.google.com/asset-inventory/docs/supported-asset-types)
   * for all supported asset types.
   */
  assetType: string;
}

/**
 * Represents a Google Cloud asset(resource or IAM policy) governed by the
 * organization policies of the
 * [AnalyzeOrgPolicyGovernedAssetsRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsRequest.constraint].
 */
export interface AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset {
  /**
   * A Google Cloud resource governed by the organization
   * policies of the
   * [AnalyzeOrgPolicyGovernedAssetsRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsRequest.constraint].
   */
  governedResource?:
    | AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource
    | undefined;
  /**
   * An IAM policy governed by the organization
   * policies of the
   * [AnalyzeOrgPolicyGovernedAssetsRequest.constraint][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsRequest.constraint].
   */
  governedIamPolicy?:
    | AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy
    | undefined;
  /**
   * The consolidated policy for the analyzed asset. The consolidated
   * policy is computed by merging and evaluating
   * [AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset.policy_bundle][google.cloud.asset.v1.AnalyzeOrgPolicyGovernedAssetsResponse.GovernedAsset.policy_bundle].
   * The evaluation will respect the organization policy [hierarchy
   * rules](https://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy).
   */
  consolidatedPolicy:
    | AnalyzerOrgPolicy
    | undefined;
  /**
   * The ordered list of all organization policies from the
   * [AnalyzeOrgPoliciesResponse.OrgPolicyResult.consolidated_policy.attached_resource][]
   * to the scope specified in the request.
   *
   * If the constraint is defined with default policy, it will also appear in
   * the list.
   */
  policyBundle: AnalyzerOrgPolicy[];
}

function createBaseAnalyzeIamPolicyLongrunningMetadata(): AnalyzeIamPolicyLongrunningMetadata {
  return { createTime: undefined };
}

export const AnalyzeIamPolicyLongrunningMetadata: MessageFns<AnalyzeIamPolicyLongrunningMetadata> = {
  encode(message: AnalyzeIamPolicyLongrunningMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIamPolicyLongrunningMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIamPolicyLongrunningMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIamPolicyLongrunningMetadata {
    return { createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined };
  },

  toJSON(message: AnalyzeIamPolicyLongrunningMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeIamPolicyLongrunningMetadata>): AnalyzeIamPolicyLongrunningMetadata {
    return AnalyzeIamPolicyLongrunningMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeIamPolicyLongrunningMetadata>): AnalyzeIamPolicyLongrunningMetadata {
    const message = createBaseAnalyzeIamPolicyLongrunningMetadata();
    message.createTime = object.createTime ?? undefined;
    return message;
  },
};

function createBaseExportAssetsRequest(): ExportAssetsRequest {
  return {
    parent: "",
    readTime: undefined,
    assetTypes: [],
    contentType: 0,
    outputConfig: undefined,
    relationshipTypes: [],
  };
}

export const ExportAssetsRequest: MessageFns<ExportAssetsRequest> = {
  encode(message: ExportAssetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(18).fork()).join();
    }
    for (const v of message.assetTypes) {
      writer.uint32(26).string(v!);
    }
    if (message.contentType !== 0) {
      writer.uint32(32).int32(message.contentType);
    }
    if (message.outputConfig !== undefined) {
      OutputConfig.encode(message.outputConfig, writer.uint32(42).fork()).join();
    }
    for (const v of message.relationshipTypes) {
      writer.uint32(50).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportAssetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportAssetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.assetTypes.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.contentType = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.outputConfig = OutputConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.relationshipTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportAssetsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      assetTypes: globalThis.Array.isArray(object?.assetTypes)
        ? object.assetTypes.map((e: any) => globalThis.String(e))
        : [],
      contentType: isSet(object.contentType) ? contentTypeFromJSON(object.contentType) : 0,
      outputConfig: isSet(object.outputConfig) ? OutputConfig.fromJSON(object.outputConfig) : undefined,
      relationshipTypes: globalThis.Array.isArray(object?.relationshipTypes)
        ? object.relationshipTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ExportAssetsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.assetTypes?.length) {
      obj.assetTypes = message.assetTypes;
    }
    if (message.contentType !== 0) {
      obj.contentType = contentTypeToJSON(message.contentType);
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = OutputConfig.toJSON(message.outputConfig);
    }
    if (message.relationshipTypes?.length) {
      obj.relationshipTypes = message.relationshipTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportAssetsRequest>): ExportAssetsRequest {
    return ExportAssetsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportAssetsRequest>): ExportAssetsRequest {
    const message = createBaseExportAssetsRequest();
    message.parent = object.parent ?? "";
    message.readTime = object.readTime ?? undefined;
    message.assetTypes = object.assetTypes?.map((e) => e) || [];
    message.contentType = object.contentType ?? 0;
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? OutputConfig.fromPartial(object.outputConfig)
      : undefined;
    message.relationshipTypes = object.relationshipTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseExportAssetsResponse(): ExportAssetsResponse {
  return { readTime: undefined, outputConfig: undefined, outputResult: undefined };
}

export const ExportAssetsResponse: MessageFns<ExportAssetsResponse> = {
  encode(message: ExportAssetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(10).fork()).join();
    }
    if (message.outputConfig !== undefined) {
      OutputConfig.encode(message.outputConfig, writer.uint32(18).fork()).join();
    }
    if (message.outputResult !== undefined) {
      OutputResult.encode(message.outputResult, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportAssetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportAssetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.outputConfig = OutputConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.outputResult = OutputResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportAssetsResponse {
    return {
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      outputConfig: isSet(object.outputConfig) ? OutputConfig.fromJSON(object.outputConfig) : undefined,
      outputResult: isSet(object.outputResult) ? OutputResult.fromJSON(object.outputResult) : undefined,
    };
  },

  toJSON(message: ExportAssetsResponse): unknown {
    const obj: any = {};
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = OutputConfig.toJSON(message.outputConfig);
    }
    if (message.outputResult !== undefined) {
      obj.outputResult = OutputResult.toJSON(message.outputResult);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportAssetsResponse>): ExportAssetsResponse {
    return ExportAssetsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportAssetsResponse>): ExportAssetsResponse {
    const message = createBaseExportAssetsResponse();
    message.readTime = object.readTime ?? undefined;
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? OutputConfig.fromPartial(object.outputConfig)
      : undefined;
    message.outputResult = (object.outputResult !== undefined && object.outputResult !== null)
      ? OutputResult.fromPartial(object.outputResult)
      : undefined;
    return message;
  },
};

function createBaseListAssetsRequest(): ListAssetsRequest {
  return {
    parent: "",
    readTime: undefined,
    assetTypes: [],
    contentType: 0,
    pageSize: 0,
    pageToken: "",
    relationshipTypes: [],
  };
}

export const ListAssetsRequest: MessageFns<ListAssetsRequest> = {
  encode(message: ListAssetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(18).fork()).join();
    }
    for (const v of message.assetTypes) {
      writer.uint32(26).string(v!);
    }
    if (message.contentType !== 0) {
      writer.uint32(32).int32(message.contentType);
    }
    if (message.pageSize !== 0) {
      writer.uint32(40).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(50).string(message.pageToken);
    }
    for (const v of message.relationshipTypes) {
      writer.uint32(58).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListAssetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListAssetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.assetTypes.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.contentType = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.relationshipTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListAssetsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      assetTypes: globalThis.Array.isArray(object?.assetTypes)
        ? object.assetTypes.map((e: any) => globalThis.String(e))
        : [],
      contentType: isSet(object.contentType) ? contentTypeFromJSON(object.contentType) : 0,
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      relationshipTypes: globalThis.Array.isArray(object?.relationshipTypes)
        ? object.relationshipTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListAssetsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.assetTypes?.length) {
      obj.assetTypes = message.assetTypes;
    }
    if (message.contentType !== 0) {
      obj.contentType = contentTypeToJSON(message.contentType);
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.relationshipTypes?.length) {
      obj.relationshipTypes = message.relationshipTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<ListAssetsRequest>): ListAssetsRequest {
    return ListAssetsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListAssetsRequest>): ListAssetsRequest {
    const message = createBaseListAssetsRequest();
    message.parent = object.parent ?? "";
    message.readTime = object.readTime ?? undefined;
    message.assetTypes = object.assetTypes?.map((e) => e) || [];
    message.contentType = object.contentType ?? 0;
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.relationshipTypes = object.relationshipTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseListAssetsResponse(): ListAssetsResponse {
  return { readTime: undefined, assets: [], nextPageToken: "" };
}

export const ListAssetsResponse: MessageFns<ListAssetsResponse> = {
  encode(message: ListAssetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(10).fork()).join();
    }
    for (const v of message.assets) {
      Asset.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListAssetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListAssetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.assets.push(Asset.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListAssetsResponse {
    return {
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      assets: globalThis.Array.isArray(object?.assets) ? object.assets.map((e: any) => Asset.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListAssetsResponse): unknown {
    const obj: any = {};
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.assets?.length) {
      obj.assets = message.assets.map((e) => Asset.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListAssetsResponse>): ListAssetsResponse {
    return ListAssetsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListAssetsResponse>): ListAssetsResponse {
    const message = createBaseListAssetsResponse();
    message.readTime = object.readTime ?? undefined;
    message.assets = object.assets?.map((e) => Asset.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseBatchGetAssetsHistoryRequest(): BatchGetAssetsHistoryRequest {
  return { parent: "", assetNames: [], contentType: 0, readTimeWindow: undefined, relationshipTypes: [] };
}

export const BatchGetAssetsHistoryRequest: MessageFns<BatchGetAssetsHistoryRequest> = {
  encode(message: BatchGetAssetsHistoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.assetNames) {
      writer.uint32(18).string(v!);
    }
    if (message.contentType !== 0) {
      writer.uint32(24).int32(message.contentType);
    }
    if (message.readTimeWindow !== undefined) {
      TimeWindow.encode(message.readTimeWindow, writer.uint32(34).fork()).join();
    }
    for (const v of message.relationshipTypes) {
      writer.uint32(42).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetAssetsHistoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetAssetsHistoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.assetNames.push(reader.string());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.contentType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.readTimeWindow = TimeWindow.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.relationshipTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetAssetsHistoryRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      assetNames: globalThis.Array.isArray(object?.assetNames)
        ? object.assetNames.map((e: any) => globalThis.String(e))
        : [],
      contentType: isSet(object.contentType) ? contentTypeFromJSON(object.contentType) : 0,
      readTimeWindow: isSet(object.readTimeWindow) ? TimeWindow.fromJSON(object.readTimeWindow) : undefined,
      relationshipTypes: globalThis.Array.isArray(object?.relationshipTypes)
        ? object.relationshipTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: BatchGetAssetsHistoryRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.assetNames?.length) {
      obj.assetNames = message.assetNames;
    }
    if (message.contentType !== 0) {
      obj.contentType = contentTypeToJSON(message.contentType);
    }
    if (message.readTimeWindow !== undefined) {
      obj.readTimeWindow = TimeWindow.toJSON(message.readTimeWindow);
    }
    if (message.relationshipTypes?.length) {
      obj.relationshipTypes = message.relationshipTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetAssetsHistoryRequest>): BatchGetAssetsHistoryRequest {
    return BatchGetAssetsHistoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetAssetsHistoryRequest>): BatchGetAssetsHistoryRequest {
    const message = createBaseBatchGetAssetsHistoryRequest();
    message.parent = object.parent ?? "";
    message.assetNames = object.assetNames?.map((e) => e) || [];
    message.contentType = object.contentType ?? 0;
    message.readTimeWindow = (object.readTimeWindow !== undefined && object.readTimeWindow !== null)
      ? TimeWindow.fromPartial(object.readTimeWindow)
      : undefined;
    message.relationshipTypes = object.relationshipTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseBatchGetAssetsHistoryResponse(): BatchGetAssetsHistoryResponse {
  return { assets: [] };
}

export const BatchGetAssetsHistoryResponse: MessageFns<BatchGetAssetsHistoryResponse> = {
  encode(message: BatchGetAssetsHistoryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.assets) {
      TemporalAsset.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetAssetsHistoryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetAssetsHistoryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.assets.push(TemporalAsset.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetAssetsHistoryResponse {
    return {
      assets: globalThis.Array.isArray(object?.assets) ? object.assets.map((e: any) => TemporalAsset.fromJSON(e)) : [],
    };
  },

  toJSON(message: BatchGetAssetsHistoryResponse): unknown {
    const obj: any = {};
    if (message.assets?.length) {
      obj.assets = message.assets.map((e) => TemporalAsset.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetAssetsHistoryResponse>): BatchGetAssetsHistoryResponse {
    return BatchGetAssetsHistoryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetAssetsHistoryResponse>): BatchGetAssetsHistoryResponse {
    const message = createBaseBatchGetAssetsHistoryResponse();
    message.assets = object.assets?.map((e) => TemporalAsset.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCreateFeedRequest(): CreateFeedRequest {
  return { parent: "", feedId: "", feed: undefined };
}

export const CreateFeedRequest: MessageFns<CreateFeedRequest> = {
  encode(message: CreateFeedRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.feedId !== "") {
      writer.uint32(18).string(message.feedId);
    }
    if (message.feed !== undefined) {
      Feed.encode(message.feed, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFeedRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFeedRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.feedId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.feed = Feed.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFeedRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      feedId: isSet(object.feedId) ? globalThis.String(object.feedId) : "",
      feed: isSet(object.feed) ? Feed.fromJSON(object.feed) : undefined,
    };
  },

  toJSON(message: CreateFeedRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.feedId !== "") {
      obj.feedId = message.feedId;
    }
    if (message.feed !== undefined) {
      obj.feed = Feed.toJSON(message.feed);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFeedRequest>): CreateFeedRequest {
    return CreateFeedRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFeedRequest>): CreateFeedRequest {
    const message = createBaseCreateFeedRequest();
    message.parent = object.parent ?? "";
    message.feedId = object.feedId ?? "";
    message.feed = (object.feed !== undefined && object.feed !== null) ? Feed.fromPartial(object.feed) : undefined;
    return message;
  },
};

function createBaseGetFeedRequest(): GetFeedRequest {
  return { name: "" };
}

export const GetFeedRequest: MessageFns<GetFeedRequest> = {
  encode(message: GetFeedRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFeedRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFeedRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFeedRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetFeedRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetFeedRequest>): GetFeedRequest {
    return GetFeedRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFeedRequest>): GetFeedRequest {
    const message = createBaseGetFeedRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListFeedsRequest(): ListFeedsRequest {
  return { parent: "" };
}

export const ListFeedsRequest: MessageFns<ListFeedsRequest> = {
  encode(message: ListFeedsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFeedsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFeedsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFeedsRequest {
    return { parent: isSet(object.parent) ? globalThis.String(object.parent) : "" };
  },

  toJSON(message: ListFeedsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFeedsRequest>): ListFeedsRequest {
    return ListFeedsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFeedsRequest>): ListFeedsRequest {
    const message = createBaseListFeedsRequest();
    message.parent = object.parent ?? "";
    return message;
  },
};

function createBaseListFeedsResponse(): ListFeedsResponse {
  return { feeds: [] };
}

export const ListFeedsResponse: MessageFns<ListFeedsResponse> = {
  encode(message: ListFeedsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.feeds) {
      Feed.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFeedsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFeedsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.feeds.push(Feed.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFeedsResponse {
    return { feeds: globalThis.Array.isArray(object?.feeds) ? object.feeds.map((e: any) => Feed.fromJSON(e)) : [] };
  },

  toJSON(message: ListFeedsResponse): unknown {
    const obj: any = {};
    if (message.feeds?.length) {
      obj.feeds = message.feeds.map((e) => Feed.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ListFeedsResponse>): ListFeedsResponse {
    return ListFeedsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFeedsResponse>): ListFeedsResponse {
    const message = createBaseListFeedsResponse();
    message.feeds = object.feeds?.map((e) => Feed.fromPartial(e)) || [];
    return message;
  },
};

function createBaseUpdateFeedRequest(): UpdateFeedRequest {
  return { feed: undefined, updateMask: undefined };
}

export const UpdateFeedRequest: MessageFns<UpdateFeedRequest> = {
  encode(message: UpdateFeedRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.feed !== undefined) {
      Feed.encode(message.feed, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFeedRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFeedRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.feed = Feed.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFeedRequest {
    return {
      feed: isSet(object.feed) ? Feed.fromJSON(object.feed) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateFeedRequest): unknown {
    const obj: any = {};
    if (message.feed !== undefined) {
      obj.feed = Feed.toJSON(message.feed);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFeedRequest>): UpdateFeedRequest {
    return UpdateFeedRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFeedRequest>): UpdateFeedRequest {
    const message = createBaseUpdateFeedRequest();
    message.feed = (object.feed !== undefined && object.feed !== null) ? Feed.fromPartial(object.feed) : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteFeedRequest(): DeleteFeedRequest {
  return { name: "" };
}

export const DeleteFeedRequest: MessageFns<DeleteFeedRequest> = {
  encode(message: DeleteFeedRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeedRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeedRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeedRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteFeedRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeedRequest>): DeleteFeedRequest {
    return DeleteFeedRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeedRequest>): DeleteFeedRequest {
    const message = createBaseDeleteFeedRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseOutputConfig(): OutputConfig {
  return { gcsDestination: undefined, bigqueryDestination: undefined };
}

export const OutputConfig: MessageFns<OutputConfig> = {
  encode(message: OutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsDestination !== undefined) {
      GcsDestination.encode(message.gcsDestination, writer.uint32(10).fork()).join();
    }
    if (message.bigqueryDestination !== undefined) {
      BigQueryDestination.encode(message.bigqueryDestination, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsDestination = GcsDestination.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bigqueryDestination = BigQueryDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OutputConfig {
    return {
      gcsDestination: isSet(object.gcsDestination) ? GcsDestination.fromJSON(object.gcsDestination) : undefined,
      bigqueryDestination: isSet(object.bigqueryDestination)
        ? BigQueryDestination.fromJSON(object.bigqueryDestination)
        : undefined,
    };
  },

  toJSON(message: OutputConfig): unknown {
    const obj: any = {};
    if (message.gcsDestination !== undefined) {
      obj.gcsDestination = GcsDestination.toJSON(message.gcsDestination);
    }
    if (message.bigqueryDestination !== undefined) {
      obj.bigqueryDestination = BigQueryDestination.toJSON(message.bigqueryDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<OutputConfig>): OutputConfig {
    return OutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OutputConfig>): OutputConfig {
    const message = createBaseOutputConfig();
    message.gcsDestination = (object.gcsDestination !== undefined && object.gcsDestination !== null)
      ? GcsDestination.fromPartial(object.gcsDestination)
      : undefined;
    message.bigqueryDestination = (object.bigqueryDestination !== undefined && object.bigqueryDestination !== null)
      ? BigQueryDestination.fromPartial(object.bigqueryDestination)
      : undefined;
    return message;
  },
};

function createBaseOutputResult(): OutputResult {
  return { gcsResult: undefined };
}

export const OutputResult: MessageFns<OutputResult> = {
  encode(message: OutputResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsResult !== undefined) {
      GcsOutputResult.encode(message.gcsResult, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OutputResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOutputResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsResult = GcsOutputResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OutputResult {
    return { gcsResult: isSet(object.gcsResult) ? GcsOutputResult.fromJSON(object.gcsResult) : undefined };
  },

  toJSON(message: OutputResult): unknown {
    const obj: any = {};
    if (message.gcsResult !== undefined) {
      obj.gcsResult = GcsOutputResult.toJSON(message.gcsResult);
    }
    return obj;
  },

  create(base?: DeepPartial<OutputResult>): OutputResult {
    return OutputResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OutputResult>): OutputResult {
    const message = createBaseOutputResult();
    message.gcsResult = (object.gcsResult !== undefined && object.gcsResult !== null)
      ? GcsOutputResult.fromPartial(object.gcsResult)
      : undefined;
    return message;
  },
};

function createBaseGcsOutputResult(): GcsOutputResult {
  return { uris: [] };
}

export const GcsOutputResult: MessageFns<GcsOutputResult> = {
  encode(message: GcsOutputResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.uris) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsOutputResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsOutputResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uris.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsOutputResult {
    return { uris: globalThis.Array.isArray(object?.uris) ? object.uris.map((e: any) => globalThis.String(e)) : [] };
  },

  toJSON(message: GcsOutputResult): unknown {
    const obj: any = {};
    if (message.uris?.length) {
      obj.uris = message.uris;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsOutputResult>): GcsOutputResult {
    return GcsOutputResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsOutputResult>): GcsOutputResult {
    const message = createBaseGcsOutputResult();
    message.uris = object.uris?.map((e) => e) || [];
    return message;
  },
};

function createBaseGcsDestination(): GcsDestination {
  return { uri: undefined, uriPrefix: undefined };
}

export const GcsDestination: MessageFns<GcsDestination> = {
  encode(message: GcsDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== undefined) {
      writer.uint32(10).string(message.uri);
    }
    if (message.uriPrefix !== undefined) {
      writer.uint32(18).string(message.uriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsDestination {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : undefined,
      uriPrefix: isSet(object.uriPrefix) ? globalThis.String(object.uriPrefix) : undefined,
    };
  },

  toJSON(message: GcsDestination): unknown {
    const obj: any = {};
    if (message.uri !== undefined) {
      obj.uri = message.uri;
    }
    if (message.uriPrefix !== undefined) {
      obj.uriPrefix = message.uriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsDestination>): GcsDestination {
    return GcsDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsDestination>): GcsDestination {
    const message = createBaseGcsDestination();
    message.uri = object.uri ?? undefined;
    message.uriPrefix = object.uriPrefix ?? undefined;
    return message;
  },
};

function createBaseBigQueryDestination(): BigQueryDestination {
  return { dataset: "", table: "", force: false, partitionSpec: undefined, separateTablesPerAssetType: false };
}

export const BigQueryDestination: MessageFns<BigQueryDestination> = {
  encode(message: BigQueryDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataset !== "") {
      writer.uint32(10).string(message.dataset);
    }
    if (message.table !== "") {
      writer.uint32(18).string(message.table);
    }
    if (message.force !== false) {
      writer.uint32(24).bool(message.force);
    }
    if (message.partitionSpec !== undefined) {
      PartitionSpec.encode(message.partitionSpec, writer.uint32(34).fork()).join();
    }
    if (message.separateTablesPerAssetType !== false) {
      writer.uint32(40).bool(message.separateTablesPerAssetType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataset = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.table = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.force = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.partitionSpec = PartitionSpec.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.separateTablesPerAssetType = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDestination {
    return {
      dataset: isSet(object.dataset) ? globalThis.String(object.dataset) : "",
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      force: isSet(object.force) ? globalThis.Boolean(object.force) : false,
      partitionSpec: isSet(object.partitionSpec) ? PartitionSpec.fromJSON(object.partitionSpec) : undefined,
      separateTablesPerAssetType: isSet(object.separateTablesPerAssetType)
        ? globalThis.Boolean(object.separateTablesPerAssetType)
        : false,
    };
  },

  toJSON(message: BigQueryDestination): unknown {
    const obj: any = {};
    if (message.dataset !== "") {
      obj.dataset = message.dataset;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.force !== false) {
      obj.force = message.force;
    }
    if (message.partitionSpec !== undefined) {
      obj.partitionSpec = PartitionSpec.toJSON(message.partitionSpec);
    }
    if (message.separateTablesPerAssetType !== false) {
      obj.separateTablesPerAssetType = message.separateTablesPerAssetType;
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryDestination>): BigQueryDestination {
    return BigQueryDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryDestination>): BigQueryDestination {
    const message = createBaseBigQueryDestination();
    message.dataset = object.dataset ?? "";
    message.table = object.table ?? "";
    message.force = object.force ?? false;
    message.partitionSpec = (object.partitionSpec !== undefined && object.partitionSpec !== null)
      ? PartitionSpec.fromPartial(object.partitionSpec)
      : undefined;
    message.separateTablesPerAssetType = object.separateTablesPerAssetType ?? false;
    return message;
  },
};

function createBasePartitionSpec(): PartitionSpec {
  return { partitionKey: 0 };
}

export const PartitionSpec: MessageFns<PartitionSpec> = {
  encode(message: PartitionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.partitionKey !== 0) {
      writer.uint32(8).int32(message.partitionKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PartitionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartitionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.partitionKey = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PartitionSpec {
    return { partitionKey: isSet(object.partitionKey) ? partitionSpec_PartitionKeyFromJSON(object.partitionKey) : 0 };
  },

  toJSON(message: PartitionSpec): unknown {
    const obj: any = {};
    if (message.partitionKey !== 0) {
      obj.partitionKey = partitionSpec_PartitionKeyToJSON(message.partitionKey);
    }
    return obj;
  },

  create(base?: DeepPartial<PartitionSpec>): PartitionSpec {
    return PartitionSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PartitionSpec>): PartitionSpec {
    const message = createBasePartitionSpec();
    message.partitionKey = object.partitionKey ?? 0;
    return message;
  },
};

function createBasePubsubDestination(): PubsubDestination {
  return { topic: "" };
}

export const PubsubDestination: MessageFns<PubsubDestination> = {
  encode(message: PubsubDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PubsubDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePubsubDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PubsubDestination {
    return { topic: isSet(object.topic) ? globalThis.String(object.topic) : "" };
  },

  toJSON(message: PubsubDestination): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    return obj;
  },

  create(base?: DeepPartial<PubsubDestination>): PubsubDestination {
    return PubsubDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PubsubDestination>): PubsubDestination {
    const message = createBasePubsubDestination();
    message.topic = object.topic ?? "";
    return message;
  },
};

function createBaseFeedOutputConfig(): FeedOutputConfig {
  return { pubsubDestination: undefined };
}

export const FeedOutputConfig: MessageFns<FeedOutputConfig> = {
  encode(message: FeedOutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pubsubDestination !== undefined) {
      PubsubDestination.encode(message.pubsubDestination, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FeedOutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeedOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pubsubDestination = PubsubDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FeedOutputConfig {
    return {
      pubsubDestination: isSet(object.pubsubDestination)
        ? PubsubDestination.fromJSON(object.pubsubDestination)
        : undefined,
    };
  },

  toJSON(message: FeedOutputConfig): unknown {
    const obj: any = {};
    if (message.pubsubDestination !== undefined) {
      obj.pubsubDestination = PubsubDestination.toJSON(message.pubsubDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<FeedOutputConfig>): FeedOutputConfig {
    return FeedOutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FeedOutputConfig>): FeedOutputConfig {
    const message = createBaseFeedOutputConfig();
    message.pubsubDestination = (object.pubsubDestination !== undefined && object.pubsubDestination !== null)
      ? PubsubDestination.fromPartial(object.pubsubDestination)
      : undefined;
    return message;
  },
};

function createBaseFeed(): Feed {
  return {
    name: "",
    assetNames: [],
    assetTypes: [],
    contentType: 0,
    feedOutputConfig: undefined,
    condition: undefined,
    relationshipTypes: [],
  };
}

export const Feed: MessageFns<Feed> = {
  encode(message: Feed, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.assetNames) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.assetTypes) {
      writer.uint32(26).string(v!);
    }
    if (message.contentType !== 0) {
      writer.uint32(32).int32(message.contentType);
    }
    if (message.feedOutputConfig !== undefined) {
      FeedOutputConfig.encode(message.feedOutputConfig, writer.uint32(42).fork()).join();
    }
    if (message.condition !== undefined) {
      Expr.encode(message.condition, writer.uint32(50).fork()).join();
    }
    for (const v of message.relationshipTypes) {
      writer.uint32(58).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Feed {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeed();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.assetNames.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.assetTypes.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.contentType = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.feedOutputConfig = FeedOutputConfig.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.condition = Expr.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.relationshipTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Feed {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      assetNames: globalThis.Array.isArray(object?.assetNames)
        ? object.assetNames.map((e: any) => globalThis.String(e))
        : [],
      assetTypes: globalThis.Array.isArray(object?.assetTypes)
        ? object.assetTypes.map((e: any) => globalThis.String(e))
        : [],
      contentType: isSet(object.contentType) ? contentTypeFromJSON(object.contentType) : 0,
      feedOutputConfig: isSet(object.feedOutputConfig) ? FeedOutputConfig.fromJSON(object.feedOutputConfig) : undefined,
      condition: isSet(object.condition) ? Expr.fromJSON(object.condition) : undefined,
      relationshipTypes: globalThis.Array.isArray(object?.relationshipTypes)
        ? object.relationshipTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Feed): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.assetNames?.length) {
      obj.assetNames = message.assetNames;
    }
    if (message.assetTypes?.length) {
      obj.assetTypes = message.assetTypes;
    }
    if (message.contentType !== 0) {
      obj.contentType = contentTypeToJSON(message.contentType);
    }
    if (message.feedOutputConfig !== undefined) {
      obj.feedOutputConfig = FeedOutputConfig.toJSON(message.feedOutputConfig);
    }
    if (message.condition !== undefined) {
      obj.condition = Expr.toJSON(message.condition);
    }
    if (message.relationshipTypes?.length) {
      obj.relationshipTypes = message.relationshipTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<Feed>): Feed {
    return Feed.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Feed>): Feed {
    const message = createBaseFeed();
    message.name = object.name ?? "";
    message.assetNames = object.assetNames?.map((e) => e) || [];
    message.assetTypes = object.assetTypes?.map((e) => e) || [];
    message.contentType = object.contentType ?? 0;
    message.feedOutputConfig = (object.feedOutputConfig !== undefined && object.feedOutputConfig !== null)
      ? FeedOutputConfig.fromPartial(object.feedOutputConfig)
      : undefined;
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? Expr.fromPartial(object.condition)
      : undefined;
    message.relationshipTypes = object.relationshipTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseSearchAllResourcesRequest(): SearchAllResourcesRequest {
  return { scope: "", query: "", assetTypes: [], pageSize: 0, pageToken: "", orderBy: "", readMask: undefined };
}

export const SearchAllResourcesRequest: MessageFns<SearchAllResourcesRequest> = {
  encode(message: SearchAllResourcesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    if (message.query !== "") {
      writer.uint32(18).string(message.query);
    }
    for (const v of message.assetTypes) {
      writer.uint32(26).string(v!);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(50).string(message.orderBy);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchAllResourcesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchAllResourcesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.query = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.assetTypes.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchAllResourcesRequest {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      assetTypes: globalThis.Array.isArray(object?.assetTypes)
        ? object.assetTypes.map((e: any) => globalThis.String(e))
        : [],
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: SearchAllResourcesRequest): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.assetTypes?.length) {
      obj.assetTypes = message.assetTypes;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<SearchAllResourcesRequest>): SearchAllResourcesRequest {
    return SearchAllResourcesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchAllResourcesRequest>): SearchAllResourcesRequest {
    const message = createBaseSearchAllResourcesRequest();
    message.scope = object.scope ?? "";
    message.query = object.query ?? "";
    message.assetTypes = object.assetTypes?.map((e) => e) || [];
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseSearchAllResourcesResponse(): SearchAllResourcesResponse {
  return { results: [], nextPageToken: "" };
}

export const SearchAllResourcesResponse: MessageFns<SearchAllResourcesResponse> = {
  encode(message: SearchAllResourcesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      ResourceSearchResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchAllResourcesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchAllResourcesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(ResourceSearchResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchAllResourcesResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => ResourceSearchResult.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: SearchAllResourcesResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => ResourceSearchResult.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchAllResourcesResponse>): SearchAllResourcesResponse {
    return SearchAllResourcesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchAllResourcesResponse>): SearchAllResourcesResponse {
    const message = createBaseSearchAllResourcesResponse();
    message.results = object.results?.map((e) => ResourceSearchResult.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseSearchAllIamPoliciesRequest(): SearchAllIamPoliciesRequest {
  return { scope: "", query: "", pageSize: 0, pageToken: "", assetTypes: [], orderBy: "" };
}

export const SearchAllIamPoliciesRequest: MessageFns<SearchAllIamPoliciesRequest> = {
  encode(message: SearchAllIamPoliciesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    if (message.query !== "") {
      writer.uint32(18).string(message.query);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    for (const v of message.assetTypes) {
      writer.uint32(42).string(v!);
    }
    if (message.orderBy !== "") {
      writer.uint32(58).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchAllIamPoliciesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchAllIamPoliciesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.query = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.assetTypes.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchAllIamPoliciesRequest {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      assetTypes: globalThis.Array.isArray(object?.assetTypes)
        ? object.assetTypes.map((e: any) => globalThis.String(e))
        : [],
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: SearchAllIamPoliciesRequest): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.assetTypes?.length) {
      obj.assetTypes = message.assetTypes;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchAllIamPoliciesRequest>): SearchAllIamPoliciesRequest {
    return SearchAllIamPoliciesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchAllIamPoliciesRequest>): SearchAllIamPoliciesRequest {
    const message = createBaseSearchAllIamPoliciesRequest();
    message.scope = object.scope ?? "";
    message.query = object.query ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.assetTypes = object.assetTypes?.map((e) => e) || [];
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseSearchAllIamPoliciesResponse(): SearchAllIamPoliciesResponse {
  return { results: [], nextPageToken: "" };
}

export const SearchAllIamPoliciesResponse: MessageFns<SearchAllIamPoliciesResponse> = {
  encode(message: SearchAllIamPoliciesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      IamPolicySearchResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchAllIamPoliciesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchAllIamPoliciesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(IamPolicySearchResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchAllIamPoliciesResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => IamPolicySearchResult.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: SearchAllIamPoliciesResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => IamPolicySearchResult.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchAllIamPoliciesResponse>): SearchAllIamPoliciesResponse {
    return SearchAllIamPoliciesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchAllIamPoliciesResponse>): SearchAllIamPoliciesResponse {
    const message = createBaseSearchAllIamPoliciesResponse();
    message.results = object.results?.map((e) => IamPolicySearchResult.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseIamPolicyAnalysisQuery(): IamPolicyAnalysisQuery {
  return {
    scope: "",
    resourceSelector: undefined,
    identitySelector: undefined,
    accessSelector: undefined,
    options: undefined,
    conditionContext: undefined,
  };
}

export const IamPolicyAnalysisQuery: MessageFns<IamPolicyAnalysisQuery> = {
  encode(message: IamPolicyAnalysisQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    if (message.resourceSelector !== undefined) {
      IamPolicyAnalysisQuery_ResourceSelector.encode(message.resourceSelector, writer.uint32(18).fork()).join();
    }
    if (message.identitySelector !== undefined) {
      IamPolicyAnalysisQuery_IdentitySelector.encode(message.identitySelector, writer.uint32(26).fork()).join();
    }
    if (message.accessSelector !== undefined) {
      IamPolicyAnalysisQuery_AccessSelector.encode(message.accessSelector, writer.uint32(34).fork()).join();
    }
    if (message.options !== undefined) {
      IamPolicyAnalysisQuery_Options.encode(message.options, writer.uint32(42).fork()).join();
    }
    if (message.conditionContext !== undefined) {
      IamPolicyAnalysisQuery_ConditionContext.encode(message.conditionContext, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisQuery {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisQuery();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resourceSelector = IamPolicyAnalysisQuery_ResourceSelector.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.identitySelector = IamPolicyAnalysisQuery_IdentitySelector.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.accessSelector = IamPolicyAnalysisQuery_AccessSelector.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.options = IamPolicyAnalysisQuery_Options.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.conditionContext = IamPolicyAnalysisQuery_ConditionContext.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisQuery {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      resourceSelector: isSet(object.resourceSelector)
        ? IamPolicyAnalysisQuery_ResourceSelector.fromJSON(object.resourceSelector)
        : undefined,
      identitySelector: isSet(object.identitySelector)
        ? IamPolicyAnalysisQuery_IdentitySelector.fromJSON(object.identitySelector)
        : undefined,
      accessSelector: isSet(object.accessSelector)
        ? IamPolicyAnalysisQuery_AccessSelector.fromJSON(object.accessSelector)
        : undefined,
      options: isSet(object.options) ? IamPolicyAnalysisQuery_Options.fromJSON(object.options) : undefined,
      conditionContext: isSet(object.conditionContext)
        ? IamPolicyAnalysisQuery_ConditionContext.fromJSON(object.conditionContext)
        : undefined,
    };
  },

  toJSON(message: IamPolicyAnalysisQuery): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.resourceSelector !== undefined) {
      obj.resourceSelector = IamPolicyAnalysisQuery_ResourceSelector.toJSON(message.resourceSelector);
    }
    if (message.identitySelector !== undefined) {
      obj.identitySelector = IamPolicyAnalysisQuery_IdentitySelector.toJSON(message.identitySelector);
    }
    if (message.accessSelector !== undefined) {
      obj.accessSelector = IamPolicyAnalysisQuery_AccessSelector.toJSON(message.accessSelector);
    }
    if (message.options !== undefined) {
      obj.options = IamPolicyAnalysisQuery_Options.toJSON(message.options);
    }
    if (message.conditionContext !== undefined) {
      obj.conditionContext = IamPolicyAnalysisQuery_ConditionContext.toJSON(message.conditionContext);
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisQuery>): IamPolicyAnalysisQuery {
    return IamPolicyAnalysisQuery.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisQuery>): IamPolicyAnalysisQuery {
    const message = createBaseIamPolicyAnalysisQuery();
    message.scope = object.scope ?? "";
    message.resourceSelector = (object.resourceSelector !== undefined && object.resourceSelector !== null)
      ? IamPolicyAnalysisQuery_ResourceSelector.fromPartial(object.resourceSelector)
      : undefined;
    message.identitySelector = (object.identitySelector !== undefined && object.identitySelector !== null)
      ? IamPolicyAnalysisQuery_IdentitySelector.fromPartial(object.identitySelector)
      : undefined;
    message.accessSelector = (object.accessSelector !== undefined && object.accessSelector !== null)
      ? IamPolicyAnalysisQuery_AccessSelector.fromPartial(object.accessSelector)
      : undefined;
    message.options = (object.options !== undefined && object.options !== null)
      ? IamPolicyAnalysisQuery_Options.fromPartial(object.options)
      : undefined;
    message.conditionContext = (object.conditionContext !== undefined && object.conditionContext !== null)
      ? IamPolicyAnalysisQuery_ConditionContext.fromPartial(object.conditionContext)
      : undefined;
    return message;
  },
};

function createBaseIamPolicyAnalysisQuery_ResourceSelector(): IamPolicyAnalysisQuery_ResourceSelector {
  return { fullResourceName: "" };
}

export const IamPolicyAnalysisQuery_ResourceSelector: MessageFns<IamPolicyAnalysisQuery_ResourceSelector> = {
  encode(message: IamPolicyAnalysisQuery_ResourceSelector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fullResourceName !== "") {
      writer.uint32(10).string(message.fullResourceName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisQuery_ResourceSelector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisQuery_ResourceSelector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fullResourceName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisQuery_ResourceSelector {
    return { fullResourceName: isSet(object.fullResourceName) ? globalThis.String(object.fullResourceName) : "" };
  },

  toJSON(message: IamPolicyAnalysisQuery_ResourceSelector): unknown {
    const obj: any = {};
    if (message.fullResourceName !== "") {
      obj.fullResourceName = message.fullResourceName;
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisQuery_ResourceSelector>): IamPolicyAnalysisQuery_ResourceSelector {
    return IamPolicyAnalysisQuery_ResourceSelector.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisQuery_ResourceSelector>): IamPolicyAnalysisQuery_ResourceSelector {
    const message = createBaseIamPolicyAnalysisQuery_ResourceSelector();
    message.fullResourceName = object.fullResourceName ?? "";
    return message;
  },
};

function createBaseIamPolicyAnalysisQuery_IdentitySelector(): IamPolicyAnalysisQuery_IdentitySelector {
  return { identity: "" };
}

export const IamPolicyAnalysisQuery_IdentitySelector: MessageFns<IamPolicyAnalysisQuery_IdentitySelector> = {
  encode(message: IamPolicyAnalysisQuery_IdentitySelector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.identity !== "") {
      writer.uint32(10).string(message.identity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisQuery_IdentitySelector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisQuery_IdentitySelector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.identity = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisQuery_IdentitySelector {
    return { identity: isSet(object.identity) ? globalThis.String(object.identity) : "" };
  },

  toJSON(message: IamPolicyAnalysisQuery_IdentitySelector): unknown {
    const obj: any = {};
    if (message.identity !== "") {
      obj.identity = message.identity;
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisQuery_IdentitySelector>): IamPolicyAnalysisQuery_IdentitySelector {
    return IamPolicyAnalysisQuery_IdentitySelector.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisQuery_IdentitySelector>): IamPolicyAnalysisQuery_IdentitySelector {
    const message = createBaseIamPolicyAnalysisQuery_IdentitySelector();
    message.identity = object.identity ?? "";
    return message;
  },
};

function createBaseIamPolicyAnalysisQuery_AccessSelector(): IamPolicyAnalysisQuery_AccessSelector {
  return { roles: [], permissions: [] };
}

export const IamPolicyAnalysisQuery_AccessSelector: MessageFns<IamPolicyAnalysisQuery_AccessSelector> = {
  encode(message: IamPolicyAnalysisQuery_AccessSelector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.roles) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.permissions) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisQuery_AccessSelector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisQuery_AccessSelector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.roles.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.permissions.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisQuery_AccessSelector {
    return {
      roles: globalThis.Array.isArray(object?.roles) ? object.roles.map((e: any) => globalThis.String(e)) : [],
      permissions: globalThis.Array.isArray(object?.permissions)
        ? object.permissions.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: IamPolicyAnalysisQuery_AccessSelector): unknown {
    const obj: any = {};
    if (message.roles?.length) {
      obj.roles = message.roles;
    }
    if (message.permissions?.length) {
      obj.permissions = message.permissions;
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisQuery_AccessSelector>): IamPolicyAnalysisQuery_AccessSelector {
    return IamPolicyAnalysisQuery_AccessSelector.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisQuery_AccessSelector>): IamPolicyAnalysisQuery_AccessSelector {
    const message = createBaseIamPolicyAnalysisQuery_AccessSelector();
    message.roles = object.roles?.map((e) => e) || [];
    message.permissions = object.permissions?.map((e) => e) || [];
    return message;
  },
};

function createBaseIamPolicyAnalysisQuery_Options(): IamPolicyAnalysisQuery_Options {
  return {
    expandGroups: false,
    expandRoles: false,
    expandResources: false,
    outputResourceEdges: false,
    outputGroupEdges: false,
    analyzeServiceAccountImpersonation: false,
  };
}

export const IamPolicyAnalysisQuery_Options: MessageFns<IamPolicyAnalysisQuery_Options> = {
  encode(message: IamPolicyAnalysisQuery_Options, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.expandGroups !== false) {
      writer.uint32(8).bool(message.expandGroups);
    }
    if (message.expandRoles !== false) {
      writer.uint32(16).bool(message.expandRoles);
    }
    if (message.expandResources !== false) {
      writer.uint32(24).bool(message.expandResources);
    }
    if (message.outputResourceEdges !== false) {
      writer.uint32(32).bool(message.outputResourceEdges);
    }
    if (message.outputGroupEdges !== false) {
      writer.uint32(40).bool(message.outputGroupEdges);
    }
    if (message.analyzeServiceAccountImpersonation !== false) {
      writer.uint32(48).bool(message.analyzeServiceAccountImpersonation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisQuery_Options {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisQuery_Options();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.expandGroups = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.expandRoles = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.expandResources = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.outputResourceEdges = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.outputGroupEdges = reader.bool();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.analyzeServiceAccountImpersonation = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisQuery_Options {
    return {
      expandGroups: isSet(object.expandGroups) ? globalThis.Boolean(object.expandGroups) : false,
      expandRoles: isSet(object.expandRoles) ? globalThis.Boolean(object.expandRoles) : false,
      expandResources: isSet(object.expandResources) ? globalThis.Boolean(object.expandResources) : false,
      outputResourceEdges: isSet(object.outputResourceEdges) ? globalThis.Boolean(object.outputResourceEdges) : false,
      outputGroupEdges: isSet(object.outputGroupEdges) ? globalThis.Boolean(object.outputGroupEdges) : false,
      analyzeServiceAccountImpersonation: isSet(object.analyzeServiceAccountImpersonation)
        ? globalThis.Boolean(object.analyzeServiceAccountImpersonation)
        : false,
    };
  },

  toJSON(message: IamPolicyAnalysisQuery_Options): unknown {
    const obj: any = {};
    if (message.expandGroups !== false) {
      obj.expandGroups = message.expandGroups;
    }
    if (message.expandRoles !== false) {
      obj.expandRoles = message.expandRoles;
    }
    if (message.expandResources !== false) {
      obj.expandResources = message.expandResources;
    }
    if (message.outputResourceEdges !== false) {
      obj.outputResourceEdges = message.outputResourceEdges;
    }
    if (message.outputGroupEdges !== false) {
      obj.outputGroupEdges = message.outputGroupEdges;
    }
    if (message.analyzeServiceAccountImpersonation !== false) {
      obj.analyzeServiceAccountImpersonation = message.analyzeServiceAccountImpersonation;
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisQuery_Options>): IamPolicyAnalysisQuery_Options {
    return IamPolicyAnalysisQuery_Options.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisQuery_Options>): IamPolicyAnalysisQuery_Options {
    const message = createBaseIamPolicyAnalysisQuery_Options();
    message.expandGroups = object.expandGroups ?? false;
    message.expandRoles = object.expandRoles ?? false;
    message.expandResources = object.expandResources ?? false;
    message.outputResourceEdges = object.outputResourceEdges ?? false;
    message.outputGroupEdges = object.outputGroupEdges ?? false;
    message.analyzeServiceAccountImpersonation = object.analyzeServiceAccountImpersonation ?? false;
    return message;
  },
};

function createBaseIamPolicyAnalysisQuery_ConditionContext(): IamPolicyAnalysisQuery_ConditionContext {
  return { accessTime: undefined };
}

export const IamPolicyAnalysisQuery_ConditionContext: MessageFns<IamPolicyAnalysisQuery_ConditionContext> = {
  encode(message: IamPolicyAnalysisQuery_ConditionContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accessTime !== undefined) {
      Timestamp.encode(toTimestamp(message.accessTime), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisQuery_ConditionContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisQuery_ConditionContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.accessTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisQuery_ConditionContext {
    return { accessTime: isSet(object.accessTime) ? fromJsonTimestamp(object.accessTime) : undefined };
  },

  toJSON(message: IamPolicyAnalysisQuery_ConditionContext): unknown {
    const obj: any = {};
    if (message.accessTime !== undefined) {
      obj.accessTime = message.accessTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisQuery_ConditionContext>): IamPolicyAnalysisQuery_ConditionContext {
    return IamPolicyAnalysisQuery_ConditionContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisQuery_ConditionContext>): IamPolicyAnalysisQuery_ConditionContext {
    const message = createBaseIamPolicyAnalysisQuery_ConditionContext();
    message.accessTime = object.accessTime ?? undefined;
    return message;
  },
};

function createBaseAnalyzeIamPolicyRequest(): AnalyzeIamPolicyRequest {
  return { analysisQuery: undefined, savedAnalysisQuery: "", executionTimeout: undefined };
}

export const AnalyzeIamPolicyRequest: MessageFns<AnalyzeIamPolicyRequest> = {
  encode(message: AnalyzeIamPolicyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.analysisQuery !== undefined) {
      IamPolicyAnalysisQuery.encode(message.analysisQuery, writer.uint32(10).fork()).join();
    }
    if (message.savedAnalysisQuery !== "") {
      writer.uint32(26).string(message.savedAnalysisQuery);
    }
    if (message.executionTimeout !== undefined) {
      Duration.encode(message.executionTimeout, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIamPolicyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIamPolicyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.analysisQuery = IamPolicyAnalysisQuery.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.savedAnalysisQuery = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.executionTimeout = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIamPolicyRequest {
    return {
      analysisQuery: isSet(object.analysisQuery) ? IamPolicyAnalysisQuery.fromJSON(object.analysisQuery) : undefined,
      savedAnalysisQuery: isSet(object.savedAnalysisQuery) ? globalThis.String(object.savedAnalysisQuery) : "",
      executionTimeout: isSet(object.executionTimeout) ? Duration.fromJSON(object.executionTimeout) : undefined,
    };
  },

  toJSON(message: AnalyzeIamPolicyRequest): unknown {
    const obj: any = {};
    if (message.analysisQuery !== undefined) {
      obj.analysisQuery = IamPolicyAnalysisQuery.toJSON(message.analysisQuery);
    }
    if (message.savedAnalysisQuery !== "") {
      obj.savedAnalysisQuery = message.savedAnalysisQuery;
    }
    if (message.executionTimeout !== undefined) {
      obj.executionTimeout = Duration.toJSON(message.executionTimeout);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeIamPolicyRequest>): AnalyzeIamPolicyRequest {
    return AnalyzeIamPolicyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeIamPolicyRequest>): AnalyzeIamPolicyRequest {
    const message = createBaseAnalyzeIamPolicyRequest();
    message.analysisQuery = (object.analysisQuery !== undefined && object.analysisQuery !== null)
      ? IamPolicyAnalysisQuery.fromPartial(object.analysisQuery)
      : undefined;
    message.savedAnalysisQuery = object.savedAnalysisQuery ?? "";
    message.executionTimeout = (object.executionTimeout !== undefined && object.executionTimeout !== null)
      ? Duration.fromPartial(object.executionTimeout)
      : undefined;
    return message;
  },
};

function createBaseAnalyzeIamPolicyResponse(): AnalyzeIamPolicyResponse {
  return { mainAnalysis: undefined, serviceAccountImpersonationAnalysis: [], fullyExplored: false };
}

export const AnalyzeIamPolicyResponse: MessageFns<AnalyzeIamPolicyResponse> = {
  encode(message: AnalyzeIamPolicyResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mainAnalysis !== undefined) {
      AnalyzeIamPolicyResponse_IamPolicyAnalysis.encode(message.mainAnalysis, writer.uint32(10).fork()).join();
    }
    for (const v of message.serviceAccountImpersonationAnalysis) {
      AnalyzeIamPolicyResponse_IamPolicyAnalysis.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.fullyExplored !== false) {
      writer.uint32(24).bool(message.fullyExplored);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIamPolicyResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIamPolicyResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.mainAnalysis = AnalyzeIamPolicyResponse_IamPolicyAnalysis.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.serviceAccountImpersonationAnalysis.push(
            AnalyzeIamPolicyResponse_IamPolicyAnalysis.decode(reader, reader.uint32()),
          );
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.fullyExplored = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIamPolicyResponse {
    return {
      mainAnalysis: isSet(object.mainAnalysis)
        ? AnalyzeIamPolicyResponse_IamPolicyAnalysis.fromJSON(object.mainAnalysis)
        : undefined,
      serviceAccountImpersonationAnalysis: globalThis.Array.isArray(object?.serviceAccountImpersonationAnalysis)
        ? object.serviceAccountImpersonationAnalysis.map((e: any) =>
          AnalyzeIamPolicyResponse_IamPolicyAnalysis.fromJSON(e)
        )
        : [],
      fullyExplored: isSet(object.fullyExplored) ? globalThis.Boolean(object.fullyExplored) : false,
    };
  },

  toJSON(message: AnalyzeIamPolicyResponse): unknown {
    const obj: any = {};
    if (message.mainAnalysis !== undefined) {
      obj.mainAnalysis = AnalyzeIamPolicyResponse_IamPolicyAnalysis.toJSON(message.mainAnalysis);
    }
    if (message.serviceAccountImpersonationAnalysis?.length) {
      obj.serviceAccountImpersonationAnalysis = message.serviceAccountImpersonationAnalysis.map((e) =>
        AnalyzeIamPolicyResponse_IamPolicyAnalysis.toJSON(e)
      );
    }
    if (message.fullyExplored !== false) {
      obj.fullyExplored = message.fullyExplored;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeIamPolicyResponse>): AnalyzeIamPolicyResponse {
    return AnalyzeIamPolicyResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeIamPolicyResponse>): AnalyzeIamPolicyResponse {
    const message = createBaseAnalyzeIamPolicyResponse();
    message.mainAnalysis = (object.mainAnalysis !== undefined && object.mainAnalysis !== null)
      ? AnalyzeIamPolicyResponse_IamPolicyAnalysis.fromPartial(object.mainAnalysis)
      : undefined;
    message.serviceAccountImpersonationAnalysis =
      object.serviceAccountImpersonationAnalysis?.map((e) =>
        AnalyzeIamPolicyResponse_IamPolicyAnalysis.fromPartial(e)
      ) || [];
    message.fullyExplored = object.fullyExplored ?? false;
    return message;
  },
};

function createBaseAnalyzeIamPolicyResponse_IamPolicyAnalysis(): AnalyzeIamPolicyResponse_IamPolicyAnalysis {
  return { analysisQuery: undefined, analysisResults: [], fullyExplored: false, nonCriticalErrors: [] };
}

export const AnalyzeIamPolicyResponse_IamPolicyAnalysis: MessageFns<AnalyzeIamPolicyResponse_IamPolicyAnalysis> = {
  encode(message: AnalyzeIamPolicyResponse_IamPolicyAnalysis, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.analysisQuery !== undefined) {
      IamPolicyAnalysisQuery.encode(message.analysisQuery, writer.uint32(10).fork()).join();
    }
    for (const v of message.analysisResults) {
      IamPolicyAnalysisResult.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.fullyExplored !== false) {
      writer.uint32(24).bool(message.fullyExplored);
    }
    for (const v of message.nonCriticalErrors) {
      IamPolicyAnalysisState.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIamPolicyResponse_IamPolicyAnalysis {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIamPolicyResponse_IamPolicyAnalysis();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.analysisQuery = IamPolicyAnalysisQuery.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.analysisResults.push(IamPolicyAnalysisResult.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.fullyExplored = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.nonCriticalErrors.push(IamPolicyAnalysisState.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIamPolicyResponse_IamPolicyAnalysis {
    return {
      analysisQuery: isSet(object.analysisQuery) ? IamPolicyAnalysisQuery.fromJSON(object.analysisQuery) : undefined,
      analysisResults: globalThis.Array.isArray(object?.analysisResults)
        ? object.analysisResults.map((e: any) => IamPolicyAnalysisResult.fromJSON(e))
        : [],
      fullyExplored: isSet(object.fullyExplored) ? globalThis.Boolean(object.fullyExplored) : false,
      nonCriticalErrors: globalThis.Array.isArray(object?.nonCriticalErrors)
        ? object.nonCriticalErrors.map((e: any) => IamPolicyAnalysisState.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeIamPolicyResponse_IamPolicyAnalysis): unknown {
    const obj: any = {};
    if (message.analysisQuery !== undefined) {
      obj.analysisQuery = IamPolicyAnalysisQuery.toJSON(message.analysisQuery);
    }
    if (message.analysisResults?.length) {
      obj.analysisResults = message.analysisResults.map((e) => IamPolicyAnalysisResult.toJSON(e));
    }
    if (message.fullyExplored !== false) {
      obj.fullyExplored = message.fullyExplored;
    }
    if (message.nonCriticalErrors?.length) {
      obj.nonCriticalErrors = message.nonCriticalErrors.map((e) => IamPolicyAnalysisState.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeIamPolicyResponse_IamPolicyAnalysis>): AnalyzeIamPolicyResponse_IamPolicyAnalysis {
    return AnalyzeIamPolicyResponse_IamPolicyAnalysis.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeIamPolicyResponse_IamPolicyAnalysis>,
  ): AnalyzeIamPolicyResponse_IamPolicyAnalysis {
    const message = createBaseAnalyzeIamPolicyResponse_IamPolicyAnalysis();
    message.analysisQuery = (object.analysisQuery !== undefined && object.analysisQuery !== null)
      ? IamPolicyAnalysisQuery.fromPartial(object.analysisQuery)
      : undefined;
    message.analysisResults = object.analysisResults?.map((e) => IamPolicyAnalysisResult.fromPartial(e)) || [];
    message.fullyExplored = object.fullyExplored ?? false;
    message.nonCriticalErrors = object.nonCriticalErrors?.map((e) => IamPolicyAnalysisState.fromPartial(e)) || [];
    return message;
  },
};

function createBaseIamPolicyAnalysisOutputConfig(): IamPolicyAnalysisOutputConfig {
  return { gcsDestination: undefined, bigqueryDestination: undefined };
}

export const IamPolicyAnalysisOutputConfig: MessageFns<IamPolicyAnalysisOutputConfig> = {
  encode(message: IamPolicyAnalysisOutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsDestination !== undefined) {
      IamPolicyAnalysisOutputConfig_GcsDestination.encode(message.gcsDestination, writer.uint32(10).fork()).join();
    }
    if (message.bigqueryDestination !== undefined) {
      IamPolicyAnalysisOutputConfig_BigQueryDestination.encode(message.bigqueryDestination, writer.uint32(18).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisOutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsDestination = IamPolicyAnalysisOutputConfig_GcsDestination.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bigqueryDestination = IamPolicyAnalysisOutputConfig_BigQueryDestination.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisOutputConfig {
    return {
      gcsDestination: isSet(object.gcsDestination)
        ? IamPolicyAnalysisOutputConfig_GcsDestination.fromJSON(object.gcsDestination)
        : undefined,
      bigqueryDestination: isSet(object.bigqueryDestination)
        ? IamPolicyAnalysisOutputConfig_BigQueryDestination.fromJSON(object.bigqueryDestination)
        : undefined,
    };
  },

  toJSON(message: IamPolicyAnalysisOutputConfig): unknown {
    const obj: any = {};
    if (message.gcsDestination !== undefined) {
      obj.gcsDestination = IamPolicyAnalysisOutputConfig_GcsDestination.toJSON(message.gcsDestination);
    }
    if (message.bigqueryDestination !== undefined) {
      obj.bigqueryDestination = IamPolicyAnalysisOutputConfig_BigQueryDestination.toJSON(message.bigqueryDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<IamPolicyAnalysisOutputConfig>): IamPolicyAnalysisOutputConfig {
    return IamPolicyAnalysisOutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<IamPolicyAnalysisOutputConfig>): IamPolicyAnalysisOutputConfig {
    const message = createBaseIamPolicyAnalysisOutputConfig();
    message.gcsDestination = (object.gcsDestination !== undefined && object.gcsDestination !== null)
      ? IamPolicyAnalysisOutputConfig_GcsDestination.fromPartial(object.gcsDestination)
      : undefined;
    message.bigqueryDestination = (object.bigqueryDestination !== undefined && object.bigqueryDestination !== null)
      ? IamPolicyAnalysisOutputConfig_BigQueryDestination.fromPartial(object.bigqueryDestination)
      : undefined;
    return message;
  },
};

function createBaseIamPolicyAnalysisOutputConfig_GcsDestination(): IamPolicyAnalysisOutputConfig_GcsDestination {
  return { uri: "" };
}

export const IamPolicyAnalysisOutputConfig_GcsDestination: MessageFns<IamPolicyAnalysisOutputConfig_GcsDestination> = {
  encode(
    message: IamPolicyAnalysisOutputConfig_GcsDestination,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisOutputConfig_GcsDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisOutputConfig_GcsDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisOutputConfig_GcsDestination {
    return { uri: isSet(object.uri) ? globalThis.String(object.uri) : "" };
  },

  toJSON(message: IamPolicyAnalysisOutputConfig_GcsDestination): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(
    base?: DeepPartial<IamPolicyAnalysisOutputConfig_GcsDestination>,
  ): IamPolicyAnalysisOutputConfig_GcsDestination {
    return IamPolicyAnalysisOutputConfig_GcsDestination.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<IamPolicyAnalysisOutputConfig_GcsDestination>,
  ): IamPolicyAnalysisOutputConfig_GcsDestination {
    const message = createBaseIamPolicyAnalysisOutputConfig_GcsDestination();
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseIamPolicyAnalysisOutputConfig_BigQueryDestination(): IamPolicyAnalysisOutputConfig_BigQueryDestination {
  return { dataset: "", tablePrefix: "", partitionKey: 0, writeDisposition: "" };
}

export const IamPolicyAnalysisOutputConfig_BigQueryDestination: MessageFns<
  IamPolicyAnalysisOutputConfig_BigQueryDestination
> = {
  encode(
    message: IamPolicyAnalysisOutputConfig_BigQueryDestination,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.dataset !== "") {
      writer.uint32(10).string(message.dataset);
    }
    if (message.tablePrefix !== "") {
      writer.uint32(18).string(message.tablePrefix);
    }
    if (message.partitionKey !== 0) {
      writer.uint32(24).int32(message.partitionKey);
    }
    if (message.writeDisposition !== "") {
      writer.uint32(34).string(message.writeDisposition);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IamPolicyAnalysisOutputConfig_BigQueryDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIamPolicyAnalysisOutputConfig_BigQueryDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataset = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tablePrefix = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.partitionKey = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.writeDisposition = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IamPolicyAnalysisOutputConfig_BigQueryDestination {
    return {
      dataset: isSet(object.dataset) ? globalThis.String(object.dataset) : "",
      tablePrefix: isSet(object.tablePrefix) ? globalThis.String(object.tablePrefix) : "",
      partitionKey: isSet(object.partitionKey)
        ? iamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKeyFromJSON(object.partitionKey)
        : 0,
      writeDisposition: isSet(object.writeDisposition) ? globalThis.String(object.writeDisposition) : "",
    };
  },

  toJSON(message: IamPolicyAnalysisOutputConfig_BigQueryDestination): unknown {
    const obj: any = {};
    if (message.dataset !== "") {
      obj.dataset = message.dataset;
    }
    if (message.tablePrefix !== "") {
      obj.tablePrefix = message.tablePrefix;
    }
    if (message.partitionKey !== 0) {
      obj.partitionKey = iamPolicyAnalysisOutputConfig_BigQueryDestination_PartitionKeyToJSON(message.partitionKey);
    }
    if (message.writeDisposition !== "") {
      obj.writeDisposition = message.writeDisposition;
    }
    return obj;
  },

  create(
    base?: DeepPartial<IamPolicyAnalysisOutputConfig_BigQueryDestination>,
  ): IamPolicyAnalysisOutputConfig_BigQueryDestination {
    return IamPolicyAnalysisOutputConfig_BigQueryDestination.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<IamPolicyAnalysisOutputConfig_BigQueryDestination>,
  ): IamPolicyAnalysisOutputConfig_BigQueryDestination {
    const message = createBaseIamPolicyAnalysisOutputConfig_BigQueryDestination();
    message.dataset = object.dataset ?? "";
    message.tablePrefix = object.tablePrefix ?? "";
    message.partitionKey = object.partitionKey ?? 0;
    message.writeDisposition = object.writeDisposition ?? "";
    return message;
  },
};

function createBaseAnalyzeIamPolicyLongrunningRequest(): AnalyzeIamPolicyLongrunningRequest {
  return { analysisQuery: undefined, savedAnalysisQuery: "", outputConfig: undefined };
}

export const AnalyzeIamPolicyLongrunningRequest: MessageFns<AnalyzeIamPolicyLongrunningRequest> = {
  encode(message: AnalyzeIamPolicyLongrunningRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.analysisQuery !== undefined) {
      IamPolicyAnalysisQuery.encode(message.analysisQuery, writer.uint32(10).fork()).join();
    }
    if (message.savedAnalysisQuery !== "") {
      writer.uint32(26).string(message.savedAnalysisQuery);
    }
    if (message.outputConfig !== undefined) {
      IamPolicyAnalysisOutputConfig.encode(message.outputConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIamPolicyLongrunningRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIamPolicyLongrunningRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.analysisQuery = IamPolicyAnalysisQuery.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.savedAnalysisQuery = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.outputConfig = IamPolicyAnalysisOutputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIamPolicyLongrunningRequest {
    return {
      analysisQuery: isSet(object.analysisQuery) ? IamPolicyAnalysisQuery.fromJSON(object.analysisQuery) : undefined,
      savedAnalysisQuery: isSet(object.savedAnalysisQuery) ? globalThis.String(object.savedAnalysisQuery) : "",
      outputConfig: isSet(object.outputConfig)
        ? IamPolicyAnalysisOutputConfig.fromJSON(object.outputConfig)
        : undefined,
    };
  },

  toJSON(message: AnalyzeIamPolicyLongrunningRequest): unknown {
    const obj: any = {};
    if (message.analysisQuery !== undefined) {
      obj.analysisQuery = IamPolicyAnalysisQuery.toJSON(message.analysisQuery);
    }
    if (message.savedAnalysisQuery !== "") {
      obj.savedAnalysisQuery = message.savedAnalysisQuery;
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = IamPolicyAnalysisOutputConfig.toJSON(message.outputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeIamPolicyLongrunningRequest>): AnalyzeIamPolicyLongrunningRequest {
    return AnalyzeIamPolicyLongrunningRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeIamPolicyLongrunningRequest>): AnalyzeIamPolicyLongrunningRequest {
    const message = createBaseAnalyzeIamPolicyLongrunningRequest();
    message.analysisQuery = (object.analysisQuery !== undefined && object.analysisQuery !== null)
      ? IamPolicyAnalysisQuery.fromPartial(object.analysisQuery)
      : undefined;
    message.savedAnalysisQuery = object.savedAnalysisQuery ?? "";
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? IamPolicyAnalysisOutputConfig.fromPartial(object.outputConfig)
      : undefined;
    return message;
  },
};

function createBaseAnalyzeIamPolicyLongrunningResponse(): AnalyzeIamPolicyLongrunningResponse {
  return {};
}

export const AnalyzeIamPolicyLongrunningResponse: MessageFns<AnalyzeIamPolicyLongrunningResponse> = {
  encode(_: AnalyzeIamPolicyLongrunningResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIamPolicyLongrunningResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIamPolicyLongrunningResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AnalyzeIamPolicyLongrunningResponse {
    return {};
  },

  toJSON(_: AnalyzeIamPolicyLongrunningResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AnalyzeIamPolicyLongrunningResponse>): AnalyzeIamPolicyLongrunningResponse {
    return AnalyzeIamPolicyLongrunningResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AnalyzeIamPolicyLongrunningResponse>): AnalyzeIamPolicyLongrunningResponse {
    const message = createBaseAnalyzeIamPolicyLongrunningResponse();
    return message;
  },
};

function createBaseSavedQuery(): SavedQuery {
  return {
    name: "",
    description: "",
    createTime: undefined,
    creator: "",
    lastUpdateTime: undefined,
    lastUpdater: "",
    labels: {},
    content: undefined,
  };
}

export const SavedQuery: MessageFns<SavedQuery> = {
  encode(message: SavedQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.creator !== "") {
      writer.uint32(34).string(message.creator);
    }
    if (message.lastUpdateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastUpdateTime), writer.uint32(42).fork()).join();
    }
    if (message.lastUpdater !== "") {
      writer.uint32(50).string(message.lastUpdater);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      SavedQuery_LabelsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    if (message.content !== undefined) {
      SavedQuery_QueryContent.encode(message.content, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SavedQuery {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSavedQuery();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.creator = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.lastUpdateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.lastUpdater = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = SavedQuery_LabelsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.labels[entry7.key] = entry7.value;
          }
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.content = SavedQuery_QueryContent.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SavedQuery {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      creator: isSet(object.creator) ? globalThis.String(object.creator) : "",
      lastUpdateTime: isSet(object.lastUpdateTime) ? fromJsonTimestamp(object.lastUpdateTime) : undefined,
      lastUpdater: isSet(object.lastUpdater) ? globalThis.String(object.lastUpdater) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      content: isSet(object.content) ? SavedQuery_QueryContent.fromJSON(object.content) : undefined,
    };
  },

  toJSON(message: SavedQuery): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.creator !== "") {
      obj.creator = message.creator;
    }
    if (message.lastUpdateTime !== undefined) {
      obj.lastUpdateTime = message.lastUpdateTime.toISOString();
    }
    if (message.lastUpdater !== "") {
      obj.lastUpdater = message.lastUpdater;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.content !== undefined) {
      obj.content = SavedQuery_QueryContent.toJSON(message.content);
    }
    return obj;
  },

  create(base?: DeepPartial<SavedQuery>): SavedQuery {
    return SavedQuery.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SavedQuery>): SavedQuery {
    const message = createBaseSavedQuery();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.creator = object.creator ?? "";
    message.lastUpdateTime = object.lastUpdateTime ?? undefined;
    message.lastUpdater = object.lastUpdater ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.content = (object.content !== undefined && object.content !== null)
      ? SavedQuery_QueryContent.fromPartial(object.content)
      : undefined;
    return message;
  },
};

function createBaseSavedQuery_QueryContent(): SavedQuery_QueryContent {
  return { iamPolicyAnalysisQuery: undefined };
}

export const SavedQuery_QueryContent: MessageFns<SavedQuery_QueryContent> = {
  encode(message: SavedQuery_QueryContent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.iamPolicyAnalysisQuery !== undefined) {
      IamPolicyAnalysisQuery.encode(message.iamPolicyAnalysisQuery, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SavedQuery_QueryContent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSavedQuery_QueryContent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.iamPolicyAnalysisQuery = IamPolicyAnalysisQuery.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SavedQuery_QueryContent {
    return {
      iamPolicyAnalysisQuery: isSet(object.iamPolicyAnalysisQuery)
        ? IamPolicyAnalysisQuery.fromJSON(object.iamPolicyAnalysisQuery)
        : undefined,
    };
  },

  toJSON(message: SavedQuery_QueryContent): unknown {
    const obj: any = {};
    if (message.iamPolicyAnalysisQuery !== undefined) {
      obj.iamPolicyAnalysisQuery = IamPolicyAnalysisQuery.toJSON(message.iamPolicyAnalysisQuery);
    }
    return obj;
  },

  create(base?: DeepPartial<SavedQuery_QueryContent>): SavedQuery_QueryContent {
    return SavedQuery_QueryContent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SavedQuery_QueryContent>): SavedQuery_QueryContent {
    const message = createBaseSavedQuery_QueryContent();
    message.iamPolicyAnalysisQuery =
      (object.iamPolicyAnalysisQuery !== undefined && object.iamPolicyAnalysisQuery !== null)
        ? IamPolicyAnalysisQuery.fromPartial(object.iamPolicyAnalysisQuery)
        : undefined;
    return message;
  },
};

function createBaseSavedQuery_LabelsEntry(): SavedQuery_LabelsEntry {
  return { key: "", value: "" };
}

export const SavedQuery_LabelsEntry: MessageFns<SavedQuery_LabelsEntry> = {
  encode(message: SavedQuery_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SavedQuery_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSavedQuery_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SavedQuery_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: SavedQuery_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<SavedQuery_LabelsEntry>): SavedQuery_LabelsEntry {
    return SavedQuery_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SavedQuery_LabelsEntry>): SavedQuery_LabelsEntry {
    const message = createBaseSavedQuery_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCreateSavedQueryRequest(): CreateSavedQueryRequest {
  return { parent: "", savedQuery: undefined, savedQueryId: "" };
}

export const CreateSavedQueryRequest: MessageFns<CreateSavedQueryRequest> = {
  encode(message: CreateSavedQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.savedQuery !== undefined) {
      SavedQuery.encode(message.savedQuery, writer.uint32(18).fork()).join();
    }
    if (message.savedQueryId !== "") {
      writer.uint32(26).string(message.savedQueryId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateSavedQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateSavedQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.savedQuery = SavedQuery.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.savedQueryId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateSavedQueryRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      savedQuery: isSet(object.savedQuery) ? SavedQuery.fromJSON(object.savedQuery) : undefined,
      savedQueryId: isSet(object.savedQueryId) ? globalThis.String(object.savedQueryId) : "",
    };
  },

  toJSON(message: CreateSavedQueryRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.savedQuery !== undefined) {
      obj.savedQuery = SavedQuery.toJSON(message.savedQuery);
    }
    if (message.savedQueryId !== "") {
      obj.savedQueryId = message.savedQueryId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateSavedQueryRequest>): CreateSavedQueryRequest {
    return CreateSavedQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateSavedQueryRequest>): CreateSavedQueryRequest {
    const message = createBaseCreateSavedQueryRequest();
    message.parent = object.parent ?? "";
    message.savedQuery = (object.savedQuery !== undefined && object.savedQuery !== null)
      ? SavedQuery.fromPartial(object.savedQuery)
      : undefined;
    message.savedQueryId = object.savedQueryId ?? "";
    return message;
  },
};

function createBaseGetSavedQueryRequest(): GetSavedQueryRequest {
  return { name: "" };
}

export const GetSavedQueryRequest: MessageFns<GetSavedQueryRequest> = {
  encode(message: GetSavedQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetSavedQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetSavedQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetSavedQueryRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetSavedQueryRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetSavedQueryRequest>): GetSavedQueryRequest {
    return GetSavedQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetSavedQueryRequest>): GetSavedQueryRequest {
    const message = createBaseGetSavedQueryRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListSavedQueriesRequest(): ListSavedQueriesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "" };
}

export const ListSavedQueriesRequest: MessageFns<ListSavedQueriesRequest> = {
  encode(message: ListSavedQueriesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSavedQueriesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSavedQueriesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSavedQueriesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListSavedQueriesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSavedQueriesRequest>): ListSavedQueriesRequest {
    return ListSavedQueriesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSavedQueriesRequest>): ListSavedQueriesRequest {
    const message = createBaseListSavedQueriesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListSavedQueriesResponse(): ListSavedQueriesResponse {
  return { savedQueries: [], nextPageToken: "" };
}

export const ListSavedQueriesResponse: MessageFns<ListSavedQueriesResponse> = {
  encode(message: ListSavedQueriesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.savedQueries) {
      SavedQuery.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSavedQueriesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSavedQueriesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.savedQueries.push(SavedQuery.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSavedQueriesResponse {
    return {
      savedQueries: globalThis.Array.isArray(object?.savedQueries)
        ? object.savedQueries.map((e: any) => SavedQuery.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListSavedQueriesResponse): unknown {
    const obj: any = {};
    if (message.savedQueries?.length) {
      obj.savedQueries = message.savedQueries.map((e) => SavedQuery.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSavedQueriesResponse>): ListSavedQueriesResponse {
    return ListSavedQueriesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSavedQueriesResponse>): ListSavedQueriesResponse {
    const message = createBaseListSavedQueriesResponse();
    message.savedQueries = object.savedQueries?.map((e) => SavedQuery.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateSavedQueryRequest(): UpdateSavedQueryRequest {
  return { savedQuery: undefined, updateMask: undefined };
}

export const UpdateSavedQueryRequest: MessageFns<UpdateSavedQueryRequest> = {
  encode(message: UpdateSavedQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.savedQuery !== undefined) {
      SavedQuery.encode(message.savedQuery, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateSavedQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateSavedQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.savedQuery = SavedQuery.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateSavedQueryRequest {
    return {
      savedQuery: isSet(object.savedQuery) ? SavedQuery.fromJSON(object.savedQuery) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateSavedQueryRequest): unknown {
    const obj: any = {};
    if (message.savedQuery !== undefined) {
      obj.savedQuery = SavedQuery.toJSON(message.savedQuery);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateSavedQueryRequest>): UpdateSavedQueryRequest {
    return UpdateSavedQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateSavedQueryRequest>): UpdateSavedQueryRequest {
    const message = createBaseUpdateSavedQueryRequest();
    message.savedQuery = (object.savedQuery !== undefined && object.savedQuery !== null)
      ? SavedQuery.fromPartial(object.savedQuery)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteSavedQueryRequest(): DeleteSavedQueryRequest {
  return { name: "" };
}

export const DeleteSavedQueryRequest: MessageFns<DeleteSavedQueryRequest> = {
  encode(message: DeleteSavedQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteSavedQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteSavedQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteSavedQueryRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteSavedQueryRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteSavedQueryRequest>): DeleteSavedQueryRequest {
    return DeleteSavedQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteSavedQueryRequest>): DeleteSavedQueryRequest {
    const message = createBaseDeleteSavedQueryRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseAnalyzeMoveRequest(): AnalyzeMoveRequest {
  return { resource: "", destinationParent: "", view: 0 };
}

export const AnalyzeMoveRequest: MessageFns<AnalyzeMoveRequest> = {
  encode(message: AnalyzeMoveRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== "") {
      writer.uint32(10).string(message.resource);
    }
    if (message.destinationParent !== "") {
      writer.uint32(18).string(message.destinationParent);
    }
    if (message.view !== 0) {
      writer.uint32(24).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeMoveRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeMoveRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.destinationParent = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeMoveRequest {
    return {
      resource: isSet(object.resource) ? globalThis.String(object.resource) : "",
      destinationParent: isSet(object.destinationParent) ? globalThis.String(object.destinationParent) : "",
      view: isSet(object.view) ? analyzeMoveRequest_AnalysisViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: AnalyzeMoveRequest): unknown {
    const obj: any = {};
    if (message.resource !== "") {
      obj.resource = message.resource;
    }
    if (message.destinationParent !== "") {
      obj.destinationParent = message.destinationParent;
    }
    if (message.view !== 0) {
      obj.view = analyzeMoveRequest_AnalysisViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeMoveRequest>): AnalyzeMoveRequest {
    return AnalyzeMoveRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeMoveRequest>): AnalyzeMoveRequest {
    const message = createBaseAnalyzeMoveRequest();
    message.resource = object.resource ?? "";
    message.destinationParent = object.destinationParent ?? "";
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseAnalyzeMoveResponse(): AnalyzeMoveResponse {
  return { moveAnalysis: [] };
}

export const AnalyzeMoveResponse: MessageFns<AnalyzeMoveResponse> = {
  encode(message: AnalyzeMoveResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.moveAnalysis) {
      MoveAnalysis.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeMoveResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeMoveResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.moveAnalysis.push(MoveAnalysis.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeMoveResponse {
    return {
      moveAnalysis: globalThis.Array.isArray(object?.moveAnalysis)
        ? object.moveAnalysis.map((e: any) => MoveAnalysis.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeMoveResponse): unknown {
    const obj: any = {};
    if (message.moveAnalysis?.length) {
      obj.moveAnalysis = message.moveAnalysis.map((e) => MoveAnalysis.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeMoveResponse>): AnalyzeMoveResponse {
    return AnalyzeMoveResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeMoveResponse>): AnalyzeMoveResponse {
    const message = createBaseAnalyzeMoveResponse();
    message.moveAnalysis = object.moveAnalysis?.map((e) => MoveAnalysis.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMoveAnalysis(): MoveAnalysis {
  return { displayName: "", analysis: undefined, error: undefined };
}

export const MoveAnalysis: MessageFns<MoveAnalysis> = {
  encode(message: MoveAnalysis, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.displayName !== "") {
      writer.uint32(10).string(message.displayName);
    }
    if (message.analysis !== undefined) {
      MoveAnalysisResult.encode(message.analysis, writer.uint32(18).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveAnalysis {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveAnalysis();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.analysis = MoveAnalysisResult.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MoveAnalysis {
    return {
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      analysis: isSet(object.analysis) ? MoveAnalysisResult.fromJSON(object.analysis) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
    };
  },

  toJSON(message: MoveAnalysis): unknown {
    const obj: any = {};
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.analysis !== undefined) {
      obj.analysis = MoveAnalysisResult.toJSON(message.analysis);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    return obj;
  },

  create(base?: DeepPartial<MoveAnalysis>): MoveAnalysis {
    return MoveAnalysis.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MoveAnalysis>): MoveAnalysis {
    const message = createBaseMoveAnalysis();
    message.displayName = object.displayName ?? "";
    message.analysis = (object.analysis !== undefined && object.analysis !== null)
      ? MoveAnalysisResult.fromPartial(object.analysis)
      : undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    return message;
  },
};

function createBaseMoveAnalysisResult(): MoveAnalysisResult {
  return { blockers: [], warnings: [] };
}

export const MoveAnalysisResult: MessageFns<MoveAnalysisResult> = {
  encode(message: MoveAnalysisResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.blockers) {
      MoveImpact.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.warnings) {
      MoveImpact.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveAnalysisResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveAnalysisResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.blockers.push(MoveImpact.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.warnings.push(MoveImpact.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MoveAnalysisResult {
    return {
      blockers: globalThis.Array.isArray(object?.blockers)
        ? object.blockers.map((e: any) => MoveImpact.fromJSON(e))
        : [],
      warnings: globalThis.Array.isArray(object?.warnings)
        ? object.warnings.map((e: any) => MoveImpact.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MoveAnalysisResult): unknown {
    const obj: any = {};
    if (message.blockers?.length) {
      obj.blockers = message.blockers.map((e) => MoveImpact.toJSON(e));
    }
    if (message.warnings?.length) {
      obj.warnings = message.warnings.map((e) => MoveImpact.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MoveAnalysisResult>): MoveAnalysisResult {
    return MoveAnalysisResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MoveAnalysisResult>): MoveAnalysisResult {
    const message = createBaseMoveAnalysisResult();
    message.blockers = object.blockers?.map((e) => MoveImpact.fromPartial(e)) || [];
    message.warnings = object.warnings?.map((e) => MoveImpact.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMoveImpact(): MoveImpact {
  return { detail: "" };
}

export const MoveImpact: MessageFns<MoveImpact> = {
  encode(message: MoveImpact, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.detail !== "") {
      writer.uint32(10).string(message.detail);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveImpact {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveImpact();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.detail = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MoveImpact {
    return { detail: isSet(object.detail) ? globalThis.String(object.detail) : "" };
  },

  toJSON(message: MoveImpact): unknown {
    const obj: any = {};
    if (message.detail !== "") {
      obj.detail = message.detail;
    }
    return obj;
  },

  create(base?: DeepPartial<MoveImpact>): MoveImpact {
    return MoveImpact.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MoveImpact>): MoveImpact {
    const message = createBaseMoveImpact();
    message.detail = object.detail ?? "";
    return message;
  },
};

function createBaseQueryAssetsOutputConfig(): QueryAssetsOutputConfig {
  return { bigqueryDestination: undefined };
}

export const QueryAssetsOutputConfig: MessageFns<QueryAssetsOutputConfig> = {
  encode(message: QueryAssetsOutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bigqueryDestination !== undefined) {
      QueryAssetsOutputConfig_BigQueryDestination.encode(message.bigqueryDestination, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryAssetsOutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryAssetsOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bigqueryDestination = QueryAssetsOutputConfig_BigQueryDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryAssetsOutputConfig {
    return {
      bigqueryDestination: isSet(object.bigqueryDestination)
        ? QueryAssetsOutputConfig_BigQueryDestination.fromJSON(object.bigqueryDestination)
        : undefined,
    };
  },

  toJSON(message: QueryAssetsOutputConfig): unknown {
    const obj: any = {};
    if (message.bigqueryDestination !== undefined) {
      obj.bigqueryDestination = QueryAssetsOutputConfig_BigQueryDestination.toJSON(message.bigqueryDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryAssetsOutputConfig>): QueryAssetsOutputConfig {
    return QueryAssetsOutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryAssetsOutputConfig>): QueryAssetsOutputConfig {
    const message = createBaseQueryAssetsOutputConfig();
    message.bigqueryDestination = (object.bigqueryDestination !== undefined && object.bigqueryDestination !== null)
      ? QueryAssetsOutputConfig_BigQueryDestination.fromPartial(object.bigqueryDestination)
      : undefined;
    return message;
  },
};

function createBaseQueryAssetsOutputConfig_BigQueryDestination(): QueryAssetsOutputConfig_BigQueryDestination {
  return { dataset: "", table: "", writeDisposition: "" };
}

export const QueryAssetsOutputConfig_BigQueryDestination: MessageFns<QueryAssetsOutputConfig_BigQueryDestination> = {
  encode(
    message: QueryAssetsOutputConfig_BigQueryDestination,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.dataset !== "") {
      writer.uint32(10).string(message.dataset);
    }
    if (message.table !== "") {
      writer.uint32(18).string(message.table);
    }
    if (message.writeDisposition !== "") {
      writer.uint32(26).string(message.writeDisposition);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryAssetsOutputConfig_BigQueryDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryAssetsOutputConfig_BigQueryDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataset = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.table = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.writeDisposition = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryAssetsOutputConfig_BigQueryDestination {
    return {
      dataset: isSet(object.dataset) ? globalThis.String(object.dataset) : "",
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      writeDisposition: isSet(object.writeDisposition) ? globalThis.String(object.writeDisposition) : "",
    };
  },

  toJSON(message: QueryAssetsOutputConfig_BigQueryDestination): unknown {
    const obj: any = {};
    if (message.dataset !== "") {
      obj.dataset = message.dataset;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.writeDisposition !== "") {
      obj.writeDisposition = message.writeDisposition;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryAssetsOutputConfig_BigQueryDestination>): QueryAssetsOutputConfig_BigQueryDestination {
    return QueryAssetsOutputConfig_BigQueryDestination.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<QueryAssetsOutputConfig_BigQueryDestination>,
  ): QueryAssetsOutputConfig_BigQueryDestination {
    const message = createBaseQueryAssetsOutputConfig_BigQueryDestination();
    message.dataset = object.dataset ?? "";
    message.table = object.table ?? "";
    message.writeDisposition = object.writeDisposition ?? "";
    return message;
  },
};

function createBaseQueryAssetsRequest(): QueryAssetsRequest {
  return {
    parent: "",
    statement: undefined,
    jobReference: undefined,
    pageSize: 0,
    pageToken: "",
    timeout: undefined,
    readTimeWindow: undefined,
    readTime: undefined,
    outputConfig: undefined,
  };
}

export const QueryAssetsRequest: MessageFns<QueryAssetsRequest> = {
  encode(message: QueryAssetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.statement !== undefined) {
      writer.uint32(18).string(message.statement);
    }
    if (message.jobReference !== undefined) {
      writer.uint32(26).string(message.jobReference);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(50).fork()).join();
    }
    if (message.readTimeWindow !== undefined) {
      TimeWindow.encode(message.readTimeWindow, writer.uint32(58).fork()).join();
    }
    if (message.readTime !== undefined) {
      Timestamp.encode(toTimestamp(message.readTime), writer.uint32(66).fork()).join();
    }
    if (message.outputConfig !== undefined) {
      QueryAssetsOutputConfig.encode(message.outputConfig, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryAssetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryAssetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.statement = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.jobReference = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.readTimeWindow = TimeWindow.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.readTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.outputConfig = QueryAssetsOutputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryAssetsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      statement: isSet(object.statement) ? globalThis.String(object.statement) : undefined,
      jobReference: isSet(object.jobReference) ? globalThis.String(object.jobReference) : undefined,
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      readTimeWindow: isSet(object.readTimeWindow) ? TimeWindow.fromJSON(object.readTimeWindow) : undefined,
      readTime: isSet(object.readTime) ? fromJsonTimestamp(object.readTime) : undefined,
      outputConfig: isSet(object.outputConfig) ? QueryAssetsOutputConfig.fromJSON(object.outputConfig) : undefined,
    };
  },

  toJSON(message: QueryAssetsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.statement !== undefined) {
      obj.statement = message.statement;
    }
    if (message.jobReference !== undefined) {
      obj.jobReference = message.jobReference;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.readTimeWindow !== undefined) {
      obj.readTimeWindow = TimeWindow.toJSON(message.readTimeWindow);
    }
    if (message.readTime !== undefined) {
      obj.readTime = message.readTime.toISOString();
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = QueryAssetsOutputConfig.toJSON(message.outputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryAssetsRequest>): QueryAssetsRequest {
    return QueryAssetsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryAssetsRequest>): QueryAssetsRequest {
    const message = createBaseQueryAssetsRequest();
    message.parent = object.parent ?? "";
    message.statement = object.statement ?? undefined;
    message.jobReference = object.jobReference ?? undefined;
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.readTimeWindow = (object.readTimeWindow !== undefined && object.readTimeWindow !== null)
      ? TimeWindow.fromPartial(object.readTimeWindow)
      : undefined;
    message.readTime = object.readTime ?? undefined;
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? QueryAssetsOutputConfig.fromPartial(object.outputConfig)
      : undefined;
    return message;
  },
};

function createBaseQueryAssetsResponse(): QueryAssetsResponse {
  return { jobReference: "", done: false, error: undefined, queryResult: undefined, outputConfig: undefined };
}

export const QueryAssetsResponse: MessageFns<QueryAssetsResponse> = {
  encode(message: QueryAssetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.jobReference !== "") {
      writer.uint32(10).string(message.jobReference);
    }
    if (message.done !== false) {
      writer.uint32(16).bool(message.done);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(26).fork()).join();
    }
    if (message.queryResult !== undefined) {
      QueryResult.encode(message.queryResult, writer.uint32(34).fork()).join();
    }
    if (message.outputConfig !== undefined) {
      QueryAssetsOutputConfig.encode(message.outputConfig, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryAssetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryAssetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobReference = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.done = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.queryResult = QueryResult.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.outputConfig = QueryAssetsOutputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryAssetsResponse {
    return {
      jobReference: isSet(object.jobReference) ? globalThis.String(object.jobReference) : "",
      done: isSet(object.done) ? globalThis.Boolean(object.done) : false,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      queryResult: isSet(object.queryResult) ? QueryResult.fromJSON(object.queryResult) : undefined,
      outputConfig: isSet(object.outputConfig) ? QueryAssetsOutputConfig.fromJSON(object.outputConfig) : undefined,
    };
  },

  toJSON(message: QueryAssetsResponse): unknown {
    const obj: any = {};
    if (message.jobReference !== "") {
      obj.jobReference = message.jobReference;
    }
    if (message.done !== false) {
      obj.done = message.done;
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.queryResult !== undefined) {
      obj.queryResult = QueryResult.toJSON(message.queryResult);
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = QueryAssetsOutputConfig.toJSON(message.outputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryAssetsResponse>): QueryAssetsResponse {
    return QueryAssetsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryAssetsResponse>): QueryAssetsResponse {
    const message = createBaseQueryAssetsResponse();
    message.jobReference = object.jobReference ?? "";
    message.done = object.done ?? false;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.queryResult = (object.queryResult !== undefined && object.queryResult !== null)
      ? QueryResult.fromPartial(object.queryResult)
      : undefined;
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? QueryAssetsOutputConfig.fromPartial(object.outputConfig)
      : undefined;
    return message;
  },
};

function createBaseQueryResult(): QueryResult {
  return { rows: [], schema: undefined, nextPageToken: "", totalRows: Long.ZERO };
}

export const QueryResult: MessageFns<QueryResult> = {
  encode(message: QueryResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.rows) {
      Struct.encode(Struct.wrap(v!), writer.uint32(10).fork()).join();
    }
    if (message.schema !== undefined) {
      TableSchema.encode(message.schema, writer.uint32(18).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    if (!message.totalRows.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.totalRows.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rows.push(Struct.unwrap(Struct.decode(reader, reader.uint32())));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.schema = TableSchema.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.totalRows = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryResult {
    return {
      rows: globalThis.Array.isArray(object?.rows) ? [...object.rows] : [],
      schema: isSet(object.schema) ? TableSchema.fromJSON(object.schema) : undefined,
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      totalRows: isSet(object.totalRows) ? Long.fromValue(object.totalRows) : Long.ZERO,
    };
  },

  toJSON(message: QueryResult): unknown {
    const obj: any = {};
    if (message.rows?.length) {
      obj.rows = message.rows;
    }
    if (message.schema !== undefined) {
      obj.schema = TableSchema.toJSON(message.schema);
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (!message.totalRows.equals(Long.ZERO)) {
      obj.totalRows = (message.totalRows || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<QueryResult>): QueryResult {
    return QueryResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryResult>): QueryResult {
    const message = createBaseQueryResult();
    message.rows = object.rows?.map((e) => e) || [];
    message.schema = (object.schema !== undefined && object.schema !== null)
      ? TableSchema.fromPartial(object.schema)
      : undefined;
    message.nextPageToken = object.nextPageToken ?? "";
    message.totalRows = (object.totalRows !== undefined && object.totalRows !== null)
      ? Long.fromValue(object.totalRows)
      : Long.ZERO;
    return message;
  },
};

function createBaseTableSchema(): TableSchema {
  return { fields: [] };
}

export const TableSchema: MessageFns<TableSchema> = {
  encode(message: TableSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fields) {
      TableFieldSchema.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fields.push(TableFieldSchema.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableSchema {
    return {
      fields: globalThis.Array.isArray(object?.fields)
        ? object.fields.map((e: any) => TableFieldSchema.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TableSchema): unknown {
    const obj: any = {};
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => TableFieldSchema.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TableSchema>): TableSchema {
    return TableSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableSchema>): TableSchema {
    const message = createBaseTableSchema();
    message.fields = object.fields?.map((e) => TableFieldSchema.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTableFieldSchema(): TableFieldSchema {
  return { field: "", type: "", mode: "", fields: [] };
}

export const TableFieldSchema: MessageFns<TableFieldSchema> = {
  encode(message: TableFieldSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== "") {
      writer.uint32(10).string(message.field);
    }
    if (message.type !== "") {
      writer.uint32(18).string(message.type);
    }
    if (message.mode !== "") {
      writer.uint32(26).string(message.mode);
    }
    for (const v of message.fields) {
      TableFieldSchema.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableFieldSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableFieldSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.type = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mode = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.fields.push(TableFieldSchema.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableFieldSchema {
    return {
      field: isSet(object.field) ? globalThis.String(object.field) : "",
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      mode: isSet(object.mode) ? globalThis.String(object.mode) : "",
      fields: globalThis.Array.isArray(object?.fields)
        ? object.fields.map((e: any) => TableFieldSchema.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TableFieldSchema): unknown {
    const obj: any = {};
    if (message.field !== "") {
      obj.field = message.field;
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.mode !== "") {
      obj.mode = message.mode;
    }
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => TableFieldSchema.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TableFieldSchema>): TableFieldSchema {
    return TableFieldSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableFieldSchema>): TableFieldSchema {
    const message = createBaseTableFieldSchema();
    message.field = object.field ?? "";
    message.type = object.type ?? "";
    message.mode = object.mode ?? "";
    message.fields = object.fields?.map((e) => TableFieldSchema.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBatchGetEffectiveIamPoliciesRequest(): BatchGetEffectiveIamPoliciesRequest {
  return { scope: "", names: [] };
}

export const BatchGetEffectiveIamPoliciesRequest: MessageFns<BatchGetEffectiveIamPoliciesRequest> = {
  encode(message: BatchGetEffectiveIamPoliciesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    for (const v of message.names) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetEffectiveIamPoliciesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetEffectiveIamPoliciesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.names.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetEffectiveIamPoliciesRequest {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      names: globalThis.Array.isArray(object?.names) ? object.names.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: BatchGetEffectiveIamPoliciesRequest): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.names?.length) {
      obj.names = message.names;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetEffectiveIamPoliciesRequest>): BatchGetEffectiveIamPoliciesRequest {
    return BatchGetEffectiveIamPoliciesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetEffectiveIamPoliciesRequest>): BatchGetEffectiveIamPoliciesRequest {
    const message = createBaseBatchGetEffectiveIamPoliciesRequest();
    message.scope = object.scope ?? "";
    message.names = object.names?.map((e) => e) || [];
    return message;
  },
};

function createBaseBatchGetEffectiveIamPoliciesResponse(): BatchGetEffectiveIamPoliciesResponse {
  return { policyResults: [] };
}

export const BatchGetEffectiveIamPoliciesResponse: MessageFns<BatchGetEffectiveIamPoliciesResponse> = {
  encode(message: BatchGetEffectiveIamPoliciesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.policyResults) {
      BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetEffectiveIamPoliciesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetEffectiveIamPoliciesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.policyResults.push(
            BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetEffectiveIamPoliciesResponse {
    return {
      policyResults: globalThis.Array.isArray(object?.policyResults)
        ? object.policyResults.map((e: any) => BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchGetEffectiveIamPoliciesResponse): unknown {
    const obj: any = {};
    if (message.policyResults?.length) {
      obj.policyResults = message.policyResults.map((e) =>
        BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetEffectiveIamPoliciesResponse>): BatchGetEffectiveIamPoliciesResponse {
    return BatchGetEffectiveIamPoliciesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetEffectiveIamPoliciesResponse>): BatchGetEffectiveIamPoliciesResponse {
    const message = createBaseBatchGetEffectiveIamPoliciesResponse();
    message.policyResults =
      object.policyResults?.map((e) => BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy(): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy {
  return { fullResourceName: "", policies: [] };
}

export const BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy: MessageFns<
  BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy
> = {
  encode(
    message: BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.fullResourceName !== "") {
      writer.uint32(10).string(message.fullResourceName);
    }
    for (const v of message.policies) {
      BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fullResourceName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.policies.push(
            BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy {
    return {
      fullResourceName: isSet(object.fullResourceName) ? globalThis.String(object.fullResourceName) : "",
      policies: globalThis.Array.isArray(object?.policies)
        ? object.policies.map((e: any) =>
          BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo.fromJSON(e)
        )
        : [],
    };
  },

  toJSON(message: BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy): unknown {
    const obj: any = {};
    if (message.fullResourceName !== "") {
      obj.fullResourceName = message.fullResourceName;
    }
    if (message.policies?.length) {
      obj.policies = message.policies.map((e) =>
        BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo.toJSON(e)
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy>,
  ): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy {
    return BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy>,
  ): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy {
    const message = createBaseBatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy();
    message.fullResourceName = object.fullResourceName ?? "";
    message.policies =
      object.policies?.map((e) => BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseBatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo(): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo {
  return { attachedResource: "", policy: undefined };
}

export const BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo: MessageFns<
  BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo
> = {
  encode(
    message: BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.attachedResource !== "") {
      writer.uint32(10).string(message.attachedResource);
    }
    if (message.policy !== undefined) {
      Policy.encode(message.policy, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.attachedResource = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.policy = Policy.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo {
    return {
      attachedResource: isSet(object.attachedResource) ? globalThis.String(object.attachedResource) : "",
      policy: isSet(object.policy) ? Policy.fromJSON(object.policy) : undefined,
    };
  },

  toJSON(message: BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo): unknown {
    const obj: any = {};
    if (message.attachedResource !== "") {
      obj.attachedResource = message.attachedResource;
    }
    if (message.policy !== undefined) {
      obj.policy = Policy.toJSON(message.policy);
    }
    return obj;
  },

  create(
    base?: DeepPartial<BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo>,
  ): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo {
    return BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo>,
  ): BatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo {
    const message = createBaseBatchGetEffectiveIamPoliciesResponse_EffectiveIamPolicy_PolicyInfo();
    message.attachedResource = object.attachedResource ?? "";
    message.policy = (object.policy !== undefined && object.policy !== null)
      ? Policy.fromPartial(object.policy)
      : undefined;
    return message;
  },
};

function createBaseAnalyzerOrgPolicy(): AnalyzerOrgPolicy {
  return { attachedResource: "", appliedResource: "", rules: [], inheritFromParent: false, reset: false };
}

export const AnalyzerOrgPolicy: MessageFns<AnalyzerOrgPolicy> = {
  encode(message: AnalyzerOrgPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.attachedResource !== "") {
      writer.uint32(10).string(message.attachedResource);
    }
    if (message.appliedResource !== "") {
      writer.uint32(42).string(message.appliedResource);
    }
    for (const v of message.rules) {
      AnalyzerOrgPolicy_Rule.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.inheritFromParent !== false) {
      writer.uint32(24).bool(message.inheritFromParent);
    }
    if (message.reset !== false) {
      writer.uint32(32).bool(message.reset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.attachedResource = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.appliedResource = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rules.push(AnalyzerOrgPolicy_Rule.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.inheritFromParent = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.reset = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicy {
    return {
      attachedResource: isSet(object.attachedResource) ? globalThis.String(object.attachedResource) : "",
      appliedResource: isSet(object.appliedResource) ? globalThis.String(object.appliedResource) : "",
      rules: globalThis.Array.isArray(object?.rules)
        ? object.rules.map((e: any) => AnalyzerOrgPolicy_Rule.fromJSON(e))
        : [],
      inheritFromParent: isSet(object.inheritFromParent) ? globalThis.Boolean(object.inheritFromParent) : false,
      reset: isSet(object.reset) ? globalThis.Boolean(object.reset) : false,
    };
  },

  toJSON(message: AnalyzerOrgPolicy): unknown {
    const obj: any = {};
    if (message.attachedResource !== "") {
      obj.attachedResource = message.attachedResource;
    }
    if (message.appliedResource !== "") {
      obj.appliedResource = message.appliedResource;
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => AnalyzerOrgPolicy_Rule.toJSON(e));
    }
    if (message.inheritFromParent !== false) {
      obj.inheritFromParent = message.inheritFromParent;
    }
    if (message.reset !== false) {
      obj.reset = message.reset;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzerOrgPolicy>): AnalyzerOrgPolicy {
    return AnalyzerOrgPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzerOrgPolicy>): AnalyzerOrgPolicy {
    const message = createBaseAnalyzerOrgPolicy();
    message.attachedResource = object.attachedResource ?? "";
    message.appliedResource = object.appliedResource ?? "";
    message.rules = object.rules?.map((e) => AnalyzerOrgPolicy_Rule.fromPartial(e)) || [];
    message.inheritFromParent = object.inheritFromParent ?? false;
    message.reset = object.reset ?? false;
    return message;
  },
};

function createBaseAnalyzerOrgPolicy_Rule(): AnalyzerOrgPolicy_Rule {
  return {
    values: undefined,
    allowAll: undefined,
    denyAll: undefined,
    enforce: undefined,
    condition: undefined,
    conditionEvaluation: undefined,
  };
}

export const AnalyzerOrgPolicy_Rule: MessageFns<AnalyzerOrgPolicy_Rule> = {
  encode(message: AnalyzerOrgPolicy_Rule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.values !== undefined) {
      AnalyzerOrgPolicy_Rule_StringValues.encode(message.values, writer.uint32(26).fork()).join();
    }
    if (message.allowAll !== undefined) {
      writer.uint32(32).bool(message.allowAll);
    }
    if (message.denyAll !== undefined) {
      writer.uint32(40).bool(message.denyAll);
    }
    if (message.enforce !== undefined) {
      writer.uint32(48).bool(message.enforce);
    }
    if (message.condition !== undefined) {
      Expr.encode(message.condition, writer.uint32(58).fork()).join();
    }
    if (message.conditionEvaluation !== undefined) {
      ConditionEvaluation.encode(message.conditionEvaluation, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicy_Rule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicy_Rule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.values = AnalyzerOrgPolicy_Rule_StringValues.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.allowAll = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.denyAll = reader.bool();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.enforce = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.condition = Expr.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.conditionEvaluation = ConditionEvaluation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicy_Rule {
    return {
      values: isSet(object.values) ? AnalyzerOrgPolicy_Rule_StringValues.fromJSON(object.values) : undefined,
      allowAll: isSet(object.allowAll) ? globalThis.Boolean(object.allowAll) : undefined,
      denyAll: isSet(object.denyAll) ? globalThis.Boolean(object.denyAll) : undefined,
      enforce: isSet(object.enforce) ? globalThis.Boolean(object.enforce) : undefined,
      condition: isSet(object.condition) ? Expr.fromJSON(object.condition) : undefined,
      conditionEvaluation: isSet(object.conditionEvaluation)
        ? ConditionEvaluation.fromJSON(object.conditionEvaluation)
        : undefined,
    };
  },

  toJSON(message: AnalyzerOrgPolicy_Rule): unknown {
    const obj: any = {};
    if (message.values !== undefined) {
      obj.values = AnalyzerOrgPolicy_Rule_StringValues.toJSON(message.values);
    }
    if (message.allowAll !== undefined) {
      obj.allowAll = message.allowAll;
    }
    if (message.denyAll !== undefined) {
      obj.denyAll = message.denyAll;
    }
    if (message.enforce !== undefined) {
      obj.enforce = message.enforce;
    }
    if (message.condition !== undefined) {
      obj.condition = Expr.toJSON(message.condition);
    }
    if (message.conditionEvaluation !== undefined) {
      obj.conditionEvaluation = ConditionEvaluation.toJSON(message.conditionEvaluation);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzerOrgPolicy_Rule>): AnalyzerOrgPolicy_Rule {
    return AnalyzerOrgPolicy_Rule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzerOrgPolicy_Rule>): AnalyzerOrgPolicy_Rule {
    const message = createBaseAnalyzerOrgPolicy_Rule();
    message.values = (object.values !== undefined && object.values !== null)
      ? AnalyzerOrgPolicy_Rule_StringValues.fromPartial(object.values)
      : undefined;
    message.allowAll = object.allowAll ?? undefined;
    message.denyAll = object.denyAll ?? undefined;
    message.enforce = object.enforce ?? undefined;
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? Expr.fromPartial(object.condition)
      : undefined;
    message.conditionEvaluation = (object.conditionEvaluation !== undefined && object.conditionEvaluation !== null)
      ? ConditionEvaluation.fromPartial(object.conditionEvaluation)
      : undefined;
    return message;
  },
};

function createBaseAnalyzerOrgPolicy_Rule_StringValues(): AnalyzerOrgPolicy_Rule_StringValues {
  return { allowedValues: [], deniedValues: [] };
}

export const AnalyzerOrgPolicy_Rule_StringValues: MessageFns<AnalyzerOrgPolicy_Rule_StringValues> = {
  encode(message: AnalyzerOrgPolicy_Rule_StringValues, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.allowedValues) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.deniedValues) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicy_Rule_StringValues {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicy_Rule_StringValues();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.allowedValues.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deniedValues.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicy_Rule_StringValues {
    return {
      allowedValues: globalThis.Array.isArray(object?.allowedValues)
        ? object.allowedValues.map((e: any) => globalThis.String(e))
        : [],
      deniedValues: globalThis.Array.isArray(object?.deniedValues)
        ? object.deniedValues.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: AnalyzerOrgPolicy_Rule_StringValues): unknown {
    const obj: any = {};
    if (message.allowedValues?.length) {
      obj.allowedValues = message.allowedValues;
    }
    if (message.deniedValues?.length) {
      obj.deniedValues = message.deniedValues;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzerOrgPolicy_Rule_StringValues>): AnalyzerOrgPolicy_Rule_StringValues {
    return AnalyzerOrgPolicy_Rule_StringValues.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzerOrgPolicy_Rule_StringValues>): AnalyzerOrgPolicy_Rule_StringValues {
    const message = createBaseAnalyzerOrgPolicy_Rule_StringValues();
    message.allowedValues = object.allowedValues?.map((e) => e) || [];
    message.deniedValues = object.deniedValues?.map((e) => e) || [];
    return message;
  },
};

function createBaseAnalyzerOrgPolicyConstraint(): AnalyzerOrgPolicyConstraint {
  return { googleDefinedConstraint: undefined, customConstraint: undefined };
}

export const AnalyzerOrgPolicyConstraint: MessageFns<AnalyzerOrgPolicyConstraint> = {
  encode(message: AnalyzerOrgPolicyConstraint, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.googleDefinedConstraint !== undefined) {
      AnalyzerOrgPolicyConstraint_Constraint.encode(message.googleDefinedConstraint, writer.uint32(10).fork()).join();
    }
    if (message.customConstraint !== undefined) {
      AnalyzerOrgPolicyConstraint_CustomConstraint.encode(message.customConstraint, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicyConstraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicyConstraint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.googleDefinedConstraint = AnalyzerOrgPolicyConstraint_Constraint.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.customConstraint = AnalyzerOrgPolicyConstraint_CustomConstraint.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicyConstraint {
    return {
      googleDefinedConstraint: isSet(object.googleDefinedConstraint)
        ? AnalyzerOrgPolicyConstraint_Constraint.fromJSON(object.googleDefinedConstraint)
        : undefined,
      customConstraint: isSet(object.customConstraint)
        ? AnalyzerOrgPolicyConstraint_CustomConstraint.fromJSON(object.customConstraint)
        : undefined,
    };
  },

  toJSON(message: AnalyzerOrgPolicyConstraint): unknown {
    const obj: any = {};
    if (message.googleDefinedConstraint !== undefined) {
      obj.googleDefinedConstraint = AnalyzerOrgPolicyConstraint_Constraint.toJSON(message.googleDefinedConstraint);
    }
    if (message.customConstraint !== undefined) {
      obj.customConstraint = AnalyzerOrgPolicyConstraint_CustomConstraint.toJSON(message.customConstraint);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzerOrgPolicyConstraint>): AnalyzerOrgPolicyConstraint {
    return AnalyzerOrgPolicyConstraint.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzerOrgPolicyConstraint>): AnalyzerOrgPolicyConstraint {
    const message = createBaseAnalyzerOrgPolicyConstraint();
    message.googleDefinedConstraint =
      (object.googleDefinedConstraint !== undefined && object.googleDefinedConstraint !== null)
        ? AnalyzerOrgPolicyConstraint_Constraint.fromPartial(object.googleDefinedConstraint)
        : undefined;
    message.customConstraint = (object.customConstraint !== undefined && object.customConstraint !== null)
      ? AnalyzerOrgPolicyConstraint_CustomConstraint.fromPartial(object.customConstraint)
      : undefined;
    return message;
  },
};

function createBaseAnalyzerOrgPolicyConstraint_Constraint(): AnalyzerOrgPolicyConstraint_Constraint {
  return {
    name: "",
    displayName: "",
    description: "",
    constraintDefault: 0,
    listConstraint: undefined,
    booleanConstraint: undefined,
  };
}

export const AnalyzerOrgPolicyConstraint_Constraint: MessageFns<AnalyzerOrgPolicyConstraint_Constraint> = {
  encode(message: AnalyzerOrgPolicyConstraint_Constraint, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.constraintDefault !== 0) {
      writer.uint32(32).int32(message.constraintDefault);
    }
    if (message.listConstraint !== undefined) {
      AnalyzerOrgPolicyConstraint_Constraint_ListConstraint.encode(message.listConstraint, writer.uint32(42).fork())
        .join();
    }
    if (message.booleanConstraint !== undefined) {
      AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint.encode(
        message.booleanConstraint,
        writer.uint32(50).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicyConstraint_Constraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicyConstraint_Constraint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.constraintDefault = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.listConstraint = AnalyzerOrgPolicyConstraint_Constraint_ListConstraint.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.booleanConstraint = AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicyConstraint_Constraint {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      constraintDefault: isSet(object.constraintDefault)
        ? analyzerOrgPolicyConstraint_Constraint_ConstraintDefaultFromJSON(object.constraintDefault)
        : 0,
      listConstraint: isSet(object.listConstraint)
        ? AnalyzerOrgPolicyConstraint_Constraint_ListConstraint.fromJSON(object.listConstraint)
        : undefined,
      booleanConstraint: isSet(object.booleanConstraint)
        ? AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint.fromJSON(object.booleanConstraint)
        : undefined,
    };
  },

  toJSON(message: AnalyzerOrgPolicyConstraint_Constraint): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.constraintDefault !== 0) {
      obj.constraintDefault = analyzerOrgPolicyConstraint_Constraint_ConstraintDefaultToJSON(message.constraintDefault);
    }
    if (message.listConstraint !== undefined) {
      obj.listConstraint = AnalyzerOrgPolicyConstraint_Constraint_ListConstraint.toJSON(message.listConstraint);
    }
    if (message.booleanConstraint !== undefined) {
      obj.booleanConstraint = AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint.toJSON(
        message.booleanConstraint,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzerOrgPolicyConstraint_Constraint>): AnalyzerOrgPolicyConstraint_Constraint {
    return AnalyzerOrgPolicyConstraint_Constraint.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzerOrgPolicyConstraint_Constraint>): AnalyzerOrgPolicyConstraint_Constraint {
    const message = createBaseAnalyzerOrgPolicyConstraint_Constraint();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.constraintDefault = object.constraintDefault ?? 0;
    message.listConstraint = (object.listConstraint !== undefined && object.listConstraint !== null)
      ? AnalyzerOrgPolicyConstraint_Constraint_ListConstraint.fromPartial(object.listConstraint)
      : undefined;
    message.booleanConstraint = (object.booleanConstraint !== undefined && object.booleanConstraint !== null)
      ? AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint.fromPartial(object.booleanConstraint)
      : undefined;
    return message;
  },
};

function createBaseAnalyzerOrgPolicyConstraint_Constraint_ListConstraint(): AnalyzerOrgPolicyConstraint_Constraint_ListConstraint {
  return { supportsIn: false, supportsUnder: false };
}

export const AnalyzerOrgPolicyConstraint_Constraint_ListConstraint: MessageFns<
  AnalyzerOrgPolicyConstraint_Constraint_ListConstraint
> = {
  encode(
    message: AnalyzerOrgPolicyConstraint_Constraint_ListConstraint,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.supportsIn !== false) {
      writer.uint32(8).bool(message.supportsIn);
    }
    if (message.supportsUnder !== false) {
      writer.uint32(16).bool(message.supportsUnder);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicyConstraint_Constraint_ListConstraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicyConstraint_Constraint_ListConstraint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.supportsIn = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.supportsUnder = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicyConstraint_Constraint_ListConstraint {
    return {
      supportsIn: isSet(object.supportsIn) ? globalThis.Boolean(object.supportsIn) : false,
      supportsUnder: isSet(object.supportsUnder) ? globalThis.Boolean(object.supportsUnder) : false,
    };
  },

  toJSON(message: AnalyzerOrgPolicyConstraint_Constraint_ListConstraint): unknown {
    const obj: any = {};
    if (message.supportsIn !== false) {
      obj.supportsIn = message.supportsIn;
    }
    if (message.supportsUnder !== false) {
      obj.supportsUnder = message.supportsUnder;
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzerOrgPolicyConstraint_Constraint_ListConstraint>,
  ): AnalyzerOrgPolicyConstraint_Constraint_ListConstraint {
    return AnalyzerOrgPolicyConstraint_Constraint_ListConstraint.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzerOrgPolicyConstraint_Constraint_ListConstraint>,
  ): AnalyzerOrgPolicyConstraint_Constraint_ListConstraint {
    const message = createBaseAnalyzerOrgPolicyConstraint_Constraint_ListConstraint();
    message.supportsIn = object.supportsIn ?? false;
    message.supportsUnder = object.supportsUnder ?? false;
    return message;
  },
};

function createBaseAnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint(): AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint {
  return {};
}

export const AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint: MessageFns<
  AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint
> = {
  encode(
    _: AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint {
    return {};
  },

  toJSON(_: AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint>,
  ): AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint {
    return AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint>,
  ): AnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint {
    const message = createBaseAnalyzerOrgPolicyConstraint_Constraint_BooleanConstraint();
    return message;
  },
};

function createBaseAnalyzerOrgPolicyConstraint_CustomConstraint(): AnalyzerOrgPolicyConstraint_CustomConstraint {
  return {
    name: "",
    resourceTypes: [],
    methodTypes: [],
    condition: "",
    actionType: 0,
    displayName: "",
    description: "",
  };
}

export const AnalyzerOrgPolicyConstraint_CustomConstraint: MessageFns<AnalyzerOrgPolicyConstraint_CustomConstraint> = {
  encode(
    message: AnalyzerOrgPolicyConstraint_CustomConstraint,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.resourceTypes) {
      writer.uint32(18).string(v!);
    }
    writer.uint32(26).fork();
    for (const v of message.methodTypes) {
      writer.int32(v);
    }
    writer.join();
    if (message.condition !== "") {
      writer.uint32(34).string(message.condition);
    }
    if (message.actionType !== 0) {
      writer.uint32(40).int32(message.actionType);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzerOrgPolicyConstraint_CustomConstraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzerOrgPolicyConstraint_CustomConstraint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resourceTypes.push(reader.string());
          continue;
        case 3:
          if (tag === 24) {
            message.methodTypes.push(reader.int32() as any);

            continue;
          }

          if (tag === 26) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.methodTypes.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.condition = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.actionType = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzerOrgPolicyConstraint_CustomConstraint {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      resourceTypes: globalThis.Array.isArray(object?.resourceTypes)
        ? object.resourceTypes.map((e: any) => globalThis.String(e))
        : [],
      methodTypes: globalThis.Array.isArray(object?.methodTypes)
        ? object.methodTypes.map((e: any) => analyzerOrgPolicyConstraint_CustomConstraint_MethodTypeFromJSON(e))
        : [],
      condition: isSet(object.condition) ? globalThis.String(object.condition) : "",
      actionType: isSet(object.actionType)
        ? analyzerOrgPolicyConstraint_CustomConstraint_ActionTypeFromJSON(object.actionType)
        : 0,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: AnalyzerOrgPolicyConstraint_CustomConstraint): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.resourceTypes?.length) {
      obj.resourceTypes = message.resourceTypes;
    }
    if (message.methodTypes?.length) {
      obj.methodTypes = message.methodTypes.map((e) =>
        analyzerOrgPolicyConstraint_CustomConstraint_MethodTypeToJSON(e)
      );
    }
    if (message.condition !== "") {
      obj.condition = message.condition;
    }
    if (message.actionType !== 0) {
      obj.actionType = analyzerOrgPolicyConstraint_CustomConstraint_ActionTypeToJSON(message.actionType);
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzerOrgPolicyConstraint_CustomConstraint>,
  ): AnalyzerOrgPolicyConstraint_CustomConstraint {
    return AnalyzerOrgPolicyConstraint_CustomConstraint.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzerOrgPolicyConstraint_CustomConstraint>,
  ): AnalyzerOrgPolicyConstraint_CustomConstraint {
    const message = createBaseAnalyzerOrgPolicyConstraint_CustomConstraint();
    message.name = object.name ?? "";
    message.resourceTypes = object.resourceTypes?.map((e) => e) || [];
    message.methodTypes = object.methodTypes?.map((e) => e) || [];
    message.condition = object.condition ?? "";
    message.actionType = object.actionType ?? 0;
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPoliciesRequest(): AnalyzeOrgPoliciesRequest {
  return { scope: "", constraint: "", filter: "", pageSize: undefined, pageToken: "" };
}

export const AnalyzeOrgPoliciesRequest: MessageFns<AnalyzeOrgPoliciesRequest> = {
  encode(message: AnalyzeOrgPoliciesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    if (message.constraint !== "") {
      writer.uint32(18).string(message.constraint);
    }
    if (message.filter !== "") {
      writer.uint32(26).string(message.filter);
    }
    if (message.pageSize !== undefined) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPoliciesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPoliciesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.constraint = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPoliciesRequest {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      constraint: isSet(object.constraint) ? globalThis.String(object.constraint) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: AnalyzeOrgPoliciesRequest): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.constraint !== "") {
      obj.constraint = message.constraint;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== undefined) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPoliciesRequest>): AnalyzeOrgPoliciesRequest {
    return AnalyzeOrgPoliciesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeOrgPoliciesRequest>): AnalyzeOrgPoliciesRequest {
    const message = createBaseAnalyzeOrgPoliciesRequest();
    message.scope = object.scope ?? "";
    message.constraint = object.constraint ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? undefined;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPoliciesResponse(): AnalyzeOrgPoliciesResponse {
  return { orgPolicyResults: [], constraint: undefined, nextPageToken: "" };
}

export const AnalyzeOrgPoliciesResponse: MessageFns<AnalyzeOrgPoliciesResponse> = {
  encode(message: AnalyzeOrgPoliciesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.orgPolicyResults) {
      AnalyzeOrgPoliciesResponse_OrgPolicyResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.constraint !== undefined) {
      AnalyzerOrgPolicyConstraint.encode(message.constraint, writer.uint32(18).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPoliciesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPoliciesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.orgPolicyResults.push(AnalyzeOrgPoliciesResponse_OrgPolicyResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.constraint = AnalyzerOrgPolicyConstraint.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPoliciesResponse {
    return {
      orgPolicyResults: globalThis.Array.isArray(object?.orgPolicyResults)
        ? object.orgPolicyResults.map((e: any) => AnalyzeOrgPoliciesResponse_OrgPolicyResult.fromJSON(e))
        : [],
      constraint: isSet(object.constraint) ? AnalyzerOrgPolicyConstraint.fromJSON(object.constraint) : undefined,
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: AnalyzeOrgPoliciesResponse): unknown {
    const obj: any = {};
    if (message.orgPolicyResults?.length) {
      obj.orgPolicyResults = message.orgPolicyResults.map((e) => AnalyzeOrgPoliciesResponse_OrgPolicyResult.toJSON(e));
    }
    if (message.constraint !== undefined) {
      obj.constraint = AnalyzerOrgPolicyConstraint.toJSON(message.constraint);
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPoliciesResponse>): AnalyzeOrgPoliciesResponse {
    return AnalyzeOrgPoliciesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeOrgPoliciesResponse>): AnalyzeOrgPoliciesResponse {
    const message = createBaseAnalyzeOrgPoliciesResponse();
    message.orgPolicyResults =
      object.orgPolicyResults?.map((e) => AnalyzeOrgPoliciesResponse_OrgPolicyResult.fromPartial(e)) || [];
    message.constraint = (object.constraint !== undefined && object.constraint !== null)
      ? AnalyzerOrgPolicyConstraint.fromPartial(object.constraint)
      : undefined;
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPoliciesResponse_OrgPolicyResult(): AnalyzeOrgPoliciesResponse_OrgPolicyResult {
  return { consolidatedPolicy: undefined, policyBundle: [], project: "", folders: [], organization: "" };
}

export const AnalyzeOrgPoliciesResponse_OrgPolicyResult: MessageFns<AnalyzeOrgPoliciesResponse_OrgPolicyResult> = {
  encode(message: AnalyzeOrgPoliciesResponse_OrgPolicyResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.consolidatedPolicy !== undefined) {
      AnalyzerOrgPolicy.encode(message.consolidatedPolicy, writer.uint32(10).fork()).join();
    }
    for (const v of message.policyBundle) {
      AnalyzerOrgPolicy.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.project !== "") {
      writer.uint32(26).string(message.project);
    }
    for (const v of message.folders) {
      writer.uint32(34).string(v!);
    }
    if (message.organization !== "") {
      writer.uint32(42).string(message.organization);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPoliciesResponse_OrgPolicyResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPoliciesResponse_OrgPolicyResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.consolidatedPolicy = AnalyzerOrgPolicy.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.policyBundle.push(AnalyzerOrgPolicy.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.project = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.folders.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.organization = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPoliciesResponse_OrgPolicyResult {
    return {
      consolidatedPolicy: isSet(object.consolidatedPolicy)
        ? AnalyzerOrgPolicy.fromJSON(object.consolidatedPolicy)
        : undefined,
      policyBundle: globalThis.Array.isArray(object?.policyBundle)
        ? object.policyBundle.map((e: any) => AnalyzerOrgPolicy.fromJSON(e))
        : [],
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      folders: globalThis.Array.isArray(object?.folders) ? object.folders.map((e: any) => globalThis.String(e)) : [],
      organization: isSet(object.organization) ? globalThis.String(object.organization) : "",
    };
  },

  toJSON(message: AnalyzeOrgPoliciesResponse_OrgPolicyResult): unknown {
    const obj: any = {};
    if (message.consolidatedPolicy !== undefined) {
      obj.consolidatedPolicy = AnalyzerOrgPolicy.toJSON(message.consolidatedPolicy);
    }
    if (message.policyBundle?.length) {
      obj.policyBundle = message.policyBundle.map((e) => AnalyzerOrgPolicy.toJSON(e));
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.folders?.length) {
      obj.folders = message.folders;
    }
    if (message.organization !== "") {
      obj.organization = message.organization;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPoliciesResponse_OrgPolicyResult>): AnalyzeOrgPoliciesResponse_OrgPolicyResult {
    return AnalyzeOrgPoliciesResponse_OrgPolicyResult.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPoliciesResponse_OrgPolicyResult>,
  ): AnalyzeOrgPoliciesResponse_OrgPolicyResult {
    const message = createBaseAnalyzeOrgPoliciesResponse_OrgPolicyResult();
    message.consolidatedPolicy = (object.consolidatedPolicy !== undefined && object.consolidatedPolicy !== null)
      ? AnalyzerOrgPolicy.fromPartial(object.consolidatedPolicy)
      : undefined;
    message.policyBundle = object.policyBundle?.map((e) => AnalyzerOrgPolicy.fromPartial(e)) || [];
    message.project = object.project ?? "";
    message.folders = object.folders?.map((e) => e) || [];
    message.organization = object.organization ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedContainersRequest(): AnalyzeOrgPolicyGovernedContainersRequest {
  return { scope: "", constraint: "", filter: "", pageSize: undefined, pageToken: "" };
}

export const AnalyzeOrgPolicyGovernedContainersRequest: MessageFns<AnalyzeOrgPolicyGovernedContainersRequest> = {
  encode(message: AnalyzeOrgPolicyGovernedContainersRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    if (message.constraint !== "") {
      writer.uint32(18).string(message.constraint);
    }
    if (message.filter !== "") {
      writer.uint32(26).string(message.filter);
    }
    if (message.pageSize !== undefined) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedContainersRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedContainersRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.constraint = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedContainersRequest {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      constraint: isSet(object.constraint) ? globalThis.String(object.constraint) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedContainersRequest): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.constraint !== "") {
      obj.constraint = message.constraint;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== undefined) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPolicyGovernedContainersRequest>): AnalyzeOrgPolicyGovernedContainersRequest {
    return AnalyzeOrgPolicyGovernedContainersRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPolicyGovernedContainersRequest>,
  ): AnalyzeOrgPolicyGovernedContainersRequest {
    const message = createBaseAnalyzeOrgPolicyGovernedContainersRequest();
    message.scope = object.scope ?? "";
    message.constraint = object.constraint ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? undefined;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedContainersResponse(): AnalyzeOrgPolicyGovernedContainersResponse {
  return { governedContainers: [], constraint: undefined, nextPageToken: "" };
}

export const AnalyzeOrgPolicyGovernedContainersResponse: MessageFns<AnalyzeOrgPolicyGovernedContainersResponse> = {
  encode(message: AnalyzeOrgPolicyGovernedContainersResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.governedContainers) {
      AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.constraint !== undefined) {
      AnalyzerOrgPolicyConstraint.encode(message.constraint, writer.uint32(18).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedContainersResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedContainersResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.governedContainers.push(
            AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer.decode(reader, reader.uint32()),
          );
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.constraint = AnalyzerOrgPolicyConstraint.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedContainersResponse {
    return {
      governedContainers: globalThis.Array.isArray(object?.governedContainers)
        ? object.governedContainers.map((e: any) =>
          AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer.fromJSON(e)
        )
        : [],
      constraint: isSet(object.constraint) ? AnalyzerOrgPolicyConstraint.fromJSON(object.constraint) : undefined,
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedContainersResponse): unknown {
    const obj: any = {};
    if (message.governedContainers?.length) {
      obj.governedContainers = message.governedContainers.map((e) =>
        AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer.toJSON(e)
      );
    }
    if (message.constraint !== undefined) {
      obj.constraint = AnalyzerOrgPolicyConstraint.toJSON(message.constraint);
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPolicyGovernedContainersResponse>): AnalyzeOrgPolicyGovernedContainersResponse {
    return AnalyzeOrgPolicyGovernedContainersResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPolicyGovernedContainersResponse>,
  ): AnalyzeOrgPolicyGovernedContainersResponse {
    const message = createBaseAnalyzeOrgPolicyGovernedContainersResponse();
    message.governedContainers =
      object.governedContainers?.map((e) =>
        AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer.fromPartial(e)
      ) || [];
    message.constraint = (object.constraint !== undefined && object.constraint !== null)
      ? AnalyzerOrgPolicyConstraint.fromPartial(object.constraint)
      : undefined;
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer(): AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer {
  return {
    fullResourceName: "",
    parent: "",
    consolidatedPolicy: undefined,
    policyBundle: [],
    project: "",
    folders: [],
    organization: "",
    effectiveTags: [],
  };
}

export const AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer: MessageFns<
  AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer
> = {
  encode(
    message: AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.fullResourceName !== "") {
      writer.uint32(10).string(message.fullResourceName);
    }
    if (message.parent !== "") {
      writer.uint32(18).string(message.parent);
    }
    if (message.consolidatedPolicy !== undefined) {
      AnalyzerOrgPolicy.encode(message.consolidatedPolicy, writer.uint32(26).fork()).join();
    }
    for (const v of message.policyBundle) {
      AnalyzerOrgPolicy.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.project !== "") {
      writer.uint32(42).string(message.project);
    }
    for (const v of message.folders) {
      writer.uint32(50).string(v!);
    }
    if (message.organization !== "") {
      writer.uint32(58).string(message.organization);
    }
    for (const v of message.effectiveTags) {
      EffectiveTagDetails.encode(v!, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fullResourceName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.consolidatedPolicy = AnalyzerOrgPolicy.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.policyBundle.push(AnalyzerOrgPolicy.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.project = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.folders.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.organization = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.effectiveTags.push(EffectiveTagDetails.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer {
    return {
      fullResourceName: isSet(object.fullResourceName) ? globalThis.String(object.fullResourceName) : "",
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      consolidatedPolicy: isSet(object.consolidatedPolicy)
        ? AnalyzerOrgPolicy.fromJSON(object.consolidatedPolicy)
        : undefined,
      policyBundle: globalThis.Array.isArray(object?.policyBundle)
        ? object.policyBundle.map((e: any) => AnalyzerOrgPolicy.fromJSON(e))
        : [],
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      folders: globalThis.Array.isArray(object?.folders) ? object.folders.map((e: any) => globalThis.String(e)) : [],
      organization: isSet(object.organization) ? globalThis.String(object.organization) : "",
      effectiveTags: globalThis.Array.isArray(object?.effectiveTags)
        ? object.effectiveTags.map((e: any) => EffectiveTagDetails.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer): unknown {
    const obj: any = {};
    if (message.fullResourceName !== "") {
      obj.fullResourceName = message.fullResourceName;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.consolidatedPolicy !== undefined) {
      obj.consolidatedPolicy = AnalyzerOrgPolicy.toJSON(message.consolidatedPolicy);
    }
    if (message.policyBundle?.length) {
      obj.policyBundle = message.policyBundle.map((e) => AnalyzerOrgPolicy.toJSON(e));
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.folders?.length) {
      obj.folders = message.folders;
    }
    if (message.organization !== "") {
      obj.organization = message.organization;
    }
    if (message.effectiveTags?.length) {
      obj.effectiveTags = message.effectiveTags.map((e) => EffectiveTagDetails.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer>,
  ): AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer {
    return AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer>,
  ): AnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer {
    const message = createBaseAnalyzeOrgPolicyGovernedContainersResponse_GovernedContainer();
    message.fullResourceName = object.fullResourceName ?? "";
    message.parent = object.parent ?? "";
    message.consolidatedPolicy = (object.consolidatedPolicy !== undefined && object.consolidatedPolicy !== null)
      ? AnalyzerOrgPolicy.fromPartial(object.consolidatedPolicy)
      : undefined;
    message.policyBundle = object.policyBundle?.map((e) => AnalyzerOrgPolicy.fromPartial(e)) || [];
    message.project = object.project ?? "";
    message.folders = object.folders?.map((e) => e) || [];
    message.organization = object.organization ?? "";
    message.effectiveTags = object.effectiveTags?.map((e) => EffectiveTagDetails.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedAssetsRequest(): AnalyzeOrgPolicyGovernedAssetsRequest {
  return { scope: "", constraint: "", filter: "", pageSize: undefined, pageToken: "" };
}

export const AnalyzeOrgPolicyGovernedAssetsRequest: MessageFns<AnalyzeOrgPolicyGovernedAssetsRequest> = {
  encode(message: AnalyzeOrgPolicyGovernedAssetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scope !== "") {
      writer.uint32(10).string(message.scope);
    }
    if (message.constraint !== "") {
      writer.uint32(18).string(message.constraint);
    }
    if (message.filter !== "") {
      writer.uint32(26).string(message.filter);
    }
    if (message.pageSize !== undefined) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedAssetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.scope = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.constraint = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedAssetsRequest {
    return {
      scope: isSet(object.scope) ? globalThis.String(object.scope) : "",
      constraint: isSet(object.constraint) ? globalThis.String(object.constraint) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : undefined,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedAssetsRequest): unknown {
    const obj: any = {};
    if (message.scope !== "") {
      obj.scope = message.scope;
    }
    if (message.constraint !== "") {
      obj.constraint = message.constraint;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== undefined) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPolicyGovernedAssetsRequest>): AnalyzeOrgPolicyGovernedAssetsRequest {
    return AnalyzeOrgPolicyGovernedAssetsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeOrgPolicyGovernedAssetsRequest>): AnalyzeOrgPolicyGovernedAssetsRequest {
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsRequest();
    message.scope = object.scope ?? "";
    message.constraint = object.constraint ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? undefined;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedAssetsResponse(): AnalyzeOrgPolicyGovernedAssetsResponse {
  return { governedAssets: [], constraint: undefined, nextPageToken: "" };
}

export const AnalyzeOrgPolicyGovernedAssetsResponse: MessageFns<AnalyzeOrgPolicyGovernedAssetsResponse> = {
  encode(message: AnalyzeOrgPolicyGovernedAssetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.governedAssets) {
      AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.constraint !== undefined) {
      AnalyzerOrgPolicyConstraint.encode(message.constraint, writer.uint32(18).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedAssetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.governedAssets.push(
            AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset.decode(reader, reader.uint32()),
          );
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.constraint = AnalyzerOrgPolicyConstraint.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedAssetsResponse {
    return {
      governedAssets: globalThis.Array.isArray(object?.governedAssets)
        ? object.governedAssets.map((e: any) => AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset.fromJSON(e))
        : [],
      constraint: isSet(object.constraint) ? AnalyzerOrgPolicyConstraint.fromJSON(object.constraint) : undefined,
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedAssetsResponse): unknown {
    const obj: any = {};
    if (message.governedAssets?.length) {
      obj.governedAssets = message.governedAssets.map((e) =>
        AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset.toJSON(e)
      );
    }
    if (message.constraint !== undefined) {
      obj.constraint = AnalyzerOrgPolicyConstraint.toJSON(message.constraint);
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse>): AnalyzeOrgPolicyGovernedAssetsResponse {
    return AnalyzeOrgPolicyGovernedAssetsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse>): AnalyzeOrgPolicyGovernedAssetsResponse {
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse();
    message.governedAssets =
      object.governedAssets?.map((e) => AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset.fromPartial(e)) || [];
    message.constraint = (object.constraint !== undefined && object.constraint !== null)
      ? AnalyzerOrgPolicyConstraint.fromPartial(object.constraint)
      : undefined;
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource(): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource {
  return {
    fullResourceName: "",
    parent: "",
    project: "",
    folders: [],
    organization: "",
    assetType: "",
    effectiveTags: [],
  };
}

export const AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource: MessageFns<
  AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource
> = {
  encode(
    message: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.fullResourceName !== "") {
      writer.uint32(10).string(message.fullResourceName);
    }
    if (message.parent !== "") {
      writer.uint32(18).string(message.parent);
    }
    if (message.project !== "") {
      writer.uint32(42).string(message.project);
    }
    for (const v of message.folders) {
      writer.uint32(50).string(v!);
    }
    if (message.organization !== "") {
      writer.uint32(58).string(message.organization);
    }
    if (message.assetType !== "") {
      writer.uint32(66).string(message.assetType);
    }
    for (const v of message.effectiveTags) {
      EffectiveTagDetails.encode(v!, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fullResourceName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.project = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.folders.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.organization = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.assetType = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.effectiveTags.push(EffectiveTagDetails.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource {
    return {
      fullResourceName: isSet(object.fullResourceName) ? globalThis.String(object.fullResourceName) : "",
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      folders: globalThis.Array.isArray(object?.folders) ? object.folders.map((e: any) => globalThis.String(e)) : [],
      organization: isSet(object.organization) ? globalThis.String(object.organization) : "",
      assetType: isSet(object.assetType) ? globalThis.String(object.assetType) : "",
      effectiveTags: globalThis.Array.isArray(object?.effectiveTags)
        ? object.effectiveTags.map((e: any) => EffectiveTagDetails.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource): unknown {
    const obj: any = {};
    if (message.fullResourceName !== "") {
      obj.fullResourceName = message.fullResourceName;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.folders?.length) {
      obj.folders = message.folders;
    }
    if (message.organization !== "") {
      obj.organization = message.organization;
    }
    if (message.assetType !== "") {
      obj.assetType = message.assetType;
    }
    if (message.effectiveTags?.length) {
      obj.effectiveTags = message.effectiveTags.map((e) => EffectiveTagDetails.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource>,
  ): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource {
    return AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource>,
  ): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource {
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource();
    message.fullResourceName = object.fullResourceName ?? "";
    message.parent = object.parent ?? "";
    message.project = object.project ?? "";
    message.folders = object.folders?.map((e) => e) || [];
    message.organization = object.organization ?? "";
    message.assetType = object.assetType ?? "";
    message.effectiveTags = object.effectiveTags?.map((e) => EffectiveTagDetails.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy(): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy {
  return { attachedResource: "", policy: undefined, project: "", folders: [], organization: "", assetType: "" };
}

export const AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy: MessageFns<
  AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy
> = {
  encode(
    message: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.attachedResource !== "") {
      writer.uint32(10).string(message.attachedResource);
    }
    if (message.policy !== undefined) {
      Policy.encode(message.policy, writer.uint32(18).fork()).join();
    }
    if (message.project !== "") {
      writer.uint32(42).string(message.project);
    }
    for (const v of message.folders) {
      writer.uint32(50).string(v!);
    }
    if (message.organization !== "") {
      writer.uint32(58).string(message.organization);
    }
    if (message.assetType !== "") {
      writer.uint32(66).string(message.assetType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.attachedResource = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.policy = Policy.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.project = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.folders.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.organization = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.assetType = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy {
    return {
      attachedResource: isSet(object.attachedResource) ? globalThis.String(object.attachedResource) : "",
      policy: isSet(object.policy) ? Policy.fromJSON(object.policy) : undefined,
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      folders: globalThis.Array.isArray(object?.folders) ? object.folders.map((e: any) => globalThis.String(e)) : [],
      organization: isSet(object.organization) ? globalThis.String(object.organization) : "",
      assetType: isSet(object.assetType) ? globalThis.String(object.assetType) : "",
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy): unknown {
    const obj: any = {};
    if (message.attachedResource !== "") {
      obj.attachedResource = message.attachedResource;
    }
    if (message.policy !== undefined) {
      obj.policy = Policy.toJSON(message.policy);
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.folders?.length) {
      obj.folders = message.folders;
    }
    if (message.organization !== "") {
      obj.organization = message.organization;
    }
    if (message.assetType !== "") {
      obj.assetType = message.assetType;
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy>,
  ): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy {
    return AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy>,
  ): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy {
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy();
    message.attachedResource = object.attachedResource ?? "";
    message.policy = (object.policy !== undefined && object.policy !== null)
      ? Policy.fromPartial(object.policy)
      : undefined;
    message.project = object.project ?? "";
    message.folders = object.folders?.map((e) => e) || [];
    message.organization = object.organization ?? "";
    message.assetType = object.assetType ?? "";
    return message;
  },
};

function createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset(): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset {
  return { governedResource: undefined, governedIamPolicy: undefined, consolidatedPolicy: undefined, policyBundle: [] };
}

export const AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset: MessageFns<
  AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset
> = {
  encode(
    message: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.governedResource !== undefined) {
      AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource.encode(message.governedResource, writer.uint32(10).fork())
        .join();
    }
    if (message.governedIamPolicy !== undefined) {
      AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy.encode(
        message.governedIamPolicy,
        writer.uint32(18).fork(),
      ).join();
    }
    if (message.consolidatedPolicy !== undefined) {
      AnalyzerOrgPolicy.encode(message.consolidatedPolicy, writer.uint32(26).fork()).join();
    }
    for (const v of message.policyBundle) {
      AnalyzerOrgPolicy.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.governedResource = AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.governedIamPolicy = AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.consolidatedPolicy = AnalyzerOrgPolicy.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.policyBundle.push(AnalyzerOrgPolicy.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset {
    return {
      governedResource: isSet(object.governedResource)
        ? AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource.fromJSON(object.governedResource)
        : undefined,
      governedIamPolicy: isSet(object.governedIamPolicy)
        ? AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy.fromJSON(object.governedIamPolicy)
        : undefined,
      consolidatedPolicy: isSet(object.consolidatedPolicy)
        ? AnalyzerOrgPolicy.fromJSON(object.consolidatedPolicy)
        : undefined,
      policyBundle: globalThis.Array.isArray(object?.policyBundle)
        ? object.policyBundle.map((e: any) => AnalyzerOrgPolicy.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset): unknown {
    const obj: any = {};
    if (message.governedResource !== undefined) {
      obj.governedResource = AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource.toJSON(message.governedResource);
    }
    if (message.governedIamPolicy !== undefined) {
      obj.governedIamPolicy = AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy.toJSON(
        message.governedIamPolicy,
      );
    }
    if (message.consolidatedPolicy !== undefined) {
      obj.consolidatedPolicy = AnalyzerOrgPolicy.toJSON(message.consolidatedPolicy);
    }
    if (message.policyBundle?.length) {
      obj.policyBundle = message.policyBundle.map((e) => AnalyzerOrgPolicy.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset>,
  ): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset {
    return AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset>,
  ): AnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset {
    const message = createBaseAnalyzeOrgPolicyGovernedAssetsResponse_GovernedAsset();
    message.governedResource = (object.governedResource !== undefined && object.governedResource !== null)
      ? AnalyzeOrgPolicyGovernedAssetsResponse_GovernedResource.fromPartial(object.governedResource)
      : undefined;
    message.governedIamPolicy = (object.governedIamPolicy !== undefined && object.governedIamPolicy !== null)
      ? AnalyzeOrgPolicyGovernedAssetsResponse_GovernedIamPolicy.fromPartial(object.governedIamPolicy)
      : undefined;
    message.consolidatedPolicy = (object.consolidatedPolicy !== undefined && object.consolidatedPolicy !== null)
      ? AnalyzerOrgPolicy.fromPartial(object.consolidatedPolicy)
      : undefined;
    message.policyBundle = object.policyBundle?.map((e) => AnalyzerOrgPolicy.fromPartial(e)) || [];
    return message;
  },
};

/** Asset service definition. */
export type AssetServiceDefinition = typeof AssetServiceDefinition;
export const AssetServiceDefinition = {
  name: "AssetService",
  fullName: "google.cloud.asset.v1.AssetService",
  methods: {
    /**
     * Exports assets with time and resource types to a given Cloud Storage
     * location/BigQuery table. For Cloud Storage location destinations, the
     * output format is newline-delimited JSON. Each line represents a
     * [google.cloud.asset.v1.Asset][google.cloud.asset.v1.Asset] in the JSON
     * format; for BigQuery table destinations, the output table stores the fields
     * in asset Protobuf as columns. This API implements the
     * [google.longrunning.Operation][google.longrunning.Operation] API, which
     * allows you to keep track of the export. We recommend intervals of at least
     * 2 seconds with exponential retry to poll the export operation result. For
     * regular-size resource parent, the export operation usually finishes within
     * 5 minutes.
     */
    exportAssets: {
      name: "ExportAssets",
      requestType: ExportAssetsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              87,
              10,
              42,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              97,
              115,
              115,
              101,
              116,
              46,
              118,
              49,
              46,
              69,
              120,
              112,
              111,
              114,
              116,
              65,
              115,
              115,
              101,
              116,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              41,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              97,
              115,
              115,
              101,
              116,
              46,
              118,
              49,
              46,
              69,
              120,
              112,
              111,
              114,
              116,
              65,
              115,
              115,
              101,
              116,
              115,
              82,
              101,
              113,
              117,
              101,
              115,
              116,
            ]),
          ],
          578365826: [
            Buffer.from([
              34,
              58,
              1,
              42,
              34,
              29,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
              65,
              115,
              115,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Lists assets with time and resource types and returns paged results in
     * response.
     */
    listAssets: {
      name: "ListAssets",
      requestType: ListAssetsRequest,
      requestStream: false,
      responseType: ListAssetsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              25,
              18,
              23,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              47,
              97,
              115,
              115,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Batch gets the update history of assets that overlap a time window.
     * For IAM_POLICY content, this API outputs history when the asset and its
     * attached IAM POLICY both exist. This can create gaps in the output history.
     * Otherwise, this API outputs history with asset in both non-delete or
     * deleted status.
     * If a specified asset does not exist, this API returns an INVALID_ARGUMENT
     * error.
     */
    batchGetAssetsHistory: {
      name: "BatchGetAssetsHistory",
      requestType: BatchGetAssetsHistoryRequest,
      requestStream: false,
      responseType: BatchGetAssetsHistoryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              40,
              18,
              38,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              58,
              98,
              97,
              116,
              99,
              104,
              71,
              101,
              116,
              65,
              115,
              115,
              101,
              116,
              115,
              72,
              105,
              115,
              116,
              111,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a feed in a parent project/folder/organization to listen to its
     * asset updates.
     */
    createFeed: {
      name: "CreateFeed",
      requestType: CreateFeedRequest,
      requestStream: false,
      responseType: Feed,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              27,
              58,
              1,
              42,
              34,
              22,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              47,
              102,
              101,
              101,
              100,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details about an asset feed. */
    getFeed: {
      name: "GetFeed",
      requestType: GetFeedRequest,
      requestStream: false,
      responseType: Feed,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              24,
              18,
              22,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              42,
              47,
              42,
              47,
              102,
              101,
              101,
              100,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists all asset feeds in a parent project/folder/organization. */
    listFeeds: {
      name: "ListFeeds",
      requestType: ListFeedsRequest,
      requestStream: false,
      responseType: ListFeedsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              24,
              18,
              22,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              47,
              102,
              101,
              101,
              100,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates an asset feed configuration. */
    updateFeed: {
      name: "UpdateFeed",
      requestType: UpdateFeedRequest,
      requestStream: false,
      responseType: Feed,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 102, 101, 101, 100])],
          578365826: [
            Buffer.from([
              32,
              58,
              1,
              42,
              50,
              27,
              47,
              118,
              49,
              47,
              123,
              102,
              101,
              101,
              100,
              46,
              110,
              97,
              109,
              101,
              61,
              42,
              47,
              42,
              47,
              102,
              101,
              101,
              100,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes an asset feed. */
    deleteFeed: {
      name: "DeleteFeed",
      requestType: DeleteFeedRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              24,
              42,
              22,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              42,
              47,
              42,
              47,
              102,
              101,
              101,
              100,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Searches all Google Cloud resources within the specified scope, such as a
     * project, folder, or organization. The caller must be granted the
     * `cloudasset.assets.searchAllResources` permission on the desired scope,
     * otherwise the request will be rejected.
     */
    searchAllResources: {
      name: "SearchAllResources",
      requestType: SearchAllResourcesRequest,
      requestStream: false,
      responseType: SearchAllResourcesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              115,
              99,
              111,
              112,
              101,
              44,
              113,
              117,
              101,
              114,
              121,
              44,
              97,
              115,
              115,
              101,
              116,
              95,
              116,
              121,
              112,
              101,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              36,
              18,
              34,
              47,
              118,
              49,
              47,
              123,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              115,
              101,
              97,
              114,
              99,
              104,
              65,
              108,
              108,
              82,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Searches all IAM policies within the specified scope, such as a project,
     * folder, or organization. The caller must be granted the
     * `cloudasset.assets.searchAllIamPolicies` permission on the desired scope,
     * otherwise the request will be rejected.
     */
    searchAllIamPolicies: {
      name: "SearchAllIamPolicies",
      requestType: SearchAllIamPoliciesRequest,
      requestStream: false,
      responseType: SearchAllIamPoliciesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([11, 115, 99, 111, 112, 101, 44, 113, 117, 101, 114, 121])],
          578365826: [
            Buffer.from([
              38,
              18,
              36,
              47,
              118,
              49,
              47,
              123,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              115,
              101,
              97,
              114,
              99,
              104,
              65,
              108,
              108,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Analyzes IAM policies to answer which identities have what accesses on
     * which resources.
     */
    analyzeIamPolicy: {
      name: "AnalyzeIamPolicy",
      requestType: AnalyzeIamPolicyRequest,
      requestStream: false,
      responseType: AnalyzeIamPolicyResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              49,
              47,
              123,
              97,
              110,
              97,
              108,
              121,
              115,
              105,
              115,
              95,
              113,
              117,
              101,
              114,
              121,
              46,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Analyzes IAM policies asynchronously to answer which identities have what
     * accesses on which resources, and writes the analysis results to a Google
     * Cloud Storage or a BigQuery destination. For Cloud Storage destination, the
     * output format is the JSON format that represents a
     * [AnalyzeIamPolicyResponse][google.cloud.asset.v1.AnalyzeIamPolicyResponse].
     * This method implements the
     * [google.longrunning.Operation][google.longrunning.Operation], which allows
     * you to track the operation status. We recommend intervals of at least 2
     * seconds with exponential backoff retry to poll the operation result. The
     * metadata contains the metadata for the long-running operation.
     */
    analyzeIamPolicyLongrunning: {
      name: "AnalyzeIamPolicyLongrunning",
      requestType: AnalyzeIamPolicyLongrunningRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              118,
              10,
              57,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              97,
              115,
              115,
              101,
              116,
              46,
              118,
              49,
              46,
              65,
              110,
              97,
              108,
              121,
              122,
              101,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              76,
              111,
              110,
              103,
              114,
              117,
              110,
              110,
              105,
              110,
              103,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              57,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              97,
              115,
              115,
              101,
              116,
              46,
              118,
              49,
              46,
              65,
              110,
              97,
              108,
              121,
              122,
              101,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              76,
              111,
              110,
              103,
              114,
              117,
              110,
              110,
              105,
              110,
              103,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              63,
              58,
              1,
              42,
              34,
              58,
              47,
              118,
              49,
              47,
              123,
              97,
              110,
              97,
              108,
              121,
              115,
              105,
              115,
              95,
              113,
              117,
              101,
              114,
              121,
              46,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              76,
              111,
              110,
              103,
              114,
              117,
              110,
              110,
              105,
              110,
              103,
            ]),
          ],
        },
      },
    },
    /**
     * Analyze moving a resource to a specified destination without kicking off
     * the actual move. The analysis is best effort depending on the user's
     * permissions of viewing different hierarchical policies and configurations.
     * The policies and configuration are subject to change before the actual
     * resource migration takes place.
     */
    analyzeMove: {
      name: "AnalyzeMove",
      requestType: AnalyzeMoveRequest,
      requestStream: false,
      responseType: AnalyzeMoveResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              32,
              18,
              30,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              77,
              111,
              118,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Issue a job that queries assets using a SQL statement compatible with
     * [BigQuery SQL](https://cloud.google.com/bigquery/docs/introduction-sql).
     *
     * If the query execution finishes within timeout and there's no pagination,
     * the full query results will be returned in the `QueryAssetsResponse`.
     *
     * Otherwise, full query results can be obtained by issuing extra requests
     * with the `job_reference` from the a previous `QueryAssets` call.
     *
     * Note, the query result has approximately 10 GB limitation enforced by
     * [BigQuery](https://cloud.google.com/bigquery/docs/best-practices-performance-output).
     * Queries return larger results will result in errors.
     */
    queryAssets: {
      name: "QueryAssets",
      requestType: QueryAssetsRequest,
      requestStream: false,
      responseType: QueryAssetsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              33,
              58,
              1,
              42,
              34,
              28,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              58,
              113,
              117,
              101,
              114,
              121,
              65,
              115,
              115,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Creates a saved query in a parent project/folder/organization. */
    createSavedQuery: {
      name: "CreateSavedQuery",
      requestType: CreateSavedQueryRequest,
      requestStream: false,
      responseType: SavedQuery,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              33,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              115,
              97,
              118,
              101,
              100,
              95,
              113,
              117,
              101,
              114,
              121,
              44,
              115,
              97,
              118,
              101,
              100,
              95,
              113,
              117,
              101,
              114,
              121,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              44,
              58,
              11,
              115,
              97,
              118,
              101,
              100,
              95,
              113,
              117,
              101,
              114,
              121,
              34,
              29,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              47,
              115,
              97,
              118,
              101,
              100,
              81,
              117,
              101,
              114,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details about a saved query. */
    getSavedQuery: {
      name: "GetSavedQuery",
      requestType: GetSavedQueryRequest,
      requestStream: false,
      responseType: SavedQuery,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              31,
              18,
              29,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              42,
              47,
              42,
              47,
              115,
              97,
              118,
              101,
              100,
              81,
              117,
              101,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists all saved queries in a parent project/folder/organization. */
    listSavedQueries: {
      name: "ListSavedQueries",
      requestType: ListSavedQueriesRequest,
      requestStream: false,
      responseType: ListSavedQueriesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              31,
              18,
              29,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              42,
              47,
              42,
              125,
              47,
              115,
              97,
              118,
              101,
              100,
              81,
              117,
              101,
              114,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a saved query. */
    updateSavedQuery: {
      name: "UpdateSavedQuery",
      requestType: UpdateSavedQueryRequest,
      requestStream: false,
      responseType: SavedQuery,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              115,
              97,
              118,
              101,
              100,
              95,
              113,
              117,
              101,
              114,
              121,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              56,
              58,
              11,
              115,
              97,
              118,
              101,
              100,
              95,
              113,
              117,
              101,
              114,
              121,
              50,
              41,
              47,
              118,
              49,
              47,
              123,
              115,
              97,
              118,
              101,
              100,
              95,
              113,
              117,
              101,
              114,
              121,
              46,
              110,
              97,
              109,
              101,
              61,
              42,
              47,
              42,
              47,
              115,
              97,
              118,
              101,
              100,
              81,
              117,
              101,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a saved query. */
    deleteSavedQuery: {
      name: "DeleteSavedQuery",
      requestType: DeleteSavedQueryRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              31,
              42,
              29,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              42,
              47,
              42,
              47,
              115,
              97,
              118,
              101,
              100,
              81,
              117,
              101,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets effective IAM policies for a batch of resources. */
    batchGetEffectiveIamPolicies: {
      name: "BatchGetEffectiveIamPolicies",
      requestType: BatchGetEffectiveIamPoliciesRequest,
      requestStream: false,
      responseType: BatchGetEffectiveIamPoliciesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              47,
              101,
              102,
              102,
              101,
              99,
              116,
              105,
              118,
              101,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              105,
              101,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              71,
              101,
              116,
            ]),
          ],
        },
      },
    },
    /** Analyzes organization policies under a scope. */
    analyzeOrgPolicies: {
      name: "AnalyzeOrgPolicies",
      requestType: AnalyzeOrgPoliciesRequest,
      requestStream: false,
      responseType: AnalyzeOrgPoliciesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              115,
              99,
              111,
              112,
              101,
              44,
              99,
              111,
              110,
              115,
              116,
              114,
              97,
              105,
              110,
              116,
              44,
              102,
              105,
              108,
              116,
              101,
              114,
            ]),
          ],
          578365826: [
            Buffer.from([
              36,
              18,
              34,
              47,
              118,
              49,
              47,
              123,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              79,
              114,
              103,
              80,
              111,
              108,
              105,
              99,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Analyzes organization policies governed containers (projects, folders or
     * organization) under a scope.
     */
    analyzeOrgPolicyGovernedContainers: {
      name: "AnalyzeOrgPolicyGovernedContainers",
      requestType: AnalyzeOrgPolicyGovernedContainersRequest,
      requestStream: false,
      responseType: AnalyzeOrgPolicyGovernedContainersResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              115,
              99,
              111,
              112,
              101,
              44,
              99,
              111,
              110,
              115,
              116,
              114,
              97,
              105,
              110,
              116,
              44,
              102,
              105,
              108,
              116,
              101,
              114,
            ]),
          ],
          578365826: [
            Buffer.from([
              52,
              18,
              50,
              47,
              118,
              49,
              47,
              123,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              79,
              114,
              103,
              80,
              111,
              108,
              105,
              99,
              121,
              71,
              111,
              118,
              101,
              114,
              110,
              101,
              100,
              67,
              111,
              110,
              116,
              97,
              105,
              110,
              101,
              114,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Analyzes organization policies governed assets (Google Cloud resources or
     * policies) under a scope. This RPC supports custom constraints and the
     * following canned constraints:
     *
     * * constraints/ainotebooks.accessMode
     * * constraints/ainotebooks.disableFileDownloads
     * * constraints/ainotebooks.disableRootAccess
     * * constraints/ainotebooks.disableTerminal
     * * constraints/ainotebooks.environmentOptions
     * * constraints/ainotebooks.requireAutoUpgradeSchedule
     * * constraints/ainotebooks.restrictVpcNetworks
     * * constraints/compute.disableGuestAttributesAccess
     * * constraints/compute.disableInstanceDataAccessApis
     * * constraints/compute.disableNestedVirtualization
     * * constraints/compute.disableSerialPortAccess
     * * constraints/compute.disableSerialPortLogging
     * * constraints/compute.disableVpcExternalIpv6
     * * constraints/compute.requireOsLogin
     * * constraints/compute.requireShieldedVm
     * * constraints/compute.restrictLoadBalancerCreationForTypes
     * * constraints/compute.restrictProtocolForwardingCreationForTypes
     * * constraints/compute.restrictXpnProjectLienRemoval
     * * constraints/compute.setNewProjectDefaultToZonalDNSOnly
     * * constraints/compute.skipDefaultNetworkCreation
     * * constraints/compute.trustedImageProjects
     * * constraints/compute.vmCanIpForward
     * * constraints/compute.vmExternalIpAccess
     * * constraints/gcp.detailedAuditLoggingMode
     * * constraints/gcp.resourceLocations
     * * constraints/iam.allowedPolicyMemberDomains
     * * constraints/iam.automaticIamGrantsForDefaultServiceAccounts
     * * constraints/iam.disableServiceAccountCreation
     * * constraints/iam.disableServiceAccountKeyCreation
     * * constraints/iam.disableServiceAccountKeyUpload
     * * constraints/iam.restrictCrossProjectServiceAccountLienRemoval
     * * constraints/iam.serviceAccountKeyExpiryHours
     * * constraints/resourcemanager.accessBoundaries
     * * constraints/resourcemanager.allowedExportDestinations
     * * constraints/sql.restrictAuthorizedNetworks
     * * constraints/sql.restrictNoncompliantDiagnosticDataAccess
     * * constraints/sql.restrictNoncompliantResourceCreation
     * * constraints/sql.restrictPublicIp
     * * constraints/storage.publicAccessPrevention
     * * constraints/storage.restrictAuthTypes
     * * constraints/storage.uniformBucketLevelAccess
     *
     * This RPC only returns either resources of types [supported by search
     * APIs](https://cloud.google.com/asset-inventory/docs/supported-asset-types)
     * or IAM policies.
     */
    analyzeOrgPolicyGovernedAssets: {
      name: "AnalyzeOrgPolicyGovernedAssets",
      requestType: AnalyzeOrgPolicyGovernedAssetsRequest,
      requestStream: false,
      responseType: AnalyzeOrgPolicyGovernedAssetsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              115,
              99,
              111,
              112,
              101,
              44,
              99,
              111,
              110,
              115,
              116,
              114,
              97,
              105,
              110,
              116,
              44,
              102,
              105,
              108,
              116,
              101,
              114,
            ]),
          ],
          578365826: [
            Buffer.from([
              48,
              18,
              46,
              47,
              118,
              49,
              47,
              123,
              115,
              99,
              111,
              112,
              101,
              61,
              42,
              47,
              42,
              125,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              79,
              114,
              103,
              80,
              111,
              108,
              105,
              99,
              121,
              71,
              111,
              118,
              101,
              114,
              110,
              101,
              100,
              65,
              115,
              115,
              101,
              116,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface AssetServiceImplementation<CallContextExt = {}> {
  /**
   * Exports assets with time and resource types to a given Cloud Storage
   * location/BigQuery table. For Cloud Storage location destinations, the
   * output format is newline-delimited JSON. Each line represents a
   * [google.cloud.asset.v1.Asset][google.cloud.asset.v1.Asset] in the JSON
   * format; for BigQuery table destinations, the output table stores the fields
   * in asset Protobuf as columns. This API implements the
   * [google.longrunning.Operation][google.longrunning.Operation] API, which
   * allows you to keep track of the export. We recommend intervals of at least
   * 2 seconds with exponential retry to poll the export operation result. For
   * regular-size resource parent, the export operation usually finishes within
   * 5 minutes.
   */
  exportAssets(request: ExportAssetsRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Lists assets with time and resource types and returns paged results in
   * response.
   */
  listAssets(
    request: ListAssetsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListAssetsResponse>>;
  /**
   * Batch gets the update history of assets that overlap a time window.
   * For IAM_POLICY content, this API outputs history when the asset and its
   * attached IAM POLICY both exist. This can create gaps in the output history.
   * Otherwise, this API outputs history with asset in both non-delete or
   * deleted status.
   * If a specified asset does not exist, this API returns an INVALID_ARGUMENT
   * error.
   */
  batchGetAssetsHistory(
    request: BatchGetAssetsHistoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BatchGetAssetsHistoryResponse>>;
  /**
   * Creates a feed in a parent project/folder/organization to listen to its
   * asset updates.
   */
  createFeed(request: CreateFeedRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Feed>>;
  /** Gets details about an asset feed. */
  getFeed(request: GetFeedRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Feed>>;
  /** Lists all asset feeds in a parent project/folder/organization. */
  listFeeds(request: ListFeedsRequest, context: CallContext & CallContextExt): Promise<DeepPartial<ListFeedsResponse>>;
  /** Updates an asset feed configuration. */
  updateFeed(request: UpdateFeedRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Feed>>;
  /** Deletes an asset feed. */
  deleteFeed(request: DeleteFeedRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Searches all Google Cloud resources within the specified scope, such as a
   * project, folder, or organization. The caller must be granted the
   * `cloudasset.assets.searchAllResources` permission on the desired scope,
   * otherwise the request will be rejected.
   */
  searchAllResources(
    request: SearchAllResourcesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SearchAllResourcesResponse>>;
  /**
   * Searches all IAM policies within the specified scope, such as a project,
   * folder, or organization. The caller must be granted the
   * `cloudasset.assets.searchAllIamPolicies` permission on the desired scope,
   * otherwise the request will be rejected.
   */
  searchAllIamPolicies(
    request: SearchAllIamPoliciesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SearchAllIamPoliciesResponse>>;
  /**
   * Analyzes IAM policies to answer which identities have what accesses on
   * which resources.
   */
  analyzeIamPolicy(
    request: AnalyzeIamPolicyRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeIamPolicyResponse>>;
  /**
   * Analyzes IAM policies asynchronously to answer which identities have what
   * accesses on which resources, and writes the analysis results to a Google
   * Cloud Storage or a BigQuery destination. For Cloud Storage destination, the
   * output format is the JSON format that represents a
   * [AnalyzeIamPolicyResponse][google.cloud.asset.v1.AnalyzeIamPolicyResponse].
   * This method implements the
   * [google.longrunning.Operation][google.longrunning.Operation], which allows
   * you to track the operation status. We recommend intervals of at least 2
   * seconds with exponential backoff retry to poll the operation result. The
   * metadata contains the metadata for the long-running operation.
   */
  analyzeIamPolicyLongrunning(
    request: AnalyzeIamPolicyLongrunningRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Analyze moving a resource to a specified destination without kicking off
   * the actual move. The analysis is best effort depending on the user's
   * permissions of viewing different hierarchical policies and configurations.
   * The policies and configuration are subject to change before the actual
   * resource migration takes place.
   */
  analyzeMove(
    request: AnalyzeMoveRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeMoveResponse>>;
  /**
   * Issue a job that queries assets using a SQL statement compatible with
   * [BigQuery SQL](https://cloud.google.com/bigquery/docs/introduction-sql).
   *
   * If the query execution finishes within timeout and there's no pagination,
   * the full query results will be returned in the `QueryAssetsResponse`.
   *
   * Otherwise, full query results can be obtained by issuing extra requests
   * with the `job_reference` from the a previous `QueryAssets` call.
   *
   * Note, the query result has approximately 10 GB limitation enforced by
   * [BigQuery](https://cloud.google.com/bigquery/docs/best-practices-performance-output).
   * Queries return larger results will result in errors.
   */
  queryAssets(
    request: QueryAssetsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<QueryAssetsResponse>>;
  /** Creates a saved query in a parent project/folder/organization. */
  createSavedQuery(
    request: CreateSavedQueryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SavedQuery>>;
  /** Gets details about a saved query. */
  getSavedQuery(request: GetSavedQueryRequest, context: CallContext & CallContextExt): Promise<DeepPartial<SavedQuery>>;
  /** Lists all saved queries in a parent project/folder/organization. */
  listSavedQueries(
    request: ListSavedQueriesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListSavedQueriesResponse>>;
  /** Updates a saved query. */
  updateSavedQuery(
    request: UpdateSavedQueryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SavedQuery>>;
  /** Deletes a saved query. */
  deleteSavedQuery(
    request: DeleteSavedQueryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Gets effective IAM policies for a batch of resources. */
  batchGetEffectiveIamPolicies(
    request: BatchGetEffectiveIamPoliciesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BatchGetEffectiveIamPoliciesResponse>>;
  /** Analyzes organization policies under a scope. */
  analyzeOrgPolicies(
    request: AnalyzeOrgPoliciesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeOrgPoliciesResponse>>;
  /**
   * Analyzes organization policies governed containers (projects, folders or
   * organization) under a scope.
   */
  analyzeOrgPolicyGovernedContainers(
    request: AnalyzeOrgPolicyGovernedContainersRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeOrgPolicyGovernedContainersResponse>>;
  /**
   * Analyzes organization policies governed assets (Google Cloud resources or
   * policies) under a scope. This RPC supports custom constraints and the
   * following canned constraints:
   *
   * * constraints/ainotebooks.accessMode
   * * constraints/ainotebooks.disableFileDownloads
   * * constraints/ainotebooks.disableRootAccess
   * * constraints/ainotebooks.disableTerminal
   * * constraints/ainotebooks.environmentOptions
   * * constraints/ainotebooks.requireAutoUpgradeSchedule
   * * constraints/ainotebooks.restrictVpcNetworks
   * * constraints/compute.disableGuestAttributesAccess
   * * constraints/compute.disableInstanceDataAccessApis
   * * constraints/compute.disableNestedVirtualization
   * * constraints/compute.disableSerialPortAccess
   * * constraints/compute.disableSerialPortLogging
   * * constraints/compute.disableVpcExternalIpv6
   * * constraints/compute.requireOsLogin
   * * constraints/compute.requireShieldedVm
   * * constraints/compute.restrictLoadBalancerCreationForTypes
   * * constraints/compute.restrictProtocolForwardingCreationForTypes
   * * constraints/compute.restrictXpnProjectLienRemoval
   * * constraints/compute.setNewProjectDefaultToZonalDNSOnly
   * * constraints/compute.skipDefaultNetworkCreation
   * * constraints/compute.trustedImageProjects
   * * constraints/compute.vmCanIpForward
   * * constraints/compute.vmExternalIpAccess
   * * constraints/gcp.detailedAuditLoggingMode
   * * constraints/gcp.resourceLocations
   * * constraints/iam.allowedPolicyMemberDomains
   * * constraints/iam.automaticIamGrantsForDefaultServiceAccounts
   * * constraints/iam.disableServiceAccountCreation
   * * constraints/iam.disableServiceAccountKeyCreation
   * * constraints/iam.disableServiceAccountKeyUpload
   * * constraints/iam.restrictCrossProjectServiceAccountLienRemoval
   * * constraints/iam.serviceAccountKeyExpiryHours
   * * constraints/resourcemanager.accessBoundaries
   * * constraints/resourcemanager.allowedExportDestinations
   * * constraints/sql.restrictAuthorizedNetworks
   * * constraints/sql.restrictNoncompliantDiagnosticDataAccess
   * * constraints/sql.restrictNoncompliantResourceCreation
   * * constraints/sql.restrictPublicIp
   * * constraints/storage.publicAccessPrevention
   * * constraints/storage.restrictAuthTypes
   * * constraints/storage.uniformBucketLevelAccess
   *
   * This RPC only returns either resources of types [supported by search
   * APIs](https://cloud.google.com/asset-inventory/docs/supported-asset-types)
   * or IAM policies.
   */
  analyzeOrgPolicyGovernedAssets(
    request: AnalyzeOrgPolicyGovernedAssetsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeOrgPolicyGovernedAssetsResponse>>;
}

export interface AssetServiceClient<CallOptionsExt = {}> {
  /**
   * Exports assets with time and resource types to a given Cloud Storage
   * location/BigQuery table. For Cloud Storage location destinations, the
   * output format is newline-delimited JSON. Each line represents a
   * [google.cloud.asset.v1.Asset][google.cloud.asset.v1.Asset] in the JSON
   * format; for BigQuery table destinations, the output table stores the fields
   * in asset Protobuf as columns. This API implements the
   * [google.longrunning.Operation][google.longrunning.Operation] API, which
   * allows you to keep track of the export. We recommend intervals of at least
   * 2 seconds with exponential retry to poll the export operation result. For
   * regular-size resource parent, the export operation usually finishes within
   * 5 minutes.
   */
  exportAssets(request: DeepPartial<ExportAssetsRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Lists assets with time and resource types and returns paged results in
   * response.
   */
  listAssets(
    request: DeepPartial<ListAssetsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListAssetsResponse>;
  /**
   * Batch gets the update history of assets that overlap a time window.
   * For IAM_POLICY content, this API outputs history when the asset and its
   * attached IAM POLICY both exist. This can create gaps in the output history.
   * Otherwise, this API outputs history with asset in both non-delete or
   * deleted status.
   * If a specified asset does not exist, this API returns an INVALID_ARGUMENT
   * error.
   */
  batchGetAssetsHistory(
    request: DeepPartial<BatchGetAssetsHistoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BatchGetAssetsHistoryResponse>;
  /**
   * Creates a feed in a parent project/folder/organization to listen to its
   * asset updates.
   */
  createFeed(request: DeepPartial<CreateFeedRequest>, options?: CallOptions & CallOptionsExt): Promise<Feed>;
  /** Gets details about an asset feed. */
  getFeed(request: DeepPartial<GetFeedRequest>, options?: CallOptions & CallOptionsExt): Promise<Feed>;
  /** Lists all asset feeds in a parent project/folder/organization. */
  listFeeds(request: DeepPartial<ListFeedsRequest>, options?: CallOptions & CallOptionsExt): Promise<ListFeedsResponse>;
  /** Updates an asset feed configuration. */
  updateFeed(request: DeepPartial<UpdateFeedRequest>, options?: CallOptions & CallOptionsExt): Promise<Feed>;
  /** Deletes an asset feed. */
  deleteFeed(request: DeepPartial<DeleteFeedRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Searches all Google Cloud resources within the specified scope, such as a
   * project, folder, or organization. The caller must be granted the
   * `cloudasset.assets.searchAllResources` permission on the desired scope,
   * otherwise the request will be rejected.
   */
  searchAllResources(
    request: DeepPartial<SearchAllResourcesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SearchAllResourcesResponse>;
  /**
   * Searches all IAM policies within the specified scope, such as a project,
   * folder, or organization. The caller must be granted the
   * `cloudasset.assets.searchAllIamPolicies` permission on the desired scope,
   * otherwise the request will be rejected.
   */
  searchAllIamPolicies(
    request: DeepPartial<SearchAllIamPoliciesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SearchAllIamPoliciesResponse>;
  /**
   * Analyzes IAM policies to answer which identities have what accesses on
   * which resources.
   */
  analyzeIamPolicy(
    request: DeepPartial<AnalyzeIamPolicyRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeIamPolicyResponse>;
  /**
   * Analyzes IAM policies asynchronously to answer which identities have what
   * accesses on which resources, and writes the analysis results to a Google
   * Cloud Storage or a BigQuery destination. For Cloud Storage destination, the
   * output format is the JSON format that represents a
   * [AnalyzeIamPolicyResponse][google.cloud.asset.v1.AnalyzeIamPolicyResponse].
   * This method implements the
   * [google.longrunning.Operation][google.longrunning.Operation], which allows
   * you to track the operation status. We recommend intervals of at least 2
   * seconds with exponential backoff retry to poll the operation result. The
   * metadata contains the metadata for the long-running operation.
   */
  analyzeIamPolicyLongrunning(
    request: DeepPartial<AnalyzeIamPolicyLongrunningRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Analyze moving a resource to a specified destination without kicking off
   * the actual move. The analysis is best effort depending on the user's
   * permissions of viewing different hierarchical policies and configurations.
   * The policies and configuration are subject to change before the actual
   * resource migration takes place.
   */
  analyzeMove(
    request: DeepPartial<AnalyzeMoveRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeMoveResponse>;
  /**
   * Issue a job that queries assets using a SQL statement compatible with
   * [BigQuery SQL](https://cloud.google.com/bigquery/docs/introduction-sql).
   *
   * If the query execution finishes within timeout and there's no pagination,
   * the full query results will be returned in the `QueryAssetsResponse`.
   *
   * Otherwise, full query results can be obtained by issuing extra requests
   * with the `job_reference` from the a previous `QueryAssets` call.
   *
   * Note, the query result has approximately 10 GB limitation enforced by
   * [BigQuery](https://cloud.google.com/bigquery/docs/best-practices-performance-output).
   * Queries return larger results will result in errors.
   */
  queryAssets(
    request: DeepPartial<QueryAssetsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<QueryAssetsResponse>;
  /** Creates a saved query in a parent project/folder/organization. */
  createSavedQuery(
    request: DeepPartial<CreateSavedQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SavedQuery>;
  /** Gets details about a saved query. */
  getSavedQuery(
    request: DeepPartial<GetSavedQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SavedQuery>;
  /** Lists all saved queries in a parent project/folder/organization. */
  listSavedQueries(
    request: DeepPartial<ListSavedQueriesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListSavedQueriesResponse>;
  /** Updates a saved query. */
  updateSavedQuery(
    request: DeepPartial<UpdateSavedQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SavedQuery>;
  /** Deletes a saved query. */
  deleteSavedQuery(
    request: DeepPartial<DeleteSavedQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Gets effective IAM policies for a batch of resources. */
  batchGetEffectiveIamPolicies(
    request: DeepPartial<BatchGetEffectiveIamPoliciesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BatchGetEffectiveIamPoliciesResponse>;
  /** Analyzes organization policies under a scope. */
  analyzeOrgPolicies(
    request: DeepPartial<AnalyzeOrgPoliciesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeOrgPoliciesResponse>;
  /**
   * Analyzes organization policies governed containers (projects, folders or
   * organization) under a scope.
   */
  analyzeOrgPolicyGovernedContainers(
    request: DeepPartial<AnalyzeOrgPolicyGovernedContainersRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeOrgPolicyGovernedContainersResponse>;
  /**
   * Analyzes organization policies governed assets (Google Cloud resources or
   * policies) under a scope. This RPC supports custom constraints and the
   * following canned constraints:
   *
   * * constraints/ainotebooks.accessMode
   * * constraints/ainotebooks.disableFileDownloads
   * * constraints/ainotebooks.disableRootAccess
   * * constraints/ainotebooks.disableTerminal
   * * constraints/ainotebooks.environmentOptions
   * * constraints/ainotebooks.requireAutoUpgradeSchedule
   * * constraints/ainotebooks.restrictVpcNetworks
   * * constraints/compute.disableGuestAttributesAccess
   * * constraints/compute.disableInstanceDataAccessApis
   * * constraints/compute.disableNestedVirtualization
   * * constraints/compute.disableSerialPortAccess
   * * constraints/compute.disableSerialPortLogging
   * * constraints/compute.disableVpcExternalIpv6
   * * constraints/compute.requireOsLogin
   * * constraints/compute.requireShieldedVm
   * * constraints/compute.restrictLoadBalancerCreationForTypes
   * * constraints/compute.restrictProtocolForwardingCreationForTypes
   * * constraints/compute.restrictXpnProjectLienRemoval
   * * constraints/compute.setNewProjectDefaultToZonalDNSOnly
   * * constraints/compute.skipDefaultNetworkCreation
   * * constraints/compute.trustedImageProjects
   * * constraints/compute.vmCanIpForward
   * * constraints/compute.vmExternalIpAccess
   * * constraints/gcp.detailedAuditLoggingMode
   * * constraints/gcp.resourceLocations
   * * constraints/iam.allowedPolicyMemberDomains
   * * constraints/iam.automaticIamGrantsForDefaultServiceAccounts
   * * constraints/iam.disableServiceAccountCreation
   * * constraints/iam.disableServiceAccountKeyCreation
   * * constraints/iam.disableServiceAccountKeyUpload
   * * constraints/iam.restrictCrossProjectServiceAccountLienRemoval
   * * constraints/iam.serviceAccountKeyExpiryHours
   * * constraints/resourcemanager.accessBoundaries
   * * constraints/resourcemanager.allowedExportDestinations
   * * constraints/sql.restrictAuthorizedNetworks
   * * constraints/sql.restrictNoncompliantDiagnosticDataAccess
   * * constraints/sql.restrictNoncompliantResourceCreation
   * * constraints/sql.restrictPublicIp
   * * constraints/storage.publicAccessPrevention
   * * constraints/storage.restrictAuthTypes
   * * constraints/storage.uniformBucketLevelAccess
   *
   * This RPC only returns either resources of types [supported by search
   * APIs](https://cloud.google.com/asset-inventory/docs/supported-asset-types)
   * or IAM policies.
   */
  analyzeOrgPolicyGovernedAssets(
    request: DeepPartial<AnalyzeOrgPolicyGovernedAssetsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeOrgPolicyGovernedAssetsResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
