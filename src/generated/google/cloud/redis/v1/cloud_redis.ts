// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/redis/v1/cloud_redis.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { DayOfWeek, dayOfWeekFromJSON, dayOfWeekToJSON } from "../../../type/dayofweek.js";
import { TimeOfDay } from "../../../type/timeofday.js";

export const protobufPackage = "google.cloud.redis.v1";

/** Node specific properties. */
export interface NodeInfo {
  /** Output only. Node identifying string. e.g. 'node-0', 'node-1' */
  id: string;
  /** Output only. Location of the node. */
  zone: string;
}

/** A Memorystore for Redis instance. */
export interface Instance {
  /**
   * Required. Unique name of the resource in this scope including project and
   * location using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   *
   * Note: Redis instances are managed and addressed at regional level so
   * location_id here refers to a GCP region; however, users may choose which
   * specific zone (or collection of zones for cross-zone instances) an instance
   * should be provisioned in. Refer to
   * [location_id][google.cloud.redis.v1.Instance.location_id] and
   * [alternative_location_id][google.cloud.redis.v1.Instance.alternative_location_id]
   * fields for more details.
   */
  name: string;
  /** An arbitrary and optional user-provided name for the instance. */
  displayName: string;
  /** Resource labels to represent user provided metadata */
  labels: { [key: string]: string };
  /**
   * Optional. The zone where the instance will be provisioned. If not provided,
   * the service will choose a zone from the specified region for the instance.
   * For standard tier, additional nodes will be added across multiple zones for
   * protection against zonal failures. If specified, at least one node will be
   * provisioned in this zone.
   */
  locationId: string;
  /**
   * Optional. If specified, at least one node will be provisioned in this zone
   * in addition to the zone specified in location_id. Only applicable to
   * standard tier. If provided, it must be a different zone from the one
   * provided in [location_id]. Additional nodes beyond the first 2 will be
   * placed in zones selected by the service.
   */
  alternativeLocationId: string;
  /**
   * Optional. The version of Redis software.
   * If not provided, latest supported version will be used. Currently, the
   * supported values are:
   *
   *  *   `REDIS_3_2` for Redis 3.2 compatibility
   *  *   `REDIS_4_0` for Redis 4.0 compatibility (default)
   *  *   `REDIS_5_0` for Redis 5.0 compatibility
   *  *   `REDIS_6_X` for Redis 6.x compatibility
   */
  redisVersion: string;
  /**
   * Optional. For DIRECT_PEERING mode, the CIDR range of internal addresses
   * that are reserved for this instance. Range must
   * be unique and non-overlapping with existing subnets in an authorized
   * network. For PRIVATE_SERVICE_ACCESS mode, the name of one allocated IP
   * address ranges associated with this private service access connection.
   * If not provided, the service will choose an unused /29 block, for
   * example, 10.0.0.0/29 or 192.168.0.0/29.  For READ_REPLICAS_ENABLED
   * the default block size is /28.
   */
  reservedIpRange: string;
  /**
   * Optional. Additional IP range for node placement. Required when enabling
   * read replicas on an existing instance. For DIRECT_PEERING mode value must
   * be a CIDR range of size /28, or "auto". For PRIVATE_SERVICE_ACCESS mode
   * value must be the name of an allocated address range associated with the
   * private service access connection, or "auto".
   */
  secondaryIpRange: string;
  /**
   * Output only. Hostname or IP address of the exposed Redis endpoint used by
   * clients to connect to the service.
   */
  host: string;
  /** Output only. The port number of the exposed Redis endpoint. */
  port: number;
  /**
   * Output only. The current zone where the Redis primary node is located. In
   * basic tier, this will always be the same as [location_id]. In
   * standard tier, this can be the zone of any node in the instance.
   */
  currentLocationId: string;
  /** Output only. The time the instance was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The current state of this instance. */
  state: Instance_State;
  /**
   * Output only. Additional information about the current status of this
   * instance, if available.
   */
  statusMessage: string;
  /**
   * Optional. Redis configuration parameters, according to
   * http://redis.io/topics/config. Currently, the only supported parameters
   * are:
   *
   *  Redis version 3.2 and newer:
   *
   *  *   maxmemory-policy
   *  *   notify-keyspace-events
   *
   *  Redis version 4.0 and newer:
   *
   *  *   activedefrag
   *  *   lfu-decay-time
   *  *   lfu-log-factor
   *  *   maxmemory-gb
   *
   *  Redis version 5.0 and newer:
   *
   *  *   stream-node-max-bytes
   *  *   stream-node-max-entries
   */
  redisConfigs: { [key: string]: string };
  /** Required. The service tier of the instance. */
  tier: Instance_Tier;
  /** Required. Redis memory size in GiB. */
  memorySizeGb: number;
  /**
   * Optional. The full name of the Google Compute Engine
   * [network](https://cloud.google.com/vpc/docs/vpc) to which the
   * instance is connected. If left unspecified, the `default` network
   * will be used.
   */
  authorizedNetwork: string;
  /**
   * Output only. Cloud IAM identity used by import / export operations to
   * transfer data to/from Cloud Storage. Format is
   * "serviceAccount:<service_account_email>". The value may change over time
   * for a given instance so should be checked before each import/export
   * operation.
   */
  persistenceIamIdentity: string;
  /**
   * Optional. The network connect mode of the Redis instance.
   * If not provided, the connect mode defaults to DIRECT_PEERING.
   */
  connectMode: Instance_ConnectMode;
  /**
   * Optional. Indicates whether OSS Redis AUTH is enabled for the instance. If
   * set to "true" AUTH is enabled on the instance. Default value is "false"
   * meaning AUTH is disabled.
   */
  authEnabled: boolean;
  /** Output only. List of server CA certificates for the instance. */
  serverCaCerts: TlsCertificate[];
  /**
   * Optional. The TLS mode of the Redis instance.
   * If not provided, TLS is disabled for the instance.
   */
  transitEncryptionMode: Instance_TransitEncryptionMode;
  /**
   * Optional. The maintenance policy for the instance. If not provided,
   * maintenance events can be performed at any time.
   */
  maintenancePolicy:
    | MaintenancePolicy
    | undefined;
  /**
   * Output only. Date and time of upcoming maintenance events which have been
   * scheduled.
   */
  maintenanceSchedule:
    | MaintenanceSchedule
    | undefined;
  /**
   * Optional. The number of replica nodes. The valid range for the Standard
   * Tier with read replicas enabled is [1-5] and defaults to 2. If read
   * replicas are not enabled for a Standard Tier instance, the only valid value
   * is 1 and the default is 1. The valid value for basic tier is 0 and the
   * default is also 0.
   */
  replicaCount: number;
  /** Output only. Info per node. */
  nodes: NodeInfo[];
  /**
   * Output only. Hostname or IP address of the exposed readonly Redis
   * endpoint. Standard tier only. Targets all healthy replica nodes in
   * instance. Replication is asynchronous and replica nodes will exhibit some
   * lag behind the primary. Write requests must target 'host'.
   */
  readEndpoint: string;
  /**
   * Output only. The port number of the exposed readonly redis
   * endpoint. Standard tier only. Write requests should target 'port'.
   */
  readEndpointPort: number;
  /**
   * Optional. Read replicas mode for the instance. Defaults to
   * READ_REPLICAS_DISABLED.
   */
  readReplicasMode: Instance_ReadReplicasMode;
  /**
   * Optional. The KMS key reference that the customer provides when trying to
   * create the instance.
   */
  customerManagedKey: string;
  /** Optional. Persistence configuration parameters */
  persistenceConfig:
    | PersistenceConfig
    | undefined;
  /** Optional. reasons that causes instance in "SUSPENDED" state. */
  suspensionReasons: Instance_SuspensionReason[];
  /**
   * Optional. The self service update maintenance version.
   * The version is date based such as "20210712_00_00".
   */
  maintenanceVersion: string;
  /**
   * Optional. The available maintenance versions that an instance could update
   * to.
   */
  availableMaintenanceVersions: string[];
}

/** Represents the different states of a Redis instance. */
export enum Instance_State {
  /** STATE_UNSPECIFIED - Not set. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - Redis instance is being created. */
  CREATING = 1,
  /** READY - Redis instance has been created and is fully usable. */
  READY = 2,
  /**
   * UPDATING - Redis instance configuration is being updated. Certain kinds of updates
   * may cause the instance to become unusable while the update is in
   * progress.
   */
  UPDATING = 3,
  /** DELETING - Redis instance is being deleted. */
  DELETING = 4,
  /** REPAIRING - Redis instance is being repaired and may be unusable. */
  REPAIRING = 5,
  /** MAINTENANCE - Maintenance is being performed on this Redis instance. */
  MAINTENANCE = 6,
  /** IMPORTING - Redis instance is importing data (availability may be affected). */
  IMPORTING = 8,
  /** FAILING_OVER - Redis instance is failing over (availability may be affected). */
  FAILING_OVER = 9,
  UNRECOGNIZED = -1,
}

export function instance_StateFromJSON(object: any): Instance_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Instance_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Instance_State.CREATING;
    case 2:
    case "READY":
      return Instance_State.READY;
    case 3:
    case "UPDATING":
      return Instance_State.UPDATING;
    case 4:
    case "DELETING":
      return Instance_State.DELETING;
    case 5:
    case "REPAIRING":
      return Instance_State.REPAIRING;
    case 6:
    case "MAINTENANCE":
      return Instance_State.MAINTENANCE;
    case 8:
    case "IMPORTING":
      return Instance_State.IMPORTING;
    case 9:
    case "FAILING_OVER":
      return Instance_State.FAILING_OVER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_State.UNRECOGNIZED;
  }
}

export function instance_StateToJSON(object: Instance_State): string {
  switch (object) {
    case Instance_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Instance_State.CREATING:
      return "CREATING";
    case Instance_State.READY:
      return "READY";
    case Instance_State.UPDATING:
      return "UPDATING";
    case Instance_State.DELETING:
      return "DELETING";
    case Instance_State.REPAIRING:
      return "REPAIRING";
    case Instance_State.MAINTENANCE:
      return "MAINTENANCE";
    case Instance_State.IMPORTING:
      return "IMPORTING";
    case Instance_State.FAILING_OVER:
      return "FAILING_OVER";
    case Instance_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available service tiers to choose from */
export enum Instance_Tier {
  /** TIER_UNSPECIFIED - Not set. */
  TIER_UNSPECIFIED = 0,
  /** BASIC - BASIC tier: standalone instance */
  BASIC = 1,
  /** STANDARD_HA - STANDARD_HA tier: highly available primary/replica instances */
  STANDARD_HA = 3,
  UNRECOGNIZED = -1,
}

export function instance_TierFromJSON(object: any): Instance_Tier {
  switch (object) {
    case 0:
    case "TIER_UNSPECIFIED":
      return Instance_Tier.TIER_UNSPECIFIED;
    case 1:
    case "BASIC":
      return Instance_Tier.BASIC;
    case 3:
    case "STANDARD_HA":
      return Instance_Tier.STANDARD_HA;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_Tier.UNRECOGNIZED;
  }
}

export function instance_TierToJSON(object: Instance_Tier): string {
  switch (object) {
    case Instance_Tier.TIER_UNSPECIFIED:
      return "TIER_UNSPECIFIED";
    case Instance_Tier.BASIC:
      return "BASIC";
    case Instance_Tier.STANDARD_HA:
      return "STANDARD_HA";
    case Instance_Tier.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available connection modes. */
export enum Instance_ConnectMode {
  /** CONNECT_MODE_UNSPECIFIED - Not set. */
  CONNECT_MODE_UNSPECIFIED = 0,
  /** DIRECT_PEERING - Connect via direct peering to the Memorystore for Redis hosted service. */
  DIRECT_PEERING = 1,
  /**
   * PRIVATE_SERVICE_ACCESS - Connect your Memorystore for Redis instance using Private Service
   * Access. Private services access provides an IP address range for multiple
   * Google Cloud services, including Memorystore.
   */
  PRIVATE_SERVICE_ACCESS = 2,
  UNRECOGNIZED = -1,
}

export function instance_ConnectModeFromJSON(object: any): Instance_ConnectMode {
  switch (object) {
    case 0:
    case "CONNECT_MODE_UNSPECIFIED":
      return Instance_ConnectMode.CONNECT_MODE_UNSPECIFIED;
    case 1:
    case "DIRECT_PEERING":
      return Instance_ConnectMode.DIRECT_PEERING;
    case 2:
    case "PRIVATE_SERVICE_ACCESS":
      return Instance_ConnectMode.PRIVATE_SERVICE_ACCESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_ConnectMode.UNRECOGNIZED;
  }
}

export function instance_ConnectModeToJSON(object: Instance_ConnectMode): string {
  switch (object) {
    case Instance_ConnectMode.CONNECT_MODE_UNSPECIFIED:
      return "CONNECT_MODE_UNSPECIFIED";
    case Instance_ConnectMode.DIRECT_PEERING:
      return "DIRECT_PEERING";
    case Instance_ConnectMode.PRIVATE_SERVICE_ACCESS:
      return "PRIVATE_SERVICE_ACCESS";
    case Instance_ConnectMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available TLS modes. */
export enum Instance_TransitEncryptionMode {
  /** TRANSIT_ENCRYPTION_MODE_UNSPECIFIED - Not set. */
  TRANSIT_ENCRYPTION_MODE_UNSPECIFIED = 0,
  /** SERVER_AUTHENTICATION - Client to Server traffic encryption enabled with server authentication. */
  SERVER_AUTHENTICATION = 1,
  /** DISABLED - TLS is disabled for the instance. */
  DISABLED = 2,
  UNRECOGNIZED = -1,
}

export function instance_TransitEncryptionModeFromJSON(object: any): Instance_TransitEncryptionMode {
  switch (object) {
    case 0:
    case "TRANSIT_ENCRYPTION_MODE_UNSPECIFIED":
      return Instance_TransitEncryptionMode.TRANSIT_ENCRYPTION_MODE_UNSPECIFIED;
    case 1:
    case "SERVER_AUTHENTICATION":
      return Instance_TransitEncryptionMode.SERVER_AUTHENTICATION;
    case 2:
    case "DISABLED":
      return Instance_TransitEncryptionMode.DISABLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_TransitEncryptionMode.UNRECOGNIZED;
  }
}

export function instance_TransitEncryptionModeToJSON(object: Instance_TransitEncryptionMode): string {
  switch (object) {
    case Instance_TransitEncryptionMode.TRANSIT_ENCRYPTION_MODE_UNSPECIFIED:
      return "TRANSIT_ENCRYPTION_MODE_UNSPECIFIED";
    case Instance_TransitEncryptionMode.SERVER_AUTHENTICATION:
      return "SERVER_AUTHENTICATION";
    case Instance_TransitEncryptionMode.DISABLED:
      return "DISABLED";
    case Instance_TransitEncryptionMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Read replicas mode. */
export enum Instance_ReadReplicasMode {
  /**
   * READ_REPLICAS_MODE_UNSPECIFIED - If not set, Memorystore Redis backend will default to
   * READ_REPLICAS_DISABLED.
   */
  READ_REPLICAS_MODE_UNSPECIFIED = 0,
  /**
   * READ_REPLICAS_DISABLED - If disabled, read endpoint will not be provided and the instance cannot
   * scale up or down the number of replicas.
   */
  READ_REPLICAS_DISABLED = 1,
  /**
   * READ_REPLICAS_ENABLED - If enabled, read endpoint will be provided and the instance can scale
   * up and down the number of replicas. Not valid for basic tier.
   */
  READ_REPLICAS_ENABLED = 2,
  UNRECOGNIZED = -1,
}

export function instance_ReadReplicasModeFromJSON(object: any): Instance_ReadReplicasMode {
  switch (object) {
    case 0:
    case "READ_REPLICAS_MODE_UNSPECIFIED":
      return Instance_ReadReplicasMode.READ_REPLICAS_MODE_UNSPECIFIED;
    case 1:
    case "READ_REPLICAS_DISABLED":
      return Instance_ReadReplicasMode.READ_REPLICAS_DISABLED;
    case 2:
    case "READ_REPLICAS_ENABLED":
      return Instance_ReadReplicasMode.READ_REPLICAS_ENABLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_ReadReplicasMode.UNRECOGNIZED;
  }
}

export function instance_ReadReplicasModeToJSON(object: Instance_ReadReplicasMode): string {
  switch (object) {
    case Instance_ReadReplicasMode.READ_REPLICAS_MODE_UNSPECIFIED:
      return "READ_REPLICAS_MODE_UNSPECIFIED";
    case Instance_ReadReplicasMode.READ_REPLICAS_DISABLED:
      return "READ_REPLICAS_DISABLED";
    case Instance_ReadReplicasMode.READ_REPLICAS_ENABLED:
      return "READ_REPLICAS_ENABLED";
    case Instance_ReadReplicasMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Possible reasons for the instance to be in a "SUSPENDED" state. */
export enum Instance_SuspensionReason {
  /** SUSPENSION_REASON_UNSPECIFIED - Not set. */
  SUSPENSION_REASON_UNSPECIFIED = 0,
  /** CUSTOMER_MANAGED_KEY_ISSUE - Something wrong with the CMEK key provided by customer. */
  CUSTOMER_MANAGED_KEY_ISSUE = 1,
  UNRECOGNIZED = -1,
}

export function instance_SuspensionReasonFromJSON(object: any): Instance_SuspensionReason {
  switch (object) {
    case 0:
    case "SUSPENSION_REASON_UNSPECIFIED":
      return Instance_SuspensionReason.SUSPENSION_REASON_UNSPECIFIED;
    case 1:
    case "CUSTOMER_MANAGED_KEY_ISSUE":
      return Instance_SuspensionReason.CUSTOMER_MANAGED_KEY_ISSUE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_SuspensionReason.UNRECOGNIZED;
  }
}

export function instance_SuspensionReasonToJSON(object: Instance_SuspensionReason): string {
  switch (object) {
    case Instance_SuspensionReason.SUSPENSION_REASON_UNSPECIFIED:
      return "SUSPENSION_REASON_UNSPECIFIED";
    case Instance_SuspensionReason.CUSTOMER_MANAGED_KEY_ISSUE:
      return "CUSTOMER_MANAGED_KEY_ISSUE";
    case Instance_SuspensionReason.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Instance_LabelsEntry {
  key: string;
  value: string;
}

export interface Instance_RedisConfigsEntry {
  key: string;
  value: string;
}

/** Configuration of the persistence functionality. */
export interface PersistenceConfig {
  /**
   * Optional. Controls whether Persistence features are enabled.
   * If not provided, the existing value will be used.
   */
  persistenceMode: PersistenceConfig_PersistenceMode;
  /**
   * Optional. Period between RDB snapshots. Snapshots will be attempted every
   * period starting from the provided snapshot start time. For example, a start
   * time of 01/01/2033 06:45 and SIX_HOURS snapshot period will do nothing
   * until 01/01/2033, and then trigger snapshots every day at 06:45, 12:45,
   * 18:45, and 00:45 the next day, and so on. If not provided,
   * TWENTY_FOUR_HOURS will be used as default.
   */
  rdbSnapshotPeriod: PersistenceConfig_SnapshotPeriod;
  /** Output only. The next time that a snapshot attempt is scheduled to occur. */
  rdbNextSnapshotTime:
    | Date
    | undefined;
  /**
   * Optional. Date and time that the first snapshot was/will be attempted, and
   * to which future snapshots will be aligned. If not provided, the current
   * time will be used.
   */
  rdbSnapshotStartTime: Date | undefined;
}

/** Available Persistence modes. */
export enum PersistenceConfig_PersistenceMode {
  /** PERSISTENCE_MODE_UNSPECIFIED - Not set. */
  PERSISTENCE_MODE_UNSPECIFIED = 0,
  /**
   * DISABLED - Persistence is disabled for the instance,
   * and any existing snapshots are deleted.
   */
  DISABLED = 1,
  /** RDB - RDB based Persistence is enabled. */
  RDB = 2,
  UNRECOGNIZED = -1,
}

export function persistenceConfig_PersistenceModeFromJSON(object: any): PersistenceConfig_PersistenceMode {
  switch (object) {
    case 0:
    case "PERSISTENCE_MODE_UNSPECIFIED":
      return PersistenceConfig_PersistenceMode.PERSISTENCE_MODE_UNSPECIFIED;
    case 1:
    case "DISABLED":
      return PersistenceConfig_PersistenceMode.DISABLED;
    case 2:
    case "RDB":
      return PersistenceConfig_PersistenceMode.RDB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PersistenceConfig_PersistenceMode.UNRECOGNIZED;
  }
}

export function persistenceConfig_PersistenceModeToJSON(object: PersistenceConfig_PersistenceMode): string {
  switch (object) {
    case PersistenceConfig_PersistenceMode.PERSISTENCE_MODE_UNSPECIFIED:
      return "PERSISTENCE_MODE_UNSPECIFIED";
    case PersistenceConfig_PersistenceMode.DISABLED:
      return "DISABLED";
    case PersistenceConfig_PersistenceMode.RDB:
      return "RDB";
    case PersistenceConfig_PersistenceMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available snapshot periods for scheduling. */
export enum PersistenceConfig_SnapshotPeriod {
  /** SNAPSHOT_PERIOD_UNSPECIFIED - Not set. */
  SNAPSHOT_PERIOD_UNSPECIFIED = 0,
  /** ONE_HOUR - Snapshot every 1 hour. */
  ONE_HOUR = 3,
  /** SIX_HOURS - Snapshot every 6 hours. */
  SIX_HOURS = 4,
  /** TWELVE_HOURS - Snapshot every 12 hours. */
  TWELVE_HOURS = 5,
  /** TWENTY_FOUR_HOURS - Snapshot every 24 hours. */
  TWENTY_FOUR_HOURS = 6,
  UNRECOGNIZED = -1,
}

export function persistenceConfig_SnapshotPeriodFromJSON(object: any): PersistenceConfig_SnapshotPeriod {
  switch (object) {
    case 0:
    case "SNAPSHOT_PERIOD_UNSPECIFIED":
      return PersistenceConfig_SnapshotPeriod.SNAPSHOT_PERIOD_UNSPECIFIED;
    case 3:
    case "ONE_HOUR":
      return PersistenceConfig_SnapshotPeriod.ONE_HOUR;
    case 4:
    case "SIX_HOURS":
      return PersistenceConfig_SnapshotPeriod.SIX_HOURS;
    case 5:
    case "TWELVE_HOURS":
      return PersistenceConfig_SnapshotPeriod.TWELVE_HOURS;
    case 6:
    case "TWENTY_FOUR_HOURS":
      return PersistenceConfig_SnapshotPeriod.TWENTY_FOUR_HOURS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PersistenceConfig_SnapshotPeriod.UNRECOGNIZED;
  }
}

export function persistenceConfig_SnapshotPeriodToJSON(object: PersistenceConfig_SnapshotPeriod): string {
  switch (object) {
    case PersistenceConfig_SnapshotPeriod.SNAPSHOT_PERIOD_UNSPECIFIED:
      return "SNAPSHOT_PERIOD_UNSPECIFIED";
    case PersistenceConfig_SnapshotPeriod.ONE_HOUR:
      return "ONE_HOUR";
    case PersistenceConfig_SnapshotPeriod.SIX_HOURS:
      return "SIX_HOURS";
    case PersistenceConfig_SnapshotPeriod.TWELVE_HOURS:
      return "TWELVE_HOURS";
    case PersistenceConfig_SnapshotPeriod.TWENTY_FOUR_HOURS:
      return "TWENTY_FOUR_HOURS";
    case PersistenceConfig_SnapshotPeriod.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Request for
 * [RescheduleMaintenance][google.cloud.redis.v1.CloudRedis.RescheduleMaintenance].
 */
export interface RescheduleMaintenanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
  /**
   * Required. If reschedule type is SPECIFIC_TIME, must set up schedule_time as
   * well.
   */
  rescheduleType: RescheduleMaintenanceRequest_RescheduleType;
  /**
   * Optional. Timestamp when the maintenance shall be rescheduled to if
   * reschedule_type=SPECIFIC_TIME, in RFC 3339 format, for
   * example `2012-11-15T16:19:00.094Z`.
   */
  scheduleTime: Date | undefined;
}

/** Reschedule options. */
export enum RescheduleMaintenanceRequest_RescheduleType {
  /** RESCHEDULE_TYPE_UNSPECIFIED - Not set. */
  RESCHEDULE_TYPE_UNSPECIFIED = 0,
  /** IMMEDIATE - If the user wants to schedule the maintenance to happen now. */
  IMMEDIATE = 1,
  /**
   * NEXT_AVAILABLE_WINDOW - If the user wants to use the existing maintenance policy to find the
   * next available window.
   */
  NEXT_AVAILABLE_WINDOW = 2,
  /** SPECIFIC_TIME - If the user wants to reschedule the maintenance to a specific time. */
  SPECIFIC_TIME = 3,
  UNRECOGNIZED = -1,
}

export function rescheduleMaintenanceRequest_RescheduleTypeFromJSON(
  object: any,
): RescheduleMaintenanceRequest_RescheduleType {
  switch (object) {
    case 0:
    case "RESCHEDULE_TYPE_UNSPECIFIED":
      return RescheduleMaintenanceRequest_RescheduleType.RESCHEDULE_TYPE_UNSPECIFIED;
    case 1:
    case "IMMEDIATE":
      return RescheduleMaintenanceRequest_RescheduleType.IMMEDIATE;
    case 2:
    case "NEXT_AVAILABLE_WINDOW":
      return RescheduleMaintenanceRequest_RescheduleType.NEXT_AVAILABLE_WINDOW;
    case 3:
    case "SPECIFIC_TIME":
      return RescheduleMaintenanceRequest_RescheduleType.SPECIFIC_TIME;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RescheduleMaintenanceRequest_RescheduleType.UNRECOGNIZED;
  }
}

export function rescheduleMaintenanceRequest_RescheduleTypeToJSON(
  object: RescheduleMaintenanceRequest_RescheduleType,
): string {
  switch (object) {
    case RescheduleMaintenanceRequest_RescheduleType.RESCHEDULE_TYPE_UNSPECIFIED:
      return "RESCHEDULE_TYPE_UNSPECIFIED";
    case RescheduleMaintenanceRequest_RescheduleType.IMMEDIATE:
      return "IMMEDIATE";
    case RescheduleMaintenanceRequest_RescheduleType.NEXT_AVAILABLE_WINDOW:
      return "NEXT_AVAILABLE_WINDOW";
    case RescheduleMaintenanceRequest_RescheduleType.SPECIFIC_TIME:
      return "SPECIFIC_TIME";
    case RescheduleMaintenanceRequest_RescheduleType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Maintenance policy for an instance. */
export interface MaintenancePolicy {
  /** Output only. The time when the policy was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the policy was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Optional. Description of what this policy is for. Create/Update methods
   * return INVALID_ARGUMENT if the length is greater than 512.
   */
  description: string;
  /**
   * Optional. Maintenance window that is applied to resources covered by this
   * policy. Minimum 1. For the current version, the maximum number of
   * weekly_window is expected to be one.
   */
  weeklyMaintenanceWindow: WeeklyMaintenanceWindow[];
}

/**
 * Time window in which disruptive maintenance updates occur. Non-disruptive
 * updates can occur inside or outside this window.
 */
export interface WeeklyMaintenanceWindow {
  /** Required. The day of week that maintenance updates occur. */
  day: DayOfWeek;
  /** Required. Start time of the window in UTC time. */
  startTime:
    | TimeOfDay
    | undefined;
  /**
   * Output only. Duration of the maintenance window. The current window is
   * fixed at 1 hour.
   */
  duration: Duration | undefined;
}

/**
 * Upcoming maintenance schedule. If no maintenance is scheduled, fields are not
 * populated.
 */
export interface MaintenanceSchedule {
  /**
   * Output only. The start time of any upcoming scheduled maintenance for this
   * instance.
   */
  startTime:
    | Date
    | undefined;
  /**
   * Output only. The end time of any upcoming scheduled maintenance for this
   * instance.
   */
  endTime:
    | Date
    | undefined;
  /**
   * If the scheduled maintenance can be rescheduled, default is true.
   *
   * @deprecated
   */
  canReschedule: boolean;
  /**
   * Output only. The deadline that the maintenance schedule start time can not
   * go beyond, including reschedule.
   */
  scheduleDeadlineTime: Date | undefined;
}

/** Request for [ListInstances][google.cloud.redis.v1.CloudRedis.ListInstances]. */
export interface ListInstancesRequest {
  /**
   * Required. The resource name of the instance location using the form:
   *     `projects/{project_id}/locations/{location_id}`
   * where `location_id` refers to a GCP region.
   */
  parent: string;
  /**
   * The maximum number of items to return.
   *
   * If not specified, a default value of 1000 will be used by the service.
   * Regardless of the page_size value, the response may include a partial list
   * and a caller should only rely on response's
   * [`next_page_token`][google.cloud.redis.v1.ListInstancesResponse.next_page_token]
   * to determine if there are more instances left to be queried.
   */
  pageSize: number;
  /**
   * The `next_page_token` value returned from a previous
   * [ListInstances][google.cloud.redis.v1.CloudRedis.ListInstances] request, if
   * any.
   */
  pageToken: string;
}

/** Response for [ListInstances][google.cloud.redis.v1.CloudRedis.ListInstances]. */
export interface ListInstancesResponse {
  /**
   * A list of Redis instances in the project in the specified location,
   * or across all locations.
   *
   * If the `location_id` in the parent field of the request is "-", all regions
   * available to the project are queried, and the results aggregated.
   * If in such an aggregated query a location is unavailable, a placeholder
   * Redis entry is included in the response with the `name` field set to a
   * value of the form
   * `projects/{project_id}/locations/{location_id}/instances/`- and the
   * `status` field set to ERROR and `status_message` field set to "location not
   * available for ListInstances".
   */
  instances: Instance[];
  /**
   * Token to retrieve the next page of results, or empty if there are no more
   * results in the list.
   */
  nextPageToken: string;
  /** Locations that could not be reached. */
  unreachable: string[];
}

/** Request for [GetInstance][google.cloud.redis.v1.CloudRedis.GetInstance]. */
export interface GetInstanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
}

/**
 * Request for
 * [GetInstanceAuthString][google.cloud.redis.v1.CloudRedis.GetInstanceAuthString].
 */
export interface GetInstanceAuthStringRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
}

/** Instance AUTH string details. */
export interface InstanceAuthString {
  /** AUTH string set on the instance. */
  authString: string;
}

/**
 * Request for
 * [CreateInstance][google.cloud.redis.v1.CloudRedis.CreateInstance].
 */
export interface CreateInstanceRequest {
  /**
   * Required. The resource name of the instance location using the form:
   *     `projects/{project_id}/locations/{location_id}`
   * where `location_id` refers to a GCP region.
   */
  parent: string;
  /**
   * Required. The logical name of the Redis instance in the customer project
   * with the following restrictions:
   *
   * * Must contain only lowercase letters, numbers, and hyphens.
   * * Must start with a letter.
   * * Must be between 1-40 characters.
   * * Must end with a number or a letter.
   * * Must be unique within the customer project / location
   */
  instanceId: string;
  /** Required. A Redis [Instance] resource */
  instance: Instance | undefined;
}

/**
 * Request for
 * [UpdateInstance][google.cloud.redis.v1.CloudRedis.UpdateInstance].
 */
export interface UpdateInstanceRequest {
  /**
   * Required. Mask of fields to update. At least one path must be supplied in
   * this field. The elements of the repeated paths field may only include these
   * fields from [Instance][google.cloud.redis.v1.Instance]:
   *
   *  *   `displayName`
   *  *   `labels`
   *  *   `memorySizeGb`
   *  *   `redisConfig`
   *  *   `replica_count`
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * Required. Update description.
   * Only fields specified in update_mask are updated.
   */
  instance: Instance | undefined;
}

/**
 * Request for
 * [UpgradeInstance][google.cloud.redis.v1.CloudRedis.UpgradeInstance].
 */
export interface UpgradeInstanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
  /** Required. Specifies the target version of Redis software to upgrade to. */
  redisVersion: string;
}

/**
 * Request for
 * [DeleteInstance][google.cloud.redis.v1.CloudRedis.DeleteInstance].
 */
export interface DeleteInstanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
}

/** The Cloud Storage location for the input content */
export interface GcsSource {
  /** Required. Source data URI. (e.g. 'gs://my_bucket/my_object'). */
  uri: string;
}

/** The input content */
export interface InputConfig {
  /** Google Cloud Storage location where input content is located. */
  gcsSource?: GcsSource | undefined;
}

/** Request for [Import][google.cloud.redis.v1.CloudRedis.ImportInstance]. */
export interface ImportInstanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
  /** Required. Specify data to be imported. */
  inputConfig: InputConfig | undefined;
}

/** The Cloud Storage location for the output content */
export interface GcsDestination {
  /**
   * Required. Data destination URI (e.g.
   * 'gs://my_bucket/my_object'). Existing files will be overwritten.
   */
  uri: string;
}

/** The output content */
export interface OutputConfig {
  /** Google Cloud Storage destination for output content. */
  gcsDestination?: GcsDestination | undefined;
}

/** Request for [Export][google.cloud.redis.v1.CloudRedis.ExportInstance]. */
export interface ExportInstanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
  /** Required. Specify data to be exported. */
  outputConfig: OutputConfig | undefined;
}

/** Request for [Failover][google.cloud.redis.v1.CloudRedis.FailoverInstance]. */
export interface FailoverInstanceRequest {
  /**
   * Required. Redis instance resource name using the form:
   *     `projects/{project_id}/locations/{location_id}/instances/{instance_id}`
   * where `location_id` refers to a GCP region.
   */
  name: string;
  /**
   * Optional. Available data protection modes that the user can choose. If it's
   * unspecified, data protection mode will be LIMITED_DATA_LOSS by default.
   */
  dataProtectionMode: FailoverInstanceRequest_DataProtectionMode;
}

/** Specifies different modes of operation in relation to the data retention. */
export enum FailoverInstanceRequest_DataProtectionMode {
  /**
   * DATA_PROTECTION_MODE_UNSPECIFIED - Defaults to LIMITED_DATA_LOSS if a data protection mode is not
   * specified.
   */
  DATA_PROTECTION_MODE_UNSPECIFIED = 0,
  /**
   * LIMITED_DATA_LOSS - Instance failover will be protected with data loss control. More
   * specifically, the failover will only be performed if the current
   * replication offset diff between primary and replica is under a certain
   * threshold.
   */
  LIMITED_DATA_LOSS = 1,
  /** FORCE_DATA_LOSS - Instance failover will be performed without data loss control. */
  FORCE_DATA_LOSS = 2,
  UNRECOGNIZED = -1,
}

export function failoverInstanceRequest_DataProtectionModeFromJSON(
  object: any,
): FailoverInstanceRequest_DataProtectionMode {
  switch (object) {
    case 0:
    case "DATA_PROTECTION_MODE_UNSPECIFIED":
      return FailoverInstanceRequest_DataProtectionMode.DATA_PROTECTION_MODE_UNSPECIFIED;
    case 1:
    case "LIMITED_DATA_LOSS":
      return FailoverInstanceRequest_DataProtectionMode.LIMITED_DATA_LOSS;
    case 2:
    case "FORCE_DATA_LOSS":
      return FailoverInstanceRequest_DataProtectionMode.FORCE_DATA_LOSS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FailoverInstanceRequest_DataProtectionMode.UNRECOGNIZED;
  }
}

export function failoverInstanceRequest_DataProtectionModeToJSON(
  object: FailoverInstanceRequest_DataProtectionMode,
): string {
  switch (object) {
    case FailoverInstanceRequest_DataProtectionMode.DATA_PROTECTION_MODE_UNSPECIFIED:
      return "DATA_PROTECTION_MODE_UNSPECIFIED";
    case FailoverInstanceRequest_DataProtectionMode.LIMITED_DATA_LOSS:
      return "LIMITED_DATA_LOSS";
    case FailoverInstanceRequest_DataProtectionMode.FORCE_DATA_LOSS:
      return "FORCE_DATA_LOSS";
    case FailoverInstanceRequest_DataProtectionMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the v1 metadata of the long-running operation. */
export interface OperationMetadata {
  /** Creation timestamp. */
  createTime:
    | Date
    | undefined;
  /** End timestamp. */
  endTime:
    | Date
    | undefined;
  /** Operation target. */
  target: string;
  /** Operation verb. */
  verb: string;
  /** Operation status details. */
  statusDetail: string;
  /** Specifies if cancellation was requested for the operation. */
  cancelRequested: boolean;
  /** API version. */
  apiVersion: string;
}

/**
 * This location metadata represents additional configuration options for a
 * given location where a Redis instance may be created. All fields are output
 * only. It is returned as content of the
 * `google.cloud.location.Location.metadata` field.
 */
export interface LocationMetadata {
  /**
   * Output only. The set of available zones in the location. The map is keyed
   * by the lowercase ID of each zone, as defined by GCE. These keys can be
   * specified in `location_id` or `alternative_location_id` fields when
   * creating a Redis instance.
   */
  availableZones: { [key: string]: ZoneMetadata };
}

export interface LocationMetadata_AvailableZonesEntry {
  key: string;
  value: ZoneMetadata | undefined;
}

/**
 * Defines specific information for a particular zone. Currently empty and
 * reserved for future use only.
 */
export interface ZoneMetadata {
}

/** TlsCertificate Resource */
export interface TlsCertificate {
  /** Serial number, as extracted from the certificate. */
  serialNumber: string;
  /** PEM representation. */
  cert: string;
  /**
   * Output only. The time when the certificate was created in [RFC
   * 3339](https://tools.ietf.org/html/rfc3339) format, for example
   * `2020-05-18T00:00:00.094Z`.
   */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. The time when the certificate expires in [RFC
   * 3339](https://tools.ietf.org/html/rfc3339) format, for example
   * `2020-05-18T00:00:00.094Z`.
   */
  expireTime:
    | Date
    | undefined;
  /** Sha1 Fingerprint of the certificate. */
  sha1Fingerprint: string;
}

function createBaseNodeInfo(): NodeInfo {
  return { id: "", zone: "" };
}

export const NodeInfo: MessageFns<NodeInfo> = {
  encode(message: NodeInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.zone !== "") {
      writer.uint32(18).string(message.zone);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NodeInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNodeInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.zone = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NodeInfo {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
    };
  },

  toJSON(message: NodeInfo): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    return obj;
  },

  create(base?: DeepPartial<NodeInfo>): NodeInfo {
    return NodeInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NodeInfo>): NodeInfo {
    const message = createBaseNodeInfo();
    message.id = object.id ?? "";
    message.zone = object.zone ?? "";
    return message;
  },
};

function createBaseInstance(): Instance {
  return {
    name: "",
    displayName: "",
    labels: {},
    locationId: "",
    alternativeLocationId: "",
    redisVersion: "",
    reservedIpRange: "",
    secondaryIpRange: "",
    host: "",
    port: 0,
    currentLocationId: "",
    createTime: undefined,
    state: 0,
    statusMessage: "",
    redisConfigs: {},
    tier: 0,
    memorySizeGb: 0,
    authorizedNetwork: "",
    persistenceIamIdentity: "",
    connectMode: 0,
    authEnabled: false,
    serverCaCerts: [],
    transitEncryptionMode: 0,
    maintenancePolicy: undefined,
    maintenanceSchedule: undefined,
    replicaCount: 0,
    nodes: [],
    readEndpoint: "",
    readEndpointPort: 0,
    readReplicasMode: 0,
    customerManagedKey: "",
    persistenceConfig: undefined,
    suspensionReasons: [],
    maintenanceVersion: "",
    availableMaintenanceVersions: [],
  };
}

export const Instance: MessageFns<Instance> = {
  encode(message: Instance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Instance_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.locationId !== "") {
      writer.uint32(34).string(message.locationId);
    }
    if (message.alternativeLocationId !== "") {
      writer.uint32(42).string(message.alternativeLocationId);
    }
    if (message.redisVersion !== "") {
      writer.uint32(58).string(message.redisVersion);
    }
    if (message.reservedIpRange !== "") {
      writer.uint32(74).string(message.reservedIpRange);
    }
    if (message.secondaryIpRange !== "") {
      writer.uint32(242).string(message.secondaryIpRange);
    }
    if (message.host !== "") {
      writer.uint32(82).string(message.host);
    }
    if (message.port !== 0) {
      writer.uint32(88).int32(message.port);
    }
    if (message.currentLocationId !== "") {
      writer.uint32(98).string(message.currentLocationId);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(106).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(112).int32(message.state);
    }
    if (message.statusMessage !== "") {
      writer.uint32(122).string(message.statusMessage);
    }
    Object.entries(message.redisConfigs).forEach(([key, value]) => {
      Instance_RedisConfigsEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
    });
    if (message.tier !== 0) {
      writer.uint32(136).int32(message.tier);
    }
    if (message.memorySizeGb !== 0) {
      writer.uint32(144).int32(message.memorySizeGb);
    }
    if (message.authorizedNetwork !== "") {
      writer.uint32(162).string(message.authorizedNetwork);
    }
    if (message.persistenceIamIdentity !== "") {
      writer.uint32(170).string(message.persistenceIamIdentity);
    }
    if (message.connectMode !== 0) {
      writer.uint32(176).int32(message.connectMode);
    }
    if (message.authEnabled !== false) {
      writer.uint32(184).bool(message.authEnabled);
    }
    for (const v of message.serverCaCerts) {
      TlsCertificate.encode(v!, writer.uint32(202).fork()).join();
    }
    if (message.transitEncryptionMode !== 0) {
      writer.uint32(208).int32(message.transitEncryptionMode);
    }
    if (message.maintenancePolicy !== undefined) {
      MaintenancePolicy.encode(message.maintenancePolicy, writer.uint32(218).fork()).join();
    }
    if (message.maintenanceSchedule !== undefined) {
      MaintenanceSchedule.encode(message.maintenanceSchedule, writer.uint32(226).fork()).join();
    }
    if (message.replicaCount !== 0) {
      writer.uint32(248).int32(message.replicaCount);
    }
    for (const v of message.nodes) {
      NodeInfo.encode(v!, writer.uint32(258).fork()).join();
    }
    if (message.readEndpoint !== "") {
      writer.uint32(266).string(message.readEndpoint);
    }
    if (message.readEndpointPort !== 0) {
      writer.uint32(272).int32(message.readEndpointPort);
    }
    if (message.readReplicasMode !== 0) {
      writer.uint32(280).int32(message.readReplicasMode);
    }
    if (message.customerManagedKey !== "") {
      writer.uint32(290).string(message.customerManagedKey);
    }
    if (message.persistenceConfig !== undefined) {
      PersistenceConfig.encode(message.persistenceConfig, writer.uint32(298).fork()).join();
    }
    writer.uint32(306).fork();
    for (const v of message.suspensionReasons) {
      writer.int32(v);
    }
    writer.join();
    if (message.maintenanceVersion !== "") {
      writer.uint32(314).string(message.maintenanceVersion);
    }
    for (const v of message.availableMaintenanceVersions) {
      writer.uint32(322).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Instance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = Instance_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.locationId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.alternativeLocationId = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.redisVersion = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.reservedIpRange = reader.string();
          continue;
        case 30:
          if (tag !== 242) {
            break;
          }

          message.secondaryIpRange = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.host = reader.string();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.currentLocationId = reader.string();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.statusMessage = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          const entry16 = Instance_RedisConfigsEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.redisConfigs[entry16.key] = entry16.value;
          }
          continue;
        case 17:
          if (tag !== 136) {
            break;
          }

          message.tier = reader.int32() as any;
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.memorySizeGb = reader.int32();
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.authorizedNetwork = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.persistenceIamIdentity = reader.string();
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.connectMode = reader.int32() as any;
          continue;
        case 23:
          if (tag !== 184) {
            break;
          }

          message.authEnabled = reader.bool();
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.serverCaCerts.push(TlsCertificate.decode(reader, reader.uint32()));
          continue;
        case 26:
          if (tag !== 208) {
            break;
          }

          message.transitEncryptionMode = reader.int32() as any;
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.maintenancePolicy = MaintenancePolicy.decode(reader, reader.uint32());
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.maintenanceSchedule = MaintenanceSchedule.decode(reader, reader.uint32());
          continue;
        case 31:
          if (tag !== 248) {
            break;
          }

          message.replicaCount = reader.int32();
          continue;
        case 32:
          if (tag !== 258) {
            break;
          }

          message.nodes.push(NodeInfo.decode(reader, reader.uint32()));
          continue;
        case 33:
          if (tag !== 266) {
            break;
          }

          message.readEndpoint = reader.string();
          continue;
        case 34:
          if (tag !== 272) {
            break;
          }

          message.readEndpointPort = reader.int32();
          continue;
        case 35:
          if (tag !== 280) {
            break;
          }

          message.readReplicasMode = reader.int32() as any;
          continue;
        case 36:
          if (tag !== 290) {
            break;
          }

          message.customerManagedKey = reader.string();
          continue;
        case 37:
          if (tag !== 298) {
            break;
          }

          message.persistenceConfig = PersistenceConfig.decode(reader, reader.uint32());
          continue;
        case 38:
          if (tag === 304) {
            message.suspensionReasons.push(reader.int32() as any);

            continue;
          }

          if (tag === 306) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.suspensionReasons.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 39:
          if (tag !== 314) {
            break;
          }

          message.maintenanceVersion = reader.string();
          continue;
        case 40:
          if (tag !== 322) {
            break;
          }

          message.availableMaintenanceVersions.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Instance {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
      alternativeLocationId: isSet(object.alternativeLocationId) ? globalThis.String(object.alternativeLocationId) : "",
      redisVersion: isSet(object.redisVersion) ? globalThis.String(object.redisVersion) : "",
      reservedIpRange: isSet(object.reservedIpRange) ? globalThis.String(object.reservedIpRange) : "",
      secondaryIpRange: isSet(object.secondaryIpRange) ? globalThis.String(object.secondaryIpRange) : "",
      host: isSet(object.host) ? globalThis.String(object.host) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      currentLocationId: isSet(object.currentLocationId) ? globalThis.String(object.currentLocationId) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      state: isSet(object.state) ? instance_StateFromJSON(object.state) : 0,
      statusMessage: isSet(object.statusMessage) ? globalThis.String(object.statusMessage) : "",
      redisConfigs: isObject(object.redisConfigs)
        ? Object.entries(object.redisConfigs).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      tier: isSet(object.tier) ? instance_TierFromJSON(object.tier) : 0,
      memorySizeGb: isSet(object.memorySizeGb) ? globalThis.Number(object.memorySizeGb) : 0,
      authorizedNetwork: isSet(object.authorizedNetwork) ? globalThis.String(object.authorizedNetwork) : "",
      persistenceIamIdentity: isSet(object.persistenceIamIdentity)
        ? globalThis.String(object.persistenceIamIdentity)
        : "",
      connectMode: isSet(object.connectMode) ? instance_ConnectModeFromJSON(object.connectMode) : 0,
      authEnabled: isSet(object.authEnabled) ? globalThis.Boolean(object.authEnabled) : false,
      serverCaCerts: globalThis.Array.isArray(object?.serverCaCerts)
        ? object.serverCaCerts.map((e: any) => TlsCertificate.fromJSON(e))
        : [],
      transitEncryptionMode: isSet(object.transitEncryptionMode)
        ? instance_TransitEncryptionModeFromJSON(object.transitEncryptionMode)
        : 0,
      maintenancePolicy: isSet(object.maintenancePolicy)
        ? MaintenancePolicy.fromJSON(object.maintenancePolicy)
        : undefined,
      maintenanceSchedule: isSet(object.maintenanceSchedule)
        ? MaintenanceSchedule.fromJSON(object.maintenanceSchedule)
        : undefined,
      replicaCount: isSet(object.replicaCount) ? globalThis.Number(object.replicaCount) : 0,
      nodes: globalThis.Array.isArray(object?.nodes)
        ? object.nodes.map((e: any) => NodeInfo.fromJSON(e))
        : [],
      readEndpoint: isSet(object.readEndpoint) ? globalThis.String(object.readEndpoint) : "",
      readEndpointPort: isSet(object.readEndpointPort) ? globalThis.Number(object.readEndpointPort) : 0,
      readReplicasMode: isSet(object.readReplicasMode) ? instance_ReadReplicasModeFromJSON(object.readReplicasMode) : 0,
      customerManagedKey: isSet(object.customerManagedKey) ? globalThis.String(object.customerManagedKey) : "",
      persistenceConfig: isSet(object.persistenceConfig)
        ? PersistenceConfig.fromJSON(object.persistenceConfig)
        : undefined,
      suspensionReasons: globalThis.Array.isArray(object?.suspensionReasons)
        ? object.suspensionReasons.map((e: any) => instance_SuspensionReasonFromJSON(e))
        : [],
      maintenanceVersion: isSet(object.maintenanceVersion) ? globalThis.String(object.maintenanceVersion) : "",
      availableMaintenanceVersions: globalThis.Array.isArray(object?.availableMaintenanceVersions)
        ? object.availableMaintenanceVersions.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Instance): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    if (message.alternativeLocationId !== "") {
      obj.alternativeLocationId = message.alternativeLocationId;
    }
    if (message.redisVersion !== "") {
      obj.redisVersion = message.redisVersion;
    }
    if (message.reservedIpRange !== "") {
      obj.reservedIpRange = message.reservedIpRange;
    }
    if (message.secondaryIpRange !== "") {
      obj.secondaryIpRange = message.secondaryIpRange;
    }
    if (message.host !== "") {
      obj.host = message.host;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.currentLocationId !== "") {
      obj.currentLocationId = message.currentLocationId;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = instance_StateToJSON(message.state);
    }
    if (message.statusMessage !== "") {
      obj.statusMessage = message.statusMessage;
    }
    if (message.redisConfigs) {
      const entries = Object.entries(message.redisConfigs);
      if (entries.length > 0) {
        obj.redisConfigs = {};
        entries.forEach(([k, v]) => {
          obj.redisConfigs[k] = v;
        });
      }
    }
    if (message.tier !== 0) {
      obj.tier = instance_TierToJSON(message.tier);
    }
    if (message.memorySizeGb !== 0) {
      obj.memorySizeGb = Math.round(message.memorySizeGb);
    }
    if (message.authorizedNetwork !== "") {
      obj.authorizedNetwork = message.authorizedNetwork;
    }
    if (message.persistenceIamIdentity !== "") {
      obj.persistenceIamIdentity = message.persistenceIamIdentity;
    }
    if (message.connectMode !== 0) {
      obj.connectMode = instance_ConnectModeToJSON(message.connectMode);
    }
    if (message.authEnabled !== false) {
      obj.authEnabled = message.authEnabled;
    }
    if (message.serverCaCerts?.length) {
      obj.serverCaCerts = message.serverCaCerts.map((e) => TlsCertificate.toJSON(e));
    }
    if (message.transitEncryptionMode !== 0) {
      obj.transitEncryptionMode = instance_TransitEncryptionModeToJSON(message.transitEncryptionMode);
    }
    if (message.maintenancePolicy !== undefined) {
      obj.maintenancePolicy = MaintenancePolicy.toJSON(message.maintenancePolicy);
    }
    if (message.maintenanceSchedule !== undefined) {
      obj.maintenanceSchedule = MaintenanceSchedule.toJSON(message.maintenanceSchedule);
    }
    if (message.replicaCount !== 0) {
      obj.replicaCount = Math.round(message.replicaCount);
    }
    if (message.nodes?.length) {
      obj.nodes = message.nodes.map((e) => NodeInfo.toJSON(e));
    }
    if (message.readEndpoint !== "") {
      obj.readEndpoint = message.readEndpoint;
    }
    if (message.readEndpointPort !== 0) {
      obj.readEndpointPort = Math.round(message.readEndpointPort);
    }
    if (message.readReplicasMode !== 0) {
      obj.readReplicasMode = instance_ReadReplicasModeToJSON(message.readReplicasMode);
    }
    if (message.customerManagedKey !== "") {
      obj.customerManagedKey = message.customerManagedKey;
    }
    if (message.persistenceConfig !== undefined) {
      obj.persistenceConfig = PersistenceConfig.toJSON(message.persistenceConfig);
    }
    if (message.suspensionReasons?.length) {
      obj.suspensionReasons = message.suspensionReasons.map((e) => instance_SuspensionReasonToJSON(e));
    }
    if (message.maintenanceVersion !== "") {
      obj.maintenanceVersion = message.maintenanceVersion;
    }
    if (message.availableMaintenanceVersions?.length) {
      obj.availableMaintenanceVersions = message.availableMaintenanceVersions;
    }
    return obj;
  },

  create(base?: DeepPartial<Instance>): Instance {
    return Instance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Instance>): Instance {
    const message = createBaseInstance();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.locationId = object.locationId ?? "";
    message.alternativeLocationId = object.alternativeLocationId ?? "";
    message.redisVersion = object.redisVersion ?? "";
    message.reservedIpRange = object.reservedIpRange ?? "";
    message.secondaryIpRange = object.secondaryIpRange ?? "";
    message.host = object.host ?? "";
    message.port = object.port ?? 0;
    message.currentLocationId = object.currentLocationId ?? "";
    message.createTime = object.createTime ?? undefined;
    message.state = object.state ?? 0;
    message.statusMessage = object.statusMessage ?? "";
    message.redisConfigs = Object.entries(object.redisConfigs ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.tier = object.tier ?? 0;
    message.memorySizeGb = object.memorySizeGb ?? 0;
    message.authorizedNetwork = object.authorizedNetwork ?? "";
    message.persistenceIamIdentity = object.persistenceIamIdentity ?? "";
    message.connectMode = object.connectMode ?? 0;
    message.authEnabled = object.authEnabled ?? false;
    message.serverCaCerts = object.serverCaCerts?.map((e) => TlsCertificate.fromPartial(e)) || [];
    message.transitEncryptionMode = object.transitEncryptionMode ?? 0;
    message.maintenancePolicy = (object.maintenancePolicy !== undefined && object.maintenancePolicy !== null)
      ? MaintenancePolicy.fromPartial(object.maintenancePolicy)
      : undefined;
    message.maintenanceSchedule = (object.maintenanceSchedule !== undefined && object.maintenanceSchedule !== null)
      ? MaintenanceSchedule.fromPartial(object.maintenanceSchedule)
      : undefined;
    message.replicaCount = object.replicaCount ?? 0;
    message.nodes = object.nodes?.map((e) => NodeInfo.fromPartial(e)) || [];
    message.readEndpoint = object.readEndpoint ?? "";
    message.readEndpointPort = object.readEndpointPort ?? 0;
    message.readReplicasMode = object.readReplicasMode ?? 0;
    message.customerManagedKey = object.customerManagedKey ?? "";
    message.persistenceConfig = (object.persistenceConfig !== undefined && object.persistenceConfig !== null)
      ? PersistenceConfig.fromPartial(object.persistenceConfig)
      : undefined;
    message.suspensionReasons = object.suspensionReasons?.map((e) => e) || [];
    message.maintenanceVersion = object.maintenanceVersion ?? "";
    message.availableMaintenanceVersions = object.availableMaintenanceVersions?.map((e) => e) || [];
    return message;
  },
};

function createBaseInstance_LabelsEntry(): Instance_LabelsEntry {
  return { key: "", value: "" };
}

export const Instance_LabelsEntry: MessageFns<Instance_LabelsEntry> = {
  encode(message: Instance_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Instance_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstance_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Instance_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Instance_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Instance_LabelsEntry>): Instance_LabelsEntry {
    return Instance_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Instance_LabelsEntry>): Instance_LabelsEntry {
    const message = createBaseInstance_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseInstance_RedisConfigsEntry(): Instance_RedisConfigsEntry {
  return { key: "", value: "" };
}

export const Instance_RedisConfigsEntry: MessageFns<Instance_RedisConfigsEntry> = {
  encode(message: Instance_RedisConfigsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Instance_RedisConfigsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstance_RedisConfigsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Instance_RedisConfigsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Instance_RedisConfigsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Instance_RedisConfigsEntry>): Instance_RedisConfigsEntry {
    return Instance_RedisConfigsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Instance_RedisConfigsEntry>): Instance_RedisConfigsEntry {
    const message = createBaseInstance_RedisConfigsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePersistenceConfig(): PersistenceConfig {
  return { persistenceMode: 0, rdbSnapshotPeriod: 0, rdbNextSnapshotTime: undefined, rdbSnapshotStartTime: undefined };
}

export const PersistenceConfig: MessageFns<PersistenceConfig> = {
  encode(message: PersistenceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.persistenceMode !== 0) {
      writer.uint32(8).int32(message.persistenceMode);
    }
    if (message.rdbSnapshotPeriod !== 0) {
      writer.uint32(16).int32(message.rdbSnapshotPeriod);
    }
    if (message.rdbNextSnapshotTime !== undefined) {
      Timestamp.encode(toTimestamp(message.rdbNextSnapshotTime), writer.uint32(34).fork()).join();
    }
    if (message.rdbSnapshotStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.rdbSnapshotStartTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PersistenceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePersistenceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.persistenceMode = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.rdbSnapshotPeriod = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.rdbNextSnapshotTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.rdbSnapshotStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PersistenceConfig {
    return {
      persistenceMode: isSet(object.persistenceMode)
        ? persistenceConfig_PersistenceModeFromJSON(object.persistenceMode)
        : 0,
      rdbSnapshotPeriod: isSet(object.rdbSnapshotPeriod)
        ? persistenceConfig_SnapshotPeriodFromJSON(object.rdbSnapshotPeriod)
        : 0,
      rdbNextSnapshotTime: isSet(object.rdbNextSnapshotTime)
        ? fromJsonTimestamp(object.rdbNextSnapshotTime)
        : undefined,
      rdbSnapshotStartTime: isSet(object.rdbSnapshotStartTime)
        ? fromJsonTimestamp(object.rdbSnapshotStartTime)
        : undefined,
    };
  },

  toJSON(message: PersistenceConfig): unknown {
    const obj: any = {};
    if (message.persistenceMode !== 0) {
      obj.persistenceMode = persistenceConfig_PersistenceModeToJSON(message.persistenceMode);
    }
    if (message.rdbSnapshotPeriod !== 0) {
      obj.rdbSnapshotPeriod = persistenceConfig_SnapshotPeriodToJSON(message.rdbSnapshotPeriod);
    }
    if (message.rdbNextSnapshotTime !== undefined) {
      obj.rdbNextSnapshotTime = message.rdbNextSnapshotTime.toISOString();
    }
    if (message.rdbSnapshotStartTime !== undefined) {
      obj.rdbSnapshotStartTime = message.rdbSnapshotStartTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<PersistenceConfig>): PersistenceConfig {
    return PersistenceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PersistenceConfig>): PersistenceConfig {
    const message = createBasePersistenceConfig();
    message.persistenceMode = object.persistenceMode ?? 0;
    message.rdbSnapshotPeriod = object.rdbSnapshotPeriod ?? 0;
    message.rdbNextSnapshotTime = object.rdbNextSnapshotTime ?? undefined;
    message.rdbSnapshotStartTime = object.rdbSnapshotStartTime ?? undefined;
    return message;
  },
};

function createBaseRescheduleMaintenanceRequest(): RescheduleMaintenanceRequest {
  return { name: "", rescheduleType: 0, scheduleTime: undefined };
}

export const RescheduleMaintenanceRequest: MessageFns<RescheduleMaintenanceRequest> = {
  encode(message: RescheduleMaintenanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.rescheduleType !== 0) {
      writer.uint32(16).int32(message.rescheduleType);
    }
    if (message.scheduleTime !== undefined) {
      Timestamp.encode(toTimestamp(message.scheduleTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RescheduleMaintenanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRescheduleMaintenanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.rescheduleType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.scheduleTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RescheduleMaintenanceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      rescheduleType: isSet(object.rescheduleType)
        ? rescheduleMaintenanceRequest_RescheduleTypeFromJSON(object.rescheduleType)
        : 0,
      scheduleTime: isSet(object.scheduleTime) ? fromJsonTimestamp(object.scheduleTime) : undefined,
    };
  },

  toJSON(message: RescheduleMaintenanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.rescheduleType !== 0) {
      obj.rescheduleType = rescheduleMaintenanceRequest_RescheduleTypeToJSON(message.rescheduleType);
    }
    if (message.scheduleTime !== undefined) {
      obj.scheduleTime = message.scheduleTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<RescheduleMaintenanceRequest>): RescheduleMaintenanceRequest {
    return RescheduleMaintenanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RescheduleMaintenanceRequest>): RescheduleMaintenanceRequest {
    const message = createBaseRescheduleMaintenanceRequest();
    message.name = object.name ?? "";
    message.rescheduleType = object.rescheduleType ?? 0;
    message.scheduleTime = object.scheduleTime ?? undefined;
    return message;
  },
};

function createBaseMaintenancePolicy(): MaintenancePolicy {
  return { createTime: undefined, updateTime: undefined, description: "", weeklyMaintenanceWindow: [] };
}

export const MaintenancePolicy: MessageFns<MaintenancePolicy> = {
  encode(message: MaintenancePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(18).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    for (const v of message.weeklyMaintenanceWindow) {
      WeeklyMaintenanceWindow.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MaintenancePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMaintenancePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.weeklyMaintenanceWindow.push(WeeklyMaintenanceWindow.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MaintenancePolicy {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      weeklyMaintenanceWindow: globalThis.Array.isArray(object?.weeklyMaintenanceWindow)
        ? object.weeklyMaintenanceWindow.map((e: any) => WeeklyMaintenanceWindow.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MaintenancePolicy): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.weeklyMaintenanceWindow?.length) {
      obj.weeklyMaintenanceWindow = message.weeklyMaintenanceWindow.map((e) => WeeklyMaintenanceWindow.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MaintenancePolicy>): MaintenancePolicy {
    return MaintenancePolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MaintenancePolicy>): MaintenancePolicy {
    const message = createBaseMaintenancePolicy();
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.weeklyMaintenanceWindow =
      object.weeklyMaintenanceWindow?.map((e) => WeeklyMaintenanceWindow.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWeeklyMaintenanceWindow(): WeeklyMaintenanceWindow {
  return { day: 0, startTime: undefined, duration: undefined };
}

export const WeeklyMaintenanceWindow: MessageFns<WeeklyMaintenanceWindow> = {
  encode(message: WeeklyMaintenanceWindow, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.day !== 0) {
      writer.uint32(8).int32(message.day);
    }
    if (message.startTime !== undefined) {
      TimeOfDay.encode(message.startTime, writer.uint32(18).fork()).join();
    }
    if (message.duration !== undefined) {
      Duration.encode(message.duration, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WeeklyMaintenanceWindow {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWeeklyMaintenanceWindow();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.day = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = TimeOfDay.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.duration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WeeklyMaintenanceWindow {
    return {
      day: isSet(object.day) ? dayOfWeekFromJSON(object.day) : 0,
      startTime: isSet(object.startTime) ? TimeOfDay.fromJSON(object.startTime) : undefined,
      duration: isSet(object.duration) ? Duration.fromJSON(object.duration) : undefined,
    };
  },

  toJSON(message: WeeklyMaintenanceWindow): unknown {
    const obj: any = {};
    if (message.day !== 0) {
      obj.day = dayOfWeekToJSON(message.day);
    }
    if (message.startTime !== undefined) {
      obj.startTime = TimeOfDay.toJSON(message.startTime);
    }
    if (message.duration !== undefined) {
      obj.duration = Duration.toJSON(message.duration);
    }
    return obj;
  },

  create(base?: DeepPartial<WeeklyMaintenanceWindow>): WeeklyMaintenanceWindow {
    return WeeklyMaintenanceWindow.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WeeklyMaintenanceWindow>): WeeklyMaintenanceWindow {
    const message = createBaseWeeklyMaintenanceWindow();
    message.day = object.day ?? 0;
    message.startTime = (object.startTime !== undefined && object.startTime !== null)
      ? TimeOfDay.fromPartial(object.startTime)
      : undefined;
    message.duration = (object.duration !== undefined && object.duration !== null)
      ? Duration.fromPartial(object.duration)
      : undefined;
    return message;
  },
};

function createBaseMaintenanceSchedule(): MaintenanceSchedule {
  return { startTime: undefined, endTime: undefined, canReschedule: false, scheduleDeadlineTime: undefined };
}

export const MaintenanceSchedule: MessageFns<MaintenanceSchedule> = {
  encode(message: MaintenanceSchedule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.canReschedule !== false) {
      writer.uint32(24).bool(message.canReschedule);
    }
    if (message.scheduleDeadlineTime !== undefined) {
      Timestamp.encode(toTimestamp(message.scheduleDeadlineTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MaintenanceSchedule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMaintenanceSchedule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.canReschedule = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.scheduleDeadlineTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MaintenanceSchedule {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      canReschedule: isSet(object.canReschedule) ? globalThis.Boolean(object.canReschedule) : false,
      scheduleDeadlineTime: isSet(object.scheduleDeadlineTime)
        ? fromJsonTimestamp(object.scheduleDeadlineTime)
        : undefined,
    };
  },

  toJSON(message: MaintenanceSchedule): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.canReschedule !== false) {
      obj.canReschedule = message.canReschedule;
    }
    if (message.scheduleDeadlineTime !== undefined) {
      obj.scheduleDeadlineTime = message.scheduleDeadlineTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<MaintenanceSchedule>): MaintenanceSchedule {
    return MaintenanceSchedule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MaintenanceSchedule>): MaintenanceSchedule {
    const message = createBaseMaintenanceSchedule();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.canReschedule = object.canReschedule ?? false;
    message.scheduleDeadlineTime = object.scheduleDeadlineTime ?? undefined;
    return message;
  },
};

function createBaseListInstancesRequest(): ListInstancesRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListInstancesRequest: MessageFns<ListInstancesRequest> = {
  encode(message: ListInstancesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInstancesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInstancesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInstancesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListInstancesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInstancesRequest>): ListInstancesRequest {
    return ListInstancesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInstancesRequest>): ListInstancesRequest {
    const message = createBaseListInstancesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListInstancesResponse(): ListInstancesResponse {
  return { instances: [], nextPageToken: "", unreachable: [] };
}

export const ListInstancesResponse: MessageFns<ListInstancesResponse> = {
  encode(message: ListInstancesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.instances) {
      Instance.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInstancesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInstancesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instances.push(Instance.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInstancesResponse {
    return {
      instances: globalThis.Array.isArray(object?.instances)
        ? object.instances.map((e: any) => Instance.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListInstancesResponse): unknown {
    const obj: any = {};
    if (message.instances?.length) {
      obj.instances = message.instances.map((e) => Instance.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInstancesResponse>): ListInstancesResponse {
    return ListInstancesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInstancesResponse>): ListInstancesResponse {
    const message = createBaseListInstancesResponse();
    message.instances = object.instances?.map((e) => Instance.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetInstanceRequest(): GetInstanceRequest {
  return { name: "" };
}

export const GetInstanceRequest: MessageFns<GetInstanceRequest> = {
  encode(message: GetInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetInstanceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetInstanceRequest>): GetInstanceRequest {
    return GetInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetInstanceRequest>): GetInstanceRequest {
    const message = createBaseGetInstanceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGetInstanceAuthStringRequest(): GetInstanceAuthStringRequest {
  return { name: "" };
}

export const GetInstanceAuthStringRequest: MessageFns<GetInstanceAuthStringRequest> = {
  encode(message: GetInstanceAuthStringRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetInstanceAuthStringRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetInstanceAuthStringRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetInstanceAuthStringRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetInstanceAuthStringRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetInstanceAuthStringRequest>): GetInstanceAuthStringRequest {
    return GetInstanceAuthStringRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetInstanceAuthStringRequest>): GetInstanceAuthStringRequest {
    const message = createBaseGetInstanceAuthStringRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseInstanceAuthString(): InstanceAuthString {
  return { authString: "" };
}

export const InstanceAuthString: MessageFns<InstanceAuthString> = {
  encode(message: InstanceAuthString, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.authString !== "") {
      writer.uint32(10).string(message.authString);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstanceAuthString {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstanceAuthString();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.authString = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstanceAuthString {
    return { authString: isSet(object.authString) ? globalThis.String(object.authString) : "" };
  },

  toJSON(message: InstanceAuthString): unknown {
    const obj: any = {};
    if (message.authString !== "") {
      obj.authString = message.authString;
    }
    return obj;
  },

  create(base?: DeepPartial<InstanceAuthString>): InstanceAuthString {
    return InstanceAuthString.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstanceAuthString>): InstanceAuthString {
    const message = createBaseInstanceAuthString();
    message.authString = object.authString ?? "";
    return message;
  },
};

function createBaseCreateInstanceRequest(): CreateInstanceRequest {
  return { parent: "", instanceId: "", instance: undefined };
}

export const CreateInstanceRequest: MessageFns<CreateInstanceRequest> = {
  encode(message: CreateInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.instanceId !== "") {
      writer.uint32(18).string(message.instanceId);
    }
    if (message.instance !== undefined) {
      Instance.encode(message.instance, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instanceId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.instance = Instance.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateInstanceRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      instanceId: isSet(object.instanceId) ? globalThis.String(object.instanceId) : "",
      instance: isSet(object.instance) ? Instance.fromJSON(object.instance) : undefined,
    };
  },

  toJSON(message: CreateInstanceRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.instanceId !== "") {
      obj.instanceId = message.instanceId;
    }
    if (message.instance !== undefined) {
      obj.instance = Instance.toJSON(message.instance);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateInstanceRequest>): CreateInstanceRequest {
    return CreateInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateInstanceRequest>): CreateInstanceRequest {
    const message = createBaseCreateInstanceRequest();
    message.parent = object.parent ?? "";
    message.instanceId = object.instanceId ?? "";
    message.instance = (object.instance !== undefined && object.instance !== null)
      ? Instance.fromPartial(object.instance)
      : undefined;
    return message;
  },
};

function createBaseUpdateInstanceRequest(): UpdateInstanceRequest {
  return { updateMask: undefined, instance: undefined };
}

export const UpdateInstanceRequest: MessageFns<UpdateInstanceRequest> = {
  encode(message: UpdateInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.instance !== undefined) {
      Instance.encode(message.instance, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instance = Instance.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateInstanceRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      instance: isSet(object.instance) ? Instance.fromJSON(object.instance) : undefined,
    };
  },

  toJSON(message: UpdateInstanceRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.instance !== undefined) {
      obj.instance = Instance.toJSON(message.instance);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateInstanceRequest>): UpdateInstanceRequest {
    return UpdateInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateInstanceRequest>): UpdateInstanceRequest {
    const message = createBaseUpdateInstanceRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.instance = (object.instance !== undefined && object.instance !== null)
      ? Instance.fromPartial(object.instance)
      : undefined;
    return message;
  },
};

function createBaseUpgradeInstanceRequest(): UpgradeInstanceRequest {
  return { name: "", redisVersion: "" };
}

export const UpgradeInstanceRequest: MessageFns<UpgradeInstanceRequest> = {
  encode(message: UpgradeInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.redisVersion !== "") {
      writer.uint32(18).string(message.redisVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpgradeInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpgradeInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.redisVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpgradeInstanceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      redisVersion: isSet(object.redisVersion) ? globalThis.String(object.redisVersion) : "",
    };
  },

  toJSON(message: UpgradeInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.redisVersion !== "") {
      obj.redisVersion = message.redisVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<UpgradeInstanceRequest>): UpgradeInstanceRequest {
    return UpgradeInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpgradeInstanceRequest>): UpgradeInstanceRequest {
    const message = createBaseUpgradeInstanceRequest();
    message.name = object.name ?? "";
    message.redisVersion = object.redisVersion ?? "";
    return message;
  },
};

function createBaseDeleteInstanceRequest(): DeleteInstanceRequest {
  return { name: "" };
}

export const DeleteInstanceRequest: MessageFns<DeleteInstanceRequest> = {
  encode(message: DeleteInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteInstanceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteInstanceRequest>): DeleteInstanceRequest {
    return DeleteInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteInstanceRequest>): DeleteInstanceRequest {
    const message = createBaseDeleteInstanceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGcsSource(): GcsSource {
  return { uri: "" };
}

export const GcsSource: MessageFns<GcsSource> = {
  encode(message: GcsSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsSource {
    return { uri: isSet(object.uri) ? globalThis.String(object.uri) : "" };
  },

  toJSON(message: GcsSource): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsSource>): GcsSource {
    return GcsSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsSource>): GcsSource {
    const message = createBaseGcsSource();
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseInputConfig(): InputConfig {
  return { gcsSource: undefined };
}

export const InputConfig: MessageFns<InputConfig> = {
  encode(message: InputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsSource !== undefined) {
      GcsSource.encode(message.gcsSource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsSource = GcsSource.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InputConfig {
    return { gcsSource: isSet(object.gcsSource) ? GcsSource.fromJSON(object.gcsSource) : undefined };
  },

  toJSON(message: InputConfig): unknown {
    const obj: any = {};
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSource.toJSON(message.gcsSource);
    }
    return obj;
  },

  create(base?: DeepPartial<InputConfig>): InputConfig {
    return InputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InputConfig>): InputConfig {
    const message = createBaseInputConfig();
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSource.fromPartial(object.gcsSource)
      : undefined;
    return message;
  },
};

function createBaseImportInstanceRequest(): ImportInstanceRequest {
  return { name: "", inputConfig: undefined };
}

export const ImportInstanceRequest: MessageFns<ImportInstanceRequest> = {
  encode(message: ImportInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.inputConfig !== undefined) {
      InputConfig.encode(message.inputConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inputConfig = InputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportInstanceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      inputConfig: isSet(object.inputConfig) ? InputConfig.fromJSON(object.inputConfig) : undefined,
    };
  },

  toJSON(message: ImportInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.inputConfig !== undefined) {
      obj.inputConfig = InputConfig.toJSON(message.inputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<ImportInstanceRequest>): ImportInstanceRequest {
    return ImportInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportInstanceRequest>): ImportInstanceRequest {
    const message = createBaseImportInstanceRequest();
    message.name = object.name ?? "";
    message.inputConfig = (object.inputConfig !== undefined && object.inputConfig !== null)
      ? InputConfig.fromPartial(object.inputConfig)
      : undefined;
    return message;
  },
};

function createBaseGcsDestination(): GcsDestination {
  return { uri: "" };
}

export const GcsDestination: MessageFns<GcsDestination> = {
  encode(message: GcsDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsDestination {
    return { uri: isSet(object.uri) ? globalThis.String(object.uri) : "" };
  },

  toJSON(message: GcsDestination): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsDestination>): GcsDestination {
    return GcsDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsDestination>): GcsDestination {
    const message = createBaseGcsDestination();
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseOutputConfig(): OutputConfig {
  return { gcsDestination: undefined };
}

export const OutputConfig: MessageFns<OutputConfig> = {
  encode(message: OutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsDestination !== undefined) {
      GcsDestination.encode(message.gcsDestination, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsDestination = GcsDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OutputConfig {
    return {
      gcsDestination: isSet(object.gcsDestination) ? GcsDestination.fromJSON(object.gcsDestination) : undefined,
    };
  },

  toJSON(message: OutputConfig): unknown {
    const obj: any = {};
    if (message.gcsDestination !== undefined) {
      obj.gcsDestination = GcsDestination.toJSON(message.gcsDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<OutputConfig>): OutputConfig {
    return OutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OutputConfig>): OutputConfig {
    const message = createBaseOutputConfig();
    message.gcsDestination = (object.gcsDestination !== undefined && object.gcsDestination !== null)
      ? GcsDestination.fromPartial(object.gcsDestination)
      : undefined;
    return message;
  },
};

function createBaseExportInstanceRequest(): ExportInstanceRequest {
  return { name: "", outputConfig: undefined };
}

export const ExportInstanceRequest: MessageFns<ExportInstanceRequest> = {
  encode(message: ExportInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.outputConfig !== undefined) {
      OutputConfig.encode(message.outputConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.outputConfig = OutputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportInstanceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      outputConfig: isSet(object.outputConfig) ? OutputConfig.fromJSON(object.outputConfig) : undefined,
    };
  },

  toJSON(message: ExportInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = OutputConfig.toJSON(message.outputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportInstanceRequest>): ExportInstanceRequest {
    return ExportInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportInstanceRequest>): ExportInstanceRequest {
    const message = createBaseExportInstanceRequest();
    message.name = object.name ?? "";
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? OutputConfig.fromPartial(object.outputConfig)
      : undefined;
    return message;
  },
};

function createBaseFailoverInstanceRequest(): FailoverInstanceRequest {
  return { name: "", dataProtectionMode: 0 };
}

export const FailoverInstanceRequest: MessageFns<FailoverInstanceRequest> = {
  encode(message: FailoverInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.dataProtectionMode !== 0) {
      writer.uint32(16).int32(message.dataProtectionMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailoverInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailoverInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.dataProtectionMode = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FailoverInstanceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      dataProtectionMode: isSet(object.dataProtectionMode)
        ? failoverInstanceRequest_DataProtectionModeFromJSON(object.dataProtectionMode)
        : 0,
    };
  },

  toJSON(message: FailoverInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.dataProtectionMode !== 0) {
      obj.dataProtectionMode = failoverInstanceRequest_DataProtectionModeToJSON(message.dataProtectionMode);
    }
    return obj;
  },

  create(base?: DeepPartial<FailoverInstanceRequest>): FailoverInstanceRequest {
    return FailoverInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FailoverInstanceRequest>): FailoverInstanceRequest {
    const message = createBaseFailoverInstanceRequest();
    message.name = object.name ?? "";
    message.dataProtectionMode = object.dataProtectionMode ?? 0;
    return message;
  },
};

function createBaseOperationMetadata(): OperationMetadata {
  return {
    createTime: undefined,
    endTime: undefined,
    target: "",
    verb: "",
    statusDetail: "",
    cancelRequested: false,
    apiVersion: "",
  };
}

export const OperationMetadata: MessageFns<OperationMetadata> = {
  encode(message: OperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(26).string(message.target);
    }
    if (message.verb !== "") {
      writer.uint32(34).string(message.verb);
    }
    if (message.statusDetail !== "") {
      writer.uint32(42).string(message.statusDetail);
    }
    if (message.cancelRequested !== false) {
      writer.uint32(48).bool(message.cancelRequested);
    }
    if (message.apiVersion !== "") {
      writer.uint32(58).string(message.apiVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.target = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.statusDetail = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.cancelRequested = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.apiVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OperationMetadata {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      statusDetail: isSet(object.statusDetail) ? globalThis.String(object.statusDetail) : "",
      cancelRequested: isSet(object.cancelRequested) ? globalThis.Boolean(object.cancelRequested) : false,
      apiVersion: isSet(object.apiVersion) ? globalThis.String(object.apiVersion) : "",
    };
  },

  toJSON(message: OperationMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.statusDetail !== "") {
      obj.statusDetail = message.statusDetail;
    }
    if (message.cancelRequested !== false) {
      obj.cancelRequested = message.cancelRequested;
    }
    if (message.apiVersion !== "") {
      obj.apiVersion = message.apiVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<OperationMetadata>): OperationMetadata {
    return OperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OperationMetadata>): OperationMetadata {
    const message = createBaseOperationMetadata();
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.verb = object.verb ?? "";
    message.statusDetail = object.statusDetail ?? "";
    message.cancelRequested = object.cancelRequested ?? false;
    message.apiVersion = object.apiVersion ?? "";
    return message;
  },
};

function createBaseLocationMetadata(): LocationMetadata {
  return { availableZones: {} };
}

export const LocationMetadata: MessageFns<LocationMetadata> = {
  encode(message: LocationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.availableZones).forEach(([key, value]) => {
      LocationMetadata_AvailableZonesEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LocationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLocationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          const entry1 = LocationMetadata_AvailableZonesEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.availableZones[entry1.key] = entry1.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LocationMetadata {
    return {
      availableZones: isObject(object.availableZones)
        ? Object.entries(object.availableZones).reduce<{ [key: string]: ZoneMetadata }>((acc, [key, value]) => {
          acc[key] = ZoneMetadata.fromJSON(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: LocationMetadata): unknown {
    const obj: any = {};
    if (message.availableZones) {
      const entries = Object.entries(message.availableZones);
      if (entries.length > 0) {
        obj.availableZones = {};
        entries.forEach(([k, v]) => {
          obj.availableZones[k] = ZoneMetadata.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<LocationMetadata>): LocationMetadata {
    return LocationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LocationMetadata>): LocationMetadata {
    const message = createBaseLocationMetadata();
    message.availableZones = Object.entries(object.availableZones ?? {}).reduce<{ [key: string]: ZoneMetadata }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = ZoneMetadata.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseLocationMetadata_AvailableZonesEntry(): LocationMetadata_AvailableZonesEntry {
  return { key: "", value: undefined };
}

export const LocationMetadata_AvailableZonesEntry: MessageFns<LocationMetadata_AvailableZonesEntry> = {
  encode(message: LocationMetadata_AvailableZonesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      ZoneMetadata.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LocationMetadata_AvailableZonesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLocationMetadata_AvailableZonesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = ZoneMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LocationMetadata_AvailableZonesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? ZoneMetadata.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: LocationMetadata_AvailableZonesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = ZoneMetadata.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<LocationMetadata_AvailableZonesEntry>): LocationMetadata_AvailableZonesEntry {
    return LocationMetadata_AvailableZonesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LocationMetadata_AvailableZonesEntry>): LocationMetadata_AvailableZonesEntry {
    const message = createBaseLocationMetadata_AvailableZonesEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? ZoneMetadata.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseZoneMetadata(): ZoneMetadata {
  return {};
}

export const ZoneMetadata: MessageFns<ZoneMetadata> = {
  encode(_: ZoneMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ZoneMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZoneMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ZoneMetadata {
    return {};
  },

  toJSON(_: ZoneMetadata): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ZoneMetadata>): ZoneMetadata {
    return ZoneMetadata.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ZoneMetadata>): ZoneMetadata {
    const message = createBaseZoneMetadata();
    return message;
  },
};

function createBaseTlsCertificate(): TlsCertificate {
  return { serialNumber: "", cert: "", createTime: undefined, expireTime: undefined, sha1Fingerprint: "" };
}

export const TlsCertificate: MessageFns<TlsCertificate> = {
  encode(message: TlsCertificate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serialNumber !== "") {
      writer.uint32(10).string(message.serialNumber);
    }
    if (message.cert !== "") {
      writer.uint32(18).string(message.cert);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(34).fork()).join();
    }
    if (message.sha1Fingerprint !== "") {
      writer.uint32(42).string(message.sha1Fingerprint);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TlsCertificate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTlsCertificate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.serialNumber = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cert = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.sha1Fingerprint = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TlsCertificate {
    return {
      serialNumber: isSet(object.serialNumber) ? globalThis.String(object.serialNumber) : "",
      cert: isSet(object.cert) ? globalThis.String(object.cert) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      sha1Fingerprint: isSet(object.sha1Fingerprint) ? globalThis.String(object.sha1Fingerprint) : "",
    };
  },

  toJSON(message: TlsCertificate): unknown {
    const obj: any = {};
    if (message.serialNumber !== "") {
      obj.serialNumber = message.serialNumber;
    }
    if (message.cert !== "") {
      obj.cert = message.cert;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.sha1Fingerprint !== "") {
      obj.sha1Fingerprint = message.sha1Fingerprint;
    }
    return obj;
  },

  create(base?: DeepPartial<TlsCertificate>): TlsCertificate {
    return TlsCertificate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TlsCertificate>): TlsCertificate {
    const message = createBaseTlsCertificate();
    message.serialNumber = object.serialNumber ?? "";
    message.cert = object.cert ?? "";
    message.createTime = object.createTime ?? undefined;
    message.expireTime = object.expireTime ?? undefined;
    message.sha1Fingerprint = object.sha1Fingerprint ?? "";
    return message;
  },
};

/**
 * Configures and manages Cloud Memorystore for Redis instances
 *
 * Google Cloud Memorystore for Redis v1
 *
 * The `redis.googleapis.com` service implements the Google Cloud Memorystore
 * for Redis API and defines the following resource model for managing Redis
 * instances:
 * * The service works with a collection of cloud projects, named: `/projects/*`
 * * Each project has a collection of available locations, named: `/locations/*`
 * * Each location has a collection of Redis instances, named: `/instances/*`
 * * As such, Redis instances are resources of the form:
 *   `/projects/{project_id}/locations/{location_id}/instances/{instance_id}`
 *
 * Note that location_id must be referring to a GCP `region`; for example:
 * * `projects/redpepper-1290/locations/us-central1/instances/my-redis`
 */
export type CloudRedisDefinition = typeof CloudRedisDefinition;
export const CloudRedisDefinition = {
  name: "CloudRedis",
  fullName: "google.cloud.redis.v1.CloudRedis",
  methods: {
    /**
     * Lists all Redis instances owned by a project in either the specified
     * location (region) or all locations.
     *
     * The location should have the following format:
     *
     * * `projects/{project_id}/locations/{location_id}`
     *
     * If `location_id` is specified as `-` (wildcard), then all regions
     * available to the project are queried, and the results are aggregated.
     */
    listInstances: {
      name: "ListInstances",
      requestType: ListInstancesRequest,
      requestStream: false,
      responseType: ListInstancesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets the details of a specific Redis instance. */
    getInstance: {
      name: "GetInstance",
      requestType: GetInstanceRequest,
      requestStream: false,
      responseType: Instance,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the AUTH string for a Redis instance. If AUTH is not enabled for the
     * instance the response will be empty. This information is not included in
     * the details returned to GetInstance.
     */
    getInstanceAuthString: {
      name: "GetInstanceAuthString",
      requestType: GetInstanceAuthStringRequest,
      requestStream: false,
      responseType: InstanceAuthString,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              58,
              18,
              56,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              97,
              117,
              116,
              104,
              83,
              116,
              114,
              105,
              110,
              103,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a Redis instance based on the specified tier and memory size.
     *
     * By default, the instance is accessible from the project's
     * [default network](https://cloud.google.com/vpc/docs/vpc).
     *
     * The creation is executed asynchronously and callers may check the returned
     * operation to track its progress. Once the operation is completed the Redis
     * instance will be fully functional. Completed longrunning.Operation will
     * contain the new instance object in the response field.
     *
     * The returned operation is automatically deleted after a few hours, so there
     * is no need to call DeleteOperation.
     */
    createInstance: {
      name: "CreateInstance",
      requestType: CreateInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              95,
              105,
              100,
              44,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              57,
              58,
              8,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              34,
              45,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Updates the metadata and configuration of a specific Redis instance.
     *
     * Completed longrunning.Operation will contain the new instance object
     * in the response field. The returned operation is automatically deleted
     * after a few hours, so there is no need to call DeleteOperation.
     */
    updateInstance: {
      name: "UpdateInstance",
      requestType: UpdateInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              20,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
              44,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              66,
              58,
              8,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              50,
              54,
              47,
              118,
              49,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Upgrades Redis instance to the newer Redis version specified in the
     * request.
     */
    upgradeInstance: {
      name: "UpgradeInstance",
      requestType: UpgradeInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([18, 110, 97, 109, 101, 44, 114, 101, 100, 105, 115, 95, 118, 101, 114, 115, 105, 111, 110]),
          ],
          578365826: [
            Buffer.from([
              58,
              58,
              1,
              42,
              34,
              53,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              117,
              112,
              103,
              114,
              97,
              100,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Import a Redis RDB snapshot file from Cloud Storage into a Redis instance.
     *
     * Redis may stop serving during this operation. Instance state will be
     * IMPORTING for entire operation. When complete, the instance will contain
     * only data from the imported file.
     *
     * The returned operation is automatically deleted after a few hours, so
     * there is no need to call DeleteOperation.
     */
    importInstance: {
      name: "ImportInstance",
      requestType: ImportInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([17, 110, 97, 109, 101, 44, 105, 110, 112, 117, 116, 95, 99, 111, 110, 102, 105, 103])],
          578365826: [
            Buffer.from([
              57,
              58,
              1,
              42,
              34,
              52,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Export Redis instance data into a Redis RDB format file in Cloud Storage.
     *
     * Redis will continue serving during this operation.
     *
     * The returned operation is automatically deleted after a few hours, so
     * there is no need to call DeleteOperation.
     */
    exportInstance: {
      name: "ExportInstance",
      requestType: ExportInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([18, 110, 97, 109, 101, 44, 111, 117, 116, 112, 117, 116, 95, 99, 111, 110, 102, 105, 103]),
          ],
          578365826: [
            Buffer.from([
              57,
              58,
              1,
              42,
              34,
              52,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Initiates a failover of the primary node to current replica node for a
     * specific STANDARD tier Cloud Memorystore for Redis instance.
     */
    failoverInstance: {
      name: "FailoverInstance",
      requestType: FailoverInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              25,
              110,
              97,
              109,
              101,
              44,
              100,
              97,
              116,
              97,
              95,
              112,
              114,
              111,
              116,
              101,
              99,
              116,
              105,
              111,
              110,
              95,
              109,
              111,
              100,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              102,
              97,
              105,
              108,
              111,
              118,
              101,
              114,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a specific Redis instance.  Instance stops serving and data is
     * deleted.
     */
    deleteInstance: {
      name: "DeleteInstance",
      requestType: DeleteInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              64,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              47,
              42,
              45,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Reschedule maintenance for a given instance in a given project and
     * location.
     */
    rescheduleMaintenance: {
      name: "RescheduleMaintenance",
      requestType: RescheduleMaintenanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              99,
              108,
              111,
              117,
              100,
              46,
              114,
              101,
              100,
              105,
              115,
              46,
              118,
              49,
              46,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              36,
              110,
              97,
              109,
              101,
              44,
              32,
              114,
              101,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              95,
              116,
              121,
              112,
              101,
              44,
              32,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              95,
              116,
              105,
              109,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              72,
              58,
              1,
              42,
              34,
              67,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              77,
              97,
              105,
              110,
              116,
              101,
              110,
              97,
              110,
              99,
              101,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface CloudRedisServiceImplementation<CallContextExt = {}> {
  /**
   * Lists all Redis instances owned by a project in either the specified
   * location (region) or all locations.
   *
   * The location should have the following format:
   *
   * * `projects/{project_id}/locations/{location_id}`
   *
   * If `location_id` is specified as `-` (wildcard), then all regions
   * available to the project are queried, and the results are aggregated.
   */
  listInstances(
    request: ListInstancesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListInstancesResponse>>;
  /** Gets the details of a specific Redis instance. */
  getInstance(request: GetInstanceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Instance>>;
  /**
   * Gets the AUTH string for a Redis instance. If AUTH is not enabled for the
   * instance the response will be empty. This information is not included in
   * the details returned to GetInstance.
   */
  getInstanceAuthString(
    request: GetInstanceAuthStringRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InstanceAuthString>>;
  /**
   * Creates a Redis instance based on the specified tier and memory size.
   *
   * By default, the instance is accessible from the project's
   * [default network](https://cloud.google.com/vpc/docs/vpc).
   *
   * The creation is executed asynchronously and callers may check the returned
   * operation to track its progress. Once the operation is completed the Redis
   * instance will be fully functional. Completed longrunning.Operation will
   * contain the new instance object in the response field.
   *
   * The returned operation is automatically deleted after a few hours, so there
   * is no need to call DeleteOperation.
   */
  createInstance(
    request: CreateInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Updates the metadata and configuration of a specific Redis instance.
   *
   * Completed longrunning.Operation will contain the new instance object
   * in the response field. The returned operation is automatically deleted
   * after a few hours, so there is no need to call DeleteOperation.
   */
  updateInstance(
    request: UpdateInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Upgrades Redis instance to the newer Redis version specified in the
   * request.
   */
  upgradeInstance(
    request: UpgradeInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Import a Redis RDB snapshot file from Cloud Storage into a Redis instance.
   *
   * Redis may stop serving during this operation. Instance state will be
   * IMPORTING for entire operation. When complete, the instance will contain
   * only data from the imported file.
   *
   * The returned operation is automatically deleted after a few hours, so
   * there is no need to call DeleteOperation.
   */
  importInstance(
    request: ImportInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Export Redis instance data into a Redis RDB format file in Cloud Storage.
   *
   * Redis will continue serving during this operation.
   *
   * The returned operation is automatically deleted after a few hours, so
   * there is no need to call DeleteOperation.
   */
  exportInstance(
    request: ExportInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Initiates a failover of the primary node to current replica node for a
   * specific STANDARD tier Cloud Memorystore for Redis instance.
   */
  failoverInstance(
    request: FailoverInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deletes a specific Redis instance.  Instance stops serving and data is
   * deleted.
   */
  deleteInstance(
    request: DeleteInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Reschedule maintenance for a given instance in a given project and
   * location.
   */
  rescheduleMaintenance(
    request: RescheduleMaintenanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface CloudRedisClient<CallOptionsExt = {}> {
  /**
   * Lists all Redis instances owned by a project in either the specified
   * location (region) or all locations.
   *
   * The location should have the following format:
   *
   * * `projects/{project_id}/locations/{location_id}`
   *
   * If `location_id` is specified as `-` (wildcard), then all regions
   * available to the project are queried, and the results are aggregated.
   */
  listInstances(
    request: DeepPartial<ListInstancesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListInstancesResponse>;
  /** Gets the details of a specific Redis instance. */
  getInstance(request: DeepPartial<GetInstanceRequest>, options?: CallOptions & CallOptionsExt): Promise<Instance>;
  /**
   * Gets the AUTH string for a Redis instance. If AUTH is not enabled for the
   * instance the response will be empty. This information is not included in
   * the details returned to GetInstance.
   */
  getInstanceAuthString(
    request: DeepPartial<GetInstanceAuthStringRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InstanceAuthString>;
  /**
   * Creates a Redis instance based on the specified tier and memory size.
   *
   * By default, the instance is accessible from the project's
   * [default network](https://cloud.google.com/vpc/docs/vpc).
   *
   * The creation is executed asynchronously and callers may check the returned
   * operation to track its progress. Once the operation is completed the Redis
   * instance will be fully functional. Completed longrunning.Operation will
   * contain the new instance object in the response field.
   *
   * The returned operation is automatically deleted after a few hours, so there
   * is no need to call DeleteOperation.
   */
  createInstance(
    request: DeepPartial<CreateInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Updates the metadata and configuration of a specific Redis instance.
   *
   * Completed longrunning.Operation will contain the new instance object
   * in the response field. The returned operation is automatically deleted
   * after a few hours, so there is no need to call DeleteOperation.
   */
  updateInstance(
    request: DeepPartial<UpdateInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Upgrades Redis instance to the newer Redis version specified in the
   * request.
   */
  upgradeInstance(
    request: DeepPartial<UpgradeInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Import a Redis RDB snapshot file from Cloud Storage into a Redis instance.
   *
   * Redis may stop serving during this operation. Instance state will be
   * IMPORTING for entire operation. When complete, the instance will contain
   * only data from the imported file.
   *
   * The returned operation is automatically deleted after a few hours, so
   * there is no need to call DeleteOperation.
   */
  importInstance(
    request: DeepPartial<ImportInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Export Redis instance data into a Redis RDB format file in Cloud Storage.
   *
   * Redis will continue serving during this operation.
   *
   * The returned operation is automatically deleted after a few hours, so
   * there is no need to call DeleteOperation.
   */
  exportInstance(
    request: DeepPartial<ExportInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Initiates a failover of the primary node to current replica node for a
   * specific STANDARD tier Cloud Memorystore for Redis instance.
   */
  failoverInstance(
    request: DeepPartial<FailoverInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deletes a specific Redis instance.  Instance stops serving and data is
   * deleted.
   */
  deleteInstance(
    request: DeepPartial<DeleteInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Reschedule maintenance for a given instance in a given project and
   * location.
   */
  rescheduleMaintenance(
    request: DeepPartial<RescheduleMaintenanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
