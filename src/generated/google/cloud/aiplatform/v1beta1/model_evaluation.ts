// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/model_evaluation.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Value } from "../../../protobuf/struct.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { ExplanationSpec, ModelExplanation } from "./explanation.js";
import { ModelEvaluationSlice_Slice_SliceSpec } from "./model_evaluation_slice.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/**
 * A collection of metrics calculated by comparing Model's predictions on all of
 * the test data against annotations from the test data.
 */
export interface ModelEvaluation {
  /** Output only. The resource name of the ModelEvaluation. */
  name: string;
  /** The display name of the ModelEvaluation. */
  displayName: string;
  /**
   * Points to a YAML file stored on Google Cloud Storage describing the
   * [metrics][google.cloud.aiplatform.v1beta1.ModelEvaluation.metrics] of this
   * ModelEvaluation. The schema is defined as an OpenAPI 3.0.2 [Schema
   * Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
   */
  metricsSchemaUri: string;
  /**
   * Evaluation metrics of the Model. The schema of the metrics is stored in
   * [metrics_schema_uri][google.cloud.aiplatform.v1beta1.ModelEvaluation.metrics_schema_uri]
   */
  metrics:
    | any
    | undefined;
  /** Output only. Timestamp when this ModelEvaluation was created. */
  createTime:
    | Date
    | undefined;
  /**
   * All possible
   * [dimensions][google.cloud.aiplatform.v1beta1.ModelEvaluationSlice.Slice.dimension]
   * of ModelEvaluationSlices. The dimensions can be used as the filter of the
   * [ModelService.ListModelEvaluationSlices][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluationSlices]
   * request, in the form of `slice.dimension = <dimension>`.
   */
  sliceDimensions: string[];
  /**
   * Aggregated explanation metrics for the Model's prediction output over the
   * data this ModelEvaluation uses. This field is populated only if the Model
   * is evaluated with explanations, and only for AutoML tabular Models.
   */
  modelExplanation:
    | ModelExplanation
    | undefined;
  /**
   * Describes the values of
   * [ExplanationSpec][google.cloud.aiplatform.v1beta1.ExplanationSpec] that are
   * used for explaining the predicted values on the evaluated data.
   */
  explanationSpecs: ModelEvaluation_ModelEvaluationExplanationSpec[];
  /**
   * The metadata of the ModelEvaluation.
   * For the ModelEvaluation uploaded from Managed Pipeline, metadata contains a
   * structured value with keys of "pipeline_job_id", "evaluation_dataset_type",
   * "evaluation_dataset_path", "row_based_metrics_path".
   */
  metadata:
    | any
    | undefined;
  /** Specify the configuration for bias detection. */
  biasConfigs: ModelEvaluation_BiasConfig | undefined;
}

export interface ModelEvaluation_ModelEvaluationExplanationSpec {
  /**
   * Explanation type.
   *
   * For AutoML Image Classification models, possible values are:
   *
   *   * `image-integrated-gradients`
   *   * `image-xrai`
   */
  explanationType: string;
  /** Explanation spec details. */
  explanationSpec: ExplanationSpec | undefined;
}

/** Configuration for bias detection. */
export interface ModelEvaluation_BiasConfig {
  /**
   * Specification for how the data should be sliced for bias. It contains a
   * list of slices, with limitation of two slices. The first slice of data
   * will be the slice_a. The second slice in the list (slice_b) will be
   * compared against the first slice. If only a single slice is provided,
   * then slice_a will be compared against "not slice_a".
   * Below are examples with feature "education" with value "low", "medium",
   * "high" in the dataset:
   *
   * Example 1:
   *
   *     bias_slices = [{'education': 'low'}]
   *
   * A single slice provided. In this case, slice_a is the collection of data
   * with 'education' equals 'low', and slice_b is the collection of data with
   * 'education' equals 'medium' or 'high'.
   *
   * Example 2:
   *
   *     bias_slices = [{'education': 'low'},
   *                    {'education': 'high'}]
   *
   * Two slices provided. In this case, slice_a is the collection of data
   * with 'education' equals 'low', and slice_b is the collection of data with
   * 'education' equals 'high'.
   */
  biasSlices:
    | ModelEvaluationSlice_Slice_SliceSpec
    | undefined;
  /** Positive labels selection on the target field. */
  labels: string[];
}

function createBaseModelEvaluation(): ModelEvaluation {
  return {
    name: "",
    displayName: "",
    metricsSchemaUri: "",
    metrics: undefined,
    createTime: undefined,
    sliceDimensions: [],
    modelExplanation: undefined,
    explanationSpecs: [],
    metadata: undefined,
    biasConfigs: undefined,
  };
}

export const ModelEvaluation: MessageFns<ModelEvaluation> = {
  encode(message: ModelEvaluation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(82).string(message.displayName);
    }
    if (message.metricsSchemaUri !== "") {
      writer.uint32(18).string(message.metricsSchemaUri);
    }
    if (message.metrics !== undefined) {
      Value.encode(Value.wrap(message.metrics), writer.uint32(26).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    for (const v of message.sliceDimensions) {
      writer.uint32(42).string(v!);
    }
    if (message.modelExplanation !== undefined) {
      ModelExplanation.encode(message.modelExplanation, writer.uint32(66).fork()).join();
    }
    for (const v of message.explanationSpecs) {
      ModelEvaluation_ModelEvaluationExplanationSpec.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.metadata !== undefined) {
      Value.encode(Value.wrap(message.metadata), writer.uint32(90).fork()).join();
    }
    if (message.biasConfigs !== undefined) {
      ModelEvaluation_BiasConfig.encode(message.biasConfigs, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelEvaluation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelEvaluation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metricsSchemaUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.metrics = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.sliceDimensions.push(reader.string());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.modelExplanation = ModelExplanation.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.explanationSpecs.push(ModelEvaluation_ModelEvaluationExplanationSpec.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.metadata = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.biasConfigs = ModelEvaluation_BiasConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelEvaluation {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      metricsSchemaUri: isSet(object.metricsSchemaUri) ? globalThis.String(object.metricsSchemaUri) : "",
      metrics: isSet(object?.metrics) ? object.metrics : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      sliceDimensions: globalThis.Array.isArray(object?.sliceDimensions)
        ? object.sliceDimensions.map((e: any) => globalThis.String(e))
        : [],
      modelExplanation: isSet(object.modelExplanation) ? ModelExplanation.fromJSON(object.modelExplanation) : undefined,
      explanationSpecs: globalThis.Array.isArray(object?.explanationSpecs)
        ? object.explanationSpecs.map((e: any) => ModelEvaluation_ModelEvaluationExplanationSpec.fromJSON(e))
        : [],
      metadata: isSet(object?.metadata) ? object.metadata : undefined,
      biasConfigs: isSet(object.biasConfigs) ? ModelEvaluation_BiasConfig.fromJSON(object.biasConfigs) : undefined,
    };
  },

  toJSON(message: ModelEvaluation): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.metricsSchemaUri !== "") {
      obj.metricsSchemaUri = message.metricsSchemaUri;
    }
    if (message.metrics !== undefined) {
      obj.metrics = message.metrics;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.sliceDimensions?.length) {
      obj.sliceDimensions = message.sliceDimensions;
    }
    if (message.modelExplanation !== undefined) {
      obj.modelExplanation = ModelExplanation.toJSON(message.modelExplanation);
    }
    if (message.explanationSpecs?.length) {
      obj.explanationSpecs = message.explanationSpecs.map((e) =>
        ModelEvaluation_ModelEvaluationExplanationSpec.toJSON(e)
      );
    }
    if (message.metadata !== undefined) {
      obj.metadata = message.metadata;
    }
    if (message.biasConfigs !== undefined) {
      obj.biasConfigs = ModelEvaluation_BiasConfig.toJSON(message.biasConfigs);
    }
    return obj;
  },

  create(base?: DeepPartial<ModelEvaluation>): ModelEvaluation {
    return ModelEvaluation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelEvaluation>): ModelEvaluation {
    const message = createBaseModelEvaluation();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.metricsSchemaUri = object.metricsSchemaUri ?? "";
    message.metrics = object.metrics ?? undefined;
    message.createTime = object.createTime ?? undefined;
    message.sliceDimensions = object.sliceDimensions?.map((e) => e) || [];
    message.modelExplanation = (object.modelExplanation !== undefined && object.modelExplanation !== null)
      ? ModelExplanation.fromPartial(object.modelExplanation)
      : undefined;
    message.explanationSpecs =
      object.explanationSpecs?.map((e) => ModelEvaluation_ModelEvaluationExplanationSpec.fromPartial(e)) || [];
    message.metadata = object.metadata ?? undefined;
    message.biasConfigs = (object.biasConfigs !== undefined && object.biasConfigs !== null)
      ? ModelEvaluation_BiasConfig.fromPartial(object.biasConfigs)
      : undefined;
    return message;
  },
};

function createBaseModelEvaluation_ModelEvaluationExplanationSpec(): ModelEvaluation_ModelEvaluationExplanationSpec {
  return { explanationType: "", explanationSpec: undefined };
}

export const ModelEvaluation_ModelEvaluationExplanationSpec: MessageFns<
  ModelEvaluation_ModelEvaluationExplanationSpec
> = {
  encode(
    message: ModelEvaluation_ModelEvaluationExplanationSpec,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.explanationType !== "") {
      writer.uint32(10).string(message.explanationType);
    }
    if (message.explanationSpec !== undefined) {
      ExplanationSpec.encode(message.explanationSpec, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelEvaluation_ModelEvaluationExplanationSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelEvaluation_ModelEvaluationExplanationSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.explanationType = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.explanationSpec = ExplanationSpec.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelEvaluation_ModelEvaluationExplanationSpec {
    return {
      explanationType: isSet(object.explanationType) ? globalThis.String(object.explanationType) : "",
      explanationSpec: isSet(object.explanationSpec) ? ExplanationSpec.fromJSON(object.explanationSpec) : undefined,
    };
  },

  toJSON(message: ModelEvaluation_ModelEvaluationExplanationSpec): unknown {
    const obj: any = {};
    if (message.explanationType !== "") {
      obj.explanationType = message.explanationType;
    }
    if (message.explanationSpec !== undefined) {
      obj.explanationSpec = ExplanationSpec.toJSON(message.explanationSpec);
    }
    return obj;
  },

  create(
    base?: DeepPartial<ModelEvaluation_ModelEvaluationExplanationSpec>,
  ): ModelEvaluation_ModelEvaluationExplanationSpec {
    return ModelEvaluation_ModelEvaluationExplanationSpec.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ModelEvaluation_ModelEvaluationExplanationSpec>,
  ): ModelEvaluation_ModelEvaluationExplanationSpec {
    const message = createBaseModelEvaluation_ModelEvaluationExplanationSpec();
    message.explanationType = object.explanationType ?? "";
    message.explanationSpec = (object.explanationSpec !== undefined && object.explanationSpec !== null)
      ? ExplanationSpec.fromPartial(object.explanationSpec)
      : undefined;
    return message;
  },
};

function createBaseModelEvaluation_BiasConfig(): ModelEvaluation_BiasConfig {
  return { biasSlices: undefined, labels: [] };
}

export const ModelEvaluation_BiasConfig: MessageFns<ModelEvaluation_BiasConfig> = {
  encode(message: ModelEvaluation_BiasConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.biasSlices !== undefined) {
      ModelEvaluationSlice_Slice_SliceSpec.encode(message.biasSlices, writer.uint32(10).fork()).join();
    }
    for (const v of message.labels) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelEvaluation_BiasConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelEvaluation_BiasConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.biasSlices = ModelEvaluationSlice_Slice_SliceSpec.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.labels.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelEvaluation_BiasConfig {
    return {
      biasSlices: isSet(object.biasSlices)
        ? ModelEvaluationSlice_Slice_SliceSpec.fromJSON(object.biasSlices)
        : undefined,
      labels: globalThis.Array.isArray(object?.labels) ? object.labels.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: ModelEvaluation_BiasConfig): unknown {
    const obj: any = {};
    if (message.biasSlices !== undefined) {
      obj.biasSlices = ModelEvaluationSlice_Slice_SliceSpec.toJSON(message.biasSlices);
    }
    if (message.labels?.length) {
      obj.labels = message.labels;
    }
    return obj;
  },

  create(base?: DeepPartial<ModelEvaluation_BiasConfig>): ModelEvaluation_BiasConfig {
    return ModelEvaluation_BiasConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelEvaluation_BiasConfig>): ModelEvaluation_BiasConfig {
    const message = createBaseModelEvaluation_BiasConfig();
    message.biasSlices = (object.biasSlices !== undefined && object.biasSlices !== null)
      ? ModelEvaluationSlice_Slice_SliceSpec.fromPartial(object.biasSlices)
      : undefined;
    message.labels = object.labels?.map((e) => e) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
