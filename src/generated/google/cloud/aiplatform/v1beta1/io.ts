// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/io.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { ApiAuth_ApiKeyConfig } from "./api_auth.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/** The storage details for Avro input content. */
export interface AvroSource {
  /** Required. Google Cloud Storage location. */
  gcsSource: GcsSource | undefined;
}

/** The storage details for CSV input content. */
export interface CsvSource {
  /** Required. Google Cloud Storage location. */
  gcsSource: GcsSource | undefined;
}

/** The Google Cloud Storage location for the input content. */
export interface GcsSource {
  /**
   * Required. Google Cloud Storage URI(-s) to the input file(s). May contain
   * wildcards. For more information on wildcards, see
   * https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
   */
  uris: string[];
}

/** The Google Cloud Storage location where the output is to be written to. */
export interface GcsDestination {
  /**
   * Required. Google Cloud Storage URI to output directory. If the uri doesn't
   * end with
   * '/', a '/' will be automatically appended. The directory is created if it
   * doesn't exist.
   */
  outputUriPrefix: string;
}

/** The BigQuery location for the input content. */
export interface BigQuerySource {
  /**
   * Required. BigQuery URI to a table, up to 2000 characters long.
   * Accepted forms:
   *
   * *  BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
   */
  inputUri: string;
}

/** The BigQuery location for the output content. */
export interface BigQueryDestination {
  /**
   * Required. BigQuery URI to a project or table, up to 2000 characters long.
   *
   * When only the project is specified, the Dataset and Table is created.
   * When the full table reference is specified, the Dataset must exist and
   * table must not exist.
   *
   * Accepted forms:
   *
   * *  BigQuery path. For example:
   * `bq://projectId` or `bq://projectId.bqDatasetId` or
   * `bq://projectId.bqDatasetId.bqTableId`.
   */
  outputUri: string;
}

/** The storage details for CSV output content. */
export interface CsvDestination {
  /** Required. Google Cloud Storage location. */
  gcsDestination: GcsDestination | undefined;
}

/** The storage details for TFRecord output content. */
export interface TFRecordDestination {
  /** Required. Google Cloud Storage location. */
  gcsDestination: GcsDestination | undefined;
}

/** The Container Registry location for the container image. */
export interface ContainerRegistryDestination {
  /**
   * Required. Container Registry URI of a container image.
   * Only Google Container Registry and Artifact Registry are supported now.
   * Accepted forms:
   *
   * *  Google Container Registry path. For example:
   *    `gcr.io/projectId/imageName:tag`.
   *
   * *  Artifact Registry path. For example:
   *    `us-central1-docker.pkg.dev/projectId/repoName/imageName:tag`.
   *
   * If a tag is not specified, "latest" will be used as the default tag.
   */
  outputUri: string;
}

/** The Google Drive location for the input content. */
export interface GoogleDriveSource {
  /** Required. Google Drive resource IDs. */
  resourceIds: GoogleDriveSource_ResourceId[];
}

/** The type and ID of the Google Drive resource. */
export interface GoogleDriveSource_ResourceId {
  /** Required. The type of the Google Drive resource. */
  resourceType: GoogleDriveSource_ResourceId_ResourceType;
  /** Required. The ID of the Google Drive resource. */
  resourceId: string;
}

/** The type of the Google Drive resource. */
export enum GoogleDriveSource_ResourceId_ResourceType {
  /** RESOURCE_TYPE_UNSPECIFIED - Unspecified resource type. */
  RESOURCE_TYPE_UNSPECIFIED = 0,
  /** RESOURCE_TYPE_FILE - File resource type. */
  RESOURCE_TYPE_FILE = 1,
  /** RESOURCE_TYPE_FOLDER - Folder resource type. */
  RESOURCE_TYPE_FOLDER = 2,
  UNRECOGNIZED = -1,
}

export function googleDriveSource_ResourceId_ResourceTypeFromJSON(
  object: any,
): GoogleDriveSource_ResourceId_ResourceType {
  switch (object) {
    case 0:
    case "RESOURCE_TYPE_UNSPECIFIED":
      return GoogleDriveSource_ResourceId_ResourceType.RESOURCE_TYPE_UNSPECIFIED;
    case 1:
    case "RESOURCE_TYPE_FILE":
      return GoogleDriveSource_ResourceId_ResourceType.RESOURCE_TYPE_FILE;
    case 2:
    case "RESOURCE_TYPE_FOLDER":
      return GoogleDriveSource_ResourceId_ResourceType.RESOURCE_TYPE_FOLDER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return GoogleDriveSource_ResourceId_ResourceType.UNRECOGNIZED;
  }
}

export function googleDriveSource_ResourceId_ResourceTypeToJSON(
  object: GoogleDriveSource_ResourceId_ResourceType,
): string {
  switch (object) {
    case GoogleDriveSource_ResourceId_ResourceType.RESOURCE_TYPE_UNSPECIFIED:
      return "RESOURCE_TYPE_UNSPECIFIED";
    case GoogleDriveSource_ResourceId_ResourceType.RESOURCE_TYPE_FILE:
      return "RESOURCE_TYPE_FILE";
    case GoogleDriveSource_ResourceId_ResourceType.RESOURCE_TYPE_FOLDER:
      return "RESOURCE_TYPE_FOLDER";
    case GoogleDriveSource_ResourceId_ResourceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The input content is encapsulated and uploaded in the request. */
export interface DirectUploadSource {
}

/** The Slack source for the ImportRagFilesRequest. */
export interface SlackSource {
  /** Required. The Slack channels. */
  channels: SlackSource_SlackChannels[];
}

/** SlackChannels contains the Slack channels and corresponding access token. */
export interface SlackSource_SlackChannels {
  /** Required. The Slack channel IDs. */
  channels: SlackSource_SlackChannels_SlackChannel[];
  /**
   * Required. The SecretManager secret version resource name (e.g.
   * projects/{project}/secrets/{secret}/versions/{version}) storing the
   * Slack channel access token that has access to the slack channel IDs.
   * See: https://api.slack.com/tutorials/tracks/getting-a-token.
   */
  apiKeyConfig: ApiAuth_ApiKeyConfig | undefined;
}

/** SlackChannel contains the Slack channel ID and the time range to import. */
export interface SlackSource_SlackChannels_SlackChannel {
  /** Required. The Slack channel ID. */
  channelId: string;
  /** Optional. The starting timestamp for messages to import. */
  startTime:
    | Date
    | undefined;
  /** Optional. The ending timestamp for messages to import. */
  endTime: Date | undefined;
}

/** The Jira source for the ImportRagFilesRequest. */
export interface JiraSource {
  /** Required. The Jira queries. */
  jiraQueries: JiraSource_JiraQueries[];
}

/** JiraQueries contains the Jira queries and corresponding authentication. */
export interface JiraSource_JiraQueries {
  /** A list of Jira projects to import in their entirety. */
  projects: string[];
  /**
   * A list of custom Jira queries to import. For information about JQL (Jira
   * Query Language), see
   * https://support.atlassian.com/jira-service-management-cloud/docs/use-advanced-search-with-jira-query-language-jql/
   */
  customQueries: string[];
  /** Required. The Jira email address. */
  email: string;
  /** Required. The Jira server URI. */
  serverUri: string;
  /**
   * Required. The SecretManager secret version resource name (e.g.
   * projects/{project}/secrets/{secret}/versions/{version}) storing the
   * Jira API key
   * (https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/).
   */
  apiKeyConfig: ApiAuth_ApiKeyConfig | undefined;
}

/** The SharePointSources to pass to ImportRagFiles. */
export interface SharePointSources {
  /** The SharePoint sources. */
  sharePointSources: SharePointSources_SharePointSource[];
}

/** An individual SharePointSource. */
export interface SharePointSources_SharePointSource {
  /** The path of the SharePoint folder to download from. */
  sharepointFolderPath?:
    | string
    | undefined;
  /** The ID of the SharePoint folder to download from. */
  sharepointFolderId?:
    | string
    | undefined;
  /** The name of the drive to download from. */
  driveName?:
    | string
    | undefined;
  /** The ID of the drive to download from. */
  driveId?:
    | string
    | undefined;
  /**
   * The Application ID for the app registered in Microsoft Azure Portal.
   * The application must also be configured with MS Graph permissions
   * "Files.ReadAll", "Sites.ReadAll" and BrowserSiteLists.Read.All.
   */
  clientId: string;
  /** The application secret for the app registered in Azure. */
  clientSecret:
    | ApiAuth_ApiKeyConfig
    | undefined;
  /** Unique identifier of the Azure Active Directory Instance. */
  tenantId: string;
  /**
   * The name of the SharePoint site to download from. This can be the site
   * name or the site id.
   */
  sharepointSiteName: string;
  /** Output only. The SharePoint file id. Output only. */
  fileId: string;
}

function createBaseAvroSource(): AvroSource {
  return { gcsSource: undefined };
}

export const AvroSource: MessageFns<AvroSource> = {
  encode(message: AvroSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsSource !== undefined) {
      GcsSource.encode(message.gcsSource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AvroSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAvroSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsSource = GcsSource.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AvroSource {
    return { gcsSource: isSet(object.gcsSource) ? GcsSource.fromJSON(object.gcsSource) : undefined };
  },

  toJSON(message: AvroSource): unknown {
    const obj: any = {};
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSource.toJSON(message.gcsSource);
    }
    return obj;
  },

  create(base?: DeepPartial<AvroSource>): AvroSource {
    return AvroSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AvroSource>): AvroSource {
    const message = createBaseAvroSource();
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSource.fromPartial(object.gcsSource)
      : undefined;
    return message;
  },
};

function createBaseCsvSource(): CsvSource {
  return { gcsSource: undefined };
}

export const CsvSource: MessageFns<CsvSource> = {
  encode(message: CsvSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsSource !== undefined) {
      GcsSource.encode(message.gcsSource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CsvSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCsvSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsSource = GcsSource.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CsvSource {
    return { gcsSource: isSet(object.gcsSource) ? GcsSource.fromJSON(object.gcsSource) : undefined };
  },

  toJSON(message: CsvSource): unknown {
    const obj: any = {};
    if (message.gcsSource !== undefined) {
      obj.gcsSource = GcsSource.toJSON(message.gcsSource);
    }
    return obj;
  },

  create(base?: DeepPartial<CsvSource>): CsvSource {
    return CsvSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CsvSource>): CsvSource {
    const message = createBaseCsvSource();
    message.gcsSource = (object.gcsSource !== undefined && object.gcsSource !== null)
      ? GcsSource.fromPartial(object.gcsSource)
      : undefined;
    return message;
  },
};

function createBaseGcsSource(): GcsSource {
  return { uris: [] };
}

export const GcsSource: MessageFns<GcsSource> = {
  encode(message: GcsSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.uris) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uris.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsSource {
    return { uris: globalThis.Array.isArray(object?.uris) ? object.uris.map((e: any) => globalThis.String(e)) : [] };
  },

  toJSON(message: GcsSource): unknown {
    const obj: any = {};
    if (message.uris?.length) {
      obj.uris = message.uris;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsSource>): GcsSource {
    return GcsSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsSource>): GcsSource {
    const message = createBaseGcsSource();
    message.uris = object.uris?.map((e) => e) || [];
    return message;
  },
};

function createBaseGcsDestination(): GcsDestination {
  return { outputUriPrefix: "" };
}

export const GcsDestination: MessageFns<GcsDestination> = {
  encode(message: GcsDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputUriPrefix !== "") {
      writer.uint32(10).string(message.outputUriPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsDestination {
    return { outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "" };
  },

  toJSON(message: GcsDestination): unknown {
    const obj: any = {};
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsDestination>): GcsDestination {
    return GcsDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsDestination>): GcsDestination {
    const message = createBaseGcsDestination();
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    return message;
  },
};

function createBaseBigQuerySource(): BigQuerySource {
  return { inputUri: "" };
}

export const BigQuerySource: MessageFns<BigQuerySource> = {
  encode(message: BigQuerySource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.inputUri !== "") {
      writer.uint32(10).string(message.inputUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQuerySource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQuerySource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQuerySource {
    return { inputUri: isSet(object.inputUri) ? globalThis.String(object.inputUri) : "" };
  },

  toJSON(message: BigQuerySource): unknown {
    const obj: any = {};
    if (message.inputUri !== "") {
      obj.inputUri = message.inputUri;
    }
    return obj;
  },

  create(base?: DeepPartial<BigQuerySource>): BigQuerySource {
    return BigQuerySource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQuerySource>): BigQuerySource {
    const message = createBaseBigQuerySource();
    message.inputUri = object.inputUri ?? "";
    return message;
  },
};

function createBaseBigQueryDestination(): BigQueryDestination {
  return { outputUri: "" };
}

export const BigQueryDestination: MessageFns<BigQueryDestination> = {
  encode(message: BigQueryDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputUri !== "") {
      writer.uint32(10).string(message.outputUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDestination {
    return { outputUri: isSet(object.outputUri) ? globalThis.String(object.outputUri) : "" };
  },

  toJSON(message: BigQueryDestination): unknown {
    const obj: any = {};
    if (message.outputUri !== "") {
      obj.outputUri = message.outputUri;
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryDestination>): BigQueryDestination {
    return BigQueryDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryDestination>): BigQueryDestination {
    const message = createBaseBigQueryDestination();
    message.outputUri = object.outputUri ?? "";
    return message;
  },
};

function createBaseCsvDestination(): CsvDestination {
  return { gcsDestination: undefined };
}

export const CsvDestination: MessageFns<CsvDestination> = {
  encode(message: CsvDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsDestination !== undefined) {
      GcsDestination.encode(message.gcsDestination, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CsvDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCsvDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsDestination = GcsDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CsvDestination {
    return {
      gcsDestination: isSet(object.gcsDestination) ? GcsDestination.fromJSON(object.gcsDestination) : undefined,
    };
  },

  toJSON(message: CsvDestination): unknown {
    const obj: any = {};
    if (message.gcsDestination !== undefined) {
      obj.gcsDestination = GcsDestination.toJSON(message.gcsDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<CsvDestination>): CsvDestination {
    return CsvDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CsvDestination>): CsvDestination {
    const message = createBaseCsvDestination();
    message.gcsDestination = (object.gcsDestination !== undefined && object.gcsDestination !== null)
      ? GcsDestination.fromPartial(object.gcsDestination)
      : undefined;
    return message;
  },
};

function createBaseTFRecordDestination(): TFRecordDestination {
  return { gcsDestination: undefined };
}

export const TFRecordDestination: MessageFns<TFRecordDestination> = {
  encode(message: TFRecordDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcsDestination !== undefined) {
      GcsDestination.encode(message.gcsDestination, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TFRecordDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTFRecordDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.gcsDestination = GcsDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TFRecordDestination {
    return {
      gcsDestination: isSet(object.gcsDestination) ? GcsDestination.fromJSON(object.gcsDestination) : undefined,
    };
  },

  toJSON(message: TFRecordDestination): unknown {
    const obj: any = {};
    if (message.gcsDestination !== undefined) {
      obj.gcsDestination = GcsDestination.toJSON(message.gcsDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<TFRecordDestination>): TFRecordDestination {
    return TFRecordDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TFRecordDestination>): TFRecordDestination {
    const message = createBaseTFRecordDestination();
    message.gcsDestination = (object.gcsDestination !== undefined && object.gcsDestination !== null)
      ? GcsDestination.fromPartial(object.gcsDestination)
      : undefined;
    return message;
  },
};

function createBaseContainerRegistryDestination(): ContainerRegistryDestination {
  return { outputUri: "" };
}

export const ContainerRegistryDestination: MessageFns<ContainerRegistryDestination> = {
  encode(message: ContainerRegistryDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.outputUri !== "") {
      writer.uint32(10).string(message.outputUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerRegistryDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerRegistryDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.outputUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerRegistryDestination {
    return { outputUri: isSet(object.outputUri) ? globalThis.String(object.outputUri) : "" };
  },

  toJSON(message: ContainerRegistryDestination): unknown {
    const obj: any = {};
    if (message.outputUri !== "") {
      obj.outputUri = message.outputUri;
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerRegistryDestination>): ContainerRegistryDestination {
    return ContainerRegistryDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerRegistryDestination>): ContainerRegistryDestination {
    const message = createBaseContainerRegistryDestination();
    message.outputUri = object.outputUri ?? "";
    return message;
  },
};

function createBaseGoogleDriveSource(): GoogleDriveSource {
  return { resourceIds: [] };
}

export const GoogleDriveSource: MessageFns<GoogleDriveSource> = {
  encode(message: GoogleDriveSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.resourceIds) {
      GoogleDriveSource_ResourceId.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GoogleDriveSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGoogleDriveSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resourceIds.push(GoogleDriveSource_ResourceId.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GoogleDriveSource {
    return {
      resourceIds: globalThis.Array.isArray(object?.resourceIds)
        ? object.resourceIds.map((e: any) => GoogleDriveSource_ResourceId.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GoogleDriveSource): unknown {
    const obj: any = {};
    if (message.resourceIds?.length) {
      obj.resourceIds = message.resourceIds.map((e) => GoogleDriveSource_ResourceId.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<GoogleDriveSource>): GoogleDriveSource {
    return GoogleDriveSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GoogleDriveSource>): GoogleDriveSource {
    const message = createBaseGoogleDriveSource();
    message.resourceIds = object.resourceIds?.map((e) => GoogleDriveSource_ResourceId.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGoogleDriveSource_ResourceId(): GoogleDriveSource_ResourceId {
  return { resourceType: 0, resourceId: "" };
}

export const GoogleDriveSource_ResourceId: MessageFns<GoogleDriveSource_ResourceId> = {
  encode(message: GoogleDriveSource_ResourceId, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resourceType !== 0) {
      writer.uint32(8).int32(message.resourceType);
    }
    if (message.resourceId !== "") {
      writer.uint32(18).string(message.resourceId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GoogleDriveSource_ResourceId {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGoogleDriveSource_ResourceId();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.resourceType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resourceId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GoogleDriveSource_ResourceId {
    return {
      resourceType: isSet(object.resourceType)
        ? googleDriveSource_ResourceId_ResourceTypeFromJSON(object.resourceType)
        : 0,
      resourceId: isSet(object.resourceId) ? globalThis.String(object.resourceId) : "",
    };
  },

  toJSON(message: GoogleDriveSource_ResourceId): unknown {
    const obj: any = {};
    if (message.resourceType !== 0) {
      obj.resourceType = googleDriveSource_ResourceId_ResourceTypeToJSON(message.resourceType);
    }
    if (message.resourceId !== "") {
      obj.resourceId = message.resourceId;
    }
    return obj;
  },

  create(base?: DeepPartial<GoogleDriveSource_ResourceId>): GoogleDriveSource_ResourceId {
    return GoogleDriveSource_ResourceId.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GoogleDriveSource_ResourceId>): GoogleDriveSource_ResourceId {
    const message = createBaseGoogleDriveSource_ResourceId();
    message.resourceType = object.resourceType ?? 0;
    message.resourceId = object.resourceId ?? "";
    return message;
  },
};

function createBaseDirectUploadSource(): DirectUploadSource {
  return {};
}

export const DirectUploadSource: MessageFns<DirectUploadSource> = {
  encode(_: DirectUploadSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DirectUploadSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDirectUploadSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DirectUploadSource {
    return {};
  },

  toJSON(_: DirectUploadSource): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DirectUploadSource>): DirectUploadSource {
    return DirectUploadSource.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DirectUploadSource>): DirectUploadSource {
    const message = createBaseDirectUploadSource();
    return message;
  },
};

function createBaseSlackSource(): SlackSource {
  return { channels: [] };
}

export const SlackSource: MessageFns<SlackSource> = {
  encode(message: SlackSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.channels) {
      SlackSource_SlackChannels.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SlackSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSlackSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.channels.push(SlackSource_SlackChannels.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SlackSource {
    return {
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => SlackSource_SlackChannels.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SlackSource): unknown {
    const obj: any = {};
    if (message.channels?.length) {
      obj.channels = message.channels.map((e) => SlackSource_SlackChannels.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SlackSource>): SlackSource {
    return SlackSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SlackSource>): SlackSource {
    const message = createBaseSlackSource();
    message.channels = object.channels?.map((e) => SlackSource_SlackChannels.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSlackSource_SlackChannels(): SlackSource_SlackChannels {
  return { channels: [], apiKeyConfig: undefined };
}

export const SlackSource_SlackChannels: MessageFns<SlackSource_SlackChannels> = {
  encode(message: SlackSource_SlackChannels, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.channels) {
      SlackSource_SlackChannels_SlackChannel.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.apiKeyConfig !== undefined) {
      ApiAuth_ApiKeyConfig.encode(message.apiKeyConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SlackSource_SlackChannels {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSlackSource_SlackChannels();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.channels.push(SlackSource_SlackChannels_SlackChannel.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.apiKeyConfig = ApiAuth_ApiKeyConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SlackSource_SlackChannels {
    return {
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => SlackSource_SlackChannels_SlackChannel.fromJSON(e))
        : [],
      apiKeyConfig: isSet(object.apiKeyConfig) ? ApiAuth_ApiKeyConfig.fromJSON(object.apiKeyConfig) : undefined,
    };
  },

  toJSON(message: SlackSource_SlackChannels): unknown {
    const obj: any = {};
    if (message.channels?.length) {
      obj.channels = message.channels.map((e) => SlackSource_SlackChannels_SlackChannel.toJSON(e));
    }
    if (message.apiKeyConfig !== undefined) {
      obj.apiKeyConfig = ApiAuth_ApiKeyConfig.toJSON(message.apiKeyConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<SlackSource_SlackChannels>): SlackSource_SlackChannels {
    return SlackSource_SlackChannels.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SlackSource_SlackChannels>): SlackSource_SlackChannels {
    const message = createBaseSlackSource_SlackChannels();
    message.channels = object.channels?.map((e) => SlackSource_SlackChannels_SlackChannel.fromPartial(e)) || [];
    message.apiKeyConfig = (object.apiKeyConfig !== undefined && object.apiKeyConfig !== null)
      ? ApiAuth_ApiKeyConfig.fromPartial(object.apiKeyConfig)
      : undefined;
    return message;
  },
};

function createBaseSlackSource_SlackChannels_SlackChannel(): SlackSource_SlackChannels_SlackChannel {
  return { channelId: "", startTime: undefined, endTime: undefined };
}

export const SlackSource_SlackChannels_SlackChannel: MessageFns<SlackSource_SlackChannels_SlackChannel> = {
  encode(message: SlackSource_SlackChannels_SlackChannel, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.channelId !== "") {
      writer.uint32(10).string(message.channelId);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SlackSource_SlackChannels_SlackChannel {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSlackSource_SlackChannels_SlackChannel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.channelId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SlackSource_SlackChannels_SlackChannel {
    return {
      channelId: isSet(object.channelId) ? globalThis.String(object.channelId) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: SlackSource_SlackChannels_SlackChannel): unknown {
    const obj: any = {};
    if (message.channelId !== "") {
      obj.channelId = message.channelId;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<SlackSource_SlackChannels_SlackChannel>): SlackSource_SlackChannels_SlackChannel {
    return SlackSource_SlackChannels_SlackChannel.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SlackSource_SlackChannels_SlackChannel>): SlackSource_SlackChannels_SlackChannel {
    const message = createBaseSlackSource_SlackChannels_SlackChannel();
    message.channelId = object.channelId ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseJiraSource(): JiraSource {
  return { jiraQueries: [] };
}

export const JiraSource: MessageFns<JiraSource> = {
  encode(message: JiraSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.jiraQueries) {
      JiraSource_JiraQueries.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JiraSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJiraSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jiraQueries.push(JiraSource_JiraQueries.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JiraSource {
    return {
      jiraQueries: globalThis.Array.isArray(object?.jiraQueries)
        ? object.jiraQueries.map((e: any) => JiraSource_JiraQueries.fromJSON(e))
        : [],
    };
  },

  toJSON(message: JiraSource): unknown {
    const obj: any = {};
    if (message.jiraQueries?.length) {
      obj.jiraQueries = message.jiraQueries.map((e) => JiraSource_JiraQueries.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<JiraSource>): JiraSource {
    return JiraSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JiraSource>): JiraSource {
    const message = createBaseJiraSource();
    message.jiraQueries = object.jiraQueries?.map((e) => JiraSource_JiraQueries.fromPartial(e)) || [];
    return message;
  },
};

function createBaseJiraSource_JiraQueries(): JiraSource_JiraQueries {
  return { projects: [], customQueries: [], email: "", serverUri: "", apiKeyConfig: undefined };
}

export const JiraSource_JiraQueries: MessageFns<JiraSource_JiraQueries> = {
  encode(message: JiraSource_JiraQueries, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.projects) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.customQueries) {
      writer.uint32(34).string(v!);
    }
    if (message.email !== "") {
      writer.uint32(42).string(message.email);
    }
    if (message.serverUri !== "") {
      writer.uint32(50).string(message.serverUri);
    }
    if (message.apiKeyConfig !== undefined) {
      ApiAuth_ApiKeyConfig.encode(message.apiKeyConfig, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JiraSource_JiraQueries {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJiraSource_JiraQueries();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.projects.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.customQueries.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.email = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.serverUri = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.apiKeyConfig = ApiAuth_ApiKeyConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JiraSource_JiraQueries {
    return {
      projects: globalThis.Array.isArray(object?.projects) ? object.projects.map((e: any) => globalThis.String(e)) : [],
      customQueries: globalThis.Array.isArray(object?.customQueries)
        ? object.customQueries.map((e: any) => globalThis.String(e))
        : [],
      email: isSet(object.email) ? globalThis.String(object.email) : "",
      serverUri: isSet(object.serverUri) ? globalThis.String(object.serverUri) : "",
      apiKeyConfig: isSet(object.apiKeyConfig) ? ApiAuth_ApiKeyConfig.fromJSON(object.apiKeyConfig) : undefined,
    };
  },

  toJSON(message: JiraSource_JiraQueries): unknown {
    const obj: any = {};
    if (message.projects?.length) {
      obj.projects = message.projects;
    }
    if (message.customQueries?.length) {
      obj.customQueries = message.customQueries;
    }
    if (message.email !== "") {
      obj.email = message.email;
    }
    if (message.serverUri !== "") {
      obj.serverUri = message.serverUri;
    }
    if (message.apiKeyConfig !== undefined) {
      obj.apiKeyConfig = ApiAuth_ApiKeyConfig.toJSON(message.apiKeyConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<JiraSource_JiraQueries>): JiraSource_JiraQueries {
    return JiraSource_JiraQueries.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JiraSource_JiraQueries>): JiraSource_JiraQueries {
    const message = createBaseJiraSource_JiraQueries();
    message.projects = object.projects?.map((e) => e) || [];
    message.customQueries = object.customQueries?.map((e) => e) || [];
    message.email = object.email ?? "";
    message.serverUri = object.serverUri ?? "";
    message.apiKeyConfig = (object.apiKeyConfig !== undefined && object.apiKeyConfig !== null)
      ? ApiAuth_ApiKeyConfig.fromPartial(object.apiKeyConfig)
      : undefined;
    return message;
  },
};

function createBaseSharePointSources(): SharePointSources {
  return { sharePointSources: [] };
}

export const SharePointSources: MessageFns<SharePointSources> = {
  encode(message: SharePointSources, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sharePointSources) {
      SharePointSources_SharePointSource.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SharePointSources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSharePointSources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sharePointSources.push(SharePointSources_SharePointSource.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SharePointSources {
    return {
      sharePointSources: globalThis.Array.isArray(object?.sharePointSources)
        ? object.sharePointSources.map((e: any) => SharePointSources_SharePointSource.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SharePointSources): unknown {
    const obj: any = {};
    if (message.sharePointSources?.length) {
      obj.sharePointSources = message.sharePointSources.map((e) => SharePointSources_SharePointSource.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<SharePointSources>): SharePointSources {
    return SharePointSources.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SharePointSources>): SharePointSources {
    const message = createBaseSharePointSources();
    message.sharePointSources =
      object.sharePointSources?.map((e) => SharePointSources_SharePointSource.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSharePointSources_SharePointSource(): SharePointSources_SharePointSource {
  return {
    sharepointFolderPath: undefined,
    sharepointFolderId: undefined,
    driveName: undefined,
    driveId: undefined,
    clientId: "",
    clientSecret: undefined,
    tenantId: "",
    sharepointSiteName: "",
    fileId: "",
  };
}

export const SharePointSources_SharePointSource: MessageFns<SharePointSources_SharePointSource> = {
  encode(message: SharePointSources_SharePointSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sharepointFolderPath !== undefined) {
      writer.uint32(42).string(message.sharepointFolderPath);
    }
    if (message.sharepointFolderId !== undefined) {
      writer.uint32(50).string(message.sharepointFolderId);
    }
    if (message.driveName !== undefined) {
      writer.uint32(58).string(message.driveName);
    }
    if (message.driveId !== undefined) {
      writer.uint32(66).string(message.driveId);
    }
    if (message.clientId !== "") {
      writer.uint32(10).string(message.clientId);
    }
    if (message.clientSecret !== undefined) {
      ApiAuth_ApiKeyConfig.encode(message.clientSecret, writer.uint32(18).fork()).join();
    }
    if (message.tenantId !== "") {
      writer.uint32(26).string(message.tenantId);
    }
    if (message.sharepointSiteName !== "") {
      writer.uint32(34).string(message.sharepointSiteName);
    }
    if (message.fileId !== "") {
      writer.uint32(74).string(message.fileId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SharePointSources_SharePointSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSharePointSources_SharePointSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.sharepointFolderPath = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.sharepointFolderId = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.driveName = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.driveId = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.clientId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.clientSecret = ApiAuth_ApiKeyConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tenantId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sharepointSiteName = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.fileId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SharePointSources_SharePointSource {
    return {
      sharepointFolderPath: isSet(object.sharepointFolderPath)
        ? globalThis.String(object.sharepointFolderPath)
        : undefined,
      sharepointFolderId: isSet(object.sharepointFolderId) ? globalThis.String(object.sharepointFolderId) : undefined,
      driveName: isSet(object.driveName) ? globalThis.String(object.driveName) : undefined,
      driveId: isSet(object.driveId) ? globalThis.String(object.driveId) : undefined,
      clientId: isSet(object.clientId) ? globalThis.String(object.clientId) : "",
      clientSecret: isSet(object.clientSecret) ? ApiAuth_ApiKeyConfig.fromJSON(object.clientSecret) : undefined,
      tenantId: isSet(object.tenantId) ? globalThis.String(object.tenantId) : "",
      sharepointSiteName: isSet(object.sharepointSiteName) ? globalThis.String(object.sharepointSiteName) : "",
      fileId: isSet(object.fileId) ? globalThis.String(object.fileId) : "",
    };
  },

  toJSON(message: SharePointSources_SharePointSource): unknown {
    const obj: any = {};
    if (message.sharepointFolderPath !== undefined) {
      obj.sharepointFolderPath = message.sharepointFolderPath;
    }
    if (message.sharepointFolderId !== undefined) {
      obj.sharepointFolderId = message.sharepointFolderId;
    }
    if (message.driveName !== undefined) {
      obj.driveName = message.driveName;
    }
    if (message.driveId !== undefined) {
      obj.driveId = message.driveId;
    }
    if (message.clientId !== "") {
      obj.clientId = message.clientId;
    }
    if (message.clientSecret !== undefined) {
      obj.clientSecret = ApiAuth_ApiKeyConfig.toJSON(message.clientSecret);
    }
    if (message.tenantId !== "") {
      obj.tenantId = message.tenantId;
    }
    if (message.sharepointSiteName !== "") {
      obj.sharepointSiteName = message.sharepointSiteName;
    }
    if (message.fileId !== "") {
      obj.fileId = message.fileId;
    }
    return obj;
  },

  create(base?: DeepPartial<SharePointSources_SharePointSource>): SharePointSources_SharePointSource {
    return SharePointSources_SharePointSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SharePointSources_SharePointSource>): SharePointSources_SharePointSource {
    const message = createBaseSharePointSources_SharePointSource();
    message.sharepointFolderPath = object.sharepointFolderPath ?? undefined;
    message.sharepointFolderId = object.sharepointFolderId ?? undefined;
    message.driveName = object.driveName ?? undefined;
    message.driveId = object.driveId ?? undefined;
    message.clientId = object.clientId ?? "";
    message.clientSecret = (object.clientSecret !== undefined && object.clientSecret !== null)
      ? ApiAuth_ApiKeyConfig.fromPartial(object.clientSecret)
      : undefined;
    message.tenantId = object.tenantId ?? "";
    message.sharepointSiteName = object.sharepointSiteName ?? "";
    message.fileId = object.fileId ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
