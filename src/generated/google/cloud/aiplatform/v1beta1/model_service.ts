// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/model_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { EncryptionSpec } from "./encryption_spec.js";
import { EvaluatedAnnotation } from "./evaluated_annotation.js";
import { Examples } from "./explanation.js";
import { ContainerRegistryDestination, GcsDestination } from "./io.js";
import { Model } from "./model.js";
import { ModelEvaluation } from "./model_evaluation.js";
import { ModelEvaluationSlice } from "./model_evaluation_slice.js";
import { GenericOperationMetadata } from "./operation.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/**
 * Request message for
 * [ModelService.UploadModel][google.cloud.aiplatform.v1beta1.ModelService.UploadModel].
 */
export interface UploadModelRequest {
  /**
   * Required. The resource name of the Location into which to upload the Model.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * Optional. The resource name of the model into which to upload the version.
   * Only specify this field when uploading a new version.
   */
  parentModel: string;
  /**
   * Optional. The ID to use for the uploaded Model, which will become the final
   * component of the model resource name.
   *
   * This value may be up to 63 characters, and valid characters are
   * `[a-z0-9_-]`. The first character cannot be a number or hyphen.
   */
  modelId: string;
  /** Required. The Model to create. */
  model:
    | Model
    | undefined;
  /**
   * Optional. The user-provided custom service account to use to do the model
   * upload. If empty, [Vertex AI Service
   * Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
   * will be used to access resources needed to upload the model. This account
   * must belong to the target project where the model is uploaded to, i.e., the
   * project specified in the `parent` field of this request and have necessary
   * read permissions (to Google Cloud Storage, Artifact Registry, etc.).
   */
  serviceAccount: string;
}

/**
 * Details of
 * [ModelService.UploadModel][google.cloud.aiplatform.v1beta1.ModelService.UploadModel]
 * operation.
 */
export interface UploadModelOperationMetadata {
  /** The common part of the operation metadata. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/**
 * Response message of
 * [ModelService.UploadModel][google.cloud.aiplatform.v1beta1.ModelService.UploadModel]
 * operation.
 */
export interface UploadModelResponse {
  /**
   * The name of the uploaded Model resource.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   */
  model: string;
  /** Output only. The version ID of the model that is uploaded. */
  modelVersionId: string;
}

/**
 * Request message for
 * [ModelService.GetModel][google.cloud.aiplatform.v1beta1.ModelService.GetModel].
 */
export interface GetModelRequest {
  /**
   * Required. The name of the Model resource.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   *
   * In order to retrieve a specific version of the model, also provide
   * the version ID or version alias.
   *   Example: `projects/{project}/locations/{location}/models/{model}@2`
   *              or
   *            `projects/{project}/locations/{location}/models/{model}@golden`
   * If no version ID or alias is specified, the "default" version will be
   * returned. The "default" version alias is created for the first version of
   * the model, and can be moved to other versions later on. There will be
   * exactly one default version.
   */
  name: string;
}

/**
 * Request message for
 * [ModelService.ListModels][google.cloud.aiplatform.v1beta1.ModelService.ListModels].
 */
export interface ListModelsRequest {
  /**
   * Required. The resource name of the Location to list the Models from.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * An expression for filtering the results of the request. For field names
   * both snake_case and camelCase are supported.
   *
   *   * `model` supports = and !=. `model` represents the Model ID,
   *     i.e. the last segment of the Model's [resource
   *     name][google.cloud.aiplatform.v1beta1.Model.name].
   *   * `display_name` supports = and !=
   *   * `labels` supports general map functions that is:
   *     * `labels.key=value` - key:value equality
   *     * `labels.key:* or labels:key - key existence
   *     * A key including a space must be quoted. `labels."a key"`.
   *   * `base_model_name` only supports =
   *
   * Some examples:
   *
   *   * `model=1234`
   *   * `displayName="myDisplayName"`
   *   * `labels.myKey="myValue"`
   *   * `baseModelName="text-bison"`
   */
  filter: string;
  /** The standard list page size. */
  pageSize: number;
  /**
   * The standard list page token.
   * Typically obtained via
   * [ListModelsResponse.next_page_token][google.cloud.aiplatform.v1beta1.ListModelsResponse.next_page_token]
   * of the previous
   * [ModelService.ListModels][google.cloud.aiplatform.v1beta1.ModelService.ListModels]
   * call.
   */
  pageToken: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [ModelService.ListModels][google.cloud.aiplatform.v1beta1.ModelService.ListModels]
 */
export interface ListModelsResponse {
  /** List of Models in the requested page. */
  models: Model[];
  /**
   * A token to retrieve next page of results.
   * Pass to
   * [ListModelsRequest.page_token][google.cloud.aiplatform.v1beta1.ListModelsRequest.page_token]
   * to obtain that page.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [ModelService.ListModelVersions][google.cloud.aiplatform.v1beta1.ModelService.ListModelVersions].
 */
export interface ListModelVersionsRequest {
  /** Required. The name of the model to list versions for. */
  name: string;
  /** The standard list page size. */
  pageSize: number;
  /**
   * The standard list page token.
   * Typically obtained via
   * [next_page_token][google.cloud.aiplatform.v1beta1.ListModelVersionsResponse.next_page_token]
   * of the previous
   * [ListModelVersions][google.cloud.aiplatform.v1beta1.ModelService.ListModelVersions]
   * call.
   */
  pageToken: string;
  /**
   * An expression for filtering the results of the request. For field names
   * both snake_case and camelCase are supported.
   *
   *   * `labels` supports general map functions that is:
   *     * `labels.key=value` - key:value equality
   *     * `labels.key:* or labels:key - key existence
   *     * A key including a space must be quoted. `labels."a key"`.
   *
   * Some examples:
   *
   *   * `labels.myKey="myValue"`
   */
  filter: string;
  /** Mask specifying which fields to read. */
  readMask:
    | string[]
    | undefined;
  /**
   * A comma-separated list of fields to order by, sorted in ascending order.
   * Use "desc" after a field name for descending.
   * Supported fields:
   *
   *   * `create_time`
   *   * `update_time`
   *
   * Example: `update_time asc, create_time desc`.
   */
  orderBy: string;
}

/**
 * Response message for
 * [ModelService.ListModelVersions][google.cloud.aiplatform.v1beta1.ModelService.ListModelVersions]
 */
export interface ListModelVersionsResponse {
  /**
   * List of Model versions in the requested page.
   * In the returned Model name field, version ID instead of regvision tag will
   * be included.
   */
  models: Model[];
  /**
   * A token to retrieve the next page of results.
   * Pass to
   * [ListModelVersionsRequest.page_token][google.cloud.aiplatform.v1beta1.ListModelVersionsRequest.page_token]
   * to obtain that page.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [ModelService.UpdateModel][google.cloud.aiplatform.v1beta1.ModelService.UpdateModel].
 */
export interface UpdateModelRequest {
  /**
   * Required. The Model which replaces the resource on the server.
   * When Model Versioning is enabled, the model.name will be used to determine
   * whether to update the model or model version.
   * 1. model.name with the @ value, e.g. models/123@1, refers to a version
   * specific update.
   * 2. model.name without the @ value, e.g. models/123, refers to a model
   * update.
   * 3. model.name with @-, e.g. models/123@-, refers to a model update.
   * 4. Supported model fields: display_name, description; supported
   * version-specific fields: version_description. Labels are supported in both
   * scenarios. Both the model labels and the version labels are merged when a
   * model is returned. When updating labels, if the request is for
   * model-specific update, model label gets updated. Otherwise, version labels
   * get updated.
   * 5. A model name or model version name fields update mismatch will cause a
   * precondition error.
   * 6. One request cannot update both the model and the version fields. You
   * must update them separately.
   */
  model:
    | Model
    | undefined;
  /**
   * Required. The update mask applies to the resource.
   * For the `FieldMask` definition, see
   * [google.protobuf.FieldMask][google.protobuf.FieldMask].
   */
  updateMask: string[] | undefined;
}

/**
 * Request message for
 * [ModelService.UpdateExplanationDataset][google.cloud.aiplatform.v1beta1.ModelService.UpdateExplanationDataset].
 */
export interface UpdateExplanationDatasetRequest {
  /**
   * Required. The resource name of the Model to update.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   */
  model: string;
  /** The example config containing the location of the dataset. */
  examples: Examples | undefined;
}

/**
 * Runtime operation information for
 * [ModelService.UpdateExplanationDataset][google.cloud.aiplatform.v1beta1.ModelService.UpdateExplanationDataset].
 */
export interface UpdateExplanationDatasetOperationMetadata {
  /** The common part of the operation metadata. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/**
 * Request message for
 * [ModelService.DeleteModel][google.cloud.aiplatform.v1beta1.ModelService.DeleteModel].
 */
export interface DeleteModelRequest {
  /**
   * Required. The name of the Model resource to be deleted.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   */
  name: string;
}

/**
 * Request message for
 * [ModelService.DeleteModelVersion][google.cloud.aiplatform.v1beta1.ModelService.DeleteModelVersion].
 */
export interface DeleteModelVersionRequest {
  /**
   * Required. The name of the model version to be deleted, with a version ID
   * explicitly included.
   *
   * Example: `projects/{project}/locations/{location}/models/{model}@1234`
   */
  name: string;
}

/**
 * Request message for
 * [ModelService.MergeVersionAliases][google.cloud.aiplatform.v1beta1.ModelService.MergeVersionAliases].
 */
export interface MergeVersionAliasesRequest {
  /**
   * Required. The name of the model version to merge aliases, with a version ID
   * explicitly included.
   *
   * Example: `projects/{project}/locations/{location}/models/{model}@1234`
   */
  name: string;
  /**
   * Required. The set of version aliases to merge.
   * The alias should be at most 128 characters, and match
   * `[a-z][a-zA-Z0-9-]{0,126}[a-z-0-9]`.
   * Add the `-` prefix to an alias means removing that alias from the version.
   * `-` is NOT counted in the 128 characters. Example: `-golden` means removing
   * the `golden` alias from the version.
   *
   * There is NO ordering in aliases, which means
   * 1) The aliases returned from GetModel API might not have the exactly same
   * order from this MergeVersionAliases API. 2) Adding and deleting the same
   * alias in the request is not recommended, and the 2 operations will be
   * cancelled out.
   */
  versionAliases: string[];
}

/**
 * Request message for
 * [ModelService.ExportModel][google.cloud.aiplatform.v1beta1.ModelService.ExportModel].
 */
export interface ExportModelRequest {
  /**
   * Required. The resource name of the Model to export.
   * The resource name may contain version id or version alias to specify the
   * version, if no version is specified, the default version will be exported.
   */
  name: string;
  /** Required. The desired output location and configuration. */
  outputConfig: ExportModelRequest_OutputConfig | undefined;
}

/** Output configuration for the Model export. */
export interface ExportModelRequest_OutputConfig {
  /**
   * The ID of the format in which the Model must be exported. Each Model
   * lists the [export formats it
   * supports][google.cloud.aiplatform.v1beta1.Model.supported_export_formats].
   * If no value is provided here, then the first from the list of the Model's
   * supported formats is used by default.
   */
  exportFormatId: string;
  /**
   * The Cloud Storage location where the Model artifact is to be
   * written to. Under the directory given as the destination a new one with
   * name "`model-export-<model-display-name>-<timestamp-of-export-call>`",
   * where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format,
   * will be created. Inside, the Model and any of its supporting files
   * will be written.
   * This field should only be set when the `exportableContent` field of the
   * [Model.supported_export_formats] object contains `ARTIFACT`.
   */
  artifactDestination:
    | GcsDestination
    | undefined;
  /**
   * The Google Container Registry or Artifact Registry uri where the
   * Model container image will be copied to.
   * This field should only be set when the `exportableContent` field of the
   * [Model.supported_export_formats] object contains `IMAGE`.
   */
  imageDestination: ContainerRegistryDestination | undefined;
}

/**
 * Details of
 * [ModelService.ExportModel][google.cloud.aiplatform.v1beta1.ModelService.ExportModel]
 * operation.
 */
export interface ExportModelOperationMetadata {
  /** The common part of the operation metadata. */
  genericMetadata:
    | GenericOperationMetadata
    | undefined;
  /**
   * Output only. Information further describing the output of this Model
   * export.
   */
  outputInfo: ExportModelOperationMetadata_OutputInfo | undefined;
}

/**
 * Further describes the output of the ExportModel. Supplements
 * [ExportModelRequest.OutputConfig][google.cloud.aiplatform.v1beta1.ExportModelRequest.OutputConfig].
 */
export interface ExportModelOperationMetadata_OutputInfo {
  /**
   * Output only. If the Model artifact is being exported to Google Cloud
   * Storage this is the full path of the directory created, into which the
   * Model files are being written to.
   */
  artifactOutputUri: string;
  /**
   * Output only. If the Model image is being exported to Google Container
   * Registry or Artifact Registry this is the full path of the image created.
   */
  imageOutputUri: string;
}

/**
 * Response message of
 * [ModelService.UpdateExplanationDataset][google.cloud.aiplatform.v1beta1.ModelService.UpdateExplanationDataset]
 * operation.
 */
export interface UpdateExplanationDatasetResponse {
}

/**
 * Response message of
 * [ModelService.ExportModel][google.cloud.aiplatform.v1beta1.ModelService.ExportModel]
 * operation.
 */
export interface ExportModelResponse {
}

/**
 * Request message for
 * [ModelService.CopyModel][google.cloud.aiplatform.v1beta1.ModelService.CopyModel].
 */
export interface CopyModelRequest {
  /**
   * Optional. Copy source_model into a new Model with this ID. The ID will
   * become the final component of the model resource name.
   *
   * This value may be up to 63 characters, and valid characters are
   * `[a-z0-9_-]`. The first character cannot be a number or hyphen.
   */
  modelId?:
    | string
    | undefined;
  /**
   * Optional. Specify this field to copy source_model into this existing
   * Model as a new version. Format:
   * `projects/{project}/locations/{location}/models/{model}`
   */
  parentModel?:
    | string
    | undefined;
  /**
   * Required. The resource name of the Location into which to copy the Model.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * Required. The resource name of the Model to copy. That Model must be in the
   * same Project. Format:
   * `projects/{project}/locations/{location}/models/{model}`
   */
  sourceModel: string;
  /**
   * Customer-managed encryption key options. If this is set,
   * then the Model copy will be encrypted with the provided encryption key.
   */
  encryptionSpec: EncryptionSpec | undefined;
}

/**
 * Details of
 * [ModelService.CopyModel][google.cloud.aiplatform.v1beta1.ModelService.CopyModel]
 * operation.
 */
export interface CopyModelOperationMetadata {
  /** The common part of the operation metadata. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/**
 * Response message of
 * [ModelService.CopyModel][google.cloud.aiplatform.v1beta1.ModelService.CopyModel]
 * operation.
 */
export interface CopyModelResponse {
  /**
   * The name of the copied Model resource.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   */
  model: string;
  /** Output only. The version ID of the model that is copied. */
  modelVersionId: string;
}

/**
 * Request message for
 * [ModelService.ImportModelEvaluation][google.cloud.aiplatform.v1beta1.ModelService.ImportModelEvaluation]
 */
export interface ImportModelEvaluationRequest {
  /**
   * Required. The name of the parent model resource.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   */
  parent: string;
  /** Required. Model evaluation resource to be imported. */
  modelEvaluation: ModelEvaluation | undefined;
}

/**
 * Request message for
 * [ModelService.BatchImportModelEvaluationSlices][google.cloud.aiplatform.v1beta1.ModelService.BatchImportModelEvaluationSlices]
 */
export interface BatchImportModelEvaluationSlicesRequest {
  /**
   * Required. The name of the parent ModelEvaluation resource.
   * Format:
   * `projects/{project}/locations/{location}/models/{model}/evaluations/{evaluation}`
   */
  parent: string;
  /** Required. Model evaluation slice resource to be imported. */
  modelEvaluationSlices: ModelEvaluationSlice[];
}

/**
 * Response message for
 * [ModelService.BatchImportModelEvaluationSlices][google.cloud.aiplatform.v1beta1.ModelService.BatchImportModelEvaluationSlices]
 */
export interface BatchImportModelEvaluationSlicesResponse {
  /**
   * Output only. List of imported
   * [ModelEvaluationSlice.name][google.cloud.aiplatform.v1beta1.ModelEvaluationSlice.name].
   */
  importedModelEvaluationSlices: string[];
}

/**
 * Request message for
 * [ModelService.BatchImportEvaluatedAnnotations][google.cloud.aiplatform.v1beta1.ModelService.BatchImportEvaluatedAnnotations]
 */
export interface BatchImportEvaluatedAnnotationsRequest {
  /**
   * Required. The name of the parent ModelEvaluationSlice resource.
   * Format:
   * `projects/{project}/locations/{location}/models/{model}/evaluations/{evaluation}/slices/{slice}`
   */
  parent: string;
  /** Required. Evaluated annotations resource to be imported. */
  evaluatedAnnotations: EvaluatedAnnotation[];
}

/**
 * Response message for
 * [ModelService.BatchImportEvaluatedAnnotations][google.cloud.aiplatform.v1beta1.ModelService.BatchImportEvaluatedAnnotations]
 */
export interface BatchImportEvaluatedAnnotationsResponse {
  /** Output only. Number of EvaluatedAnnotations imported. */
  importedEvaluatedAnnotationsCount: number;
}

/**
 * Request message for
 * [ModelService.GetModelEvaluation][google.cloud.aiplatform.v1beta1.ModelService.GetModelEvaluation].
 */
export interface GetModelEvaluationRequest {
  /**
   * Required. The name of the ModelEvaluation resource.
   * Format:
   * `projects/{project}/locations/{location}/models/{model}/evaluations/{evaluation}`
   */
  name: string;
}

/**
 * Request message for
 * [ModelService.ListModelEvaluations][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluations].
 */
export interface ListModelEvaluationsRequest {
  /**
   * Required. The resource name of the Model to list the ModelEvaluations from.
   * Format: `projects/{project}/locations/{location}/models/{model}`
   */
  parent: string;
  /** The standard list filter. */
  filter: string;
  /** The standard list page size. */
  pageSize: number;
  /**
   * The standard list page token.
   * Typically obtained via
   * [ListModelEvaluationsResponse.next_page_token][google.cloud.aiplatform.v1beta1.ListModelEvaluationsResponse.next_page_token]
   * of the previous
   * [ModelService.ListModelEvaluations][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluations]
   * call.
   */
  pageToken: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [ModelService.ListModelEvaluations][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluations].
 */
export interface ListModelEvaluationsResponse {
  /** List of ModelEvaluations in the requested page. */
  modelEvaluations: ModelEvaluation[];
  /**
   * A token to retrieve next page of results.
   * Pass to
   * [ListModelEvaluationsRequest.page_token][google.cloud.aiplatform.v1beta1.ListModelEvaluationsRequest.page_token]
   * to obtain that page.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [ModelService.GetModelEvaluationSlice][google.cloud.aiplatform.v1beta1.ModelService.GetModelEvaluationSlice].
 */
export interface GetModelEvaluationSliceRequest {
  /**
   * Required. The name of the ModelEvaluationSlice resource.
   * Format:
   * `projects/{project}/locations/{location}/models/{model}/evaluations/{evaluation}/slices/{slice}`
   */
  name: string;
}

/**
 * Request message for
 * [ModelService.ListModelEvaluationSlices][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluationSlices].
 */
export interface ListModelEvaluationSlicesRequest {
  /**
   * Required. The resource name of the ModelEvaluation to list the
   * ModelEvaluationSlices from. Format:
   * `projects/{project}/locations/{location}/models/{model}/evaluations/{evaluation}`
   */
  parent: string;
  /**
   * The standard list filter.
   *
   *   * `slice.dimension` - for =.
   */
  filter: string;
  /** The standard list page size. */
  pageSize: number;
  /**
   * The standard list page token.
   * Typically obtained via
   * [ListModelEvaluationSlicesResponse.next_page_token][google.cloud.aiplatform.v1beta1.ListModelEvaluationSlicesResponse.next_page_token]
   * of the previous
   * [ModelService.ListModelEvaluationSlices][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluationSlices]
   * call.
   */
  pageToken: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [ModelService.ListModelEvaluationSlices][google.cloud.aiplatform.v1beta1.ModelService.ListModelEvaluationSlices].
 */
export interface ListModelEvaluationSlicesResponse {
  /** List of ModelEvaluations in the requested page. */
  modelEvaluationSlices: ModelEvaluationSlice[];
  /**
   * A token to retrieve next page of results.
   * Pass to
   * [ListModelEvaluationSlicesRequest.page_token][google.cloud.aiplatform.v1beta1.ListModelEvaluationSlicesRequest.page_token]
   * to obtain that page.
   */
  nextPageToken: string;
}

function createBaseUploadModelRequest(): UploadModelRequest {
  return { parent: "", parentModel: "", modelId: "", model: undefined, serviceAccount: "" };
}

export const UploadModelRequest: MessageFns<UploadModelRequest> = {
  encode(message: UploadModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.parentModel !== "") {
      writer.uint32(34).string(message.parentModel);
    }
    if (message.modelId !== "") {
      writer.uint32(42).string(message.modelId);
    }
    if (message.model !== undefined) {
      Model.encode(message.model, writer.uint32(18).fork()).join();
    }
    if (message.serviceAccount !== "") {
      writer.uint32(50).string(message.serviceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parentModel = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.modelId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.model = Model.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadModelRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      parentModel: isSet(object.parentModel) ? globalThis.String(object.parentModel) : "",
      modelId: isSet(object.modelId) ? globalThis.String(object.modelId) : "",
      model: isSet(object.model) ? Model.fromJSON(object.model) : undefined,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
    };
  },

  toJSON(message: UploadModelRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.parentModel !== "") {
      obj.parentModel = message.parentModel;
    }
    if (message.modelId !== "") {
      obj.modelId = message.modelId;
    }
    if (message.model !== undefined) {
      obj.model = Model.toJSON(message.model);
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<UploadModelRequest>): UploadModelRequest {
    return UploadModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadModelRequest>): UploadModelRequest {
    const message = createBaseUploadModelRequest();
    message.parent = object.parent ?? "";
    message.parentModel = object.parentModel ?? "";
    message.modelId = object.modelId ?? "";
    message.model = (object.model !== undefined && object.model !== null) ? Model.fromPartial(object.model) : undefined;
    message.serviceAccount = object.serviceAccount ?? "";
    return message;
  },
};

function createBaseUploadModelOperationMetadata(): UploadModelOperationMetadata {
  return { genericMetadata: undefined };
}

export const UploadModelOperationMetadata: MessageFns<UploadModelOperationMetadata> = {
  encode(message: UploadModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadModelOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: UploadModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<UploadModelOperationMetadata>): UploadModelOperationMetadata {
    return UploadModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadModelOperationMetadata>): UploadModelOperationMetadata {
    const message = createBaseUploadModelOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseUploadModelResponse(): UploadModelResponse {
  return { model: "", modelVersionId: "" };
}

export const UploadModelResponse: MessageFns<UploadModelResponse> = {
  encode(message: UploadModelResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    if (message.modelVersionId !== "") {
      writer.uint32(18).string(message.modelVersionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadModelResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadModelResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.modelVersionId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadModelResponse {
    return {
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      modelVersionId: isSet(object.modelVersionId) ? globalThis.String(object.modelVersionId) : "",
    };
  },

  toJSON(message: UploadModelResponse): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.modelVersionId !== "") {
      obj.modelVersionId = message.modelVersionId;
    }
    return obj;
  },

  create(base?: DeepPartial<UploadModelResponse>): UploadModelResponse {
    return UploadModelResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadModelResponse>): UploadModelResponse {
    const message = createBaseUploadModelResponse();
    message.model = object.model ?? "";
    message.modelVersionId = object.modelVersionId ?? "";
    return message;
  },
};

function createBaseGetModelRequest(): GetModelRequest {
  return { name: "" };
}

export const GetModelRequest: MessageFns<GetModelRequest> = {
  encode(message: GetModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetModelRequest>): GetModelRequest {
    return GetModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetModelRequest>): GetModelRequest {
    const message = createBaseGetModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListModelsRequest(): ListModelsRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", readMask: undefined };
}

export const ListModelsRequest: MessageFns<ListModelsRequest> = {
  encode(message: ListModelsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListModelsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelsRequest>): ListModelsRequest {
    return ListModelsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelsRequest>): ListModelsRequest {
    const message = createBaseListModelsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListModelsResponse(): ListModelsResponse {
  return { models: [], nextPageToken: "" };
}

export const ListModelsResponse: MessageFns<ListModelsResponse> = {
  encode(message: ListModelsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.models) {
      Model.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.models.push(Model.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelsResponse {
    return {
      models: globalThis.Array.isArray(object?.models) ? object.models.map((e: any) => Model.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListModelsResponse): unknown {
    const obj: any = {};
    if (message.models?.length) {
      obj.models = message.models.map((e) => Model.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelsResponse>): ListModelsResponse {
    return ListModelsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelsResponse>): ListModelsResponse {
    const message = createBaseListModelsResponse();
    message.models = object.models?.map((e) => Model.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseListModelVersionsRequest(): ListModelVersionsRequest {
  return { name: "", pageSize: 0, pageToken: "", filter: "", readMask: undefined, orderBy: "" };
}

export const ListModelVersionsRequest: MessageFns<ListModelVersionsRequest> = {
  encode(message: ListModelVersionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    if (message.orderBy !== "") {
      writer.uint32(50).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelVersionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelVersionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelVersionsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListModelVersionsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelVersionsRequest>): ListModelVersionsRequest {
    return ListModelVersionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelVersionsRequest>): ListModelVersionsRequest {
    const message = createBaseListModelVersionsRequest();
    message.name = object.name ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    message.readMask = object.readMask ?? undefined;
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListModelVersionsResponse(): ListModelVersionsResponse {
  return { models: [], nextPageToken: "" };
}

export const ListModelVersionsResponse: MessageFns<ListModelVersionsResponse> = {
  encode(message: ListModelVersionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.models) {
      Model.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelVersionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelVersionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.models.push(Model.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelVersionsResponse {
    return {
      models: globalThis.Array.isArray(object?.models) ? object.models.map((e: any) => Model.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListModelVersionsResponse): unknown {
    const obj: any = {};
    if (message.models?.length) {
      obj.models = message.models.map((e) => Model.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelVersionsResponse>): ListModelVersionsResponse {
    return ListModelVersionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelVersionsResponse>): ListModelVersionsResponse {
    const message = createBaseListModelVersionsResponse();
    message.models = object.models?.map((e) => Model.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateModelRequest(): UpdateModelRequest {
  return { model: undefined, updateMask: undefined };
}

export const UpdateModelRequest: MessageFns<UpdateModelRequest> = {
  encode(message: UpdateModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== undefined) {
      Model.encode(message.model, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = Model.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateModelRequest {
    return {
      model: isSet(object.model) ? Model.fromJSON(object.model) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateModelRequest): unknown {
    const obj: any = {};
    if (message.model !== undefined) {
      obj.model = Model.toJSON(message.model);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateModelRequest>): UpdateModelRequest {
    return UpdateModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateModelRequest>): UpdateModelRequest {
    const message = createBaseUpdateModelRequest();
    message.model = (object.model !== undefined && object.model !== null) ? Model.fromPartial(object.model) : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseUpdateExplanationDatasetRequest(): UpdateExplanationDatasetRequest {
  return { model: "", examples: undefined };
}

export const UpdateExplanationDatasetRequest: MessageFns<UpdateExplanationDatasetRequest> = {
  encode(message: UpdateExplanationDatasetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    if (message.examples !== undefined) {
      Examples.encode(message.examples, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateExplanationDatasetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateExplanationDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.examples = Examples.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateExplanationDatasetRequest {
    return {
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      examples: isSet(object.examples) ? Examples.fromJSON(object.examples) : undefined,
    };
  },

  toJSON(message: UpdateExplanationDatasetRequest): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.examples !== undefined) {
      obj.examples = Examples.toJSON(message.examples);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateExplanationDatasetRequest>): UpdateExplanationDatasetRequest {
    return UpdateExplanationDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateExplanationDatasetRequest>): UpdateExplanationDatasetRequest {
    const message = createBaseUpdateExplanationDatasetRequest();
    message.model = object.model ?? "";
    message.examples = (object.examples !== undefined && object.examples !== null)
      ? Examples.fromPartial(object.examples)
      : undefined;
    return message;
  },
};

function createBaseUpdateExplanationDatasetOperationMetadata(): UpdateExplanationDatasetOperationMetadata {
  return { genericMetadata: undefined };
}

export const UpdateExplanationDatasetOperationMetadata: MessageFns<UpdateExplanationDatasetOperationMetadata> = {
  encode(message: UpdateExplanationDatasetOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateExplanationDatasetOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateExplanationDatasetOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateExplanationDatasetOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: UpdateExplanationDatasetOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateExplanationDatasetOperationMetadata>): UpdateExplanationDatasetOperationMetadata {
    return UpdateExplanationDatasetOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<UpdateExplanationDatasetOperationMetadata>,
  ): UpdateExplanationDatasetOperationMetadata {
    const message = createBaseUpdateExplanationDatasetOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseDeleteModelRequest(): DeleteModelRequest {
  return { name: "" };
}

export const DeleteModelRequest: MessageFns<DeleteModelRequest> = {
  encode(message: DeleteModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteModelRequest>): DeleteModelRequest {
    return DeleteModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteModelRequest>): DeleteModelRequest {
    const message = createBaseDeleteModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDeleteModelVersionRequest(): DeleteModelVersionRequest {
  return { name: "" };
}

export const DeleteModelVersionRequest: MessageFns<DeleteModelVersionRequest> = {
  encode(message: DeleteModelVersionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteModelVersionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteModelVersionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteModelVersionRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteModelVersionRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteModelVersionRequest>): DeleteModelVersionRequest {
    return DeleteModelVersionRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteModelVersionRequest>): DeleteModelVersionRequest {
    const message = createBaseDeleteModelVersionRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseMergeVersionAliasesRequest(): MergeVersionAliasesRequest {
  return { name: "", versionAliases: [] };
}

export const MergeVersionAliasesRequest: MessageFns<MergeVersionAliasesRequest> = {
  encode(message: MergeVersionAliasesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.versionAliases) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MergeVersionAliasesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMergeVersionAliasesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.versionAliases.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MergeVersionAliasesRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      versionAliases: globalThis.Array.isArray(object?.versionAliases)
        ? object.versionAliases.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: MergeVersionAliasesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.versionAliases?.length) {
      obj.versionAliases = message.versionAliases;
    }
    return obj;
  },

  create(base?: DeepPartial<MergeVersionAliasesRequest>): MergeVersionAliasesRequest {
    return MergeVersionAliasesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MergeVersionAliasesRequest>): MergeVersionAliasesRequest {
    const message = createBaseMergeVersionAliasesRequest();
    message.name = object.name ?? "";
    message.versionAliases = object.versionAliases?.map((e) => e) || [];
    return message;
  },
};

function createBaseExportModelRequest(): ExportModelRequest {
  return { name: "", outputConfig: undefined };
}

export const ExportModelRequest: MessageFns<ExportModelRequest> = {
  encode(message: ExportModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.outputConfig !== undefined) {
      ExportModelRequest_OutputConfig.encode(message.outputConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.outputConfig = ExportModelRequest_OutputConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportModelRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      outputConfig: isSet(object.outputConfig)
        ? ExportModelRequest_OutputConfig.fromJSON(object.outputConfig)
        : undefined,
    };
  },

  toJSON(message: ExportModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.outputConfig !== undefined) {
      obj.outputConfig = ExportModelRequest_OutputConfig.toJSON(message.outputConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportModelRequest>): ExportModelRequest {
    return ExportModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportModelRequest>): ExportModelRequest {
    const message = createBaseExportModelRequest();
    message.name = object.name ?? "";
    message.outputConfig = (object.outputConfig !== undefined && object.outputConfig !== null)
      ? ExportModelRequest_OutputConfig.fromPartial(object.outputConfig)
      : undefined;
    return message;
  },
};

function createBaseExportModelRequest_OutputConfig(): ExportModelRequest_OutputConfig {
  return { exportFormatId: "", artifactDestination: undefined, imageDestination: undefined };
}

export const ExportModelRequest_OutputConfig: MessageFns<ExportModelRequest_OutputConfig> = {
  encode(message: ExportModelRequest_OutputConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.exportFormatId !== "") {
      writer.uint32(10).string(message.exportFormatId);
    }
    if (message.artifactDestination !== undefined) {
      GcsDestination.encode(message.artifactDestination, writer.uint32(26).fork()).join();
    }
    if (message.imageDestination !== undefined) {
      ContainerRegistryDestination.encode(message.imageDestination, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportModelRequest_OutputConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportModelRequest_OutputConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.exportFormatId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.artifactDestination = GcsDestination.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.imageDestination = ContainerRegistryDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportModelRequest_OutputConfig {
    return {
      exportFormatId: isSet(object.exportFormatId) ? globalThis.String(object.exportFormatId) : "",
      artifactDestination: isSet(object.artifactDestination)
        ? GcsDestination.fromJSON(object.artifactDestination)
        : undefined,
      imageDestination: isSet(object.imageDestination)
        ? ContainerRegistryDestination.fromJSON(object.imageDestination)
        : undefined,
    };
  },

  toJSON(message: ExportModelRequest_OutputConfig): unknown {
    const obj: any = {};
    if (message.exportFormatId !== "") {
      obj.exportFormatId = message.exportFormatId;
    }
    if (message.artifactDestination !== undefined) {
      obj.artifactDestination = GcsDestination.toJSON(message.artifactDestination);
    }
    if (message.imageDestination !== undefined) {
      obj.imageDestination = ContainerRegistryDestination.toJSON(message.imageDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportModelRequest_OutputConfig>): ExportModelRequest_OutputConfig {
    return ExportModelRequest_OutputConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportModelRequest_OutputConfig>): ExportModelRequest_OutputConfig {
    const message = createBaseExportModelRequest_OutputConfig();
    message.exportFormatId = object.exportFormatId ?? "";
    message.artifactDestination = (object.artifactDestination !== undefined && object.artifactDestination !== null)
      ? GcsDestination.fromPartial(object.artifactDestination)
      : undefined;
    message.imageDestination = (object.imageDestination !== undefined && object.imageDestination !== null)
      ? ContainerRegistryDestination.fromPartial(object.imageDestination)
      : undefined;
    return message;
  },
};

function createBaseExportModelOperationMetadata(): ExportModelOperationMetadata {
  return { genericMetadata: undefined, outputInfo: undefined };
}

export const ExportModelOperationMetadata: MessageFns<ExportModelOperationMetadata> = {
  encode(message: ExportModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    if (message.outputInfo !== undefined) {
      ExportModelOperationMetadata_OutputInfo.encode(message.outputInfo, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.outputInfo = ExportModelOperationMetadata_OutputInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportModelOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
      outputInfo: isSet(object.outputInfo)
        ? ExportModelOperationMetadata_OutputInfo.fromJSON(object.outputInfo)
        : undefined,
    };
  },

  toJSON(message: ExportModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    if (message.outputInfo !== undefined) {
      obj.outputInfo = ExportModelOperationMetadata_OutputInfo.toJSON(message.outputInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportModelOperationMetadata>): ExportModelOperationMetadata {
    return ExportModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportModelOperationMetadata>): ExportModelOperationMetadata {
    const message = createBaseExportModelOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    message.outputInfo = (object.outputInfo !== undefined && object.outputInfo !== null)
      ? ExportModelOperationMetadata_OutputInfo.fromPartial(object.outputInfo)
      : undefined;
    return message;
  },
};

function createBaseExportModelOperationMetadata_OutputInfo(): ExportModelOperationMetadata_OutputInfo {
  return { artifactOutputUri: "", imageOutputUri: "" };
}

export const ExportModelOperationMetadata_OutputInfo: MessageFns<ExportModelOperationMetadata_OutputInfo> = {
  encode(message: ExportModelOperationMetadata_OutputInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.artifactOutputUri !== "") {
      writer.uint32(18).string(message.artifactOutputUri);
    }
    if (message.imageOutputUri !== "") {
      writer.uint32(26).string(message.imageOutputUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportModelOperationMetadata_OutputInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportModelOperationMetadata_OutputInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.artifactOutputUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.imageOutputUri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportModelOperationMetadata_OutputInfo {
    return {
      artifactOutputUri: isSet(object.artifactOutputUri) ? globalThis.String(object.artifactOutputUri) : "",
      imageOutputUri: isSet(object.imageOutputUri) ? globalThis.String(object.imageOutputUri) : "",
    };
  },

  toJSON(message: ExportModelOperationMetadata_OutputInfo): unknown {
    const obj: any = {};
    if (message.artifactOutputUri !== "") {
      obj.artifactOutputUri = message.artifactOutputUri;
    }
    if (message.imageOutputUri !== "") {
      obj.imageOutputUri = message.imageOutputUri;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportModelOperationMetadata_OutputInfo>): ExportModelOperationMetadata_OutputInfo {
    return ExportModelOperationMetadata_OutputInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportModelOperationMetadata_OutputInfo>): ExportModelOperationMetadata_OutputInfo {
    const message = createBaseExportModelOperationMetadata_OutputInfo();
    message.artifactOutputUri = object.artifactOutputUri ?? "";
    message.imageOutputUri = object.imageOutputUri ?? "";
    return message;
  },
};

function createBaseUpdateExplanationDatasetResponse(): UpdateExplanationDatasetResponse {
  return {};
}

export const UpdateExplanationDatasetResponse: MessageFns<UpdateExplanationDatasetResponse> = {
  encode(_: UpdateExplanationDatasetResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateExplanationDatasetResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateExplanationDatasetResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): UpdateExplanationDatasetResponse {
    return {};
  },

  toJSON(_: UpdateExplanationDatasetResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<UpdateExplanationDatasetResponse>): UpdateExplanationDatasetResponse {
    return UpdateExplanationDatasetResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<UpdateExplanationDatasetResponse>): UpdateExplanationDatasetResponse {
    const message = createBaseUpdateExplanationDatasetResponse();
    return message;
  },
};

function createBaseExportModelResponse(): ExportModelResponse {
  return {};
}

export const ExportModelResponse: MessageFns<ExportModelResponse> = {
  encode(_: ExportModelResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportModelResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportModelResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ExportModelResponse {
    return {};
  },

  toJSON(_: ExportModelResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ExportModelResponse>): ExportModelResponse {
    return ExportModelResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ExportModelResponse>): ExportModelResponse {
    const message = createBaseExportModelResponse();
    return message;
  },
};

function createBaseCopyModelRequest(): CopyModelRequest {
  return { modelId: undefined, parentModel: undefined, parent: "", sourceModel: "", encryptionSpec: undefined };
}

export const CopyModelRequest: MessageFns<CopyModelRequest> = {
  encode(message: CopyModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.modelId !== undefined) {
      writer.uint32(34).string(message.modelId);
    }
    if (message.parentModel !== undefined) {
      writer.uint32(42).string(message.parentModel);
    }
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.sourceModel !== "") {
      writer.uint32(18).string(message.sourceModel);
    }
    if (message.encryptionSpec !== undefined) {
      EncryptionSpec.encode(message.encryptionSpec, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CopyModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCopyModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.modelId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.parentModel = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceModel = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.encryptionSpec = EncryptionSpec.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CopyModelRequest {
    return {
      modelId: isSet(object.modelId) ? globalThis.String(object.modelId) : undefined,
      parentModel: isSet(object.parentModel) ? globalThis.String(object.parentModel) : undefined,
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      sourceModel: isSet(object.sourceModel) ? globalThis.String(object.sourceModel) : "",
      encryptionSpec: isSet(object.encryptionSpec) ? EncryptionSpec.fromJSON(object.encryptionSpec) : undefined,
    };
  },

  toJSON(message: CopyModelRequest): unknown {
    const obj: any = {};
    if (message.modelId !== undefined) {
      obj.modelId = message.modelId;
    }
    if (message.parentModel !== undefined) {
      obj.parentModel = message.parentModel;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.sourceModel !== "") {
      obj.sourceModel = message.sourceModel;
    }
    if (message.encryptionSpec !== undefined) {
      obj.encryptionSpec = EncryptionSpec.toJSON(message.encryptionSpec);
    }
    return obj;
  },

  create(base?: DeepPartial<CopyModelRequest>): CopyModelRequest {
    return CopyModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CopyModelRequest>): CopyModelRequest {
    const message = createBaseCopyModelRequest();
    message.modelId = object.modelId ?? undefined;
    message.parentModel = object.parentModel ?? undefined;
    message.parent = object.parent ?? "";
    message.sourceModel = object.sourceModel ?? "";
    message.encryptionSpec = (object.encryptionSpec !== undefined && object.encryptionSpec !== null)
      ? EncryptionSpec.fromPartial(object.encryptionSpec)
      : undefined;
    return message;
  },
};

function createBaseCopyModelOperationMetadata(): CopyModelOperationMetadata {
  return { genericMetadata: undefined };
}

export const CopyModelOperationMetadata: MessageFns<CopyModelOperationMetadata> = {
  encode(message: CopyModelOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CopyModelOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCopyModelOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CopyModelOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: CopyModelOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<CopyModelOperationMetadata>): CopyModelOperationMetadata {
    return CopyModelOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CopyModelOperationMetadata>): CopyModelOperationMetadata {
    const message = createBaseCopyModelOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseCopyModelResponse(): CopyModelResponse {
  return { model: "", modelVersionId: "" };
}

export const CopyModelResponse: MessageFns<CopyModelResponse> = {
  encode(message: CopyModelResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    if (message.modelVersionId !== "") {
      writer.uint32(18).string(message.modelVersionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CopyModelResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCopyModelResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.modelVersionId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CopyModelResponse {
    return {
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      modelVersionId: isSet(object.modelVersionId) ? globalThis.String(object.modelVersionId) : "",
    };
  },

  toJSON(message: CopyModelResponse): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.modelVersionId !== "") {
      obj.modelVersionId = message.modelVersionId;
    }
    return obj;
  },

  create(base?: DeepPartial<CopyModelResponse>): CopyModelResponse {
    return CopyModelResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CopyModelResponse>): CopyModelResponse {
    const message = createBaseCopyModelResponse();
    message.model = object.model ?? "";
    message.modelVersionId = object.modelVersionId ?? "";
    return message;
  },
};

function createBaseImportModelEvaluationRequest(): ImportModelEvaluationRequest {
  return { parent: "", modelEvaluation: undefined };
}

export const ImportModelEvaluationRequest: MessageFns<ImportModelEvaluationRequest> = {
  encode(message: ImportModelEvaluationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.modelEvaluation !== undefined) {
      ModelEvaluation.encode(message.modelEvaluation, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportModelEvaluationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportModelEvaluationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.modelEvaluation = ModelEvaluation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportModelEvaluationRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      modelEvaluation: isSet(object.modelEvaluation) ? ModelEvaluation.fromJSON(object.modelEvaluation) : undefined,
    };
  },

  toJSON(message: ImportModelEvaluationRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.modelEvaluation !== undefined) {
      obj.modelEvaluation = ModelEvaluation.toJSON(message.modelEvaluation);
    }
    return obj;
  },

  create(base?: DeepPartial<ImportModelEvaluationRequest>): ImportModelEvaluationRequest {
    return ImportModelEvaluationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportModelEvaluationRequest>): ImportModelEvaluationRequest {
    const message = createBaseImportModelEvaluationRequest();
    message.parent = object.parent ?? "";
    message.modelEvaluation = (object.modelEvaluation !== undefined && object.modelEvaluation !== null)
      ? ModelEvaluation.fromPartial(object.modelEvaluation)
      : undefined;
    return message;
  },
};

function createBaseBatchImportModelEvaluationSlicesRequest(): BatchImportModelEvaluationSlicesRequest {
  return { parent: "", modelEvaluationSlices: [] };
}

export const BatchImportModelEvaluationSlicesRequest: MessageFns<BatchImportModelEvaluationSlicesRequest> = {
  encode(message: BatchImportModelEvaluationSlicesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.modelEvaluationSlices) {
      ModelEvaluationSlice.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchImportModelEvaluationSlicesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchImportModelEvaluationSlicesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.modelEvaluationSlices.push(ModelEvaluationSlice.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchImportModelEvaluationSlicesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      modelEvaluationSlices: globalThis.Array.isArray(object?.modelEvaluationSlices)
        ? object.modelEvaluationSlices.map((e: any) => ModelEvaluationSlice.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchImportModelEvaluationSlicesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.modelEvaluationSlices?.length) {
      obj.modelEvaluationSlices = message.modelEvaluationSlices.map((e) => ModelEvaluationSlice.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchImportModelEvaluationSlicesRequest>): BatchImportModelEvaluationSlicesRequest {
    return BatchImportModelEvaluationSlicesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchImportModelEvaluationSlicesRequest>): BatchImportModelEvaluationSlicesRequest {
    const message = createBaseBatchImportModelEvaluationSlicesRequest();
    message.parent = object.parent ?? "";
    message.modelEvaluationSlices = object.modelEvaluationSlices?.map((e) => ModelEvaluationSlice.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBatchImportModelEvaluationSlicesResponse(): BatchImportModelEvaluationSlicesResponse {
  return { importedModelEvaluationSlices: [] };
}

export const BatchImportModelEvaluationSlicesResponse: MessageFns<BatchImportModelEvaluationSlicesResponse> = {
  encode(message: BatchImportModelEvaluationSlicesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.importedModelEvaluationSlices) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchImportModelEvaluationSlicesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchImportModelEvaluationSlicesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.importedModelEvaluationSlices.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchImportModelEvaluationSlicesResponse {
    return {
      importedModelEvaluationSlices: globalThis.Array.isArray(object?.importedModelEvaluationSlices)
        ? object.importedModelEvaluationSlices.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: BatchImportModelEvaluationSlicesResponse): unknown {
    const obj: any = {};
    if (message.importedModelEvaluationSlices?.length) {
      obj.importedModelEvaluationSlices = message.importedModelEvaluationSlices;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchImportModelEvaluationSlicesResponse>): BatchImportModelEvaluationSlicesResponse {
    return BatchImportModelEvaluationSlicesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchImportModelEvaluationSlicesResponse>): BatchImportModelEvaluationSlicesResponse {
    const message = createBaseBatchImportModelEvaluationSlicesResponse();
    message.importedModelEvaluationSlices = object.importedModelEvaluationSlices?.map((e) => e) || [];
    return message;
  },
};

function createBaseBatchImportEvaluatedAnnotationsRequest(): BatchImportEvaluatedAnnotationsRequest {
  return { parent: "", evaluatedAnnotations: [] };
}

export const BatchImportEvaluatedAnnotationsRequest: MessageFns<BatchImportEvaluatedAnnotationsRequest> = {
  encode(message: BatchImportEvaluatedAnnotationsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.evaluatedAnnotations) {
      EvaluatedAnnotation.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchImportEvaluatedAnnotationsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchImportEvaluatedAnnotationsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.evaluatedAnnotations.push(EvaluatedAnnotation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchImportEvaluatedAnnotationsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      evaluatedAnnotations: globalThis.Array.isArray(object?.evaluatedAnnotations)
        ? object.evaluatedAnnotations.map((e: any) => EvaluatedAnnotation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchImportEvaluatedAnnotationsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.evaluatedAnnotations?.length) {
      obj.evaluatedAnnotations = message.evaluatedAnnotations.map((e) => EvaluatedAnnotation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchImportEvaluatedAnnotationsRequest>): BatchImportEvaluatedAnnotationsRequest {
    return BatchImportEvaluatedAnnotationsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchImportEvaluatedAnnotationsRequest>): BatchImportEvaluatedAnnotationsRequest {
    const message = createBaseBatchImportEvaluatedAnnotationsRequest();
    message.parent = object.parent ?? "";
    message.evaluatedAnnotations = object.evaluatedAnnotations?.map((e) => EvaluatedAnnotation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBatchImportEvaluatedAnnotationsResponse(): BatchImportEvaluatedAnnotationsResponse {
  return { importedEvaluatedAnnotationsCount: 0 };
}

export const BatchImportEvaluatedAnnotationsResponse: MessageFns<BatchImportEvaluatedAnnotationsResponse> = {
  encode(message: BatchImportEvaluatedAnnotationsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.importedEvaluatedAnnotationsCount !== 0) {
      writer.uint32(8).int32(message.importedEvaluatedAnnotationsCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchImportEvaluatedAnnotationsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchImportEvaluatedAnnotationsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.importedEvaluatedAnnotationsCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchImportEvaluatedAnnotationsResponse {
    return {
      importedEvaluatedAnnotationsCount: isSet(object.importedEvaluatedAnnotationsCount)
        ? globalThis.Number(object.importedEvaluatedAnnotationsCount)
        : 0,
    };
  },

  toJSON(message: BatchImportEvaluatedAnnotationsResponse): unknown {
    const obj: any = {};
    if (message.importedEvaluatedAnnotationsCount !== 0) {
      obj.importedEvaluatedAnnotationsCount = Math.round(message.importedEvaluatedAnnotationsCount);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchImportEvaluatedAnnotationsResponse>): BatchImportEvaluatedAnnotationsResponse {
    return BatchImportEvaluatedAnnotationsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchImportEvaluatedAnnotationsResponse>): BatchImportEvaluatedAnnotationsResponse {
    const message = createBaseBatchImportEvaluatedAnnotationsResponse();
    message.importedEvaluatedAnnotationsCount = object.importedEvaluatedAnnotationsCount ?? 0;
    return message;
  },
};

function createBaseGetModelEvaluationRequest(): GetModelEvaluationRequest {
  return { name: "" };
}

export const GetModelEvaluationRequest: MessageFns<GetModelEvaluationRequest> = {
  encode(message: GetModelEvaluationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetModelEvaluationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetModelEvaluationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetModelEvaluationRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetModelEvaluationRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetModelEvaluationRequest>): GetModelEvaluationRequest {
    return GetModelEvaluationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetModelEvaluationRequest>): GetModelEvaluationRequest {
    const message = createBaseGetModelEvaluationRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListModelEvaluationsRequest(): ListModelEvaluationsRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", readMask: undefined };
}

export const ListModelEvaluationsRequest: MessageFns<ListModelEvaluationsRequest> = {
  encode(message: ListModelEvaluationsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelEvaluationsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelEvaluationsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelEvaluationsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListModelEvaluationsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelEvaluationsRequest>): ListModelEvaluationsRequest {
    return ListModelEvaluationsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelEvaluationsRequest>): ListModelEvaluationsRequest {
    const message = createBaseListModelEvaluationsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListModelEvaluationsResponse(): ListModelEvaluationsResponse {
  return { modelEvaluations: [], nextPageToken: "" };
}

export const ListModelEvaluationsResponse: MessageFns<ListModelEvaluationsResponse> = {
  encode(message: ListModelEvaluationsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.modelEvaluations) {
      ModelEvaluation.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelEvaluationsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelEvaluationsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.modelEvaluations.push(ModelEvaluation.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelEvaluationsResponse {
    return {
      modelEvaluations: globalThis.Array.isArray(object?.modelEvaluations)
        ? object.modelEvaluations.map((e: any) => ModelEvaluation.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListModelEvaluationsResponse): unknown {
    const obj: any = {};
    if (message.modelEvaluations?.length) {
      obj.modelEvaluations = message.modelEvaluations.map((e) => ModelEvaluation.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelEvaluationsResponse>): ListModelEvaluationsResponse {
    return ListModelEvaluationsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelEvaluationsResponse>): ListModelEvaluationsResponse {
    const message = createBaseListModelEvaluationsResponse();
    message.modelEvaluations = object.modelEvaluations?.map((e) => ModelEvaluation.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetModelEvaluationSliceRequest(): GetModelEvaluationSliceRequest {
  return { name: "" };
}

export const GetModelEvaluationSliceRequest: MessageFns<GetModelEvaluationSliceRequest> = {
  encode(message: GetModelEvaluationSliceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetModelEvaluationSliceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetModelEvaluationSliceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetModelEvaluationSliceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetModelEvaluationSliceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetModelEvaluationSliceRequest>): GetModelEvaluationSliceRequest {
    return GetModelEvaluationSliceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetModelEvaluationSliceRequest>): GetModelEvaluationSliceRequest {
    const message = createBaseGetModelEvaluationSliceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListModelEvaluationSlicesRequest(): ListModelEvaluationSlicesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", readMask: undefined };
}

export const ListModelEvaluationSlicesRequest: MessageFns<ListModelEvaluationSlicesRequest> = {
  encode(message: ListModelEvaluationSlicesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelEvaluationSlicesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelEvaluationSlicesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelEvaluationSlicesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListModelEvaluationSlicesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelEvaluationSlicesRequest>): ListModelEvaluationSlicesRequest {
    return ListModelEvaluationSlicesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelEvaluationSlicesRequest>): ListModelEvaluationSlicesRequest {
    const message = createBaseListModelEvaluationSlicesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListModelEvaluationSlicesResponse(): ListModelEvaluationSlicesResponse {
  return { modelEvaluationSlices: [], nextPageToken: "" };
}

export const ListModelEvaluationSlicesResponse: MessageFns<ListModelEvaluationSlicesResponse> = {
  encode(message: ListModelEvaluationSlicesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.modelEvaluationSlices) {
      ModelEvaluationSlice.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelEvaluationSlicesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelEvaluationSlicesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.modelEvaluationSlices.push(ModelEvaluationSlice.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelEvaluationSlicesResponse {
    return {
      modelEvaluationSlices: globalThis.Array.isArray(object?.modelEvaluationSlices)
        ? object.modelEvaluationSlices.map((e: any) => ModelEvaluationSlice.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListModelEvaluationSlicesResponse): unknown {
    const obj: any = {};
    if (message.modelEvaluationSlices?.length) {
      obj.modelEvaluationSlices = message.modelEvaluationSlices.map((e) => ModelEvaluationSlice.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelEvaluationSlicesResponse>): ListModelEvaluationSlicesResponse {
    return ListModelEvaluationSlicesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelEvaluationSlicesResponse>): ListModelEvaluationSlicesResponse {
    const message = createBaseListModelEvaluationSlicesResponse();
    message.modelEvaluationSlices = object.modelEvaluationSlices?.map((e) => ModelEvaluationSlice.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

/** A service for managing Vertex AI's machine learning Models. */
export type ModelServiceDefinition = typeof ModelServiceDefinition;
export const ModelServiceDefinition = {
  name: "ModelService",
  fullName: "google.cloud.aiplatform.v1beta1.ModelService",
  methods: {
    /** Uploads a Model artifact into Vertex AI. */
    uploadModel: {
      name: "UploadModel",
      requestType: UploadModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              51,
              10,
              19,
              85,
              112,
              108,
              111,
              97,
              100,
              77,
              111,
              100,
              101,
              108,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              28,
              85,
              112,
              108,
              111,
              97,
              100,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([12, 112, 97, 114, 101, 110, 116, 44, 109, 111, 100, 101, 108])],
          578365826: [
            Buffer.from([
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              58,
              117,
              112,
              108,
              111,
              97,
              100,
            ]),
          ],
        },
      },
    },
    /** Gets a Model. */
    getModel: {
      name: "GetModel",
      requestType: GetModelRequest,
      requestStream: false,
      responseType: Model,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists Models in a Location. */
    listModels: {
      name: "ListModels",
      requestType: ListModelsRequest,
      requestStream: false,
      responseType: ListModelsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists versions of the specified model. */
    listModelVersions: {
      name: "ListModelVersions",
      requestType: ListModelVersionsRequest,
      requestStream: false,
      responseType: ListModelVersionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              62,
              18,
              60,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              108,
              105,
              115,
              116,
              86,
              101,
              114,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a Model. */
    updateModel: {
      name: "UpdateModel",
      requestType: UpdateModelRequest,
      requestStream: false,
      responseType: Model,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([17, 109, 111, 100, 101, 108, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365826: [
            Buffer.from([
              62,
              58,
              5,
              109,
              111,
              100,
              101,
              108,
              50,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              109,
              111,
              100,
              101,
              108,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Incrementally update the dataset used for an examples model. */
    updateExplanationDataset: {
      name: "UpdateExplanationDataset",
      requestType: UpdateExplanationDatasetRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              77,
              10,
              32,
              85,
              112,
              100,
              97,
              116,
              101,
              69,
              120,
              112,
              108,
              97,
              110,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              41,
              85,
              112,
              100,
              97,
              116,
              101,
              69,
              120,
              112,
              108,
              97,
              110,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([5, 109, 111, 100, 101, 108])],
          578365826: [
            Buffer.from([
              78,
              58,
              1,
              42,
              34,
              73,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              109,
              111,
              100,
              101,
              108,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              117,
              112,
              100,
              97,
              116,
              101,
              69,
              120,
              112,
              108,
              97,
              110,
              97,
              116,
              105,
              111,
              110,
              68,
              97,
              116,
              97,
              115,
              101,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a Model.
     *
     * A model cannot be deleted if any
     * [Endpoint][google.cloud.aiplatform.v1beta1.Endpoint] resource has a
     * [DeployedModel][google.cloud.aiplatform.v1beta1.DeployedModel] based on the
     * model in its
     * [deployed_models][google.cloud.aiplatform.v1beta1.Endpoint.deployed_models]
     * field.
     */
    deleteModel: {
      name: "DeleteModel",
      requestType: DeleteModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              49,
              42,
              47,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a Model version.
     *
     * Model version can only be deleted if there are no
     * [DeployedModels][google.cloud.aiplatform.v1beta1.DeployedModel] created
     * from it. Deleting the only version in the Model is not allowed. Use
     * [DeleteModel][google.cloud.aiplatform.v1beta1.ModelService.DeleteModel] for
     * deleting the Model instead.
     */
    deleteModelVersion: {
      name: "DeleteModelVersion",
      requestType: DeleteModelVersionRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              63,
              42,
              61,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              108,
              101,
              116,
              101,
              86,
              101,
              114,
              115,
              105,
              111,
              110,
            ]),
          ],
        },
      },
    },
    /** Merges a set of aliases for a Model version. */
    mergeVersionAliases: {
      name: "MergeVersionAliases",
      requestType: MergeVersionAliasesRequest,
      requestStream: false,
      responseType: Model,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              110,
              97,
              109,
              101,
              44,
              118,
              101,
              114,
              115,
              105,
              111,
              110,
              95,
              97,
              108,
              105,
              97,
              115,
              101,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              72,
              58,
              1,
              42,
              34,
              67,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              109,
              101,
              114,
              103,
              101,
              86,
              101,
              114,
              115,
              105,
              111,
              110,
              65,
              108,
              105,
              97,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Exports a trained, exportable Model to a location specified by the
     * user. A Model is considered to be exportable if it has at least one
     * [supported export
     * format][google.cloud.aiplatform.v1beta1.Model.supported_export_formats].
     */
    exportModel: {
      name: "ExportModel",
      requestType: ExportModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              51,
              10,
              19,
              69,
              120,
              112,
              111,
              114,
              116,
              77,
              111,
              100,
              101,
              108,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              28,
              69,
              120,
              112,
              111,
              114,
              116,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([18, 110, 97, 109, 101, 44, 111, 117, 116, 112, 117, 116, 95, 99, 111, 110, 102, 105, 103]),
          ],
          578365826: [
            Buffer.from([
              59,
              58,
              1,
              42,
              34,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Copies an already existing Vertex AI Model into the specified Location.
     * The source Model must exist in the same Project.
     * When copying custom Models, the users themselves are responsible for
     * [Model.metadata][google.cloud.aiplatform.v1beta1.Model.metadata] content to
     * be region-agnostic, as well as making sure that any resources (e.g. files)
     * it depends on remain accessible.
     */
    copyModel: {
      name: "CopyModel",
      requestType: CopyModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              47,
              10,
              17,
              67,
              111,
              112,
              121,
              77,
              111,
              100,
              101,
              108,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              26,
              67,
              111,
              112,
              121,
              77,
              111,
              100,
              101,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              19,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              109,
              111,
              100,
              101,
              108,
            ]),
          ],
          578365826: [
            Buffer.from([
              57,
              58,
              1,
              42,
              34,
              52,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              58,
              99,
              111,
              112,
              121,
            ]),
          ],
        },
      },
    },
    /** Imports an externally generated ModelEvaluation. */
    importModelEvaluation: {
      name: "ImportModelEvaluation",
      requestType: ImportModelEvaluationRequest,
      requestStream: false,
      responseType: ModelEvaluation,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              109,
              111,
              100,
              101,
              108,
              95,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              73,
              58,
              1,
              42,
              34,
              68,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /** Imports a list of externally generated ModelEvaluationSlice. */
    batchImportModelEvaluationSlices: {
      name: "BatchImportModelEvaluationSlices",
      requestType: BatchImportModelEvaluationSlicesRequest,
      requestStream: false,
      responseType: BatchImportModelEvaluationSlicesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              30,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              109,
              111,
              100,
              101,
              108,
              95,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              95,
              115,
              108,
              105,
              99,
              101,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              87,
              58,
              1,
              42,
              34,
              82,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              108,
              105,
              99,
              101,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              73,
              109,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /** Imports a list of externally generated EvaluatedAnnotations. */
    batchImportEvaluatedAnnotations: {
      name: "BatchImportEvaluatedAnnotations",
      requestType: BatchImportEvaluatedAnnotationsRequest,
      requestStream: false,
      responseType: BatchImportEvaluatedAnnotationsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              28,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              101,
              100,
              95,
              97,
              110,
              110,
              111,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              89,
              58,
              1,
              42,
              34,
              84,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              108,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              98,
              97,
              116,
              99,
              104,
              73,
              109,
              112,
              111,
              114,
              116,
            ]),
          ],
        },
      },
    },
    /** Gets a ModelEvaluation. */
    getModelEvaluation: {
      name: "GetModelEvaluation",
      requestType: GetModelEvaluationRequest,
      requestStream: false,
      responseType: ModelEvaluation,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              63,
              18,
              61,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists ModelEvaluations in a Model. */
    listModelEvaluations: {
      name: "ListModelEvaluations",
      requestType: ListModelEvaluationsRequest,
      requestStream: false,
      responseType: ListModelEvaluationsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              63,
              18,
              61,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets a ModelEvaluationSlice. */
    getModelEvaluationSlice: {
      name: "GetModelEvaluationSlice",
      requestType: GetModelEvaluationSliceRequest,
      requestStream: false,
      responseType: ModelEvaluationSlice,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              72,
              18,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              115,
              108,
              105,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists ModelEvaluationSlices in a ModelEvaluation. */
    listModelEvaluationSlices: {
      name: "ListModelEvaluationSlices",
      requestType: ListModelEvaluationSlicesRequest,
      requestStream: false,
      responseType: ListModelEvaluationSlicesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              72,
              18,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              47,
              101,
              118,
              97,
              108,
              117,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              115,
              108,
              105,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface ModelServiceImplementation<CallContextExt = {}> {
  /** Uploads a Model artifact into Vertex AI. */
  uploadModel(request: UploadModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Gets a Model. */
  getModel(request: GetModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Model>>;
  /** Lists Models in a Location. */
  listModels(
    request: ListModelsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListModelsResponse>>;
  /** Lists versions of the specified model. */
  listModelVersions(
    request: ListModelVersionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListModelVersionsResponse>>;
  /** Updates a Model. */
  updateModel(request: UpdateModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Model>>;
  /** Incrementally update the dataset used for an examples model. */
  updateExplanationDataset(
    request: UpdateExplanationDatasetRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deletes a Model.
   *
   * A model cannot be deleted if any
   * [Endpoint][google.cloud.aiplatform.v1beta1.Endpoint] resource has a
   * [DeployedModel][google.cloud.aiplatform.v1beta1.DeployedModel] based on the
   * model in its
   * [deployed_models][google.cloud.aiplatform.v1beta1.Endpoint.deployed_models]
   * field.
   */
  deleteModel(request: DeleteModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Deletes a Model version.
   *
   * Model version can only be deleted if there are no
   * [DeployedModels][google.cloud.aiplatform.v1beta1.DeployedModel] created
   * from it. Deleting the only version in the Model is not allowed. Use
   * [DeleteModel][google.cloud.aiplatform.v1beta1.ModelService.DeleteModel] for
   * deleting the Model instead.
   */
  deleteModelVersion(
    request: DeleteModelVersionRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Merges a set of aliases for a Model version. */
  mergeVersionAliases(
    request: MergeVersionAliasesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Model>>;
  /**
   * Exports a trained, exportable Model to a location specified by the
   * user. A Model is considered to be exportable if it has at least one
   * [supported export
   * format][google.cloud.aiplatform.v1beta1.Model.supported_export_formats].
   */
  exportModel(request: ExportModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Copies an already existing Vertex AI Model into the specified Location.
   * The source Model must exist in the same Project.
   * When copying custom Models, the users themselves are responsible for
   * [Model.metadata][google.cloud.aiplatform.v1beta1.Model.metadata] content to
   * be region-agnostic, as well as making sure that any resources (e.g. files)
   * it depends on remain accessible.
   */
  copyModel(request: CopyModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Imports an externally generated ModelEvaluation. */
  importModelEvaluation(
    request: ImportModelEvaluationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ModelEvaluation>>;
  /** Imports a list of externally generated ModelEvaluationSlice. */
  batchImportModelEvaluationSlices(
    request: BatchImportModelEvaluationSlicesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BatchImportModelEvaluationSlicesResponse>>;
  /** Imports a list of externally generated EvaluatedAnnotations. */
  batchImportEvaluatedAnnotations(
    request: BatchImportEvaluatedAnnotationsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BatchImportEvaluatedAnnotationsResponse>>;
  /** Gets a ModelEvaluation. */
  getModelEvaluation(
    request: GetModelEvaluationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ModelEvaluation>>;
  /** Lists ModelEvaluations in a Model. */
  listModelEvaluations(
    request: ListModelEvaluationsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListModelEvaluationsResponse>>;
  /** Gets a ModelEvaluationSlice. */
  getModelEvaluationSlice(
    request: GetModelEvaluationSliceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ModelEvaluationSlice>>;
  /** Lists ModelEvaluationSlices in a ModelEvaluation. */
  listModelEvaluationSlices(
    request: ListModelEvaluationSlicesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListModelEvaluationSlicesResponse>>;
}

export interface ModelServiceClient<CallOptionsExt = {}> {
  /** Uploads a Model artifact into Vertex AI. */
  uploadModel(request: DeepPartial<UploadModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Gets a Model. */
  getModel(request: DeepPartial<GetModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Model>;
  /** Lists Models in a Location. */
  listModels(
    request: DeepPartial<ListModelsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListModelsResponse>;
  /** Lists versions of the specified model. */
  listModelVersions(
    request: DeepPartial<ListModelVersionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListModelVersionsResponse>;
  /** Updates a Model. */
  updateModel(request: DeepPartial<UpdateModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Model>;
  /** Incrementally update the dataset used for an examples model. */
  updateExplanationDataset(
    request: DeepPartial<UpdateExplanationDatasetRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deletes a Model.
   *
   * A model cannot be deleted if any
   * [Endpoint][google.cloud.aiplatform.v1beta1.Endpoint] resource has a
   * [DeployedModel][google.cloud.aiplatform.v1beta1.DeployedModel] based on the
   * model in its
   * [deployed_models][google.cloud.aiplatform.v1beta1.Endpoint.deployed_models]
   * field.
   */
  deleteModel(request: DeepPartial<DeleteModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Deletes a Model version.
   *
   * Model version can only be deleted if there are no
   * [DeployedModels][google.cloud.aiplatform.v1beta1.DeployedModel] created
   * from it. Deleting the only version in the Model is not allowed. Use
   * [DeleteModel][google.cloud.aiplatform.v1beta1.ModelService.DeleteModel] for
   * deleting the Model instead.
   */
  deleteModelVersion(
    request: DeepPartial<DeleteModelVersionRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Merges a set of aliases for a Model version. */
  mergeVersionAliases(
    request: DeepPartial<MergeVersionAliasesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Model>;
  /**
   * Exports a trained, exportable Model to a location specified by the
   * user. A Model is considered to be exportable if it has at least one
   * [supported export
   * format][google.cloud.aiplatform.v1beta1.Model.supported_export_formats].
   */
  exportModel(request: DeepPartial<ExportModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Copies an already existing Vertex AI Model into the specified Location.
   * The source Model must exist in the same Project.
   * When copying custom Models, the users themselves are responsible for
   * [Model.metadata][google.cloud.aiplatform.v1beta1.Model.metadata] content to
   * be region-agnostic, as well as making sure that any resources (e.g. files)
   * it depends on remain accessible.
   */
  copyModel(request: DeepPartial<CopyModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Imports an externally generated ModelEvaluation. */
  importModelEvaluation(
    request: DeepPartial<ImportModelEvaluationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ModelEvaluation>;
  /** Imports a list of externally generated ModelEvaluationSlice. */
  batchImportModelEvaluationSlices(
    request: DeepPartial<BatchImportModelEvaluationSlicesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BatchImportModelEvaluationSlicesResponse>;
  /** Imports a list of externally generated EvaluatedAnnotations. */
  batchImportEvaluatedAnnotations(
    request: DeepPartial<BatchImportEvaluatedAnnotationsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BatchImportEvaluatedAnnotationsResponse>;
  /** Gets a ModelEvaluation. */
  getModelEvaluation(
    request: DeepPartial<GetModelEvaluationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ModelEvaluation>;
  /** Lists ModelEvaluations in a Model. */
  listModelEvaluations(
    request: DeepPartial<ListModelEvaluationsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListModelEvaluationsResponse>;
  /** Gets a ModelEvaluationSlice. */
  getModelEvaluationSlice(
    request: DeepPartial<GetModelEvaluationSliceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ModelEvaluationSlice>;
  /** Lists ModelEvaluationSlices in a ModelEvaluation. */
  listModelEvaluationSlices(
    request: DeepPartial<ListModelEvaluationSlicesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListModelEvaluationSlicesResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
