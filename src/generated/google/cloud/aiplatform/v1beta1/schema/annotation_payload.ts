// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/schema/annotation_payload.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../protobuf/duration.js";
import { AnnotationSpecColor } from "./annotation_spec_color.js";
import { Vertex } from "./geometry.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1.schema";

/** Annotation details specific to image classification. */
export interface ImageClassificationAnnotation {
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** Annotation details specific to image object detection. */
export interface ImageBoundingBoxAnnotation {
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
  /** The leftmost coordinate of the bounding box. */
  xMin: number;
  /** The rightmost coordinate of the bounding box. */
  xMax: number;
  /** The topmost coordinate of the bounding box. */
  yMin: number;
  /** The bottommost coordinate of the bounding box. */
  yMax: number;
}

/** Annotation details specific to image segmentation. */
export interface ImageSegmentationAnnotation {
  /**
   * Mask based segmentation annotation. Only one mask annotation can exist
   * for one image.
   */
  maskAnnotation?:
    | ImageSegmentationAnnotation_MaskAnnotation
    | undefined;
  /** Polygon annotation. */
  polygonAnnotation?:
    | ImageSegmentationAnnotation_PolygonAnnotation
    | undefined;
  /** Polyline annotation. */
  polylineAnnotation?: ImageSegmentationAnnotation_PolylineAnnotation | undefined;
}

/** The mask based segmentation annotation. */
export interface ImageSegmentationAnnotation_MaskAnnotation {
  /**
   * Google Cloud Storage URI that points to the mask image. The image must be
   * in PNG format. It must have the same size as the DataItem's image. Each
   * pixel in the image mask represents the AnnotationSpec which the pixel in
   * the image DataItem belong to. Each color is mapped to one AnnotationSpec
   * based on annotation_spec_colors.
   */
  maskGcsUri: string;
  /** The mapping between color and AnnotationSpec for this Annotation. */
  annotationSpecColors: AnnotationSpecColor[];
}

/** Represents a polygon in image. */
export interface ImageSegmentationAnnotation_PolygonAnnotation {
  /**
   * The vertexes are connected one by one and the last vertex is connected to
   * the first one to represent a polygon.
   */
  vertexes: Vertex[];
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** Represents a polyline in image. */
export interface ImageSegmentationAnnotation_PolylineAnnotation {
  /**
   * The vertexes are connected one by one and the last vertex in not
   * connected to the first one.
   */
  vertexes: Vertex[];
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** Annotation details specific to text classification. */
export interface TextClassificationAnnotation {
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** Annotation details specific to text extraction. */
export interface TextExtractionAnnotation {
  /** The segment of the text content. */
  textSegment:
    | TextSegment
    | undefined;
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** The text segment inside of DataItem. */
export interface TextSegment {
  /**
   * Zero-based character index of the first character of the text
   * segment (counting characters from the beginning of the text).
   */
  startOffset: Long;
  /**
   * Zero-based character index of the first character past the end of
   * the text segment (counting character from the beginning of the text).
   * The character at the end_offset is NOT included in the text segment.
   */
  endOffset: Long;
  /** The text content in the segment for output only. */
  content: string;
}

/** Annotation details specific to text sentiment. */
export interface TextSentimentAnnotation {
  /** The sentiment score for text. */
  sentiment: number;
  /** The sentiment max score for text. */
  sentimentMax: number;
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** Annotation details specific to video classification. */
export interface VideoClassificationAnnotation {
  /**
   * This Annotation applies to the time period represented by the TimeSegment.
   * If it's not set, the Annotation applies to the whole video.
   */
  timeSegment:
    | TimeSegment
    | undefined;
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** A time period inside of a DataItem that has a time dimension (e.g. video). */
export interface TimeSegment {
  /**
   * Start of the time segment (inclusive), represented as the duration since
   * the start of the DataItem.
   */
  startTimeOffset:
    | Duration
    | undefined;
  /**
   * End of the time segment (exclusive), represented as the duration since the
   * start of the DataItem.
   */
  endTimeOffset: Duration | undefined;
}

/** Annotation details specific to video object tracking. */
export interface VideoObjectTrackingAnnotation {
  /**
   * A time (frame) of a video to which this annotation pertains.
   * Represented as the duration since the video's start.
   */
  timeOffset:
    | Duration
    | undefined;
  /** The leftmost coordinate of the bounding box. */
  xMin: number;
  /** The rightmost coordinate of the bounding box. */
  xMax: number;
  /** The topmost coordinate of the bounding box. */
  yMin: number;
  /** The bottommost coordinate of the bounding box. */
  yMax: number;
  /**
   * The instance of the object, expressed as a positive integer. Used to track
   * the same object across different frames.
   */
  instanceId: Long;
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

/** Annotation details specific to video action recognition. */
export interface VideoActionRecognitionAnnotation {
  /**
   * This Annotation applies to the time period represented by the TimeSegment.
   * If it's not set, the Annotation applies to the whole video.
   */
  timeSegment:
    | TimeSegment
    | undefined;
  /** The resource Id of the AnnotationSpec that this Annotation pertains to. */
  annotationSpecId: string;
  /** The display name of the AnnotationSpec that this Annotation pertains to. */
  displayName: string;
}

function createBaseImageClassificationAnnotation(): ImageClassificationAnnotation {
  return { annotationSpecId: "", displayName: "" };
}

export const ImageClassificationAnnotation: MessageFns<ImageClassificationAnnotation> = {
  encode(message: ImageClassificationAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecId !== "") {
      writer.uint32(10).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageClassificationAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageClassificationAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageClassificationAnnotation {
    return {
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: ImageClassificationAnnotation): unknown {
    const obj: any = {};
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<ImageClassificationAnnotation>): ImageClassificationAnnotation {
    return ImageClassificationAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageClassificationAnnotation>): ImageClassificationAnnotation {
    const message = createBaseImageClassificationAnnotation();
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseImageBoundingBoxAnnotation(): ImageBoundingBoxAnnotation {
  return { annotationSpecId: "", displayName: "", xMin: 0, xMax: 0, yMin: 0, yMax: 0 };
}

export const ImageBoundingBoxAnnotation: MessageFns<ImageBoundingBoxAnnotation> = {
  encode(message: ImageBoundingBoxAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecId !== "") {
      writer.uint32(10).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.xMin !== 0) {
      writer.uint32(25).double(message.xMin);
    }
    if (message.xMax !== 0) {
      writer.uint32(33).double(message.xMax);
    }
    if (message.yMin !== 0) {
      writer.uint32(41).double(message.yMin);
    }
    if (message.yMax !== 0) {
      writer.uint32(49).double(message.yMax);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageBoundingBoxAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageBoundingBoxAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 25) {
            break;
          }

          message.xMin = reader.double();
          continue;
        case 4:
          if (tag !== 33) {
            break;
          }

          message.xMax = reader.double();
          continue;
        case 5:
          if (tag !== 41) {
            break;
          }

          message.yMin = reader.double();
          continue;
        case 6:
          if (tag !== 49) {
            break;
          }

          message.yMax = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageBoundingBoxAnnotation {
    return {
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      xMin: isSet(object.xMin) ? globalThis.Number(object.xMin) : 0,
      xMax: isSet(object.xMax) ? globalThis.Number(object.xMax) : 0,
      yMin: isSet(object.yMin) ? globalThis.Number(object.yMin) : 0,
      yMax: isSet(object.yMax) ? globalThis.Number(object.yMax) : 0,
    };
  },

  toJSON(message: ImageBoundingBoxAnnotation): unknown {
    const obj: any = {};
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.xMin !== 0) {
      obj.xMin = message.xMin;
    }
    if (message.xMax !== 0) {
      obj.xMax = message.xMax;
    }
    if (message.yMin !== 0) {
      obj.yMin = message.yMin;
    }
    if (message.yMax !== 0) {
      obj.yMax = message.yMax;
    }
    return obj;
  },

  create(base?: DeepPartial<ImageBoundingBoxAnnotation>): ImageBoundingBoxAnnotation {
    return ImageBoundingBoxAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageBoundingBoxAnnotation>): ImageBoundingBoxAnnotation {
    const message = createBaseImageBoundingBoxAnnotation();
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    message.xMin = object.xMin ?? 0;
    message.xMax = object.xMax ?? 0;
    message.yMin = object.yMin ?? 0;
    message.yMax = object.yMax ?? 0;
    return message;
  },
};

function createBaseImageSegmentationAnnotation(): ImageSegmentationAnnotation {
  return { maskAnnotation: undefined, polygonAnnotation: undefined, polylineAnnotation: undefined };
}

export const ImageSegmentationAnnotation: MessageFns<ImageSegmentationAnnotation> = {
  encode(message: ImageSegmentationAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maskAnnotation !== undefined) {
      ImageSegmentationAnnotation_MaskAnnotation.encode(message.maskAnnotation, writer.uint32(26).fork()).join();
    }
    if (message.polygonAnnotation !== undefined) {
      ImageSegmentationAnnotation_PolygonAnnotation.encode(message.polygonAnnotation, writer.uint32(34).fork()).join();
    }
    if (message.polylineAnnotation !== undefined) {
      ImageSegmentationAnnotation_PolylineAnnotation.encode(message.polylineAnnotation, writer.uint32(42).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageSegmentationAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageSegmentationAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.maskAnnotation = ImageSegmentationAnnotation_MaskAnnotation.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.polygonAnnotation = ImageSegmentationAnnotation_PolygonAnnotation.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.polylineAnnotation = ImageSegmentationAnnotation_PolylineAnnotation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageSegmentationAnnotation {
    return {
      maskAnnotation: isSet(object.maskAnnotation)
        ? ImageSegmentationAnnotation_MaskAnnotation.fromJSON(object.maskAnnotation)
        : undefined,
      polygonAnnotation: isSet(object.polygonAnnotation)
        ? ImageSegmentationAnnotation_PolygonAnnotation.fromJSON(object.polygonAnnotation)
        : undefined,
      polylineAnnotation: isSet(object.polylineAnnotation)
        ? ImageSegmentationAnnotation_PolylineAnnotation.fromJSON(object.polylineAnnotation)
        : undefined,
    };
  },

  toJSON(message: ImageSegmentationAnnotation): unknown {
    const obj: any = {};
    if (message.maskAnnotation !== undefined) {
      obj.maskAnnotation = ImageSegmentationAnnotation_MaskAnnotation.toJSON(message.maskAnnotation);
    }
    if (message.polygonAnnotation !== undefined) {
      obj.polygonAnnotation = ImageSegmentationAnnotation_PolygonAnnotation.toJSON(message.polygonAnnotation);
    }
    if (message.polylineAnnotation !== undefined) {
      obj.polylineAnnotation = ImageSegmentationAnnotation_PolylineAnnotation.toJSON(message.polylineAnnotation);
    }
    return obj;
  },

  create(base?: DeepPartial<ImageSegmentationAnnotation>): ImageSegmentationAnnotation {
    return ImageSegmentationAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageSegmentationAnnotation>): ImageSegmentationAnnotation {
    const message = createBaseImageSegmentationAnnotation();
    message.maskAnnotation = (object.maskAnnotation !== undefined && object.maskAnnotation !== null)
      ? ImageSegmentationAnnotation_MaskAnnotation.fromPartial(object.maskAnnotation)
      : undefined;
    message.polygonAnnotation = (object.polygonAnnotation !== undefined && object.polygonAnnotation !== null)
      ? ImageSegmentationAnnotation_PolygonAnnotation.fromPartial(object.polygonAnnotation)
      : undefined;
    message.polylineAnnotation = (object.polylineAnnotation !== undefined && object.polylineAnnotation !== null)
      ? ImageSegmentationAnnotation_PolylineAnnotation.fromPartial(object.polylineAnnotation)
      : undefined;
    return message;
  },
};

function createBaseImageSegmentationAnnotation_MaskAnnotation(): ImageSegmentationAnnotation_MaskAnnotation {
  return { maskGcsUri: "", annotationSpecColors: [] };
}

export const ImageSegmentationAnnotation_MaskAnnotation: MessageFns<ImageSegmentationAnnotation_MaskAnnotation> = {
  encode(message: ImageSegmentationAnnotation_MaskAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maskGcsUri !== "") {
      writer.uint32(10).string(message.maskGcsUri);
    }
    for (const v of message.annotationSpecColors) {
      AnnotationSpecColor.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageSegmentationAnnotation_MaskAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageSegmentationAnnotation_MaskAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.maskGcsUri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotationSpecColors.push(AnnotationSpecColor.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageSegmentationAnnotation_MaskAnnotation {
    return {
      maskGcsUri: isSet(object.maskGcsUri) ? globalThis.String(object.maskGcsUri) : "",
      annotationSpecColors: globalThis.Array.isArray(object?.annotationSpecColors)
        ? object.annotationSpecColors.map((e: any) => AnnotationSpecColor.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ImageSegmentationAnnotation_MaskAnnotation): unknown {
    const obj: any = {};
    if (message.maskGcsUri !== "") {
      obj.maskGcsUri = message.maskGcsUri;
    }
    if (message.annotationSpecColors?.length) {
      obj.annotationSpecColors = message.annotationSpecColors.map((e) => AnnotationSpecColor.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ImageSegmentationAnnotation_MaskAnnotation>): ImageSegmentationAnnotation_MaskAnnotation {
    return ImageSegmentationAnnotation_MaskAnnotation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ImageSegmentationAnnotation_MaskAnnotation>,
  ): ImageSegmentationAnnotation_MaskAnnotation {
    const message = createBaseImageSegmentationAnnotation_MaskAnnotation();
    message.maskGcsUri = object.maskGcsUri ?? "";
    message.annotationSpecColors = object.annotationSpecColors?.map((e) => AnnotationSpecColor.fromPartial(e)) || [];
    return message;
  },
};

function createBaseImageSegmentationAnnotation_PolygonAnnotation(): ImageSegmentationAnnotation_PolygonAnnotation {
  return { vertexes: [], annotationSpecId: "", displayName: "" };
}

export const ImageSegmentationAnnotation_PolygonAnnotation: MessageFns<ImageSegmentationAnnotation_PolygonAnnotation> =
  {
    encode(
      message: ImageSegmentationAnnotation_PolygonAnnotation,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.vertexes) {
        Vertex.encode(v!, writer.uint32(10).fork()).join();
      }
      if (message.annotationSpecId !== "") {
        writer.uint32(18).string(message.annotationSpecId);
      }
      if (message.displayName !== "") {
        writer.uint32(26).string(message.displayName);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): ImageSegmentationAnnotation_PolygonAnnotation {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseImageSegmentationAnnotation_PolygonAnnotation();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.vertexes.push(Vertex.decode(reader, reader.uint32()));
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.annotationSpecId = reader.string();
            continue;
          case 3:
            if (tag !== 26) {
              break;
            }

            message.displayName = reader.string();
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): ImageSegmentationAnnotation_PolygonAnnotation {
      return {
        vertexes: globalThis.Array.isArray(object?.vertexes) ? object.vertexes.map((e: any) => Vertex.fromJSON(e)) : [],
        annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
        displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      };
    },

    toJSON(message: ImageSegmentationAnnotation_PolygonAnnotation): unknown {
      const obj: any = {};
      if (message.vertexes?.length) {
        obj.vertexes = message.vertexes.map((e) => Vertex.toJSON(e));
      }
      if (message.annotationSpecId !== "") {
        obj.annotationSpecId = message.annotationSpecId;
      }
      if (message.displayName !== "") {
        obj.displayName = message.displayName;
      }
      return obj;
    },

    create(
      base?: DeepPartial<ImageSegmentationAnnotation_PolygonAnnotation>,
    ): ImageSegmentationAnnotation_PolygonAnnotation {
      return ImageSegmentationAnnotation_PolygonAnnotation.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<ImageSegmentationAnnotation_PolygonAnnotation>,
    ): ImageSegmentationAnnotation_PolygonAnnotation {
      const message = createBaseImageSegmentationAnnotation_PolygonAnnotation();
      message.vertexes = object.vertexes?.map((e) => Vertex.fromPartial(e)) || [];
      message.annotationSpecId = object.annotationSpecId ?? "";
      message.displayName = object.displayName ?? "";
      return message;
    },
  };

function createBaseImageSegmentationAnnotation_PolylineAnnotation(): ImageSegmentationAnnotation_PolylineAnnotation {
  return { vertexes: [], annotationSpecId: "", displayName: "" };
}

export const ImageSegmentationAnnotation_PolylineAnnotation: MessageFns<
  ImageSegmentationAnnotation_PolylineAnnotation
> = {
  encode(
    message: ImageSegmentationAnnotation_PolylineAnnotation,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.vertexes) {
      Vertex.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(18).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(26).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageSegmentationAnnotation_PolylineAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageSegmentationAnnotation_PolylineAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vertexes.push(Vertex.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageSegmentationAnnotation_PolylineAnnotation {
    return {
      vertexes: globalThis.Array.isArray(object?.vertexes) ? object.vertexes.map((e: any) => Vertex.fromJSON(e)) : [],
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: ImageSegmentationAnnotation_PolylineAnnotation): unknown {
    const obj: any = {};
    if (message.vertexes?.length) {
      obj.vertexes = message.vertexes.map((e) => Vertex.toJSON(e));
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(
    base?: DeepPartial<ImageSegmentationAnnotation_PolylineAnnotation>,
  ): ImageSegmentationAnnotation_PolylineAnnotation {
    return ImageSegmentationAnnotation_PolylineAnnotation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ImageSegmentationAnnotation_PolylineAnnotation>,
  ): ImageSegmentationAnnotation_PolylineAnnotation {
    const message = createBaseImageSegmentationAnnotation_PolylineAnnotation();
    message.vertexes = object.vertexes?.map((e) => Vertex.fromPartial(e)) || [];
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseTextClassificationAnnotation(): TextClassificationAnnotation {
  return { annotationSpecId: "", displayName: "" };
}

export const TextClassificationAnnotation: MessageFns<TextClassificationAnnotation> = {
  encode(message: TextClassificationAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.annotationSpecId !== "") {
      writer.uint32(10).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextClassificationAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextClassificationAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextClassificationAnnotation {
    return {
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: TextClassificationAnnotation): unknown {
    const obj: any = {};
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<TextClassificationAnnotation>): TextClassificationAnnotation {
    return TextClassificationAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextClassificationAnnotation>): TextClassificationAnnotation {
    const message = createBaseTextClassificationAnnotation();
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseTextExtractionAnnotation(): TextExtractionAnnotation {
  return { textSegment: undefined, annotationSpecId: "", displayName: "" };
}

export const TextExtractionAnnotation: MessageFns<TextExtractionAnnotation> = {
  encode(message: TextExtractionAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.textSegment !== undefined) {
      TextSegment.encode(message.textSegment, writer.uint32(10).fork()).join();
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(18).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(26).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextExtractionAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextExtractionAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.textSegment = TextSegment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextExtractionAnnotation {
    return {
      textSegment: isSet(object.textSegment) ? TextSegment.fromJSON(object.textSegment) : undefined,
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: TextExtractionAnnotation): unknown {
    const obj: any = {};
    if (message.textSegment !== undefined) {
      obj.textSegment = TextSegment.toJSON(message.textSegment);
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<TextExtractionAnnotation>): TextExtractionAnnotation {
    return TextExtractionAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextExtractionAnnotation>): TextExtractionAnnotation {
    const message = createBaseTextExtractionAnnotation();
    message.textSegment = (object.textSegment !== undefined && object.textSegment !== null)
      ? TextSegment.fromPartial(object.textSegment)
      : undefined;
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseTextSegment(): TextSegment {
  return { startOffset: Long.UZERO, endOffset: Long.UZERO, content: "" };
}

export const TextSegment: MessageFns<TextSegment> = {
  encode(message: TextSegment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.startOffset.equals(Long.UZERO)) {
      writer.uint32(8).uint64(message.startOffset.toString());
    }
    if (!message.endOffset.equals(Long.UZERO)) {
      writer.uint32(16).uint64(message.endOffset.toString());
    }
    if (message.content !== "") {
      writer.uint32(26).string(message.content);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextSegment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.startOffset = Long.fromString(reader.uint64().toString(), true);
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.endOffset = Long.fromString(reader.uint64().toString(), true);
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.content = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextSegment {
    return {
      startOffset: isSet(object.startOffset) ? Long.fromValue(object.startOffset) : Long.UZERO,
      endOffset: isSet(object.endOffset) ? Long.fromValue(object.endOffset) : Long.UZERO,
      content: isSet(object.content) ? globalThis.String(object.content) : "",
    };
  },

  toJSON(message: TextSegment): unknown {
    const obj: any = {};
    if (!message.startOffset.equals(Long.UZERO)) {
      obj.startOffset = (message.startOffset || Long.UZERO).toString();
    }
    if (!message.endOffset.equals(Long.UZERO)) {
      obj.endOffset = (message.endOffset || Long.UZERO).toString();
    }
    if (message.content !== "") {
      obj.content = message.content;
    }
    return obj;
  },

  create(base?: DeepPartial<TextSegment>): TextSegment {
    return TextSegment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextSegment>): TextSegment {
    const message = createBaseTextSegment();
    message.startOffset = (object.startOffset !== undefined && object.startOffset !== null)
      ? Long.fromValue(object.startOffset)
      : Long.UZERO;
    message.endOffset = (object.endOffset !== undefined && object.endOffset !== null)
      ? Long.fromValue(object.endOffset)
      : Long.UZERO;
    message.content = object.content ?? "";
    return message;
  },
};

function createBaseTextSentimentAnnotation(): TextSentimentAnnotation {
  return { sentiment: 0, sentimentMax: 0, annotationSpecId: "", displayName: "" };
}

export const TextSentimentAnnotation: MessageFns<TextSentimentAnnotation> = {
  encode(message: TextSentimentAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sentiment !== 0) {
      writer.uint32(8).int32(message.sentiment);
    }
    if (message.sentimentMax !== 0) {
      writer.uint32(16).int32(message.sentimentMax);
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(26).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(34).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextSentimentAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextSentimentAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sentiment = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sentimentMax = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextSentimentAnnotation {
    return {
      sentiment: isSet(object.sentiment) ? globalThis.Number(object.sentiment) : 0,
      sentimentMax: isSet(object.sentimentMax) ? globalThis.Number(object.sentimentMax) : 0,
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: TextSentimentAnnotation): unknown {
    const obj: any = {};
    if (message.sentiment !== 0) {
      obj.sentiment = Math.round(message.sentiment);
    }
    if (message.sentimentMax !== 0) {
      obj.sentimentMax = Math.round(message.sentimentMax);
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<TextSentimentAnnotation>): TextSentimentAnnotation {
    return TextSentimentAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextSentimentAnnotation>): TextSentimentAnnotation {
    const message = createBaseTextSentimentAnnotation();
    message.sentiment = object.sentiment ?? 0;
    message.sentimentMax = object.sentimentMax ?? 0;
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseVideoClassificationAnnotation(): VideoClassificationAnnotation {
  return { timeSegment: undefined, annotationSpecId: "", displayName: "" };
}

export const VideoClassificationAnnotation: MessageFns<VideoClassificationAnnotation> = {
  encode(message: VideoClassificationAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeSegment !== undefined) {
      TimeSegment.encode(message.timeSegment, writer.uint32(10).fork()).join();
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(18).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(26).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoClassificationAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoClassificationAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeSegment = TimeSegment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoClassificationAnnotation {
    return {
      timeSegment: isSet(object.timeSegment) ? TimeSegment.fromJSON(object.timeSegment) : undefined,
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: VideoClassificationAnnotation): unknown {
    const obj: any = {};
    if (message.timeSegment !== undefined) {
      obj.timeSegment = TimeSegment.toJSON(message.timeSegment);
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoClassificationAnnotation>): VideoClassificationAnnotation {
    return VideoClassificationAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoClassificationAnnotation>): VideoClassificationAnnotation {
    const message = createBaseVideoClassificationAnnotation();
    message.timeSegment = (object.timeSegment !== undefined && object.timeSegment !== null)
      ? TimeSegment.fromPartial(object.timeSegment)
      : undefined;
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseTimeSegment(): TimeSegment {
  return { startTimeOffset: undefined, endTimeOffset: undefined };
}

export const TimeSegment: MessageFns<TimeSegment> = {
  encode(message: TimeSegment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTimeOffset !== undefined) {
      Duration.encode(message.startTimeOffset, writer.uint32(10).fork()).join();
    }
    if (message.endTimeOffset !== undefined) {
      Duration.encode(message.endTimeOffset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TimeSegment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTimeSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TimeSegment {
    return {
      startTimeOffset: isSet(object.startTimeOffset) ? Duration.fromJSON(object.startTimeOffset) : undefined,
      endTimeOffset: isSet(object.endTimeOffset) ? Duration.fromJSON(object.endTimeOffset) : undefined,
    };
  },

  toJSON(message: TimeSegment): unknown {
    const obj: any = {};
    if (message.startTimeOffset !== undefined) {
      obj.startTimeOffset = Duration.toJSON(message.startTimeOffset);
    }
    if (message.endTimeOffset !== undefined) {
      obj.endTimeOffset = Duration.toJSON(message.endTimeOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<TimeSegment>): TimeSegment {
    return TimeSegment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TimeSegment>): TimeSegment {
    const message = createBaseTimeSegment();
    message.startTimeOffset = (object.startTimeOffset !== undefined && object.startTimeOffset !== null)
      ? Duration.fromPartial(object.startTimeOffset)
      : undefined;
    message.endTimeOffset = (object.endTimeOffset !== undefined && object.endTimeOffset !== null)
      ? Duration.fromPartial(object.endTimeOffset)
      : undefined;
    return message;
  },
};

function createBaseVideoObjectTrackingAnnotation(): VideoObjectTrackingAnnotation {
  return {
    timeOffset: undefined,
    xMin: 0,
    xMax: 0,
    yMin: 0,
    yMax: 0,
    instanceId: Long.ZERO,
    annotationSpecId: "",
    displayName: "",
  };
}

export const VideoObjectTrackingAnnotation: MessageFns<VideoObjectTrackingAnnotation> = {
  encode(message: VideoObjectTrackingAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(10).fork()).join();
    }
    if (message.xMin !== 0) {
      writer.uint32(17).double(message.xMin);
    }
    if (message.xMax !== 0) {
      writer.uint32(25).double(message.xMax);
    }
    if (message.yMin !== 0) {
      writer.uint32(33).double(message.yMin);
    }
    if (message.yMax !== 0) {
      writer.uint32(41).double(message.yMax);
    }
    if (!message.instanceId.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.instanceId.toString());
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(58).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(66).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoObjectTrackingAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoObjectTrackingAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.xMin = reader.double();
          continue;
        case 3:
          if (tag !== 25) {
            break;
          }

          message.xMax = reader.double();
          continue;
        case 4:
          if (tag !== 33) {
            break;
          }

          message.yMin = reader.double();
          continue;
        case 5:
          if (tag !== 41) {
            break;
          }

          message.yMax = reader.double();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.instanceId = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoObjectTrackingAnnotation {
    return {
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
      xMin: isSet(object.xMin) ? globalThis.Number(object.xMin) : 0,
      xMax: isSet(object.xMax) ? globalThis.Number(object.xMax) : 0,
      yMin: isSet(object.yMin) ? globalThis.Number(object.yMin) : 0,
      yMax: isSet(object.yMax) ? globalThis.Number(object.yMax) : 0,
      instanceId: isSet(object.instanceId) ? Long.fromValue(object.instanceId) : Long.ZERO,
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: VideoObjectTrackingAnnotation): unknown {
    const obj: any = {};
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    if (message.xMin !== 0) {
      obj.xMin = message.xMin;
    }
    if (message.xMax !== 0) {
      obj.xMax = message.xMax;
    }
    if (message.yMin !== 0) {
      obj.yMin = message.yMin;
    }
    if (message.yMax !== 0) {
      obj.yMax = message.yMax;
    }
    if (!message.instanceId.equals(Long.ZERO)) {
      obj.instanceId = (message.instanceId || Long.ZERO).toString();
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoObjectTrackingAnnotation>): VideoObjectTrackingAnnotation {
    return VideoObjectTrackingAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoObjectTrackingAnnotation>): VideoObjectTrackingAnnotation {
    const message = createBaseVideoObjectTrackingAnnotation();
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    message.xMin = object.xMin ?? 0;
    message.xMax = object.xMax ?? 0;
    message.yMin = object.yMin ?? 0;
    message.yMax = object.yMax ?? 0;
    message.instanceId = (object.instanceId !== undefined && object.instanceId !== null)
      ? Long.fromValue(object.instanceId)
      : Long.ZERO;
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseVideoActionRecognitionAnnotation(): VideoActionRecognitionAnnotation {
  return { timeSegment: undefined, annotationSpecId: "", displayName: "" };
}

export const VideoActionRecognitionAnnotation: MessageFns<VideoActionRecognitionAnnotation> = {
  encode(message: VideoActionRecognitionAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeSegment !== undefined) {
      TimeSegment.encode(message.timeSegment, writer.uint32(10).fork()).join();
    }
    if (message.annotationSpecId !== "") {
      writer.uint32(18).string(message.annotationSpecId);
    }
    if (message.displayName !== "") {
      writer.uint32(26).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoActionRecognitionAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoActionRecognitionAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeSegment = TimeSegment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.annotationSpecId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.displayName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoActionRecognitionAnnotation {
    return {
      timeSegment: isSet(object.timeSegment) ? TimeSegment.fromJSON(object.timeSegment) : undefined,
      annotationSpecId: isSet(object.annotationSpecId) ? globalThis.String(object.annotationSpecId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: VideoActionRecognitionAnnotation): unknown {
    const obj: any = {};
    if (message.timeSegment !== undefined) {
      obj.timeSegment = TimeSegment.toJSON(message.timeSegment);
    }
    if (message.annotationSpecId !== "") {
      obj.annotationSpecId = message.annotationSpecId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoActionRecognitionAnnotation>): VideoActionRecognitionAnnotation {
    return VideoActionRecognitionAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoActionRecognitionAnnotation>): VideoActionRecognitionAnnotation {
    const message = createBaseVideoActionRecognitionAnnotation();
    message.timeSegment = (object.timeSegment !== undefined && object.timeSegment !== null)
      ? TimeSegment.fromPartial(object.timeSegment)
      : undefined;
    message.annotationSpecId = object.annotationSpecId ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
