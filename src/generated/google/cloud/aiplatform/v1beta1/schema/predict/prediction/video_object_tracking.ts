// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/schema/predict/prediction/video_object_tracking.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../../../protobuf/duration.js";
import { FloatValue } from "../../../../../../protobuf/wrappers.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1.schema.predict.prediction";

/** Prediction output format for Video Object Tracking. */
export interface VideoObjectTrackingPredictionResult {
  /** The resource ID of the AnnotationSpec that had been identified. */
  id: string;
  /** The display name of the AnnotationSpec that had been identified. */
  displayName: string;
  /**
   * The beginning, inclusive, of the video's time segment in which the
   * object instance has been detected. Expressed as a number of seconds as
   * measured from the start of the video, with fractions up to a microsecond
   * precision, and with "s" appended at the end.
   */
  timeSegmentStart:
    | Duration
    | undefined;
  /**
   * The end, inclusive, of the video's time segment in which the
   * object instance has been detected. Expressed as a number of seconds as
   * measured from the start of the video, with fractions up to a microsecond
   * precision, and with "s" appended at the end.
   */
  timeSegmentEnd:
    | Duration
    | undefined;
  /**
   * The Model's confidence in correction of this prediction, higher
   * value means higher confidence.
   */
  confidence:
    | number
    | undefined;
  /**
   * All of the frames of the video in which a single object instance has been
   * detected. The bounding boxes in the frames identify the same object.
   */
  frames: VideoObjectTrackingPredictionResult_Frame[];
}

/**
 * The fields `xMin`, `xMax`, `yMin`, and `yMax` refer to a bounding box,
 * i.e. the rectangle over the video frame pinpointing the found
 * AnnotationSpec. The coordinates are relative to the frame size, and the
 * point 0,0 is in the top left of the frame.
 */
export interface VideoObjectTrackingPredictionResult_Frame {
  /**
   * A time (frame) of a video in which the object has been detected.
   * Expressed as a number of seconds as measured from the
   * start of the video, with fractions up to a microsecond precision, and
   * with "s" appended at the end.
   */
  timeOffset:
    | Duration
    | undefined;
  /** The leftmost coordinate of the bounding box. */
  xMin:
    | number
    | undefined;
  /** The rightmost coordinate of the bounding box. */
  xMax:
    | number
    | undefined;
  /** The topmost coordinate of the bounding box. */
  yMin:
    | number
    | undefined;
  /** The bottommost coordinate of the bounding box. */
  yMax: number | undefined;
}

function createBaseVideoObjectTrackingPredictionResult(): VideoObjectTrackingPredictionResult {
  return {
    id: "",
    displayName: "",
    timeSegmentStart: undefined,
    timeSegmentEnd: undefined,
    confidence: undefined,
    frames: [],
  };
}

export const VideoObjectTrackingPredictionResult: MessageFns<VideoObjectTrackingPredictionResult> = {
  encode(message: VideoObjectTrackingPredictionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.timeSegmentStart !== undefined) {
      Duration.encode(message.timeSegmentStart, writer.uint32(26).fork()).join();
    }
    if (message.timeSegmentEnd !== undefined) {
      Duration.encode(message.timeSegmentEnd, writer.uint32(34).fork()).join();
    }
    if (message.confidence !== undefined) {
      FloatValue.encode({ value: message.confidence! }, writer.uint32(42).fork()).join();
    }
    for (const v of message.frames) {
      VideoObjectTrackingPredictionResult_Frame.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoObjectTrackingPredictionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoObjectTrackingPredictionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timeSegmentStart = Duration.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.timeSegmentEnd = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.confidence = FloatValue.decode(reader, reader.uint32()).value;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.frames.push(VideoObjectTrackingPredictionResult_Frame.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoObjectTrackingPredictionResult {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      timeSegmentStart: isSet(object.timeSegmentStart) ? Duration.fromJSON(object.timeSegmentStart) : undefined,
      timeSegmentEnd: isSet(object.timeSegmentEnd) ? Duration.fromJSON(object.timeSegmentEnd) : undefined,
      confidence: isSet(object.confidence) ? Number(object.confidence) : undefined,
      frames: globalThis.Array.isArray(object?.frames)
        ? object.frames.map((e: any) => VideoObjectTrackingPredictionResult_Frame.fromJSON(e))
        : [],
    };
  },

  toJSON(message: VideoObjectTrackingPredictionResult): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.timeSegmentStart !== undefined) {
      obj.timeSegmentStart = Duration.toJSON(message.timeSegmentStart);
    }
    if (message.timeSegmentEnd !== undefined) {
      obj.timeSegmentEnd = Duration.toJSON(message.timeSegmentEnd);
    }
    if (message.confidence !== undefined) {
      obj.confidence = message.confidence;
    }
    if (message.frames?.length) {
      obj.frames = message.frames.map((e) => VideoObjectTrackingPredictionResult_Frame.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<VideoObjectTrackingPredictionResult>): VideoObjectTrackingPredictionResult {
    return VideoObjectTrackingPredictionResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoObjectTrackingPredictionResult>): VideoObjectTrackingPredictionResult {
    const message = createBaseVideoObjectTrackingPredictionResult();
    message.id = object.id ?? "";
    message.displayName = object.displayName ?? "";
    message.timeSegmentStart = (object.timeSegmentStart !== undefined && object.timeSegmentStart !== null)
      ? Duration.fromPartial(object.timeSegmentStart)
      : undefined;
    message.timeSegmentEnd = (object.timeSegmentEnd !== undefined && object.timeSegmentEnd !== null)
      ? Duration.fromPartial(object.timeSegmentEnd)
      : undefined;
    message.confidence = object.confidence ?? undefined;
    message.frames = object.frames?.map((e) => VideoObjectTrackingPredictionResult_Frame.fromPartial(e)) || [];
    return message;
  },
};

function createBaseVideoObjectTrackingPredictionResult_Frame(): VideoObjectTrackingPredictionResult_Frame {
  return { timeOffset: undefined, xMin: undefined, xMax: undefined, yMin: undefined, yMax: undefined };
}

export const VideoObjectTrackingPredictionResult_Frame: MessageFns<VideoObjectTrackingPredictionResult_Frame> = {
  encode(message: VideoObjectTrackingPredictionResult_Frame, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(10).fork()).join();
    }
    if (message.xMin !== undefined) {
      FloatValue.encode({ value: message.xMin! }, writer.uint32(18).fork()).join();
    }
    if (message.xMax !== undefined) {
      FloatValue.encode({ value: message.xMax! }, writer.uint32(26).fork()).join();
    }
    if (message.yMin !== undefined) {
      FloatValue.encode({ value: message.yMin! }, writer.uint32(34).fork()).join();
    }
    if (message.yMax !== undefined) {
      FloatValue.encode({ value: message.yMax! }, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoObjectTrackingPredictionResult_Frame {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoObjectTrackingPredictionResult_Frame();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.xMin = FloatValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.xMax = FloatValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.yMin = FloatValue.decode(reader, reader.uint32()).value;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.yMax = FloatValue.decode(reader, reader.uint32()).value;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoObjectTrackingPredictionResult_Frame {
    return {
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
      xMin: isSet(object.xMin) ? Number(object.xMin) : undefined,
      xMax: isSet(object.xMax) ? Number(object.xMax) : undefined,
      yMin: isSet(object.yMin) ? Number(object.yMin) : undefined,
      yMax: isSet(object.yMax) ? Number(object.yMax) : undefined,
    };
  },

  toJSON(message: VideoObjectTrackingPredictionResult_Frame): unknown {
    const obj: any = {};
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    if (message.xMin !== undefined) {
      obj.xMin = message.xMin;
    }
    if (message.xMax !== undefined) {
      obj.xMax = message.xMax;
    }
    if (message.yMin !== undefined) {
      obj.yMin = message.yMin;
    }
    if (message.yMax !== undefined) {
      obj.yMax = message.yMax;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoObjectTrackingPredictionResult_Frame>): VideoObjectTrackingPredictionResult_Frame {
    return VideoObjectTrackingPredictionResult_Frame.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<VideoObjectTrackingPredictionResult_Frame>,
  ): VideoObjectTrackingPredictionResult_Frame {
    const message = createBaseVideoObjectTrackingPredictionResult_Frame();
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    message.xMin = object.xMin ?? undefined;
    message.xMax = object.xMax ?? undefined;
    message.yMin = object.yMin ?? undefined;
    message.yMax = object.yMax ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
