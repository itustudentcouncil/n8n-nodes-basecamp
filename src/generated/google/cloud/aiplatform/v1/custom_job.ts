// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1/custom_job.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { EncryptionSpec } from "./encryption_spec.js";
import { EnvVar } from "./env_var.js";
import { GcsDestination } from "./io.js";
import { JobState, jobStateFromJSON, jobStateToJSON } from "./job_state.js";
import { DiskSpec, MachineSpec, NfsMount } from "./machine_resources.js";

export const protobufPackage = "google.cloud.aiplatform.v1";

/**
 * Represents a job that runs custom workloads such as a Docker container or a
 * Python package. A CustomJob can have multiple worker pools and each worker
 * pool can have its own machine and input spec. A CustomJob will be cleaned up
 * once the job enters terminal state (failed or succeeded).
 */
export interface CustomJob {
  /** Output only. Resource name of a CustomJob. */
  name: string;
  /**
   * Required. The display name of the CustomJob.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   */
  displayName: string;
  /** Required. Job spec. */
  jobSpec:
    | CustomJobSpec
    | undefined;
  /** Output only. The detailed state of the job. */
  state: JobState;
  /** Output only. Time when the CustomJob was created. */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Time when the CustomJob for the first time entered the
   * `JOB_STATE_RUNNING` state.
   */
  startTime:
    | Date
    | undefined;
  /**
   * Output only. Time when the CustomJob entered any of the following states:
   * `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.
   */
  endTime:
    | Date
    | undefined;
  /** Output only. Time when the CustomJob was most recently updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Output only. Only populated when job's state is `JOB_STATE_FAILED` or
   * `JOB_STATE_CANCELLED`.
   */
  error:
    | Status
    | undefined;
  /**
   * The labels with user-defined metadata to organize CustomJobs.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   *
   * See https://goo.gl/xmQnxf for more information and examples of labels.
   */
  labels: { [key: string]: string };
  /**
   * Customer-managed encryption key options for a CustomJob. If this is set,
   * then all resources created by the CustomJob will be encrypted with the
   * provided encryption key.
   */
  encryptionSpec:
    | EncryptionSpec
    | undefined;
  /**
   * Output only. URIs for accessing [interactive
   * shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
   * (one URI for each training node). Only available if
   * [job_spec.enable_web_access][google.cloud.aiplatform.v1.CustomJobSpec.enable_web_access]
   * is `true`.
   *
   * The keys are names of each node in the training job; for example,
   * `workerpool0-0` for the primary node, `workerpool1-0` for the first node in
   * the second worker pool, and `workerpool1-1` for the second node in the
   * second worker pool.
   *
   * The values are the URIs for each node's interactive shell.
   */
  webAccessUris: { [key: string]: string };
  /** Output only. Reserved for future use. */
  satisfiesPzs: boolean;
  /** Output only. Reserved for future use. */
  satisfiesPzi: boolean;
}

export interface CustomJob_LabelsEntry {
  key: string;
  value: string;
}

export interface CustomJob_WebAccessUrisEntry {
  key: string;
  value: string;
}

/** Represents the spec of a CustomJob. */
export interface CustomJobSpec {
  /**
   * Optional. The ID of the PersistentResource in the same Project and Location
   * which to run
   *
   * If this is specified, the job will be run on existing machines held by the
   * PersistentResource instead of on-demand short-live machines.
   * The network and CMEK configs on the job should be consistent with those on
   * the PersistentResource, otherwise, the job will be rejected.
   */
  persistentResourceId: string;
  /**
   * Required. The spec of the worker pools including machine type and Docker
   * image. All worker pools except the first one are optional and can be
   * skipped by providing an empty value.
   */
  workerPoolSpecs: WorkerPoolSpec[];
  /** Scheduling options for a CustomJob. */
  scheduling:
    | Scheduling
    | undefined;
  /**
   * Specifies the service account for workload run-as account.
   * Users submitting jobs must have act-as permission on this run-as account.
   * If unspecified, the [Vertex AI Custom Code Service
   * Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
   * for the CustomJob's project is used.
   */
  serviceAccount: string;
  /**
   * Optional. The full name of the Compute Engine
   * [network](/compute/docs/networks-and-firewalls#networks) to which the Job
   * should be peered. For example, `projects/12345/global/networks/myVPC`.
   * [Format](/compute/docs/reference/rest/v1/networks/insert)
   * is of the form `projects/{project}/global/networks/{network}`.
   * Where {project} is a project number, as in `12345`, and {network} is a
   * network name.
   *
   * To specify this field, you must have already [configured VPC Network
   * Peering for Vertex
   * AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering).
   *
   * If this field is left unspecified, the job is not peered with any network.
   */
  network: string;
  /**
   * Optional. A list of names for the reserved ip ranges under the VPC network
   * that can be used for this job.
   *
   * If set, we will deploy the job within the provided ip ranges. Otherwise,
   * the job will be deployed to any ip ranges under the provided VPC
   * network.
   *
   * Example: ['vertex-ai-ip-range'].
   */
  reservedIpRanges: string[];
  /**
   * The Cloud Storage location to store the output of this CustomJob or
   * HyperparameterTuningJob. For HyperparameterTuningJob,
   * the baseOutputDirectory of
   * each child CustomJob backing a Trial is set to a subdirectory of name
   * [id][google.cloud.aiplatform.v1.Trial.id] under its parent
   * HyperparameterTuningJob's baseOutputDirectory.
   *
   * The following Vertex AI environment variables will be passed to
   * containers or python modules when this field is set:
   *
   *   For CustomJob:
   *
   *   * AIP_MODEL_DIR = `<base_output_directory>/model/`
   *   * AIP_CHECKPOINT_DIR = `<base_output_directory>/checkpoints/`
   *   * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/logs/`
   *
   *   For CustomJob backing a Trial of HyperparameterTuningJob:
   *
   *   * AIP_MODEL_DIR = `<base_output_directory>/<trial_id>/model/`
   *   * AIP_CHECKPOINT_DIR = `<base_output_directory>/<trial_id>/checkpoints/`
   *   * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/<trial_id>/logs/`
   */
  baseOutputDirectory:
    | GcsDestination
    | undefined;
  /**
   * The ID of the location to store protected artifacts. e.g. us-central1.
   * Populate only when the location is different than CustomJob location.
   * List of supported locations:
   * https://cloud.google.com/vertex-ai/docs/general/locations
   */
  protectedArtifactLocationId: string;
  /**
   * Optional. The name of a Vertex AI
   * [Tensorboard][google.cloud.aiplatform.v1.Tensorboard] resource to which
   * this CustomJob will upload Tensorboard logs. Format:
   * `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
   */
  tensorboard: string;
  /**
   * Optional. Whether you want Vertex AI to enable [interactive shell
   * access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
   * to training containers.
   *
   * If set to `true`, you can access interactive shells at the URIs given
   * by
   * [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris]
   * or
   * [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris]
   * (within
   * [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
   */
  enableWebAccess: boolean;
  /**
   * Optional. Whether you want Vertex AI to enable access to the customized
   * dashboard in training chief container.
   *
   * If set to `true`, you can access the dashboard at the URIs given
   * by
   * [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris]
   * or
   * [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris]
   * (within
   * [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
   */
  enableDashboardAccess: boolean;
  /**
   * Optional. The Experiment associated with this job.
   * Format:
   * `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
   */
  experiment: string;
  /**
   * Optional. The Experiment Run associated with this job.
   * Format:
   * `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
   */
  experimentRun: string;
  /**
   * Optional. The name of the Model resources for which to generate a mapping
   * to artifact URIs. Applicable only to some of the Google-provided custom
   * jobs. Format: `projects/{project}/locations/{location}/models/{model}`
   *
   * In order to retrieve a specific version of the model, also provide
   * the version ID or version alias.
   *   Example: `projects/{project}/locations/{location}/models/{model}@2`
   *              or
   *            `projects/{project}/locations/{location}/models/{model}@golden`
   * If no version ID or alias is specified, the "default" version will be
   * returned. The "default" version alias is created for the first version of
   * the model, and can be moved to other versions later on. There will be
   * exactly one default version.
   */
  models: string[];
}

/** Represents the spec of a worker pool in a job. */
export interface WorkerPoolSpec {
  /** The custom container task. */
  containerSpec?:
    | ContainerSpec
    | undefined;
  /** The Python packaged task. */
  pythonPackageSpec?:
    | PythonPackageSpec
    | undefined;
  /** Optional. Immutable. The specification of a single machine. */
  machineSpec:
    | MachineSpec
    | undefined;
  /** Optional. The number of worker replicas to use for this worker pool. */
  replicaCount: Long;
  /** Optional. List of NFS mount spec. */
  nfsMounts: NfsMount[];
  /** Disk spec. */
  diskSpec: DiskSpec | undefined;
}

/** The spec of a Container. */
export interface ContainerSpec {
  /**
   * Required. The URI of a container image in the Container Registry that is to
   * be run on each worker replica.
   */
  imageUri: string;
  /**
   * The command to be invoked when the container is started.
   * It overrides the entrypoint instruction in Dockerfile when provided.
   */
  command: string[];
  /** The arguments to be passed when starting the container. */
  args: string[];
  /**
   * Environment variables to be passed to the container.
   * Maximum limit is 100.
   */
  env: EnvVar[];
}

/** The spec of a Python packaged code. */
export interface PythonPackageSpec {
  /**
   * Required. The URI of a container image in Artifact Registry that will run
   * the provided Python package. Vertex AI provides a wide range of executor
   * images with pre-installed packages to meet users' various use cases. See
   * the list of [pre-built containers for
   * training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers).
   * You must use an image from this list.
   */
  executorImageUri: string;
  /**
   * Required. The Google Cloud Storage location of the Python package files
   * which are the training program and its dependent packages. The maximum
   * number of package URIs is 100.
   */
  packageUris: string[];
  /** Required. The Python module name to run after installing the packages. */
  pythonModule: string;
  /** Command line arguments to be passed to the Python task. */
  args: string[];
  /**
   * Environment variables to be passed to the python module.
   * Maximum limit is 100.
   */
  env: EnvVar[];
}

/** All parameters related to queuing and scheduling of custom jobs. */
export interface Scheduling {
  /** The maximum job running time. The default is 7 days. */
  timeout:
    | Duration
    | undefined;
  /**
   * Restarts the entire CustomJob if a worker gets restarted.
   * This feature can be used by distributed training jobs that are not
   * resilient to workers leaving and joining a job.
   */
  restartJobOnWorkerRestart: boolean;
  /** Optional. This determines which type of scheduling strategy to use. */
  strategy: Scheduling_Strategy;
  /**
   * Optional. Indicates if the job should retry for internal errors after the
   * job starts running. If true, overrides
   * `Scheduling.restart_job_on_worker_restart` to false.
   */
  disableRetries: boolean;
  /**
   * Optional. This is the maximum duration that a job will wait for the
   * requested resources to be provisioned if the scheduling strategy is set to
   * [Strategy.DWS_FLEX_START].
   * If set to 0, the job will wait indefinitely. The default is 24 hours.
   */
  maxWaitDuration: Duration | undefined;
}

/**
 * Optional. This determines which type of scheduling strategy to use. Right
 * now users have two options such as STANDARD which will use regular on
 * demand resources to schedule the job, the other is SPOT which would
 * leverage spot resources alongwith regular resources to schedule
 * the job.
 */
export enum Scheduling_Strategy {
  /** STRATEGY_UNSPECIFIED - Strategy will default to STANDARD. */
  STRATEGY_UNSPECIFIED = 0,
  /**
   * ON_DEMAND - Deprecated. Regular on-demand provisioning strategy.
   *
   * @deprecated
   */
  ON_DEMAND = 1,
  /**
   * LOW_COST - Deprecated. Low cost by making potential use of spot resources.
   *
   * @deprecated
   */
  LOW_COST = 2,
  /** STANDARD - Standard provisioning strategy uses regular on-demand resources. */
  STANDARD = 3,
  /** SPOT - Spot provisioning strategy uses spot resources. */
  SPOT = 4,
  /** FLEX_START - Flex Start strategy uses DWS to queue for resources. */
  FLEX_START = 6,
  UNRECOGNIZED = -1,
}

export function scheduling_StrategyFromJSON(object: any): Scheduling_Strategy {
  switch (object) {
    case 0:
    case "STRATEGY_UNSPECIFIED":
      return Scheduling_Strategy.STRATEGY_UNSPECIFIED;
    case 1:
    case "ON_DEMAND":
      return Scheduling_Strategy.ON_DEMAND;
    case 2:
    case "LOW_COST":
      return Scheduling_Strategy.LOW_COST;
    case 3:
    case "STANDARD":
      return Scheduling_Strategy.STANDARD;
    case 4:
    case "SPOT":
      return Scheduling_Strategy.SPOT;
    case 6:
    case "FLEX_START":
      return Scheduling_Strategy.FLEX_START;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Scheduling_Strategy.UNRECOGNIZED;
  }
}

export function scheduling_StrategyToJSON(object: Scheduling_Strategy): string {
  switch (object) {
    case Scheduling_Strategy.STRATEGY_UNSPECIFIED:
      return "STRATEGY_UNSPECIFIED";
    case Scheduling_Strategy.ON_DEMAND:
      return "ON_DEMAND";
    case Scheduling_Strategy.LOW_COST:
      return "LOW_COST";
    case Scheduling_Strategy.STANDARD:
      return "STANDARD";
    case Scheduling_Strategy.SPOT:
      return "SPOT";
    case Scheduling_Strategy.FLEX_START:
      return "FLEX_START";
    case Scheduling_Strategy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseCustomJob(): CustomJob {
  return {
    name: "",
    displayName: "",
    jobSpec: undefined,
    state: 0,
    createTime: undefined,
    startTime: undefined,
    endTime: undefined,
    updateTime: undefined,
    error: undefined,
    labels: {},
    encryptionSpec: undefined,
    webAccessUris: {},
    satisfiesPzs: false,
    satisfiesPzi: false,
  };
}

export const CustomJob: MessageFns<CustomJob> = {
  encode(message: CustomJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.jobSpec !== undefined) {
      CustomJobSpec.encode(message.jobSpec, writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(58).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(66).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(74).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(82).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      CustomJob_LabelsEntry.encode({ key: key as any, value }, writer.uint32(90).fork()).join();
    });
    if (message.encryptionSpec !== undefined) {
      EncryptionSpec.encode(message.encryptionSpec, writer.uint32(98).fork()).join();
    }
    Object.entries(message.webAccessUris).forEach(([key, value]) => {
      CustomJob_WebAccessUrisEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
    });
    if (message.satisfiesPzs !== false) {
      writer.uint32(144).bool(message.satisfiesPzs);
    }
    if (message.satisfiesPzi !== false) {
      writer.uint32(152).bool(message.satisfiesPzi);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.jobSpec = CustomJobSpec.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          const entry11 = CustomJob_LabelsEntry.decode(reader, reader.uint32());
          if (entry11.value !== undefined) {
            message.labels[entry11.key] = entry11.value;
          }
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.encryptionSpec = EncryptionSpec.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          const entry16 = CustomJob_WebAccessUrisEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.webAccessUris[entry16.key] = entry16.value;
          }
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
        case 19:
          if (tag !== 152) {
            break;
          }

          message.satisfiesPzi = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomJob {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      jobSpec: isSet(object.jobSpec) ? CustomJobSpec.fromJSON(object.jobSpec) : undefined,
      state: isSet(object.state) ? jobStateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      encryptionSpec: isSet(object.encryptionSpec) ? EncryptionSpec.fromJSON(object.encryptionSpec) : undefined,
      webAccessUris: isObject(object.webAccessUris)
        ? Object.entries(object.webAccessUris).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : false,
      satisfiesPzi: isSet(object.satisfiesPzi) ? globalThis.Boolean(object.satisfiesPzi) : false,
    };
  },

  toJSON(message: CustomJob): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.jobSpec !== undefined) {
      obj.jobSpec = CustomJobSpec.toJSON(message.jobSpec);
    }
    if (message.state !== 0) {
      obj.state = jobStateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.encryptionSpec !== undefined) {
      obj.encryptionSpec = EncryptionSpec.toJSON(message.encryptionSpec);
    }
    if (message.webAccessUris) {
      const entries = Object.entries(message.webAccessUris);
      if (entries.length > 0) {
        obj.webAccessUris = {};
        entries.forEach(([k, v]) => {
          obj.webAccessUris[k] = v;
        });
      }
    }
    if (message.satisfiesPzs !== false) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.satisfiesPzi !== false) {
      obj.satisfiesPzi = message.satisfiesPzi;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomJob>): CustomJob {
    return CustomJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomJob>): CustomJob {
    const message = createBaseCustomJob();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.jobSpec = (object.jobSpec !== undefined && object.jobSpec !== null)
      ? CustomJobSpec.fromPartial(object.jobSpec)
      : undefined;
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.encryptionSpec = (object.encryptionSpec !== undefined && object.encryptionSpec !== null)
      ? EncryptionSpec.fromPartial(object.encryptionSpec)
      : undefined;
    message.webAccessUris = Object.entries(object.webAccessUris ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.satisfiesPzs = object.satisfiesPzs ?? false;
    message.satisfiesPzi = object.satisfiesPzi ?? false;
    return message;
  },
};

function createBaseCustomJob_LabelsEntry(): CustomJob_LabelsEntry {
  return { key: "", value: "" };
}

export const CustomJob_LabelsEntry: MessageFns<CustomJob_LabelsEntry> = {
  encode(message: CustomJob_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomJob_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomJob_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomJob_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CustomJob_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomJob_LabelsEntry>): CustomJob_LabelsEntry {
    return CustomJob_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomJob_LabelsEntry>): CustomJob_LabelsEntry {
    const message = createBaseCustomJob_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCustomJob_WebAccessUrisEntry(): CustomJob_WebAccessUrisEntry {
  return { key: "", value: "" };
}

export const CustomJob_WebAccessUrisEntry: MessageFns<CustomJob_WebAccessUrisEntry> = {
  encode(message: CustomJob_WebAccessUrisEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomJob_WebAccessUrisEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomJob_WebAccessUrisEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomJob_WebAccessUrisEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CustomJob_WebAccessUrisEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomJob_WebAccessUrisEntry>): CustomJob_WebAccessUrisEntry {
    return CustomJob_WebAccessUrisEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomJob_WebAccessUrisEntry>): CustomJob_WebAccessUrisEntry {
    const message = createBaseCustomJob_WebAccessUrisEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCustomJobSpec(): CustomJobSpec {
  return {
    persistentResourceId: "",
    workerPoolSpecs: [],
    scheduling: undefined,
    serviceAccount: "",
    network: "",
    reservedIpRanges: [],
    baseOutputDirectory: undefined,
    protectedArtifactLocationId: "",
    tensorboard: "",
    enableWebAccess: false,
    enableDashboardAccess: false,
    experiment: "",
    experimentRun: "",
    models: [],
  };
}

export const CustomJobSpec: MessageFns<CustomJobSpec> = {
  encode(message: CustomJobSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.persistentResourceId !== "") {
      writer.uint32(114).string(message.persistentResourceId);
    }
    for (const v of message.workerPoolSpecs) {
      WorkerPoolSpec.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.scheduling !== undefined) {
      Scheduling.encode(message.scheduling, writer.uint32(26).fork()).join();
    }
    if (message.serviceAccount !== "") {
      writer.uint32(34).string(message.serviceAccount);
    }
    if (message.network !== "") {
      writer.uint32(42).string(message.network);
    }
    for (const v of message.reservedIpRanges) {
      writer.uint32(106).string(v!);
    }
    if (message.baseOutputDirectory !== undefined) {
      GcsDestination.encode(message.baseOutputDirectory, writer.uint32(50).fork()).join();
    }
    if (message.protectedArtifactLocationId !== "") {
      writer.uint32(154).string(message.protectedArtifactLocationId);
    }
    if (message.tensorboard !== "") {
      writer.uint32(58).string(message.tensorboard);
    }
    if (message.enableWebAccess !== false) {
      writer.uint32(80).bool(message.enableWebAccess);
    }
    if (message.enableDashboardAccess !== false) {
      writer.uint32(128).bool(message.enableDashboardAccess);
    }
    if (message.experiment !== "") {
      writer.uint32(138).string(message.experiment);
    }
    if (message.experimentRun !== "") {
      writer.uint32(146).string(message.experimentRun);
    }
    for (const v of message.models) {
      writer.uint32(162).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomJobSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomJobSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 14:
          if (tag !== 114) {
            break;
          }

          message.persistentResourceId = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerPoolSpecs.push(WorkerPoolSpec.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.scheduling = Scheduling.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.network = reader.string();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.reservedIpRanges.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.baseOutputDirectory = GcsDestination.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.protectedArtifactLocationId = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.tensorboard = reader.string();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.enableWebAccess = reader.bool();
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.enableDashboardAccess = reader.bool();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.experiment = reader.string();
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.experimentRun = reader.string();
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.models.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomJobSpec {
    return {
      persistentResourceId: isSet(object.persistentResourceId) ? globalThis.String(object.persistentResourceId) : "",
      workerPoolSpecs: globalThis.Array.isArray(object?.workerPoolSpecs)
        ? object.workerPoolSpecs.map((e: any) => WorkerPoolSpec.fromJSON(e))
        : [],
      scheduling: isSet(object.scheduling) ? Scheduling.fromJSON(object.scheduling) : undefined,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      reservedIpRanges: globalThis.Array.isArray(object?.reservedIpRanges)
        ? object.reservedIpRanges.map((e: any) => globalThis.String(e))
        : [],
      baseOutputDirectory: isSet(object.baseOutputDirectory)
        ? GcsDestination.fromJSON(object.baseOutputDirectory)
        : undefined,
      protectedArtifactLocationId: isSet(object.protectedArtifactLocationId)
        ? globalThis.String(object.protectedArtifactLocationId)
        : "",
      tensorboard: isSet(object.tensorboard) ? globalThis.String(object.tensorboard) : "",
      enableWebAccess: isSet(object.enableWebAccess) ? globalThis.Boolean(object.enableWebAccess) : false,
      enableDashboardAccess: isSet(object.enableDashboardAccess)
        ? globalThis.Boolean(object.enableDashboardAccess)
        : false,
      experiment: isSet(object.experiment) ? globalThis.String(object.experiment) : "",
      experimentRun: isSet(object.experimentRun) ? globalThis.String(object.experimentRun) : "",
      models: globalThis.Array.isArray(object?.models)
        ? object.models.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: CustomJobSpec): unknown {
    const obj: any = {};
    if (message.persistentResourceId !== "") {
      obj.persistentResourceId = message.persistentResourceId;
    }
    if (message.workerPoolSpecs?.length) {
      obj.workerPoolSpecs = message.workerPoolSpecs.map((e) => WorkerPoolSpec.toJSON(e));
    }
    if (message.scheduling !== undefined) {
      obj.scheduling = Scheduling.toJSON(message.scheduling);
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.reservedIpRanges?.length) {
      obj.reservedIpRanges = message.reservedIpRanges;
    }
    if (message.baseOutputDirectory !== undefined) {
      obj.baseOutputDirectory = GcsDestination.toJSON(message.baseOutputDirectory);
    }
    if (message.protectedArtifactLocationId !== "") {
      obj.protectedArtifactLocationId = message.protectedArtifactLocationId;
    }
    if (message.tensorboard !== "") {
      obj.tensorboard = message.tensorboard;
    }
    if (message.enableWebAccess !== false) {
      obj.enableWebAccess = message.enableWebAccess;
    }
    if (message.enableDashboardAccess !== false) {
      obj.enableDashboardAccess = message.enableDashboardAccess;
    }
    if (message.experiment !== "") {
      obj.experiment = message.experiment;
    }
    if (message.experimentRun !== "") {
      obj.experimentRun = message.experimentRun;
    }
    if (message.models?.length) {
      obj.models = message.models;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomJobSpec>): CustomJobSpec {
    return CustomJobSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomJobSpec>): CustomJobSpec {
    const message = createBaseCustomJobSpec();
    message.persistentResourceId = object.persistentResourceId ?? "";
    message.workerPoolSpecs = object.workerPoolSpecs?.map((e) => WorkerPoolSpec.fromPartial(e)) || [];
    message.scheduling = (object.scheduling !== undefined && object.scheduling !== null)
      ? Scheduling.fromPartial(object.scheduling)
      : undefined;
    message.serviceAccount = object.serviceAccount ?? "";
    message.network = object.network ?? "";
    message.reservedIpRanges = object.reservedIpRanges?.map((e) => e) || [];
    message.baseOutputDirectory = (object.baseOutputDirectory !== undefined && object.baseOutputDirectory !== null)
      ? GcsDestination.fromPartial(object.baseOutputDirectory)
      : undefined;
    message.protectedArtifactLocationId = object.protectedArtifactLocationId ?? "";
    message.tensorboard = object.tensorboard ?? "";
    message.enableWebAccess = object.enableWebAccess ?? false;
    message.enableDashboardAccess = object.enableDashboardAccess ?? false;
    message.experiment = object.experiment ?? "";
    message.experimentRun = object.experimentRun ?? "";
    message.models = object.models?.map((e) => e) || [];
    return message;
  },
};

function createBaseWorkerPoolSpec(): WorkerPoolSpec {
  return {
    containerSpec: undefined,
    pythonPackageSpec: undefined,
    machineSpec: undefined,
    replicaCount: Long.ZERO,
    nfsMounts: [],
    diskSpec: undefined,
  };
}

export const WorkerPoolSpec: MessageFns<WorkerPoolSpec> = {
  encode(message: WorkerPoolSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.containerSpec !== undefined) {
      ContainerSpec.encode(message.containerSpec, writer.uint32(50).fork()).join();
    }
    if (message.pythonPackageSpec !== undefined) {
      PythonPackageSpec.encode(message.pythonPackageSpec, writer.uint32(58).fork()).join();
    }
    if (message.machineSpec !== undefined) {
      MachineSpec.encode(message.machineSpec, writer.uint32(10).fork()).join();
    }
    if (!message.replicaCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.replicaCount.toString());
    }
    for (const v of message.nfsMounts) {
      NfsMount.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.diskSpec !== undefined) {
      DiskSpec.encode(message.diskSpec, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkerPoolSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerPoolSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6:
          if (tag !== 50) {
            break;
          }

          message.containerSpec = ContainerSpec.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.pythonPackageSpec = PythonPackageSpec.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.machineSpec = MachineSpec.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.replicaCount = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.nfsMounts.push(NfsMount.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.diskSpec = DiskSpec.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkerPoolSpec {
    return {
      containerSpec: isSet(object.containerSpec) ? ContainerSpec.fromJSON(object.containerSpec) : undefined,
      pythonPackageSpec: isSet(object.pythonPackageSpec)
        ? PythonPackageSpec.fromJSON(object.pythonPackageSpec)
        : undefined,
      machineSpec: isSet(object.machineSpec) ? MachineSpec.fromJSON(object.machineSpec) : undefined,
      replicaCount: isSet(object.replicaCount) ? Long.fromValue(object.replicaCount) : Long.ZERO,
      nfsMounts: globalThis.Array.isArray(object?.nfsMounts)
        ? object.nfsMounts.map((e: any) => NfsMount.fromJSON(e))
        : [],
      diskSpec: isSet(object.diskSpec) ? DiskSpec.fromJSON(object.diskSpec) : undefined,
    };
  },

  toJSON(message: WorkerPoolSpec): unknown {
    const obj: any = {};
    if (message.containerSpec !== undefined) {
      obj.containerSpec = ContainerSpec.toJSON(message.containerSpec);
    }
    if (message.pythonPackageSpec !== undefined) {
      obj.pythonPackageSpec = PythonPackageSpec.toJSON(message.pythonPackageSpec);
    }
    if (message.machineSpec !== undefined) {
      obj.machineSpec = MachineSpec.toJSON(message.machineSpec);
    }
    if (!message.replicaCount.equals(Long.ZERO)) {
      obj.replicaCount = (message.replicaCount || Long.ZERO).toString();
    }
    if (message.nfsMounts?.length) {
      obj.nfsMounts = message.nfsMounts.map((e) => NfsMount.toJSON(e));
    }
    if (message.diskSpec !== undefined) {
      obj.diskSpec = DiskSpec.toJSON(message.diskSpec);
    }
    return obj;
  },

  create(base?: DeepPartial<WorkerPoolSpec>): WorkerPoolSpec {
    return WorkerPoolSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerPoolSpec>): WorkerPoolSpec {
    const message = createBaseWorkerPoolSpec();
    message.containerSpec = (object.containerSpec !== undefined && object.containerSpec !== null)
      ? ContainerSpec.fromPartial(object.containerSpec)
      : undefined;
    message.pythonPackageSpec = (object.pythonPackageSpec !== undefined && object.pythonPackageSpec !== null)
      ? PythonPackageSpec.fromPartial(object.pythonPackageSpec)
      : undefined;
    message.machineSpec = (object.machineSpec !== undefined && object.machineSpec !== null)
      ? MachineSpec.fromPartial(object.machineSpec)
      : undefined;
    message.replicaCount = (object.replicaCount !== undefined && object.replicaCount !== null)
      ? Long.fromValue(object.replicaCount)
      : Long.ZERO;
    message.nfsMounts = object.nfsMounts?.map((e) => NfsMount.fromPartial(e)) || [];
    message.diskSpec = (object.diskSpec !== undefined && object.diskSpec !== null)
      ? DiskSpec.fromPartial(object.diskSpec)
      : undefined;
    return message;
  },
};

function createBaseContainerSpec(): ContainerSpec {
  return { imageUri: "", command: [], args: [], env: [] };
}

export const ContainerSpec: MessageFns<ContainerSpec> = {
  encode(message: ContainerSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.imageUri !== "") {
      writer.uint32(10).string(message.imageUri);
    }
    for (const v of message.command) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.args) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.env) {
      EnvVar.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.imageUri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.command.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.args.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.env.push(EnvVar.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerSpec {
    return {
      imageUri: isSet(object.imageUri) ? globalThis.String(object.imageUri) : "",
      command: globalThis.Array.isArray(object?.command) ? object.command.map((e: any) => globalThis.String(e)) : [],
      args: globalThis.Array.isArray(object?.args) ? object.args.map((e: any) => globalThis.String(e)) : [],
      env: globalThis.Array.isArray(object?.env) ? object.env.map((e: any) => EnvVar.fromJSON(e)) : [],
    };
  },

  toJSON(message: ContainerSpec): unknown {
    const obj: any = {};
    if (message.imageUri !== "") {
      obj.imageUri = message.imageUri;
    }
    if (message.command?.length) {
      obj.command = message.command;
    }
    if (message.args?.length) {
      obj.args = message.args;
    }
    if (message.env?.length) {
      obj.env = message.env.map((e) => EnvVar.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerSpec>): ContainerSpec {
    return ContainerSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerSpec>): ContainerSpec {
    const message = createBaseContainerSpec();
    message.imageUri = object.imageUri ?? "";
    message.command = object.command?.map((e) => e) || [];
    message.args = object.args?.map((e) => e) || [];
    message.env = object.env?.map((e) => EnvVar.fromPartial(e)) || [];
    return message;
  },
};

function createBasePythonPackageSpec(): PythonPackageSpec {
  return { executorImageUri: "", packageUris: [], pythonModule: "", args: [], env: [] };
}

export const PythonPackageSpec: MessageFns<PythonPackageSpec> = {
  encode(message: PythonPackageSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.executorImageUri !== "") {
      writer.uint32(10).string(message.executorImageUri);
    }
    for (const v of message.packageUris) {
      writer.uint32(18).string(v!);
    }
    if (message.pythonModule !== "") {
      writer.uint32(26).string(message.pythonModule);
    }
    for (const v of message.args) {
      writer.uint32(34).string(v!);
    }
    for (const v of message.env) {
      EnvVar.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PythonPackageSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePythonPackageSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.executorImageUri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.packageUris.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pythonModule = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.args.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.env.push(EnvVar.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PythonPackageSpec {
    return {
      executorImageUri: isSet(object.executorImageUri) ? globalThis.String(object.executorImageUri) : "",
      packageUris: globalThis.Array.isArray(object?.packageUris)
        ? object.packageUris.map((e: any) => globalThis.String(e))
        : [],
      pythonModule: isSet(object.pythonModule) ? globalThis.String(object.pythonModule) : "",
      args: globalThis.Array.isArray(object?.args) ? object.args.map((e: any) => globalThis.String(e)) : [],
      env: globalThis.Array.isArray(object?.env) ? object.env.map((e: any) => EnvVar.fromJSON(e)) : [],
    };
  },

  toJSON(message: PythonPackageSpec): unknown {
    const obj: any = {};
    if (message.executorImageUri !== "") {
      obj.executorImageUri = message.executorImageUri;
    }
    if (message.packageUris?.length) {
      obj.packageUris = message.packageUris;
    }
    if (message.pythonModule !== "") {
      obj.pythonModule = message.pythonModule;
    }
    if (message.args?.length) {
      obj.args = message.args;
    }
    if (message.env?.length) {
      obj.env = message.env.map((e) => EnvVar.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PythonPackageSpec>): PythonPackageSpec {
    return PythonPackageSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PythonPackageSpec>): PythonPackageSpec {
    const message = createBasePythonPackageSpec();
    message.executorImageUri = object.executorImageUri ?? "";
    message.packageUris = object.packageUris?.map((e) => e) || [];
    message.pythonModule = object.pythonModule ?? "";
    message.args = object.args?.map((e) => e) || [];
    message.env = object.env?.map((e) => EnvVar.fromPartial(e)) || [];
    return message;
  },
};

function createBaseScheduling(): Scheduling {
  return {
    timeout: undefined,
    restartJobOnWorkerRestart: false,
    strategy: 0,
    disableRetries: false,
    maxWaitDuration: undefined,
  };
}

export const Scheduling: MessageFns<Scheduling> = {
  encode(message: Scheduling, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(10).fork()).join();
    }
    if (message.restartJobOnWorkerRestart !== false) {
      writer.uint32(24).bool(message.restartJobOnWorkerRestart);
    }
    if (message.strategy !== 0) {
      writer.uint32(32).int32(message.strategy);
    }
    if (message.disableRetries !== false) {
      writer.uint32(40).bool(message.disableRetries);
    }
    if (message.maxWaitDuration !== undefined) {
      Duration.encode(message.maxWaitDuration, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Scheduling {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScheduling();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.restartJobOnWorkerRestart = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.strategy = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.disableRetries = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.maxWaitDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Scheduling {
    return {
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      restartJobOnWorkerRestart: isSet(object.restartJobOnWorkerRestart)
        ? globalThis.Boolean(object.restartJobOnWorkerRestart)
        : false,
      strategy: isSet(object.strategy) ? scheduling_StrategyFromJSON(object.strategy) : 0,
      disableRetries: isSet(object.disableRetries) ? globalThis.Boolean(object.disableRetries) : false,
      maxWaitDuration: isSet(object.maxWaitDuration) ? Duration.fromJSON(object.maxWaitDuration) : undefined,
    };
  },

  toJSON(message: Scheduling): unknown {
    const obj: any = {};
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.restartJobOnWorkerRestart !== false) {
      obj.restartJobOnWorkerRestart = message.restartJobOnWorkerRestart;
    }
    if (message.strategy !== 0) {
      obj.strategy = scheduling_StrategyToJSON(message.strategy);
    }
    if (message.disableRetries !== false) {
      obj.disableRetries = message.disableRetries;
    }
    if (message.maxWaitDuration !== undefined) {
      obj.maxWaitDuration = Duration.toJSON(message.maxWaitDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<Scheduling>): Scheduling {
    return Scheduling.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Scheduling>): Scheduling {
    const message = createBaseScheduling();
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.restartJobOnWorkerRestart = object.restartJobOnWorkerRestart ?? false;
    message.strategy = object.strategy ?? 0;
    message.disableRetries = object.disableRetries ?? false;
    message.maxWaitDuration = (object.maxWaitDuration !== undefined && object.maxWaitDuration !== null)
      ? Duration.fromPartial(object.maxWaitDuration)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
