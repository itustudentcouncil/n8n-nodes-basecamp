// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1/feature.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { FeatureStatsAnomaly } from "./feature_monitoring_stats.js";

export const protobufPackage = "google.cloud.aiplatform.v1";

/**
 * Feature Metadata information.
 * For example, color is a feature that describes an apple.
 */
export interface Feature {
  /**
   * Immutable. Name of the Feature.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}/features/{feature}`
   * `projects/{project}/locations/{location}/featureGroups/{feature_group}/features/{feature}`
   *
   * The last part feature is assigned by the client. The feature can be up to
   * 64 characters long and can consist only of ASCII Latin letters A-Z and a-z,
   * underscore(_), and ASCII digits 0-9 starting with a letter. The value will
   * be unique given an entity type.
   */
  name: string;
  /** Description of the Feature. */
  description: string;
  /**
   * Immutable. Only applicable for Vertex AI Feature Store (Legacy).
   * Type of Feature value.
   */
  valueType: Feature_ValueType;
  /**
   * Output only. Only applicable for Vertex AI Feature Store (Legacy).
   * Timestamp when this EntityType was created.
   */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Only applicable for Vertex AI Feature Store (Legacy).
   * Timestamp when this EntityType was most recently updated.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * Optional. The labels with user-defined metadata to organize your Features.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   *
   * See https://goo.gl/xmQnxf for more information on and examples of labels.
   * No more than 64 user labels can be associated with one Feature (System
   * labels are excluded)."
   * System reserved label keys are prefixed with "aiplatform.googleapis.com/"
   * and are immutable.
   */
  labels: { [key: string]: string };
  /**
   * Used to perform a consistent read-modify-write updates. If not set, a blind
   * "overwrite" update happens.
   */
  etag: string;
  /**
   * Optional. Only applicable for Vertex AI Feature Store (Legacy).
   * If not set, use the monitoring_config defined for the EntityType this
   * Feature belongs to.
   * Only Features with type
   * ([Feature.ValueType][google.cloud.aiplatform.v1.Feature.ValueType]) BOOL,
   * STRING, DOUBLE or INT64 can enable monitoring.
   *
   * If set to true, all types of data monitoring are disabled despite the
   * config on EntityType.
   */
  disableMonitoring: boolean;
  /**
   * Output only. Only applicable for Vertex AI Feature Store (Legacy).
   * The list of historical stats and anomalies with specified objectives.
   */
  monitoringStatsAnomalies: Feature_MonitoringStatsAnomaly[];
  /**
   * Only applicable for Vertex AI Feature Store.
   * The name of the BigQuery Table/View column hosting data for this version.
   * If no value is provided, will use feature_id.
   */
  versionColumnName: string;
  /**
   * Entity responsible for maintaining this feature. Can be comma separated
   * list of email addresses or URIs.
   */
  pointOfContact: string;
}

/**
 * Only applicable for Vertex AI Legacy Feature Store.
 * An enum representing the value type of a feature.
 */
export enum Feature_ValueType {
  /** VALUE_TYPE_UNSPECIFIED - The value type is unspecified. */
  VALUE_TYPE_UNSPECIFIED = 0,
  /** BOOL - Used for Feature that is a boolean. */
  BOOL = 1,
  /** BOOL_ARRAY - Used for Feature that is a list of boolean. */
  BOOL_ARRAY = 2,
  /** DOUBLE - Used for Feature that is double. */
  DOUBLE = 3,
  /** DOUBLE_ARRAY - Used for Feature that is a list of double. */
  DOUBLE_ARRAY = 4,
  /** INT64 - Used for Feature that is INT64. */
  INT64 = 9,
  /** INT64_ARRAY - Used for Feature that is a list of INT64. */
  INT64_ARRAY = 10,
  /** STRING - Used for Feature that is string. */
  STRING = 11,
  /** STRING_ARRAY - Used for Feature that is a list of String. */
  STRING_ARRAY = 12,
  /** BYTES - Used for Feature that is bytes. */
  BYTES = 13,
  /** STRUCT - Used for Feature that is struct. */
  STRUCT = 14,
  UNRECOGNIZED = -1,
}

export function feature_ValueTypeFromJSON(object: any): Feature_ValueType {
  switch (object) {
    case 0:
    case "VALUE_TYPE_UNSPECIFIED":
      return Feature_ValueType.VALUE_TYPE_UNSPECIFIED;
    case 1:
    case "BOOL":
      return Feature_ValueType.BOOL;
    case 2:
    case "BOOL_ARRAY":
      return Feature_ValueType.BOOL_ARRAY;
    case 3:
    case "DOUBLE":
      return Feature_ValueType.DOUBLE;
    case 4:
    case "DOUBLE_ARRAY":
      return Feature_ValueType.DOUBLE_ARRAY;
    case 9:
    case "INT64":
      return Feature_ValueType.INT64;
    case 10:
    case "INT64_ARRAY":
      return Feature_ValueType.INT64_ARRAY;
    case 11:
    case "STRING":
      return Feature_ValueType.STRING;
    case 12:
    case "STRING_ARRAY":
      return Feature_ValueType.STRING_ARRAY;
    case 13:
    case "BYTES":
      return Feature_ValueType.BYTES;
    case 14:
    case "STRUCT":
      return Feature_ValueType.STRUCT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Feature_ValueType.UNRECOGNIZED;
  }
}

export function feature_ValueTypeToJSON(object: Feature_ValueType): string {
  switch (object) {
    case Feature_ValueType.VALUE_TYPE_UNSPECIFIED:
      return "VALUE_TYPE_UNSPECIFIED";
    case Feature_ValueType.BOOL:
      return "BOOL";
    case Feature_ValueType.BOOL_ARRAY:
      return "BOOL_ARRAY";
    case Feature_ValueType.DOUBLE:
      return "DOUBLE";
    case Feature_ValueType.DOUBLE_ARRAY:
      return "DOUBLE_ARRAY";
    case Feature_ValueType.INT64:
      return "INT64";
    case Feature_ValueType.INT64_ARRAY:
      return "INT64_ARRAY";
    case Feature_ValueType.STRING:
      return "STRING";
    case Feature_ValueType.STRING_ARRAY:
      return "STRING_ARRAY";
    case Feature_ValueType.BYTES:
      return "BYTES";
    case Feature_ValueType.STRUCT:
      return "STRUCT";
    case Feature_ValueType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A list of historical
 * [SnapshotAnalysis][google.cloud.aiplatform.v1.FeaturestoreMonitoringConfig.SnapshotAnalysis]
 * or
 * [ImportFeaturesAnalysis][google.cloud.aiplatform.v1.FeaturestoreMonitoringConfig.ImportFeaturesAnalysis]
 * stats requested by user, sorted by
 * [FeatureStatsAnomaly.start_time][google.cloud.aiplatform.v1.FeatureStatsAnomaly.start_time]
 * descending.
 */
export interface Feature_MonitoringStatsAnomaly {
  /** Output only. The objective for each stats. */
  objective: Feature_MonitoringStatsAnomaly_Objective;
  /** Output only. The stats and anomalies generated at specific timestamp. */
  featureStatsAnomaly: FeatureStatsAnomaly | undefined;
}

/**
 * If the objective in the request is both
 * Import Feature Analysis and Snapshot Analysis, this objective could be
 * one of them. Otherwise, this objective should be the same as the
 * objective in the request.
 */
export enum Feature_MonitoringStatsAnomaly_Objective {
  /** OBJECTIVE_UNSPECIFIED - If it's OBJECTIVE_UNSPECIFIED, monitoring_stats will be empty. */
  OBJECTIVE_UNSPECIFIED = 0,
  /** IMPORT_FEATURE_ANALYSIS - Stats are generated by Import Feature Analysis. */
  IMPORT_FEATURE_ANALYSIS = 1,
  /** SNAPSHOT_ANALYSIS - Stats are generated by Snapshot Analysis. */
  SNAPSHOT_ANALYSIS = 2,
  UNRECOGNIZED = -1,
}

export function feature_MonitoringStatsAnomaly_ObjectiveFromJSON(
  object: any,
): Feature_MonitoringStatsAnomaly_Objective {
  switch (object) {
    case 0:
    case "OBJECTIVE_UNSPECIFIED":
      return Feature_MonitoringStatsAnomaly_Objective.OBJECTIVE_UNSPECIFIED;
    case 1:
    case "IMPORT_FEATURE_ANALYSIS":
      return Feature_MonitoringStatsAnomaly_Objective.IMPORT_FEATURE_ANALYSIS;
    case 2:
    case "SNAPSHOT_ANALYSIS":
      return Feature_MonitoringStatsAnomaly_Objective.SNAPSHOT_ANALYSIS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Feature_MonitoringStatsAnomaly_Objective.UNRECOGNIZED;
  }
}

export function feature_MonitoringStatsAnomaly_ObjectiveToJSON(
  object: Feature_MonitoringStatsAnomaly_Objective,
): string {
  switch (object) {
    case Feature_MonitoringStatsAnomaly_Objective.OBJECTIVE_UNSPECIFIED:
      return "OBJECTIVE_UNSPECIFIED";
    case Feature_MonitoringStatsAnomaly_Objective.IMPORT_FEATURE_ANALYSIS:
      return "IMPORT_FEATURE_ANALYSIS";
    case Feature_MonitoringStatsAnomaly_Objective.SNAPSHOT_ANALYSIS:
      return "SNAPSHOT_ANALYSIS";
    case Feature_MonitoringStatsAnomaly_Objective.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Feature_LabelsEntry {
  key: string;
  value: string;
}

function createBaseFeature(): Feature {
  return {
    name: "",
    description: "",
    valueType: 0,
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    etag: "",
    disableMonitoring: false,
    monitoringStatsAnomalies: [],
    versionColumnName: "",
    pointOfContact: "",
  };
}

export const Feature: MessageFns<Feature> = {
  encode(message: Feature, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.valueType !== 0) {
      writer.uint32(24).int32(message.valueType);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Feature_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.etag !== "") {
      writer.uint32(58).string(message.etag);
    }
    if (message.disableMonitoring !== false) {
      writer.uint32(96).bool(message.disableMonitoring);
    }
    for (const v of message.monitoringStatsAnomalies) {
      Feature_MonitoringStatsAnomaly.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.versionColumnName !== "") {
      writer.uint32(850).string(message.versionColumnName);
    }
    if (message.pointOfContact !== "") {
      writer.uint32(858).string(message.pointOfContact);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Feature {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeature();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.valueType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = Feature_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.disableMonitoring = reader.bool();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.monitoringStatsAnomalies.push(Feature_MonitoringStatsAnomaly.decode(reader, reader.uint32()));
          continue;
        case 106:
          if (tag !== 850) {
            break;
          }

          message.versionColumnName = reader.string();
          continue;
        case 107:
          if (tag !== 858) {
            break;
          }

          message.pointOfContact = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Feature {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      valueType: isSet(object.valueType) ? feature_ValueTypeFromJSON(object.valueType) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      disableMonitoring: isSet(object.disableMonitoring) ? globalThis.Boolean(object.disableMonitoring) : false,
      monitoringStatsAnomalies: globalThis.Array.isArray(object?.monitoringStatsAnomalies)
        ? object.monitoringStatsAnomalies.map((e: any) => Feature_MonitoringStatsAnomaly.fromJSON(e))
        : [],
      versionColumnName: isSet(object.versionColumnName) ? globalThis.String(object.versionColumnName) : "",
      pointOfContact: isSet(object.pointOfContact) ? globalThis.String(object.pointOfContact) : "",
    };
  },

  toJSON(message: Feature): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.valueType !== 0) {
      obj.valueType = feature_ValueTypeToJSON(message.valueType);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.disableMonitoring !== false) {
      obj.disableMonitoring = message.disableMonitoring;
    }
    if (message.monitoringStatsAnomalies?.length) {
      obj.monitoringStatsAnomalies = message.monitoringStatsAnomalies.map((e) =>
        Feature_MonitoringStatsAnomaly.toJSON(e)
      );
    }
    if (message.versionColumnName !== "") {
      obj.versionColumnName = message.versionColumnName;
    }
    if (message.pointOfContact !== "") {
      obj.pointOfContact = message.pointOfContact;
    }
    return obj;
  },

  create(base?: DeepPartial<Feature>): Feature {
    return Feature.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Feature>): Feature {
    const message = createBaseFeature();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.valueType = object.valueType ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.etag = object.etag ?? "";
    message.disableMonitoring = object.disableMonitoring ?? false;
    message.monitoringStatsAnomalies =
      object.monitoringStatsAnomalies?.map((e) => Feature_MonitoringStatsAnomaly.fromPartial(e)) || [];
    message.versionColumnName = object.versionColumnName ?? "";
    message.pointOfContact = object.pointOfContact ?? "";
    return message;
  },
};

function createBaseFeature_MonitoringStatsAnomaly(): Feature_MonitoringStatsAnomaly {
  return { objective: 0, featureStatsAnomaly: undefined };
}

export const Feature_MonitoringStatsAnomaly: MessageFns<Feature_MonitoringStatsAnomaly> = {
  encode(message: Feature_MonitoringStatsAnomaly, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.objective !== 0) {
      writer.uint32(8).int32(message.objective);
    }
    if (message.featureStatsAnomaly !== undefined) {
      FeatureStatsAnomaly.encode(message.featureStatsAnomaly, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Feature_MonitoringStatsAnomaly {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeature_MonitoringStatsAnomaly();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.objective = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.featureStatsAnomaly = FeatureStatsAnomaly.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Feature_MonitoringStatsAnomaly {
    return {
      objective: isSet(object.objective) ? feature_MonitoringStatsAnomaly_ObjectiveFromJSON(object.objective) : 0,
      featureStatsAnomaly: isSet(object.featureStatsAnomaly)
        ? FeatureStatsAnomaly.fromJSON(object.featureStatsAnomaly)
        : undefined,
    };
  },

  toJSON(message: Feature_MonitoringStatsAnomaly): unknown {
    const obj: any = {};
    if (message.objective !== 0) {
      obj.objective = feature_MonitoringStatsAnomaly_ObjectiveToJSON(message.objective);
    }
    if (message.featureStatsAnomaly !== undefined) {
      obj.featureStatsAnomaly = FeatureStatsAnomaly.toJSON(message.featureStatsAnomaly);
    }
    return obj;
  },

  create(base?: DeepPartial<Feature_MonitoringStatsAnomaly>): Feature_MonitoringStatsAnomaly {
    return Feature_MonitoringStatsAnomaly.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Feature_MonitoringStatsAnomaly>): Feature_MonitoringStatsAnomaly {
    const message = createBaseFeature_MonitoringStatsAnomaly();
    message.objective = object.objective ?? 0;
    message.featureStatsAnomaly = (object.featureStatsAnomaly !== undefined && object.featureStatsAnomaly !== null)
      ? FeatureStatsAnomaly.fromPartial(object.featureStatsAnomaly)
      : undefined;
    return message;
  },
};

function createBaseFeature_LabelsEntry(): Feature_LabelsEntry {
  return { key: "", value: "" };
}

export const Feature_LabelsEntry: MessageFns<Feature_LabelsEntry> = {
  encode(message: Feature_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Feature_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeature_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Feature_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Feature_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Feature_LabelsEntry>): Feature_LabelsEntry {
    return Feature_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Feature_LabelsEntry>): Feature_LabelsEntry {
    const message = createBaseFeature_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
