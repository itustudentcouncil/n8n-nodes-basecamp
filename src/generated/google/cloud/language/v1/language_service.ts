// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/language/v1/language_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";

export const protobufPackage = "google.cloud.language.v1";

/**
 * Represents the text encoding that the caller uses to process the output.
 * Providing an `EncodingType` is recommended because the API provides the
 * beginning offsets for various outputs, such as tokens and mentions, and
 * languages that natively use different text encodings may access offsets
 * differently.
 */
export enum EncodingType {
  /**
   * NONE - If `EncodingType` is not specified, encoding-dependent information (such as
   * `begin_offset`) will be set at `-1`.
   */
  NONE = 0,
  /**
   * UTF8 - Encoding-dependent information (such as `begin_offset`) is calculated based
   * on the UTF-8 encoding of the input. C++ and Go are examples of languages
   * that use this encoding natively.
   */
  UTF8 = 1,
  /**
   * UTF16 - Encoding-dependent information (such as `begin_offset`) is calculated based
   * on the UTF-16 encoding of the input. Java and JavaScript are examples of
   * languages that use this encoding natively.
   */
  UTF16 = 2,
  /**
   * UTF32 - Encoding-dependent information (such as `begin_offset`) is calculated based
   * on the UTF-32 encoding of the input. Python is an example of a language
   * that uses this encoding natively.
   */
  UTF32 = 3,
  UNRECOGNIZED = -1,
}

export function encodingTypeFromJSON(object: any): EncodingType {
  switch (object) {
    case 0:
    case "NONE":
      return EncodingType.NONE;
    case 1:
    case "UTF8":
      return EncodingType.UTF8;
    case 2:
    case "UTF16":
      return EncodingType.UTF16;
    case 3:
    case "UTF32":
      return EncodingType.UTF32;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EncodingType.UNRECOGNIZED;
  }
}

export function encodingTypeToJSON(object: EncodingType): string {
  switch (object) {
    case EncodingType.NONE:
      return "NONE";
    case EncodingType.UTF8:
      return "UTF8";
    case EncodingType.UTF16:
      return "UTF16";
    case EncodingType.UTF32:
      return "UTF32";
    case EncodingType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the input to API methods. */
export interface Document {
  /**
   * Required. If the type is not set or is `TYPE_UNSPECIFIED`,
   * returns an `INVALID_ARGUMENT` error.
   */
  type: Document_Type;
  /**
   * The content of the input in string format.
   * Cloud audit logging exempt since it is based on user data.
   */
  content?:
    | string
    | undefined;
  /**
   * The Google Cloud Storage URI where the file content is located.
   * This URI must be of the form: gs://bucket_name/object_name. For more
   * details, see https://cloud.google.com/storage/docs/reference-uris.
   * NOTE: Cloud Storage object versioning is not supported.
   */
  gcsContentUri?:
    | string
    | undefined;
  /**
   * The language of the document (if not specified, the language is
   * automatically detected). Both ISO and BCP-47 language codes are
   * accepted.<br>
   * [Language
   * Support](https://cloud.google.com/natural-language/docs/languages) lists
   * currently supported languages for each API method. If the language (either
   * specified by the caller or automatically detected) is not supported by the
   * called API method, an `INVALID_ARGUMENT` error is returned.
   */
  language: string;
}

/** The document types enum. */
export enum Document_Type {
  /** TYPE_UNSPECIFIED - The content type is not specified. */
  TYPE_UNSPECIFIED = 0,
  /** PLAIN_TEXT - Plain text */
  PLAIN_TEXT = 1,
  /** HTML - HTML */
  HTML = 2,
  UNRECOGNIZED = -1,
}

export function document_TypeFromJSON(object: any): Document_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Document_Type.TYPE_UNSPECIFIED;
    case 1:
    case "PLAIN_TEXT":
      return Document_Type.PLAIN_TEXT;
    case 2:
    case "HTML":
      return Document_Type.HTML;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Document_Type.UNRECOGNIZED;
  }
}

export function document_TypeToJSON(object: Document_Type): string {
  switch (object) {
    case Document_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Document_Type.PLAIN_TEXT:
      return "PLAIN_TEXT";
    case Document_Type.HTML:
      return "HTML";
    case Document_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents a sentence in the input document. */
export interface Sentence {
  /** The sentence text. */
  text:
    | TextSpan
    | undefined;
  /**
   * For calls to [AnalyzeSentiment][] or if
   * [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v1.AnnotateTextRequest.Features.extract_document_sentiment]
   * is set to true, this field will contain the sentiment for the sentence.
   */
  sentiment: Sentiment | undefined;
}

/**
 * Represents a phrase in the text that is a known entity, such as
 * a person, an organization, or location. The API associates information, such
 * as salience and mentions, with entities.
 */
export interface Entity {
  /** The representative name for the entity. */
  name: string;
  /** The entity type. */
  type: Entity_Type;
  /**
   * Metadata associated with the entity.
   *
   * For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`)
   * and Knowledge Graph MID (`mid`), if they are available. For the metadata
   * associated with other entity types, see the Type table below.
   */
  metadata: { [key: string]: string };
  /**
   * The salience score associated with the entity in the [0, 1.0] range.
   *
   * The salience score for an entity provides information about the
   * importance or centrality of that entity to the entire document text.
   * Scores closer to 0 are less salient, while scores closer to 1.0 are highly
   * salient.
   */
  salience: number;
  /**
   * The mentions of this entity in the input document. The API currently
   * supports proper noun mentions.
   */
  mentions: EntityMention[];
  /**
   * For calls to [AnalyzeEntitySentiment][] or if
   * [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v1.AnnotateTextRequest.Features.extract_entity_sentiment]
   * is set to true, this field will contain the aggregate sentiment expressed
   * for this entity in the provided document.
   */
  sentiment: Sentiment | undefined;
}

/**
 * The type of the entity. For most entity types, the associated metadata is a
 * Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`). The table
 * below lists the associated fields for entities that have different
 * metadata.
 */
export enum Entity_Type {
  /** UNKNOWN - Unknown */
  UNKNOWN = 0,
  /** PERSON - Person */
  PERSON = 1,
  /** LOCATION - Location */
  LOCATION = 2,
  /** ORGANIZATION - Organization */
  ORGANIZATION = 3,
  /** EVENT - Event */
  EVENT = 4,
  /** WORK_OF_ART - Artwork */
  WORK_OF_ART = 5,
  /** CONSUMER_GOOD - Consumer product */
  CONSUMER_GOOD = 6,
  /** OTHER - Other types of entities */
  OTHER = 7,
  /**
   * PHONE_NUMBER - Phone number
   *
   * The metadata lists the phone number, formatted according to local
   * convention, plus whichever additional elements appear in the text:
   *
   * * `number` - the actual number, broken down into sections as per local
   * convention
   * * `national_prefix` - country code, if detected
   * * `area_code` - region or area code, if detected
   * * `extension` - phone extension (to be dialed after connection), if
   * detected
   */
  PHONE_NUMBER = 9,
  /**
   * ADDRESS - Address
   *
   * The metadata identifies the street number and locality plus whichever
   * additional elements appear in the text:
   *
   * * `street_number` - street number
   * * `locality` - city or town
   * * `street_name` - street/route name, if detected
   * * `postal_code` - postal code, if detected
   * * `country` - country, if detected<
   * * `broad_region` - administrative area, such as the state, if detected
   * * `narrow_region` - smaller administrative area, such as county, if
   * detected
   * * `sublocality` - used in Asian addresses to demark a district within a
   * city, if detected
   */
  ADDRESS = 10,
  /**
   * DATE - Date
   *
   * The metadata identifies the components of the date:
   *
   * * `year` - four digit year, if detected
   * * `month` - two digit month number, if detected
   * * `day` - two digit day number, if detected
   */
  DATE = 11,
  /**
   * NUMBER - Number
   *
   * The metadata is the number itself.
   */
  NUMBER = 12,
  /**
   * PRICE - Price
   *
   * The metadata identifies the `value` and `currency`.
   */
  PRICE = 13,
  UNRECOGNIZED = -1,
}

export function entity_TypeFromJSON(object: any): Entity_Type {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return Entity_Type.UNKNOWN;
    case 1:
    case "PERSON":
      return Entity_Type.PERSON;
    case 2:
    case "LOCATION":
      return Entity_Type.LOCATION;
    case 3:
    case "ORGANIZATION":
      return Entity_Type.ORGANIZATION;
    case 4:
    case "EVENT":
      return Entity_Type.EVENT;
    case 5:
    case "WORK_OF_ART":
      return Entity_Type.WORK_OF_ART;
    case 6:
    case "CONSUMER_GOOD":
      return Entity_Type.CONSUMER_GOOD;
    case 7:
    case "OTHER":
      return Entity_Type.OTHER;
    case 9:
    case "PHONE_NUMBER":
      return Entity_Type.PHONE_NUMBER;
    case 10:
    case "ADDRESS":
      return Entity_Type.ADDRESS;
    case 11:
    case "DATE":
      return Entity_Type.DATE;
    case 12:
    case "NUMBER":
      return Entity_Type.NUMBER;
    case 13:
    case "PRICE":
      return Entity_Type.PRICE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Entity_Type.UNRECOGNIZED;
  }
}

export function entity_TypeToJSON(object: Entity_Type): string {
  switch (object) {
    case Entity_Type.UNKNOWN:
      return "UNKNOWN";
    case Entity_Type.PERSON:
      return "PERSON";
    case Entity_Type.LOCATION:
      return "LOCATION";
    case Entity_Type.ORGANIZATION:
      return "ORGANIZATION";
    case Entity_Type.EVENT:
      return "EVENT";
    case Entity_Type.WORK_OF_ART:
      return "WORK_OF_ART";
    case Entity_Type.CONSUMER_GOOD:
      return "CONSUMER_GOOD";
    case Entity_Type.OTHER:
      return "OTHER";
    case Entity_Type.PHONE_NUMBER:
      return "PHONE_NUMBER";
    case Entity_Type.ADDRESS:
      return "ADDRESS";
    case Entity_Type.DATE:
      return "DATE";
    case Entity_Type.NUMBER:
      return "NUMBER";
    case Entity_Type.PRICE:
      return "PRICE";
    case Entity_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Entity_MetadataEntry {
  key: string;
  value: string;
}

/** Represents the smallest syntactic building block of the text. */
export interface Token {
  /** The token text. */
  text:
    | TextSpan
    | undefined;
  /** Parts of speech tag for this token. */
  partOfSpeech:
    | PartOfSpeech
    | undefined;
  /** Dependency tree parse for this token. */
  dependencyEdge:
    | DependencyEdge
    | undefined;
  /** [Lemma](https://en.wikipedia.org/wiki/Lemma_%28morphology%29) of the token. */
  lemma: string;
}

/**
 * Represents the feeling associated with the entire text or entities in
 * the text.
 */
export interface Sentiment {
  /**
   * A non-negative number in the [0, +inf) range, which represents
   * the absolute magnitude of sentiment regardless of score (positive or
   * negative).
   */
  magnitude: number;
  /**
   * Sentiment score between -1.0 (negative sentiment) and 1.0
   * (positive sentiment).
   */
  score: number;
}

/**
 * Represents part of speech information for a token. Parts of speech
 * are as defined in
 * http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf
 */
export interface PartOfSpeech {
  /** The part of speech tag. */
  tag: PartOfSpeech_Tag;
  /** The grammatical aspect. */
  aspect: PartOfSpeech_Aspect;
  /** The grammatical case. */
  case: PartOfSpeech_Case;
  /** The grammatical form. */
  form: PartOfSpeech_Form;
  /** The grammatical gender. */
  gender: PartOfSpeech_Gender;
  /** The grammatical mood. */
  mood: PartOfSpeech_Mood;
  /** The grammatical number. */
  number: PartOfSpeech_Number;
  /** The grammatical person. */
  person: PartOfSpeech_Person;
  /** The grammatical properness. */
  proper: PartOfSpeech_Proper;
  /** The grammatical reciprocity. */
  reciprocity: PartOfSpeech_Reciprocity;
  /** The grammatical tense. */
  tense: PartOfSpeech_Tense;
  /** The grammatical voice. */
  voice: PartOfSpeech_Voice;
}

/** The part of speech tags enum. */
export enum PartOfSpeech_Tag {
  /** UNKNOWN - Unknown */
  UNKNOWN = 0,
  /** ADJ - Adjective */
  ADJ = 1,
  /** ADP - Adposition (preposition and postposition) */
  ADP = 2,
  /** ADV - Adverb */
  ADV = 3,
  /** CONJ - Conjunction */
  CONJ = 4,
  /** DET - Determiner */
  DET = 5,
  /** NOUN - Noun (common and proper) */
  NOUN = 6,
  /** NUM - Cardinal number */
  NUM = 7,
  /** PRON - Pronoun */
  PRON = 8,
  /** PRT - Particle or other function word */
  PRT = 9,
  /** PUNCT - Punctuation */
  PUNCT = 10,
  /** VERB - Verb (all tenses and modes) */
  VERB = 11,
  /** X - Other: foreign words, typos, abbreviations */
  X = 12,
  /** AFFIX - Affix */
  AFFIX = 13,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_TagFromJSON(object: any): PartOfSpeech_Tag {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return PartOfSpeech_Tag.UNKNOWN;
    case 1:
    case "ADJ":
      return PartOfSpeech_Tag.ADJ;
    case 2:
    case "ADP":
      return PartOfSpeech_Tag.ADP;
    case 3:
    case "ADV":
      return PartOfSpeech_Tag.ADV;
    case 4:
    case "CONJ":
      return PartOfSpeech_Tag.CONJ;
    case 5:
    case "DET":
      return PartOfSpeech_Tag.DET;
    case 6:
    case "NOUN":
      return PartOfSpeech_Tag.NOUN;
    case 7:
    case "NUM":
      return PartOfSpeech_Tag.NUM;
    case 8:
    case "PRON":
      return PartOfSpeech_Tag.PRON;
    case 9:
    case "PRT":
      return PartOfSpeech_Tag.PRT;
    case 10:
    case "PUNCT":
      return PartOfSpeech_Tag.PUNCT;
    case 11:
    case "VERB":
      return PartOfSpeech_Tag.VERB;
    case 12:
    case "X":
      return PartOfSpeech_Tag.X;
    case 13:
    case "AFFIX":
      return PartOfSpeech_Tag.AFFIX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Tag.UNRECOGNIZED;
  }
}

export function partOfSpeech_TagToJSON(object: PartOfSpeech_Tag): string {
  switch (object) {
    case PartOfSpeech_Tag.UNKNOWN:
      return "UNKNOWN";
    case PartOfSpeech_Tag.ADJ:
      return "ADJ";
    case PartOfSpeech_Tag.ADP:
      return "ADP";
    case PartOfSpeech_Tag.ADV:
      return "ADV";
    case PartOfSpeech_Tag.CONJ:
      return "CONJ";
    case PartOfSpeech_Tag.DET:
      return "DET";
    case PartOfSpeech_Tag.NOUN:
      return "NOUN";
    case PartOfSpeech_Tag.NUM:
      return "NUM";
    case PartOfSpeech_Tag.PRON:
      return "PRON";
    case PartOfSpeech_Tag.PRT:
      return "PRT";
    case PartOfSpeech_Tag.PUNCT:
      return "PUNCT";
    case PartOfSpeech_Tag.VERB:
      return "VERB";
    case PartOfSpeech_Tag.X:
      return "X";
    case PartOfSpeech_Tag.AFFIX:
      return "AFFIX";
    case PartOfSpeech_Tag.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The characteristic of a verb that expresses time flow during an event. */
export enum PartOfSpeech_Aspect {
  /** ASPECT_UNKNOWN - Aspect is not applicable in the analyzed language or is not predicted. */
  ASPECT_UNKNOWN = 0,
  /** PERFECTIVE - Perfective */
  PERFECTIVE = 1,
  /** IMPERFECTIVE - Imperfective */
  IMPERFECTIVE = 2,
  /** PROGRESSIVE - Progressive */
  PROGRESSIVE = 3,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_AspectFromJSON(object: any): PartOfSpeech_Aspect {
  switch (object) {
    case 0:
    case "ASPECT_UNKNOWN":
      return PartOfSpeech_Aspect.ASPECT_UNKNOWN;
    case 1:
    case "PERFECTIVE":
      return PartOfSpeech_Aspect.PERFECTIVE;
    case 2:
    case "IMPERFECTIVE":
      return PartOfSpeech_Aspect.IMPERFECTIVE;
    case 3:
    case "PROGRESSIVE":
      return PartOfSpeech_Aspect.PROGRESSIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Aspect.UNRECOGNIZED;
  }
}

export function partOfSpeech_AspectToJSON(object: PartOfSpeech_Aspect): string {
  switch (object) {
    case PartOfSpeech_Aspect.ASPECT_UNKNOWN:
      return "ASPECT_UNKNOWN";
    case PartOfSpeech_Aspect.PERFECTIVE:
      return "PERFECTIVE";
    case PartOfSpeech_Aspect.IMPERFECTIVE:
      return "IMPERFECTIVE";
    case PartOfSpeech_Aspect.PROGRESSIVE:
      return "PROGRESSIVE";
    case PartOfSpeech_Aspect.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The grammatical function performed by a noun or pronoun in a phrase,
 * clause, or sentence. In some languages, other parts of speech, such as
 * adjective and determiner, take case inflection in agreement with the noun.
 */
export enum PartOfSpeech_Case {
  /** CASE_UNKNOWN - Case is not applicable in the analyzed language or is not predicted. */
  CASE_UNKNOWN = 0,
  /** ACCUSATIVE - Accusative */
  ACCUSATIVE = 1,
  /** ADVERBIAL - Adverbial */
  ADVERBIAL = 2,
  /** COMPLEMENTIVE - Complementive */
  COMPLEMENTIVE = 3,
  /** DATIVE - Dative */
  DATIVE = 4,
  /** GENITIVE - Genitive */
  GENITIVE = 5,
  /** INSTRUMENTAL - Instrumental */
  INSTRUMENTAL = 6,
  /** LOCATIVE - Locative */
  LOCATIVE = 7,
  /** NOMINATIVE - Nominative */
  NOMINATIVE = 8,
  /** OBLIQUE - Oblique */
  OBLIQUE = 9,
  /** PARTITIVE - Partitive */
  PARTITIVE = 10,
  /** PREPOSITIONAL - Prepositional */
  PREPOSITIONAL = 11,
  /** REFLEXIVE_CASE - Reflexive */
  REFLEXIVE_CASE = 12,
  /** RELATIVE_CASE - Relative */
  RELATIVE_CASE = 13,
  /** VOCATIVE - Vocative */
  VOCATIVE = 14,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_CaseFromJSON(object: any): PartOfSpeech_Case {
  switch (object) {
    case 0:
    case "CASE_UNKNOWN":
      return PartOfSpeech_Case.CASE_UNKNOWN;
    case 1:
    case "ACCUSATIVE":
      return PartOfSpeech_Case.ACCUSATIVE;
    case 2:
    case "ADVERBIAL":
      return PartOfSpeech_Case.ADVERBIAL;
    case 3:
    case "COMPLEMENTIVE":
      return PartOfSpeech_Case.COMPLEMENTIVE;
    case 4:
    case "DATIVE":
      return PartOfSpeech_Case.DATIVE;
    case 5:
    case "GENITIVE":
      return PartOfSpeech_Case.GENITIVE;
    case 6:
    case "INSTRUMENTAL":
      return PartOfSpeech_Case.INSTRUMENTAL;
    case 7:
    case "LOCATIVE":
      return PartOfSpeech_Case.LOCATIVE;
    case 8:
    case "NOMINATIVE":
      return PartOfSpeech_Case.NOMINATIVE;
    case 9:
    case "OBLIQUE":
      return PartOfSpeech_Case.OBLIQUE;
    case 10:
    case "PARTITIVE":
      return PartOfSpeech_Case.PARTITIVE;
    case 11:
    case "PREPOSITIONAL":
      return PartOfSpeech_Case.PREPOSITIONAL;
    case 12:
    case "REFLEXIVE_CASE":
      return PartOfSpeech_Case.REFLEXIVE_CASE;
    case 13:
    case "RELATIVE_CASE":
      return PartOfSpeech_Case.RELATIVE_CASE;
    case 14:
    case "VOCATIVE":
      return PartOfSpeech_Case.VOCATIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Case.UNRECOGNIZED;
  }
}

export function partOfSpeech_CaseToJSON(object: PartOfSpeech_Case): string {
  switch (object) {
    case PartOfSpeech_Case.CASE_UNKNOWN:
      return "CASE_UNKNOWN";
    case PartOfSpeech_Case.ACCUSATIVE:
      return "ACCUSATIVE";
    case PartOfSpeech_Case.ADVERBIAL:
      return "ADVERBIAL";
    case PartOfSpeech_Case.COMPLEMENTIVE:
      return "COMPLEMENTIVE";
    case PartOfSpeech_Case.DATIVE:
      return "DATIVE";
    case PartOfSpeech_Case.GENITIVE:
      return "GENITIVE";
    case PartOfSpeech_Case.INSTRUMENTAL:
      return "INSTRUMENTAL";
    case PartOfSpeech_Case.LOCATIVE:
      return "LOCATIVE";
    case PartOfSpeech_Case.NOMINATIVE:
      return "NOMINATIVE";
    case PartOfSpeech_Case.OBLIQUE:
      return "OBLIQUE";
    case PartOfSpeech_Case.PARTITIVE:
      return "PARTITIVE";
    case PartOfSpeech_Case.PREPOSITIONAL:
      return "PREPOSITIONAL";
    case PartOfSpeech_Case.REFLEXIVE_CASE:
      return "REFLEXIVE_CASE";
    case PartOfSpeech_Case.RELATIVE_CASE:
      return "RELATIVE_CASE";
    case PartOfSpeech_Case.VOCATIVE:
      return "VOCATIVE";
    case PartOfSpeech_Case.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Depending on the language, Form can be categorizing different forms of
 * verbs, adjectives, adverbs, etc. For example, categorizing inflected
 * endings of verbs and adjectives or distinguishing between short and long
 * forms of adjectives and participles
 */
export enum PartOfSpeech_Form {
  /** FORM_UNKNOWN - Form is not applicable in the analyzed language or is not predicted. */
  FORM_UNKNOWN = 0,
  /** ADNOMIAL - Adnomial */
  ADNOMIAL = 1,
  /** AUXILIARY - Auxiliary */
  AUXILIARY = 2,
  /** COMPLEMENTIZER - Complementizer */
  COMPLEMENTIZER = 3,
  /** FINAL_ENDING - Final ending */
  FINAL_ENDING = 4,
  /** GERUND - Gerund */
  GERUND = 5,
  /** REALIS - Realis */
  REALIS = 6,
  /** IRREALIS - Irrealis */
  IRREALIS = 7,
  /** SHORT - Short form */
  SHORT = 8,
  /** LONG - Long form */
  LONG = 9,
  /** ORDER - Order form */
  ORDER = 10,
  /** SPECIFIC - Specific form */
  SPECIFIC = 11,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_FormFromJSON(object: any): PartOfSpeech_Form {
  switch (object) {
    case 0:
    case "FORM_UNKNOWN":
      return PartOfSpeech_Form.FORM_UNKNOWN;
    case 1:
    case "ADNOMIAL":
      return PartOfSpeech_Form.ADNOMIAL;
    case 2:
    case "AUXILIARY":
      return PartOfSpeech_Form.AUXILIARY;
    case 3:
    case "COMPLEMENTIZER":
      return PartOfSpeech_Form.COMPLEMENTIZER;
    case 4:
    case "FINAL_ENDING":
      return PartOfSpeech_Form.FINAL_ENDING;
    case 5:
    case "GERUND":
      return PartOfSpeech_Form.GERUND;
    case 6:
    case "REALIS":
      return PartOfSpeech_Form.REALIS;
    case 7:
    case "IRREALIS":
      return PartOfSpeech_Form.IRREALIS;
    case 8:
    case "SHORT":
      return PartOfSpeech_Form.SHORT;
    case 9:
    case "LONG":
      return PartOfSpeech_Form.LONG;
    case 10:
    case "ORDER":
      return PartOfSpeech_Form.ORDER;
    case 11:
    case "SPECIFIC":
      return PartOfSpeech_Form.SPECIFIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Form.UNRECOGNIZED;
  }
}

export function partOfSpeech_FormToJSON(object: PartOfSpeech_Form): string {
  switch (object) {
    case PartOfSpeech_Form.FORM_UNKNOWN:
      return "FORM_UNKNOWN";
    case PartOfSpeech_Form.ADNOMIAL:
      return "ADNOMIAL";
    case PartOfSpeech_Form.AUXILIARY:
      return "AUXILIARY";
    case PartOfSpeech_Form.COMPLEMENTIZER:
      return "COMPLEMENTIZER";
    case PartOfSpeech_Form.FINAL_ENDING:
      return "FINAL_ENDING";
    case PartOfSpeech_Form.GERUND:
      return "GERUND";
    case PartOfSpeech_Form.REALIS:
      return "REALIS";
    case PartOfSpeech_Form.IRREALIS:
      return "IRREALIS";
    case PartOfSpeech_Form.SHORT:
      return "SHORT";
    case PartOfSpeech_Form.LONG:
      return "LONG";
    case PartOfSpeech_Form.ORDER:
      return "ORDER";
    case PartOfSpeech_Form.SPECIFIC:
      return "SPECIFIC";
    case PartOfSpeech_Form.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Gender classes of nouns reflected in the behaviour of associated words. */
export enum PartOfSpeech_Gender {
  /** GENDER_UNKNOWN - Gender is not applicable in the analyzed language or is not predicted. */
  GENDER_UNKNOWN = 0,
  /** FEMININE - Feminine */
  FEMININE = 1,
  /** MASCULINE - Masculine */
  MASCULINE = 2,
  /** NEUTER - Neuter */
  NEUTER = 3,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_GenderFromJSON(object: any): PartOfSpeech_Gender {
  switch (object) {
    case 0:
    case "GENDER_UNKNOWN":
      return PartOfSpeech_Gender.GENDER_UNKNOWN;
    case 1:
    case "FEMININE":
      return PartOfSpeech_Gender.FEMININE;
    case 2:
    case "MASCULINE":
      return PartOfSpeech_Gender.MASCULINE;
    case 3:
    case "NEUTER":
      return PartOfSpeech_Gender.NEUTER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Gender.UNRECOGNIZED;
  }
}

export function partOfSpeech_GenderToJSON(object: PartOfSpeech_Gender): string {
  switch (object) {
    case PartOfSpeech_Gender.GENDER_UNKNOWN:
      return "GENDER_UNKNOWN";
    case PartOfSpeech_Gender.FEMININE:
      return "FEMININE";
    case PartOfSpeech_Gender.MASCULINE:
      return "MASCULINE";
    case PartOfSpeech_Gender.NEUTER:
      return "NEUTER";
    case PartOfSpeech_Gender.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The grammatical feature of verbs, used for showing modality and attitude. */
export enum PartOfSpeech_Mood {
  /** MOOD_UNKNOWN - Mood is not applicable in the analyzed language or is not predicted. */
  MOOD_UNKNOWN = 0,
  /** CONDITIONAL_MOOD - Conditional */
  CONDITIONAL_MOOD = 1,
  /** IMPERATIVE - Imperative */
  IMPERATIVE = 2,
  /** INDICATIVE - Indicative */
  INDICATIVE = 3,
  /** INTERROGATIVE - Interrogative */
  INTERROGATIVE = 4,
  /** JUSSIVE - Jussive */
  JUSSIVE = 5,
  /** SUBJUNCTIVE - Subjunctive */
  SUBJUNCTIVE = 6,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_MoodFromJSON(object: any): PartOfSpeech_Mood {
  switch (object) {
    case 0:
    case "MOOD_UNKNOWN":
      return PartOfSpeech_Mood.MOOD_UNKNOWN;
    case 1:
    case "CONDITIONAL_MOOD":
      return PartOfSpeech_Mood.CONDITIONAL_MOOD;
    case 2:
    case "IMPERATIVE":
      return PartOfSpeech_Mood.IMPERATIVE;
    case 3:
    case "INDICATIVE":
      return PartOfSpeech_Mood.INDICATIVE;
    case 4:
    case "INTERROGATIVE":
      return PartOfSpeech_Mood.INTERROGATIVE;
    case 5:
    case "JUSSIVE":
      return PartOfSpeech_Mood.JUSSIVE;
    case 6:
    case "SUBJUNCTIVE":
      return PartOfSpeech_Mood.SUBJUNCTIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Mood.UNRECOGNIZED;
  }
}

export function partOfSpeech_MoodToJSON(object: PartOfSpeech_Mood): string {
  switch (object) {
    case PartOfSpeech_Mood.MOOD_UNKNOWN:
      return "MOOD_UNKNOWN";
    case PartOfSpeech_Mood.CONDITIONAL_MOOD:
      return "CONDITIONAL_MOOD";
    case PartOfSpeech_Mood.IMPERATIVE:
      return "IMPERATIVE";
    case PartOfSpeech_Mood.INDICATIVE:
      return "INDICATIVE";
    case PartOfSpeech_Mood.INTERROGATIVE:
      return "INTERROGATIVE";
    case PartOfSpeech_Mood.JUSSIVE:
      return "JUSSIVE";
    case PartOfSpeech_Mood.SUBJUNCTIVE:
      return "SUBJUNCTIVE";
    case PartOfSpeech_Mood.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Count distinctions. */
export enum PartOfSpeech_Number {
  /** NUMBER_UNKNOWN - Number is not applicable in the analyzed language or is not predicted. */
  NUMBER_UNKNOWN = 0,
  /** SINGULAR - Singular */
  SINGULAR = 1,
  /** PLURAL - Plural */
  PLURAL = 2,
  /** DUAL - Dual */
  DUAL = 3,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_NumberFromJSON(object: any): PartOfSpeech_Number {
  switch (object) {
    case 0:
    case "NUMBER_UNKNOWN":
      return PartOfSpeech_Number.NUMBER_UNKNOWN;
    case 1:
    case "SINGULAR":
      return PartOfSpeech_Number.SINGULAR;
    case 2:
    case "PLURAL":
      return PartOfSpeech_Number.PLURAL;
    case 3:
    case "DUAL":
      return PartOfSpeech_Number.DUAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Number.UNRECOGNIZED;
  }
}

export function partOfSpeech_NumberToJSON(object: PartOfSpeech_Number): string {
  switch (object) {
    case PartOfSpeech_Number.NUMBER_UNKNOWN:
      return "NUMBER_UNKNOWN";
    case PartOfSpeech_Number.SINGULAR:
      return "SINGULAR";
    case PartOfSpeech_Number.PLURAL:
      return "PLURAL";
    case PartOfSpeech_Number.DUAL:
      return "DUAL";
    case PartOfSpeech_Number.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The distinction between the speaker, second person, third person, etc. */
export enum PartOfSpeech_Person {
  /** PERSON_UNKNOWN - Person is not applicable in the analyzed language or is not predicted. */
  PERSON_UNKNOWN = 0,
  /** FIRST - First */
  FIRST = 1,
  /** SECOND - Second */
  SECOND = 2,
  /** THIRD - Third */
  THIRD = 3,
  /** REFLEXIVE_PERSON - Reflexive */
  REFLEXIVE_PERSON = 4,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_PersonFromJSON(object: any): PartOfSpeech_Person {
  switch (object) {
    case 0:
    case "PERSON_UNKNOWN":
      return PartOfSpeech_Person.PERSON_UNKNOWN;
    case 1:
    case "FIRST":
      return PartOfSpeech_Person.FIRST;
    case 2:
    case "SECOND":
      return PartOfSpeech_Person.SECOND;
    case 3:
    case "THIRD":
      return PartOfSpeech_Person.THIRD;
    case 4:
    case "REFLEXIVE_PERSON":
      return PartOfSpeech_Person.REFLEXIVE_PERSON;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Person.UNRECOGNIZED;
  }
}

export function partOfSpeech_PersonToJSON(object: PartOfSpeech_Person): string {
  switch (object) {
    case PartOfSpeech_Person.PERSON_UNKNOWN:
      return "PERSON_UNKNOWN";
    case PartOfSpeech_Person.FIRST:
      return "FIRST";
    case PartOfSpeech_Person.SECOND:
      return "SECOND";
    case PartOfSpeech_Person.THIRD:
      return "THIRD";
    case PartOfSpeech_Person.REFLEXIVE_PERSON:
      return "REFLEXIVE_PERSON";
    case PartOfSpeech_Person.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** This category shows if the token is part of a proper name. */
export enum PartOfSpeech_Proper {
  /** PROPER_UNKNOWN - Proper is not applicable in the analyzed language or is not predicted. */
  PROPER_UNKNOWN = 0,
  /** PROPER - Proper */
  PROPER = 1,
  /** NOT_PROPER - Not proper */
  NOT_PROPER = 2,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_ProperFromJSON(object: any): PartOfSpeech_Proper {
  switch (object) {
    case 0:
    case "PROPER_UNKNOWN":
      return PartOfSpeech_Proper.PROPER_UNKNOWN;
    case 1:
    case "PROPER":
      return PartOfSpeech_Proper.PROPER;
    case 2:
    case "NOT_PROPER":
      return PartOfSpeech_Proper.NOT_PROPER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Proper.UNRECOGNIZED;
  }
}

export function partOfSpeech_ProperToJSON(object: PartOfSpeech_Proper): string {
  switch (object) {
    case PartOfSpeech_Proper.PROPER_UNKNOWN:
      return "PROPER_UNKNOWN";
    case PartOfSpeech_Proper.PROPER:
      return "PROPER";
    case PartOfSpeech_Proper.NOT_PROPER:
      return "NOT_PROPER";
    case PartOfSpeech_Proper.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Reciprocal features of a pronoun. */
export enum PartOfSpeech_Reciprocity {
  /**
   * RECIPROCITY_UNKNOWN - Reciprocity is not applicable in the analyzed language or is not
   * predicted.
   */
  RECIPROCITY_UNKNOWN = 0,
  /** RECIPROCAL - Reciprocal */
  RECIPROCAL = 1,
  /** NON_RECIPROCAL - Non-reciprocal */
  NON_RECIPROCAL = 2,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_ReciprocityFromJSON(object: any): PartOfSpeech_Reciprocity {
  switch (object) {
    case 0:
    case "RECIPROCITY_UNKNOWN":
      return PartOfSpeech_Reciprocity.RECIPROCITY_UNKNOWN;
    case 1:
    case "RECIPROCAL":
      return PartOfSpeech_Reciprocity.RECIPROCAL;
    case 2:
    case "NON_RECIPROCAL":
      return PartOfSpeech_Reciprocity.NON_RECIPROCAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Reciprocity.UNRECOGNIZED;
  }
}

export function partOfSpeech_ReciprocityToJSON(object: PartOfSpeech_Reciprocity): string {
  switch (object) {
    case PartOfSpeech_Reciprocity.RECIPROCITY_UNKNOWN:
      return "RECIPROCITY_UNKNOWN";
    case PartOfSpeech_Reciprocity.RECIPROCAL:
      return "RECIPROCAL";
    case PartOfSpeech_Reciprocity.NON_RECIPROCAL:
      return "NON_RECIPROCAL";
    case PartOfSpeech_Reciprocity.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Time reference. */
export enum PartOfSpeech_Tense {
  /** TENSE_UNKNOWN - Tense is not applicable in the analyzed language or is not predicted. */
  TENSE_UNKNOWN = 0,
  /** CONDITIONAL_TENSE - Conditional */
  CONDITIONAL_TENSE = 1,
  /** FUTURE - Future */
  FUTURE = 2,
  /** PAST - Past */
  PAST = 3,
  /** PRESENT - Present */
  PRESENT = 4,
  /** IMPERFECT - Imperfect */
  IMPERFECT = 5,
  /** PLUPERFECT - Pluperfect */
  PLUPERFECT = 6,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_TenseFromJSON(object: any): PartOfSpeech_Tense {
  switch (object) {
    case 0:
    case "TENSE_UNKNOWN":
      return PartOfSpeech_Tense.TENSE_UNKNOWN;
    case 1:
    case "CONDITIONAL_TENSE":
      return PartOfSpeech_Tense.CONDITIONAL_TENSE;
    case 2:
    case "FUTURE":
      return PartOfSpeech_Tense.FUTURE;
    case 3:
    case "PAST":
      return PartOfSpeech_Tense.PAST;
    case 4:
    case "PRESENT":
      return PartOfSpeech_Tense.PRESENT;
    case 5:
    case "IMPERFECT":
      return PartOfSpeech_Tense.IMPERFECT;
    case 6:
    case "PLUPERFECT":
      return PartOfSpeech_Tense.PLUPERFECT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Tense.UNRECOGNIZED;
  }
}

export function partOfSpeech_TenseToJSON(object: PartOfSpeech_Tense): string {
  switch (object) {
    case PartOfSpeech_Tense.TENSE_UNKNOWN:
      return "TENSE_UNKNOWN";
    case PartOfSpeech_Tense.CONDITIONAL_TENSE:
      return "CONDITIONAL_TENSE";
    case PartOfSpeech_Tense.FUTURE:
      return "FUTURE";
    case PartOfSpeech_Tense.PAST:
      return "PAST";
    case PartOfSpeech_Tense.PRESENT:
      return "PRESENT";
    case PartOfSpeech_Tense.IMPERFECT:
      return "IMPERFECT";
    case PartOfSpeech_Tense.PLUPERFECT:
      return "PLUPERFECT";
    case PartOfSpeech_Tense.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The relationship between the action that a verb expresses and the
 * participants identified by its arguments.
 */
export enum PartOfSpeech_Voice {
  /** VOICE_UNKNOWN - Voice is not applicable in the analyzed language or is not predicted. */
  VOICE_UNKNOWN = 0,
  /** ACTIVE - Active */
  ACTIVE = 1,
  /** CAUSATIVE - Causative */
  CAUSATIVE = 2,
  /** PASSIVE - Passive */
  PASSIVE = 3,
  UNRECOGNIZED = -1,
}

export function partOfSpeech_VoiceFromJSON(object: any): PartOfSpeech_Voice {
  switch (object) {
    case 0:
    case "VOICE_UNKNOWN":
      return PartOfSpeech_Voice.VOICE_UNKNOWN;
    case 1:
    case "ACTIVE":
      return PartOfSpeech_Voice.ACTIVE;
    case 2:
    case "CAUSATIVE":
      return PartOfSpeech_Voice.CAUSATIVE;
    case 3:
    case "PASSIVE":
      return PartOfSpeech_Voice.PASSIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PartOfSpeech_Voice.UNRECOGNIZED;
  }
}

export function partOfSpeech_VoiceToJSON(object: PartOfSpeech_Voice): string {
  switch (object) {
    case PartOfSpeech_Voice.VOICE_UNKNOWN:
      return "VOICE_UNKNOWN";
    case PartOfSpeech_Voice.ACTIVE:
      return "ACTIVE";
    case PartOfSpeech_Voice.CAUSATIVE:
      return "CAUSATIVE";
    case PartOfSpeech_Voice.PASSIVE:
      return "PASSIVE";
    case PartOfSpeech_Voice.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Represents dependency parse tree information for a token. (For more
 * information on dependency labels, see
 * http://www.aclweb.org/anthology/P13-2017
 */
export interface DependencyEdge {
  /**
   * Represents the head of this token in the dependency tree.
   * This is the index of the token which has an arc going to this token.
   * The index is the position of the token in the array of tokens returned
   * by the API method. If this token is a root token, then the
   * `head_token_index` is its own index.
   */
  headTokenIndex: number;
  /** The parse label for the token. */
  label: DependencyEdge_Label;
}

/** The parse label enum for the token. */
export enum DependencyEdge_Label {
  /** UNKNOWN - Unknown */
  UNKNOWN = 0,
  /** ABBREV - Abbreviation modifier */
  ABBREV = 1,
  /** ACOMP - Adjectival complement */
  ACOMP = 2,
  /** ADVCL - Adverbial clause modifier */
  ADVCL = 3,
  /** ADVMOD - Adverbial modifier */
  ADVMOD = 4,
  /** AMOD - Adjectival modifier of an NP */
  AMOD = 5,
  /** APPOS - Appositional modifier of an NP */
  APPOS = 6,
  /** ATTR - Attribute dependent of a copular verb */
  ATTR = 7,
  /** AUX - Auxiliary (non-main) verb */
  AUX = 8,
  /** AUXPASS - Passive auxiliary */
  AUXPASS = 9,
  /** CC - Coordinating conjunction */
  CC = 10,
  /** CCOMP - Clausal complement of a verb or adjective */
  CCOMP = 11,
  /** CONJ - Conjunct */
  CONJ = 12,
  /** CSUBJ - Clausal subject */
  CSUBJ = 13,
  /** CSUBJPASS - Clausal passive subject */
  CSUBJPASS = 14,
  /** DEP - Dependency (unable to determine) */
  DEP = 15,
  /** DET - Determiner */
  DET = 16,
  /** DISCOURSE - Discourse */
  DISCOURSE = 17,
  /** DOBJ - Direct object */
  DOBJ = 18,
  /** EXPL - Expletive */
  EXPL = 19,
  /** GOESWITH - Goes with (part of a word in a text not well edited) */
  GOESWITH = 20,
  /** IOBJ - Indirect object */
  IOBJ = 21,
  /** MARK - Marker (word introducing a subordinate clause) */
  MARK = 22,
  /** MWE - Multi-word expression */
  MWE = 23,
  /** MWV - Multi-word verbal expression */
  MWV = 24,
  /** NEG - Negation modifier */
  NEG = 25,
  /** NN - Noun compound modifier */
  NN = 26,
  /** NPADVMOD - Noun phrase used as an adverbial modifier */
  NPADVMOD = 27,
  /** NSUBJ - Nominal subject */
  NSUBJ = 28,
  /** NSUBJPASS - Passive nominal subject */
  NSUBJPASS = 29,
  /** NUM - Numeric modifier of a noun */
  NUM = 30,
  /** NUMBER - Element of compound number */
  NUMBER = 31,
  /** P - Punctuation mark */
  P = 32,
  /** PARATAXIS - Parataxis relation */
  PARATAXIS = 33,
  /** PARTMOD - Participial modifier */
  PARTMOD = 34,
  /** PCOMP - The complement of a preposition is a clause */
  PCOMP = 35,
  /** POBJ - Object of a preposition */
  POBJ = 36,
  /** POSS - Possession modifier */
  POSS = 37,
  /** POSTNEG - Postverbal negative particle */
  POSTNEG = 38,
  /** PRECOMP - Predicate complement */
  PRECOMP = 39,
  /** PRECONJ - Preconjunt */
  PRECONJ = 40,
  /** PREDET - Predeterminer */
  PREDET = 41,
  /** PREF - Prefix */
  PREF = 42,
  /** PREP - Prepositional modifier */
  PREP = 43,
  /** PRONL - The relationship between a verb and verbal morpheme */
  PRONL = 44,
  /** PRT - Particle */
  PRT = 45,
  /** PS - Associative or possessive marker */
  PS = 46,
  /** QUANTMOD - Quantifier phrase modifier */
  QUANTMOD = 47,
  /** RCMOD - Relative clause modifier */
  RCMOD = 48,
  /** RCMODREL - Complementizer in relative clause */
  RCMODREL = 49,
  /** RDROP - Ellipsis without a preceding predicate */
  RDROP = 50,
  /** REF - Referent */
  REF = 51,
  /** REMNANT - Remnant */
  REMNANT = 52,
  /** REPARANDUM - Reparandum */
  REPARANDUM = 53,
  /** ROOT - Root */
  ROOT = 54,
  /** SNUM - Suffix specifying a unit of number */
  SNUM = 55,
  /** SUFF - Suffix */
  SUFF = 56,
  /** TMOD - Temporal modifier */
  TMOD = 57,
  /** TOPIC - Topic marker */
  TOPIC = 58,
  /** VMOD - Clause headed by an infinite form of the verb that modifies a noun */
  VMOD = 59,
  /** VOCATIVE - Vocative */
  VOCATIVE = 60,
  /** XCOMP - Open clausal complement */
  XCOMP = 61,
  /** SUFFIX - Name suffix */
  SUFFIX = 62,
  /** TITLE - Name title */
  TITLE = 63,
  /** ADVPHMOD - Adverbial phrase modifier */
  ADVPHMOD = 64,
  /** AUXCAUS - Causative auxiliary */
  AUXCAUS = 65,
  /** AUXVV - Helper auxiliary */
  AUXVV = 66,
  /** DTMOD - Rentaishi (Prenominal modifier) */
  DTMOD = 67,
  /** FOREIGN - Foreign words */
  FOREIGN = 68,
  /** KW - Keyword */
  KW = 69,
  /** LIST - List for chains of comparable items */
  LIST = 70,
  /** NOMC - Nominalized clause */
  NOMC = 71,
  /** NOMCSUBJ - Nominalized clausal subject */
  NOMCSUBJ = 72,
  /** NOMCSUBJPASS - Nominalized clausal passive */
  NOMCSUBJPASS = 73,
  /** NUMC - Compound of numeric modifier */
  NUMC = 74,
  /** COP - Copula */
  COP = 75,
  /** DISLOCATED - Dislocated relation (for fronted/topicalized elements) */
  DISLOCATED = 76,
  /** ASP - Aspect marker */
  ASP = 77,
  /** GMOD - Genitive modifier */
  GMOD = 78,
  /** GOBJ - Genitive object */
  GOBJ = 79,
  /** INFMOD - Infinitival modifier */
  INFMOD = 80,
  /** MES - Measure */
  MES = 81,
  /** NCOMP - Nominal complement of a noun */
  NCOMP = 82,
  UNRECOGNIZED = -1,
}

export function dependencyEdge_LabelFromJSON(object: any): DependencyEdge_Label {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return DependencyEdge_Label.UNKNOWN;
    case 1:
    case "ABBREV":
      return DependencyEdge_Label.ABBREV;
    case 2:
    case "ACOMP":
      return DependencyEdge_Label.ACOMP;
    case 3:
    case "ADVCL":
      return DependencyEdge_Label.ADVCL;
    case 4:
    case "ADVMOD":
      return DependencyEdge_Label.ADVMOD;
    case 5:
    case "AMOD":
      return DependencyEdge_Label.AMOD;
    case 6:
    case "APPOS":
      return DependencyEdge_Label.APPOS;
    case 7:
    case "ATTR":
      return DependencyEdge_Label.ATTR;
    case 8:
    case "AUX":
      return DependencyEdge_Label.AUX;
    case 9:
    case "AUXPASS":
      return DependencyEdge_Label.AUXPASS;
    case 10:
    case "CC":
      return DependencyEdge_Label.CC;
    case 11:
    case "CCOMP":
      return DependencyEdge_Label.CCOMP;
    case 12:
    case "CONJ":
      return DependencyEdge_Label.CONJ;
    case 13:
    case "CSUBJ":
      return DependencyEdge_Label.CSUBJ;
    case 14:
    case "CSUBJPASS":
      return DependencyEdge_Label.CSUBJPASS;
    case 15:
    case "DEP":
      return DependencyEdge_Label.DEP;
    case 16:
    case "DET":
      return DependencyEdge_Label.DET;
    case 17:
    case "DISCOURSE":
      return DependencyEdge_Label.DISCOURSE;
    case 18:
    case "DOBJ":
      return DependencyEdge_Label.DOBJ;
    case 19:
    case "EXPL":
      return DependencyEdge_Label.EXPL;
    case 20:
    case "GOESWITH":
      return DependencyEdge_Label.GOESWITH;
    case 21:
    case "IOBJ":
      return DependencyEdge_Label.IOBJ;
    case 22:
    case "MARK":
      return DependencyEdge_Label.MARK;
    case 23:
    case "MWE":
      return DependencyEdge_Label.MWE;
    case 24:
    case "MWV":
      return DependencyEdge_Label.MWV;
    case 25:
    case "NEG":
      return DependencyEdge_Label.NEG;
    case 26:
    case "NN":
      return DependencyEdge_Label.NN;
    case 27:
    case "NPADVMOD":
      return DependencyEdge_Label.NPADVMOD;
    case 28:
    case "NSUBJ":
      return DependencyEdge_Label.NSUBJ;
    case 29:
    case "NSUBJPASS":
      return DependencyEdge_Label.NSUBJPASS;
    case 30:
    case "NUM":
      return DependencyEdge_Label.NUM;
    case 31:
    case "NUMBER":
      return DependencyEdge_Label.NUMBER;
    case 32:
    case "P":
      return DependencyEdge_Label.P;
    case 33:
    case "PARATAXIS":
      return DependencyEdge_Label.PARATAXIS;
    case 34:
    case "PARTMOD":
      return DependencyEdge_Label.PARTMOD;
    case 35:
    case "PCOMP":
      return DependencyEdge_Label.PCOMP;
    case 36:
    case "POBJ":
      return DependencyEdge_Label.POBJ;
    case 37:
    case "POSS":
      return DependencyEdge_Label.POSS;
    case 38:
    case "POSTNEG":
      return DependencyEdge_Label.POSTNEG;
    case 39:
    case "PRECOMP":
      return DependencyEdge_Label.PRECOMP;
    case 40:
    case "PRECONJ":
      return DependencyEdge_Label.PRECONJ;
    case 41:
    case "PREDET":
      return DependencyEdge_Label.PREDET;
    case 42:
    case "PREF":
      return DependencyEdge_Label.PREF;
    case 43:
    case "PREP":
      return DependencyEdge_Label.PREP;
    case 44:
    case "PRONL":
      return DependencyEdge_Label.PRONL;
    case 45:
    case "PRT":
      return DependencyEdge_Label.PRT;
    case 46:
    case "PS":
      return DependencyEdge_Label.PS;
    case 47:
    case "QUANTMOD":
      return DependencyEdge_Label.QUANTMOD;
    case 48:
    case "RCMOD":
      return DependencyEdge_Label.RCMOD;
    case 49:
    case "RCMODREL":
      return DependencyEdge_Label.RCMODREL;
    case 50:
    case "RDROP":
      return DependencyEdge_Label.RDROP;
    case 51:
    case "REF":
      return DependencyEdge_Label.REF;
    case 52:
    case "REMNANT":
      return DependencyEdge_Label.REMNANT;
    case 53:
    case "REPARANDUM":
      return DependencyEdge_Label.REPARANDUM;
    case 54:
    case "ROOT":
      return DependencyEdge_Label.ROOT;
    case 55:
    case "SNUM":
      return DependencyEdge_Label.SNUM;
    case 56:
    case "SUFF":
      return DependencyEdge_Label.SUFF;
    case 57:
    case "TMOD":
      return DependencyEdge_Label.TMOD;
    case 58:
    case "TOPIC":
      return DependencyEdge_Label.TOPIC;
    case 59:
    case "VMOD":
      return DependencyEdge_Label.VMOD;
    case 60:
    case "VOCATIVE":
      return DependencyEdge_Label.VOCATIVE;
    case 61:
    case "XCOMP":
      return DependencyEdge_Label.XCOMP;
    case 62:
    case "SUFFIX":
      return DependencyEdge_Label.SUFFIX;
    case 63:
    case "TITLE":
      return DependencyEdge_Label.TITLE;
    case 64:
    case "ADVPHMOD":
      return DependencyEdge_Label.ADVPHMOD;
    case 65:
    case "AUXCAUS":
      return DependencyEdge_Label.AUXCAUS;
    case 66:
    case "AUXVV":
      return DependencyEdge_Label.AUXVV;
    case 67:
    case "DTMOD":
      return DependencyEdge_Label.DTMOD;
    case 68:
    case "FOREIGN":
      return DependencyEdge_Label.FOREIGN;
    case 69:
    case "KW":
      return DependencyEdge_Label.KW;
    case 70:
    case "LIST":
      return DependencyEdge_Label.LIST;
    case 71:
    case "NOMC":
      return DependencyEdge_Label.NOMC;
    case 72:
    case "NOMCSUBJ":
      return DependencyEdge_Label.NOMCSUBJ;
    case 73:
    case "NOMCSUBJPASS":
      return DependencyEdge_Label.NOMCSUBJPASS;
    case 74:
    case "NUMC":
      return DependencyEdge_Label.NUMC;
    case 75:
    case "COP":
      return DependencyEdge_Label.COP;
    case 76:
    case "DISLOCATED":
      return DependencyEdge_Label.DISLOCATED;
    case 77:
    case "ASP":
      return DependencyEdge_Label.ASP;
    case 78:
    case "GMOD":
      return DependencyEdge_Label.GMOD;
    case 79:
    case "GOBJ":
      return DependencyEdge_Label.GOBJ;
    case 80:
    case "INFMOD":
      return DependencyEdge_Label.INFMOD;
    case 81:
    case "MES":
      return DependencyEdge_Label.MES;
    case 82:
    case "NCOMP":
      return DependencyEdge_Label.NCOMP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DependencyEdge_Label.UNRECOGNIZED;
  }
}

export function dependencyEdge_LabelToJSON(object: DependencyEdge_Label): string {
  switch (object) {
    case DependencyEdge_Label.UNKNOWN:
      return "UNKNOWN";
    case DependencyEdge_Label.ABBREV:
      return "ABBREV";
    case DependencyEdge_Label.ACOMP:
      return "ACOMP";
    case DependencyEdge_Label.ADVCL:
      return "ADVCL";
    case DependencyEdge_Label.ADVMOD:
      return "ADVMOD";
    case DependencyEdge_Label.AMOD:
      return "AMOD";
    case DependencyEdge_Label.APPOS:
      return "APPOS";
    case DependencyEdge_Label.ATTR:
      return "ATTR";
    case DependencyEdge_Label.AUX:
      return "AUX";
    case DependencyEdge_Label.AUXPASS:
      return "AUXPASS";
    case DependencyEdge_Label.CC:
      return "CC";
    case DependencyEdge_Label.CCOMP:
      return "CCOMP";
    case DependencyEdge_Label.CONJ:
      return "CONJ";
    case DependencyEdge_Label.CSUBJ:
      return "CSUBJ";
    case DependencyEdge_Label.CSUBJPASS:
      return "CSUBJPASS";
    case DependencyEdge_Label.DEP:
      return "DEP";
    case DependencyEdge_Label.DET:
      return "DET";
    case DependencyEdge_Label.DISCOURSE:
      return "DISCOURSE";
    case DependencyEdge_Label.DOBJ:
      return "DOBJ";
    case DependencyEdge_Label.EXPL:
      return "EXPL";
    case DependencyEdge_Label.GOESWITH:
      return "GOESWITH";
    case DependencyEdge_Label.IOBJ:
      return "IOBJ";
    case DependencyEdge_Label.MARK:
      return "MARK";
    case DependencyEdge_Label.MWE:
      return "MWE";
    case DependencyEdge_Label.MWV:
      return "MWV";
    case DependencyEdge_Label.NEG:
      return "NEG";
    case DependencyEdge_Label.NN:
      return "NN";
    case DependencyEdge_Label.NPADVMOD:
      return "NPADVMOD";
    case DependencyEdge_Label.NSUBJ:
      return "NSUBJ";
    case DependencyEdge_Label.NSUBJPASS:
      return "NSUBJPASS";
    case DependencyEdge_Label.NUM:
      return "NUM";
    case DependencyEdge_Label.NUMBER:
      return "NUMBER";
    case DependencyEdge_Label.P:
      return "P";
    case DependencyEdge_Label.PARATAXIS:
      return "PARATAXIS";
    case DependencyEdge_Label.PARTMOD:
      return "PARTMOD";
    case DependencyEdge_Label.PCOMP:
      return "PCOMP";
    case DependencyEdge_Label.POBJ:
      return "POBJ";
    case DependencyEdge_Label.POSS:
      return "POSS";
    case DependencyEdge_Label.POSTNEG:
      return "POSTNEG";
    case DependencyEdge_Label.PRECOMP:
      return "PRECOMP";
    case DependencyEdge_Label.PRECONJ:
      return "PRECONJ";
    case DependencyEdge_Label.PREDET:
      return "PREDET";
    case DependencyEdge_Label.PREF:
      return "PREF";
    case DependencyEdge_Label.PREP:
      return "PREP";
    case DependencyEdge_Label.PRONL:
      return "PRONL";
    case DependencyEdge_Label.PRT:
      return "PRT";
    case DependencyEdge_Label.PS:
      return "PS";
    case DependencyEdge_Label.QUANTMOD:
      return "QUANTMOD";
    case DependencyEdge_Label.RCMOD:
      return "RCMOD";
    case DependencyEdge_Label.RCMODREL:
      return "RCMODREL";
    case DependencyEdge_Label.RDROP:
      return "RDROP";
    case DependencyEdge_Label.REF:
      return "REF";
    case DependencyEdge_Label.REMNANT:
      return "REMNANT";
    case DependencyEdge_Label.REPARANDUM:
      return "REPARANDUM";
    case DependencyEdge_Label.ROOT:
      return "ROOT";
    case DependencyEdge_Label.SNUM:
      return "SNUM";
    case DependencyEdge_Label.SUFF:
      return "SUFF";
    case DependencyEdge_Label.TMOD:
      return "TMOD";
    case DependencyEdge_Label.TOPIC:
      return "TOPIC";
    case DependencyEdge_Label.VMOD:
      return "VMOD";
    case DependencyEdge_Label.VOCATIVE:
      return "VOCATIVE";
    case DependencyEdge_Label.XCOMP:
      return "XCOMP";
    case DependencyEdge_Label.SUFFIX:
      return "SUFFIX";
    case DependencyEdge_Label.TITLE:
      return "TITLE";
    case DependencyEdge_Label.ADVPHMOD:
      return "ADVPHMOD";
    case DependencyEdge_Label.AUXCAUS:
      return "AUXCAUS";
    case DependencyEdge_Label.AUXVV:
      return "AUXVV";
    case DependencyEdge_Label.DTMOD:
      return "DTMOD";
    case DependencyEdge_Label.FOREIGN:
      return "FOREIGN";
    case DependencyEdge_Label.KW:
      return "KW";
    case DependencyEdge_Label.LIST:
      return "LIST";
    case DependencyEdge_Label.NOMC:
      return "NOMC";
    case DependencyEdge_Label.NOMCSUBJ:
      return "NOMCSUBJ";
    case DependencyEdge_Label.NOMCSUBJPASS:
      return "NOMCSUBJPASS";
    case DependencyEdge_Label.NUMC:
      return "NUMC";
    case DependencyEdge_Label.COP:
      return "COP";
    case DependencyEdge_Label.DISLOCATED:
      return "DISLOCATED";
    case DependencyEdge_Label.ASP:
      return "ASP";
    case DependencyEdge_Label.GMOD:
      return "GMOD";
    case DependencyEdge_Label.GOBJ:
      return "GOBJ";
    case DependencyEdge_Label.INFMOD:
      return "INFMOD";
    case DependencyEdge_Label.MES:
      return "MES";
    case DependencyEdge_Label.NCOMP:
      return "NCOMP";
    case DependencyEdge_Label.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Represents a mention for an entity in the text. Currently, proper noun
 * mentions are supported.
 */
export interface EntityMention {
  /** The mention text. */
  text:
    | TextSpan
    | undefined;
  /** The type of the entity mention. */
  type: EntityMention_Type;
  /**
   * For calls to [AnalyzeEntitySentiment][] or if
   * [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v1.AnnotateTextRequest.Features.extract_entity_sentiment]
   * is set to true, this field will contain the sentiment expressed for this
   * mention of the entity in the provided document.
   */
  sentiment: Sentiment | undefined;
}

/** The supported types of mentions. */
export enum EntityMention_Type {
  /** TYPE_UNKNOWN - Unknown */
  TYPE_UNKNOWN = 0,
  /** PROPER - Proper name */
  PROPER = 1,
  /** COMMON - Common noun (or noun compound) */
  COMMON = 2,
  UNRECOGNIZED = -1,
}

export function entityMention_TypeFromJSON(object: any): EntityMention_Type {
  switch (object) {
    case 0:
    case "TYPE_UNKNOWN":
      return EntityMention_Type.TYPE_UNKNOWN;
    case 1:
    case "PROPER":
      return EntityMention_Type.PROPER;
    case 2:
    case "COMMON":
      return EntityMention_Type.COMMON;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EntityMention_Type.UNRECOGNIZED;
  }
}

export function entityMention_TypeToJSON(object: EntityMention_Type): string {
  switch (object) {
    case EntityMention_Type.TYPE_UNKNOWN:
      return "TYPE_UNKNOWN";
    case EntityMention_Type.PROPER:
      return "PROPER";
    case EntityMention_Type.COMMON:
      return "COMMON";
    case EntityMention_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents an output piece of text. */
export interface TextSpan {
  /** The content of the output text. */
  content: string;
  /**
   * The API calculates the beginning offset of the content in the original
   * document according to the
   * [EncodingType][google.cloud.language.v1.EncodingType] specified in the API
   * request.
   */
  beginOffset: number;
}

/** Represents a category returned from the text classifier. */
export interface ClassificationCategory {
  /** The name of the category representing the document. */
  name: string;
  /**
   * The classifier's confidence of the category. Number represents how certain
   * the classifier is that this category represents the given text.
   */
  confidence: number;
}

/** Model options available for classification requests. */
export interface ClassificationModelOptions {
  /**
   * Setting this field will use the V1 model and V1 content categories
   * version. The V1 model is a legacy model; support for this will be
   * discontinued in the future.
   */
  v1Model?:
    | ClassificationModelOptions_V1Model
    | undefined;
  /**
   * Setting this field will use the V2 model with the appropriate content
   * categories version. The V2 model is a better performing model.
   */
  v2Model?: ClassificationModelOptions_V2Model | undefined;
}

/** Options for the V1 model. */
export interface ClassificationModelOptions_V1Model {
}

/** Options for the V2 model. */
export interface ClassificationModelOptions_V2Model {
  /** The content categories used for classification. */
  contentCategoriesVersion: ClassificationModelOptions_V2Model_ContentCategoriesVersion;
}

/** The content categories used for classification. */
export enum ClassificationModelOptions_V2Model_ContentCategoriesVersion {
  /**
   * CONTENT_CATEGORIES_VERSION_UNSPECIFIED - If `ContentCategoriesVersion` is not specified, this option will
   * default to `V1`.
   */
  CONTENT_CATEGORIES_VERSION_UNSPECIFIED = 0,
  /** V1 - Legacy content categories of our initial launch in 2017. */
  V1 = 1,
  /** V2 - Updated content categories in 2022. */
  V2 = 2,
  UNRECOGNIZED = -1,
}

export function classificationModelOptions_V2Model_ContentCategoriesVersionFromJSON(
  object: any,
): ClassificationModelOptions_V2Model_ContentCategoriesVersion {
  switch (object) {
    case 0:
    case "CONTENT_CATEGORIES_VERSION_UNSPECIFIED":
      return ClassificationModelOptions_V2Model_ContentCategoriesVersion.CONTENT_CATEGORIES_VERSION_UNSPECIFIED;
    case 1:
    case "V1":
      return ClassificationModelOptions_V2Model_ContentCategoriesVersion.V1;
    case 2:
    case "V2":
      return ClassificationModelOptions_V2Model_ContentCategoriesVersion.V2;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ClassificationModelOptions_V2Model_ContentCategoriesVersion.UNRECOGNIZED;
  }
}

export function classificationModelOptions_V2Model_ContentCategoriesVersionToJSON(
  object: ClassificationModelOptions_V2Model_ContentCategoriesVersion,
): string {
  switch (object) {
    case ClassificationModelOptions_V2Model_ContentCategoriesVersion.CONTENT_CATEGORIES_VERSION_UNSPECIFIED:
      return "CONTENT_CATEGORIES_VERSION_UNSPECIFIED";
    case ClassificationModelOptions_V2Model_ContentCategoriesVersion.V1:
      return "V1";
    case ClassificationModelOptions_V2Model_ContentCategoriesVersion.V2:
      return "V2";
    case ClassificationModelOptions_V2Model_ContentCategoriesVersion.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The sentiment analysis request message. */
export interface AnalyzeSentimentRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** The encoding type used by the API to calculate sentence offsets. */
  encodingType: EncodingType;
}

/** The sentiment analysis response message. */
export interface AnalyzeSentimentResponse {
  /** The overall sentiment of the input document. */
  documentSentiment:
    | Sentiment
    | undefined;
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][google.cloud.language.v1.Document.language] field
   * for more details.
   */
  language: string;
  /** The sentiment for all the sentences in the document. */
  sentences: Sentence[];
}

/** The entity-level sentiment analysis request message. */
export interface AnalyzeEntitySentimentRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** The encoding type used by the API to calculate offsets. */
  encodingType: EncodingType;
}

/** The entity-level sentiment analysis response message. */
export interface AnalyzeEntitySentimentResponse {
  /** The recognized entities in the input document with associated sentiments. */
  entities: Entity[];
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][google.cloud.language.v1.Document.language] field
   * for more details.
   */
  language: string;
}

/** The entity analysis request message. */
export interface AnalyzeEntitiesRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** The encoding type used by the API to calculate offsets. */
  encodingType: EncodingType;
}

/** The entity analysis response message. */
export interface AnalyzeEntitiesResponse {
  /** The recognized entities in the input document. */
  entities: Entity[];
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][google.cloud.language.v1.Document.language] field
   * for more details.
   */
  language: string;
}

/** The syntax analysis request message. */
export interface AnalyzeSyntaxRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** The encoding type used by the API to calculate offsets. */
  encodingType: EncodingType;
}

/** The syntax analysis response message. */
export interface AnalyzeSyntaxResponse {
  /** Sentences in the input document. */
  sentences: Sentence[];
  /** Tokens, along with their syntactic information, in the input document. */
  tokens: Token[];
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][google.cloud.language.v1.Document.language] field
   * for more details.
   */
  language: string;
}

/** The document classification request message. */
export interface ClassifyTextRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /**
   * Model options to use for classification. Defaults to v1 options if not
   * specified.
   */
  classificationModelOptions: ClassificationModelOptions | undefined;
}

/** The document classification response message. */
export interface ClassifyTextResponse {
  /** Categories representing the input document. */
  categories: ClassificationCategory[];
}

/** The document moderation request message. */
export interface ModerateTextRequest {
  /** Required. Input document. */
  document: Document | undefined;
}

/** The document moderation response message. */
export interface ModerateTextResponse {
  /** Harmful and sensitive categories representing the input document. */
  moderationCategories: ClassificationCategory[];
}

/**
 * The request message for the text annotation API, which can perform multiple
 * analysis types (sentiment, entities, and syntax) in one call.
 */
export interface AnnotateTextRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** Required. The enabled features. */
  features:
    | AnnotateTextRequest_Features
    | undefined;
  /** The encoding type used by the API to calculate offsets. */
  encodingType: EncodingType;
}

/**
 * All available features for sentiment, syntax, and semantic analysis.
 * Setting each one to true will enable that specific analysis for the input.
 */
export interface AnnotateTextRequest_Features {
  /** Extract syntax information. */
  extractSyntax: boolean;
  /** Extract entities. */
  extractEntities: boolean;
  /** Extract document-level sentiment. */
  extractDocumentSentiment: boolean;
  /** Extract entities and their associated sentiment. */
  extractEntitySentiment: boolean;
  /** Classify the full document into categories. */
  classifyText: boolean;
  /** Moderate the document for harmful and sensitive categories. */
  moderateText: boolean;
  /**
   * The model options to use for classification. Defaults to v1 options
   * if not specified. Only used if `classify_text` is set to true.
   */
  classificationModelOptions: ClassificationModelOptions | undefined;
}

/** The text annotations response message. */
export interface AnnotateTextResponse {
  /**
   * Sentences in the input document. Populated if the user enables
   * [AnnotateTextRequest.Features.extract_syntax][google.cloud.language.v1.AnnotateTextRequest.Features.extract_syntax].
   */
  sentences: Sentence[];
  /**
   * Tokens, along with their syntactic information, in the input document.
   * Populated if the user enables
   * [AnnotateTextRequest.Features.extract_syntax][google.cloud.language.v1.AnnotateTextRequest.Features.extract_syntax].
   */
  tokens: Token[];
  /**
   * Entities, along with their semantic information, in the input document.
   * Populated if the user enables
   * [AnnotateTextRequest.Features.extract_entities][google.cloud.language.v1.AnnotateTextRequest.Features.extract_entities].
   */
  entities: Entity[];
  /**
   * The overall sentiment for the document. Populated if the user enables
   * [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v1.AnnotateTextRequest.Features.extract_document_sentiment].
   */
  documentSentiment:
    | Sentiment
    | undefined;
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][google.cloud.language.v1.Document.language] field
   * for more details.
   */
  language: string;
  /** Categories identified in the input document. */
  categories: ClassificationCategory[];
  /** Harmful and sensitive categories identified in the input document. */
  moderationCategories: ClassificationCategory[];
}

function createBaseDocument(): Document {
  return { type: 0, content: undefined, gcsContentUri: undefined, language: "" };
}

export const Document: MessageFns<Document> = {
  encode(message: Document, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.content !== undefined) {
      writer.uint32(18).string(message.content);
    }
    if (message.gcsContentUri !== undefined) {
      writer.uint32(26).string(message.gcsContentUri);
    }
    if (message.language !== "") {
      writer.uint32(34).string(message.language);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Document {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDocument();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.content = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.gcsContentUri = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.language = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Document {
    return {
      type: isSet(object.type) ? document_TypeFromJSON(object.type) : 0,
      content: isSet(object.content) ? globalThis.String(object.content) : undefined,
      gcsContentUri: isSet(object.gcsContentUri) ? globalThis.String(object.gcsContentUri) : undefined,
      language: isSet(object.language) ? globalThis.String(object.language) : "",
    };
  },

  toJSON(message: Document): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = document_TypeToJSON(message.type);
    }
    if (message.content !== undefined) {
      obj.content = message.content;
    }
    if (message.gcsContentUri !== undefined) {
      obj.gcsContentUri = message.gcsContentUri;
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    return obj;
  },

  create(base?: DeepPartial<Document>): Document {
    return Document.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Document>): Document {
    const message = createBaseDocument();
    message.type = object.type ?? 0;
    message.content = object.content ?? undefined;
    message.gcsContentUri = object.gcsContentUri ?? undefined;
    message.language = object.language ?? "";
    return message;
  },
};

function createBaseSentence(): Sentence {
  return { text: undefined, sentiment: undefined };
}

export const Sentence: MessageFns<Sentence> = {
  encode(message: Sentence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      TextSpan.encode(message.text, writer.uint32(10).fork()).join();
    }
    if (message.sentiment !== undefined) {
      Sentiment.encode(message.sentiment, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Sentence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSentence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = TextSpan.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sentiment = Sentiment.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Sentence {
    return {
      text: isSet(object.text) ? TextSpan.fromJSON(object.text) : undefined,
      sentiment: isSet(object.sentiment) ? Sentiment.fromJSON(object.sentiment) : undefined,
    };
  },

  toJSON(message: Sentence): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = TextSpan.toJSON(message.text);
    }
    if (message.sentiment !== undefined) {
      obj.sentiment = Sentiment.toJSON(message.sentiment);
    }
    return obj;
  },

  create(base?: DeepPartial<Sentence>): Sentence {
    return Sentence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Sentence>): Sentence {
    const message = createBaseSentence();
    message.text = (object.text !== undefined && object.text !== null) ? TextSpan.fromPartial(object.text) : undefined;
    message.sentiment = (object.sentiment !== undefined && object.sentiment !== null)
      ? Sentiment.fromPartial(object.sentiment)
      : undefined;
    return message;
  },
};

function createBaseEntity(): Entity {
  return { name: "", type: 0, metadata: {}, salience: 0, mentions: [], sentiment: undefined };
}

export const Entity: MessageFns<Entity> = {
  encode(message: Entity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      Entity_MetadataEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.salience !== 0) {
      writer.uint32(37).float(message.salience);
    }
    for (const v of message.mentions) {
      EntityMention.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.sentiment !== undefined) {
      Sentiment.encode(message.sentiment, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = Entity_MetadataEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.metadata[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.salience = reader.float();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.mentions.push(EntityMention.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.sentiment = Sentiment.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? entity_TypeFromJSON(object.type) : 0,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      salience: isSet(object.salience) ? globalThis.Number(object.salience) : 0,
      mentions: globalThis.Array.isArray(object?.mentions)
        ? object.mentions.map((e: any) => EntityMention.fromJSON(e))
        : [],
      sentiment: isSet(object.sentiment) ? Sentiment.fromJSON(object.sentiment) : undefined,
    };
  },

  toJSON(message: Entity): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = entity_TypeToJSON(message.type);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    if (message.salience !== 0) {
      obj.salience = message.salience;
    }
    if (message.mentions?.length) {
      obj.mentions = message.mentions.map((e) => EntityMention.toJSON(e));
    }
    if (message.sentiment !== undefined) {
      obj.sentiment = Sentiment.toJSON(message.sentiment);
    }
    return obj;
  },

  create(base?: DeepPartial<Entity>): Entity {
    return Entity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity>): Entity {
    const message = createBaseEntity();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.salience = object.salience ?? 0;
    message.mentions = object.mentions?.map((e) => EntityMention.fromPartial(e)) || [];
    message.sentiment = (object.sentiment !== undefined && object.sentiment !== null)
      ? Sentiment.fromPartial(object.sentiment)
      : undefined;
    return message;
  },
};

function createBaseEntity_MetadataEntry(): Entity_MetadataEntry {
  return { key: "", value: "" };
}

export const Entity_MetadataEntry: MessageFns<Entity_MetadataEntry> = {
  encode(message: Entity_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Entity_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Entity_MetadataEntry>): Entity_MetadataEntry {
    return Entity_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity_MetadataEntry>): Entity_MetadataEntry {
    const message = createBaseEntity_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseToken(): Token {
  return { text: undefined, partOfSpeech: undefined, dependencyEdge: undefined, lemma: "" };
}

export const Token: MessageFns<Token> = {
  encode(message: Token, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      TextSpan.encode(message.text, writer.uint32(10).fork()).join();
    }
    if (message.partOfSpeech !== undefined) {
      PartOfSpeech.encode(message.partOfSpeech, writer.uint32(18).fork()).join();
    }
    if (message.dependencyEdge !== undefined) {
      DependencyEdge.encode(message.dependencyEdge, writer.uint32(26).fork()).join();
    }
    if (message.lemma !== "") {
      writer.uint32(34).string(message.lemma);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Token {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseToken();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = TextSpan.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partOfSpeech = PartOfSpeech.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.dependencyEdge = DependencyEdge.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lemma = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Token {
    return {
      text: isSet(object.text) ? TextSpan.fromJSON(object.text) : undefined,
      partOfSpeech: isSet(object.partOfSpeech) ? PartOfSpeech.fromJSON(object.partOfSpeech) : undefined,
      dependencyEdge: isSet(object.dependencyEdge) ? DependencyEdge.fromJSON(object.dependencyEdge) : undefined,
      lemma: isSet(object.lemma) ? globalThis.String(object.lemma) : "",
    };
  },

  toJSON(message: Token): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = TextSpan.toJSON(message.text);
    }
    if (message.partOfSpeech !== undefined) {
      obj.partOfSpeech = PartOfSpeech.toJSON(message.partOfSpeech);
    }
    if (message.dependencyEdge !== undefined) {
      obj.dependencyEdge = DependencyEdge.toJSON(message.dependencyEdge);
    }
    if (message.lemma !== "") {
      obj.lemma = message.lemma;
    }
    return obj;
  },

  create(base?: DeepPartial<Token>): Token {
    return Token.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Token>): Token {
    const message = createBaseToken();
    message.text = (object.text !== undefined && object.text !== null) ? TextSpan.fromPartial(object.text) : undefined;
    message.partOfSpeech = (object.partOfSpeech !== undefined && object.partOfSpeech !== null)
      ? PartOfSpeech.fromPartial(object.partOfSpeech)
      : undefined;
    message.dependencyEdge = (object.dependencyEdge !== undefined && object.dependencyEdge !== null)
      ? DependencyEdge.fromPartial(object.dependencyEdge)
      : undefined;
    message.lemma = object.lemma ?? "";
    return message;
  },
};

function createBaseSentiment(): Sentiment {
  return { magnitude: 0, score: 0 };
}

export const Sentiment: MessageFns<Sentiment> = {
  encode(message: Sentiment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.magnitude !== 0) {
      writer.uint32(21).float(message.magnitude);
    }
    if (message.score !== 0) {
      writer.uint32(29).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Sentiment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSentiment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 21) {
            break;
          }

          message.magnitude = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Sentiment {
    return {
      magnitude: isSet(object.magnitude) ? globalThis.Number(object.magnitude) : 0,
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
    };
  },

  toJSON(message: Sentiment): unknown {
    const obj: any = {};
    if (message.magnitude !== 0) {
      obj.magnitude = message.magnitude;
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    return obj;
  },

  create(base?: DeepPartial<Sentiment>): Sentiment {
    return Sentiment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Sentiment>): Sentiment {
    const message = createBaseSentiment();
    message.magnitude = object.magnitude ?? 0;
    message.score = object.score ?? 0;
    return message;
  },
};

function createBasePartOfSpeech(): PartOfSpeech {
  return {
    tag: 0,
    aspect: 0,
    case: 0,
    form: 0,
    gender: 0,
    mood: 0,
    number: 0,
    person: 0,
    proper: 0,
    reciprocity: 0,
    tense: 0,
    voice: 0,
  };
}

export const PartOfSpeech: MessageFns<PartOfSpeech> = {
  encode(message: PartOfSpeech, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tag !== 0) {
      writer.uint32(8).int32(message.tag);
    }
    if (message.aspect !== 0) {
      writer.uint32(16).int32(message.aspect);
    }
    if (message.case !== 0) {
      writer.uint32(24).int32(message.case);
    }
    if (message.form !== 0) {
      writer.uint32(32).int32(message.form);
    }
    if (message.gender !== 0) {
      writer.uint32(40).int32(message.gender);
    }
    if (message.mood !== 0) {
      writer.uint32(48).int32(message.mood);
    }
    if (message.number !== 0) {
      writer.uint32(56).int32(message.number);
    }
    if (message.person !== 0) {
      writer.uint32(64).int32(message.person);
    }
    if (message.proper !== 0) {
      writer.uint32(72).int32(message.proper);
    }
    if (message.reciprocity !== 0) {
      writer.uint32(80).int32(message.reciprocity);
    }
    if (message.tense !== 0) {
      writer.uint32(88).int32(message.tense);
    }
    if (message.voice !== 0) {
      writer.uint32(96).int32(message.voice);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PartOfSpeech {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartOfSpeech();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.tag = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.aspect = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.case = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.form = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.gender = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.mood = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.number = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.person = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.proper = reader.int32() as any;
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.reciprocity = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.tense = reader.int32() as any;
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.voice = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PartOfSpeech {
    return {
      tag: isSet(object.tag) ? partOfSpeech_TagFromJSON(object.tag) : 0,
      aspect: isSet(object.aspect) ? partOfSpeech_AspectFromJSON(object.aspect) : 0,
      case: isSet(object.case) ? partOfSpeech_CaseFromJSON(object.case) : 0,
      form: isSet(object.form) ? partOfSpeech_FormFromJSON(object.form) : 0,
      gender: isSet(object.gender) ? partOfSpeech_GenderFromJSON(object.gender) : 0,
      mood: isSet(object.mood) ? partOfSpeech_MoodFromJSON(object.mood) : 0,
      number: isSet(object.number) ? partOfSpeech_NumberFromJSON(object.number) : 0,
      person: isSet(object.person) ? partOfSpeech_PersonFromJSON(object.person) : 0,
      proper: isSet(object.proper) ? partOfSpeech_ProperFromJSON(object.proper) : 0,
      reciprocity: isSet(object.reciprocity) ? partOfSpeech_ReciprocityFromJSON(object.reciprocity) : 0,
      tense: isSet(object.tense) ? partOfSpeech_TenseFromJSON(object.tense) : 0,
      voice: isSet(object.voice) ? partOfSpeech_VoiceFromJSON(object.voice) : 0,
    };
  },

  toJSON(message: PartOfSpeech): unknown {
    const obj: any = {};
    if (message.tag !== 0) {
      obj.tag = partOfSpeech_TagToJSON(message.tag);
    }
    if (message.aspect !== 0) {
      obj.aspect = partOfSpeech_AspectToJSON(message.aspect);
    }
    if (message.case !== 0) {
      obj.case = partOfSpeech_CaseToJSON(message.case);
    }
    if (message.form !== 0) {
      obj.form = partOfSpeech_FormToJSON(message.form);
    }
    if (message.gender !== 0) {
      obj.gender = partOfSpeech_GenderToJSON(message.gender);
    }
    if (message.mood !== 0) {
      obj.mood = partOfSpeech_MoodToJSON(message.mood);
    }
    if (message.number !== 0) {
      obj.number = partOfSpeech_NumberToJSON(message.number);
    }
    if (message.person !== 0) {
      obj.person = partOfSpeech_PersonToJSON(message.person);
    }
    if (message.proper !== 0) {
      obj.proper = partOfSpeech_ProperToJSON(message.proper);
    }
    if (message.reciprocity !== 0) {
      obj.reciprocity = partOfSpeech_ReciprocityToJSON(message.reciprocity);
    }
    if (message.tense !== 0) {
      obj.tense = partOfSpeech_TenseToJSON(message.tense);
    }
    if (message.voice !== 0) {
      obj.voice = partOfSpeech_VoiceToJSON(message.voice);
    }
    return obj;
  },

  create(base?: DeepPartial<PartOfSpeech>): PartOfSpeech {
    return PartOfSpeech.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PartOfSpeech>): PartOfSpeech {
    const message = createBasePartOfSpeech();
    message.tag = object.tag ?? 0;
    message.aspect = object.aspect ?? 0;
    message.case = object.case ?? 0;
    message.form = object.form ?? 0;
    message.gender = object.gender ?? 0;
    message.mood = object.mood ?? 0;
    message.number = object.number ?? 0;
    message.person = object.person ?? 0;
    message.proper = object.proper ?? 0;
    message.reciprocity = object.reciprocity ?? 0;
    message.tense = object.tense ?? 0;
    message.voice = object.voice ?? 0;
    return message;
  },
};

function createBaseDependencyEdge(): DependencyEdge {
  return { headTokenIndex: 0, label: 0 };
}

export const DependencyEdge: MessageFns<DependencyEdge> = {
  encode(message: DependencyEdge, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.headTokenIndex !== 0) {
      writer.uint32(8).int32(message.headTokenIndex);
    }
    if (message.label !== 0) {
      writer.uint32(16).int32(message.label);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DependencyEdge {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDependencyEdge();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.headTokenIndex = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.label = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DependencyEdge {
    return {
      headTokenIndex: isSet(object.headTokenIndex) ? globalThis.Number(object.headTokenIndex) : 0,
      label: isSet(object.label) ? dependencyEdge_LabelFromJSON(object.label) : 0,
    };
  },

  toJSON(message: DependencyEdge): unknown {
    const obj: any = {};
    if (message.headTokenIndex !== 0) {
      obj.headTokenIndex = Math.round(message.headTokenIndex);
    }
    if (message.label !== 0) {
      obj.label = dependencyEdge_LabelToJSON(message.label);
    }
    return obj;
  },

  create(base?: DeepPartial<DependencyEdge>): DependencyEdge {
    return DependencyEdge.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DependencyEdge>): DependencyEdge {
    const message = createBaseDependencyEdge();
    message.headTokenIndex = object.headTokenIndex ?? 0;
    message.label = object.label ?? 0;
    return message;
  },
};

function createBaseEntityMention(): EntityMention {
  return { text: undefined, type: 0, sentiment: undefined };
}

export const EntityMention: MessageFns<EntityMention> = {
  encode(message: EntityMention, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      TextSpan.encode(message.text, writer.uint32(10).fork()).join();
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.sentiment !== undefined) {
      Sentiment.encode(message.sentiment, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EntityMention {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntityMention();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = TextSpan.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sentiment = Sentiment.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EntityMention {
    return {
      text: isSet(object.text) ? TextSpan.fromJSON(object.text) : undefined,
      type: isSet(object.type) ? entityMention_TypeFromJSON(object.type) : 0,
      sentiment: isSet(object.sentiment) ? Sentiment.fromJSON(object.sentiment) : undefined,
    };
  },

  toJSON(message: EntityMention): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = TextSpan.toJSON(message.text);
    }
    if (message.type !== 0) {
      obj.type = entityMention_TypeToJSON(message.type);
    }
    if (message.sentiment !== undefined) {
      obj.sentiment = Sentiment.toJSON(message.sentiment);
    }
    return obj;
  },

  create(base?: DeepPartial<EntityMention>): EntityMention {
    return EntityMention.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EntityMention>): EntityMention {
    const message = createBaseEntityMention();
    message.text = (object.text !== undefined && object.text !== null) ? TextSpan.fromPartial(object.text) : undefined;
    message.type = object.type ?? 0;
    message.sentiment = (object.sentiment !== undefined && object.sentiment !== null)
      ? Sentiment.fromPartial(object.sentiment)
      : undefined;
    return message;
  },
};

function createBaseTextSpan(): TextSpan {
  return { content: "", beginOffset: 0 };
}

export const TextSpan: MessageFns<TextSpan> = {
  encode(message: TextSpan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.content !== "") {
      writer.uint32(10).string(message.content);
    }
    if (message.beginOffset !== 0) {
      writer.uint32(16).int32(message.beginOffset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextSpan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextSpan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.content = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.beginOffset = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextSpan {
    return {
      content: isSet(object.content) ? globalThis.String(object.content) : "",
      beginOffset: isSet(object.beginOffset) ? globalThis.Number(object.beginOffset) : 0,
    };
  },

  toJSON(message: TextSpan): unknown {
    const obj: any = {};
    if (message.content !== "") {
      obj.content = message.content;
    }
    if (message.beginOffset !== 0) {
      obj.beginOffset = Math.round(message.beginOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<TextSpan>): TextSpan {
    return TextSpan.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextSpan>): TextSpan {
    const message = createBaseTextSpan();
    message.content = object.content ?? "";
    message.beginOffset = object.beginOffset ?? 0;
    return message;
  },
};

function createBaseClassificationCategory(): ClassificationCategory {
  return { name: "", confidence: 0 };
}

export const ClassificationCategory: MessageFns<ClassificationCategory> = {
  encode(message: ClassificationCategory, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassificationCategory {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassificationCategory();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassificationCategory {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: ClassificationCategory): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create(base?: DeepPartial<ClassificationCategory>): ClassificationCategory {
    return ClassificationCategory.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassificationCategory>): ClassificationCategory {
    const message = createBaseClassificationCategory();
    message.name = object.name ?? "";
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseClassificationModelOptions(): ClassificationModelOptions {
  return { v1Model: undefined, v2Model: undefined };
}

export const ClassificationModelOptions: MessageFns<ClassificationModelOptions> = {
  encode(message: ClassificationModelOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.v1Model !== undefined) {
      ClassificationModelOptions_V1Model.encode(message.v1Model, writer.uint32(10).fork()).join();
    }
    if (message.v2Model !== undefined) {
      ClassificationModelOptions_V2Model.encode(message.v2Model, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassificationModelOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassificationModelOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.v1Model = ClassificationModelOptions_V1Model.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.v2Model = ClassificationModelOptions_V2Model.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassificationModelOptions {
    return {
      v1Model: isSet(object.v1Model) ? ClassificationModelOptions_V1Model.fromJSON(object.v1Model) : undefined,
      v2Model: isSet(object.v2Model) ? ClassificationModelOptions_V2Model.fromJSON(object.v2Model) : undefined,
    };
  },

  toJSON(message: ClassificationModelOptions): unknown {
    const obj: any = {};
    if (message.v1Model !== undefined) {
      obj.v1Model = ClassificationModelOptions_V1Model.toJSON(message.v1Model);
    }
    if (message.v2Model !== undefined) {
      obj.v2Model = ClassificationModelOptions_V2Model.toJSON(message.v2Model);
    }
    return obj;
  },

  create(base?: DeepPartial<ClassificationModelOptions>): ClassificationModelOptions {
    return ClassificationModelOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassificationModelOptions>): ClassificationModelOptions {
    const message = createBaseClassificationModelOptions();
    message.v1Model = (object.v1Model !== undefined && object.v1Model !== null)
      ? ClassificationModelOptions_V1Model.fromPartial(object.v1Model)
      : undefined;
    message.v2Model = (object.v2Model !== undefined && object.v2Model !== null)
      ? ClassificationModelOptions_V2Model.fromPartial(object.v2Model)
      : undefined;
    return message;
  },
};

function createBaseClassificationModelOptions_V1Model(): ClassificationModelOptions_V1Model {
  return {};
}

export const ClassificationModelOptions_V1Model: MessageFns<ClassificationModelOptions_V1Model> = {
  encode(_: ClassificationModelOptions_V1Model, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassificationModelOptions_V1Model {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassificationModelOptions_V1Model();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ClassificationModelOptions_V1Model {
    return {};
  },

  toJSON(_: ClassificationModelOptions_V1Model): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ClassificationModelOptions_V1Model>): ClassificationModelOptions_V1Model {
    return ClassificationModelOptions_V1Model.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ClassificationModelOptions_V1Model>): ClassificationModelOptions_V1Model {
    const message = createBaseClassificationModelOptions_V1Model();
    return message;
  },
};

function createBaseClassificationModelOptions_V2Model(): ClassificationModelOptions_V2Model {
  return { contentCategoriesVersion: 0 };
}

export const ClassificationModelOptions_V2Model: MessageFns<ClassificationModelOptions_V2Model> = {
  encode(message: ClassificationModelOptions_V2Model, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.contentCategoriesVersion !== 0) {
      writer.uint32(8).int32(message.contentCategoriesVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassificationModelOptions_V2Model {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassificationModelOptions_V2Model();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.contentCategoriesVersion = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassificationModelOptions_V2Model {
    return {
      contentCategoriesVersion: isSet(object.contentCategoriesVersion)
        ? classificationModelOptions_V2Model_ContentCategoriesVersionFromJSON(object.contentCategoriesVersion)
        : 0,
    };
  },

  toJSON(message: ClassificationModelOptions_V2Model): unknown {
    const obj: any = {};
    if (message.contentCategoriesVersion !== 0) {
      obj.contentCategoriesVersion = classificationModelOptions_V2Model_ContentCategoriesVersionToJSON(
        message.contentCategoriesVersion,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<ClassificationModelOptions_V2Model>): ClassificationModelOptions_V2Model {
    return ClassificationModelOptions_V2Model.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassificationModelOptions_V2Model>): ClassificationModelOptions_V2Model {
    const message = createBaseClassificationModelOptions_V2Model();
    message.contentCategoriesVersion = object.contentCategoriesVersion ?? 0;
    return message;
  },
};

function createBaseAnalyzeSentimentRequest(): AnalyzeSentimentRequest {
  return { document: undefined, encodingType: 0 };
}

export const AnalyzeSentimentRequest: MessageFns<AnalyzeSentimentRequest> = {
  encode(message: AnalyzeSentimentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(16).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeSentimentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeSentimentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeSentimentRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnalyzeSentimentRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeSentimentRequest>): AnalyzeSentimentRequest {
    return AnalyzeSentimentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeSentimentRequest>): AnalyzeSentimentRequest {
    const message = createBaseAnalyzeSentimentRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnalyzeSentimentResponse(): AnalyzeSentimentResponse {
  return { documentSentiment: undefined, language: "", sentences: [] };
}

export const AnalyzeSentimentResponse: MessageFns<AnalyzeSentimentResponse> = {
  encode(message: AnalyzeSentimentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.documentSentiment !== undefined) {
      Sentiment.encode(message.documentSentiment, writer.uint32(10).fork()).join();
    }
    if (message.language !== "") {
      writer.uint32(18).string(message.language);
    }
    for (const v of message.sentences) {
      Sentence.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeSentimentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeSentimentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.documentSentiment = Sentiment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.language = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sentences.push(Sentence.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeSentimentResponse {
    return {
      documentSentiment: isSet(object.documentSentiment) ? Sentiment.fromJSON(object.documentSentiment) : undefined,
      language: isSet(object.language) ? globalThis.String(object.language) : "",
      sentences: globalThis.Array.isArray(object?.sentences)
        ? object.sentences.map((e: any) => Sentence.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeSentimentResponse): unknown {
    const obj: any = {};
    if (message.documentSentiment !== undefined) {
      obj.documentSentiment = Sentiment.toJSON(message.documentSentiment);
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    if (message.sentences?.length) {
      obj.sentences = message.sentences.map((e) => Sentence.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeSentimentResponse>): AnalyzeSentimentResponse {
    return AnalyzeSentimentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeSentimentResponse>): AnalyzeSentimentResponse {
    const message = createBaseAnalyzeSentimentResponse();
    message.documentSentiment = (object.documentSentiment !== undefined && object.documentSentiment !== null)
      ? Sentiment.fromPartial(object.documentSentiment)
      : undefined;
    message.language = object.language ?? "";
    message.sentences = object.sentences?.map((e) => Sentence.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnalyzeEntitySentimentRequest(): AnalyzeEntitySentimentRequest {
  return { document: undefined, encodingType: 0 };
}

export const AnalyzeEntitySentimentRequest: MessageFns<AnalyzeEntitySentimentRequest> = {
  encode(message: AnalyzeEntitySentimentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(16).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitySentimentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitySentimentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitySentimentRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnalyzeEntitySentimentRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeEntitySentimentRequest>): AnalyzeEntitySentimentRequest {
    return AnalyzeEntitySentimentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeEntitySentimentRequest>): AnalyzeEntitySentimentRequest {
    const message = createBaseAnalyzeEntitySentimentRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnalyzeEntitySentimentResponse(): AnalyzeEntitySentimentResponse {
  return { entities: [], language: "" };
}

export const AnalyzeEntitySentimentResponse: MessageFns<AnalyzeEntitySentimentResponse> = {
  encode(message: AnalyzeEntitySentimentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entities) {
      Entity.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.language !== "") {
      writer.uint32(18).string(message.language);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitySentimentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitySentimentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.language = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitySentimentResponse {
    return {
      entities: globalThis.Array.isArray(object?.entities) ? object.entities.map((e: any) => Entity.fromJSON(e)) : [],
      language: isSet(object.language) ? globalThis.String(object.language) : "",
    };
  },

  toJSON(message: AnalyzeEntitySentimentResponse): unknown {
    const obj: any = {};
    if (message.entities?.length) {
      obj.entities = message.entities.map((e) => Entity.toJSON(e));
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeEntitySentimentResponse>): AnalyzeEntitySentimentResponse {
    return AnalyzeEntitySentimentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeEntitySentimentResponse>): AnalyzeEntitySentimentResponse {
    const message = createBaseAnalyzeEntitySentimentResponse();
    message.entities = object.entities?.map((e) => Entity.fromPartial(e)) || [];
    message.language = object.language ?? "";
    return message;
  },
};

function createBaseAnalyzeEntitiesRequest(): AnalyzeEntitiesRequest {
  return { document: undefined, encodingType: 0 };
}

export const AnalyzeEntitiesRequest: MessageFns<AnalyzeEntitiesRequest> = {
  encode(message: AnalyzeEntitiesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(16).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitiesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitiesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitiesRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnalyzeEntitiesRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeEntitiesRequest>): AnalyzeEntitiesRequest {
    return AnalyzeEntitiesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeEntitiesRequest>): AnalyzeEntitiesRequest {
    const message = createBaseAnalyzeEntitiesRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnalyzeEntitiesResponse(): AnalyzeEntitiesResponse {
  return { entities: [], language: "" };
}

export const AnalyzeEntitiesResponse: MessageFns<AnalyzeEntitiesResponse> = {
  encode(message: AnalyzeEntitiesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entities) {
      Entity.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.language !== "") {
      writer.uint32(18).string(message.language);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitiesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitiesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.language = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitiesResponse {
    return {
      entities: globalThis.Array.isArray(object?.entities) ? object.entities.map((e: any) => Entity.fromJSON(e)) : [],
      language: isSet(object.language) ? globalThis.String(object.language) : "",
    };
  },

  toJSON(message: AnalyzeEntitiesResponse): unknown {
    const obj: any = {};
    if (message.entities?.length) {
      obj.entities = message.entities.map((e) => Entity.toJSON(e));
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeEntitiesResponse>): AnalyzeEntitiesResponse {
    return AnalyzeEntitiesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeEntitiesResponse>): AnalyzeEntitiesResponse {
    const message = createBaseAnalyzeEntitiesResponse();
    message.entities = object.entities?.map((e) => Entity.fromPartial(e)) || [];
    message.language = object.language ?? "";
    return message;
  },
};

function createBaseAnalyzeSyntaxRequest(): AnalyzeSyntaxRequest {
  return { document: undefined, encodingType: 0 };
}

export const AnalyzeSyntaxRequest: MessageFns<AnalyzeSyntaxRequest> = {
  encode(message: AnalyzeSyntaxRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(16).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeSyntaxRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeSyntaxRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeSyntaxRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnalyzeSyntaxRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeSyntaxRequest>): AnalyzeSyntaxRequest {
    return AnalyzeSyntaxRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeSyntaxRequest>): AnalyzeSyntaxRequest {
    const message = createBaseAnalyzeSyntaxRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnalyzeSyntaxResponse(): AnalyzeSyntaxResponse {
  return { sentences: [], tokens: [], language: "" };
}

export const AnalyzeSyntaxResponse: MessageFns<AnalyzeSyntaxResponse> = {
  encode(message: AnalyzeSyntaxResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sentences) {
      Sentence.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.tokens) {
      Token.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.language !== "") {
      writer.uint32(26).string(message.language);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeSyntaxResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeSyntaxResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sentences.push(Sentence.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tokens.push(Token.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.language = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeSyntaxResponse {
    return {
      sentences: globalThis.Array.isArray(object?.sentences)
        ? object.sentences.map((e: any) => Sentence.fromJSON(e))
        : [],
      tokens: globalThis.Array.isArray(object?.tokens) ? object.tokens.map((e: any) => Token.fromJSON(e)) : [],
      language: isSet(object.language) ? globalThis.String(object.language) : "",
    };
  },

  toJSON(message: AnalyzeSyntaxResponse): unknown {
    const obj: any = {};
    if (message.sentences?.length) {
      obj.sentences = message.sentences.map((e) => Sentence.toJSON(e));
    }
    if (message.tokens?.length) {
      obj.tokens = message.tokens.map((e) => Token.toJSON(e));
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeSyntaxResponse>): AnalyzeSyntaxResponse {
    return AnalyzeSyntaxResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeSyntaxResponse>): AnalyzeSyntaxResponse {
    const message = createBaseAnalyzeSyntaxResponse();
    message.sentences = object.sentences?.map((e) => Sentence.fromPartial(e)) || [];
    message.tokens = object.tokens?.map((e) => Token.fromPartial(e)) || [];
    message.language = object.language ?? "";
    return message;
  },
};

function createBaseClassifyTextRequest(): ClassifyTextRequest {
  return { document: undefined, classificationModelOptions: undefined };
}

export const ClassifyTextRequest: MessageFns<ClassifyTextRequest> = {
  encode(message: ClassifyTextRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.classificationModelOptions !== undefined) {
      ClassificationModelOptions.encode(message.classificationModelOptions, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassifyTextRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassifyTextRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.classificationModelOptions = ClassificationModelOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassifyTextRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      classificationModelOptions: isSet(object.classificationModelOptions)
        ? ClassificationModelOptions.fromJSON(object.classificationModelOptions)
        : undefined,
    };
  },

  toJSON(message: ClassifyTextRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.classificationModelOptions !== undefined) {
      obj.classificationModelOptions = ClassificationModelOptions.toJSON(message.classificationModelOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<ClassifyTextRequest>): ClassifyTextRequest {
    return ClassifyTextRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassifyTextRequest>): ClassifyTextRequest {
    const message = createBaseClassifyTextRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.classificationModelOptions =
      (object.classificationModelOptions !== undefined && object.classificationModelOptions !== null)
        ? ClassificationModelOptions.fromPartial(object.classificationModelOptions)
        : undefined;
    return message;
  },
};

function createBaseClassifyTextResponse(): ClassifyTextResponse {
  return { categories: [] };
}

export const ClassifyTextResponse: MessageFns<ClassifyTextResponse> = {
  encode(message: ClassifyTextResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.categories) {
      ClassificationCategory.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassifyTextResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassifyTextResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.categories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassifyTextResponse {
    return {
      categories: globalThis.Array.isArray(object?.categories)
        ? object.categories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ClassifyTextResponse): unknown {
    const obj: any = {};
    if (message.categories?.length) {
      obj.categories = message.categories.map((e) => ClassificationCategory.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ClassifyTextResponse>): ClassifyTextResponse {
    return ClassifyTextResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassifyTextResponse>): ClassifyTextResponse {
    const message = createBaseClassifyTextResponse();
    message.categories = object.categories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModerateTextRequest(): ModerateTextRequest {
  return { document: undefined };
}

export const ModerateTextRequest: MessageFns<ModerateTextRequest> = {
  encode(message: ModerateTextRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModerateTextRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModerateTextRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModerateTextRequest {
    return { document: isSet(object.document) ? Document.fromJSON(object.document) : undefined };
  },

  toJSON(message: ModerateTextRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    return obj;
  },

  create(base?: DeepPartial<ModerateTextRequest>): ModerateTextRequest {
    return ModerateTextRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModerateTextRequest>): ModerateTextRequest {
    const message = createBaseModerateTextRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    return message;
  },
};

function createBaseModerateTextResponse(): ModerateTextResponse {
  return { moderationCategories: [] };
}

export const ModerateTextResponse: MessageFns<ModerateTextResponse> = {
  encode(message: ModerateTextResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.moderationCategories) {
      ClassificationCategory.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModerateTextResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModerateTextResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.moderationCategories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModerateTextResponse {
    return {
      moderationCategories: globalThis.Array.isArray(object?.moderationCategories)
        ? object.moderationCategories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ModerateTextResponse): unknown {
    const obj: any = {};
    if (message.moderationCategories?.length) {
      obj.moderationCategories = message.moderationCategories.map((e) => ClassificationCategory.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ModerateTextResponse>): ModerateTextResponse {
    return ModerateTextResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModerateTextResponse>): ModerateTextResponse {
    const message = createBaseModerateTextResponse();
    message.moderationCategories = object.moderationCategories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAnnotateTextRequest(): AnnotateTextRequest {
  return { document: undefined, features: undefined, encodingType: 0 };
}

export const AnnotateTextRequest: MessageFns<AnnotateTextRequest> = {
  encode(message: AnnotateTextRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.features !== undefined) {
      AnnotateTextRequest_Features.encode(message.features, writer.uint32(18).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(24).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateTextRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateTextRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.features = AnnotateTextRequest_Features.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateTextRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      features: isSet(object.features) ? AnnotateTextRequest_Features.fromJSON(object.features) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnnotateTextRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.features !== undefined) {
      obj.features = AnnotateTextRequest_Features.toJSON(message.features);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateTextRequest>): AnnotateTextRequest {
    return AnnotateTextRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateTextRequest>): AnnotateTextRequest {
    const message = createBaseAnnotateTextRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.features = (object.features !== undefined && object.features !== null)
      ? AnnotateTextRequest_Features.fromPartial(object.features)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnnotateTextRequest_Features(): AnnotateTextRequest_Features {
  return {
    extractSyntax: false,
    extractEntities: false,
    extractDocumentSentiment: false,
    extractEntitySentiment: false,
    classifyText: false,
    moderateText: false,
    classificationModelOptions: undefined,
  };
}

export const AnnotateTextRequest_Features: MessageFns<AnnotateTextRequest_Features> = {
  encode(message: AnnotateTextRequest_Features, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.extractSyntax !== false) {
      writer.uint32(8).bool(message.extractSyntax);
    }
    if (message.extractEntities !== false) {
      writer.uint32(16).bool(message.extractEntities);
    }
    if (message.extractDocumentSentiment !== false) {
      writer.uint32(24).bool(message.extractDocumentSentiment);
    }
    if (message.extractEntitySentiment !== false) {
      writer.uint32(32).bool(message.extractEntitySentiment);
    }
    if (message.classifyText !== false) {
      writer.uint32(48).bool(message.classifyText);
    }
    if (message.moderateText !== false) {
      writer.uint32(88).bool(message.moderateText);
    }
    if (message.classificationModelOptions !== undefined) {
      ClassificationModelOptions.encode(message.classificationModelOptions, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateTextRequest_Features {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateTextRequest_Features();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.extractSyntax = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.extractEntities = reader.bool();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.extractDocumentSentiment = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.extractEntitySentiment = reader.bool();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.classifyText = reader.bool();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.moderateText = reader.bool();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.classificationModelOptions = ClassificationModelOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateTextRequest_Features {
    return {
      extractSyntax: isSet(object.extractSyntax) ? globalThis.Boolean(object.extractSyntax) : false,
      extractEntities: isSet(object.extractEntities) ? globalThis.Boolean(object.extractEntities) : false,
      extractDocumentSentiment: isSet(object.extractDocumentSentiment)
        ? globalThis.Boolean(object.extractDocumentSentiment)
        : false,
      extractEntitySentiment: isSet(object.extractEntitySentiment)
        ? globalThis.Boolean(object.extractEntitySentiment)
        : false,
      classifyText: isSet(object.classifyText) ? globalThis.Boolean(object.classifyText) : false,
      moderateText: isSet(object.moderateText) ? globalThis.Boolean(object.moderateText) : false,
      classificationModelOptions: isSet(object.classificationModelOptions)
        ? ClassificationModelOptions.fromJSON(object.classificationModelOptions)
        : undefined,
    };
  },

  toJSON(message: AnnotateTextRequest_Features): unknown {
    const obj: any = {};
    if (message.extractSyntax !== false) {
      obj.extractSyntax = message.extractSyntax;
    }
    if (message.extractEntities !== false) {
      obj.extractEntities = message.extractEntities;
    }
    if (message.extractDocumentSentiment !== false) {
      obj.extractDocumentSentiment = message.extractDocumentSentiment;
    }
    if (message.extractEntitySentiment !== false) {
      obj.extractEntitySentiment = message.extractEntitySentiment;
    }
    if (message.classifyText !== false) {
      obj.classifyText = message.classifyText;
    }
    if (message.moderateText !== false) {
      obj.moderateText = message.moderateText;
    }
    if (message.classificationModelOptions !== undefined) {
      obj.classificationModelOptions = ClassificationModelOptions.toJSON(message.classificationModelOptions);
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateTextRequest_Features>): AnnotateTextRequest_Features {
    return AnnotateTextRequest_Features.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateTextRequest_Features>): AnnotateTextRequest_Features {
    const message = createBaseAnnotateTextRequest_Features();
    message.extractSyntax = object.extractSyntax ?? false;
    message.extractEntities = object.extractEntities ?? false;
    message.extractDocumentSentiment = object.extractDocumentSentiment ?? false;
    message.extractEntitySentiment = object.extractEntitySentiment ?? false;
    message.classifyText = object.classifyText ?? false;
    message.moderateText = object.moderateText ?? false;
    message.classificationModelOptions =
      (object.classificationModelOptions !== undefined && object.classificationModelOptions !== null)
        ? ClassificationModelOptions.fromPartial(object.classificationModelOptions)
        : undefined;
    return message;
  },
};

function createBaseAnnotateTextResponse(): AnnotateTextResponse {
  return {
    sentences: [],
    tokens: [],
    entities: [],
    documentSentiment: undefined,
    language: "",
    categories: [],
    moderationCategories: [],
  };
}

export const AnnotateTextResponse: MessageFns<AnnotateTextResponse> = {
  encode(message: AnnotateTextResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sentences) {
      Sentence.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.tokens) {
      Token.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.entities) {
      Entity.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.documentSentiment !== undefined) {
      Sentiment.encode(message.documentSentiment, writer.uint32(34).fork()).join();
    }
    if (message.language !== "") {
      writer.uint32(42).string(message.language);
    }
    for (const v of message.categories) {
      ClassificationCategory.encode(v!, writer.uint32(50).fork()).join();
    }
    for (const v of message.moderationCategories) {
      ClassificationCategory.encode(v!, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateTextResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateTextResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sentences.push(Sentence.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tokens.push(Token.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.documentSentiment = Sentiment.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.language = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.categories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.moderationCategories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateTextResponse {
    return {
      sentences: globalThis.Array.isArray(object?.sentences)
        ? object.sentences.map((e: any) => Sentence.fromJSON(e))
        : [],
      tokens: globalThis.Array.isArray(object?.tokens) ? object.tokens.map((e: any) => Token.fromJSON(e)) : [],
      entities: globalThis.Array.isArray(object?.entities) ? object.entities.map((e: any) => Entity.fromJSON(e)) : [],
      documentSentiment: isSet(object.documentSentiment) ? Sentiment.fromJSON(object.documentSentiment) : undefined,
      language: isSet(object.language) ? globalThis.String(object.language) : "",
      categories: globalThis.Array.isArray(object?.categories)
        ? object.categories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
      moderationCategories: globalThis.Array.isArray(object?.moderationCategories)
        ? object.moderationCategories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnnotateTextResponse): unknown {
    const obj: any = {};
    if (message.sentences?.length) {
      obj.sentences = message.sentences.map((e) => Sentence.toJSON(e));
    }
    if (message.tokens?.length) {
      obj.tokens = message.tokens.map((e) => Token.toJSON(e));
    }
    if (message.entities?.length) {
      obj.entities = message.entities.map((e) => Entity.toJSON(e));
    }
    if (message.documentSentiment !== undefined) {
      obj.documentSentiment = Sentiment.toJSON(message.documentSentiment);
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    if (message.categories?.length) {
      obj.categories = message.categories.map((e) => ClassificationCategory.toJSON(e));
    }
    if (message.moderationCategories?.length) {
      obj.moderationCategories = message.moderationCategories.map((e) => ClassificationCategory.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateTextResponse>): AnnotateTextResponse {
    return AnnotateTextResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateTextResponse>): AnnotateTextResponse {
    const message = createBaseAnnotateTextResponse();
    message.sentences = object.sentences?.map((e) => Sentence.fromPartial(e)) || [];
    message.tokens = object.tokens?.map((e) => Token.fromPartial(e)) || [];
    message.entities = object.entities?.map((e) => Entity.fromPartial(e)) || [];
    message.documentSentiment = (object.documentSentiment !== undefined && object.documentSentiment !== null)
      ? Sentiment.fromPartial(object.documentSentiment)
      : undefined;
    message.language = object.language ?? "";
    message.categories = object.categories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    message.moderationCategories = object.moderationCategories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    return message;
  },
};

/**
 * Provides text analysis operations such as sentiment analysis and entity
 * recognition.
 */
export type LanguageServiceDefinition = typeof LanguageServiceDefinition;
export const LanguageServiceDefinition = {
  name: "LanguageService",
  fullName: "google.cloud.language.v1.LanguageService",
  methods: {
    /** Analyzes the sentiment of the provided text. */
    analyzeSentiment: {
      name: "AnalyzeSentiment",
      requestType: AnalyzeSentimentRequest,
      requestStream: false,
      responseType: AnalyzeSentimentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116]),
          ],
          578365826: [
            Buffer.from([
              35,
              58,
              1,
              42,
              34,
              30,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              83,
              101,
              110,
              116,
              105,
              109,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Finds named entities (currently proper names and common nouns) in the text
     * along with entity types, salience, mentions for each entity, and
     * other properties.
     */
    analyzeEntities: {
      name: "AnalyzeEntities",
      requestType: AnalyzeEntitiesRequest,
      requestStream: false,
      responseType: AnalyzeEntitiesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116]),
          ],
          578365826: [
            Buffer.from([
              34,
              58,
              1,
              42,
              34,
              29,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              69,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Finds entities, similar to
     * [AnalyzeEntities][google.cloud.language.v1.LanguageService.AnalyzeEntities]
     * in the text and analyzes sentiment associated with each entity and its
     * mentions.
     */
    analyzeEntitySentiment: {
      name: "AnalyzeEntitySentiment",
      requestType: AnalyzeEntitySentimentRequest,
      requestStream: false,
      responseType: AnalyzeEntitySentimentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116]),
          ],
          578365826: [
            Buffer.from([
              41,
              58,
              1,
              42,
              34,
              36,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              69,
              110,
              116,
              105,
              116,
              121,
              83,
              101,
              110,
              116,
              105,
              109,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Analyzes the syntax of the text and provides sentence boundaries and
     * tokenization along with part of speech tags, dependency trees, and other
     * properties.
     */
    analyzeSyntax: {
      name: "AnalyzeSyntax",
      requestType: AnalyzeSyntaxRequest,
      requestStream: false,
      responseType: AnalyzeSyntaxResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116]),
          ],
          578365826: [
            Buffer.from([
              32,
              58,
              1,
              42,
              34,
              27,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              83,
              121,
              110,
              116,
              97,
              120,
            ]),
          ],
        },
      },
    },
    /** Classifies a document into categories. */
    classifyText: {
      name: "ClassifyText",
      requestType: ClassifyTextRequest,
      requestStream: false,
      responseType: ClassifyTextResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116])],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              99,
              108,
              97,
              115,
              115,
              105,
              102,
              121,
              84,
              101,
              120,
              116,
            ]),
          ],
        },
      },
    },
    /** Moderates a document for harmful and sensitive categories. */
    moderateText: {
      name: "ModerateText",
      requestType: ModerateTextRequest,
      requestStream: false,
      responseType: ModerateTextResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116])],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              109,
              111,
              100,
              101,
              114,
              97,
              116,
              101,
              84,
              101,
              120,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * A convenience method that provides all the features that analyzeSentiment,
     * analyzeEntities, and analyzeSyntax provide in one call.
     */
    annotateText: {
      name: "AnnotateText",
      requestType: AnnotateTextRequest,
      requestStream: false,
      responseType: AnnotateTextResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              31,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([17, 100, 111, 99, 117, 109, 101, 110, 116, 44, 102, 101, 97, 116, 117, 114, 101, 115]),
          ],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              49,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              110,
              111,
              116,
              97,
              116,
              101,
              84,
              101,
              120,
              116,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface LanguageServiceImplementation<CallContextExt = {}> {
  /** Analyzes the sentiment of the provided text. */
  analyzeSentiment(
    request: AnalyzeSentimentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeSentimentResponse>>;
  /**
   * Finds named entities (currently proper names and common nouns) in the text
   * along with entity types, salience, mentions for each entity, and
   * other properties.
   */
  analyzeEntities(
    request: AnalyzeEntitiesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeEntitiesResponse>>;
  /**
   * Finds entities, similar to
   * [AnalyzeEntities][google.cloud.language.v1.LanguageService.AnalyzeEntities]
   * in the text and analyzes sentiment associated with each entity and its
   * mentions.
   */
  analyzeEntitySentiment(
    request: AnalyzeEntitySentimentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeEntitySentimentResponse>>;
  /**
   * Analyzes the syntax of the text and provides sentence boundaries and
   * tokenization along with part of speech tags, dependency trees, and other
   * properties.
   */
  analyzeSyntax(
    request: AnalyzeSyntaxRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeSyntaxResponse>>;
  /** Classifies a document into categories. */
  classifyText(
    request: ClassifyTextRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ClassifyTextResponse>>;
  /** Moderates a document for harmful and sensitive categories. */
  moderateText(
    request: ModerateTextRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ModerateTextResponse>>;
  /**
   * A convenience method that provides all the features that analyzeSentiment,
   * analyzeEntities, and analyzeSyntax provide in one call.
   */
  annotateText(
    request: AnnotateTextRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnnotateTextResponse>>;
}

export interface LanguageServiceClient<CallOptionsExt = {}> {
  /** Analyzes the sentiment of the provided text. */
  analyzeSentiment(
    request: DeepPartial<AnalyzeSentimentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeSentimentResponse>;
  /**
   * Finds named entities (currently proper names and common nouns) in the text
   * along with entity types, salience, mentions for each entity, and
   * other properties.
   */
  analyzeEntities(
    request: DeepPartial<AnalyzeEntitiesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeEntitiesResponse>;
  /**
   * Finds entities, similar to
   * [AnalyzeEntities][google.cloud.language.v1.LanguageService.AnalyzeEntities]
   * in the text and analyzes sentiment associated with each entity and its
   * mentions.
   */
  analyzeEntitySentiment(
    request: DeepPartial<AnalyzeEntitySentimentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeEntitySentimentResponse>;
  /**
   * Analyzes the syntax of the text and provides sentence boundaries and
   * tokenization along with part of speech tags, dependency trees, and other
   * properties.
   */
  analyzeSyntax(
    request: DeepPartial<AnalyzeSyntaxRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeSyntaxResponse>;
  /** Classifies a document into categories. */
  classifyText(
    request: DeepPartial<ClassifyTextRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ClassifyTextResponse>;
  /** Moderates a document for harmful and sensitive categories. */
  moderateText(
    request: DeepPartial<ModerateTextRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ModerateTextResponse>;
  /**
   * A convenience method that provides all the features that analyzeSentiment,
   * analyzeEntities, and analyzeSyntax provide in one call.
   */
  annotateText(
    request: DeepPartial<AnnotateTextRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnnotateTextResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
