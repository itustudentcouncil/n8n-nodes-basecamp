// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/language/v2/language_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";

export const protobufPackage = "google.cloud.language.v2";

/**
 * Represents the text encoding that the caller uses to process the output.
 * Providing an `EncodingType` is recommended because the API provides the
 * beginning offsets for various outputs, such as tokens and mentions, and
 * languages that natively use different text encodings may access offsets
 * differently.
 */
export enum EncodingType {
  /**
   * NONE - If `EncodingType` is not specified, encoding-dependent information (such as
   * `begin_offset`) will be set at `-1`.
   */
  NONE = 0,
  /**
   * UTF8 - Encoding-dependent information (such as `begin_offset`) is calculated based
   * on the UTF-8 encoding of the input. C++ and Go are examples of languages
   * that use this encoding natively.
   */
  UTF8 = 1,
  /**
   * UTF16 - Encoding-dependent information (such as `begin_offset`) is calculated based
   * on the UTF-16 encoding of the input. Java and JavaScript are examples of
   * languages that use this encoding natively.
   */
  UTF16 = 2,
  /**
   * UTF32 - Encoding-dependent information (such as `begin_offset`) is calculated based
   * on the UTF-32 encoding of the input. Python is an example of a language
   * that uses this encoding natively.
   */
  UTF32 = 3,
  UNRECOGNIZED = -1,
}

export function encodingTypeFromJSON(object: any): EncodingType {
  switch (object) {
    case 0:
    case "NONE":
      return EncodingType.NONE;
    case 1:
    case "UTF8":
      return EncodingType.UTF8;
    case 2:
    case "UTF16":
      return EncodingType.UTF16;
    case 3:
    case "UTF32":
      return EncodingType.UTF32;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EncodingType.UNRECOGNIZED;
  }
}

export function encodingTypeToJSON(object: EncodingType): string {
  switch (object) {
    case EncodingType.NONE:
      return "NONE";
    case EncodingType.UTF8:
      return "UTF8";
    case EncodingType.UTF16:
      return "UTF16";
    case EncodingType.UTF32:
      return "UTF32";
    case EncodingType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the input to API methods. */
export interface Document {
  /**
   * Required. If the type is not set or is `TYPE_UNSPECIFIED`,
   * returns an `INVALID_ARGUMENT` error.
   */
  type: Document_Type;
  /**
   * The content of the input in string format.
   * Cloud audit logging exempt since it is based on user data.
   */
  content?:
    | string
    | undefined;
  /**
   * The Google Cloud Storage URI where the file content is located.
   * This URI must be of the form: gs://bucket_name/object_name. For more
   * details, see https://cloud.google.com/storage/docs/reference-uris.
   * NOTE: Cloud Storage object versioning is not supported.
   */
  gcsContentUri?:
    | string
    | undefined;
  /**
   * Optional. The language of the document (if not specified, the language is
   * automatically detected). Both ISO and BCP-47 language codes are
   * accepted.<br>
   * [Language
   * Support](https://cloud.google.com/natural-language/docs/languages) lists
   * currently supported languages for each API method. If the language (either
   * specified by the caller or automatically detected) is not supported by the
   * called API method, an `INVALID_ARGUMENT` error is returned.
   */
  languageCode: string;
}

/** The document types enum. */
export enum Document_Type {
  /** TYPE_UNSPECIFIED - The content type is not specified. */
  TYPE_UNSPECIFIED = 0,
  /** PLAIN_TEXT - Plain text */
  PLAIN_TEXT = 1,
  /** HTML - HTML */
  HTML = 2,
  UNRECOGNIZED = -1,
}

export function document_TypeFromJSON(object: any): Document_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Document_Type.TYPE_UNSPECIFIED;
    case 1:
    case "PLAIN_TEXT":
      return Document_Type.PLAIN_TEXT;
    case 2:
    case "HTML":
      return Document_Type.HTML;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Document_Type.UNRECOGNIZED;
  }
}

export function document_TypeToJSON(object: Document_Type): string {
  switch (object) {
    case Document_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Document_Type.PLAIN_TEXT:
      return "PLAIN_TEXT";
    case Document_Type.HTML:
      return "HTML";
    case Document_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents a sentence in the input document. */
export interface Sentence {
  /** The sentence text. */
  text:
    | TextSpan
    | undefined;
  /**
   * For calls to [AnalyzeSentiment][] or if
   * [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_document_sentiment]
   * is set to true, this field will contain the sentiment for the sentence.
   */
  sentiment: Sentiment | undefined;
}

/**
 * Represents a phrase in the text that is a known entity, such as
 * a person, an organization, or location. The API associates information, such
 * as probability and mentions, with entities.
 */
export interface Entity {
  /** The representative name for the entity. */
  name: string;
  /** The entity type. */
  type: Entity_Type;
  /**
   * Metadata associated with the entity.
   *
   * For the metadata
   * associated with other entity types, see the Type table below.
   */
  metadata: { [key: string]: string };
  /**
   * The mentions of this entity in the input document. The API currently
   * supports proper noun mentions.
   */
  mentions: EntityMention[];
  /**
   * For calls to [AnalyzeEntitySentiment][] or if
   * [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entity_sentiment]
   * is set to true, this field will contain the aggregate sentiment expressed
   * for this entity in the provided document.
   */
  sentiment: Sentiment | undefined;
}

/**
 * The type of the entity. The table
 * below lists the associated fields for entities that have different
 * metadata.
 */
export enum Entity_Type {
  /** UNKNOWN - Unknown */
  UNKNOWN = 0,
  /** PERSON - Person */
  PERSON = 1,
  /** LOCATION - Location */
  LOCATION = 2,
  /** ORGANIZATION - Organization */
  ORGANIZATION = 3,
  /** EVENT - Event */
  EVENT = 4,
  /** WORK_OF_ART - Artwork */
  WORK_OF_ART = 5,
  /** CONSUMER_GOOD - Consumer product */
  CONSUMER_GOOD = 6,
  /** OTHER - Other types of entities */
  OTHER = 7,
  /**
   * PHONE_NUMBER - Phone number
   *
   * The metadata lists the phone number, formatted according to local
   * convention, plus whichever additional elements appear in the text:
   *
   * * `number` - the actual number, broken down into sections as per local
   * convention
   * * `national_prefix` - country code, if detected
   * * `area_code` - region or area code, if detected
   * * `extension` - phone extension (to be dialed after connection), if
   * detected
   */
  PHONE_NUMBER = 9,
  /**
   * ADDRESS - Address
   *
   * The metadata identifies the street number and locality plus whichever
   * additional elements appear in the text:
   *
   * * `street_number` - street number
   * * `locality` - city or town
   * * `street_name` - street/route name, if detected
   * * `postal_code` - postal code, if detected
   * * `country` - country, if detected
   * * `broad_region` - administrative area, such as the state, if detected
   * * `narrow_region` - smaller administrative area, such as county, if
   * detected
   * * `sublocality` - used in Asian addresses to demark a district within a
   * city, if detected
   */
  ADDRESS = 10,
  /**
   * DATE - Date
   *
   * The metadata identifies the components of the date:
   *
   * * `year` - four digit year, if detected
   * * `month` - two digit month number, if detected
   * * `day` - two digit day number, if detected
   */
  DATE = 11,
  /**
   * NUMBER - Number
   *
   * The metadata is the number itself.
   */
  NUMBER = 12,
  /**
   * PRICE - Price
   *
   * The metadata identifies the `value` and `currency`.
   */
  PRICE = 13,
  UNRECOGNIZED = -1,
}

export function entity_TypeFromJSON(object: any): Entity_Type {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return Entity_Type.UNKNOWN;
    case 1:
    case "PERSON":
      return Entity_Type.PERSON;
    case 2:
    case "LOCATION":
      return Entity_Type.LOCATION;
    case 3:
    case "ORGANIZATION":
      return Entity_Type.ORGANIZATION;
    case 4:
    case "EVENT":
      return Entity_Type.EVENT;
    case 5:
    case "WORK_OF_ART":
      return Entity_Type.WORK_OF_ART;
    case 6:
    case "CONSUMER_GOOD":
      return Entity_Type.CONSUMER_GOOD;
    case 7:
    case "OTHER":
      return Entity_Type.OTHER;
    case 9:
    case "PHONE_NUMBER":
      return Entity_Type.PHONE_NUMBER;
    case 10:
    case "ADDRESS":
      return Entity_Type.ADDRESS;
    case 11:
    case "DATE":
      return Entity_Type.DATE;
    case 12:
    case "NUMBER":
      return Entity_Type.NUMBER;
    case 13:
    case "PRICE":
      return Entity_Type.PRICE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Entity_Type.UNRECOGNIZED;
  }
}

export function entity_TypeToJSON(object: Entity_Type): string {
  switch (object) {
    case Entity_Type.UNKNOWN:
      return "UNKNOWN";
    case Entity_Type.PERSON:
      return "PERSON";
    case Entity_Type.LOCATION:
      return "LOCATION";
    case Entity_Type.ORGANIZATION:
      return "ORGANIZATION";
    case Entity_Type.EVENT:
      return "EVENT";
    case Entity_Type.WORK_OF_ART:
      return "WORK_OF_ART";
    case Entity_Type.CONSUMER_GOOD:
      return "CONSUMER_GOOD";
    case Entity_Type.OTHER:
      return "OTHER";
    case Entity_Type.PHONE_NUMBER:
      return "PHONE_NUMBER";
    case Entity_Type.ADDRESS:
      return "ADDRESS";
    case Entity_Type.DATE:
      return "DATE";
    case Entity_Type.NUMBER:
      return "NUMBER";
    case Entity_Type.PRICE:
      return "PRICE";
    case Entity_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Entity_MetadataEntry {
  key: string;
  value: string;
}

/**
 * Represents the feeling associated with the entire text or entities in
 * the text.
 */
export interface Sentiment {
  /**
   * A non-negative number in the [0, +inf) range, which represents
   * the absolute magnitude of sentiment regardless of score (positive or
   * negative).
   */
  magnitude: number;
  /**
   * Sentiment score between -1.0 (negative sentiment) and 1.0
   * (positive sentiment).
   */
  score: number;
}

/**
 * Represents a mention for an entity in the text. Currently, proper noun
 * mentions are supported.
 */
export interface EntityMention {
  /** The mention text. */
  text:
    | TextSpan
    | undefined;
  /** The type of the entity mention. */
  type: EntityMention_Type;
  /**
   * For calls to [AnalyzeEntitySentiment][] or if
   * [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entity_sentiment]
   * is set to true, this field will contain the sentiment expressed for this
   * mention of the entity in the provided document.
   */
  sentiment:
    | Sentiment
    | undefined;
  /**
   * Probability score associated with the entity.
   *
   * The score shows the probability of the entity mention being the entity
   * type. The score is in (0, 1] range.
   */
  probability: number;
}

/** The supported types of mentions. */
export enum EntityMention_Type {
  /** TYPE_UNKNOWN - Unknown */
  TYPE_UNKNOWN = 0,
  /** PROPER - Proper name */
  PROPER = 1,
  /** COMMON - Common noun (or noun compound) */
  COMMON = 2,
  UNRECOGNIZED = -1,
}

export function entityMention_TypeFromJSON(object: any): EntityMention_Type {
  switch (object) {
    case 0:
    case "TYPE_UNKNOWN":
      return EntityMention_Type.TYPE_UNKNOWN;
    case 1:
    case "PROPER":
      return EntityMention_Type.PROPER;
    case 2:
    case "COMMON":
      return EntityMention_Type.COMMON;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EntityMention_Type.UNRECOGNIZED;
  }
}

export function entityMention_TypeToJSON(object: EntityMention_Type): string {
  switch (object) {
    case EntityMention_Type.TYPE_UNKNOWN:
      return "TYPE_UNKNOWN";
    case EntityMention_Type.PROPER:
      return "PROPER";
    case EntityMention_Type.COMMON:
      return "COMMON";
    case EntityMention_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents a text span in the input document. */
export interface TextSpan {
  /** The content of the text span, which is a substring of the document. */
  content: string;
  /**
   * The API calculates the beginning offset of the content in the original
   * document according to the
   * [EncodingType][google.cloud.language.v2.EncodingType] specified in the API
   * request.
   */
  beginOffset: number;
}

/** Represents a category returned from the text classifier. */
export interface ClassificationCategory {
  /** The name of the category representing the document. */
  name: string;
  /**
   * The classifier's confidence of the category. Number represents how certain
   * the classifier is that this category represents the given text.
   */
  confidence: number;
  /**
   * Optional. The classifier's severity of the category. This is only present
   * when the ModerateTextRequest.ModelVersion is set to MODEL_VERSION_2, and
   * the corresponding category has a severity score.
   */
  severity: number;
}

/** The sentiment analysis request message. */
export interface AnalyzeSentimentRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** The encoding type used by the API to calculate sentence offsets. */
  encodingType: EncodingType;
}

/** The sentiment analysis response message. */
export interface AnalyzeSentimentResponse {
  /** The overall sentiment of the input document. */
  documentSentiment:
    | Sentiment
    | undefined;
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][] field for more details.
   */
  languageCode: string;
  /** The sentiment for all the sentences in the document. */
  sentences: Sentence[];
  /**
   * Whether the language is officially supported. The API may still return a
   * response when the language is not supported, but it is on a best effort
   * basis.
   */
  languageSupported: boolean;
}

/** The entity analysis request message. */
export interface AnalyzeEntitiesRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** The encoding type used by the API to calculate offsets. */
  encodingType: EncodingType;
}

/** The entity analysis response message. */
export interface AnalyzeEntitiesResponse {
  /** The recognized entities in the input document. */
  entities: Entity[];
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][] field for more details.
   */
  languageCode: string;
  /**
   * Whether the language is officially supported. The API may still return a
   * response when the language is not supported, but it is on a best effort
   * basis.
   */
  languageSupported: boolean;
}

/** The document classification request message. */
export interface ClassifyTextRequest {
  /** Required. Input document. */
  document: Document | undefined;
}

/** The document classification response message. */
export interface ClassifyTextResponse {
  /** Categories representing the input document. */
  categories: ClassificationCategory[];
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][] field for more details.
   */
  languageCode: string;
  /**
   * Whether the language is officially supported. The API may still return a
   * response when the language is not supported, but it is on a best effort
   * basis.
   */
  languageSupported: boolean;
}

/** The document moderation request message. */
export interface ModerateTextRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** Optional. The model version to use for ModerateText. */
  modelVersion: ModerateTextRequest_ModelVersion;
}

/** The model version to use for ModerateText. */
export enum ModerateTextRequest_ModelVersion {
  /** MODEL_VERSION_UNSPECIFIED - The default model version. */
  MODEL_VERSION_UNSPECIFIED = 0,
  /**
   * MODEL_VERSION_1 - Use the v1 model, this model is used by default when not provided.
   * The v1 model only returns probability (confidence) score for each
   * category.
   */
  MODEL_VERSION_1 = 1,
  /**
   * MODEL_VERSION_2 - Use the v2 model.
   * The v2 model only returns probability (confidence) score for each
   * category, and returns severity score for a subset of the categories.
   */
  MODEL_VERSION_2 = 2,
  UNRECOGNIZED = -1,
}

export function moderateTextRequest_ModelVersionFromJSON(object: any): ModerateTextRequest_ModelVersion {
  switch (object) {
    case 0:
    case "MODEL_VERSION_UNSPECIFIED":
      return ModerateTextRequest_ModelVersion.MODEL_VERSION_UNSPECIFIED;
    case 1:
    case "MODEL_VERSION_1":
      return ModerateTextRequest_ModelVersion.MODEL_VERSION_1;
    case 2:
    case "MODEL_VERSION_2":
      return ModerateTextRequest_ModelVersion.MODEL_VERSION_2;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ModerateTextRequest_ModelVersion.UNRECOGNIZED;
  }
}

export function moderateTextRequest_ModelVersionToJSON(object: ModerateTextRequest_ModelVersion): string {
  switch (object) {
    case ModerateTextRequest_ModelVersion.MODEL_VERSION_UNSPECIFIED:
      return "MODEL_VERSION_UNSPECIFIED";
    case ModerateTextRequest_ModelVersion.MODEL_VERSION_1:
      return "MODEL_VERSION_1";
    case ModerateTextRequest_ModelVersion.MODEL_VERSION_2:
      return "MODEL_VERSION_2";
    case ModerateTextRequest_ModelVersion.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The document moderation response message. */
export interface ModerateTextResponse {
  /** Harmful and sensitive categories representing the input document. */
  moderationCategories: ClassificationCategory[];
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][] field for more details.
   */
  languageCode: string;
  /**
   * Whether the language is officially supported. The API may still return a
   * response when the language is not supported, but it is on a best effort
   * basis.
   */
  languageSupported: boolean;
}

/**
 * The request message for the text annotation API, which can perform multiple
 * analysis types in one call.
 */
export interface AnnotateTextRequest {
  /** Required. Input document. */
  document:
    | Document
    | undefined;
  /** Required. The enabled features. */
  features:
    | AnnotateTextRequest_Features
    | undefined;
  /** The encoding type used by the API to calculate offsets. */
  encodingType: EncodingType;
}

/**
 * All available features.
 * Setting each one to true will enable that specific analysis for the input.
 */
export interface AnnotateTextRequest_Features {
  /** Optional. Extract entities. */
  extractEntities: boolean;
  /** Optional. Extract document-level sentiment. */
  extractDocumentSentiment: boolean;
  /** Optional. Classify the full document into categories. */
  classifyText: boolean;
  /** Optional. Moderate the document for harmful and sensitive categories. */
  moderateText: boolean;
}

/** The text annotations response message. */
export interface AnnotateTextResponse {
  /**
   * Sentences in the input document. Populated if the user enables
   * [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_document_sentiment].
   */
  sentences: Sentence[];
  /**
   * Entities, along with their semantic information, in the input document.
   * Populated if the user enables
   * [AnnotateTextRequest.Features.extract_entities][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entities]
   * or
   * [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entity_sentiment].
   */
  entities: Entity[];
  /**
   * The overall sentiment for the document. Populated if the user enables
   * [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_document_sentiment].
   */
  documentSentiment:
    | Sentiment
    | undefined;
  /**
   * The language of the text, which will be the same as the language specified
   * in the request or, if not specified, the automatically-detected language.
   * See [Document.language][] field for more details.
   */
  languageCode: string;
  /** Categories identified in the input document. */
  categories: ClassificationCategory[];
  /** Harmful and sensitive categories identified in the input document. */
  moderationCategories: ClassificationCategory[];
  /**
   * Whether the language is officially supported by all requested features.
   * The API may still return a response when the language is not supported, but
   * it is on a best effort basis.
   */
  languageSupported: boolean;
}

function createBaseDocument(): Document {
  return { type: 0, content: undefined, gcsContentUri: undefined, languageCode: "" };
}

export const Document: MessageFns<Document> = {
  encode(message: Document, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.content !== undefined) {
      writer.uint32(18).string(message.content);
    }
    if (message.gcsContentUri !== undefined) {
      writer.uint32(26).string(message.gcsContentUri);
    }
    if (message.languageCode !== "") {
      writer.uint32(34).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Document {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDocument();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.content = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.gcsContentUri = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Document {
    return {
      type: isSet(object.type) ? document_TypeFromJSON(object.type) : 0,
      content: isSet(object.content) ? globalThis.String(object.content) : undefined,
      gcsContentUri: isSet(object.gcsContentUri) ? globalThis.String(object.gcsContentUri) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: Document): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = document_TypeToJSON(message.type);
    }
    if (message.content !== undefined) {
      obj.content = message.content;
    }
    if (message.gcsContentUri !== undefined) {
      obj.gcsContentUri = message.gcsContentUri;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<Document>): Document {
    return Document.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Document>): Document {
    const message = createBaseDocument();
    message.type = object.type ?? 0;
    message.content = object.content ?? undefined;
    message.gcsContentUri = object.gcsContentUri ?? undefined;
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseSentence(): Sentence {
  return { text: undefined, sentiment: undefined };
}

export const Sentence: MessageFns<Sentence> = {
  encode(message: Sentence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      TextSpan.encode(message.text, writer.uint32(10).fork()).join();
    }
    if (message.sentiment !== undefined) {
      Sentiment.encode(message.sentiment, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Sentence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSentence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = TextSpan.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sentiment = Sentiment.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Sentence {
    return {
      text: isSet(object.text) ? TextSpan.fromJSON(object.text) : undefined,
      sentiment: isSet(object.sentiment) ? Sentiment.fromJSON(object.sentiment) : undefined,
    };
  },

  toJSON(message: Sentence): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = TextSpan.toJSON(message.text);
    }
    if (message.sentiment !== undefined) {
      obj.sentiment = Sentiment.toJSON(message.sentiment);
    }
    return obj;
  },

  create(base?: DeepPartial<Sentence>): Sentence {
    return Sentence.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Sentence>): Sentence {
    const message = createBaseSentence();
    message.text = (object.text !== undefined && object.text !== null) ? TextSpan.fromPartial(object.text) : undefined;
    message.sentiment = (object.sentiment !== undefined && object.sentiment !== null)
      ? Sentiment.fromPartial(object.sentiment)
      : undefined;
    return message;
  },
};

function createBaseEntity(): Entity {
  return { name: "", type: 0, metadata: {}, mentions: [], sentiment: undefined };
}

export const Entity: MessageFns<Entity> = {
  encode(message: Entity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      Entity_MetadataEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    for (const v of message.mentions) {
      EntityMention.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.sentiment !== undefined) {
      Sentiment.encode(message.sentiment, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = Entity_MetadataEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.metadata[entry3.key] = entry3.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.mentions.push(EntityMention.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.sentiment = Sentiment.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? entity_TypeFromJSON(object.type) : 0,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      mentions: globalThis.Array.isArray(object?.mentions)
        ? object.mentions.map((e: any) => EntityMention.fromJSON(e))
        : [],
      sentiment: isSet(object.sentiment) ? Sentiment.fromJSON(object.sentiment) : undefined,
    };
  },

  toJSON(message: Entity): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = entity_TypeToJSON(message.type);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    if (message.mentions?.length) {
      obj.mentions = message.mentions.map((e) => EntityMention.toJSON(e));
    }
    if (message.sentiment !== undefined) {
      obj.sentiment = Sentiment.toJSON(message.sentiment);
    }
    return obj;
  },

  create(base?: DeepPartial<Entity>): Entity {
    return Entity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity>): Entity {
    const message = createBaseEntity();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.mentions = object.mentions?.map((e) => EntityMention.fromPartial(e)) || [];
    message.sentiment = (object.sentiment !== undefined && object.sentiment !== null)
      ? Sentiment.fromPartial(object.sentiment)
      : undefined;
    return message;
  },
};

function createBaseEntity_MetadataEntry(): Entity_MetadataEntry {
  return { key: "", value: "" };
}

export const Entity_MetadataEntry: MessageFns<Entity_MetadataEntry> = {
  encode(message: Entity_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Entity_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Entity_MetadataEntry>): Entity_MetadataEntry {
    return Entity_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity_MetadataEntry>): Entity_MetadataEntry {
    const message = createBaseEntity_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSentiment(): Sentiment {
  return { magnitude: 0, score: 0 };
}

export const Sentiment: MessageFns<Sentiment> = {
  encode(message: Sentiment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.magnitude !== 0) {
      writer.uint32(13).float(message.magnitude);
    }
    if (message.score !== 0) {
      writer.uint32(21).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Sentiment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSentiment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.magnitude = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Sentiment {
    return {
      magnitude: isSet(object.magnitude) ? globalThis.Number(object.magnitude) : 0,
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
    };
  },

  toJSON(message: Sentiment): unknown {
    const obj: any = {};
    if (message.magnitude !== 0) {
      obj.magnitude = message.magnitude;
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    return obj;
  },

  create(base?: DeepPartial<Sentiment>): Sentiment {
    return Sentiment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Sentiment>): Sentiment {
    const message = createBaseSentiment();
    message.magnitude = object.magnitude ?? 0;
    message.score = object.score ?? 0;
    return message;
  },
};

function createBaseEntityMention(): EntityMention {
  return { text: undefined, type: 0, sentiment: undefined, probability: 0 };
}

export const EntityMention: MessageFns<EntityMention> = {
  encode(message: EntityMention, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== undefined) {
      TextSpan.encode(message.text, writer.uint32(10).fork()).join();
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.sentiment !== undefined) {
      Sentiment.encode(message.sentiment, writer.uint32(26).fork()).join();
    }
    if (message.probability !== 0) {
      writer.uint32(37).float(message.probability);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EntityMention {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntityMention();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = TextSpan.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sentiment = Sentiment.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.probability = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EntityMention {
    return {
      text: isSet(object.text) ? TextSpan.fromJSON(object.text) : undefined,
      type: isSet(object.type) ? entityMention_TypeFromJSON(object.type) : 0,
      sentiment: isSet(object.sentiment) ? Sentiment.fromJSON(object.sentiment) : undefined,
      probability: isSet(object.probability) ? globalThis.Number(object.probability) : 0,
    };
  },

  toJSON(message: EntityMention): unknown {
    const obj: any = {};
    if (message.text !== undefined) {
      obj.text = TextSpan.toJSON(message.text);
    }
    if (message.type !== 0) {
      obj.type = entityMention_TypeToJSON(message.type);
    }
    if (message.sentiment !== undefined) {
      obj.sentiment = Sentiment.toJSON(message.sentiment);
    }
    if (message.probability !== 0) {
      obj.probability = message.probability;
    }
    return obj;
  },

  create(base?: DeepPartial<EntityMention>): EntityMention {
    return EntityMention.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EntityMention>): EntityMention {
    const message = createBaseEntityMention();
    message.text = (object.text !== undefined && object.text !== null) ? TextSpan.fromPartial(object.text) : undefined;
    message.type = object.type ?? 0;
    message.sentiment = (object.sentiment !== undefined && object.sentiment !== null)
      ? Sentiment.fromPartial(object.sentiment)
      : undefined;
    message.probability = object.probability ?? 0;
    return message;
  },
};

function createBaseTextSpan(): TextSpan {
  return { content: "", beginOffset: 0 };
}

export const TextSpan: MessageFns<TextSpan> = {
  encode(message: TextSpan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.content !== "") {
      writer.uint32(10).string(message.content);
    }
    if (message.beginOffset !== 0) {
      writer.uint32(16).int32(message.beginOffset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextSpan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextSpan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.content = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.beginOffset = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextSpan {
    return {
      content: isSet(object.content) ? globalThis.String(object.content) : "",
      beginOffset: isSet(object.beginOffset) ? globalThis.Number(object.beginOffset) : 0,
    };
  },

  toJSON(message: TextSpan): unknown {
    const obj: any = {};
    if (message.content !== "") {
      obj.content = message.content;
    }
    if (message.beginOffset !== 0) {
      obj.beginOffset = Math.round(message.beginOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<TextSpan>): TextSpan {
    return TextSpan.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextSpan>): TextSpan {
    const message = createBaseTextSpan();
    message.content = object.content ?? "";
    message.beginOffset = object.beginOffset ?? 0;
    return message;
  },
};

function createBaseClassificationCategory(): ClassificationCategory {
  return { name: "", confidence: 0, severity: 0 };
}

export const ClassificationCategory: MessageFns<ClassificationCategory> = {
  encode(message: ClassificationCategory, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    if (message.severity !== 0) {
      writer.uint32(29).float(message.severity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassificationCategory {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassificationCategory();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.severity = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassificationCategory {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      severity: isSet(object.severity) ? globalThis.Number(object.severity) : 0,
    };
  },

  toJSON(message: ClassificationCategory): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.severity !== 0) {
      obj.severity = message.severity;
    }
    return obj;
  },

  create(base?: DeepPartial<ClassificationCategory>): ClassificationCategory {
    return ClassificationCategory.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassificationCategory>): ClassificationCategory {
    const message = createBaseClassificationCategory();
    message.name = object.name ?? "";
    message.confidence = object.confidence ?? 0;
    message.severity = object.severity ?? 0;
    return message;
  },
};

function createBaseAnalyzeSentimentRequest(): AnalyzeSentimentRequest {
  return { document: undefined, encodingType: 0 };
}

export const AnalyzeSentimentRequest: MessageFns<AnalyzeSentimentRequest> = {
  encode(message: AnalyzeSentimentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(16).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeSentimentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeSentimentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeSentimentRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnalyzeSentimentRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeSentimentRequest>): AnalyzeSentimentRequest {
    return AnalyzeSentimentRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeSentimentRequest>): AnalyzeSentimentRequest {
    const message = createBaseAnalyzeSentimentRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnalyzeSentimentResponse(): AnalyzeSentimentResponse {
  return { documentSentiment: undefined, languageCode: "", sentences: [], languageSupported: false };
}

export const AnalyzeSentimentResponse: MessageFns<AnalyzeSentimentResponse> = {
  encode(message: AnalyzeSentimentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.documentSentiment !== undefined) {
      Sentiment.encode(message.documentSentiment, writer.uint32(10).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(18).string(message.languageCode);
    }
    for (const v of message.sentences) {
      Sentence.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.languageSupported !== false) {
      writer.uint32(32).bool(message.languageSupported);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeSentimentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeSentimentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.documentSentiment = Sentiment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sentences.push(Sentence.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.languageSupported = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeSentimentResponse {
    return {
      documentSentiment: isSet(object.documentSentiment) ? Sentiment.fromJSON(object.documentSentiment) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      sentences: globalThis.Array.isArray(object?.sentences)
        ? object.sentences.map((e: any) => Sentence.fromJSON(e))
        : [],
      languageSupported: isSet(object.languageSupported) ? globalThis.Boolean(object.languageSupported) : false,
    };
  },

  toJSON(message: AnalyzeSentimentResponse): unknown {
    const obj: any = {};
    if (message.documentSentiment !== undefined) {
      obj.documentSentiment = Sentiment.toJSON(message.documentSentiment);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.sentences?.length) {
      obj.sentences = message.sentences.map((e) => Sentence.toJSON(e));
    }
    if (message.languageSupported !== false) {
      obj.languageSupported = message.languageSupported;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeSentimentResponse>): AnalyzeSentimentResponse {
    return AnalyzeSentimentResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeSentimentResponse>): AnalyzeSentimentResponse {
    const message = createBaseAnalyzeSentimentResponse();
    message.documentSentiment = (object.documentSentiment !== undefined && object.documentSentiment !== null)
      ? Sentiment.fromPartial(object.documentSentiment)
      : undefined;
    message.languageCode = object.languageCode ?? "";
    message.sentences = object.sentences?.map((e) => Sentence.fromPartial(e)) || [];
    message.languageSupported = object.languageSupported ?? false;
    return message;
  },
};

function createBaseAnalyzeEntitiesRequest(): AnalyzeEntitiesRequest {
  return { document: undefined, encodingType: 0 };
}

export const AnalyzeEntitiesRequest: MessageFns<AnalyzeEntitiesRequest> = {
  encode(message: AnalyzeEntitiesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(16).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitiesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitiesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitiesRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnalyzeEntitiesRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeEntitiesRequest>): AnalyzeEntitiesRequest {
    return AnalyzeEntitiesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeEntitiesRequest>): AnalyzeEntitiesRequest {
    const message = createBaseAnalyzeEntitiesRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnalyzeEntitiesResponse(): AnalyzeEntitiesResponse {
  return { entities: [], languageCode: "", languageSupported: false };
}

export const AnalyzeEntitiesResponse: MessageFns<AnalyzeEntitiesResponse> = {
  encode(message: AnalyzeEntitiesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entities) {
      Entity.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(18).string(message.languageCode);
    }
    if (message.languageSupported !== false) {
      writer.uint32(24).bool(message.languageSupported);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitiesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitiesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.languageSupported = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitiesResponse {
    return {
      entities: globalThis.Array.isArray(object?.entities) ? object.entities.map((e: any) => Entity.fromJSON(e)) : [],
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      languageSupported: isSet(object.languageSupported) ? globalThis.Boolean(object.languageSupported) : false,
    };
  },

  toJSON(message: AnalyzeEntitiesResponse): unknown {
    const obj: any = {};
    if (message.entities?.length) {
      obj.entities = message.entities.map((e) => Entity.toJSON(e));
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.languageSupported !== false) {
      obj.languageSupported = message.languageSupported;
    }
    return obj;
  },

  create(base?: DeepPartial<AnalyzeEntitiesResponse>): AnalyzeEntitiesResponse {
    return AnalyzeEntitiesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnalyzeEntitiesResponse>): AnalyzeEntitiesResponse {
    const message = createBaseAnalyzeEntitiesResponse();
    message.entities = object.entities?.map((e) => Entity.fromPartial(e)) || [];
    message.languageCode = object.languageCode ?? "";
    message.languageSupported = object.languageSupported ?? false;
    return message;
  },
};

function createBaseClassifyTextRequest(): ClassifyTextRequest {
  return { document: undefined };
}

export const ClassifyTextRequest: MessageFns<ClassifyTextRequest> = {
  encode(message: ClassifyTextRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassifyTextRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassifyTextRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassifyTextRequest {
    return { document: isSet(object.document) ? Document.fromJSON(object.document) : undefined };
  },

  toJSON(message: ClassifyTextRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    return obj;
  },

  create(base?: DeepPartial<ClassifyTextRequest>): ClassifyTextRequest {
    return ClassifyTextRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassifyTextRequest>): ClassifyTextRequest {
    const message = createBaseClassifyTextRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    return message;
  },
};

function createBaseClassifyTextResponse(): ClassifyTextResponse {
  return { categories: [], languageCode: "", languageSupported: false };
}

export const ClassifyTextResponse: MessageFns<ClassifyTextResponse> = {
  encode(message: ClassifyTextResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.categories) {
      ClassificationCategory.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(18).string(message.languageCode);
    }
    if (message.languageSupported !== false) {
      writer.uint32(24).bool(message.languageSupported);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassifyTextResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassifyTextResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.categories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.languageSupported = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassifyTextResponse {
    return {
      categories: globalThis.Array.isArray(object?.categories)
        ? object.categories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      languageSupported: isSet(object.languageSupported) ? globalThis.Boolean(object.languageSupported) : false,
    };
  },

  toJSON(message: ClassifyTextResponse): unknown {
    const obj: any = {};
    if (message.categories?.length) {
      obj.categories = message.categories.map((e) => ClassificationCategory.toJSON(e));
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.languageSupported !== false) {
      obj.languageSupported = message.languageSupported;
    }
    return obj;
  },

  create(base?: DeepPartial<ClassifyTextResponse>): ClassifyTextResponse {
    return ClassifyTextResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ClassifyTextResponse>): ClassifyTextResponse {
    const message = createBaseClassifyTextResponse();
    message.categories = object.categories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    message.languageCode = object.languageCode ?? "";
    message.languageSupported = object.languageSupported ?? false;
    return message;
  },
};

function createBaseModerateTextRequest(): ModerateTextRequest {
  return { document: undefined, modelVersion: 0 };
}

export const ModerateTextRequest: MessageFns<ModerateTextRequest> = {
  encode(message: ModerateTextRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.modelVersion !== 0) {
      writer.uint32(16).int32(message.modelVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModerateTextRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModerateTextRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.modelVersion = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModerateTextRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      modelVersion: isSet(object.modelVersion) ? moderateTextRequest_ModelVersionFromJSON(object.modelVersion) : 0,
    };
  },

  toJSON(message: ModerateTextRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.modelVersion !== 0) {
      obj.modelVersion = moderateTextRequest_ModelVersionToJSON(message.modelVersion);
    }
    return obj;
  },

  create(base?: DeepPartial<ModerateTextRequest>): ModerateTextRequest {
    return ModerateTextRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModerateTextRequest>): ModerateTextRequest {
    const message = createBaseModerateTextRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.modelVersion = object.modelVersion ?? 0;
    return message;
  },
};

function createBaseModerateTextResponse(): ModerateTextResponse {
  return { moderationCategories: [], languageCode: "", languageSupported: false };
}

export const ModerateTextResponse: MessageFns<ModerateTextResponse> = {
  encode(message: ModerateTextResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.moderationCategories) {
      ClassificationCategory.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(18).string(message.languageCode);
    }
    if (message.languageSupported !== false) {
      writer.uint32(24).bool(message.languageSupported);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModerateTextResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModerateTextResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.moderationCategories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.languageSupported = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModerateTextResponse {
    return {
      moderationCategories: globalThis.Array.isArray(object?.moderationCategories)
        ? object.moderationCategories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      languageSupported: isSet(object.languageSupported) ? globalThis.Boolean(object.languageSupported) : false,
    };
  },

  toJSON(message: ModerateTextResponse): unknown {
    const obj: any = {};
    if (message.moderationCategories?.length) {
      obj.moderationCategories = message.moderationCategories.map((e) => ClassificationCategory.toJSON(e));
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.languageSupported !== false) {
      obj.languageSupported = message.languageSupported;
    }
    return obj;
  },

  create(base?: DeepPartial<ModerateTextResponse>): ModerateTextResponse {
    return ModerateTextResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModerateTextResponse>): ModerateTextResponse {
    const message = createBaseModerateTextResponse();
    message.moderationCategories = object.moderationCategories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    message.languageCode = object.languageCode ?? "";
    message.languageSupported = object.languageSupported ?? false;
    return message;
  },
};

function createBaseAnnotateTextRequest(): AnnotateTextRequest {
  return { document: undefined, features: undefined, encodingType: 0 };
}

export const AnnotateTextRequest: MessageFns<AnnotateTextRequest> = {
  encode(message: AnnotateTextRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.document !== undefined) {
      Document.encode(message.document, writer.uint32(10).fork()).join();
    }
    if (message.features !== undefined) {
      AnnotateTextRequest_Features.encode(message.features, writer.uint32(18).fork()).join();
    }
    if (message.encodingType !== 0) {
      writer.uint32(24).int32(message.encodingType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateTextRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateTextRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.document = Document.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.features = AnnotateTextRequest_Features.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.encodingType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateTextRequest {
    return {
      document: isSet(object.document) ? Document.fromJSON(object.document) : undefined,
      features: isSet(object.features) ? AnnotateTextRequest_Features.fromJSON(object.features) : undefined,
      encodingType: isSet(object.encodingType) ? encodingTypeFromJSON(object.encodingType) : 0,
    };
  },

  toJSON(message: AnnotateTextRequest): unknown {
    const obj: any = {};
    if (message.document !== undefined) {
      obj.document = Document.toJSON(message.document);
    }
    if (message.features !== undefined) {
      obj.features = AnnotateTextRequest_Features.toJSON(message.features);
    }
    if (message.encodingType !== 0) {
      obj.encodingType = encodingTypeToJSON(message.encodingType);
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateTextRequest>): AnnotateTextRequest {
    return AnnotateTextRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateTextRequest>): AnnotateTextRequest {
    const message = createBaseAnnotateTextRequest();
    message.document = (object.document !== undefined && object.document !== null)
      ? Document.fromPartial(object.document)
      : undefined;
    message.features = (object.features !== undefined && object.features !== null)
      ? AnnotateTextRequest_Features.fromPartial(object.features)
      : undefined;
    message.encodingType = object.encodingType ?? 0;
    return message;
  },
};

function createBaseAnnotateTextRequest_Features(): AnnotateTextRequest_Features {
  return { extractEntities: false, extractDocumentSentiment: false, classifyText: false, moderateText: false };
}

export const AnnotateTextRequest_Features: MessageFns<AnnotateTextRequest_Features> = {
  encode(message: AnnotateTextRequest_Features, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.extractEntities !== false) {
      writer.uint32(8).bool(message.extractEntities);
    }
    if (message.extractDocumentSentiment !== false) {
      writer.uint32(16).bool(message.extractDocumentSentiment);
    }
    if (message.classifyText !== false) {
      writer.uint32(32).bool(message.classifyText);
    }
    if (message.moderateText !== false) {
      writer.uint32(40).bool(message.moderateText);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateTextRequest_Features {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateTextRequest_Features();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.extractEntities = reader.bool();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.extractDocumentSentiment = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.classifyText = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.moderateText = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateTextRequest_Features {
    return {
      extractEntities: isSet(object.extractEntities) ? globalThis.Boolean(object.extractEntities) : false,
      extractDocumentSentiment: isSet(object.extractDocumentSentiment)
        ? globalThis.Boolean(object.extractDocumentSentiment)
        : false,
      classifyText: isSet(object.classifyText) ? globalThis.Boolean(object.classifyText) : false,
      moderateText: isSet(object.moderateText) ? globalThis.Boolean(object.moderateText) : false,
    };
  },

  toJSON(message: AnnotateTextRequest_Features): unknown {
    const obj: any = {};
    if (message.extractEntities !== false) {
      obj.extractEntities = message.extractEntities;
    }
    if (message.extractDocumentSentiment !== false) {
      obj.extractDocumentSentiment = message.extractDocumentSentiment;
    }
    if (message.classifyText !== false) {
      obj.classifyText = message.classifyText;
    }
    if (message.moderateText !== false) {
      obj.moderateText = message.moderateText;
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateTextRequest_Features>): AnnotateTextRequest_Features {
    return AnnotateTextRequest_Features.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateTextRequest_Features>): AnnotateTextRequest_Features {
    const message = createBaseAnnotateTextRequest_Features();
    message.extractEntities = object.extractEntities ?? false;
    message.extractDocumentSentiment = object.extractDocumentSentiment ?? false;
    message.classifyText = object.classifyText ?? false;
    message.moderateText = object.moderateText ?? false;
    return message;
  },
};

function createBaseAnnotateTextResponse(): AnnotateTextResponse {
  return {
    sentences: [],
    entities: [],
    documentSentiment: undefined,
    languageCode: "",
    categories: [],
    moderationCategories: [],
    languageSupported: false,
  };
}

export const AnnotateTextResponse: MessageFns<AnnotateTextResponse> = {
  encode(message: AnnotateTextResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sentences) {
      Sentence.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.entities) {
      Entity.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.documentSentiment !== undefined) {
      Sentiment.encode(message.documentSentiment, writer.uint32(26).fork()).join();
    }
    if (message.languageCode !== "") {
      writer.uint32(34).string(message.languageCode);
    }
    for (const v of message.categories) {
      ClassificationCategory.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.moderationCategories) {
      ClassificationCategory.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.languageSupported !== false) {
      writer.uint32(56).bool(message.languageSupported);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateTextResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateTextResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sentences.push(Sentence.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.documentSentiment = Sentiment.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.categories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.moderationCategories.push(ClassificationCategory.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.languageSupported = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateTextResponse {
    return {
      sentences: globalThis.Array.isArray(object?.sentences)
        ? object.sentences.map((e: any) => Sentence.fromJSON(e))
        : [],
      entities: globalThis.Array.isArray(object?.entities) ? object.entities.map((e: any) => Entity.fromJSON(e)) : [],
      documentSentiment: isSet(object.documentSentiment) ? Sentiment.fromJSON(object.documentSentiment) : undefined,
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      categories: globalThis.Array.isArray(object?.categories)
        ? object.categories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
      moderationCategories: globalThis.Array.isArray(object?.moderationCategories)
        ? object.moderationCategories.map((e: any) => ClassificationCategory.fromJSON(e))
        : [],
      languageSupported: isSet(object.languageSupported) ? globalThis.Boolean(object.languageSupported) : false,
    };
  },

  toJSON(message: AnnotateTextResponse): unknown {
    const obj: any = {};
    if (message.sentences?.length) {
      obj.sentences = message.sentences.map((e) => Sentence.toJSON(e));
    }
    if (message.entities?.length) {
      obj.entities = message.entities.map((e) => Entity.toJSON(e));
    }
    if (message.documentSentiment !== undefined) {
      obj.documentSentiment = Sentiment.toJSON(message.documentSentiment);
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.categories?.length) {
      obj.categories = message.categories.map((e) => ClassificationCategory.toJSON(e));
    }
    if (message.moderationCategories?.length) {
      obj.moderationCategories = message.moderationCategories.map((e) => ClassificationCategory.toJSON(e));
    }
    if (message.languageSupported !== false) {
      obj.languageSupported = message.languageSupported;
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateTextResponse>): AnnotateTextResponse {
    return AnnotateTextResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateTextResponse>): AnnotateTextResponse {
    const message = createBaseAnnotateTextResponse();
    message.sentences = object.sentences?.map((e) => Sentence.fromPartial(e)) || [];
    message.entities = object.entities?.map((e) => Entity.fromPartial(e)) || [];
    message.documentSentiment = (object.documentSentiment !== undefined && object.documentSentiment !== null)
      ? Sentiment.fromPartial(object.documentSentiment)
      : undefined;
    message.languageCode = object.languageCode ?? "";
    message.categories = object.categories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    message.moderationCategories = object.moderationCategories?.map((e) => ClassificationCategory.fromPartial(e)) || [];
    message.languageSupported = object.languageSupported ?? false;
    return message;
  },
};

/**
 * Provides text analysis operations such as sentiment analysis and entity
 * recognition.
 */
export type LanguageServiceDefinition = typeof LanguageServiceDefinition;
export const LanguageServiceDefinition = {
  name: "LanguageService",
  fullName: "google.cloud.language.v2.LanguageService",
  methods: {
    /** Analyzes the sentiment of the provided text. */
    analyzeSentiment: {
      name: "AnalyzeSentiment",
      requestType: AnalyzeSentimentRequest,
      requestStream: false,
      responseType: AnalyzeSentimentResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116]),
          ],
          578365826: [
            Buffer.from([
              35,
              58,
              1,
              42,
              34,
              30,
              47,
              118,
              50,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              83,
              101,
              110,
              116,
              105,
              109,
              101,
              110,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Finds named entities (currently proper names and common nouns) in the text
     * along with entity types, probability, mentions for each entity, and
     * other properties.
     */
    analyzeEntities: {
      name: "AnalyzeEntities",
      requestType: AnalyzeEntitiesRequest,
      requestStream: false,
      responseType: AnalyzeEntitiesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116]),
          ],
          578365826: [
            Buffer.from([
              34,
              58,
              1,
              42,
              34,
              29,
              47,
              118,
              50,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              97,
              108,
              121,
              122,
              101,
              69,
              110,
              116,
              105,
              116,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Classifies a document into categories. */
    classifyText: {
      name: "ClassifyText",
      requestType: ClassifyTextRequest,
      requestStream: false,
      responseType: ClassifyTextResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116])],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              50,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              99,
              108,
              97,
              115,
              115,
              105,
              102,
              121,
              84,
              101,
              120,
              116,
            ]),
          ],
        },
      },
    },
    /** Moderates a document for harmful and sensitive categories. */
    moderateText: {
      name: "ModerateText",
      requestType: ModerateTextRequest,
      requestStream: false,
      responseType: ModerateTextResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 111, 99, 117, 109, 101, 110, 116])],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              50,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              109,
              111,
              100,
              101,
              114,
              97,
              116,
              101,
              84,
              101,
              120,
              116,
            ]),
          ],
        },
      },
    },
    /** A convenience method that provides all features in one call. */
    annotateText: {
      name: "AnnotateText",
      requestType: AnnotateTextRequest,
      requestStream: false,
      responseType: AnnotateTextResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              31,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              44,
              101,
              110,
              99,
              111,
              100,
              105,
              110,
              103,
              95,
              116,
              121,
              112,
              101,
            ]),
            Buffer.from([17, 100, 111, 99, 117, 109, 101, 110, 116, 44, 102, 101, 97, 116, 117, 114, 101, 115]),
          ],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              50,
              47,
              100,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              58,
              97,
              110,
              110,
              111,
              116,
              97,
              116,
              101,
              84,
              101,
              120,
              116,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface LanguageServiceImplementation<CallContextExt = {}> {
  /** Analyzes the sentiment of the provided text. */
  analyzeSentiment(
    request: AnalyzeSentimentRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeSentimentResponse>>;
  /**
   * Finds named entities (currently proper names and common nouns) in the text
   * along with entity types, probability, mentions for each entity, and
   * other properties.
   */
  analyzeEntities(
    request: AnalyzeEntitiesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnalyzeEntitiesResponse>>;
  /** Classifies a document into categories. */
  classifyText(
    request: ClassifyTextRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ClassifyTextResponse>>;
  /** Moderates a document for harmful and sensitive categories. */
  moderateText(
    request: ModerateTextRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ModerateTextResponse>>;
  /** A convenience method that provides all features in one call. */
  annotateText(
    request: AnnotateTextRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AnnotateTextResponse>>;
}

export interface LanguageServiceClient<CallOptionsExt = {}> {
  /** Analyzes the sentiment of the provided text. */
  analyzeSentiment(
    request: DeepPartial<AnalyzeSentimentRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeSentimentResponse>;
  /**
   * Finds named entities (currently proper names and common nouns) in the text
   * along with entity types, probability, mentions for each entity, and
   * other properties.
   */
  analyzeEntities(
    request: DeepPartial<AnalyzeEntitiesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnalyzeEntitiesResponse>;
  /** Classifies a document into categories. */
  classifyText(
    request: DeepPartial<ClassifyTextRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ClassifyTextResponse>;
  /** Moderates a document for harmful and sensitive categories. */
  moderateText(
    request: DeepPartial<ModerateTextRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ModerateTextResponse>;
  /** A convenience method that provides all features in one call. */
  annotateText(
    request: DeepPartial<AnnotateTextRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AnnotateTextResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
