// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/dataform/v1beta1/dataform.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { Interval } from "../../../type/interval.js";

export const protobufPackage = "google.cloud.dataform.v1beta1";

/** Represents a Dataform Git repository. */
export interface Repository {
  /** Output only. The repository's name. */
  name: string;
  /** Optional. The repository's user-friendly name. */
  displayName: string;
  /** Optional. If set, configures this repository to be linked to a Git remote. */
  gitRemoteSettings:
    | Repository_GitRemoteSettings
    | undefined;
  /**
   * Optional. The name of the Secret Manager secret version to be used to
   * interpolate variables into the .npmrc file for package installation
   * operations. Must be in the format `projects/* /secrets/* /versions/*`. The
   * file itself must be in a JSON format.
   */
  npmrcEnvironmentVariablesSecretVersion: string;
  /**
   * Optional. If set, fields of `workspace_compilation_overrides` override the
   * default compilation settings that are specified in dataform.json when
   * creating workspace-scoped compilation results. See documentation for
   * `WorkspaceCompilationOverrides` for more information.
   */
  workspaceCompilationOverrides:
    | Repository_WorkspaceCompilationOverrides
    | undefined;
  /** Optional. Repository user labels. */
  labels: { [key: string]: string };
  /**
   * Optional. Input only. If set to true, the authenticated user will be
   * granted the roles/dataform.admin role on the created repository. To modify
   * access to the created repository later apply setIamPolicy from
   * https://cloud.google.com/dataform/reference/rest#rest-resource:-v1beta1.projects.locations.repositories
   */
  setAuthenticatedUserAdmin: boolean;
  /** Optional. The service account to run workflow invocations under. */
  serviceAccount: string;
}

/** Controls Git remote configuration for a repository. */
export interface Repository_GitRemoteSettings {
  /** Required. The Git remote's URL. */
  url: string;
  /** Required. The Git remote's default branch name. */
  defaultBranch: string;
  /**
   * Optional. The name of the Secret Manager secret version to use as an
   * authentication token for Git operations. Must be in the format
   * `projects/* /secrets/* /versions/*`.
   */
  authenticationTokenSecretVersion: string;
  /** Optional. Authentication fields for remote uris using SSH protocol. */
  sshAuthenticationConfig:
    | Repository_GitRemoteSettings_SshAuthenticationConfig
    | undefined;
  /**
   * Output only. Deprecated: The field does not contain any token status
   * information. Instead use
   * https://cloud.google.com/dataform/reference/rest/v1beta1/projects.locations.repositories/computeAccessTokenStatus
   *
   * @deprecated
   */
  tokenStatus: Repository_GitRemoteSettings_TokenStatus;
}

export enum Repository_GitRemoteSettings_TokenStatus {
  /** TOKEN_STATUS_UNSPECIFIED - Default value. This value is unused. */
  TOKEN_STATUS_UNSPECIFIED = 0,
  /**
   * NOT_FOUND - The token could not be found in Secret Manager (or the Dataform
   * Service Account did not have permission to access it).
   */
  NOT_FOUND = 1,
  /** INVALID - The token could not be used to authenticate against the Git remote. */
  INVALID = 2,
  /** VALID - The token was used successfully to authenticate against the Git remote. */
  VALID = 3,
  UNRECOGNIZED = -1,
}

export function repository_GitRemoteSettings_TokenStatusFromJSON(
  object: any,
): Repository_GitRemoteSettings_TokenStatus {
  switch (object) {
    case 0:
    case "TOKEN_STATUS_UNSPECIFIED":
      return Repository_GitRemoteSettings_TokenStatus.TOKEN_STATUS_UNSPECIFIED;
    case 1:
    case "NOT_FOUND":
      return Repository_GitRemoteSettings_TokenStatus.NOT_FOUND;
    case 2:
    case "INVALID":
      return Repository_GitRemoteSettings_TokenStatus.INVALID;
    case 3:
    case "VALID":
      return Repository_GitRemoteSettings_TokenStatus.VALID;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Repository_GitRemoteSettings_TokenStatus.UNRECOGNIZED;
  }
}

export function repository_GitRemoteSettings_TokenStatusToJSON(
  object: Repository_GitRemoteSettings_TokenStatus,
): string {
  switch (object) {
    case Repository_GitRemoteSettings_TokenStatus.TOKEN_STATUS_UNSPECIFIED:
      return "TOKEN_STATUS_UNSPECIFIED";
    case Repository_GitRemoteSettings_TokenStatus.NOT_FOUND:
      return "NOT_FOUND";
    case Repository_GitRemoteSettings_TokenStatus.INVALID:
      return "INVALID";
    case Repository_GitRemoteSettings_TokenStatus.VALID:
      return "VALID";
    case Repository_GitRemoteSettings_TokenStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Configures fields for performing SSH authentication. */
export interface Repository_GitRemoteSettings_SshAuthenticationConfig {
  /**
   * Required. The name of the Secret Manager secret version to use as a
   * ssh private key for Git operations.
   * Must be in the format `projects/* /secrets/* /versions/*`.
   */
  userPrivateKeySecretVersion: string;
  /**
   * Required. Content of a public SSH key to verify an identity of a remote
   * Git host.
   */
  hostPublicKey: string;
}

/**
 * Configures workspace compilation overrides for a repository.
 * Primarily used by the UI (`console.cloud.google.com`).
 * `schema_suffix` and `table_prefix` can have a special expression -
 * `${workspaceName}`, which refers to the workspace name from which the
 * compilation results will be created. API callers are expected to resolve
 * the expression in these overrides and provide them explicitly in
 * `code_compilation_config`
 * (https://cloud.google.com/dataform/reference/rest/v1beta1/projects.locations.repositories.compilationResults#codecompilationconfig)
 * when creating workspace-scoped compilation results.
 */
export interface Repository_WorkspaceCompilationOverrides {
  /** Optional. The default database (Google Cloud project ID). */
  defaultDatabase: string;
  /**
   * Optional. The suffix that should be appended to all schema (BigQuery
   * dataset ID) names.
   */
  schemaSuffix: string;
  /** Optional. The prefix that should be prepended to all table names. */
  tablePrefix: string;
}

export interface Repository_LabelsEntry {
  key: string;
  value: string;
}

/** `ListRepositories` request message. */
export interface ListRepositoriesRequest {
  /**
   * Required. The location in which to list repositories. Must be in the format
   * `projects/* /locations/*`.
   */
  parent: string;
  /**
   * Optional. Maximum number of repositories to return. The server may return
   * fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListRepositories` call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListRepositories`
   * must match the call that provided the page token.
   */
  pageToken: string;
  /**
   * Optional. This field only supports ordering by `name`. If unspecified, the
   * server will choose the ordering. If specified, the default order is
   * ascending for the `name` field.
   */
  orderBy: string;
  /** Optional. Filter for the returned list. */
  filter: string;
}

/** `ListRepositories` response message. */
export interface ListRepositoriesResponse {
  /** List of repositories. */
  repositories: Repository[];
  /**
   * A token which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations which could not be reached. */
  unreachable: string[];
}

/** `GetRepository` request message. */
export interface GetRepositoryRequest {
  /** Required. The repository's name. */
  name: string;
}

/** `CreateRepository` request message. */
export interface CreateRepositoryRequest {
  /**
   * Required. The location in which to create the repository. Must be in the
   * format `projects/* /locations/*`.
   */
  parent: string;
  /** Required. The repository to create. */
  repository:
    | Repository
    | undefined;
  /**
   * Required. The ID to use for the repository, which will become the final
   * component of the repository's resource name.
   */
  repositoryId: string;
}

/** `UpdateRepository` request message. */
export interface UpdateRepositoryRequest {
  /**
   * Optional. Specifies the fields to be updated in the repository. If left
   * unset, all fields will be updated.
   */
  updateMask:
    | string[]
    | undefined;
  /** Required. The repository to update. */
  repository: Repository | undefined;
}

/** `DeleteRepository` request message. */
export interface DeleteRepositoryRequest {
  /** Required. The repository's name. */
  name: string;
  /**
   * If set to true, any child resources of this repository will also be
   * deleted. (Otherwise, the request will only succeed if the repository has no
   * child resources.)
   */
  force: boolean;
}

/** `CommitRepositoryChanges` request message. */
export interface CommitRepositoryChangesRequest {
  /** Required. The repository's name. */
  name: string;
  /** Required. The changes to commit to the repository. */
  commitMetadata:
    | CommitMetadata
    | undefined;
  /**
   * Optional. The commit SHA which must be the repository's current HEAD before
   * applying this commit; otherwise this request will fail. If unset, no
   * validation on the current HEAD commit SHA is performed.
   */
  requiredHeadCommitSha: string;
  /**
   * A map to the path of the file to the operation. The path is the full file
   * path including filename, from repository root.
   */
  fileOperations: { [key: string]: CommitRepositoryChangesRequest_FileOperation };
}

/** Represents a single file operation to the repository. */
export interface CommitRepositoryChangesRequest_FileOperation {
  /** Represents the write operation. */
  writeFile?:
    | CommitRepositoryChangesRequest_FileOperation_WriteFile
    | undefined;
  /** Represents the delete operation. */
  deleteFile?: CommitRepositoryChangesRequest_FileOperation_DeleteFile | undefined;
}

/** Represents the write file operation (for files added or modified). */
export interface CommitRepositoryChangesRequest_FileOperation_WriteFile {
  /** The file's contents. */
  contents: Buffer;
}

/** Represents the delete file operation. */
export interface CommitRepositoryChangesRequest_FileOperation_DeleteFile {
}

export interface CommitRepositoryChangesRequest_FileOperationsEntry {
  key: string;
  value: CommitRepositoryChangesRequest_FileOperation | undefined;
}

/** `ReadRepositoryFile` request message. */
export interface ReadRepositoryFileRequest {
  /** Required. The repository's name. */
  name: string;
  /**
   * Optional. The commit SHA for the commit to read from. If unset, the file
   * will be read from HEAD.
   */
  commitSha: string;
  /** Required. Full file path to read including filename, from repository root. */
  path: string;
}

/** `ReadRepositoryFile` response message. */
export interface ReadRepositoryFileResponse {
  /** The file's contents. */
  contents: Buffer;
}

/** `QueryRepositoryDirectoryContents` request message. */
export interface QueryRepositoryDirectoryContentsRequest {
  /** Required. The repository's name. */
  name: string;
  /**
   * Optional. The Commit SHA for the commit to query from. If unset, the
   * directory will be queried from HEAD.
   */
  commitSha: string;
  /**
   * Optional. The directory's full path including directory name, relative to
   * root. If left unset, the root is used.
   */
  path: string;
  /**
   * Optional. Maximum number of paths to return. The server may return fewer
   * items than requested. If unspecified, the server will pick an appropriate
   * default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous
   * `QueryRepositoryDirectoryContents` call. Provide this to retrieve the
   * subsequent page.
   *
   * When paginating, all other parameters provided to
   * `QueryRepositoryDirectoryContents` must match the call that provided the
   * page token.
   */
  pageToken: string;
}

/** `QueryRepositoryDirectoryContents` response message. */
export interface QueryRepositoryDirectoryContentsResponse {
  /** List of entries in the directory. */
  directoryEntries: DirectoryEntry[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

/** `FetchRepositoryHistory` request message. */
export interface FetchRepositoryHistoryRequest {
  /** Required. The repository's name. */
  name: string;
  /**
   * Optional. Maximum number of commits to return. The server may return fewer
   * items than requested. If unspecified, the server will pick an appropriate
   * default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `FetchRepositoryHistory`
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `FetchRepositoryHistory`
   * must match the call that provided the page token.
   */
  pageToken: string;
}

/** `FetchRepositoryHistory` response message. */
export interface FetchRepositoryHistoryResponse {
  /** A list of commit logs, ordered by 'git log' default order. */
  commits: CommitLogEntry[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

/** Represents a single commit log. */
export interface CommitLogEntry {
  /** Commit timestamp. */
  commitTime:
    | Date
    | undefined;
  /** The commit SHA for this commit log entry. */
  commitSha: string;
  /** The commit author for this commit log entry. */
  author:
    | CommitAuthor
    | undefined;
  /** The commit message for this commit log entry. */
  commitMessage: string;
}

/** Represents a Dataform Git commit. */
export interface CommitMetadata {
  /** Required. The commit's author. */
  author:
    | CommitAuthor
    | undefined;
  /** Optional. The commit's message. */
  commitMessage: string;
}

/** `ComputeRepositoryAccessTokenStatus` request message. */
export interface ComputeRepositoryAccessTokenStatusRequest {
  /** Required. The repository's name. */
  name: string;
}

/** `ComputeRepositoryAccessTokenStatus` response message. */
export interface ComputeRepositoryAccessTokenStatusResponse {
  /** Indicates the status of the Git access token. */
  tokenStatus: ComputeRepositoryAccessTokenStatusResponse_TokenStatus;
}

/** Indicates the status of a Git authentication token. */
export enum ComputeRepositoryAccessTokenStatusResponse_TokenStatus {
  /** TOKEN_STATUS_UNSPECIFIED - Default value. This value is unused. */
  TOKEN_STATUS_UNSPECIFIED = 0,
  /**
   * NOT_FOUND - The token could not be found in Secret Manager (or the Dataform
   * Service Account did not have permission to access it).
   */
  NOT_FOUND = 1,
  /** INVALID - The token could not be used to authenticate against the Git remote. */
  INVALID = 2,
  /** VALID - The token was used successfully to authenticate against the Git remote. */
  VALID = 3,
  UNRECOGNIZED = -1,
}

export function computeRepositoryAccessTokenStatusResponse_TokenStatusFromJSON(
  object: any,
): ComputeRepositoryAccessTokenStatusResponse_TokenStatus {
  switch (object) {
    case 0:
    case "TOKEN_STATUS_UNSPECIFIED":
      return ComputeRepositoryAccessTokenStatusResponse_TokenStatus.TOKEN_STATUS_UNSPECIFIED;
    case 1:
    case "NOT_FOUND":
      return ComputeRepositoryAccessTokenStatusResponse_TokenStatus.NOT_FOUND;
    case 2:
    case "INVALID":
      return ComputeRepositoryAccessTokenStatusResponse_TokenStatus.INVALID;
    case 3:
    case "VALID":
      return ComputeRepositoryAccessTokenStatusResponse_TokenStatus.VALID;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ComputeRepositoryAccessTokenStatusResponse_TokenStatus.UNRECOGNIZED;
  }
}

export function computeRepositoryAccessTokenStatusResponse_TokenStatusToJSON(
  object: ComputeRepositoryAccessTokenStatusResponse_TokenStatus,
): string {
  switch (object) {
    case ComputeRepositoryAccessTokenStatusResponse_TokenStatus.TOKEN_STATUS_UNSPECIFIED:
      return "TOKEN_STATUS_UNSPECIFIED";
    case ComputeRepositoryAccessTokenStatusResponse_TokenStatus.NOT_FOUND:
      return "NOT_FOUND";
    case ComputeRepositoryAccessTokenStatusResponse_TokenStatus.INVALID:
      return "INVALID";
    case ComputeRepositoryAccessTokenStatusResponse_TokenStatus.VALID:
      return "VALID";
    case ComputeRepositoryAccessTokenStatusResponse_TokenStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** `FetchRemoteBranches` request message. */
export interface FetchRemoteBranchesRequest {
  /** Required. The repository's name. */
  name: string;
}

/** `FetchRemoteBranches` response message. */
export interface FetchRemoteBranchesResponse {
  /** The remote repository's branch names. */
  branches: string[];
}

/** Represents a Dataform Git workspace. */
export interface Workspace {
  /** Output only. The workspace's name. */
  name: string;
}

/** `ListWorkspaces` request message. */
export interface ListWorkspacesRequest {
  /**
   * Required. The repository in which to list workspaces. Must be in the
   * format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /**
   * Optional. Maximum number of workspaces to return. The server may return
   * fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListWorkspaces` call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListWorkspaces`
   * must match the call that provided the page token.
   */
  pageToken: string;
  /**
   * Optional. This field only supports ordering by `name`. If unspecified, the
   * server will choose the ordering. If specified, the default order is
   * ascending for the `name` field.
   */
  orderBy: string;
  /** Optional. Filter for the returned list. */
  filter: string;
}

/** `ListWorkspaces` response message. */
export interface ListWorkspacesResponse {
  /** List of workspaces. */
  workspaces: Workspace[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations which could not be reached. */
  unreachable: string[];
}

/** `GetWorkspace` request message. */
export interface GetWorkspaceRequest {
  /** Required. The workspace's name. */
  name: string;
}

/** `CreateWorkspace` request message. */
export interface CreateWorkspaceRequest {
  /**
   * Required. The repository in which to create the workspace. Must be in the
   * format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /** Required. The workspace to create. */
  workspace:
    | Workspace
    | undefined;
  /**
   * Required. The ID to use for the workspace, which will become the final
   * component of the workspace's resource name.
   */
  workspaceId: string;
}

/** `DeleteWorkspace` request message. */
export interface DeleteWorkspaceRequest {
  /** Required. The workspace resource's name. */
  name: string;
}

/** Represents the author of a Git commit. */
export interface CommitAuthor {
  /** Required. The commit author's name. */
  name: string;
  /** Required. The commit author's email address. */
  emailAddress: string;
}

/** `PullGitCommits` request message. */
export interface PullGitCommitsRequest {
  /** Required. The workspace's name. */
  name: string;
  /**
   * Optional. The name of the branch in the Git remote from which to pull
   * commits. If left unset, the repository's default branch name will be used.
   */
  remoteBranch: string;
  /**
   * Required. The author of any merge commit which may be created as a result
   * of merging fetched Git commits into this workspace.
   */
  author: CommitAuthor | undefined;
}

/** `PushGitCommits` request message. */
export interface PushGitCommitsRequest {
  /** Required. The workspace's name. */
  name: string;
  /**
   * Optional. The name of the branch in the Git remote to which commits should
   * be pushed. If left unset, the repository's default branch name will be
   * used.
   */
  remoteBranch: string;
}

/** `FetchFileGitStatuses` request message. */
export interface FetchFileGitStatusesRequest {
  /** Required. The workspace's name. */
  name: string;
}

/** `FetchFileGitStatuses` response message. */
export interface FetchFileGitStatusesResponse {
  /**
   * A list of all files which have uncommitted Git changes. There will only be
   * a single entry for any given file.
   */
  uncommittedFileChanges: FetchFileGitStatusesResponse_UncommittedFileChange[];
}

/** Represents the Git state of a file with uncommitted changes. */
export interface FetchFileGitStatusesResponse_UncommittedFileChange {
  /** The file's full path including filename, relative to the workspace root. */
  path: string;
  /** Indicates the status of the file. */
  state: FetchFileGitStatusesResponse_UncommittedFileChange_State;
}

/** Indicates the status of an uncommitted file change. */
export enum FetchFileGitStatusesResponse_UncommittedFileChange_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** ADDED - The file has been newly added. */
  ADDED = 1,
  /** DELETED - The file has been deleted. */
  DELETED = 2,
  /** MODIFIED - The file has been modified. */
  MODIFIED = 3,
  /** HAS_CONFLICTS - The file contains merge conflicts. */
  HAS_CONFLICTS = 4,
  UNRECOGNIZED = -1,
}

export function fetchFileGitStatusesResponse_UncommittedFileChange_StateFromJSON(
  object: any,
): FetchFileGitStatusesResponse_UncommittedFileChange_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return FetchFileGitStatusesResponse_UncommittedFileChange_State.STATE_UNSPECIFIED;
    case 1:
    case "ADDED":
      return FetchFileGitStatusesResponse_UncommittedFileChange_State.ADDED;
    case 2:
    case "DELETED":
      return FetchFileGitStatusesResponse_UncommittedFileChange_State.DELETED;
    case 3:
    case "MODIFIED":
      return FetchFileGitStatusesResponse_UncommittedFileChange_State.MODIFIED;
    case 4:
    case "HAS_CONFLICTS":
      return FetchFileGitStatusesResponse_UncommittedFileChange_State.HAS_CONFLICTS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FetchFileGitStatusesResponse_UncommittedFileChange_State.UNRECOGNIZED;
  }
}

export function fetchFileGitStatusesResponse_UncommittedFileChange_StateToJSON(
  object: FetchFileGitStatusesResponse_UncommittedFileChange_State,
): string {
  switch (object) {
    case FetchFileGitStatusesResponse_UncommittedFileChange_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case FetchFileGitStatusesResponse_UncommittedFileChange_State.ADDED:
      return "ADDED";
    case FetchFileGitStatusesResponse_UncommittedFileChange_State.DELETED:
      return "DELETED";
    case FetchFileGitStatusesResponse_UncommittedFileChange_State.MODIFIED:
      return "MODIFIED";
    case FetchFileGitStatusesResponse_UncommittedFileChange_State.HAS_CONFLICTS:
      return "HAS_CONFLICTS";
    case FetchFileGitStatusesResponse_UncommittedFileChange_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** `FetchGitAheadBehind` request message. */
export interface FetchGitAheadBehindRequest {
  /** Required. The workspace's name. */
  name: string;
  /**
   * Optional. The name of the branch in the Git remote against which this
   * workspace should be compared. If left unset, the repository's default
   * branch name will be used.
   */
  remoteBranch: string;
}

/** `FetchGitAheadBehind` response message. */
export interface FetchGitAheadBehindResponse {
  /** The number of commits in the remote branch that are not in the workspace. */
  commitsAhead: number;
  /** The number of commits in the workspace that are not in the remote branch. */
  commitsBehind: number;
}

/** `CommitWorkspaceChanges` request message. */
export interface CommitWorkspaceChangesRequest {
  /** Required. The workspace's name. */
  name: string;
  /** Required. The commit's author. */
  author:
    | CommitAuthor
    | undefined;
  /** Optional. The commit's message. */
  commitMessage: string;
  /**
   * Optional. Full file paths to commit including filename, rooted at workspace
   * root. If left empty, all files will be committed.
   */
  paths: string[];
}

/** `ResetWorkspaceChanges` request message. */
export interface ResetWorkspaceChangesRequest {
  /** Required. The workspace's name. */
  name: string;
  /**
   * Optional. Full file paths to reset back to their committed state including
   * filename, rooted at workspace root. If left empty, all files will be reset.
   */
  paths: string[];
  /** Optional. If set to true, untracked files will be deleted. */
  clean: boolean;
}

/** `FetchFileDiff` request message. */
export interface FetchFileDiffRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The file's full path including filename, relative to the
   * workspace root.
   */
  path: string;
}

/** `FetchFileDiff` response message. */
export interface FetchFileDiffResponse {
  /** The raw formatted Git diff for the file. */
  formattedDiff: string;
}

/** `QueryDirectoryContents` request message. */
export interface QueryDirectoryContentsRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Optional. The directory's full path including directory name, relative to
   * the workspace root. If left unset, the workspace root is used.
   */
  path: string;
  /**
   * Optional. Maximum number of paths to return. The server may return fewer
   * items than requested. If unspecified, the server will pick an appropriate
   * default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `QueryDirectoryContents`
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * `QueryDirectoryContents` must match the call that provided the page
   * token.
   */
  pageToken: string;
}

/** `QueryDirectoryContents` response message. */
export interface QueryDirectoryContentsResponse {
  /** List of entries in the directory. */
  directoryEntries: DirectoryEntry[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

/** Represents a single entry in a directory. */
export interface DirectoryEntry {
  /** A file in the directory. */
  file?:
    | string
    | undefined;
  /** A child directory in the directory. */
  directory?: string | undefined;
}

/** `MakeDirectory` request message. */
export interface MakeDirectoryRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The directory's full path including directory name, relative to
   * the workspace root.
   */
  path: string;
}

/** `MakeDirectory` response message. */
export interface MakeDirectoryResponse {
}

/** `RemoveDirectory` request message. */
export interface RemoveDirectoryRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The directory's full path including directory name, relative to
   * the workspace root.
   */
  path: string;
}

/** `MoveDirectory` request message. */
export interface MoveDirectoryRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The directory's full path including directory name, relative to
   * the workspace root.
   */
  path: string;
  /**
   * Required. The new path for the directory including directory name, rooted
   * at workspace root.
   */
  newPath: string;
}

/** `MoveDirectory` response message. */
export interface MoveDirectoryResponse {
}

/** `ReadFile` request message. */
export interface ReadFileRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The file's full path including filename, relative to the
   * workspace root.
   */
  path: string;
}

/** `ReadFile` response message. */
export interface ReadFileResponse {
  /** The file's contents. */
  fileContents: Buffer;
}

/** `RemoveFile` request message. */
export interface RemoveFileRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The file's full path including filename, relative to the
   * workspace root.
   */
  path: string;
}

/** `MoveFile` request message. */
export interface MoveFileRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /**
   * Required. The file's full path including filename, relative to the
   * workspace root.
   */
  path: string;
  /**
   * Required. The file's new path including filename, relative to the workspace
   * root.
   */
  newPath: string;
}

/** `MoveFile` response message. */
export interface MoveFileResponse {
}

/** `WriteFile` request message. */
export interface WriteFileRequest {
  /** Required. The workspace's name. */
  workspace: string;
  /** Required. The file. */
  path: string;
  /** Required. The file's contents. */
  contents: Buffer;
}

/** `WriteFile` response message. */
export interface WriteFileResponse {
}

/** `InstallNpmPackages` request message. */
export interface InstallNpmPackagesRequest {
  /** Required. The workspace's name. */
  workspace: string;
}

/** `InstallNpmPackages` response message. */
export interface InstallNpmPackagesResponse {
}

/** Represents a Dataform release configuration. */
export interface ReleaseConfig {
  /** Output only. The release config's name. */
  name: string;
  /**
   * Required. Git commit/tag/branch name at which the repository should be
   * compiled. Must exist in the remote repository. Examples:
   * - a commit SHA: `12ade345`
   * - a tag: `tag1`
   * - a branch name: `branch1`
   */
  gitCommitish: string;
  /**
   * Optional. If set, fields of `code_compilation_config` override the default
   * compilation settings that are specified in dataform.json.
   */
  codeCompilationConfig:
    | CodeCompilationConfig
    | undefined;
  /**
   * Optional. Optional schedule (in cron format) for automatic creation of
   * compilation results.
   */
  cronSchedule: string;
  /**
   * Optional. Specifies the time zone to be used when interpreting
   * cron_schedule. Must be a time zone name from the time zone database
   * (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones). If left
   * unspecified, the default is UTC.
   */
  timeZone: string;
  /**
   * Output only. Records of the 10 most recent scheduled release attempts,
   * ordered in in descending order of `release_time`. Updated whenever
   * automatic creation of a compilation result is triggered by cron_schedule.
   */
  recentScheduledReleaseRecords: ReleaseConfig_ScheduledReleaseRecord[];
  /**
   * Optional. The name of the currently released compilation result for this
   * release config. This value is updated when a compilation result is created
   * from this release config, or when this resource is updated by API call
   * (perhaps to roll back to an earlier release). The compilation result must
   * have been created using this release config. Must be in the format
   * `projects/* /locations/* /repositories/* /compilationResults/*`.
   */
  releaseCompilationResult: string;
}

/**
 * A record of an attempt to create a compilation result for this release
 * config.
 */
export interface ReleaseConfig_ScheduledReleaseRecord {
  /** The timestamp of this release attempt. */
  releaseTime:
    | Date
    | undefined;
  /**
   * The name of the created compilation result, if one was successfully
   * created. Must be in the format
   * `projects/* /locations/* /repositories/* /compilationResults/*`.
   */
  compilationResult?:
    | string
    | undefined;
  /**
   * The error status encountered upon this attempt to create the
   * compilation result, if the attempt was unsuccessful.
   */
  errorStatus?: Status | undefined;
}

/** `ListReleaseConfigs` request message. */
export interface ListReleaseConfigsRequest {
  /**
   * Required. The repository in which to list release configs. Must be in the
   * format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /**
   * Optional. Maximum number of release configs to return. The server may
   * return fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListReleaseConfigs` call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListReleaseConfigs`
   * must match the call that provided the page token.
   */
  pageToken: string;
}

/** `ListReleaseConfigs` response message. */
export interface ListReleaseConfigsResponse {
  /** List of release configs. */
  releaseConfigs: ReleaseConfig[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations which could not be reached. */
  unreachable: string[];
}

/** `GetReleaseConfig` request message. */
export interface GetReleaseConfigRequest {
  /** Required. The release config's name. */
  name: string;
}

/** `CreateReleaseConfig` request message. */
export interface CreateReleaseConfigRequest {
  /**
   * Required. The repository in which to create the release config. Must be in
   * the format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /** Required. The release config to create. */
  releaseConfig:
    | ReleaseConfig
    | undefined;
  /**
   * Required. The ID to use for the release config, which will become the final
   * component of the release config's resource name.
   */
  releaseConfigId: string;
}

/** `UpdateReleaseConfig` request message. */
export interface UpdateReleaseConfigRequest {
  /**
   * Optional. Specifies the fields to be updated in the release config. If left
   * unset, all fields will be updated.
   */
  updateMask:
    | string[]
    | undefined;
  /** Required. The release config to update. */
  releaseConfig: ReleaseConfig | undefined;
}

/** `DeleteReleaseConfig` request message. */
export interface DeleteReleaseConfigRequest {
  /** Required. The release config's name. */
  name: string;
}

/** Represents the result of compiling a Dataform project. */
export interface CompilationResult {
  /** Output only. The compilation result's name. */
  name: string;
  /**
   * Immutable. Git commit/tag/branch name at which the repository should be
   * compiled. Must exist in the remote repository. Examples:
   * - a commit SHA: `12ade345`
   * - a tag: `tag1`
   * - a branch name: `branch1`
   */
  gitCommitish?:
    | string
    | undefined;
  /**
   * Immutable. The name of the workspace to compile. Must be in the format
   * `projects/* /locations/* /repositories/* /workspaces/*`.
   */
  workspace?:
    | string
    | undefined;
  /**
   * Immutable. The name of the release config to compile. The release
   * config's 'current_compilation_result' field will be updated to this
   * compilation result. Must be in the format
   * `projects/* /locations/* /repositories/* /releaseConfigs/*`.
   */
  releaseConfig?:
    | string
    | undefined;
  /**
   * Immutable. If set, fields of `code_compilation_config` override the default
   * compilation settings that are specified in dataform.json.
   */
  codeCompilationConfig:
    | CodeCompilationConfig
    | undefined;
  /**
   * Output only. The fully resolved Git commit SHA of the code that was
   * compiled. Not set for compilation results whose source is a workspace.
   */
  resolvedGitCommitSha: string;
  /** Output only. The version of `@dataform/core` that was used for compilation. */
  dataformCoreVersion: string;
  /** Output only. Errors encountered during project compilation. */
  compilationErrors: CompilationResult_CompilationError[];
}

/** An error encountered when attempting to compile a Dataform project. */
export interface CompilationResult_CompilationError {
  /** Output only. The error's top level message. */
  message: string;
  /** Output only. The error's full stack trace. */
  stack: string;
  /**
   * Output only. The path of the file where this error occurred, if
   * available, relative to the project root.
   */
  path: string;
  /**
   * Output only. The identifier of the action where this error occurred, if
   * available.
   */
  actionTarget: Target | undefined;
}

/** Configures various aspects of Dataform code compilation. */
export interface CodeCompilationConfig {
  /** Optional. The default database (Google Cloud project ID). */
  defaultDatabase: string;
  /** Optional. The default schema (BigQuery dataset ID). */
  defaultSchema: string;
  /**
   * Optional. The default BigQuery location to use. Defaults to "US".
   * See the BigQuery docs for a full list of locations:
   * https://cloud.google.com/bigquery/docs/locations.
   */
  defaultLocation: string;
  /** Optional. The default schema (BigQuery dataset ID) for assertions. */
  assertionSchema: string;
  /**
   * Optional. User-defined variables that are made available to project code
   * during compilation.
   */
  vars: { [key: string]: string };
  /**
   * Optional. The suffix that should be appended to all database (Google Cloud
   * project ID) names.
   */
  databaseSuffix: string;
  /**
   * Optional. The suffix that should be appended to all schema (BigQuery
   * dataset ID) names.
   */
  schemaSuffix: string;
  /** Optional. The prefix that should be prepended to all table names. */
  tablePrefix: string;
}

export interface CodeCompilationConfig_VarsEntry {
  key: string;
  value: string;
}

/** `ListCompilationResults` request message. */
export interface ListCompilationResultsRequest {
  /**
   * Required. The repository in which to list compilation results. Must be in
   * the format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /**
   * Optional. Maximum number of compilation results to return. The server may
   * return fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListCompilationResults`
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListCompilationResults`
   * must match the call that provided the page token.
   */
  pageToken: string;
}

/** `ListCompilationResults` response message. */
export interface ListCompilationResultsResponse {
  /** List of compilation results. */
  compilationResults: CompilationResult[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations which could not be reached. */
  unreachable: string[];
}

/** `GetCompilationResult` request message. */
export interface GetCompilationResultRequest {
  /** Required. The compilation result's name. */
  name: string;
}

/** `CreateCompilationResult` request message. */
export interface CreateCompilationResultRequest {
  /**
   * Required. The repository in which to create the compilation result. Must be
   * in the format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /** Required. The compilation result to create. */
  compilationResult: CompilationResult | undefined;
}

/**
 * Represents an action identifier. If the action writes output, the output
 * will be written to the referenced database object.
 */
export interface Target {
  /** The action's database (Google Cloud project ID) . */
  database: string;
  /** The action's schema (BigQuery dataset ID), within `database`. */
  schema: string;
  /** The action's name, within `database` and `schema`. */
  name: string;
}

/** Describes a relation and its columns. */
export interface RelationDescriptor {
  /** A text description of the relation. */
  description: string;
  /** A list of descriptions of columns within the relation. */
  columns: RelationDescriptor_ColumnDescriptor[];
  /** A set of BigQuery labels that should be applied to the relation. */
  bigqueryLabels: { [key: string]: string };
}

/** Describes a column. */
export interface RelationDescriptor_ColumnDescriptor {
  /**
   * The identifier for the column. Each entry in `path` represents one level
   * of nesting.
   */
  path: string[];
  /** A textual description of the column. */
  description: string;
  /** A list of BigQuery policy tags that will be applied to the column. */
  bigqueryPolicyTags: string[];
}

export interface RelationDescriptor_BigqueryLabelsEntry {
  key: string;
  value: string;
}

/** Represents a single Dataform action in a compilation result. */
export interface CompilationResultAction {
  /** This action's identifier. Unique within the compilation result. */
  target:
    | Target
    | undefined;
  /**
   * The action's identifier if the project had been compiled without any
   * overrides configured. Unique within the compilation result.
   */
  canonicalTarget:
    | Target
    | undefined;
  /**
   * The full path including filename in which this action is located, relative
   * to the workspace root.
   */
  filePath: string;
  /** The database relation created/updated by this action. */
  relation?:
    | CompilationResultAction_Relation
    | undefined;
  /** The database operations executed by this action. */
  operations?:
    | CompilationResultAction_Operations
    | undefined;
  /** The assertion executed by this action. */
  assertion?:
    | CompilationResultAction_Assertion
    | undefined;
  /** The declaration declared by this action. */
  declaration?: CompilationResultAction_Declaration | undefined;
}

/** Represents a database relation. */
export interface CompilationResultAction_Relation {
  /** A list of actions that this action depends on. */
  dependencyTargets: Target[];
  /** Whether this action is disabled (i.e. should not be run). */
  disabled: boolean;
  /** Arbitrary, user-defined tags on this action. */
  tags: string[];
  /** Descriptor for the relation and its columns. */
  relationDescriptor:
    | RelationDescriptor
    | undefined;
  /** The type of this relation. */
  relationType: CompilationResultAction_Relation_RelationType;
  /** The SELECT query which returns rows which this relation should contain. */
  selectQuery: string;
  /** SQL statements to be executed before creating the relation. */
  preOperations: string[];
  /** SQL statements to be executed after creating the relation. */
  postOperations: string[];
  /**
   * Configures `INCREMENTAL_TABLE` settings for this relation. Only set if
   * `relation_type` is `INCREMENTAL_TABLE`.
   */
  incrementalTableConfig:
    | CompilationResultAction_Relation_IncrementalTableConfig
    | undefined;
  /** The SQL expression used to partition the relation. */
  partitionExpression: string;
  /** A list of columns or SQL expressions used to cluster the table. */
  clusterExpressions: string[];
  /** Sets the partition expiration in days. */
  partitionExpirationDays: number;
  /**
   * Specifies whether queries on this table must include a predicate filter
   * that filters on the partitioning column.
   */
  requirePartitionFilter: boolean;
  /**
   * Additional options that will be provided as key/value pairs into the
   * options clause of a create table/view statement. See
   * https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language
   * for more information on which options are supported.
   */
  additionalOptions: { [key: string]: string };
}

/** Indicates the type of this relation. */
export enum CompilationResultAction_Relation_RelationType {
  /** RELATION_TYPE_UNSPECIFIED - Default value. This value is unused. */
  RELATION_TYPE_UNSPECIFIED = 0,
  /** TABLE - The relation is a table. */
  TABLE = 1,
  /** VIEW - The relation is a view. */
  VIEW = 2,
  /** INCREMENTAL_TABLE - The relation is an incrementalized table. */
  INCREMENTAL_TABLE = 3,
  /** MATERIALIZED_VIEW - The relation is a materialized view. */
  MATERIALIZED_VIEW = 4,
  UNRECOGNIZED = -1,
}

export function compilationResultAction_Relation_RelationTypeFromJSON(
  object: any,
): CompilationResultAction_Relation_RelationType {
  switch (object) {
    case 0:
    case "RELATION_TYPE_UNSPECIFIED":
      return CompilationResultAction_Relation_RelationType.RELATION_TYPE_UNSPECIFIED;
    case 1:
    case "TABLE":
      return CompilationResultAction_Relation_RelationType.TABLE;
    case 2:
    case "VIEW":
      return CompilationResultAction_Relation_RelationType.VIEW;
    case 3:
    case "INCREMENTAL_TABLE":
      return CompilationResultAction_Relation_RelationType.INCREMENTAL_TABLE;
    case 4:
    case "MATERIALIZED_VIEW":
      return CompilationResultAction_Relation_RelationType.MATERIALIZED_VIEW;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CompilationResultAction_Relation_RelationType.UNRECOGNIZED;
  }
}

export function compilationResultAction_Relation_RelationTypeToJSON(
  object: CompilationResultAction_Relation_RelationType,
): string {
  switch (object) {
    case CompilationResultAction_Relation_RelationType.RELATION_TYPE_UNSPECIFIED:
      return "RELATION_TYPE_UNSPECIFIED";
    case CompilationResultAction_Relation_RelationType.TABLE:
      return "TABLE";
    case CompilationResultAction_Relation_RelationType.VIEW:
      return "VIEW";
    case CompilationResultAction_Relation_RelationType.INCREMENTAL_TABLE:
      return "INCREMENTAL_TABLE";
    case CompilationResultAction_Relation_RelationType.MATERIALIZED_VIEW:
      return "MATERIALIZED_VIEW";
    case CompilationResultAction_Relation_RelationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Contains settings for relations of type `INCREMENTAL_TABLE`. */
export interface CompilationResultAction_Relation_IncrementalTableConfig {
  /**
   * The SELECT query which returns rows which should be inserted into the
   * relation if it already exists and is not being refreshed.
   */
  incrementalSelectQuery: string;
  /** Whether this table should be protected from being refreshed. */
  refreshDisabled: boolean;
  /**
   * A set of columns or SQL expressions used to define row uniqueness.
   * If any duplicates are discovered (as defined by `unique_key_parts`),
   * only the newly selected rows (as defined by `incremental_select_query`)
   * will be included in the relation.
   */
  uniqueKeyParts: string[];
  /**
   * A SQL expression conditional used to limit the set of existing rows
   * considered for a merge operation (see `unique_key_parts` for more
   * information).
   */
  updatePartitionFilter: string;
  /**
   * SQL statements to be executed before inserting new rows into the
   * relation.
   */
  incrementalPreOperations: string[];
  /**
   * SQL statements to be executed after inserting new rows into the
   * relation.
   */
  incrementalPostOperations: string[];
}

export interface CompilationResultAction_Relation_AdditionalOptionsEntry {
  key: string;
  value: string;
}

/** Represents a list of arbitrary database operations. */
export interface CompilationResultAction_Operations {
  /** A list of actions that this action depends on. */
  dependencyTargets: Target[];
  /** Whether this action is disabled (i.e. should not be run). */
  disabled: boolean;
  /** Arbitrary, user-defined tags on this action. */
  tags: string[];
  /**
   * Descriptor for any output relation and its columns. Only set if
   * `has_output` is true.
   */
  relationDescriptor:
    | RelationDescriptor
    | undefined;
  /**
   * A list of arbitrary SQL statements that will be executed without
   * alteration.
   */
  queries: string[];
  /** Whether these operations produce an output relation. */
  hasOutput: boolean;
}

/**
 * Represents an assertion upon a SQL query which is required return zero
 * rows.
 */
export interface CompilationResultAction_Assertion {
  /** A list of actions that this action depends on. */
  dependencyTargets: Target[];
  /**
   * The parent action of this assertion. Only set if this assertion was
   * automatically generated.
   */
  parentAction:
    | Target
    | undefined;
  /** Whether this action is disabled (i.e. should not be run). */
  disabled: boolean;
  /** Arbitrary, user-defined tags on this action. */
  tags: string[];
  /**
   * The SELECT query which must return zero rows in order for this assertion
   * to succeed.
   */
  selectQuery: string;
  /**
   * Descriptor for the assertion's automatically-generated view and its
   * columns.
   */
  relationDescriptor: RelationDescriptor | undefined;
}

/**
 * Represents a relation which is not managed by Dataform but which may be
 * referenced by Dataform actions.
 */
export interface CompilationResultAction_Declaration {
  /**
   * Descriptor for the relation and its columns. Used as documentation only,
   * i.e. values here will result in no changes to the relation's metadata.
   */
  relationDescriptor: RelationDescriptor | undefined;
}

/** `QueryCompilationResultActions` request message. */
export interface QueryCompilationResultActionsRequest {
  /** Required. The compilation result's name. */
  name: string;
  /**
   * Optional. Maximum number of compilation results to return. The server may
   * return fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous
   * `QueryCompilationResultActions` call. Provide this to retrieve the
   * subsequent page.
   *
   * When paginating, all other parameters provided to
   * `QueryCompilationResultActions` must match the call that provided the page
   * token.
   */
  pageToken: string;
  /**
   * Optional. Optional filter for the returned list. Filtering is only
   * currently supported on the `file_path` field.
   */
  filter: string;
}

/** `QueryCompilationResultActions` response message. */
export interface QueryCompilationResultActionsResponse {
  /** List of compilation result actions. */
  compilationResultActions: CompilationResultAction[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

/** Represents a Dataform workflow configuration. */
export interface WorkflowConfig {
  /** Output only. The workflow config's name. */
  name: string;
  /**
   * Required. The name of the release config whose release_compilation_result
   * should be executed. Must be in the format
   * `projects/* /locations/* /repositories/* /releaseConfigs/*`.
   */
  releaseConfig: string;
  /** Optional. If left unset, a default InvocationConfig will be used. */
  invocationConfig:
    | InvocationConfig
    | undefined;
  /**
   * Optional. Optional schedule (in cron format) for automatic execution of
   * this workflow config.
   */
  cronSchedule: string;
  /**
   * Optional. Specifies the time zone to be used when interpreting
   * cron_schedule. Must be a time zone name from the time zone database
   * (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones). If left
   * unspecified, the default is UTC.
   */
  timeZone: string;
  /**
   * Output only. Records of the 10 most recent scheduled execution attempts,
   * ordered in in descending order of `execution_time`. Updated whenever
   * automatic creation of a workflow invocation is triggered by cron_schedule.
   */
  recentScheduledExecutionRecords: WorkflowConfig_ScheduledExecutionRecord[];
}

/**
 * A record of an attempt to create a workflow invocation for this workflow
 * config.
 */
export interface WorkflowConfig_ScheduledExecutionRecord {
  /** The timestamp of this execution attempt. */
  executionTime:
    | Date
    | undefined;
  /**
   * The name of the created workflow invocation, if one was successfully
   * created. Must be in the format
   * `projects/* /locations/* /repositories/* /workflowInvocations/*`.
   */
  workflowInvocation?:
    | string
    | undefined;
  /**
   * The error status encountered upon this attempt to create the
   * workflow invocation, if the attempt was unsuccessful.
   */
  errorStatus?: Status | undefined;
}

/**
 * Includes various configuration options for a workflow invocation.
 * If both `included_targets` and `included_tags` are unset, all actions
 * will be included.
 */
export interface InvocationConfig {
  /** Optional. The set of action identifiers to include. */
  includedTargets: Target[];
  /** Optional. The set of tags to include. */
  includedTags: string[];
  /**
   * Optional. When set to true, transitive dependencies of included actions
   * will be executed.
   */
  transitiveDependenciesIncluded: boolean;
  /**
   * Optional. When set to true, transitive dependents of included actions will
   * be executed.
   */
  transitiveDependentsIncluded: boolean;
  /** Optional. When set to true, any incremental tables will be fully refreshed. */
  fullyRefreshIncrementalTablesEnabled: boolean;
  /** Optional. The service account to run workflow invocations under. */
  serviceAccount: string;
}

/** `ListWorkflowConfigs` request message. */
export interface ListWorkflowConfigsRequest {
  /**
   * Required. The repository in which to list workflow configs. Must be in the
   * format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /**
   * Optional. Maximum number of workflow configs to return. The server may
   * return fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListWorkflowConfigs` call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListWorkflowConfigs`
   * must match the call that provided the page token.
   */
  pageToken: string;
}

/** `ListWorkflowConfigs` response message. */
export interface ListWorkflowConfigsResponse {
  /** List of workflow configs. */
  workflowConfigs: WorkflowConfig[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations which could not be reached. */
  unreachable: string[];
}

/** `GetWorkflowConfig` request message. */
export interface GetWorkflowConfigRequest {
  /** Required. The workflow config's name. */
  name: string;
}

/** `CreateWorkflowConfig` request message. */
export interface CreateWorkflowConfigRequest {
  /**
   * Required. The repository in which to create the workflow config. Must be in
   * the format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /** Required. The workflow config to create. */
  workflowConfig:
    | WorkflowConfig
    | undefined;
  /**
   * Required. The ID to use for the workflow config, which will become the
   * final component of the workflow config's resource name.
   */
  workflowConfigId: string;
}

/** `UpdateWorkflowConfig` request message. */
export interface UpdateWorkflowConfigRequest {
  /**
   * Optional. Specifies the fields to be updated in the workflow config. If
   * left unset, all fields will be updated.
   */
  updateMask:
    | string[]
    | undefined;
  /** Required. The workflow config to update. */
  workflowConfig: WorkflowConfig | undefined;
}

/** `DeleteWorkflowConfig` request message. */
export interface DeleteWorkflowConfigRequest {
  /** Required. The workflow config's name. */
  name: string;
}

/** Represents a single invocation of a compilation result. */
export interface WorkflowInvocation {
  /** Output only. The workflow invocation's name. */
  name: string;
  /**
   * Immutable. The name of the compilation result to use for this invocation.
   * Must be in the format
   * `projects/* /locations/* /repositories/* /compilationResults/*`.
   */
  compilationResult?:
    | string
    | undefined;
  /**
   * Immutable. The name of the workflow config to invoke. Must be in the
   * format `projects/* /locations/* /repositories/* /workflowConfigs/*`.
   */
  workflowConfig?:
    | string
    | undefined;
  /** Immutable. If left unset, a default InvocationConfig will be used. */
  invocationConfig:
    | InvocationConfig
    | undefined;
  /** Output only. This workflow invocation's current state. */
  state: WorkflowInvocation_State;
  /** Output only. This workflow invocation's timing details. */
  invocationTiming: Interval | undefined;
}

/** Represents the current state of a workflow invocation. */
export enum WorkflowInvocation_State {
  /** STATE_UNSPECIFIED - Default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The workflow invocation is currently running. */
  RUNNING = 1,
  /** SUCCEEDED - The workflow invocation succeeded. A terminal state. */
  SUCCEEDED = 2,
  /** CANCELLED - The workflow invocation was cancelled. A terminal state. */
  CANCELLED = 3,
  /** FAILED - The workflow invocation failed. A terminal state. */
  FAILED = 4,
  /**
   * CANCELING - The workflow invocation is being cancelled, but some actions are still
   * running.
   */
  CANCELING = 5,
  UNRECOGNIZED = -1,
}

export function workflowInvocation_StateFromJSON(object: any): WorkflowInvocation_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return WorkflowInvocation_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return WorkflowInvocation_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return WorkflowInvocation_State.SUCCEEDED;
    case 3:
    case "CANCELLED":
      return WorkflowInvocation_State.CANCELLED;
    case 4:
    case "FAILED":
      return WorkflowInvocation_State.FAILED;
    case 5:
    case "CANCELING":
      return WorkflowInvocation_State.CANCELING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WorkflowInvocation_State.UNRECOGNIZED;
  }
}

export function workflowInvocation_StateToJSON(object: WorkflowInvocation_State): string {
  switch (object) {
    case WorkflowInvocation_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case WorkflowInvocation_State.RUNNING:
      return "RUNNING";
    case WorkflowInvocation_State.SUCCEEDED:
      return "SUCCEEDED";
    case WorkflowInvocation_State.CANCELLED:
      return "CANCELLED";
    case WorkflowInvocation_State.FAILED:
      return "FAILED";
    case WorkflowInvocation_State.CANCELING:
      return "CANCELING";
    case WorkflowInvocation_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** `ListWorkflowInvocations` request message. */
export interface ListWorkflowInvocationsRequest {
  /**
   * Required. The parent resource of the WorkflowInvocation type. Must be in
   * the format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /**
   * Optional. Maximum number of workflow invocations to return. The server may
   * return fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous `ListWorkflowInvocations`
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListWorkflowInvocations`
   * must match the call that provided the page token.
   */
  pageToken: string;
  /**
   * Optional. This field only supports ordering by `name`. If unspecified, the
   * server will choose the ordering. If specified, the default order is
   * ascending for the `name` field.
   */
  orderBy: string;
  /** Optional. Filter for the returned list. */
  filter: string;
}

/** `ListWorkflowInvocations` response message. */
export interface ListWorkflowInvocationsResponse {
  /** List of workflow invocations. */
  workflowInvocations: WorkflowInvocation[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
  /** Locations which could not be reached. */
  unreachable: string[];
}

/** `GetWorkflowInvocation` request message. */
export interface GetWorkflowInvocationRequest {
  /** Required. The workflow invocation resource's name. */
  name: string;
}

/** `CreateWorkflowInvocation` request message. */
export interface CreateWorkflowInvocationRequest {
  /**
   * Required. The repository in which to create the workflow invocation. Must
   * be in the format `projects/* /locations/* /repositories/*`.
   */
  parent: string;
  /** Required. The workflow invocation resource to create. */
  workflowInvocation: WorkflowInvocation | undefined;
}

/** `DeleteWorkflowInvocation` request message. */
export interface DeleteWorkflowInvocationRequest {
  /** Required. The workflow invocation resource's name. */
  name: string;
}

/** `CancelWorkflowInvocation` request message. */
export interface CancelWorkflowInvocationRequest {
  /** Required. The workflow invocation resource's name. */
  name: string;
}

/** Represents a single action in a workflow invocation. */
export interface WorkflowInvocationAction {
  /**
   * Output only. This action's identifier. Unique within the workflow
   * invocation.
   */
  target:
    | Target
    | undefined;
  /**
   * Output only. The action's identifier if the project had been compiled
   * without any overrides configured. Unique within the compilation result.
   */
  canonicalTarget:
    | Target
    | undefined;
  /** Output only. This action's current state. */
  state: WorkflowInvocationAction_State;
  /**
   * Output only. If and only if action's state is FAILED a failure reason is
   * set.
   */
  failureReason: string;
  /**
   * Output only. This action's timing details.
   * `start_time` will be set if the action is in [RUNNING, SUCCEEDED,
   * CANCELLED, FAILED] state.
   * `end_time` will be set if the action is in [SUCCEEDED, CANCELLED, FAILED]
   * state.
   */
  invocationTiming:
    | Interval
    | undefined;
  /** Output only. The workflow action's bigquery action details. */
  bigqueryAction: WorkflowInvocationAction_BigQueryAction | undefined;
}

/** Represents the current state of a workflow invocation action. */
export enum WorkflowInvocationAction_State {
  /** PENDING - The action has not yet been considered for invocation. */
  PENDING = 0,
  /** RUNNING - The action is currently running. */
  RUNNING = 1,
  /**
   * SKIPPED - Execution of the action was skipped because upstream dependencies did not
   * all complete successfully. A terminal state.
   */
  SKIPPED = 2,
  /**
   * DISABLED - Execution of the action was disabled as per the configuration of the
   * corresponding compilation result action. A terminal state.
   */
  DISABLED = 3,
  /** SUCCEEDED - The action succeeded. A terminal state. */
  SUCCEEDED = 4,
  /** CANCELLED - The action was cancelled. A terminal state. */
  CANCELLED = 5,
  /** FAILED - The action failed. A terminal state. */
  FAILED = 6,
  UNRECOGNIZED = -1,
}

export function workflowInvocationAction_StateFromJSON(object: any): WorkflowInvocationAction_State {
  switch (object) {
    case 0:
    case "PENDING":
      return WorkflowInvocationAction_State.PENDING;
    case 1:
    case "RUNNING":
      return WorkflowInvocationAction_State.RUNNING;
    case 2:
    case "SKIPPED":
      return WorkflowInvocationAction_State.SKIPPED;
    case 3:
    case "DISABLED":
      return WorkflowInvocationAction_State.DISABLED;
    case 4:
    case "SUCCEEDED":
      return WorkflowInvocationAction_State.SUCCEEDED;
    case 5:
    case "CANCELLED":
      return WorkflowInvocationAction_State.CANCELLED;
    case 6:
    case "FAILED":
      return WorkflowInvocationAction_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WorkflowInvocationAction_State.UNRECOGNIZED;
  }
}

export function workflowInvocationAction_StateToJSON(object: WorkflowInvocationAction_State): string {
  switch (object) {
    case WorkflowInvocationAction_State.PENDING:
      return "PENDING";
    case WorkflowInvocationAction_State.RUNNING:
      return "RUNNING";
    case WorkflowInvocationAction_State.SKIPPED:
      return "SKIPPED";
    case WorkflowInvocationAction_State.DISABLED:
      return "DISABLED";
    case WorkflowInvocationAction_State.SUCCEEDED:
      return "SUCCEEDED";
    case WorkflowInvocationAction_State.CANCELLED:
      return "CANCELLED";
    case WorkflowInvocationAction_State.FAILED:
      return "FAILED";
    case WorkflowInvocationAction_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents a workflow action that will run against BigQuery. */
export interface WorkflowInvocationAction_BigQueryAction {
  /** Output only. The generated BigQuery SQL script that will be executed. */
  sqlScript: string;
}

/** `QueryWorkflowInvocationActions` request message. */
export interface QueryWorkflowInvocationActionsRequest {
  /** Required. The workflow invocation's name. */
  name: string;
  /**
   * Optional. Maximum number of workflow invocations to return. The server may
   * return fewer items than requested. If unspecified, the server will pick an
   * appropriate default.
   */
  pageSize: number;
  /**
   * Optional. Page token received from a previous
   * `QueryWorkflowInvocationActions` call. Provide this to retrieve the
   * subsequent page.
   *
   * When paginating, all other parameters provided to
   * `QueryWorkflowInvocationActions` must match the call that provided the page
   * token.
   */
  pageToken: string;
}

/** `QueryWorkflowInvocationActions` response message. */
export interface QueryWorkflowInvocationActionsResponse {
  /** List of workflow invocation actions. */
  workflowInvocationActions: WorkflowInvocationAction[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

function createBaseRepository(): Repository {
  return {
    name: "",
    displayName: "",
    gitRemoteSettings: undefined,
    npmrcEnvironmentVariablesSecretVersion: "",
    workspaceCompilationOverrides: undefined,
    labels: {},
    setAuthenticatedUserAdmin: false,
    serviceAccount: "",
  };
}

export const Repository: MessageFns<Repository> = {
  encode(message: Repository, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(66).string(message.displayName);
    }
    if (message.gitRemoteSettings !== undefined) {
      Repository_GitRemoteSettings.encode(message.gitRemoteSettings, writer.uint32(18).fork()).join();
    }
    if (message.npmrcEnvironmentVariablesSecretVersion !== "") {
      writer.uint32(26).string(message.npmrcEnvironmentVariablesSecretVersion);
    }
    if (message.workspaceCompilationOverrides !== undefined) {
      Repository_WorkspaceCompilationOverrides.encode(message.workspaceCompilationOverrides, writer.uint32(34).fork())
        .join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Repository_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.setAuthenticatedUserAdmin !== false) {
      writer.uint32(72).bool(message.setAuthenticatedUserAdmin);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(82).string(message.serviceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Repository {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepository();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.gitRemoteSettings = Repository_GitRemoteSettings.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.npmrcEnvironmentVariablesSecretVersion = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.workspaceCompilationOverrides = Repository_WorkspaceCompilationOverrides.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = Repository_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.setAuthenticatedUserAdmin = reader.bool();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Repository {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      gitRemoteSettings: isSet(object.gitRemoteSettings)
        ? Repository_GitRemoteSettings.fromJSON(object.gitRemoteSettings)
        : undefined,
      npmrcEnvironmentVariablesSecretVersion: isSet(object.npmrcEnvironmentVariablesSecretVersion)
        ? globalThis.String(object.npmrcEnvironmentVariablesSecretVersion)
        : "",
      workspaceCompilationOverrides: isSet(object.workspaceCompilationOverrides)
        ? Repository_WorkspaceCompilationOverrides.fromJSON(object.workspaceCompilationOverrides)
        : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      setAuthenticatedUserAdmin: isSet(object.setAuthenticatedUserAdmin)
        ? globalThis.Boolean(object.setAuthenticatedUserAdmin)
        : false,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
    };
  },

  toJSON(message: Repository): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.gitRemoteSettings !== undefined) {
      obj.gitRemoteSettings = Repository_GitRemoteSettings.toJSON(message.gitRemoteSettings);
    }
    if (message.npmrcEnvironmentVariablesSecretVersion !== "") {
      obj.npmrcEnvironmentVariablesSecretVersion = message.npmrcEnvironmentVariablesSecretVersion;
    }
    if (message.workspaceCompilationOverrides !== undefined) {
      obj.workspaceCompilationOverrides = Repository_WorkspaceCompilationOverrides.toJSON(
        message.workspaceCompilationOverrides,
      );
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.setAuthenticatedUserAdmin !== false) {
      obj.setAuthenticatedUserAdmin = message.setAuthenticatedUserAdmin;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<Repository>): Repository {
    return Repository.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Repository>): Repository {
    const message = createBaseRepository();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.gitRemoteSettings = (object.gitRemoteSettings !== undefined && object.gitRemoteSettings !== null)
      ? Repository_GitRemoteSettings.fromPartial(object.gitRemoteSettings)
      : undefined;
    message.npmrcEnvironmentVariablesSecretVersion = object.npmrcEnvironmentVariablesSecretVersion ?? "";
    message.workspaceCompilationOverrides =
      (object.workspaceCompilationOverrides !== undefined && object.workspaceCompilationOverrides !== null)
        ? Repository_WorkspaceCompilationOverrides.fromPartial(object.workspaceCompilationOverrides)
        : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.setAuthenticatedUserAdmin = object.setAuthenticatedUserAdmin ?? false;
    message.serviceAccount = object.serviceAccount ?? "";
    return message;
  },
};

function createBaseRepository_GitRemoteSettings(): Repository_GitRemoteSettings {
  return {
    url: "",
    defaultBranch: "",
    authenticationTokenSecretVersion: "",
    sshAuthenticationConfig: undefined,
    tokenStatus: 0,
  };
}

export const Repository_GitRemoteSettings: MessageFns<Repository_GitRemoteSettings> = {
  encode(message: Repository_GitRemoteSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.url !== "") {
      writer.uint32(10).string(message.url);
    }
    if (message.defaultBranch !== "") {
      writer.uint32(18).string(message.defaultBranch);
    }
    if (message.authenticationTokenSecretVersion !== "") {
      writer.uint32(26).string(message.authenticationTokenSecretVersion);
    }
    if (message.sshAuthenticationConfig !== undefined) {
      Repository_GitRemoteSettings_SshAuthenticationConfig.encode(
        message.sshAuthenticationConfig,
        writer.uint32(42).fork(),
      ).join();
    }
    if (message.tokenStatus !== 0) {
      writer.uint32(32).int32(message.tokenStatus);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Repository_GitRemoteSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepository_GitRemoteSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.url = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.defaultBranch = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.authenticationTokenSecretVersion = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.sshAuthenticationConfig = Repository_GitRemoteSettings_SshAuthenticationConfig.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.tokenStatus = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Repository_GitRemoteSettings {
    return {
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      defaultBranch: isSet(object.defaultBranch) ? globalThis.String(object.defaultBranch) : "",
      authenticationTokenSecretVersion: isSet(object.authenticationTokenSecretVersion)
        ? globalThis.String(object.authenticationTokenSecretVersion)
        : "",
      sshAuthenticationConfig: isSet(object.sshAuthenticationConfig)
        ? Repository_GitRemoteSettings_SshAuthenticationConfig.fromJSON(object.sshAuthenticationConfig)
        : undefined,
      tokenStatus: isSet(object.tokenStatus) ? repository_GitRemoteSettings_TokenStatusFromJSON(object.tokenStatus) : 0,
    };
  },

  toJSON(message: Repository_GitRemoteSettings): unknown {
    const obj: any = {};
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.defaultBranch !== "") {
      obj.defaultBranch = message.defaultBranch;
    }
    if (message.authenticationTokenSecretVersion !== "") {
      obj.authenticationTokenSecretVersion = message.authenticationTokenSecretVersion;
    }
    if (message.sshAuthenticationConfig !== undefined) {
      obj.sshAuthenticationConfig = Repository_GitRemoteSettings_SshAuthenticationConfig.toJSON(
        message.sshAuthenticationConfig,
      );
    }
    if (message.tokenStatus !== 0) {
      obj.tokenStatus = repository_GitRemoteSettings_TokenStatusToJSON(message.tokenStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<Repository_GitRemoteSettings>): Repository_GitRemoteSettings {
    return Repository_GitRemoteSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Repository_GitRemoteSettings>): Repository_GitRemoteSettings {
    const message = createBaseRepository_GitRemoteSettings();
    message.url = object.url ?? "";
    message.defaultBranch = object.defaultBranch ?? "";
    message.authenticationTokenSecretVersion = object.authenticationTokenSecretVersion ?? "";
    message.sshAuthenticationConfig =
      (object.sshAuthenticationConfig !== undefined && object.sshAuthenticationConfig !== null)
        ? Repository_GitRemoteSettings_SshAuthenticationConfig.fromPartial(object.sshAuthenticationConfig)
        : undefined;
    message.tokenStatus = object.tokenStatus ?? 0;
    return message;
  },
};

function createBaseRepository_GitRemoteSettings_SshAuthenticationConfig(): Repository_GitRemoteSettings_SshAuthenticationConfig {
  return { userPrivateKeySecretVersion: "", hostPublicKey: "" };
}

export const Repository_GitRemoteSettings_SshAuthenticationConfig: MessageFns<
  Repository_GitRemoteSettings_SshAuthenticationConfig
> = {
  encode(
    message: Repository_GitRemoteSettings_SshAuthenticationConfig,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.userPrivateKeySecretVersion !== "") {
      writer.uint32(10).string(message.userPrivateKeySecretVersion);
    }
    if (message.hostPublicKey !== "") {
      writer.uint32(18).string(message.hostPublicKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Repository_GitRemoteSettings_SshAuthenticationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepository_GitRemoteSettings_SshAuthenticationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.userPrivateKeySecretVersion = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.hostPublicKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Repository_GitRemoteSettings_SshAuthenticationConfig {
    return {
      userPrivateKeySecretVersion: isSet(object.userPrivateKeySecretVersion)
        ? globalThis.String(object.userPrivateKeySecretVersion)
        : "",
      hostPublicKey: isSet(object.hostPublicKey) ? globalThis.String(object.hostPublicKey) : "",
    };
  },

  toJSON(message: Repository_GitRemoteSettings_SshAuthenticationConfig): unknown {
    const obj: any = {};
    if (message.userPrivateKeySecretVersion !== "") {
      obj.userPrivateKeySecretVersion = message.userPrivateKeySecretVersion;
    }
    if (message.hostPublicKey !== "") {
      obj.hostPublicKey = message.hostPublicKey;
    }
    return obj;
  },

  create(
    base?: DeepPartial<Repository_GitRemoteSettings_SshAuthenticationConfig>,
  ): Repository_GitRemoteSettings_SshAuthenticationConfig {
    return Repository_GitRemoteSettings_SshAuthenticationConfig.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Repository_GitRemoteSettings_SshAuthenticationConfig>,
  ): Repository_GitRemoteSettings_SshAuthenticationConfig {
    const message = createBaseRepository_GitRemoteSettings_SshAuthenticationConfig();
    message.userPrivateKeySecretVersion = object.userPrivateKeySecretVersion ?? "";
    message.hostPublicKey = object.hostPublicKey ?? "";
    return message;
  },
};

function createBaseRepository_WorkspaceCompilationOverrides(): Repository_WorkspaceCompilationOverrides {
  return { defaultDatabase: "", schemaSuffix: "", tablePrefix: "" };
}

export const Repository_WorkspaceCompilationOverrides: MessageFns<Repository_WorkspaceCompilationOverrides> = {
  encode(message: Repository_WorkspaceCompilationOverrides, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.defaultDatabase !== "") {
      writer.uint32(10).string(message.defaultDatabase);
    }
    if (message.schemaSuffix !== "") {
      writer.uint32(18).string(message.schemaSuffix);
    }
    if (message.tablePrefix !== "") {
      writer.uint32(26).string(message.tablePrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Repository_WorkspaceCompilationOverrides {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepository_WorkspaceCompilationOverrides();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.defaultDatabase = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.schemaSuffix = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tablePrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Repository_WorkspaceCompilationOverrides {
    return {
      defaultDatabase: isSet(object.defaultDatabase) ? globalThis.String(object.defaultDatabase) : "",
      schemaSuffix: isSet(object.schemaSuffix) ? globalThis.String(object.schemaSuffix) : "",
      tablePrefix: isSet(object.tablePrefix) ? globalThis.String(object.tablePrefix) : "",
    };
  },

  toJSON(message: Repository_WorkspaceCompilationOverrides): unknown {
    const obj: any = {};
    if (message.defaultDatabase !== "") {
      obj.defaultDatabase = message.defaultDatabase;
    }
    if (message.schemaSuffix !== "") {
      obj.schemaSuffix = message.schemaSuffix;
    }
    if (message.tablePrefix !== "") {
      obj.tablePrefix = message.tablePrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<Repository_WorkspaceCompilationOverrides>): Repository_WorkspaceCompilationOverrides {
    return Repository_WorkspaceCompilationOverrides.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Repository_WorkspaceCompilationOverrides>): Repository_WorkspaceCompilationOverrides {
    const message = createBaseRepository_WorkspaceCompilationOverrides();
    message.defaultDatabase = object.defaultDatabase ?? "";
    message.schemaSuffix = object.schemaSuffix ?? "";
    message.tablePrefix = object.tablePrefix ?? "";
    return message;
  },
};

function createBaseRepository_LabelsEntry(): Repository_LabelsEntry {
  return { key: "", value: "" };
}

export const Repository_LabelsEntry: MessageFns<Repository_LabelsEntry> = {
  encode(message: Repository_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Repository_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepository_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Repository_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Repository_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Repository_LabelsEntry>): Repository_LabelsEntry {
    return Repository_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Repository_LabelsEntry>): Repository_LabelsEntry {
    const message = createBaseRepository_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseListRepositoriesRequest(): ListRepositoriesRequest {
  return { parent: "", pageSize: 0, pageToken: "", orderBy: "", filter: "" };
}

export const ListRepositoriesRequest: MessageFns<ListRepositoriesRequest> = {
  encode(message: ListRepositoriesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRepositoriesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRepositoriesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRepositoriesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListRepositoriesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListRepositoriesRequest>): ListRepositoriesRequest {
    return ListRepositoriesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRepositoriesRequest>): ListRepositoriesRequest {
    const message = createBaseListRepositoriesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListRepositoriesResponse(): ListRepositoriesResponse {
  return { repositories: [], nextPageToken: "", unreachable: [] };
}

export const ListRepositoriesResponse: MessageFns<ListRepositoriesResponse> = {
  encode(message: ListRepositoriesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.repositories) {
      Repository.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListRepositoriesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListRepositoriesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.repositories.push(Repository.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListRepositoriesResponse {
    return {
      repositories: globalThis.Array.isArray(object?.repositories)
        ? object.repositories.map((e: any) => Repository.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListRepositoriesResponse): unknown {
    const obj: any = {};
    if (message.repositories?.length) {
      obj.repositories = message.repositories.map((e) => Repository.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListRepositoriesResponse>): ListRepositoriesResponse {
    return ListRepositoriesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListRepositoriesResponse>): ListRepositoriesResponse {
    const message = createBaseListRepositoriesResponse();
    message.repositories = object.repositories?.map((e) => Repository.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetRepositoryRequest(): GetRepositoryRequest {
  return { name: "" };
}

export const GetRepositoryRequest: MessageFns<GetRepositoryRequest> = {
  encode(message: GetRepositoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetRepositoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetRepositoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetRepositoryRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetRepositoryRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetRepositoryRequest>): GetRepositoryRequest {
    return GetRepositoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetRepositoryRequest>): GetRepositoryRequest {
    const message = createBaseGetRepositoryRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateRepositoryRequest(): CreateRepositoryRequest {
  return { parent: "", repository: undefined, repositoryId: "" };
}

export const CreateRepositoryRequest: MessageFns<CreateRepositoryRequest> = {
  encode(message: CreateRepositoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.repository !== undefined) {
      Repository.encode(message.repository, writer.uint32(18).fork()).join();
    }
    if (message.repositoryId !== "") {
      writer.uint32(26).string(message.repositoryId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateRepositoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateRepositoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.repository = Repository.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.repositoryId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateRepositoryRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      repository: isSet(object.repository) ? Repository.fromJSON(object.repository) : undefined,
      repositoryId: isSet(object.repositoryId) ? globalThis.String(object.repositoryId) : "",
    };
  },

  toJSON(message: CreateRepositoryRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.repository !== undefined) {
      obj.repository = Repository.toJSON(message.repository);
    }
    if (message.repositoryId !== "") {
      obj.repositoryId = message.repositoryId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateRepositoryRequest>): CreateRepositoryRequest {
    return CreateRepositoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateRepositoryRequest>): CreateRepositoryRequest {
    const message = createBaseCreateRepositoryRequest();
    message.parent = object.parent ?? "";
    message.repository = (object.repository !== undefined && object.repository !== null)
      ? Repository.fromPartial(object.repository)
      : undefined;
    message.repositoryId = object.repositoryId ?? "";
    return message;
  },
};

function createBaseUpdateRepositoryRequest(): UpdateRepositoryRequest {
  return { updateMask: undefined, repository: undefined };
}

export const UpdateRepositoryRequest: MessageFns<UpdateRepositoryRequest> = {
  encode(message: UpdateRepositoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.repository !== undefined) {
      Repository.encode(message.repository, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateRepositoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateRepositoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.repository = Repository.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateRepositoryRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      repository: isSet(object.repository) ? Repository.fromJSON(object.repository) : undefined,
    };
  },

  toJSON(message: UpdateRepositoryRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.repository !== undefined) {
      obj.repository = Repository.toJSON(message.repository);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateRepositoryRequest>): UpdateRepositoryRequest {
    return UpdateRepositoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateRepositoryRequest>): UpdateRepositoryRequest {
    const message = createBaseUpdateRepositoryRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.repository = (object.repository !== undefined && object.repository !== null)
      ? Repository.fromPartial(object.repository)
      : undefined;
    return message;
  },
};

function createBaseDeleteRepositoryRequest(): DeleteRepositoryRequest {
  return { name: "", force: false };
}

export const DeleteRepositoryRequest: MessageFns<DeleteRepositoryRequest> = {
  encode(message: DeleteRepositoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.force !== false) {
      writer.uint32(16).bool(message.force);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteRepositoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteRepositoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.force = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteRepositoryRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      force: isSet(object.force) ? globalThis.Boolean(object.force) : false,
    };
  },

  toJSON(message: DeleteRepositoryRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.force !== false) {
      obj.force = message.force;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteRepositoryRequest>): DeleteRepositoryRequest {
    return DeleteRepositoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteRepositoryRequest>): DeleteRepositoryRequest {
    const message = createBaseDeleteRepositoryRequest();
    message.name = object.name ?? "";
    message.force = object.force ?? false;
    return message;
  },
};

function createBaseCommitRepositoryChangesRequest(): CommitRepositoryChangesRequest {
  return { name: "", commitMetadata: undefined, requiredHeadCommitSha: "", fileOperations: {} };
}

export const CommitRepositoryChangesRequest: MessageFns<CommitRepositoryChangesRequest> = {
  encode(message: CommitRepositoryChangesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.commitMetadata !== undefined) {
      CommitMetadata.encode(message.commitMetadata, writer.uint32(18).fork()).join();
    }
    if (message.requiredHeadCommitSha !== "") {
      writer.uint32(34).string(message.requiredHeadCommitSha);
    }
    Object.entries(message.fileOperations).forEach(([key, value]) => {
      CommitRepositoryChangesRequest_FileOperationsEntry.encode({ key: key as any, value }, writer.uint32(26).fork())
        .join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRepositoryChangesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRepositoryChangesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitMetadata = CommitMetadata.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requiredHeadCommitSha = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = CommitRepositoryChangesRequest_FileOperationsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.fileOperations[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitRepositoryChangesRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      commitMetadata: isSet(object.commitMetadata) ? CommitMetadata.fromJSON(object.commitMetadata) : undefined,
      requiredHeadCommitSha: isSet(object.requiredHeadCommitSha) ? globalThis.String(object.requiredHeadCommitSha) : "",
      fileOperations: isObject(object.fileOperations)
        ? Object.entries(object.fileOperations).reduce<{ [key: string]: CommitRepositoryChangesRequest_FileOperation }>(
          (acc, [key, value]) => {
            acc[key] = CommitRepositoryChangesRequest_FileOperation.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
    };
  },

  toJSON(message: CommitRepositoryChangesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.commitMetadata !== undefined) {
      obj.commitMetadata = CommitMetadata.toJSON(message.commitMetadata);
    }
    if (message.requiredHeadCommitSha !== "") {
      obj.requiredHeadCommitSha = message.requiredHeadCommitSha;
    }
    if (message.fileOperations) {
      const entries = Object.entries(message.fileOperations);
      if (entries.length > 0) {
        obj.fileOperations = {};
        entries.forEach(([k, v]) => {
          obj.fileOperations[k] = CommitRepositoryChangesRequest_FileOperation.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<CommitRepositoryChangesRequest>): CommitRepositoryChangesRequest {
    return CommitRepositoryChangesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitRepositoryChangesRequest>): CommitRepositoryChangesRequest {
    const message = createBaseCommitRepositoryChangesRequest();
    message.name = object.name ?? "";
    message.commitMetadata = (object.commitMetadata !== undefined && object.commitMetadata !== null)
      ? CommitMetadata.fromPartial(object.commitMetadata)
      : undefined;
    message.requiredHeadCommitSha = object.requiredHeadCommitSha ?? "";
    message.fileOperations = Object.entries(object.fileOperations ?? {}).reduce<
      { [key: string]: CommitRepositoryChangesRequest_FileOperation }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = CommitRepositoryChangesRequest_FileOperation.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseCommitRepositoryChangesRequest_FileOperation(): CommitRepositoryChangesRequest_FileOperation {
  return { writeFile: undefined, deleteFile: undefined };
}

export const CommitRepositoryChangesRequest_FileOperation: MessageFns<CommitRepositoryChangesRequest_FileOperation> = {
  encode(
    message: CommitRepositoryChangesRequest_FileOperation,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.writeFile !== undefined) {
      CommitRepositoryChangesRequest_FileOperation_WriteFile.encode(message.writeFile, writer.uint32(10).fork()).join();
    }
    if (message.deleteFile !== undefined) {
      CommitRepositoryChangesRequest_FileOperation_DeleteFile.encode(message.deleteFile, writer.uint32(18).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRepositoryChangesRequest_FileOperation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRepositoryChangesRequest_FileOperation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.writeFile = CommitRepositoryChangesRequest_FileOperation_WriteFile.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deleteFile = CommitRepositoryChangesRequest_FileOperation_DeleteFile.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitRepositoryChangesRequest_FileOperation {
    return {
      writeFile: isSet(object.writeFile)
        ? CommitRepositoryChangesRequest_FileOperation_WriteFile.fromJSON(object.writeFile)
        : undefined,
      deleteFile: isSet(object.deleteFile)
        ? CommitRepositoryChangesRequest_FileOperation_DeleteFile.fromJSON(object.deleteFile)
        : undefined,
    };
  },

  toJSON(message: CommitRepositoryChangesRequest_FileOperation): unknown {
    const obj: any = {};
    if (message.writeFile !== undefined) {
      obj.writeFile = CommitRepositoryChangesRequest_FileOperation_WriteFile.toJSON(message.writeFile);
    }
    if (message.deleteFile !== undefined) {
      obj.deleteFile = CommitRepositoryChangesRequest_FileOperation_DeleteFile.toJSON(message.deleteFile);
    }
    return obj;
  },

  create(
    base?: DeepPartial<CommitRepositoryChangesRequest_FileOperation>,
  ): CommitRepositoryChangesRequest_FileOperation {
    return CommitRepositoryChangesRequest_FileOperation.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CommitRepositoryChangesRequest_FileOperation>,
  ): CommitRepositoryChangesRequest_FileOperation {
    const message = createBaseCommitRepositoryChangesRequest_FileOperation();
    message.writeFile = (object.writeFile !== undefined && object.writeFile !== null)
      ? CommitRepositoryChangesRequest_FileOperation_WriteFile.fromPartial(object.writeFile)
      : undefined;
    message.deleteFile = (object.deleteFile !== undefined && object.deleteFile !== null)
      ? CommitRepositoryChangesRequest_FileOperation_DeleteFile.fromPartial(object.deleteFile)
      : undefined;
    return message;
  },
};

function createBaseCommitRepositoryChangesRequest_FileOperation_WriteFile(): CommitRepositoryChangesRequest_FileOperation_WriteFile {
  return { contents: Buffer.alloc(0) };
}

export const CommitRepositoryChangesRequest_FileOperation_WriteFile: MessageFns<
  CommitRepositoryChangesRequest_FileOperation_WriteFile
> = {
  encode(
    message: CommitRepositoryChangesRequest_FileOperation_WriteFile,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.contents.length !== 0) {
      writer.uint32(10).bytes(message.contents);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRepositoryChangesRequest_FileOperation_WriteFile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRepositoryChangesRequest_FileOperation_WriteFile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.contents = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitRepositoryChangesRequest_FileOperation_WriteFile {
    return { contents: isSet(object.contents) ? Buffer.from(bytesFromBase64(object.contents)) : Buffer.alloc(0) };
  },

  toJSON(message: CommitRepositoryChangesRequest_FileOperation_WriteFile): unknown {
    const obj: any = {};
    if (message.contents.length !== 0) {
      obj.contents = base64FromBytes(message.contents);
    }
    return obj;
  },

  create(
    base?: DeepPartial<CommitRepositoryChangesRequest_FileOperation_WriteFile>,
  ): CommitRepositoryChangesRequest_FileOperation_WriteFile {
    return CommitRepositoryChangesRequest_FileOperation_WriteFile.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CommitRepositoryChangesRequest_FileOperation_WriteFile>,
  ): CommitRepositoryChangesRequest_FileOperation_WriteFile {
    const message = createBaseCommitRepositoryChangesRequest_FileOperation_WriteFile();
    message.contents = object.contents ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCommitRepositoryChangesRequest_FileOperation_DeleteFile(): CommitRepositoryChangesRequest_FileOperation_DeleteFile {
  return {};
}

export const CommitRepositoryChangesRequest_FileOperation_DeleteFile: MessageFns<
  CommitRepositoryChangesRequest_FileOperation_DeleteFile
> = {
  encode(
    _: CommitRepositoryChangesRequest_FileOperation_DeleteFile,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRepositoryChangesRequest_FileOperation_DeleteFile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRepositoryChangesRequest_FileOperation_DeleteFile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CommitRepositoryChangesRequest_FileOperation_DeleteFile {
    return {};
  },

  toJSON(_: CommitRepositoryChangesRequest_FileOperation_DeleteFile): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<CommitRepositoryChangesRequest_FileOperation_DeleteFile>,
  ): CommitRepositoryChangesRequest_FileOperation_DeleteFile {
    return CommitRepositoryChangesRequest_FileOperation_DeleteFile.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<CommitRepositoryChangesRequest_FileOperation_DeleteFile>,
  ): CommitRepositoryChangesRequest_FileOperation_DeleteFile {
    const message = createBaseCommitRepositoryChangesRequest_FileOperation_DeleteFile();
    return message;
  },
};

function createBaseCommitRepositoryChangesRequest_FileOperationsEntry(): CommitRepositoryChangesRequest_FileOperationsEntry {
  return { key: "", value: undefined };
}

export const CommitRepositoryChangesRequest_FileOperationsEntry: MessageFns<
  CommitRepositoryChangesRequest_FileOperationsEntry
> = {
  encode(
    message: CommitRepositoryChangesRequest_FileOperationsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      CommitRepositoryChangesRequest_FileOperation.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitRepositoryChangesRequest_FileOperationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitRepositoryChangesRequest_FileOperationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = CommitRepositoryChangesRequest_FileOperation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitRepositoryChangesRequest_FileOperationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? CommitRepositoryChangesRequest_FileOperation.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: CommitRepositoryChangesRequest_FileOperationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = CommitRepositoryChangesRequest_FileOperation.toJSON(message.value);
    }
    return obj;
  },

  create(
    base?: DeepPartial<CommitRepositoryChangesRequest_FileOperationsEntry>,
  ): CommitRepositoryChangesRequest_FileOperationsEntry {
    return CommitRepositoryChangesRequest_FileOperationsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CommitRepositoryChangesRequest_FileOperationsEntry>,
  ): CommitRepositoryChangesRequest_FileOperationsEntry {
    const message = createBaseCommitRepositoryChangesRequest_FileOperationsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? CommitRepositoryChangesRequest_FileOperation.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseReadRepositoryFileRequest(): ReadRepositoryFileRequest {
  return { name: "", commitSha: "", path: "" };
}

export const ReadRepositoryFileRequest: MessageFns<ReadRepositoryFileRequest> = {
  encode(message: ReadRepositoryFileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.commitSha !== "") {
      writer.uint32(18).string(message.commitSha);
    }
    if (message.path !== "") {
      writer.uint32(26).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadRepositoryFileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadRepositoryFileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadRepositoryFileRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      commitSha: isSet(object.commitSha) ? globalThis.String(object.commitSha) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: ReadRepositoryFileRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.commitSha !== "") {
      obj.commitSha = message.commitSha;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<ReadRepositoryFileRequest>): ReadRepositoryFileRequest {
    return ReadRepositoryFileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadRepositoryFileRequest>): ReadRepositoryFileRequest {
    const message = createBaseReadRepositoryFileRequest();
    message.name = object.name ?? "";
    message.commitSha = object.commitSha ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseReadRepositoryFileResponse(): ReadRepositoryFileResponse {
  return { contents: Buffer.alloc(0) };
}

export const ReadRepositoryFileResponse: MessageFns<ReadRepositoryFileResponse> = {
  encode(message: ReadRepositoryFileResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.contents.length !== 0) {
      writer.uint32(10).bytes(message.contents);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadRepositoryFileResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadRepositoryFileResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.contents = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadRepositoryFileResponse {
    return { contents: isSet(object.contents) ? Buffer.from(bytesFromBase64(object.contents)) : Buffer.alloc(0) };
  },

  toJSON(message: ReadRepositoryFileResponse): unknown {
    const obj: any = {};
    if (message.contents.length !== 0) {
      obj.contents = base64FromBytes(message.contents);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadRepositoryFileResponse>): ReadRepositoryFileResponse {
    return ReadRepositoryFileResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadRepositoryFileResponse>): ReadRepositoryFileResponse {
    const message = createBaseReadRepositoryFileResponse();
    message.contents = object.contents ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseQueryRepositoryDirectoryContentsRequest(): QueryRepositoryDirectoryContentsRequest {
  return { name: "", commitSha: "", path: "", pageSize: 0, pageToken: "" };
}

export const QueryRepositoryDirectoryContentsRequest: MessageFns<QueryRepositoryDirectoryContentsRequest> = {
  encode(message: QueryRepositoryDirectoryContentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.commitSha !== "") {
      writer.uint32(18).string(message.commitSha);
    }
    if (message.path !== "") {
      writer.uint32(26).string(message.path);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryRepositoryDirectoryContentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryRepositoryDirectoryContentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.path = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryRepositoryDirectoryContentsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      commitSha: isSet(object.commitSha) ? globalThis.String(object.commitSha) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: QueryRepositoryDirectoryContentsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.commitSha !== "") {
      obj.commitSha = message.commitSha;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryRepositoryDirectoryContentsRequest>): QueryRepositoryDirectoryContentsRequest {
    return QueryRepositoryDirectoryContentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryRepositoryDirectoryContentsRequest>): QueryRepositoryDirectoryContentsRequest {
    const message = createBaseQueryRepositoryDirectoryContentsRequest();
    message.name = object.name ?? "";
    message.commitSha = object.commitSha ?? "";
    message.path = object.path ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseQueryRepositoryDirectoryContentsResponse(): QueryRepositoryDirectoryContentsResponse {
  return { directoryEntries: [], nextPageToken: "" };
}

export const QueryRepositoryDirectoryContentsResponse: MessageFns<QueryRepositoryDirectoryContentsResponse> = {
  encode(message: QueryRepositoryDirectoryContentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.directoryEntries) {
      DirectoryEntry.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryRepositoryDirectoryContentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryRepositoryDirectoryContentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.directoryEntries.push(DirectoryEntry.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryRepositoryDirectoryContentsResponse {
    return {
      directoryEntries: globalThis.Array.isArray(object?.directoryEntries)
        ? object.directoryEntries.map((e: any) => DirectoryEntry.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: QueryRepositoryDirectoryContentsResponse): unknown {
    const obj: any = {};
    if (message.directoryEntries?.length) {
      obj.directoryEntries = message.directoryEntries.map((e) => DirectoryEntry.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryRepositoryDirectoryContentsResponse>): QueryRepositoryDirectoryContentsResponse {
    return QueryRepositoryDirectoryContentsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryRepositoryDirectoryContentsResponse>): QueryRepositoryDirectoryContentsResponse {
    const message = createBaseQueryRepositoryDirectoryContentsResponse();
    message.directoryEntries = object.directoryEntries?.map((e) => DirectoryEntry.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseFetchRepositoryHistoryRequest(): FetchRepositoryHistoryRequest {
  return { name: "", pageSize: 0, pageToken: "" };
}

export const FetchRepositoryHistoryRequest: MessageFns<FetchRepositoryHistoryRequest> = {
  encode(message: FetchRepositoryHistoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchRepositoryHistoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchRepositoryHistoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchRepositoryHistoryRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: FetchRepositoryHistoryRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchRepositoryHistoryRequest>): FetchRepositoryHistoryRequest {
    return FetchRepositoryHistoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchRepositoryHistoryRequest>): FetchRepositoryHistoryRequest {
    const message = createBaseFetchRepositoryHistoryRequest();
    message.name = object.name ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseFetchRepositoryHistoryResponse(): FetchRepositoryHistoryResponse {
  return { commits: [], nextPageToken: "" };
}

export const FetchRepositoryHistoryResponse: MessageFns<FetchRepositoryHistoryResponse> = {
  encode(message: FetchRepositoryHistoryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.commits) {
      CommitLogEntry.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchRepositoryHistoryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchRepositoryHistoryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.commits.push(CommitLogEntry.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchRepositoryHistoryResponse {
    return {
      commits: globalThis.Array.isArray(object?.commits)
        ? object.commits.map((e: any) => CommitLogEntry.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: FetchRepositoryHistoryResponse): unknown {
    const obj: any = {};
    if (message.commits?.length) {
      obj.commits = message.commits.map((e) => CommitLogEntry.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchRepositoryHistoryResponse>): FetchRepositoryHistoryResponse {
    return FetchRepositoryHistoryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchRepositoryHistoryResponse>): FetchRepositoryHistoryResponse {
    const message = createBaseFetchRepositoryHistoryResponse();
    message.commits = object.commits?.map((e) => CommitLogEntry.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCommitLogEntry(): CommitLogEntry {
  return { commitTime: undefined, commitSha: "", author: undefined, commitMessage: "" };
}

export const CommitLogEntry: MessageFns<CommitLogEntry> = {
  encode(message: CommitLogEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.commitTime !== undefined) {
      Timestamp.encode(toTimestamp(message.commitTime), writer.uint32(10).fork()).join();
    }
    if (message.commitSha !== "") {
      writer.uint32(18).string(message.commitSha);
    }
    if (message.author !== undefined) {
      CommitAuthor.encode(message.author, writer.uint32(26).fork()).join();
    }
    if (message.commitMessage !== "") {
      writer.uint32(34).string(message.commitMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitLogEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitLogEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.commitTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.author = CommitAuthor.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.commitMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitLogEntry {
    return {
      commitTime: isSet(object.commitTime) ? fromJsonTimestamp(object.commitTime) : undefined,
      commitSha: isSet(object.commitSha) ? globalThis.String(object.commitSha) : "",
      author: isSet(object.author) ? CommitAuthor.fromJSON(object.author) : undefined,
      commitMessage: isSet(object.commitMessage) ? globalThis.String(object.commitMessage) : "",
    };
  },

  toJSON(message: CommitLogEntry): unknown {
    const obj: any = {};
    if (message.commitTime !== undefined) {
      obj.commitTime = message.commitTime.toISOString();
    }
    if (message.commitSha !== "") {
      obj.commitSha = message.commitSha;
    }
    if (message.author !== undefined) {
      obj.author = CommitAuthor.toJSON(message.author);
    }
    if (message.commitMessage !== "") {
      obj.commitMessage = message.commitMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<CommitLogEntry>): CommitLogEntry {
    return CommitLogEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitLogEntry>): CommitLogEntry {
    const message = createBaseCommitLogEntry();
    message.commitTime = object.commitTime ?? undefined;
    message.commitSha = object.commitSha ?? "";
    message.author = (object.author !== undefined && object.author !== null)
      ? CommitAuthor.fromPartial(object.author)
      : undefined;
    message.commitMessage = object.commitMessage ?? "";
    return message;
  },
};

function createBaseCommitMetadata(): CommitMetadata {
  return { author: undefined, commitMessage: "" };
}

export const CommitMetadata: MessageFns<CommitMetadata> = {
  encode(message: CommitMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.author !== undefined) {
      CommitAuthor.encode(message.author, writer.uint32(10).fork()).join();
    }
    if (message.commitMessage !== "") {
      writer.uint32(18).string(message.commitMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.author = CommitAuthor.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitMetadata {
    return {
      author: isSet(object.author) ? CommitAuthor.fromJSON(object.author) : undefined,
      commitMessage: isSet(object.commitMessage) ? globalThis.String(object.commitMessage) : "",
    };
  },

  toJSON(message: CommitMetadata): unknown {
    const obj: any = {};
    if (message.author !== undefined) {
      obj.author = CommitAuthor.toJSON(message.author);
    }
    if (message.commitMessage !== "") {
      obj.commitMessage = message.commitMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<CommitMetadata>): CommitMetadata {
    return CommitMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitMetadata>): CommitMetadata {
    const message = createBaseCommitMetadata();
    message.author = (object.author !== undefined && object.author !== null)
      ? CommitAuthor.fromPartial(object.author)
      : undefined;
    message.commitMessage = object.commitMessage ?? "";
    return message;
  },
};

function createBaseComputeRepositoryAccessTokenStatusRequest(): ComputeRepositoryAccessTokenStatusRequest {
  return { name: "" };
}

export const ComputeRepositoryAccessTokenStatusRequest: MessageFns<ComputeRepositoryAccessTokenStatusRequest> = {
  encode(message: ComputeRepositoryAccessTokenStatusRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeRepositoryAccessTokenStatusRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeRepositoryAccessTokenStatusRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeRepositoryAccessTokenStatusRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: ComputeRepositoryAccessTokenStatusRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<ComputeRepositoryAccessTokenStatusRequest>): ComputeRepositoryAccessTokenStatusRequest {
    return ComputeRepositoryAccessTokenStatusRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ComputeRepositoryAccessTokenStatusRequest>,
  ): ComputeRepositoryAccessTokenStatusRequest {
    const message = createBaseComputeRepositoryAccessTokenStatusRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseComputeRepositoryAccessTokenStatusResponse(): ComputeRepositoryAccessTokenStatusResponse {
  return { tokenStatus: 0 };
}

export const ComputeRepositoryAccessTokenStatusResponse: MessageFns<ComputeRepositoryAccessTokenStatusResponse> = {
  encode(message: ComputeRepositoryAccessTokenStatusResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tokenStatus !== 0) {
      writer.uint32(8).int32(message.tokenStatus);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeRepositoryAccessTokenStatusResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeRepositoryAccessTokenStatusResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.tokenStatus = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeRepositoryAccessTokenStatusResponse {
    return {
      tokenStatus: isSet(object.tokenStatus)
        ? computeRepositoryAccessTokenStatusResponse_TokenStatusFromJSON(object.tokenStatus)
        : 0,
    };
  },

  toJSON(message: ComputeRepositoryAccessTokenStatusResponse): unknown {
    const obj: any = {};
    if (message.tokenStatus !== 0) {
      obj.tokenStatus = computeRepositoryAccessTokenStatusResponse_TokenStatusToJSON(message.tokenStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<ComputeRepositoryAccessTokenStatusResponse>): ComputeRepositoryAccessTokenStatusResponse {
    return ComputeRepositoryAccessTokenStatusResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ComputeRepositoryAccessTokenStatusResponse>,
  ): ComputeRepositoryAccessTokenStatusResponse {
    const message = createBaseComputeRepositoryAccessTokenStatusResponse();
    message.tokenStatus = object.tokenStatus ?? 0;
    return message;
  },
};

function createBaseFetchRemoteBranchesRequest(): FetchRemoteBranchesRequest {
  return { name: "" };
}

export const FetchRemoteBranchesRequest: MessageFns<FetchRemoteBranchesRequest> = {
  encode(message: FetchRemoteBranchesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchRemoteBranchesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchRemoteBranchesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchRemoteBranchesRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: FetchRemoteBranchesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchRemoteBranchesRequest>): FetchRemoteBranchesRequest {
    return FetchRemoteBranchesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchRemoteBranchesRequest>): FetchRemoteBranchesRequest {
    const message = createBaseFetchRemoteBranchesRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseFetchRemoteBranchesResponse(): FetchRemoteBranchesResponse {
  return { branches: [] };
}

export const FetchRemoteBranchesResponse: MessageFns<FetchRemoteBranchesResponse> = {
  encode(message: FetchRemoteBranchesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.branches) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchRemoteBranchesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchRemoteBranchesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.branches.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchRemoteBranchesResponse {
    return {
      branches: globalThis.Array.isArray(object?.branches) ? object.branches.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: FetchRemoteBranchesResponse): unknown {
    const obj: any = {};
    if (message.branches?.length) {
      obj.branches = message.branches;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchRemoteBranchesResponse>): FetchRemoteBranchesResponse {
    return FetchRemoteBranchesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchRemoteBranchesResponse>): FetchRemoteBranchesResponse {
    const message = createBaseFetchRemoteBranchesResponse();
    message.branches = object.branches?.map((e) => e) || [];
    return message;
  },
};

function createBaseWorkspace(): Workspace {
  return { name: "" };
}

export const Workspace: MessageFns<Workspace> = {
  encode(message: Workspace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Workspace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkspace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Workspace {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: Workspace): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<Workspace>): Workspace {
    return Workspace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Workspace>): Workspace {
    const message = createBaseWorkspace();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListWorkspacesRequest(): ListWorkspacesRequest {
  return { parent: "", pageSize: 0, pageToken: "", orderBy: "", filter: "" };
}

export const ListWorkspacesRequest: MessageFns<ListWorkspacesRequest> = {
  encode(message: ListWorkspacesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkspacesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkspacesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkspacesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListWorkspacesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkspacesRequest>): ListWorkspacesRequest {
    return ListWorkspacesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkspacesRequest>): ListWorkspacesRequest {
    const message = createBaseListWorkspacesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListWorkspacesResponse(): ListWorkspacesResponse {
  return { workspaces: [], nextPageToken: "", unreachable: [] };
}

export const ListWorkspacesResponse: MessageFns<ListWorkspacesResponse> = {
  encode(message: ListWorkspacesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workspaces) {
      Workspace.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkspacesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkspacesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspaces.push(Workspace.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkspacesResponse {
    return {
      workspaces: globalThis.Array.isArray(object?.workspaces)
        ? object.workspaces.map((e: any) => Workspace.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListWorkspacesResponse): unknown {
    const obj: any = {};
    if (message.workspaces?.length) {
      obj.workspaces = message.workspaces.map((e) => Workspace.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkspacesResponse>): ListWorkspacesResponse {
    return ListWorkspacesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkspacesResponse>): ListWorkspacesResponse {
    const message = createBaseListWorkspacesResponse();
    message.workspaces = object.workspaces?.map((e) => Workspace.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetWorkspaceRequest(): GetWorkspaceRequest {
  return { name: "" };
}

export const GetWorkspaceRequest: MessageFns<GetWorkspaceRequest> = {
  encode(message: GetWorkspaceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetWorkspaceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetWorkspaceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetWorkspaceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetWorkspaceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetWorkspaceRequest>): GetWorkspaceRequest {
    return GetWorkspaceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetWorkspaceRequest>): GetWorkspaceRequest {
    const message = createBaseGetWorkspaceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateWorkspaceRequest(): CreateWorkspaceRequest {
  return { parent: "", workspace: undefined, workspaceId: "" };
}

export const CreateWorkspaceRequest: MessageFns<CreateWorkspaceRequest> = {
  encode(message: CreateWorkspaceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.workspace !== undefined) {
      Workspace.encode(message.workspace, writer.uint32(18).fork()).join();
    }
    if (message.workspaceId !== "") {
      writer.uint32(26).string(message.workspaceId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateWorkspaceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateWorkspaceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workspace = Workspace.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.workspaceId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateWorkspaceRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      workspace: isSet(object.workspace) ? Workspace.fromJSON(object.workspace) : undefined,
      workspaceId: isSet(object.workspaceId) ? globalThis.String(object.workspaceId) : "",
    };
  },

  toJSON(message: CreateWorkspaceRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.workspace !== undefined) {
      obj.workspace = Workspace.toJSON(message.workspace);
    }
    if (message.workspaceId !== "") {
      obj.workspaceId = message.workspaceId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateWorkspaceRequest>): CreateWorkspaceRequest {
    return CreateWorkspaceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateWorkspaceRequest>): CreateWorkspaceRequest {
    const message = createBaseCreateWorkspaceRequest();
    message.parent = object.parent ?? "";
    message.workspace = (object.workspace !== undefined && object.workspace !== null)
      ? Workspace.fromPartial(object.workspace)
      : undefined;
    message.workspaceId = object.workspaceId ?? "";
    return message;
  },
};

function createBaseDeleteWorkspaceRequest(): DeleteWorkspaceRequest {
  return { name: "" };
}

export const DeleteWorkspaceRequest: MessageFns<DeleteWorkspaceRequest> = {
  encode(message: DeleteWorkspaceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteWorkspaceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteWorkspaceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteWorkspaceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteWorkspaceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteWorkspaceRequest>): DeleteWorkspaceRequest {
    return DeleteWorkspaceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteWorkspaceRequest>): DeleteWorkspaceRequest {
    const message = createBaseDeleteWorkspaceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCommitAuthor(): CommitAuthor {
  return { name: "", emailAddress: "" };
}

export const CommitAuthor: MessageFns<CommitAuthor> = {
  encode(message: CommitAuthor, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.emailAddress !== "") {
      writer.uint32(18).string(message.emailAddress);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitAuthor {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitAuthor();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.emailAddress = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitAuthor {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      emailAddress: isSet(object.emailAddress) ? globalThis.String(object.emailAddress) : "",
    };
  },

  toJSON(message: CommitAuthor): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.emailAddress !== "") {
      obj.emailAddress = message.emailAddress;
    }
    return obj;
  },

  create(base?: DeepPartial<CommitAuthor>): CommitAuthor {
    return CommitAuthor.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitAuthor>): CommitAuthor {
    const message = createBaseCommitAuthor();
    message.name = object.name ?? "";
    message.emailAddress = object.emailAddress ?? "";
    return message;
  },
};

function createBasePullGitCommitsRequest(): PullGitCommitsRequest {
  return { name: "", remoteBranch: "", author: undefined };
}

export const PullGitCommitsRequest: MessageFns<PullGitCommitsRequest> = {
  encode(message: PullGitCommitsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.remoteBranch !== "") {
      writer.uint32(18).string(message.remoteBranch);
    }
    if (message.author !== undefined) {
      CommitAuthor.encode(message.author, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PullGitCommitsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePullGitCommitsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.remoteBranch = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.author = CommitAuthor.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PullGitCommitsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      remoteBranch: isSet(object.remoteBranch) ? globalThis.String(object.remoteBranch) : "",
      author: isSet(object.author) ? CommitAuthor.fromJSON(object.author) : undefined,
    };
  },

  toJSON(message: PullGitCommitsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.remoteBranch !== "") {
      obj.remoteBranch = message.remoteBranch;
    }
    if (message.author !== undefined) {
      obj.author = CommitAuthor.toJSON(message.author);
    }
    return obj;
  },

  create(base?: DeepPartial<PullGitCommitsRequest>): PullGitCommitsRequest {
    return PullGitCommitsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PullGitCommitsRequest>): PullGitCommitsRequest {
    const message = createBasePullGitCommitsRequest();
    message.name = object.name ?? "";
    message.remoteBranch = object.remoteBranch ?? "";
    message.author = (object.author !== undefined && object.author !== null)
      ? CommitAuthor.fromPartial(object.author)
      : undefined;
    return message;
  },
};

function createBasePushGitCommitsRequest(): PushGitCommitsRequest {
  return { name: "", remoteBranch: "" };
}

export const PushGitCommitsRequest: MessageFns<PushGitCommitsRequest> = {
  encode(message: PushGitCommitsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.remoteBranch !== "") {
      writer.uint32(18).string(message.remoteBranch);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushGitCommitsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushGitCommitsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.remoteBranch = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PushGitCommitsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      remoteBranch: isSet(object.remoteBranch) ? globalThis.String(object.remoteBranch) : "",
    };
  },

  toJSON(message: PushGitCommitsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.remoteBranch !== "") {
      obj.remoteBranch = message.remoteBranch;
    }
    return obj;
  },

  create(base?: DeepPartial<PushGitCommitsRequest>): PushGitCommitsRequest {
    return PushGitCommitsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PushGitCommitsRequest>): PushGitCommitsRequest {
    const message = createBasePushGitCommitsRequest();
    message.name = object.name ?? "";
    message.remoteBranch = object.remoteBranch ?? "";
    return message;
  },
};

function createBaseFetchFileGitStatusesRequest(): FetchFileGitStatusesRequest {
  return { name: "" };
}

export const FetchFileGitStatusesRequest: MessageFns<FetchFileGitStatusesRequest> = {
  encode(message: FetchFileGitStatusesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchFileGitStatusesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchFileGitStatusesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchFileGitStatusesRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: FetchFileGitStatusesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchFileGitStatusesRequest>): FetchFileGitStatusesRequest {
    return FetchFileGitStatusesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchFileGitStatusesRequest>): FetchFileGitStatusesRequest {
    const message = createBaseFetchFileGitStatusesRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseFetchFileGitStatusesResponse(): FetchFileGitStatusesResponse {
  return { uncommittedFileChanges: [] };
}

export const FetchFileGitStatusesResponse: MessageFns<FetchFileGitStatusesResponse> = {
  encode(message: FetchFileGitStatusesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.uncommittedFileChanges) {
      FetchFileGitStatusesResponse_UncommittedFileChange.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchFileGitStatusesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchFileGitStatusesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uncommittedFileChanges.push(
            FetchFileGitStatusesResponse_UncommittedFileChange.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchFileGitStatusesResponse {
    return {
      uncommittedFileChanges: globalThis.Array.isArray(object?.uncommittedFileChanges)
        ? object.uncommittedFileChanges.map((e: any) => FetchFileGitStatusesResponse_UncommittedFileChange.fromJSON(e))
        : [],
    };
  },

  toJSON(message: FetchFileGitStatusesResponse): unknown {
    const obj: any = {};
    if (message.uncommittedFileChanges?.length) {
      obj.uncommittedFileChanges = message.uncommittedFileChanges.map((e) =>
        FetchFileGitStatusesResponse_UncommittedFileChange.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<FetchFileGitStatusesResponse>): FetchFileGitStatusesResponse {
    return FetchFileGitStatusesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchFileGitStatusesResponse>): FetchFileGitStatusesResponse {
    const message = createBaseFetchFileGitStatusesResponse();
    message.uncommittedFileChanges =
      object.uncommittedFileChanges?.map((e) => FetchFileGitStatusesResponse_UncommittedFileChange.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseFetchFileGitStatusesResponse_UncommittedFileChange(): FetchFileGitStatusesResponse_UncommittedFileChange {
  return { path: "", state: 0 };
}

export const FetchFileGitStatusesResponse_UncommittedFileChange: MessageFns<
  FetchFileGitStatusesResponse_UncommittedFileChange
> = {
  encode(
    message: FetchFileGitStatusesResponse_UncommittedFileChange,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchFileGitStatusesResponse_UncommittedFileChange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchFileGitStatusesResponse_UncommittedFileChange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchFileGitStatusesResponse_UncommittedFileChange {
    return {
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      state: isSet(object.state) ? fetchFileGitStatusesResponse_UncommittedFileChange_StateFromJSON(object.state) : 0,
    };
  },

  toJSON(message: FetchFileGitStatusesResponse_UncommittedFileChange): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.state !== 0) {
      obj.state = fetchFileGitStatusesResponse_UncommittedFileChange_StateToJSON(message.state);
    }
    return obj;
  },

  create(
    base?: DeepPartial<FetchFileGitStatusesResponse_UncommittedFileChange>,
  ): FetchFileGitStatusesResponse_UncommittedFileChange {
    return FetchFileGitStatusesResponse_UncommittedFileChange.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<FetchFileGitStatusesResponse_UncommittedFileChange>,
  ): FetchFileGitStatusesResponse_UncommittedFileChange {
    const message = createBaseFetchFileGitStatusesResponse_UncommittedFileChange();
    message.path = object.path ?? "";
    message.state = object.state ?? 0;
    return message;
  },
};

function createBaseFetchGitAheadBehindRequest(): FetchGitAheadBehindRequest {
  return { name: "", remoteBranch: "" };
}

export const FetchGitAheadBehindRequest: MessageFns<FetchGitAheadBehindRequest> = {
  encode(message: FetchGitAheadBehindRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.remoteBranch !== "") {
      writer.uint32(18).string(message.remoteBranch);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchGitAheadBehindRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchGitAheadBehindRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.remoteBranch = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchGitAheadBehindRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      remoteBranch: isSet(object.remoteBranch) ? globalThis.String(object.remoteBranch) : "",
    };
  },

  toJSON(message: FetchGitAheadBehindRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.remoteBranch !== "") {
      obj.remoteBranch = message.remoteBranch;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchGitAheadBehindRequest>): FetchGitAheadBehindRequest {
    return FetchGitAheadBehindRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchGitAheadBehindRequest>): FetchGitAheadBehindRequest {
    const message = createBaseFetchGitAheadBehindRequest();
    message.name = object.name ?? "";
    message.remoteBranch = object.remoteBranch ?? "";
    return message;
  },
};

function createBaseFetchGitAheadBehindResponse(): FetchGitAheadBehindResponse {
  return { commitsAhead: 0, commitsBehind: 0 };
}

export const FetchGitAheadBehindResponse: MessageFns<FetchGitAheadBehindResponse> = {
  encode(message: FetchGitAheadBehindResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.commitsAhead !== 0) {
      writer.uint32(8).int32(message.commitsAhead);
    }
    if (message.commitsBehind !== 0) {
      writer.uint32(16).int32(message.commitsBehind);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchGitAheadBehindResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchGitAheadBehindResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.commitsAhead = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.commitsBehind = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchGitAheadBehindResponse {
    return {
      commitsAhead: isSet(object.commitsAhead) ? globalThis.Number(object.commitsAhead) : 0,
      commitsBehind: isSet(object.commitsBehind) ? globalThis.Number(object.commitsBehind) : 0,
    };
  },

  toJSON(message: FetchGitAheadBehindResponse): unknown {
    const obj: any = {};
    if (message.commitsAhead !== 0) {
      obj.commitsAhead = Math.round(message.commitsAhead);
    }
    if (message.commitsBehind !== 0) {
      obj.commitsBehind = Math.round(message.commitsBehind);
    }
    return obj;
  },

  create(base?: DeepPartial<FetchGitAheadBehindResponse>): FetchGitAheadBehindResponse {
    return FetchGitAheadBehindResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchGitAheadBehindResponse>): FetchGitAheadBehindResponse {
    const message = createBaseFetchGitAheadBehindResponse();
    message.commitsAhead = object.commitsAhead ?? 0;
    message.commitsBehind = object.commitsBehind ?? 0;
    return message;
  },
};

function createBaseCommitWorkspaceChangesRequest(): CommitWorkspaceChangesRequest {
  return { name: "", author: undefined, commitMessage: "", paths: [] };
}

export const CommitWorkspaceChangesRequest: MessageFns<CommitWorkspaceChangesRequest> = {
  encode(message: CommitWorkspaceChangesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.author !== undefined) {
      CommitAuthor.encode(message.author, writer.uint32(34).fork()).join();
    }
    if (message.commitMessage !== "") {
      writer.uint32(18).string(message.commitMessage);
    }
    for (const v of message.paths) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommitWorkspaceChangesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommitWorkspaceChangesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.author = CommitAuthor.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commitMessage = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.paths.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommitWorkspaceChangesRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      author: isSet(object.author) ? CommitAuthor.fromJSON(object.author) : undefined,
      commitMessage: isSet(object.commitMessage) ? globalThis.String(object.commitMessage) : "",
      paths: globalThis.Array.isArray(object?.paths) ? object.paths.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: CommitWorkspaceChangesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.author !== undefined) {
      obj.author = CommitAuthor.toJSON(message.author);
    }
    if (message.commitMessage !== "") {
      obj.commitMessage = message.commitMessage;
    }
    if (message.paths?.length) {
      obj.paths = message.paths;
    }
    return obj;
  },

  create(base?: DeepPartial<CommitWorkspaceChangesRequest>): CommitWorkspaceChangesRequest {
    return CommitWorkspaceChangesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommitWorkspaceChangesRequest>): CommitWorkspaceChangesRequest {
    const message = createBaseCommitWorkspaceChangesRequest();
    message.name = object.name ?? "";
    message.author = (object.author !== undefined && object.author !== null)
      ? CommitAuthor.fromPartial(object.author)
      : undefined;
    message.commitMessage = object.commitMessage ?? "";
    message.paths = object.paths?.map((e) => e) || [];
    return message;
  },
};

function createBaseResetWorkspaceChangesRequest(): ResetWorkspaceChangesRequest {
  return { name: "", paths: [], clean: false };
}

export const ResetWorkspaceChangesRequest: MessageFns<ResetWorkspaceChangesRequest> = {
  encode(message: ResetWorkspaceChangesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.paths) {
      writer.uint32(18).string(v!);
    }
    if (message.clean !== false) {
      writer.uint32(24).bool(message.clean);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ResetWorkspaceChangesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResetWorkspaceChangesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.paths.push(reader.string());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.clean = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ResetWorkspaceChangesRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      paths: globalThis.Array.isArray(object?.paths) ? object.paths.map((e: any) => globalThis.String(e)) : [],
      clean: isSet(object.clean) ? globalThis.Boolean(object.clean) : false,
    };
  },

  toJSON(message: ResetWorkspaceChangesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.paths?.length) {
      obj.paths = message.paths;
    }
    if (message.clean !== false) {
      obj.clean = message.clean;
    }
    return obj;
  },

  create(base?: DeepPartial<ResetWorkspaceChangesRequest>): ResetWorkspaceChangesRequest {
    return ResetWorkspaceChangesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ResetWorkspaceChangesRequest>): ResetWorkspaceChangesRequest {
    const message = createBaseResetWorkspaceChangesRequest();
    message.name = object.name ?? "";
    message.paths = object.paths?.map((e) => e) || [];
    message.clean = object.clean ?? false;
    return message;
  },
};

function createBaseFetchFileDiffRequest(): FetchFileDiffRequest {
  return { workspace: "", path: "" };
}

export const FetchFileDiffRequest: MessageFns<FetchFileDiffRequest> = {
  encode(message: FetchFileDiffRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchFileDiffRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchFileDiffRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchFileDiffRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: FetchFileDiffRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchFileDiffRequest>): FetchFileDiffRequest {
    return FetchFileDiffRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchFileDiffRequest>): FetchFileDiffRequest {
    const message = createBaseFetchFileDiffRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseFetchFileDiffResponse(): FetchFileDiffResponse {
  return { formattedDiff: "" };
}

export const FetchFileDiffResponse: MessageFns<FetchFileDiffResponse> = {
  encode(message: FetchFileDiffResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.formattedDiff !== "") {
      writer.uint32(10).string(message.formattedDiff);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchFileDiffResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchFileDiffResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.formattedDiff = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchFileDiffResponse {
    return { formattedDiff: isSet(object.formattedDiff) ? globalThis.String(object.formattedDiff) : "" };
  },

  toJSON(message: FetchFileDiffResponse): unknown {
    const obj: any = {};
    if (message.formattedDiff !== "") {
      obj.formattedDiff = message.formattedDiff;
    }
    return obj;
  },

  create(base?: DeepPartial<FetchFileDiffResponse>): FetchFileDiffResponse {
    return FetchFileDiffResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FetchFileDiffResponse>): FetchFileDiffResponse {
    const message = createBaseFetchFileDiffResponse();
    message.formattedDiff = object.formattedDiff ?? "";
    return message;
  },
};

function createBaseQueryDirectoryContentsRequest(): QueryDirectoryContentsRequest {
  return { workspace: "", path: "", pageSize: 0, pageToken: "" };
}

export const QueryDirectoryContentsRequest: MessageFns<QueryDirectoryContentsRequest> = {
  encode(message: QueryDirectoryContentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryDirectoryContentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryDirectoryContentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryDirectoryContentsRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: QueryDirectoryContentsRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryDirectoryContentsRequest>): QueryDirectoryContentsRequest {
    return QueryDirectoryContentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryDirectoryContentsRequest>): QueryDirectoryContentsRequest {
    const message = createBaseQueryDirectoryContentsRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseQueryDirectoryContentsResponse(): QueryDirectoryContentsResponse {
  return { directoryEntries: [], nextPageToken: "" };
}

export const QueryDirectoryContentsResponse: MessageFns<QueryDirectoryContentsResponse> = {
  encode(message: QueryDirectoryContentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.directoryEntries) {
      DirectoryEntry.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryDirectoryContentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryDirectoryContentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.directoryEntries.push(DirectoryEntry.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryDirectoryContentsResponse {
    return {
      directoryEntries: globalThis.Array.isArray(object?.directoryEntries)
        ? object.directoryEntries.map((e: any) => DirectoryEntry.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: QueryDirectoryContentsResponse): unknown {
    const obj: any = {};
    if (message.directoryEntries?.length) {
      obj.directoryEntries = message.directoryEntries.map((e) => DirectoryEntry.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryDirectoryContentsResponse>): QueryDirectoryContentsResponse {
    return QueryDirectoryContentsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryDirectoryContentsResponse>): QueryDirectoryContentsResponse {
    const message = createBaseQueryDirectoryContentsResponse();
    message.directoryEntries = object.directoryEntries?.map((e) => DirectoryEntry.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDirectoryEntry(): DirectoryEntry {
  return { file: undefined, directory: undefined };
}

export const DirectoryEntry: MessageFns<DirectoryEntry> = {
  encode(message: DirectoryEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.file !== undefined) {
      writer.uint32(10).string(message.file);
    }
    if (message.directory !== undefined) {
      writer.uint32(18).string(message.directory);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DirectoryEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDirectoryEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.file = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.directory = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DirectoryEntry {
    return {
      file: isSet(object.file) ? globalThis.String(object.file) : undefined,
      directory: isSet(object.directory) ? globalThis.String(object.directory) : undefined,
    };
  },

  toJSON(message: DirectoryEntry): unknown {
    const obj: any = {};
    if (message.file !== undefined) {
      obj.file = message.file;
    }
    if (message.directory !== undefined) {
      obj.directory = message.directory;
    }
    return obj;
  },

  create(base?: DeepPartial<DirectoryEntry>): DirectoryEntry {
    return DirectoryEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DirectoryEntry>): DirectoryEntry {
    const message = createBaseDirectoryEntry();
    message.file = object.file ?? undefined;
    message.directory = object.directory ?? undefined;
    return message;
  },
};

function createBaseMakeDirectoryRequest(): MakeDirectoryRequest {
  return { workspace: "", path: "" };
}

export const MakeDirectoryRequest: MessageFns<MakeDirectoryRequest> = {
  encode(message: MakeDirectoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MakeDirectoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMakeDirectoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MakeDirectoryRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: MakeDirectoryRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<MakeDirectoryRequest>): MakeDirectoryRequest {
    return MakeDirectoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MakeDirectoryRequest>): MakeDirectoryRequest {
    const message = createBaseMakeDirectoryRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseMakeDirectoryResponse(): MakeDirectoryResponse {
  return {};
}

export const MakeDirectoryResponse: MessageFns<MakeDirectoryResponse> = {
  encode(_: MakeDirectoryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MakeDirectoryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMakeDirectoryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): MakeDirectoryResponse {
    return {};
  },

  toJSON(_: MakeDirectoryResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<MakeDirectoryResponse>): MakeDirectoryResponse {
    return MakeDirectoryResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<MakeDirectoryResponse>): MakeDirectoryResponse {
    const message = createBaseMakeDirectoryResponse();
    return message;
  },
};

function createBaseRemoveDirectoryRequest(): RemoveDirectoryRequest {
  return { workspace: "", path: "" };
}

export const RemoveDirectoryRequest: MessageFns<RemoveDirectoryRequest> = {
  encode(message: RemoveDirectoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RemoveDirectoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRemoveDirectoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RemoveDirectoryRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: RemoveDirectoryRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<RemoveDirectoryRequest>): RemoveDirectoryRequest {
    return RemoveDirectoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RemoveDirectoryRequest>): RemoveDirectoryRequest {
    const message = createBaseRemoveDirectoryRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseMoveDirectoryRequest(): MoveDirectoryRequest {
  return { workspace: "", path: "", newPath: "" };
}

export const MoveDirectoryRequest: MessageFns<MoveDirectoryRequest> = {
  encode(message: MoveDirectoryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.newPath !== "") {
      writer.uint32(26).string(message.newPath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveDirectoryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveDirectoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.newPath = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MoveDirectoryRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      newPath: isSet(object.newPath) ? globalThis.String(object.newPath) : "",
    };
  },

  toJSON(message: MoveDirectoryRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.newPath !== "") {
      obj.newPath = message.newPath;
    }
    return obj;
  },

  create(base?: DeepPartial<MoveDirectoryRequest>): MoveDirectoryRequest {
    return MoveDirectoryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MoveDirectoryRequest>): MoveDirectoryRequest {
    const message = createBaseMoveDirectoryRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    message.newPath = object.newPath ?? "";
    return message;
  },
};

function createBaseMoveDirectoryResponse(): MoveDirectoryResponse {
  return {};
}

export const MoveDirectoryResponse: MessageFns<MoveDirectoryResponse> = {
  encode(_: MoveDirectoryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveDirectoryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveDirectoryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): MoveDirectoryResponse {
    return {};
  },

  toJSON(_: MoveDirectoryResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<MoveDirectoryResponse>): MoveDirectoryResponse {
    return MoveDirectoryResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<MoveDirectoryResponse>): MoveDirectoryResponse {
    const message = createBaseMoveDirectoryResponse();
    return message;
  },
};

function createBaseReadFileRequest(): ReadFileRequest {
  return { workspace: "", path: "" };
}

export const ReadFileRequest: MessageFns<ReadFileRequest> = {
  encode(message: ReadFileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadFileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadFileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadFileRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: ReadFileRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<ReadFileRequest>): ReadFileRequest {
    return ReadFileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadFileRequest>): ReadFileRequest {
    const message = createBaseReadFileRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseReadFileResponse(): ReadFileResponse {
  return { fileContents: Buffer.alloc(0) };
}

export const ReadFileResponse: MessageFns<ReadFileResponse> = {
  encode(message: ReadFileResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.fileContents.length !== 0) {
      writer.uint32(10).bytes(message.fileContents);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadFileResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadFileResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fileContents = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadFileResponse {
    return {
      fileContents: isSet(object.fileContents) ? Buffer.from(bytesFromBase64(object.fileContents)) : Buffer.alloc(0),
    };
  },

  toJSON(message: ReadFileResponse): unknown {
    const obj: any = {};
    if (message.fileContents.length !== 0) {
      obj.fileContents = base64FromBytes(message.fileContents);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadFileResponse>): ReadFileResponse {
    return ReadFileResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadFileResponse>): ReadFileResponse {
    const message = createBaseReadFileResponse();
    message.fileContents = object.fileContents ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseRemoveFileRequest(): RemoveFileRequest {
  return { workspace: "", path: "" };
}

export const RemoveFileRequest: MessageFns<RemoveFileRequest> = {
  encode(message: RemoveFileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RemoveFileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRemoveFileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RemoveFileRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: RemoveFileRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<RemoveFileRequest>): RemoveFileRequest {
    return RemoveFileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RemoveFileRequest>): RemoveFileRequest {
    const message = createBaseRemoveFileRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseMoveFileRequest(): MoveFileRequest {
  return { workspace: "", path: "", newPath: "" };
}

export const MoveFileRequest: MessageFns<MoveFileRequest> = {
  encode(message: MoveFileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.newPath !== "") {
      writer.uint32(26).string(message.newPath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveFileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveFileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.newPath = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MoveFileRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      newPath: isSet(object.newPath) ? globalThis.String(object.newPath) : "",
    };
  },

  toJSON(message: MoveFileRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.newPath !== "") {
      obj.newPath = message.newPath;
    }
    return obj;
  },

  create(base?: DeepPartial<MoveFileRequest>): MoveFileRequest {
    return MoveFileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MoveFileRequest>): MoveFileRequest {
    const message = createBaseMoveFileRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    message.newPath = object.newPath ?? "";
    return message;
  },
};

function createBaseMoveFileResponse(): MoveFileResponse {
  return {};
}

export const MoveFileResponse: MessageFns<MoveFileResponse> = {
  encode(_: MoveFileResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MoveFileResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMoveFileResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): MoveFileResponse {
    return {};
  },

  toJSON(_: MoveFileResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<MoveFileResponse>): MoveFileResponse {
    return MoveFileResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<MoveFileResponse>): MoveFileResponse {
    const message = createBaseMoveFileResponse();
    return message;
  },
};

function createBaseWriteFileRequest(): WriteFileRequest {
  return { workspace: "", path: "", contents: Buffer.alloc(0) };
}

export const WriteFileRequest: MessageFns<WriteFileRequest> = {
  encode(message: WriteFileRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.contents.length !== 0) {
      writer.uint32(26).bytes(message.contents);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteFileRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteFileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.contents = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteFileRequest {
    return {
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      contents: isSet(object.contents) ? Buffer.from(bytesFromBase64(object.contents)) : Buffer.alloc(0),
    };
  },

  toJSON(message: WriteFileRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.contents.length !== 0) {
      obj.contents = base64FromBytes(message.contents);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteFileRequest>): WriteFileRequest {
    return WriteFileRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteFileRequest>): WriteFileRequest {
    const message = createBaseWriteFileRequest();
    message.workspace = object.workspace ?? "";
    message.path = object.path ?? "";
    message.contents = object.contents ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseWriteFileResponse(): WriteFileResponse {
  return {};
}

export const WriteFileResponse: MessageFns<WriteFileResponse> = {
  encode(_: WriteFileResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteFileResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteFileResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): WriteFileResponse {
    return {};
  },

  toJSON(_: WriteFileResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<WriteFileResponse>): WriteFileResponse {
    return WriteFileResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<WriteFileResponse>): WriteFileResponse {
    const message = createBaseWriteFileResponse();
    return message;
  },
};

function createBaseInstallNpmPackagesRequest(): InstallNpmPackagesRequest {
  return { workspace: "" };
}

export const InstallNpmPackagesRequest: MessageFns<InstallNpmPackagesRequest> = {
  encode(message: InstallNpmPackagesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workspace !== "") {
      writer.uint32(10).string(message.workspace);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstallNpmPackagesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstallNpmPackagesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workspace = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InstallNpmPackagesRequest {
    return { workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : "" };
  },

  toJSON(message: InstallNpmPackagesRequest): unknown {
    const obj: any = {};
    if (message.workspace !== "") {
      obj.workspace = message.workspace;
    }
    return obj;
  },

  create(base?: DeepPartial<InstallNpmPackagesRequest>): InstallNpmPackagesRequest {
    return InstallNpmPackagesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InstallNpmPackagesRequest>): InstallNpmPackagesRequest {
    const message = createBaseInstallNpmPackagesRequest();
    message.workspace = object.workspace ?? "";
    return message;
  },
};

function createBaseInstallNpmPackagesResponse(): InstallNpmPackagesResponse {
  return {};
}

export const InstallNpmPackagesResponse: MessageFns<InstallNpmPackagesResponse> = {
  encode(_: InstallNpmPackagesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstallNpmPackagesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstallNpmPackagesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): InstallNpmPackagesResponse {
    return {};
  },

  toJSON(_: InstallNpmPackagesResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<InstallNpmPackagesResponse>): InstallNpmPackagesResponse {
    return InstallNpmPackagesResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<InstallNpmPackagesResponse>): InstallNpmPackagesResponse {
    const message = createBaseInstallNpmPackagesResponse();
    return message;
  },
};

function createBaseReleaseConfig(): ReleaseConfig {
  return {
    name: "",
    gitCommitish: "",
    codeCompilationConfig: undefined,
    cronSchedule: "",
    timeZone: "",
    recentScheduledReleaseRecords: [],
    releaseCompilationResult: "",
  };
}

export const ReleaseConfig: MessageFns<ReleaseConfig> = {
  encode(message: ReleaseConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.gitCommitish !== "") {
      writer.uint32(18).string(message.gitCommitish);
    }
    if (message.codeCompilationConfig !== undefined) {
      CodeCompilationConfig.encode(message.codeCompilationConfig, writer.uint32(26).fork()).join();
    }
    if (message.cronSchedule !== "") {
      writer.uint32(34).string(message.cronSchedule);
    }
    if (message.timeZone !== "") {
      writer.uint32(58).string(message.timeZone);
    }
    for (const v of message.recentScheduledReleaseRecords) {
      ReleaseConfig_ScheduledReleaseRecord.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.releaseCompilationResult !== "") {
      writer.uint32(50).string(message.releaseCompilationResult);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReleaseConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReleaseConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.gitCommitish = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.codeCompilationConfig = CodeCompilationConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cronSchedule = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.timeZone = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.recentScheduledReleaseRecords.push(
            ReleaseConfig_ScheduledReleaseRecord.decode(reader, reader.uint32()),
          );
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.releaseCompilationResult = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReleaseConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      gitCommitish: isSet(object.gitCommitish) ? globalThis.String(object.gitCommitish) : "",
      codeCompilationConfig: isSet(object.codeCompilationConfig)
        ? CodeCompilationConfig.fromJSON(object.codeCompilationConfig)
        : undefined,
      cronSchedule: isSet(object.cronSchedule) ? globalThis.String(object.cronSchedule) : "",
      timeZone: isSet(object.timeZone) ? globalThis.String(object.timeZone) : "",
      recentScheduledReleaseRecords: globalThis.Array.isArray(object?.recentScheduledReleaseRecords)
        ? object.recentScheduledReleaseRecords.map((e: any) => ReleaseConfig_ScheduledReleaseRecord.fromJSON(e))
        : [],
      releaseCompilationResult: isSet(object.releaseCompilationResult)
        ? globalThis.String(object.releaseCompilationResult)
        : "",
    };
  },

  toJSON(message: ReleaseConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.gitCommitish !== "") {
      obj.gitCommitish = message.gitCommitish;
    }
    if (message.codeCompilationConfig !== undefined) {
      obj.codeCompilationConfig = CodeCompilationConfig.toJSON(message.codeCompilationConfig);
    }
    if (message.cronSchedule !== "") {
      obj.cronSchedule = message.cronSchedule;
    }
    if (message.timeZone !== "") {
      obj.timeZone = message.timeZone;
    }
    if (message.recentScheduledReleaseRecords?.length) {
      obj.recentScheduledReleaseRecords = message.recentScheduledReleaseRecords.map((e) =>
        ReleaseConfig_ScheduledReleaseRecord.toJSON(e)
      );
    }
    if (message.releaseCompilationResult !== "") {
      obj.releaseCompilationResult = message.releaseCompilationResult;
    }
    return obj;
  },

  create(base?: DeepPartial<ReleaseConfig>): ReleaseConfig {
    return ReleaseConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReleaseConfig>): ReleaseConfig {
    const message = createBaseReleaseConfig();
    message.name = object.name ?? "";
    message.gitCommitish = object.gitCommitish ?? "";
    message.codeCompilationConfig =
      (object.codeCompilationConfig !== undefined && object.codeCompilationConfig !== null)
        ? CodeCompilationConfig.fromPartial(object.codeCompilationConfig)
        : undefined;
    message.cronSchedule = object.cronSchedule ?? "";
    message.timeZone = object.timeZone ?? "";
    message.recentScheduledReleaseRecords =
      object.recentScheduledReleaseRecords?.map((e) => ReleaseConfig_ScheduledReleaseRecord.fromPartial(e)) || [];
    message.releaseCompilationResult = object.releaseCompilationResult ?? "";
    return message;
  },
};

function createBaseReleaseConfig_ScheduledReleaseRecord(): ReleaseConfig_ScheduledReleaseRecord {
  return { releaseTime: undefined, compilationResult: undefined, errorStatus: undefined };
}

export const ReleaseConfig_ScheduledReleaseRecord: MessageFns<ReleaseConfig_ScheduledReleaseRecord> = {
  encode(message: ReleaseConfig_ScheduledReleaseRecord, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.releaseTime !== undefined) {
      Timestamp.encode(toTimestamp(message.releaseTime), writer.uint32(10).fork()).join();
    }
    if (message.compilationResult !== undefined) {
      writer.uint32(18).string(message.compilationResult);
    }
    if (message.errorStatus !== undefined) {
      Status.encode(message.errorStatus, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReleaseConfig_ScheduledReleaseRecord {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReleaseConfig_ScheduledReleaseRecord();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.releaseTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.compilationResult = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.errorStatus = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReleaseConfig_ScheduledReleaseRecord {
    return {
      releaseTime: isSet(object.releaseTime) ? fromJsonTimestamp(object.releaseTime) : undefined,
      compilationResult: isSet(object.compilationResult) ? globalThis.String(object.compilationResult) : undefined,
      errorStatus: isSet(object.errorStatus) ? Status.fromJSON(object.errorStatus) : undefined,
    };
  },

  toJSON(message: ReleaseConfig_ScheduledReleaseRecord): unknown {
    const obj: any = {};
    if (message.releaseTime !== undefined) {
      obj.releaseTime = message.releaseTime.toISOString();
    }
    if (message.compilationResult !== undefined) {
      obj.compilationResult = message.compilationResult;
    }
    if (message.errorStatus !== undefined) {
      obj.errorStatus = Status.toJSON(message.errorStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<ReleaseConfig_ScheduledReleaseRecord>): ReleaseConfig_ScheduledReleaseRecord {
    return ReleaseConfig_ScheduledReleaseRecord.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReleaseConfig_ScheduledReleaseRecord>): ReleaseConfig_ScheduledReleaseRecord {
    const message = createBaseReleaseConfig_ScheduledReleaseRecord();
    message.releaseTime = object.releaseTime ?? undefined;
    message.compilationResult = object.compilationResult ?? undefined;
    message.errorStatus = (object.errorStatus !== undefined && object.errorStatus !== null)
      ? Status.fromPartial(object.errorStatus)
      : undefined;
    return message;
  },
};

function createBaseListReleaseConfigsRequest(): ListReleaseConfigsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListReleaseConfigsRequest: MessageFns<ListReleaseConfigsRequest> = {
  encode(message: ListReleaseConfigsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListReleaseConfigsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListReleaseConfigsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListReleaseConfigsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListReleaseConfigsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListReleaseConfigsRequest>): ListReleaseConfigsRequest {
    return ListReleaseConfigsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListReleaseConfigsRequest>): ListReleaseConfigsRequest {
    const message = createBaseListReleaseConfigsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListReleaseConfigsResponse(): ListReleaseConfigsResponse {
  return { releaseConfigs: [], nextPageToken: "", unreachable: [] };
}

export const ListReleaseConfigsResponse: MessageFns<ListReleaseConfigsResponse> = {
  encode(message: ListReleaseConfigsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.releaseConfigs) {
      ReleaseConfig.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListReleaseConfigsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListReleaseConfigsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.releaseConfigs.push(ReleaseConfig.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListReleaseConfigsResponse {
    return {
      releaseConfigs: globalThis.Array.isArray(object?.releaseConfigs)
        ? object.releaseConfigs.map((e: any) => ReleaseConfig.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListReleaseConfigsResponse): unknown {
    const obj: any = {};
    if (message.releaseConfigs?.length) {
      obj.releaseConfigs = message.releaseConfigs.map((e) => ReleaseConfig.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListReleaseConfigsResponse>): ListReleaseConfigsResponse {
    return ListReleaseConfigsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListReleaseConfigsResponse>): ListReleaseConfigsResponse {
    const message = createBaseListReleaseConfigsResponse();
    message.releaseConfigs = object.releaseConfigs?.map((e) => ReleaseConfig.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetReleaseConfigRequest(): GetReleaseConfigRequest {
  return { name: "" };
}

export const GetReleaseConfigRequest: MessageFns<GetReleaseConfigRequest> = {
  encode(message: GetReleaseConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetReleaseConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetReleaseConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetReleaseConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetReleaseConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetReleaseConfigRequest>): GetReleaseConfigRequest {
    return GetReleaseConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetReleaseConfigRequest>): GetReleaseConfigRequest {
    const message = createBaseGetReleaseConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateReleaseConfigRequest(): CreateReleaseConfigRequest {
  return { parent: "", releaseConfig: undefined, releaseConfigId: "" };
}

export const CreateReleaseConfigRequest: MessageFns<CreateReleaseConfigRequest> = {
  encode(message: CreateReleaseConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.releaseConfig !== undefined) {
      ReleaseConfig.encode(message.releaseConfig, writer.uint32(18).fork()).join();
    }
    if (message.releaseConfigId !== "") {
      writer.uint32(26).string(message.releaseConfigId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateReleaseConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateReleaseConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.releaseConfig = ReleaseConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.releaseConfigId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateReleaseConfigRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      releaseConfig: isSet(object.releaseConfig) ? ReleaseConfig.fromJSON(object.releaseConfig) : undefined,
      releaseConfigId: isSet(object.releaseConfigId) ? globalThis.String(object.releaseConfigId) : "",
    };
  },

  toJSON(message: CreateReleaseConfigRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.releaseConfig !== undefined) {
      obj.releaseConfig = ReleaseConfig.toJSON(message.releaseConfig);
    }
    if (message.releaseConfigId !== "") {
      obj.releaseConfigId = message.releaseConfigId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateReleaseConfigRequest>): CreateReleaseConfigRequest {
    return CreateReleaseConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateReleaseConfigRequest>): CreateReleaseConfigRequest {
    const message = createBaseCreateReleaseConfigRequest();
    message.parent = object.parent ?? "";
    message.releaseConfig = (object.releaseConfig !== undefined && object.releaseConfig !== null)
      ? ReleaseConfig.fromPartial(object.releaseConfig)
      : undefined;
    message.releaseConfigId = object.releaseConfigId ?? "";
    return message;
  },
};

function createBaseUpdateReleaseConfigRequest(): UpdateReleaseConfigRequest {
  return { updateMask: undefined, releaseConfig: undefined };
}

export const UpdateReleaseConfigRequest: MessageFns<UpdateReleaseConfigRequest> = {
  encode(message: UpdateReleaseConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.releaseConfig !== undefined) {
      ReleaseConfig.encode(message.releaseConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateReleaseConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateReleaseConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.releaseConfig = ReleaseConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateReleaseConfigRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      releaseConfig: isSet(object.releaseConfig) ? ReleaseConfig.fromJSON(object.releaseConfig) : undefined,
    };
  },

  toJSON(message: UpdateReleaseConfigRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.releaseConfig !== undefined) {
      obj.releaseConfig = ReleaseConfig.toJSON(message.releaseConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateReleaseConfigRequest>): UpdateReleaseConfigRequest {
    return UpdateReleaseConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateReleaseConfigRequest>): UpdateReleaseConfigRequest {
    const message = createBaseUpdateReleaseConfigRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.releaseConfig = (object.releaseConfig !== undefined && object.releaseConfig !== null)
      ? ReleaseConfig.fromPartial(object.releaseConfig)
      : undefined;
    return message;
  },
};

function createBaseDeleteReleaseConfigRequest(): DeleteReleaseConfigRequest {
  return { name: "" };
}

export const DeleteReleaseConfigRequest: MessageFns<DeleteReleaseConfigRequest> = {
  encode(message: DeleteReleaseConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteReleaseConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteReleaseConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteReleaseConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteReleaseConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteReleaseConfigRequest>): DeleteReleaseConfigRequest {
    return DeleteReleaseConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteReleaseConfigRequest>): DeleteReleaseConfigRequest {
    const message = createBaseDeleteReleaseConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCompilationResult(): CompilationResult {
  return {
    name: "",
    gitCommitish: undefined,
    workspace: undefined,
    releaseConfig: undefined,
    codeCompilationConfig: undefined,
    resolvedGitCommitSha: "",
    dataformCoreVersion: "",
    compilationErrors: [],
  };
}

export const CompilationResult: MessageFns<CompilationResult> = {
  encode(message: CompilationResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.gitCommitish !== undefined) {
      writer.uint32(18).string(message.gitCommitish);
    }
    if (message.workspace !== undefined) {
      writer.uint32(26).string(message.workspace);
    }
    if (message.releaseConfig !== undefined) {
      writer.uint32(58).string(message.releaseConfig);
    }
    if (message.codeCompilationConfig !== undefined) {
      CodeCompilationConfig.encode(message.codeCompilationConfig, writer.uint32(34).fork()).join();
    }
    if (message.resolvedGitCommitSha !== "") {
      writer.uint32(66).string(message.resolvedGitCommitSha);
    }
    if (message.dataformCoreVersion !== "") {
      writer.uint32(42).string(message.dataformCoreVersion);
    }
    for (const v of message.compilationErrors) {
      CompilationResult_CompilationError.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.gitCommitish = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.workspace = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.releaseConfig = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.codeCompilationConfig = CodeCompilationConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.resolvedGitCommitSha = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.dataformCoreVersion = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.compilationErrors.push(CompilationResult_CompilationError.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResult {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      gitCommitish: isSet(object.gitCommitish) ? globalThis.String(object.gitCommitish) : undefined,
      workspace: isSet(object.workspace) ? globalThis.String(object.workspace) : undefined,
      releaseConfig: isSet(object.releaseConfig) ? globalThis.String(object.releaseConfig) : undefined,
      codeCompilationConfig: isSet(object.codeCompilationConfig)
        ? CodeCompilationConfig.fromJSON(object.codeCompilationConfig)
        : undefined,
      resolvedGitCommitSha: isSet(object.resolvedGitCommitSha) ? globalThis.String(object.resolvedGitCommitSha) : "",
      dataformCoreVersion: isSet(object.dataformCoreVersion) ? globalThis.String(object.dataformCoreVersion) : "",
      compilationErrors: globalThis.Array.isArray(object?.compilationErrors)
        ? object.compilationErrors.map((e: any) => CompilationResult_CompilationError.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CompilationResult): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.gitCommitish !== undefined) {
      obj.gitCommitish = message.gitCommitish;
    }
    if (message.workspace !== undefined) {
      obj.workspace = message.workspace;
    }
    if (message.releaseConfig !== undefined) {
      obj.releaseConfig = message.releaseConfig;
    }
    if (message.codeCompilationConfig !== undefined) {
      obj.codeCompilationConfig = CodeCompilationConfig.toJSON(message.codeCompilationConfig);
    }
    if (message.resolvedGitCommitSha !== "") {
      obj.resolvedGitCommitSha = message.resolvedGitCommitSha;
    }
    if (message.dataformCoreVersion !== "") {
      obj.dataformCoreVersion = message.dataformCoreVersion;
    }
    if (message.compilationErrors?.length) {
      obj.compilationErrors = message.compilationErrors.map((e) => CompilationResult_CompilationError.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResult>): CompilationResult {
    return CompilationResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResult>): CompilationResult {
    const message = createBaseCompilationResult();
    message.name = object.name ?? "";
    message.gitCommitish = object.gitCommitish ?? undefined;
    message.workspace = object.workspace ?? undefined;
    message.releaseConfig = object.releaseConfig ?? undefined;
    message.codeCompilationConfig =
      (object.codeCompilationConfig !== undefined && object.codeCompilationConfig !== null)
        ? CodeCompilationConfig.fromPartial(object.codeCompilationConfig)
        : undefined;
    message.resolvedGitCommitSha = object.resolvedGitCommitSha ?? "";
    message.dataformCoreVersion = object.dataformCoreVersion ?? "";
    message.compilationErrors =
      object.compilationErrors?.map((e) => CompilationResult_CompilationError.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCompilationResult_CompilationError(): CompilationResult_CompilationError {
  return { message: "", stack: "", path: "", actionTarget: undefined };
}

export const CompilationResult_CompilationError: MessageFns<CompilationResult_CompilationError> = {
  encode(message: CompilationResult_CompilationError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    if (message.stack !== "") {
      writer.uint32(18).string(message.stack);
    }
    if (message.path !== "") {
      writer.uint32(26).string(message.path);
    }
    if (message.actionTarget !== undefined) {
      Target.encode(message.actionTarget, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResult_CompilationError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResult_CompilationError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.stack = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.path = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.actionTarget = Target.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResult_CompilationError {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      stack: isSet(object.stack) ? globalThis.String(object.stack) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      actionTarget: isSet(object.actionTarget) ? Target.fromJSON(object.actionTarget) : undefined,
    };
  },

  toJSON(message: CompilationResult_CompilationError): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.stack !== "") {
      obj.stack = message.stack;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.actionTarget !== undefined) {
      obj.actionTarget = Target.toJSON(message.actionTarget);
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResult_CompilationError>): CompilationResult_CompilationError {
    return CompilationResult_CompilationError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResult_CompilationError>): CompilationResult_CompilationError {
    const message = createBaseCompilationResult_CompilationError();
    message.message = object.message ?? "";
    message.stack = object.stack ?? "";
    message.path = object.path ?? "";
    message.actionTarget = (object.actionTarget !== undefined && object.actionTarget !== null)
      ? Target.fromPartial(object.actionTarget)
      : undefined;
    return message;
  },
};

function createBaseCodeCompilationConfig(): CodeCompilationConfig {
  return {
    defaultDatabase: "",
    defaultSchema: "",
    defaultLocation: "",
    assertionSchema: "",
    vars: {},
    databaseSuffix: "",
    schemaSuffix: "",
    tablePrefix: "",
  };
}

export const CodeCompilationConfig: MessageFns<CodeCompilationConfig> = {
  encode(message: CodeCompilationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.defaultDatabase !== "") {
      writer.uint32(10).string(message.defaultDatabase);
    }
    if (message.defaultSchema !== "") {
      writer.uint32(18).string(message.defaultSchema);
    }
    if (message.defaultLocation !== "") {
      writer.uint32(66).string(message.defaultLocation);
    }
    if (message.assertionSchema !== "") {
      writer.uint32(26).string(message.assertionSchema);
    }
    Object.entries(message.vars).forEach(([key, value]) => {
      CodeCompilationConfig_VarsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.databaseSuffix !== "") {
      writer.uint32(42).string(message.databaseSuffix);
    }
    if (message.schemaSuffix !== "") {
      writer.uint32(50).string(message.schemaSuffix);
    }
    if (message.tablePrefix !== "") {
      writer.uint32(58).string(message.tablePrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CodeCompilationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCodeCompilationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.defaultDatabase = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.defaultSchema = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.defaultLocation = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.assertionSchema = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = CodeCompilationConfig_VarsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.vars[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.databaseSuffix = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.schemaSuffix = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.tablePrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CodeCompilationConfig {
    return {
      defaultDatabase: isSet(object.defaultDatabase) ? globalThis.String(object.defaultDatabase) : "",
      defaultSchema: isSet(object.defaultSchema) ? globalThis.String(object.defaultSchema) : "",
      defaultLocation: isSet(object.defaultLocation) ? globalThis.String(object.defaultLocation) : "",
      assertionSchema: isSet(object.assertionSchema) ? globalThis.String(object.assertionSchema) : "",
      vars: isObject(object.vars)
        ? Object.entries(object.vars).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      databaseSuffix: isSet(object.databaseSuffix) ? globalThis.String(object.databaseSuffix) : "",
      schemaSuffix: isSet(object.schemaSuffix) ? globalThis.String(object.schemaSuffix) : "",
      tablePrefix: isSet(object.tablePrefix) ? globalThis.String(object.tablePrefix) : "",
    };
  },

  toJSON(message: CodeCompilationConfig): unknown {
    const obj: any = {};
    if (message.defaultDatabase !== "") {
      obj.defaultDatabase = message.defaultDatabase;
    }
    if (message.defaultSchema !== "") {
      obj.defaultSchema = message.defaultSchema;
    }
    if (message.defaultLocation !== "") {
      obj.defaultLocation = message.defaultLocation;
    }
    if (message.assertionSchema !== "") {
      obj.assertionSchema = message.assertionSchema;
    }
    if (message.vars) {
      const entries = Object.entries(message.vars);
      if (entries.length > 0) {
        obj.vars = {};
        entries.forEach(([k, v]) => {
          obj.vars[k] = v;
        });
      }
    }
    if (message.databaseSuffix !== "") {
      obj.databaseSuffix = message.databaseSuffix;
    }
    if (message.schemaSuffix !== "") {
      obj.schemaSuffix = message.schemaSuffix;
    }
    if (message.tablePrefix !== "") {
      obj.tablePrefix = message.tablePrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<CodeCompilationConfig>): CodeCompilationConfig {
    return CodeCompilationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CodeCompilationConfig>): CodeCompilationConfig {
    const message = createBaseCodeCompilationConfig();
    message.defaultDatabase = object.defaultDatabase ?? "";
    message.defaultSchema = object.defaultSchema ?? "";
    message.defaultLocation = object.defaultLocation ?? "";
    message.assertionSchema = object.assertionSchema ?? "";
    message.vars = Object.entries(object.vars ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.databaseSuffix = object.databaseSuffix ?? "";
    message.schemaSuffix = object.schemaSuffix ?? "";
    message.tablePrefix = object.tablePrefix ?? "";
    return message;
  },
};

function createBaseCodeCompilationConfig_VarsEntry(): CodeCompilationConfig_VarsEntry {
  return { key: "", value: "" };
}

export const CodeCompilationConfig_VarsEntry: MessageFns<CodeCompilationConfig_VarsEntry> = {
  encode(message: CodeCompilationConfig_VarsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CodeCompilationConfig_VarsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCodeCompilationConfig_VarsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CodeCompilationConfig_VarsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CodeCompilationConfig_VarsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<CodeCompilationConfig_VarsEntry>): CodeCompilationConfig_VarsEntry {
    return CodeCompilationConfig_VarsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CodeCompilationConfig_VarsEntry>): CodeCompilationConfig_VarsEntry {
    const message = createBaseCodeCompilationConfig_VarsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseListCompilationResultsRequest(): ListCompilationResultsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListCompilationResultsRequest: MessageFns<ListCompilationResultsRequest> = {
  encode(message: ListCompilationResultsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListCompilationResultsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListCompilationResultsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListCompilationResultsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListCompilationResultsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListCompilationResultsRequest>): ListCompilationResultsRequest {
    return ListCompilationResultsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListCompilationResultsRequest>): ListCompilationResultsRequest {
    const message = createBaseListCompilationResultsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListCompilationResultsResponse(): ListCompilationResultsResponse {
  return { compilationResults: [], nextPageToken: "", unreachable: [] };
}

export const ListCompilationResultsResponse: MessageFns<ListCompilationResultsResponse> = {
  encode(message: ListCompilationResultsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.compilationResults) {
      CompilationResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListCompilationResultsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListCompilationResultsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.compilationResults.push(CompilationResult.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListCompilationResultsResponse {
    return {
      compilationResults: globalThis.Array.isArray(object?.compilationResults)
        ? object.compilationResults.map((e: any) => CompilationResult.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListCompilationResultsResponse): unknown {
    const obj: any = {};
    if (message.compilationResults?.length) {
      obj.compilationResults = message.compilationResults.map((e) => CompilationResult.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListCompilationResultsResponse>): ListCompilationResultsResponse {
    return ListCompilationResultsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListCompilationResultsResponse>): ListCompilationResultsResponse {
    const message = createBaseListCompilationResultsResponse();
    message.compilationResults = object.compilationResults?.map((e) => CompilationResult.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetCompilationResultRequest(): GetCompilationResultRequest {
  return { name: "" };
}

export const GetCompilationResultRequest: MessageFns<GetCompilationResultRequest> = {
  encode(message: GetCompilationResultRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetCompilationResultRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetCompilationResultRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetCompilationResultRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetCompilationResultRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetCompilationResultRequest>): GetCompilationResultRequest {
    return GetCompilationResultRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetCompilationResultRequest>): GetCompilationResultRequest {
    const message = createBaseGetCompilationResultRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateCompilationResultRequest(): CreateCompilationResultRequest {
  return { parent: "", compilationResult: undefined };
}

export const CreateCompilationResultRequest: MessageFns<CreateCompilationResultRequest> = {
  encode(message: CreateCompilationResultRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.compilationResult !== undefined) {
      CompilationResult.encode(message.compilationResult, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateCompilationResultRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateCompilationResultRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.compilationResult = CompilationResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateCompilationResultRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      compilationResult: isSet(object.compilationResult)
        ? CompilationResult.fromJSON(object.compilationResult)
        : undefined,
    };
  },

  toJSON(message: CreateCompilationResultRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.compilationResult !== undefined) {
      obj.compilationResult = CompilationResult.toJSON(message.compilationResult);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateCompilationResultRequest>): CreateCompilationResultRequest {
    return CreateCompilationResultRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateCompilationResultRequest>): CreateCompilationResultRequest {
    const message = createBaseCreateCompilationResultRequest();
    message.parent = object.parent ?? "";
    message.compilationResult = (object.compilationResult !== undefined && object.compilationResult !== null)
      ? CompilationResult.fromPartial(object.compilationResult)
      : undefined;
    return message;
  },
};

function createBaseTarget(): Target {
  return { database: "", schema: "", name: "" };
}

export const Target: MessageFns<Target> = {
  encode(message: Target, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    if (message.schema !== "") {
      writer.uint32(18).string(message.schema);
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.schema = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      schema: isSet(object.schema) ? globalThis.String(object.schema) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
    };
  },

  toJSON(message: Target): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.schema !== "") {
      obj.schema = message.schema;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<Target>): Target {
    return Target.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Target>): Target {
    const message = createBaseTarget();
    message.database = object.database ?? "";
    message.schema = object.schema ?? "";
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseRelationDescriptor(): RelationDescriptor {
  return { description: "", columns: [], bigqueryLabels: {} };
}

export const RelationDescriptor: MessageFns<RelationDescriptor> = {
  encode(message: RelationDescriptor, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.description !== "") {
      writer.uint32(10).string(message.description);
    }
    for (const v of message.columns) {
      RelationDescriptor_ColumnDescriptor.encode(v!, writer.uint32(18).fork()).join();
    }
    Object.entries(message.bigqueryLabels).forEach(([key, value]) => {
      RelationDescriptor_BigqueryLabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RelationDescriptor {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelationDescriptor();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.description = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.columns.push(RelationDescriptor_ColumnDescriptor.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = RelationDescriptor_BigqueryLabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.bigqueryLabels[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RelationDescriptor {
    return {
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      columns: globalThis.Array.isArray(object?.columns)
        ? object.columns.map((e: any) => RelationDescriptor_ColumnDescriptor.fromJSON(e))
        : [],
      bigqueryLabels: isObject(object.bigqueryLabels)
        ? Object.entries(object.bigqueryLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: RelationDescriptor): unknown {
    const obj: any = {};
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.columns?.length) {
      obj.columns = message.columns.map((e) => RelationDescriptor_ColumnDescriptor.toJSON(e));
    }
    if (message.bigqueryLabels) {
      const entries = Object.entries(message.bigqueryLabels);
      if (entries.length > 0) {
        obj.bigqueryLabels = {};
        entries.forEach(([k, v]) => {
          obj.bigqueryLabels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<RelationDescriptor>): RelationDescriptor {
    return RelationDescriptor.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RelationDescriptor>): RelationDescriptor {
    const message = createBaseRelationDescriptor();
    message.description = object.description ?? "";
    message.columns = object.columns?.map((e) => RelationDescriptor_ColumnDescriptor.fromPartial(e)) || [];
    message.bigqueryLabels = Object.entries(object.bigqueryLabels ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseRelationDescriptor_ColumnDescriptor(): RelationDescriptor_ColumnDescriptor {
  return { path: [], description: "", bigqueryPolicyTags: [] };
}

export const RelationDescriptor_ColumnDescriptor: MessageFns<RelationDescriptor_ColumnDescriptor> = {
  encode(message: RelationDescriptor_ColumnDescriptor, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.path) {
      writer.uint32(10).string(v!);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    for (const v of message.bigqueryPolicyTags) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RelationDescriptor_ColumnDescriptor {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelationDescriptor_ColumnDescriptor();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.bigqueryPolicyTags.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RelationDescriptor_ColumnDescriptor {
    return {
      path: globalThis.Array.isArray(object?.path) ? object.path.map((e: any) => globalThis.String(e)) : [],
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      bigqueryPolicyTags: globalThis.Array.isArray(object?.bigqueryPolicyTags)
        ? object.bigqueryPolicyTags.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: RelationDescriptor_ColumnDescriptor): unknown {
    const obj: any = {};
    if (message.path?.length) {
      obj.path = message.path;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.bigqueryPolicyTags?.length) {
      obj.bigqueryPolicyTags = message.bigqueryPolicyTags;
    }
    return obj;
  },

  create(base?: DeepPartial<RelationDescriptor_ColumnDescriptor>): RelationDescriptor_ColumnDescriptor {
    return RelationDescriptor_ColumnDescriptor.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RelationDescriptor_ColumnDescriptor>): RelationDescriptor_ColumnDescriptor {
    const message = createBaseRelationDescriptor_ColumnDescriptor();
    message.path = object.path?.map((e) => e) || [];
    message.description = object.description ?? "";
    message.bigqueryPolicyTags = object.bigqueryPolicyTags?.map((e) => e) || [];
    return message;
  },
};

function createBaseRelationDescriptor_BigqueryLabelsEntry(): RelationDescriptor_BigqueryLabelsEntry {
  return { key: "", value: "" };
}

export const RelationDescriptor_BigqueryLabelsEntry: MessageFns<RelationDescriptor_BigqueryLabelsEntry> = {
  encode(message: RelationDescriptor_BigqueryLabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RelationDescriptor_BigqueryLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelationDescriptor_BigqueryLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RelationDescriptor_BigqueryLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: RelationDescriptor_BigqueryLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<RelationDescriptor_BigqueryLabelsEntry>): RelationDescriptor_BigqueryLabelsEntry {
    return RelationDescriptor_BigqueryLabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RelationDescriptor_BigqueryLabelsEntry>): RelationDescriptor_BigqueryLabelsEntry {
    const message = createBaseRelationDescriptor_BigqueryLabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCompilationResultAction(): CompilationResultAction {
  return {
    target: undefined,
    canonicalTarget: undefined,
    filePath: "",
    relation: undefined,
    operations: undefined,
    assertion: undefined,
    declaration: undefined,
  };
}

export const CompilationResultAction: MessageFns<CompilationResultAction> = {
  encode(message: CompilationResultAction, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.target !== undefined) {
      Target.encode(message.target, writer.uint32(10).fork()).join();
    }
    if (message.canonicalTarget !== undefined) {
      Target.encode(message.canonicalTarget, writer.uint32(18).fork()).join();
    }
    if (message.filePath !== "") {
      writer.uint32(26).string(message.filePath);
    }
    if (message.relation !== undefined) {
      CompilationResultAction_Relation.encode(message.relation, writer.uint32(34).fork()).join();
    }
    if (message.operations !== undefined) {
      CompilationResultAction_Operations.encode(message.operations, writer.uint32(42).fork()).join();
    }
    if (message.assertion !== undefined) {
      CompilationResultAction_Assertion.encode(message.assertion, writer.uint32(50).fork()).join();
    }
    if (message.declaration !== undefined) {
      CompilationResultAction_Declaration.encode(message.declaration, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.target = Target.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.canonicalTarget = Target.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.filePath = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.relation = CompilationResultAction_Relation.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.operations = CompilationResultAction_Operations.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.assertion = CompilationResultAction_Assertion.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.declaration = CompilationResultAction_Declaration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction {
    return {
      target: isSet(object.target) ? Target.fromJSON(object.target) : undefined,
      canonicalTarget: isSet(object.canonicalTarget) ? Target.fromJSON(object.canonicalTarget) : undefined,
      filePath: isSet(object.filePath) ? globalThis.String(object.filePath) : "",
      relation: isSet(object.relation) ? CompilationResultAction_Relation.fromJSON(object.relation) : undefined,
      operations: isSet(object.operations) ? CompilationResultAction_Operations.fromJSON(object.operations) : undefined,
      assertion: isSet(object.assertion) ? CompilationResultAction_Assertion.fromJSON(object.assertion) : undefined,
      declaration: isSet(object.declaration)
        ? CompilationResultAction_Declaration.fromJSON(object.declaration)
        : undefined,
    };
  },

  toJSON(message: CompilationResultAction): unknown {
    const obj: any = {};
    if (message.target !== undefined) {
      obj.target = Target.toJSON(message.target);
    }
    if (message.canonicalTarget !== undefined) {
      obj.canonicalTarget = Target.toJSON(message.canonicalTarget);
    }
    if (message.filePath !== "") {
      obj.filePath = message.filePath;
    }
    if (message.relation !== undefined) {
      obj.relation = CompilationResultAction_Relation.toJSON(message.relation);
    }
    if (message.operations !== undefined) {
      obj.operations = CompilationResultAction_Operations.toJSON(message.operations);
    }
    if (message.assertion !== undefined) {
      obj.assertion = CompilationResultAction_Assertion.toJSON(message.assertion);
    }
    if (message.declaration !== undefined) {
      obj.declaration = CompilationResultAction_Declaration.toJSON(message.declaration);
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResultAction>): CompilationResultAction {
    return CompilationResultAction.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResultAction>): CompilationResultAction {
    const message = createBaseCompilationResultAction();
    message.target = (object.target !== undefined && object.target !== null)
      ? Target.fromPartial(object.target)
      : undefined;
    message.canonicalTarget = (object.canonicalTarget !== undefined && object.canonicalTarget !== null)
      ? Target.fromPartial(object.canonicalTarget)
      : undefined;
    message.filePath = object.filePath ?? "";
    message.relation = (object.relation !== undefined && object.relation !== null)
      ? CompilationResultAction_Relation.fromPartial(object.relation)
      : undefined;
    message.operations = (object.operations !== undefined && object.operations !== null)
      ? CompilationResultAction_Operations.fromPartial(object.operations)
      : undefined;
    message.assertion = (object.assertion !== undefined && object.assertion !== null)
      ? CompilationResultAction_Assertion.fromPartial(object.assertion)
      : undefined;
    message.declaration = (object.declaration !== undefined && object.declaration !== null)
      ? CompilationResultAction_Declaration.fromPartial(object.declaration)
      : undefined;
    return message;
  },
};

function createBaseCompilationResultAction_Relation(): CompilationResultAction_Relation {
  return {
    dependencyTargets: [],
    disabled: false,
    tags: [],
    relationDescriptor: undefined,
    relationType: 0,
    selectQuery: "",
    preOperations: [],
    postOperations: [],
    incrementalTableConfig: undefined,
    partitionExpression: "",
    clusterExpressions: [],
    partitionExpirationDays: 0,
    requirePartitionFilter: false,
    additionalOptions: {},
  };
}

export const CompilationResultAction_Relation: MessageFns<CompilationResultAction_Relation> = {
  encode(message: CompilationResultAction_Relation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dependencyTargets) {
      Target.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.disabled !== false) {
      writer.uint32(16).bool(message.disabled);
    }
    for (const v of message.tags) {
      writer.uint32(26).string(v!);
    }
    if (message.relationDescriptor !== undefined) {
      RelationDescriptor.encode(message.relationDescriptor, writer.uint32(34).fork()).join();
    }
    if (message.relationType !== 0) {
      writer.uint32(40).int32(message.relationType);
    }
    if (message.selectQuery !== "") {
      writer.uint32(50).string(message.selectQuery);
    }
    for (const v of message.preOperations) {
      writer.uint32(58).string(v!);
    }
    for (const v of message.postOperations) {
      writer.uint32(66).string(v!);
    }
    if (message.incrementalTableConfig !== undefined) {
      CompilationResultAction_Relation_IncrementalTableConfig.encode(
        message.incrementalTableConfig,
        writer.uint32(74).fork(),
      ).join();
    }
    if (message.partitionExpression !== "") {
      writer.uint32(82).string(message.partitionExpression);
    }
    for (const v of message.clusterExpressions) {
      writer.uint32(90).string(v!);
    }
    if (message.partitionExpirationDays !== 0) {
      writer.uint32(96).int32(message.partitionExpirationDays);
    }
    if (message.requirePartitionFilter !== false) {
      writer.uint32(104).bool(message.requirePartitionFilter);
    }
    Object.entries(message.additionalOptions).forEach(([key, value]) => {
      CompilationResultAction_Relation_AdditionalOptionsEntry.encode(
        { key: key as any, value },
        writer.uint32(114).fork(),
      ).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction_Relation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction_Relation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dependencyTargets.push(Target.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.disabled = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tags.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.relationDescriptor = RelationDescriptor.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.relationType = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.selectQuery = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.preOperations.push(reader.string());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.postOperations.push(reader.string());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.incrementalTableConfig = CompilationResultAction_Relation_IncrementalTableConfig.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.partitionExpression = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.clusterExpressions.push(reader.string());
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.partitionExpirationDays = reader.int32();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.requirePartitionFilter = reader.bool();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          const entry14 = CompilationResultAction_Relation_AdditionalOptionsEntry.decode(reader, reader.uint32());
          if (entry14.value !== undefined) {
            message.additionalOptions[entry14.key] = entry14.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction_Relation {
    return {
      dependencyTargets: globalThis.Array.isArray(object?.dependencyTargets)
        ? object.dependencyTargets.map((e: any) => Target.fromJSON(e))
        : [],
      disabled: isSet(object.disabled) ? globalThis.Boolean(object.disabled) : false,
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => globalThis.String(e)) : [],
      relationDescriptor: isSet(object.relationDescriptor)
        ? RelationDescriptor.fromJSON(object.relationDescriptor)
        : undefined,
      relationType: isSet(object.relationType)
        ? compilationResultAction_Relation_RelationTypeFromJSON(object.relationType)
        : 0,
      selectQuery: isSet(object.selectQuery) ? globalThis.String(object.selectQuery) : "",
      preOperations: globalThis.Array.isArray(object?.preOperations)
        ? object.preOperations.map((e: any) => globalThis.String(e))
        : [],
      postOperations: globalThis.Array.isArray(object?.postOperations)
        ? object.postOperations.map((e: any) => globalThis.String(e))
        : [],
      incrementalTableConfig: isSet(object.incrementalTableConfig)
        ? CompilationResultAction_Relation_IncrementalTableConfig.fromJSON(object.incrementalTableConfig)
        : undefined,
      partitionExpression: isSet(object.partitionExpression) ? globalThis.String(object.partitionExpression) : "",
      clusterExpressions: globalThis.Array.isArray(object?.clusterExpressions)
        ? object.clusterExpressions.map((e: any) => globalThis.String(e))
        : [],
      partitionExpirationDays: isSet(object.partitionExpirationDays)
        ? globalThis.Number(object.partitionExpirationDays)
        : 0,
      requirePartitionFilter: isSet(object.requirePartitionFilter)
        ? globalThis.Boolean(object.requirePartitionFilter)
        : false,
      additionalOptions: isObject(object.additionalOptions)
        ? Object.entries(object.additionalOptions).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: CompilationResultAction_Relation): unknown {
    const obj: any = {};
    if (message.dependencyTargets?.length) {
      obj.dependencyTargets = message.dependencyTargets.map((e) => Target.toJSON(e));
    }
    if (message.disabled !== false) {
      obj.disabled = message.disabled;
    }
    if (message.tags?.length) {
      obj.tags = message.tags;
    }
    if (message.relationDescriptor !== undefined) {
      obj.relationDescriptor = RelationDescriptor.toJSON(message.relationDescriptor);
    }
    if (message.relationType !== 0) {
      obj.relationType = compilationResultAction_Relation_RelationTypeToJSON(message.relationType);
    }
    if (message.selectQuery !== "") {
      obj.selectQuery = message.selectQuery;
    }
    if (message.preOperations?.length) {
      obj.preOperations = message.preOperations;
    }
    if (message.postOperations?.length) {
      obj.postOperations = message.postOperations;
    }
    if (message.incrementalTableConfig !== undefined) {
      obj.incrementalTableConfig = CompilationResultAction_Relation_IncrementalTableConfig.toJSON(
        message.incrementalTableConfig,
      );
    }
    if (message.partitionExpression !== "") {
      obj.partitionExpression = message.partitionExpression;
    }
    if (message.clusterExpressions?.length) {
      obj.clusterExpressions = message.clusterExpressions;
    }
    if (message.partitionExpirationDays !== 0) {
      obj.partitionExpirationDays = Math.round(message.partitionExpirationDays);
    }
    if (message.requirePartitionFilter !== false) {
      obj.requirePartitionFilter = message.requirePartitionFilter;
    }
    if (message.additionalOptions) {
      const entries = Object.entries(message.additionalOptions);
      if (entries.length > 0) {
        obj.additionalOptions = {};
        entries.forEach(([k, v]) => {
          obj.additionalOptions[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResultAction_Relation>): CompilationResultAction_Relation {
    return CompilationResultAction_Relation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResultAction_Relation>): CompilationResultAction_Relation {
    const message = createBaseCompilationResultAction_Relation();
    message.dependencyTargets = object.dependencyTargets?.map((e) => Target.fromPartial(e)) || [];
    message.disabled = object.disabled ?? false;
    message.tags = object.tags?.map((e) => e) || [];
    message.relationDescriptor = (object.relationDescriptor !== undefined && object.relationDescriptor !== null)
      ? RelationDescriptor.fromPartial(object.relationDescriptor)
      : undefined;
    message.relationType = object.relationType ?? 0;
    message.selectQuery = object.selectQuery ?? "";
    message.preOperations = object.preOperations?.map((e) => e) || [];
    message.postOperations = object.postOperations?.map((e) => e) || [];
    message.incrementalTableConfig =
      (object.incrementalTableConfig !== undefined && object.incrementalTableConfig !== null)
        ? CompilationResultAction_Relation_IncrementalTableConfig.fromPartial(object.incrementalTableConfig)
        : undefined;
    message.partitionExpression = object.partitionExpression ?? "";
    message.clusterExpressions = object.clusterExpressions?.map((e) => e) || [];
    message.partitionExpirationDays = object.partitionExpirationDays ?? 0;
    message.requirePartitionFilter = object.requirePartitionFilter ?? false;
    message.additionalOptions = Object.entries(object.additionalOptions ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseCompilationResultAction_Relation_IncrementalTableConfig(): CompilationResultAction_Relation_IncrementalTableConfig {
  return {
    incrementalSelectQuery: "",
    refreshDisabled: false,
    uniqueKeyParts: [],
    updatePartitionFilter: "",
    incrementalPreOperations: [],
    incrementalPostOperations: [],
  };
}

export const CompilationResultAction_Relation_IncrementalTableConfig: MessageFns<
  CompilationResultAction_Relation_IncrementalTableConfig
> = {
  encode(
    message: CompilationResultAction_Relation_IncrementalTableConfig,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.incrementalSelectQuery !== "") {
      writer.uint32(10).string(message.incrementalSelectQuery);
    }
    if (message.refreshDisabled !== false) {
      writer.uint32(16).bool(message.refreshDisabled);
    }
    for (const v of message.uniqueKeyParts) {
      writer.uint32(26).string(v!);
    }
    if (message.updatePartitionFilter !== "") {
      writer.uint32(34).string(message.updatePartitionFilter);
    }
    for (const v of message.incrementalPreOperations) {
      writer.uint32(42).string(v!);
    }
    for (const v of message.incrementalPostOperations) {
      writer.uint32(50).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction_Relation_IncrementalTableConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction_Relation_IncrementalTableConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.incrementalSelectQuery = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.refreshDisabled = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.uniqueKeyParts.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.updatePartitionFilter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.incrementalPreOperations.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.incrementalPostOperations.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction_Relation_IncrementalTableConfig {
    return {
      incrementalSelectQuery: isSet(object.incrementalSelectQuery)
        ? globalThis.String(object.incrementalSelectQuery)
        : "",
      refreshDisabled: isSet(object.refreshDisabled) ? globalThis.Boolean(object.refreshDisabled) : false,
      uniqueKeyParts: globalThis.Array.isArray(object?.uniqueKeyParts)
        ? object.uniqueKeyParts.map((e: any) => globalThis.String(e))
        : [],
      updatePartitionFilter: isSet(object.updatePartitionFilter) ? globalThis.String(object.updatePartitionFilter) : "",
      incrementalPreOperations: globalThis.Array.isArray(object?.incrementalPreOperations)
        ? object.incrementalPreOperations.map((e: any) => globalThis.String(e))
        : [],
      incrementalPostOperations: globalThis.Array.isArray(object?.incrementalPostOperations)
        ? object.incrementalPostOperations.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: CompilationResultAction_Relation_IncrementalTableConfig): unknown {
    const obj: any = {};
    if (message.incrementalSelectQuery !== "") {
      obj.incrementalSelectQuery = message.incrementalSelectQuery;
    }
    if (message.refreshDisabled !== false) {
      obj.refreshDisabled = message.refreshDisabled;
    }
    if (message.uniqueKeyParts?.length) {
      obj.uniqueKeyParts = message.uniqueKeyParts;
    }
    if (message.updatePartitionFilter !== "") {
      obj.updatePartitionFilter = message.updatePartitionFilter;
    }
    if (message.incrementalPreOperations?.length) {
      obj.incrementalPreOperations = message.incrementalPreOperations;
    }
    if (message.incrementalPostOperations?.length) {
      obj.incrementalPostOperations = message.incrementalPostOperations;
    }
    return obj;
  },

  create(
    base?: DeepPartial<CompilationResultAction_Relation_IncrementalTableConfig>,
  ): CompilationResultAction_Relation_IncrementalTableConfig {
    return CompilationResultAction_Relation_IncrementalTableConfig.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CompilationResultAction_Relation_IncrementalTableConfig>,
  ): CompilationResultAction_Relation_IncrementalTableConfig {
    const message = createBaseCompilationResultAction_Relation_IncrementalTableConfig();
    message.incrementalSelectQuery = object.incrementalSelectQuery ?? "";
    message.refreshDisabled = object.refreshDisabled ?? false;
    message.uniqueKeyParts = object.uniqueKeyParts?.map((e) => e) || [];
    message.updatePartitionFilter = object.updatePartitionFilter ?? "";
    message.incrementalPreOperations = object.incrementalPreOperations?.map((e) => e) || [];
    message.incrementalPostOperations = object.incrementalPostOperations?.map((e) => e) || [];
    return message;
  },
};

function createBaseCompilationResultAction_Relation_AdditionalOptionsEntry(): CompilationResultAction_Relation_AdditionalOptionsEntry {
  return { key: "", value: "" };
}

export const CompilationResultAction_Relation_AdditionalOptionsEntry: MessageFns<
  CompilationResultAction_Relation_AdditionalOptionsEntry
> = {
  encode(
    message: CompilationResultAction_Relation_AdditionalOptionsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction_Relation_AdditionalOptionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction_Relation_AdditionalOptionsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction_Relation_AdditionalOptionsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CompilationResultAction_Relation_AdditionalOptionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<CompilationResultAction_Relation_AdditionalOptionsEntry>,
  ): CompilationResultAction_Relation_AdditionalOptionsEntry {
    return CompilationResultAction_Relation_AdditionalOptionsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CompilationResultAction_Relation_AdditionalOptionsEntry>,
  ): CompilationResultAction_Relation_AdditionalOptionsEntry {
    const message = createBaseCompilationResultAction_Relation_AdditionalOptionsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCompilationResultAction_Operations(): CompilationResultAction_Operations {
  return {
    dependencyTargets: [],
    disabled: false,
    tags: [],
    relationDescriptor: undefined,
    queries: [],
    hasOutput: false,
  };
}

export const CompilationResultAction_Operations: MessageFns<CompilationResultAction_Operations> = {
  encode(message: CompilationResultAction_Operations, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dependencyTargets) {
      Target.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.disabled !== false) {
      writer.uint32(16).bool(message.disabled);
    }
    for (const v of message.tags) {
      writer.uint32(26).string(v!);
    }
    if (message.relationDescriptor !== undefined) {
      RelationDescriptor.encode(message.relationDescriptor, writer.uint32(50).fork()).join();
    }
    for (const v of message.queries) {
      writer.uint32(34).string(v!);
    }
    if (message.hasOutput !== false) {
      writer.uint32(40).bool(message.hasOutput);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction_Operations {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction_Operations();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dependencyTargets.push(Target.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.disabled = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tags.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.relationDescriptor = RelationDescriptor.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.queries.push(reader.string());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.hasOutput = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction_Operations {
    return {
      dependencyTargets: globalThis.Array.isArray(object?.dependencyTargets)
        ? object.dependencyTargets.map((e: any) => Target.fromJSON(e))
        : [],
      disabled: isSet(object.disabled) ? globalThis.Boolean(object.disabled) : false,
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => globalThis.String(e)) : [],
      relationDescriptor: isSet(object.relationDescriptor)
        ? RelationDescriptor.fromJSON(object.relationDescriptor)
        : undefined,
      queries: globalThis.Array.isArray(object?.queries) ? object.queries.map((e: any) => globalThis.String(e)) : [],
      hasOutput: isSet(object.hasOutput) ? globalThis.Boolean(object.hasOutput) : false,
    };
  },

  toJSON(message: CompilationResultAction_Operations): unknown {
    const obj: any = {};
    if (message.dependencyTargets?.length) {
      obj.dependencyTargets = message.dependencyTargets.map((e) => Target.toJSON(e));
    }
    if (message.disabled !== false) {
      obj.disabled = message.disabled;
    }
    if (message.tags?.length) {
      obj.tags = message.tags;
    }
    if (message.relationDescriptor !== undefined) {
      obj.relationDescriptor = RelationDescriptor.toJSON(message.relationDescriptor);
    }
    if (message.queries?.length) {
      obj.queries = message.queries;
    }
    if (message.hasOutput !== false) {
      obj.hasOutput = message.hasOutput;
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResultAction_Operations>): CompilationResultAction_Operations {
    return CompilationResultAction_Operations.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResultAction_Operations>): CompilationResultAction_Operations {
    const message = createBaseCompilationResultAction_Operations();
    message.dependencyTargets = object.dependencyTargets?.map((e) => Target.fromPartial(e)) || [];
    message.disabled = object.disabled ?? false;
    message.tags = object.tags?.map((e) => e) || [];
    message.relationDescriptor = (object.relationDescriptor !== undefined && object.relationDescriptor !== null)
      ? RelationDescriptor.fromPartial(object.relationDescriptor)
      : undefined;
    message.queries = object.queries?.map((e) => e) || [];
    message.hasOutput = object.hasOutput ?? false;
    return message;
  },
};

function createBaseCompilationResultAction_Assertion(): CompilationResultAction_Assertion {
  return {
    dependencyTargets: [],
    parentAction: undefined,
    disabled: false,
    tags: [],
    selectQuery: "",
    relationDescriptor: undefined,
  };
}

export const CompilationResultAction_Assertion: MessageFns<CompilationResultAction_Assertion> = {
  encode(message: CompilationResultAction_Assertion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dependencyTargets) {
      Target.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.parentAction !== undefined) {
      Target.encode(message.parentAction, writer.uint32(42).fork()).join();
    }
    if (message.disabled !== false) {
      writer.uint32(16).bool(message.disabled);
    }
    for (const v of message.tags) {
      writer.uint32(26).string(v!);
    }
    if (message.selectQuery !== "") {
      writer.uint32(34).string(message.selectQuery);
    }
    if (message.relationDescriptor !== undefined) {
      RelationDescriptor.encode(message.relationDescriptor, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction_Assertion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction_Assertion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dependencyTargets.push(Target.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.parentAction = Target.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.disabled = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tags.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.selectQuery = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.relationDescriptor = RelationDescriptor.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction_Assertion {
    return {
      dependencyTargets: globalThis.Array.isArray(object?.dependencyTargets)
        ? object.dependencyTargets.map((e: any) => Target.fromJSON(e))
        : [],
      parentAction: isSet(object.parentAction) ? Target.fromJSON(object.parentAction) : undefined,
      disabled: isSet(object.disabled) ? globalThis.Boolean(object.disabled) : false,
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => globalThis.String(e)) : [],
      selectQuery: isSet(object.selectQuery) ? globalThis.String(object.selectQuery) : "",
      relationDescriptor: isSet(object.relationDescriptor)
        ? RelationDescriptor.fromJSON(object.relationDescriptor)
        : undefined,
    };
  },

  toJSON(message: CompilationResultAction_Assertion): unknown {
    const obj: any = {};
    if (message.dependencyTargets?.length) {
      obj.dependencyTargets = message.dependencyTargets.map((e) => Target.toJSON(e));
    }
    if (message.parentAction !== undefined) {
      obj.parentAction = Target.toJSON(message.parentAction);
    }
    if (message.disabled !== false) {
      obj.disabled = message.disabled;
    }
    if (message.tags?.length) {
      obj.tags = message.tags;
    }
    if (message.selectQuery !== "") {
      obj.selectQuery = message.selectQuery;
    }
    if (message.relationDescriptor !== undefined) {
      obj.relationDescriptor = RelationDescriptor.toJSON(message.relationDescriptor);
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResultAction_Assertion>): CompilationResultAction_Assertion {
    return CompilationResultAction_Assertion.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResultAction_Assertion>): CompilationResultAction_Assertion {
    const message = createBaseCompilationResultAction_Assertion();
    message.dependencyTargets = object.dependencyTargets?.map((e) => Target.fromPartial(e)) || [];
    message.parentAction = (object.parentAction !== undefined && object.parentAction !== null)
      ? Target.fromPartial(object.parentAction)
      : undefined;
    message.disabled = object.disabled ?? false;
    message.tags = object.tags?.map((e) => e) || [];
    message.selectQuery = object.selectQuery ?? "";
    message.relationDescriptor = (object.relationDescriptor !== undefined && object.relationDescriptor !== null)
      ? RelationDescriptor.fromPartial(object.relationDescriptor)
      : undefined;
    return message;
  },
};

function createBaseCompilationResultAction_Declaration(): CompilationResultAction_Declaration {
  return { relationDescriptor: undefined };
}

export const CompilationResultAction_Declaration: MessageFns<CompilationResultAction_Declaration> = {
  encode(message: CompilationResultAction_Declaration, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.relationDescriptor !== undefined) {
      RelationDescriptor.encode(message.relationDescriptor, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CompilationResultAction_Declaration {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompilationResultAction_Declaration();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.relationDescriptor = RelationDescriptor.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompilationResultAction_Declaration {
    return {
      relationDescriptor: isSet(object.relationDescriptor)
        ? RelationDescriptor.fromJSON(object.relationDescriptor)
        : undefined,
    };
  },

  toJSON(message: CompilationResultAction_Declaration): unknown {
    const obj: any = {};
    if (message.relationDescriptor !== undefined) {
      obj.relationDescriptor = RelationDescriptor.toJSON(message.relationDescriptor);
    }
    return obj;
  },

  create(base?: DeepPartial<CompilationResultAction_Declaration>): CompilationResultAction_Declaration {
    return CompilationResultAction_Declaration.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CompilationResultAction_Declaration>): CompilationResultAction_Declaration {
    const message = createBaseCompilationResultAction_Declaration();
    message.relationDescriptor = (object.relationDescriptor !== undefined && object.relationDescriptor !== null)
      ? RelationDescriptor.fromPartial(object.relationDescriptor)
      : undefined;
    return message;
  },
};

function createBaseQueryCompilationResultActionsRequest(): QueryCompilationResultActionsRequest {
  return { name: "", pageSize: 0, pageToken: "", filter: "" };
}

export const QueryCompilationResultActionsRequest: MessageFns<QueryCompilationResultActionsRequest> = {
  encode(message: QueryCompilationResultActionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryCompilationResultActionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryCompilationResultActionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryCompilationResultActionsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: QueryCompilationResultActionsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryCompilationResultActionsRequest>): QueryCompilationResultActionsRequest {
    return QueryCompilationResultActionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryCompilationResultActionsRequest>): QueryCompilationResultActionsRequest {
    const message = createBaseQueryCompilationResultActionsRequest();
    message.name = object.name ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseQueryCompilationResultActionsResponse(): QueryCompilationResultActionsResponse {
  return { compilationResultActions: [], nextPageToken: "" };
}

export const QueryCompilationResultActionsResponse: MessageFns<QueryCompilationResultActionsResponse> = {
  encode(message: QueryCompilationResultActionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.compilationResultActions) {
      CompilationResultAction.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryCompilationResultActionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryCompilationResultActionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.compilationResultActions.push(CompilationResultAction.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryCompilationResultActionsResponse {
    return {
      compilationResultActions: globalThis.Array.isArray(object?.compilationResultActions)
        ? object.compilationResultActions.map((e: any) => CompilationResultAction.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: QueryCompilationResultActionsResponse): unknown {
    const obj: any = {};
    if (message.compilationResultActions?.length) {
      obj.compilationResultActions = message.compilationResultActions.map((e) => CompilationResultAction.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryCompilationResultActionsResponse>): QueryCompilationResultActionsResponse {
    return QueryCompilationResultActionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryCompilationResultActionsResponse>): QueryCompilationResultActionsResponse {
    const message = createBaseQueryCompilationResultActionsResponse();
    message.compilationResultActions =
      object.compilationResultActions?.map((e) => CompilationResultAction.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseWorkflowConfig(): WorkflowConfig {
  return {
    name: "",
    releaseConfig: "",
    invocationConfig: undefined,
    cronSchedule: "",
    timeZone: "",
    recentScheduledExecutionRecords: [],
  };
}

export const WorkflowConfig: MessageFns<WorkflowConfig> = {
  encode(message: WorkflowConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.releaseConfig !== "") {
      writer.uint32(18).string(message.releaseConfig);
    }
    if (message.invocationConfig !== undefined) {
      InvocationConfig.encode(message.invocationConfig, writer.uint32(26).fork()).join();
    }
    if (message.cronSchedule !== "") {
      writer.uint32(34).string(message.cronSchedule);
    }
    if (message.timeZone !== "") {
      writer.uint32(58).string(message.timeZone);
    }
    for (const v of message.recentScheduledExecutionRecords) {
      WorkflowConfig_ScheduledExecutionRecord.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.releaseConfig = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.invocationConfig = InvocationConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cronSchedule = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.timeZone = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.recentScheduledExecutionRecords.push(
            WorkflowConfig_ScheduledExecutionRecord.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      releaseConfig: isSet(object.releaseConfig) ? globalThis.String(object.releaseConfig) : "",
      invocationConfig: isSet(object.invocationConfig) ? InvocationConfig.fromJSON(object.invocationConfig) : undefined,
      cronSchedule: isSet(object.cronSchedule) ? globalThis.String(object.cronSchedule) : "",
      timeZone: isSet(object.timeZone) ? globalThis.String(object.timeZone) : "",
      recentScheduledExecutionRecords: globalThis.Array.isArray(object?.recentScheduledExecutionRecords)
        ? object.recentScheduledExecutionRecords.map((e: any) => WorkflowConfig_ScheduledExecutionRecord.fromJSON(e))
        : [],
    };
  },

  toJSON(message: WorkflowConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.releaseConfig !== "") {
      obj.releaseConfig = message.releaseConfig;
    }
    if (message.invocationConfig !== undefined) {
      obj.invocationConfig = InvocationConfig.toJSON(message.invocationConfig);
    }
    if (message.cronSchedule !== "") {
      obj.cronSchedule = message.cronSchedule;
    }
    if (message.timeZone !== "") {
      obj.timeZone = message.timeZone;
    }
    if (message.recentScheduledExecutionRecords?.length) {
      obj.recentScheduledExecutionRecords = message.recentScheduledExecutionRecords.map((e) =>
        WorkflowConfig_ScheduledExecutionRecord.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowConfig>): WorkflowConfig {
    return WorkflowConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowConfig>): WorkflowConfig {
    const message = createBaseWorkflowConfig();
    message.name = object.name ?? "";
    message.releaseConfig = object.releaseConfig ?? "";
    message.invocationConfig = (object.invocationConfig !== undefined && object.invocationConfig !== null)
      ? InvocationConfig.fromPartial(object.invocationConfig)
      : undefined;
    message.cronSchedule = object.cronSchedule ?? "";
    message.timeZone = object.timeZone ?? "";
    message.recentScheduledExecutionRecords =
      object.recentScheduledExecutionRecords?.map((e) => WorkflowConfig_ScheduledExecutionRecord.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWorkflowConfig_ScheduledExecutionRecord(): WorkflowConfig_ScheduledExecutionRecord {
  return { executionTime: undefined, workflowInvocation: undefined, errorStatus: undefined };
}

export const WorkflowConfig_ScheduledExecutionRecord: MessageFns<WorkflowConfig_ScheduledExecutionRecord> = {
  encode(message: WorkflowConfig_ScheduledExecutionRecord, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.executionTime !== undefined) {
      Timestamp.encode(toTimestamp(message.executionTime), writer.uint32(10).fork()).join();
    }
    if (message.workflowInvocation !== undefined) {
      writer.uint32(18).string(message.workflowInvocation);
    }
    if (message.errorStatus !== undefined) {
      Status.encode(message.errorStatus, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowConfig_ScheduledExecutionRecord {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowConfig_ScheduledExecutionRecord();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.executionTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workflowInvocation = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.errorStatus = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowConfig_ScheduledExecutionRecord {
    return {
      executionTime: isSet(object.executionTime) ? fromJsonTimestamp(object.executionTime) : undefined,
      workflowInvocation: isSet(object.workflowInvocation) ? globalThis.String(object.workflowInvocation) : undefined,
      errorStatus: isSet(object.errorStatus) ? Status.fromJSON(object.errorStatus) : undefined,
    };
  },

  toJSON(message: WorkflowConfig_ScheduledExecutionRecord): unknown {
    const obj: any = {};
    if (message.executionTime !== undefined) {
      obj.executionTime = message.executionTime.toISOString();
    }
    if (message.workflowInvocation !== undefined) {
      obj.workflowInvocation = message.workflowInvocation;
    }
    if (message.errorStatus !== undefined) {
      obj.errorStatus = Status.toJSON(message.errorStatus);
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowConfig_ScheduledExecutionRecord>): WorkflowConfig_ScheduledExecutionRecord {
    return WorkflowConfig_ScheduledExecutionRecord.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowConfig_ScheduledExecutionRecord>): WorkflowConfig_ScheduledExecutionRecord {
    const message = createBaseWorkflowConfig_ScheduledExecutionRecord();
    message.executionTime = object.executionTime ?? undefined;
    message.workflowInvocation = object.workflowInvocation ?? undefined;
    message.errorStatus = (object.errorStatus !== undefined && object.errorStatus !== null)
      ? Status.fromPartial(object.errorStatus)
      : undefined;
    return message;
  },
};

function createBaseInvocationConfig(): InvocationConfig {
  return {
    includedTargets: [],
    includedTags: [],
    transitiveDependenciesIncluded: false,
    transitiveDependentsIncluded: false,
    fullyRefreshIncrementalTablesEnabled: false,
    serviceAccount: "",
  };
}

export const InvocationConfig: MessageFns<InvocationConfig> = {
  encode(message: InvocationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.includedTargets) {
      Target.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.includedTags) {
      writer.uint32(18).string(v!);
    }
    if (message.transitiveDependenciesIncluded !== false) {
      writer.uint32(24).bool(message.transitiveDependenciesIncluded);
    }
    if (message.transitiveDependentsIncluded !== false) {
      writer.uint32(32).bool(message.transitiveDependentsIncluded);
    }
    if (message.fullyRefreshIncrementalTablesEnabled !== false) {
      writer.uint32(40).bool(message.fullyRefreshIncrementalTablesEnabled);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(50).string(message.serviceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InvocationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInvocationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includedTargets.push(Target.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.includedTags.push(reader.string());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.transitiveDependenciesIncluded = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.transitiveDependentsIncluded = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.fullyRefreshIncrementalTablesEnabled = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InvocationConfig {
    return {
      includedTargets: globalThis.Array.isArray(object?.includedTargets)
        ? object.includedTargets.map((e: any) => Target.fromJSON(e))
        : [],
      includedTags: globalThis.Array.isArray(object?.includedTags)
        ? object.includedTags.map((e: any) => globalThis.String(e))
        : [],
      transitiveDependenciesIncluded: isSet(object.transitiveDependenciesIncluded)
        ? globalThis.Boolean(object.transitiveDependenciesIncluded)
        : false,
      transitiveDependentsIncluded: isSet(object.transitiveDependentsIncluded)
        ? globalThis.Boolean(object.transitiveDependentsIncluded)
        : false,
      fullyRefreshIncrementalTablesEnabled: isSet(object.fullyRefreshIncrementalTablesEnabled)
        ? globalThis.Boolean(object.fullyRefreshIncrementalTablesEnabled)
        : false,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
    };
  },

  toJSON(message: InvocationConfig): unknown {
    const obj: any = {};
    if (message.includedTargets?.length) {
      obj.includedTargets = message.includedTargets.map((e) => Target.toJSON(e));
    }
    if (message.includedTags?.length) {
      obj.includedTags = message.includedTags;
    }
    if (message.transitiveDependenciesIncluded !== false) {
      obj.transitiveDependenciesIncluded = message.transitiveDependenciesIncluded;
    }
    if (message.transitiveDependentsIncluded !== false) {
      obj.transitiveDependentsIncluded = message.transitiveDependentsIncluded;
    }
    if (message.fullyRefreshIncrementalTablesEnabled !== false) {
      obj.fullyRefreshIncrementalTablesEnabled = message.fullyRefreshIncrementalTablesEnabled;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<InvocationConfig>): InvocationConfig {
    return InvocationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InvocationConfig>): InvocationConfig {
    const message = createBaseInvocationConfig();
    message.includedTargets = object.includedTargets?.map((e) => Target.fromPartial(e)) || [];
    message.includedTags = object.includedTags?.map((e) => e) || [];
    message.transitiveDependenciesIncluded = object.transitiveDependenciesIncluded ?? false;
    message.transitiveDependentsIncluded = object.transitiveDependentsIncluded ?? false;
    message.fullyRefreshIncrementalTablesEnabled = object.fullyRefreshIncrementalTablesEnabled ?? false;
    message.serviceAccount = object.serviceAccount ?? "";
    return message;
  },
};

function createBaseListWorkflowConfigsRequest(): ListWorkflowConfigsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListWorkflowConfigsRequest: MessageFns<ListWorkflowConfigsRequest> = {
  encode(message: ListWorkflowConfigsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkflowConfigsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkflowConfigsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkflowConfigsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListWorkflowConfigsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkflowConfigsRequest>): ListWorkflowConfigsRequest {
    return ListWorkflowConfigsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkflowConfigsRequest>): ListWorkflowConfigsRequest {
    const message = createBaseListWorkflowConfigsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListWorkflowConfigsResponse(): ListWorkflowConfigsResponse {
  return { workflowConfigs: [], nextPageToken: "", unreachable: [] };
}

export const ListWorkflowConfigsResponse: MessageFns<ListWorkflowConfigsResponse> = {
  encode(message: ListWorkflowConfigsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workflowConfigs) {
      WorkflowConfig.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkflowConfigsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkflowConfigsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workflowConfigs.push(WorkflowConfig.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkflowConfigsResponse {
    return {
      workflowConfigs: globalThis.Array.isArray(object?.workflowConfigs)
        ? object.workflowConfigs.map((e: any) => WorkflowConfig.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListWorkflowConfigsResponse): unknown {
    const obj: any = {};
    if (message.workflowConfigs?.length) {
      obj.workflowConfigs = message.workflowConfigs.map((e) => WorkflowConfig.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkflowConfigsResponse>): ListWorkflowConfigsResponse {
    return ListWorkflowConfigsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkflowConfigsResponse>): ListWorkflowConfigsResponse {
    const message = createBaseListWorkflowConfigsResponse();
    message.workflowConfigs = object.workflowConfigs?.map((e) => WorkflowConfig.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetWorkflowConfigRequest(): GetWorkflowConfigRequest {
  return { name: "" };
}

export const GetWorkflowConfigRequest: MessageFns<GetWorkflowConfigRequest> = {
  encode(message: GetWorkflowConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetWorkflowConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetWorkflowConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetWorkflowConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetWorkflowConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetWorkflowConfigRequest>): GetWorkflowConfigRequest {
    return GetWorkflowConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetWorkflowConfigRequest>): GetWorkflowConfigRequest {
    const message = createBaseGetWorkflowConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateWorkflowConfigRequest(): CreateWorkflowConfigRequest {
  return { parent: "", workflowConfig: undefined, workflowConfigId: "" };
}

export const CreateWorkflowConfigRequest: MessageFns<CreateWorkflowConfigRequest> = {
  encode(message: CreateWorkflowConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.workflowConfig !== undefined) {
      WorkflowConfig.encode(message.workflowConfig, writer.uint32(18).fork()).join();
    }
    if (message.workflowConfigId !== "") {
      writer.uint32(26).string(message.workflowConfigId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateWorkflowConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateWorkflowConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workflowConfig = WorkflowConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.workflowConfigId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateWorkflowConfigRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      workflowConfig: isSet(object.workflowConfig) ? WorkflowConfig.fromJSON(object.workflowConfig) : undefined,
      workflowConfigId: isSet(object.workflowConfigId) ? globalThis.String(object.workflowConfigId) : "",
    };
  },

  toJSON(message: CreateWorkflowConfigRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.workflowConfig !== undefined) {
      obj.workflowConfig = WorkflowConfig.toJSON(message.workflowConfig);
    }
    if (message.workflowConfigId !== "") {
      obj.workflowConfigId = message.workflowConfigId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateWorkflowConfigRequest>): CreateWorkflowConfigRequest {
    return CreateWorkflowConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateWorkflowConfigRequest>): CreateWorkflowConfigRequest {
    const message = createBaseCreateWorkflowConfigRequest();
    message.parent = object.parent ?? "";
    message.workflowConfig = (object.workflowConfig !== undefined && object.workflowConfig !== null)
      ? WorkflowConfig.fromPartial(object.workflowConfig)
      : undefined;
    message.workflowConfigId = object.workflowConfigId ?? "";
    return message;
  },
};

function createBaseUpdateWorkflowConfigRequest(): UpdateWorkflowConfigRequest {
  return { updateMask: undefined, workflowConfig: undefined };
}

export const UpdateWorkflowConfigRequest: MessageFns<UpdateWorkflowConfigRequest> = {
  encode(message: UpdateWorkflowConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.workflowConfig !== undefined) {
      WorkflowConfig.encode(message.workflowConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateWorkflowConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateWorkflowConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workflowConfig = WorkflowConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateWorkflowConfigRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      workflowConfig: isSet(object.workflowConfig) ? WorkflowConfig.fromJSON(object.workflowConfig) : undefined,
    };
  },

  toJSON(message: UpdateWorkflowConfigRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.workflowConfig !== undefined) {
      obj.workflowConfig = WorkflowConfig.toJSON(message.workflowConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateWorkflowConfigRequest>): UpdateWorkflowConfigRequest {
    return UpdateWorkflowConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateWorkflowConfigRequest>): UpdateWorkflowConfigRequest {
    const message = createBaseUpdateWorkflowConfigRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.workflowConfig = (object.workflowConfig !== undefined && object.workflowConfig !== null)
      ? WorkflowConfig.fromPartial(object.workflowConfig)
      : undefined;
    return message;
  },
};

function createBaseDeleteWorkflowConfigRequest(): DeleteWorkflowConfigRequest {
  return { name: "" };
}

export const DeleteWorkflowConfigRequest: MessageFns<DeleteWorkflowConfigRequest> = {
  encode(message: DeleteWorkflowConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteWorkflowConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteWorkflowConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteWorkflowConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteWorkflowConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteWorkflowConfigRequest>): DeleteWorkflowConfigRequest {
    return DeleteWorkflowConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteWorkflowConfigRequest>): DeleteWorkflowConfigRequest {
    const message = createBaseDeleteWorkflowConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseWorkflowInvocation(): WorkflowInvocation {
  return {
    name: "",
    compilationResult: undefined,
    workflowConfig: undefined,
    invocationConfig: undefined,
    state: 0,
    invocationTiming: undefined,
  };
}

export const WorkflowInvocation: MessageFns<WorkflowInvocation> = {
  encode(message: WorkflowInvocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.compilationResult !== undefined) {
      writer.uint32(18).string(message.compilationResult);
    }
    if (message.workflowConfig !== undefined) {
      writer.uint32(50).string(message.workflowConfig);
    }
    if (message.invocationConfig !== undefined) {
      InvocationConfig.encode(message.invocationConfig, writer.uint32(26).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.invocationTiming !== undefined) {
      Interval.encode(message.invocationTiming, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowInvocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowInvocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.compilationResult = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.workflowConfig = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.invocationConfig = InvocationConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.invocationTiming = Interval.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowInvocation {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      compilationResult: isSet(object.compilationResult) ? globalThis.String(object.compilationResult) : undefined,
      workflowConfig: isSet(object.workflowConfig) ? globalThis.String(object.workflowConfig) : undefined,
      invocationConfig: isSet(object.invocationConfig) ? InvocationConfig.fromJSON(object.invocationConfig) : undefined,
      state: isSet(object.state) ? workflowInvocation_StateFromJSON(object.state) : 0,
      invocationTiming: isSet(object.invocationTiming) ? Interval.fromJSON(object.invocationTiming) : undefined,
    };
  },

  toJSON(message: WorkflowInvocation): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.compilationResult !== undefined) {
      obj.compilationResult = message.compilationResult;
    }
    if (message.workflowConfig !== undefined) {
      obj.workflowConfig = message.workflowConfig;
    }
    if (message.invocationConfig !== undefined) {
      obj.invocationConfig = InvocationConfig.toJSON(message.invocationConfig);
    }
    if (message.state !== 0) {
      obj.state = workflowInvocation_StateToJSON(message.state);
    }
    if (message.invocationTiming !== undefined) {
      obj.invocationTiming = Interval.toJSON(message.invocationTiming);
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowInvocation>): WorkflowInvocation {
    return WorkflowInvocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowInvocation>): WorkflowInvocation {
    const message = createBaseWorkflowInvocation();
    message.name = object.name ?? "";
    message.compilationResult = object.compilationResult ?? undefined;
    message.workflowConfig = object.workflowConfig ?? undefined;
    message.invocationConfig = (object.invocationConfig !== undefined && object.invocationConfig !== null)
      ? InvocationConfig.fromPartial(object.invocationConfig)
      : undefined;
    message.state = object.state ?? 0;
    message.invocationTiming = (object.invocationTiming !== undefined && object.invocationTiming !== null)
      ? Interval.fromPartial(object.invocationTiming)
      : undefined;
    return message;
  },
};

function createBaseListWorkflowInvocationsRequest(): ListWorkflowInvocationsRequest {
  return { parent: "", pageSize: 0, pageToken: "", orderBy: "", filter: "" };
}

export const ListWorkflowInvocationsRequest: MessageFns<ListWorkflowInvocationsRequest> = {
  encode(message: ListWorkflowInvocationsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkflowInvocationsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkflowInvocationsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkflowInvocationsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListWorkflowInvocationsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkflowInvocationsRequest>): ListWorkflowInvocationsRequest {
    return ListWorkflowInvocationsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkflowInvocationsRequest>): ListWorkflowInvocationsRequest {
    const message = createBaseListWorkflowInvocationsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListWorkflowInvocationsResponse(): ListWorkflowInvocationsResponse {
  return { workflowInvocations: [], nextPageToken: "", unreachable: [] };
}

export const ListWorkflowInvocationsResponse: MessageFns<ListWorkflowInvocationsResponse> = {
  encode(message: ListWorkflowInvocationsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workflowInvocations) {
      WorkflowInvocation.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkflowInvocationsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkflowInvocationsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workflowInvocations.push(WorkflowInvocation.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkflowInvocationsResponse {
    return {
      workflowInvocations: globalThis.Array.isArray(object?.workflowInvocations)
        ? object.workflowInvocations.map((e: any) => WorkflowInvocation.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListWorkflowInvocationsResponse): unknown {
    const obj: any = {};
    if (message.workflowInvocations?.length) {
      obj.workflowInvocations = message.workflowInvocations.map((e) => WorkflowInvocation.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkflowInvocationsResponse>): ListWorkflowInvocationsResponse {
    return ListWorkflowInvocationsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkflowInvocationsResponse>): ListWorkflowInvocationsResponse {
    const message = createBaseListWorkflowInvocationsResponse();
    message.workflowInvocations = object.workflowInvocations?.map((e) => WorkflowInvocation.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetWorkflowInvocationRequest(): GetWorkflowInvocationRequest {
  return { name: "" };
}

export const GetWorkflowInvocationRequest: MessageFns<GetWorkflowInvocationRequest> = {
  encode(message: GetWorkflowInvocationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetWorkflowInvocationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetWorkflowInvocationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetWorkflowInvocationRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetWorkflowInvocationRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetWorkflowInvocationRequest>): GetWorkflowInvocationRequest {
    return GetWorkflowInvocationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetWorkflowInvocationRequest>): GetWorkflowInvocationRequest {
    const message = createBaseGetWorkflowInvocationRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateWorkflowInvocationRequest(): CreateWorkflowInvocationRequest {
  return { parent: "", workflowInvocation: undefined };
}

export const CreateWorkflowInvocationRequest: MessageFns<CreateWorkflowInvocationRequest> = {
  encode(message: CreateWorkflowInvocationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.workflowInvocation !== undefined) {
      WorkflowInvocation.encode(message.workflowInvocation, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateWorkflowInvocationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateWorkflowInvocationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workflowInvocation = WorkflowInvocation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateWorkflowInvocationRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      workflowInvocation: isSet(object.workflowInvocation)
        ? WorkflowInvocation.fromJSON(object.workflowInvocation)
        : undefined,
    };
  },

  toJSON(message: CreateWorkflowInvocationRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.workflowInvocation !== undefined) {
      obj.workflowInvocation = WorkflowInvocation.toJSON(message.workflowInvocation);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateWorkflowInvocationRequest>): CreateWorkflowInvocationRequest {
    return CreateWorkflowInvocationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateWorkflowInvocationRequest>): CreateWorkflowInvocationRequest {
    const message = createBaseCreateWorkflowInvocationRequest();
    message.parent = object.parent ?? "";
    message.workflowInvocation = (object.workflowInvocation !== undefined && object.workflowInvocation !== null)
      ? WorkflowInvocation.fromPartial(object.workflowInvocation)
      : undefined;
    return message;
  },
};

function createBaseDeleteWorkflowInvocationRequest(): DeleteWorkflowInvocationRequest {
  return { name: "" };
}

export const DeleteWorkflowInvocationRequest: MessageFns<DeleteWorkflowInvocationRequest> = {
  encode(message: DeleteWorkflowInvocationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteWorkflowInvocationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteWorkflowInvocationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteWorkflowInvocationRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteWorkflowInvocationRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteWorkflowInvocationRequest>): DeleteWorkflowInvocationRequest {
    return DeleteWorkflowInvocationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteWorkflowInvocationRequest>): DeleteWorkflowInvocationRequest {
    const message = createBaseDeleteWorkflowInvocationRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCancelWorkflowInvocationRequest(): CancelWorkflowInvocationRequest {
  return { name: "" };
}

export const CancelWorkflowInvocationRequest: MessageFns<CancelWorkflowInvocationRequest> = {
  encode(message: CancelWorkflowInvocationRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelWorkflowInvocationRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelWorkflowInvocationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelWorkflowInvocationRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: CancelWorkflowInvocationRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelWorkflowInvocationRequest>): CancelWorkflowInvocationRequest {
    return CancelWorkflowInvocationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelWorkflowInvocationRequest>): CancelWorkflowInvocationRequest {
    const message = createBaseCancelWorkflowInvocationRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseWorkflowInvocationAction(): WorkflowInvocationAction {
  return {
    target: undefined,
    canonicalTarget: undefined,
    state: 0,
    failureReason: "",
    invocationTiming: undefined,
    bigqueryAction: undefined,
  };
}

export const WorkflowInvocationAction: MessageFns<WorkflowInvocationAction> = {
  encode(message: WorkflowInvocationAction, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.target !== undefined) {
      Target.encode(message.target, writer.uint32(10).fork()).join();
    }
    if (message.canonicalTarget !== undefined) {
      Target.encode(message.canonicalTarget, writer.uint32(18).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.failureReason !== "") {
      writer.uint32(58).string(message.failureReason);
    }
    if (message.invocationTiming !== undefined) {
      Interval.encode(message.invocationTiming, writer.uint32(42).fork()).join();
    }
    if (message.bigqueryAction !== undefined) {
      WorkflowInvocationAction_BigQueryAction.encode(message.bigqueryAction, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowInvocationAction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowInvocationAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.target = Target.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.canonicalTarget = Target.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.failureReason = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.invocationTiming = Interval.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.bigqueryAction = WorkflowInvocationAction_BigQueryAction.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowInvocationAction {
    return {
      target: isSet(object.target) ? Target.fromJSON(object.target) : undefined,
      canonicalTarget: isSet(object.canonicalTarget) ? Target.fromJSON(object.canonicalTarget) : undefined,
      state: isSet(object.state) ? workflowInvocationAction_StateFromJSON(object.state) : 0,
      failureReason: isSet(object.failureReason) ? globalThis.String(object.failureReason) : "",
      invocationTiming: isSet(object.invocationTiming) ? Interval.fromJSON(object.invocationTiming) : undefined,
      bigqueryAction: isSet(object.bigqueryAction)
        ? WorkflowInvocationAction_BigQueryAction.fromJSON(object.bigqueryAction)
        : undefined,
    };
  },

  toJSON(message: WorkflowInvocationAction): unknown {
    const obj: any = {};
    if (message.target !== undefined) {
      obj.target = Target.toJSON(message.target);
    }
    if (message.canonicalTarget !== undefined) {
      obj.canonicalTarget = Target.toJSON(message.canonicalTarget);
    }
    if (message.state !== 0) {
      obj.state = workflowInvocationAction_StateToJSON(message.state);
    }
    if (message.failureReason !== "") {
      obj.failureReason = message.failureReason;
    }
    if (message.invocationTiming !== undefined) {
      obj.invocationTiming = Interval.toJSON(message.invocationTiming);
    }
    if (message.bigqueryAction !== undefined) {
      obj.bigqueryAction = WorkflowInvocationAction_BigQueryAction.toJSON(message.bigqueryAction);
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowInvocationAction>): WorkflowInvocationAction {
    return WorkflowInvocationAction.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowInvocationAction>): WorkflowInvocationAction {
    const message = createBaseWorkflowInvocationAction();
    message.target = (object.target !== undefined && object.target !== null)
      ? Target.fromPartial(object.target)
      : undefined;
    message.canonicalTarget = (object.canonicalTarget !== undefined && object.canonicalTarget !== null)
      ? Target.fromPartial(object.canonicalTarget)
      : undefined;
    message.state = object.state ?? 0;
    message.failureReason = object.failureReason ?? "";
    message.invocationTiming = (object.invocationTiming !== undefined && object.invocationTiming !== null)
      ? Interval.fromPartial(object.invocationTiming)
      : undefined;
    message.bigqueryAction = (object.bigqueryAction !== undefined && object.bigqueryAction !== null)
      ? WorkflowInvocationAction_BigQueryAction.fromPartial(object.bigqueryAction)
      : undefined;
    return message;
  },
};

function createBaseWorkflowInvocationAction_BigQueryAction(): WorkflowInvocationAction_BigQueryAction {
  return { sqlScript: "" };
}

export const WorkflowInvocationAction_BigQueryAction: MessageFns<WorkflowInvocationAction_BigQueryAction> = {
  encode(message: WorkflowInvocationAction_BigQueryAction, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlScript !== "") {
      writer.uint32(10).string(message.sqlScript);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkflowInvocationAction_BigQueryAction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkflowInvocationAction_BigQueryAction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sqlScript = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkflowInvocationAction_BigQueryAction {
    return { sqlScript: isSet(object.sqlScript) ? globalThis.String(object.sqlScript) : "" };
  },

  toJSON(message: WorkflowInvocationAction_BigQueryAction): unknown {
    const obj: any = {};
    if (message.sqlScript !== "") {
      obj.sqlScript = message.sqlScript;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkflowInvocationAction_BigQueryAction>): WorkflowInvocationAction_BigQueryAction {
    return WorkflowInvocationAction_BigQueryAction.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkflowInvocationAction_BigQueryAction>): WorkflowInvocationAction_BigQueryAction {
    const message = createBaseWorkflowInvocationAction_BigQueryAction();
    message.sqlScript = object.sqlScript ?? "";
    return message;
  },
};

function createBaseQueryWorkflowInvocationActionsRequest(): QueryWorkflowInvocationActionsRequest {
  return { name: "", pageSize: 0, pageToken: "" };
}

export const QueryWorkflowInvocationActionsRequest: MessageFns<QueryWorkflowInvocationActionsRequest> = {
  encode(message: QueryWorkflowInvocationActionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryWorkflowInvocationActionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryWorkflowInvocationActionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryWorkflowInvocationActionsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: QueryWorkflowInvocationActionsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryWorkflowInvocationActionsRequest>): QueryWorkflowInvocationActionsRequest {
    return QueryWorkflowInvocationActionsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryWorkflowInvocationActionsRequest>): QueryWorkflowInvocationActionsRequest {
    const message = createBaseQueryWorkflowInvocationActionsRequest();
    message.name = object.name ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseQueryWorkflowInvocationActionsResponse(): QueryWorkflowInvocationActionsResponse {
  return { workflowInvocationActions: [], nextPageToken: "" };
}

export const QueryWorkflowInvocationActionsResponse: MessageFns<QueryWorkflowInvocationActionsResponse> = {
  encode(message: QueryWorkflowInvocationActionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workflowInvocationActions) {
      WorkflowInvocationAction.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryWorkflowInvocationActionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryWorkflowInvocationActionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workflowInvocationActions.push(WorkflowInvocationAction.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryWorkflowInvocationActionsResponse {
    return {
      workflowInvocationActions: globalThis.Array.isArray(object?.workflowInvocationActions)
        ? object.workflowInvocationActions.map((e: any) => WorkflowInvocationAction.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: QueryWorkflowInvocationActionsResponse): unknown {
    const obj: any = {};
    if (message.workflowInvocationActions?.length) {
      obj.workflowInvocationActions = message.workflowInvocationActions.map((e) => WorkflowInvocationAction.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<QueryWorkflowInvocationActionsResponse>): QueryWorkflowInvocationActionsResponse {
    return QueryWorkflowInvocationActionsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryWorkflowInvocationActionsResponse>): QueryWorkflowInvocationActionsResponse {
    const message = createBaseQueryWorkflowInvocationActionsResponse();
    message.workflowInvocationActions =
      object.workflowInvocationActions?.map((e) => WorkflowInvocationAction.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

/**
 * Dataform is a service to develop, create, document, test, and update curated
 * tables in BigQuery.
 */
export type DataformDefinition = typeof DataformDefinition;
export const DataformDefinition = {
  name: "Dataform",
  fullName: "google.cloud.dataform.v1beta1.Dataform",
  methods: {
    /** Lists Repositories in a given project and location. */
    listRepositories: {
      name: "ListRepositories",
      requestType: ListRepositoriesRequest,
      requestStream: false,
      responseType: ListRepositoriesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              55,
              18,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a single Repository. */
    getRepository: {
      name: "GetRepository",
      requestType: GetRepositoryRequest,
      requestStream: false,
      responseType: Repository,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              55,
              18,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new Repository in a given project and location. */
    createRepository: {
      name: "CreateRepository",
      requestType: CreateRepositoryRequest,
      requestStream: false,
      responseType: Repository,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              31,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              121,
              44,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              121,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              67,
              58,
              10,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              121,
              34,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a single Repository. */
    updateRepository: {
      name: "UpdateRepository",
      requestType: UpdateRepositoryRequest,
      requestStream: false,
      responseType: Repository,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              121,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              78,
              58,
              10,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              121,
              50,
              64,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              121,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a single Repository. */
    deleteRepository: {
      name: "DeleteRepository",
      requestType: DeleteRepositoryRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              55,
              42,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Applies a Git commit to a Repository. The Repository must not have a value
     * for `git_remote_settings.url`.
     */
    commitRepositoryChanges: {
      name: "CommitRepositoryChanges",
      requestType: CommitRepositoryChangesRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              58,
              99,
              111,
              109,
              109,
              105,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the contents of a file (inside a Repository). The Repository
     * must not have a value for `git_remote_settings.url`.
     */
    readRepositoryFile: {
      name: "ReadRepositoryFile",
      requestType: ReadRepositoryFileRequest,
      requestStream: false,
      responseType: ReadRepositoryFileResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              64,
              18,
              62,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              70,
              105,
              108,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the contents of a given Repository directory. The Repository must
     * not have a value for `git_remote_settings.url`.
     */
    queryRepositoryDirectoryContents: {
      name: "QueryRepositoryDirectoryContents",
      requestType: QueryRepositoryDirectoryContentsRequest,
      requestStream: false,
      responseType: QueryRepositoryDirectoryContentsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              78,
              18,
              76,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              58,
              113,
              117,
              101,
              114,
              121,
              68,
              105,
              114,
              101,
              99,
              116,
              111,
              114,
              121,
              67,
              111,
              110,
              116,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Fetches a Repository's history of commits.  The Repository must not have a
     * value for `git_remote_settings.url`.
     */
    fetchRepositoryHistory: {
      name: "FetchRepositoryHistory",
      requestType: FetchRepositoryHistoryRequest,
      requestStream: false,
      responseType: FetchRepositoryHistoryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              68,
              18,
              66,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              58,
              102,
              101,
              116,
              99,
              104,
              72,
              105,
              115,
              116,
              111,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /** Computes a Repository's Git access token status. */
    computeRepositoryAccessTokenStatus: {
      name: "ComputeRepositoryAccessTokenStatus",
      requestType: ComputeRepositoryAccessTokenStatusRequest,
      requestStream: false,
      responseType: ComputeRepositoryAccessTokenStatusResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              80,
              18,
              78,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              58,
              99,
              111,
              109,
              112,
              117,
              116,
              101,
              65,
              99,
              99,
              101,
              115,
              115,
              84,
              111,
              107,
              101,
              110,
              83,
              116,
              97,
              116,
              117,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a Repository's remote branches. */
    fetchRemoteBranches: {
      name: "FetchRemoteBranches",
      requestType: FetchRemoteBranchesRequest,
      requestStream: false,
      responseType: FetchRemoteBranchesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              75,
              18,
              73,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              58,
              102,
              101,
              116,
              99,
              104,
              82,
              101,
              109,
              111,
              116,
              101,
              66,
              114,
              97,
              110,
              99,
              104,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists Workspaces in a given Repository. */
    listWorkspaces: {
      name: "ListWorkspaces",
      requestType: ListWorkspacesRequest,
      requestStream: false,
      responseType: ListWorkspacesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              68,
              18,
              66,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a single Workspace. */
    getWorkspace: {
      name: "GetWorkspace",
      requestType: GetWorkspaceRequest,
      requestStream: false,
      responseType: Workspace,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              68,
              18,
              66,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new Workspace in a given Repository. */
    createWorkspace: {
      name: "CreateWorkspace",
      requestType: CreateWorkspaceRequest,
      requestStream: false,
      responseType: Workspace,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              29,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              44,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              79,
              58,
              9,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              34,
              66,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a single Workspace. */
    deleteWorkspace: {
      name: "DeleteWorkspace",
      requestType: DeleteWorkspaceRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              68,
              42,
              66,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Installs dependency NPM packages (inside a Workspace). */
    installNpmPackages: {
      name: "InstallNpmPackages",
      requestType: InstallNpmPackagesRequest,
      requestStream: false,
      responseType: InstallNpmPackagesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              95,
              58,
              1,
              42,
              34,
              90,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              110,
              115,
              116,
              97,
              108,
              108,
              78,
              112,
              109,
              80,
              97,
              99,
              107,
              97,
              103,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Pulls Git commits from the Repository's remote into a Workspace. */
    pullGitCommits: {
      name: "PullGitCommits",
      requestType: PullGitCommitsRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              76,
              58,
              1,
              42,
              34,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              112,
              117,
              108,
              108,
            ]),
          ],
        },
      },
    },
    /** Pushes Git commits from a Workspace to the Repository's remote. */
    pushGitCommits: {
      name: "PushGitCommits",
      requestType: PushGitCommitsRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              76,
              58,
              1,
              42,
              34,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              112,
              117,
              115,
              104,
            ]),
          ],
        },
      },
    },
    /** Fetches Git statuses for the files in a Workspace. */
    fetchFileGitStatuses: {
      name: "FetchFileGitStatuses",
      requestType: FetchFileGitStatusesRequest,
      requestStream: false,
      responseType: FetchFileGitStatusesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              89,
              18,
              87,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              102,
              101,
              116,
              99,
              104,
              70,
              105,
              108,
              101,
              71,
              105,
              116,
              83,
              116,
              97,
              116,
              117,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches Git ahead/behind against a remote branch. */
    fetchGitAheadBehind: {
      name: "FetchGitAheadBehind",
      requestType: FetchGitAheadBehindRequest,
      requestStream: false,
      responseType: FetchGitAheadBehindResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              88,
              18,
              86,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              102,
              101,
              116,
              99,
              104,
              71,
              105,
              116,
              65,
              104,
              101,
              97,
              100,
              66,
              101,
              104,
              105,
              110,
              100,
            ]),
          ],
        },
      },
    },
    /** Applies a Git commit for uncommitted files in a Workspace. */
    commitWorkspaceChanges: {
      name: "CommitWorkspaceChanges",
      requestType: CommitWorkspaceChangesRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              78,
              58,
              1,
              42,
              34,
              73,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              99,
              111,
              109,
              109,
              105,
              116,
            ]),
          ],
        },
      },
    },
    /** Performs a Git reset for uncommitted files in a Workspace. */
    resetWorkspaceChanges: {
      name: "ResetWorkspaceChanges",
      requestType: ResetWorkspaceChangesRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              77,
              58,
              1,
              42,
              34,
              72,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              115,
              101,
              116,
            ]),
          ],
        },
      },
    },
    /** Fetches Git diff for an uncommitted file in a Workspace. */
    fetchFileDiff: {
      name: "FetchFileDiff",
      requestType: FetchFileDiffRequest,
      requestStream: false,
      responseType: FetchFileDiffResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              87,
              18,
              85,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              102,
              101,
              116,
              99,
              104,
              70,
              105,
              108,
              101,
              68,
              105,
              102,
              102,
            ]),
          ],
        },
      },
    },
    /** Returns the contents of a given Workspace directory. */
    queryDirectoryContents: {
      name: "QueryDirectoryContents",
      requestType: QueryDirectoryContentsRequest,
      requestStream: false,
      responseType: QueryDirectoryContentsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              96,
              18,
              94,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              113,
              117,
              101,
              114,
              121,
              68,
              105,
              114,
              101,
              99,
              116,
              111,
              114,
              121,
              67,
              111,
              110,
              116,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Creates a directory inside a Workspace. */
    makeDirectory: {
      name: "MakeDirectory",
      requestType: MakeDirectoryRequest,
      requestStream: false,
      responseType: MakeDirectoryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              90,
              58,
              1,
              42,
              34,
              85,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              97,
              107,
              101,
              68,
              105,
              114,
              101,
              99,
              116,
              111,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /** Deletes a directory (inside a Workspace) and all of its contents. */
    removeDirectory: {
      name: "RemoveDirectory",
      requestType: RemoveDirectoryRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              92,
              58,
              1,
              42,
              34,
              87,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              109,
              111,
              118,
              101,
              68,
              105,
              114,
              101,
              99,
              116,
              111,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Moves a directory (inside a Workspace), and all of its contents, to a new
     * location.
     */
    moveDirectory: {
      name: "MoveDirectory",
      requestType: MoveDirectoryRequest,
      requestStream: false,
      responseType: MoveDirectoryResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              90,
              58,
              1,
              42,
              34,
              85,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              111,
              118,
              101,
              68,
              105,
              114,
              101,
              99,
              116,
              111,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /** Returns the contents of a file (inside a Workspace). */
    readFile: {
      name: "ReadFile",
      requestType: ReadFileRequest,
      requestStream: false,
      responseType: ReadFileResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              82,
              18,
              80,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              70,
              105,
              108,
              101,
            ]),
          ],
        },
      },
    },
    /** Deletes a file (inside a Workspace). */
    removeFile: {
      name: "RemoveFile",
      requestType: RemoveFileRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              87,
              58,
              1,
              42,
              34,
              82,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              109,
              111,
              118,
              101,
              70,
              105,
              108,
              101,
            ]),
          ],
        },
      },
    },
    /** Moves a file (inside a Workspace) to a new location. */
    moveFile: {
      name: "MoveFile",
      requestType: MoveFileRequest,
      requestStream: false,
      responseType: MoveFileResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              85,
              58,
              1,
              42,
              34,
              80,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              111,
              118,
              101,
              70,
              105,
              108,
              101,
            ]),
          ],
        },
      },
    },
    /** Writes to a file (inside a Workspace). */
    writeFile: {
      name: "WriteFile",
      requestType: WriteFileRequest,
      requestStream: false,
      responseType: WriteFileResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              86,
              58,
              1,
              42,
              34,
              81,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              115,
              112,
              97,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              119,
              114,
              105,
              116,
              101,
              70,
              105,
              108,
              101,
            ]),
          ],
        },
      },
    },
    /** Lists ReleaseConfigs in a given Repository. */
    listReleaseConfigs: {
      name: "ListReleaseConfigs",
      requestType: ListReleaseConfigsRequest,
      requestStream: false,
      responseType: ListReleaseConfigsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              72,
              18,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a single ReleaseConfig. */
    getReleaseConfig: {
      name: "GetReleaseConfig",
      requestType: GetReleaseConfigRequest,
      requestStream: false,
      responseType: ReleaseConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              72,
              18,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new ReleaseConfig in a given Repository. */
    createReleaseConfig: {
      name: "CreateReleaseConfig",
      requestType: CreateReleaseConfigRequest,
      requestStream: false,
      responseType: ReleaseConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              39,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              88,
              58,
              14,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              34,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a single ReleaseConfig. */
    updateReleaseConfig: {
      name: "UpdateReleaseConfig",
      requestType: UpdateReleaseConfigRequest,
      requestStream: false,
      responseType: ReleaseConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              26,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              103,
              58,
              14,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              50,
              85,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a single ReleaseConfig. */
    deleteReleaseConfig: {
      name: "DeleteReleaseConfig",
      requestType: DeleteReleaseConfigRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              72,
              42,
              70,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              114,
              101,
              108,
              101,
              97,
              115,
              101,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists CompilationResults in a given Repository. */
    listCompilationResults: {
      name: "ListCompilationResults",
      requestType: ListCompilationResultsRequest,
      requestStream: false,
      responseType: ListCompilationResultsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              76,
              18,
              74,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              109,
              112,
              105,
              108,
              97,
              116,
              105,
              111,
              110,
              82,
              101,
              115,
              117,
              108,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a single CompilationResult. */
    getCompilationResult: {
      name: "GetCompilationResult",
      requestType: GetCompilationResultRequest,
      requestStream: false,
      responseType: CompilationResult,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              76,
              18,
              74,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              109,
              112,
              105,
              108,
              97,
              116,
              105,
              111,
              110,
              82,
              101,
              115,
              117,
              108,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new CompilationResult in a given project and location. */
    createCompilationResult: {
      name: "CreateCompilationResult",
      requestType: CreateCompilationResultRequest,
      requestStream: false,
      responseType: CompilationResult,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              25,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              99,
              111,
              109,
              112,
              105,
              108,
              97,
              116,
              105,
              111,
              110,
              95,
              114,
              101,
              115,
              117,
              108,
              116,
            ]),
          ],
          578365826: [
            Buffer.from([
              96,
              58,
              18,
              99,
              111,
              109,
              112,
              105,
              108,
              97,
              116,
              105,
              111,
              110,
              95,
              114,
              101,
              115,
              117,
              108,
              116,
              34,
              74,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              99,
              111,
              109,
              112,
              105,
              108,
              97,
              116,
              105,
              111,
              110,
              82,
              101,
              115,
              117,
              108,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Returns CompilationResultActions in a given CompilationResult. */
    queryCompilationResultActions: {
      name: "QueryCompilationResultActions",
      requestType: QueryCompilationResultActionsRequest,
      requestStream: false,
      responseType: QueryCompilationResultActionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              82,
              18,
              80,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              109,
              112,
              105,
              108,
              97,
              116,
              105,
              111,
              110,
              82,
              101,
              115,
              117,
              108,
              116,
              115,
              47,
              42,
              125,
              58,
              113,
              117,
              101,
              114,
              121,
            ]),
          ],
        },
      },
    },
    /** Lists WorkflowConfigs in a given Repository. */
    listWorkflowConfigs: {
      name: "ListWorkflowConfigs",
      requestType: ListWorkflowConfigsRequest,
      requestStream: false,
      responseType: ListWorkflowConfigsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              73,
              18,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a single WorkflowConfig. */
    getWorkflowConfig: {
      name: "GetWorkflowConfig",
      requestType: GetWorkflowConfigRequest,
      requestStream: false,
      responseType: WorkflowConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              73,
              18,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new WorkflowConfig in a given Repository. */
    createWorkflowConfig: {
      name: "CreateWorkflowConfig",
      requestType: CreateWorkflowConfigRequest,
      requestStream: false,
      responseType: WorkflowConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              41,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              90,
              58,
              15,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              34,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a single WorkflowConfig. */
    updateWorkflowConfig: {
      name: "UpdateWorkflowConfig",
      requestType: UpdateWorkflowConfigRequest,
      requestStream: false,
      responseType: WorkflowConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              27,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              106,
              58,
              15,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              50,
              87,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a single WorkflowConfig. */
    deleteWorkflowConfig: {
      name: "DeleteWorkflowConfig",
      requestType: DeleteWorkflowConfigRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              73,
              42,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              67,
              111,
              110,
              102,
              105,
              103,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists WorkflowInvocations in a given Repository. */
    listWorkflowInvocations: {
      name: "ListWorkflowInvocations",
      requestType: ListWorkflowInvocationsRequest,
      requestStream: false,
      responseType: ListWorkflowInvocationsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              77,
              18,
              75,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              73,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Fetches a single WorkflowInvocation. */
    getWorkflowInvocation: {
      name: "GetWorkflowInvocation",
      requestType: GetWorkflowInvocationRequest,
      requestStream: false,
      responseType: WorkflowInvocation,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              77,
              18,
              75,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              73,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new WorkflowInvocation in a given Repository. */
    createWorkflowInvocation: {
      name: "CreateWorkflowInvocation",
      requestType: CreateWorkflowInvocationRequest,
      requestStream: false,
      responseType: WorkflowInvocation,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              26,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              105,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              98,
              58,
              19,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              95,
              105,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              34,
              75,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              73,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a single WorkflowInvocation. */
    deleteWorkflowInvocation: {
      name: "DeleteWorkflowInvocation",
      requestType: DeleteWorkflowInvocationRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              77,
              42,
              75,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              73,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Requests cancellation of a running WorkflowInvocation. */
    cancelWorkflowInvocation: {
      name: "CancelWorkflowInvocation",
      requestType: CancelWorkflowInvocationRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              87,
              58,
              1,
              42,
              34,
              82,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              73,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
        },
      },
    },
    /** Returns WorkflowInvocationActions in a given WorkflowInvocation. */
    queryWorkflowInvocationActions: {
      name: "QueryWorkflowInvocationActions",
      requestType: QueryWorkflowInvocationActionsRequest,
      requestStream: false,
      responseType: QueryWorkflowInvocationActionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              83,
              18,
              81,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              114,
              101,
              112,
              111,
              115,
              105,
              116,
              111,
              114,
              105,
              101,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              102,
              108,
              111,
              119,
              73,
              110,
              118,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              58,
              113,
              117,
              101,
              114,
              121,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface DataformServiceImplementation<CallContextExt = {}> {
  /** Lists Repositories in a given project and location. */
  listRepositories(
    request: ListRepositoriesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListRepositoriesResponse>>;
  /** Fetches a single Repository. */
  getRepository(request: GetRepositoryRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Repository>>;
  /** Creates a new Repository in a given project and location. */
  createRepository(
    request: CreateRepositoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Repository>>;
  /** Updates a single Repository. */
  updateRepository(
    request: UpdateRepositoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Repository>>;
  /** Deletes a single Repository. */
  deleteRepository(
    request: DeleteRepositoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Applies a Git commit to a Repository. The Repository must not have a value
   * for `git_remote_settings.url`.
   */
  commitRepositoryChanges(
    request: CommitRepositoryChangesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Returns the contents of a file (inside a Repository). The Repository
   * must not have a value for `git_remote_settings.url`.
   */
  readRepositoryFile(
    request: ReadRepositoryFileRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReadRepositoryFileResponse>>;
  /**
   * Returns the contents of a given Repository directory. The Repository must
   * not have a value for `git_remote_settings.url`.
   */
  queryRepositoryDirectoryContents(
    request: QueryRepositoryDirectoryContentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<QueryRepositoryDirectoryContentsResponse>>;
  /**
   * Fetches a Repository's history of commits.  The Repository must not have a
   * value for `git_remote_settings.url`.
   */
  fetchRepositoryHistory(
    request: FetchRepositoryHistoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FetchRepositoryHistoryResponse>>;
  /** Computes a Repository's Git access token status. */
  computeRepositoryAccessTokenStatus(
    request: ComputeRepositoryAccessTokenStatusRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ComputeRepositoryAccessTokenStatusResponse>>;
  /** Fetches a Repository's remote branches. */
  fetchRemoteBranches(
    request: FetchRemoteBranchesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FetchRemoteBranchesResponse>>;
  /** Lists Workspaces in a given Repository. */
  listWorkspaces(
    request: ListWorkspacesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListWorkspacesResponse>>;
  /** Fetches a single Workspace. */
  getWorkspace(request: GetWorkspaceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Workspace>>;
  /** Creates a new Workspace in a given Repository. */
  createWorkspace(
    request: CreateWorkspaceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Workspace>>;
  /** Deletes a single Workspace. */
  deleteWorkspace(request: DeleteWorkspaceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Installs dependency NPM packages (inside a Workspace). */
  installNpmPackages(
    request: InstallNpmPackagesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<InstallNpmPackagesResponse>>;
  /** Pulls Git commits from the Repository's remote into a Workspace. */
  pullGitCommits(request: PullGitCommitsRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Pushes Git commits from a Workspace to the Repository's remote. */
  pushGitCommits(request: PushGitCommitsRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Fetches Git statuses for the files in a Workspace. */
  fetchFileGitStatuses(
    request: FetchFileGitStatusesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FetchFileGitStatusesResponse>>;
  /** Fetches Git ahead/behind against a remote branch. */
  fetchGitAheadBehind(
    request: FetchGitAheadBehindRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FetchGitAheadBehindResponse>>;
  /** Applies a Git commit for uncommitted files in a Workspace. */
  commitWorkspaceChanges(
    request: CommitWorkspaceChangesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Performs a Git reset for uncommitted files in a Workspace. */
  resetWorkspaceChanges(
    request: ResetWorkspaceChangesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Fetches Git diff for an uncommitted file in a Workspace. */
  fetchFileDiff(
    request: FetchFileDiffRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<FetchFileDiffResponse>>;
  /** Returns the contents of a given Workspace directory. */
  queryDirectoryContents(
    request: QueryDirectoryContentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<QueryDirectoryContentsResponse>>;
  /** Creates a directory inside a Workspace. */
  makeDirectory(
    request: MakeDirectoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<MakeDirectoryResponse>>;
  /** Deletes a directory (inside a Workspace) and all of its contents. */
  removeDirectory(request: RemoveDirectoryRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Moves a directory (inside a Workspace), and all of its contents, to a new
   * location.
   */
  moveDirectory(
    request: MoveDirectoryRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<MoveDirectoryResponse>>;
  /** Returns the contents of a file (inside a Workspace). */
  readFile(request: ReadFileRequest, context: CallContext & CallContextExt): Promise<DeepPartial<ReadFileResponse>>;
  /** Deletes a file (inside a Workspace). */
  removeFile(request: RemoveFileRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Moves a file (inside a Workspace) to a new location. */
  moveFile(request: MoveFileRequest, context: CallContext & CallContextExt): Promise<DeepPartial<MoveFileResponse>>;
  /** Writes to a file (inside a Workspace). */
  writeFile(request: WriteFileRequest, context: CallContext & CallContextExt): Promise<DeepPartial<WriteFileResponse>>;
  /** Lists ReleaseConfigs in a given Repository. */
  listReleaseConfigs(
    request: ListReleaseConfigsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListReleaseConfigsResponse>>;
  /** Fetches a single ReleaseConfig. */
  getReleaseConfig(
    request: GetReleaseConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReleaseConfig>>;
  /** Creates a new ReleaseConfig in a given Repository. */
  createReleaseConfig(
    request: CreateReleaseConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReleaseConfig>>;
  /** Updates a single ReleaseConfig. */
  updateReleaseConfig(
    request: UpdateReleaseConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReleaseConfig>>;
  /** Deletes a single ReleaseConfig. */
  deleteReleaseConfig(
    request: DeleteReleaseConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Lists CompilationResults in a given Repository. */
  listCompilationResults(
    request: ListCompilationResultsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListCompilationResultsResponse>>;
  /** Fetches a single CompilationResult. */
  getCompilationResult(
    request: GetCompilationResultRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CompilationResult>>;
  /** Creates a new CompilationResult in a given project and location. */
  createCompilationResult(
    request: CreateCompilationResultRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CompilationResult>>;
  /** Returns CompilationResultActions in a given CompilationResult. */
  queryCompilationResultActions(
    request: QueryCompilationResultActionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<QueryCompilationResultActionsResponse>>;
  /** Lists WorkflowConfigs in a given Repository. */
  listWorkflowConfigs(
    request: ListWorkflowConfigsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListWorkflowConfigsResponse>>;
  /** Fetches a single WorkflowConfig. */
  getWorkflowConfig(
    request: GetWorkflowConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowConfig>>;
  /** Creates a new WorkflowConfig in a given Repository. */
  createWorkflowConfig(
    request: CreateWorkflowConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowConfig>>;
  /** Updates a single WorkflowConfig. */
  updateWorkflowConfig(
    request: UpdateWorkflowConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowConfig>>;
  /** Deletes a single WorkflowConfig. */
  deleteWorkflowConfig(
    request: DeleteWorkflowConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Lists WorkflowInvocations in a given Repository. */
  listWorkflowInvocations(
    request: ListWorkflowInvocationsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListWorkflowInvocationsResponse>>;
  /** Fetches a single WorkflowInvocation. */
  getWorkflowInvocation(
    request: GetWorkflowInvocationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowInvocation>>;
  /** Creates a new WorkflowInvocation in a given Repository. */
  createWorkflowInvocation(
    request: CreateWorkflowInvocationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WorkflowInvocation>>;
  /** Deletes a single WorkflowInvocation. */
  deleteWorkflowInvocation(
    request: DeleteWorkflowInvocationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Requests cancellation of a running WorkflowInvocation. */
  cancelWorkflowInvocation(
    request: CancelWorkflowInvocationRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Returns WorkflowInvocationActions in a given WorkflowInvocation. */
  queryWorkflowInvocationActions(
    request: QueryWorkflowInvocationActionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<QueryWorkflowInvocationActionsResponse>>;
}

export interface DataformClient<CallOptionsExt = {}> {
  /** Lists Repositories in a given project and location. */
  listRepositories(
    request: DeepPartial<ListRepositoriesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListRepositoriesResponse>;
  /** Fetches a single Repository. */
  getRepository(
    request: DeepPartial<GetRepositoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Repository>;
  /** Creates a new Repository in a given project and location. */
  createRepository(
    request: DeepPartial<CreateRepositoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Repository>;
  /** Updates a single Repository. */
  updateRepository(
    request: DeepPartial<UpdateRepositoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Repository>;
  /** Deletes a single Repository. */
  deleteRepository(
    request: DeepPartial<DeleteRepositoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Applies a Git commit to a Repository. The Repository must not have a value
   * for `git_remote_settings.url`.
   */
  commitRepositoryChanges(
    request: DeepPartial<CommitRepositoryChangesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Returns the contents of a file (inside a Repository). The Repository
   * must not have a value for `git_remote_settings.url`.
   */
  readRepositoryFile(
    request: DeepPartial<ReadRepositoryFileRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReadRepositoryFileResponse>;
  /**
   * Returns the contents of a given Repository directory. The Repository must
   * not have a value for `git_remote_settings.url`.
   */
  queryRepositoryDirectoryContents(
    request: DeepPartial<QueryRepositoryDirectoryContentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<QueryRepositoryDirectoryContentsResponse>;
  /**
   * Fetches a Repository's history of commits.  The Repository must not have a
   * value for `git_remote_settings.url`.
   */
  fetchRepositoryHistory(
    request: DeepPartial<FetchRepositoryHistoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FetchRepositoryHistoryResponse>;
  /** Computes a Repository's Git access token status. */
  computeRepositoryAccessTokenStatus(
    request: DeepPartial<ComputeRepositoryAccessTokenStatusRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ComputeRepositoryAccessTokenStatusResponse>;
  /** Fetches a Repository's remote branches. */
  fetchRemoteBranches(
    request: DeepPartial<FetchRemoteBranchesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FetchRemoteBranchesResponse>;
  /** Lists Workspaces in a given Repository. */
  listWorkspaces(
    request: DeepPartial<ListWorkspacesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListWorkspacesResponse>;
  /** Fetches a single Workspace. */
  getWorkspace(request: DeepPartial<GetWorkspaceRequest>, options?: CallOptions & CallOptionsExt): Promise<Workspace>;
  /** Creates a new Workspace in a given Repository. */
  createWorkspace(
    request: DeepPartial<CreateWorkspaceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Workspace>;
  /** Deletes a single Workspace. */
  deleteWorkspace(request: DeepPartial<DeleteWorkspaceRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Installs dependency NPM packages (inside a Workspace). */
  installNpmPackages(
    request: DeepPartial<InstallNpmPackagesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<InstallNpmPackagesResponse>;
  /** Pulls Git commits from the Repository's remote into a Workspace. */
  pullGitCommits(request: DeepPartial<PullGitCommitsRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Pushes Git commits from a Workspace to the Repository's remote. */
  pushGitCommits(request: DeepPartial<PushGitCommitsRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Fetches Git statuses for the files in a Workspace. */
  fetchFileGitStatuses(
    request: DeepPartial<FetchFileGitStatusesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FetchFileGitStatusesResponse>;
  /** Fetches Git ahead/behind against a remote branch. */
  fetchGitAheadBehind(
    request: DeepPartial<FetchGitAheadBehindRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FetchGitAheadBehindResponse>;
  /** Applies a Git commit for uncommitted files in a Workspace. */
  commitWorkspaceChanges(
    request: DeepPartial<CommitWorkspaceChangesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Performs a Git reset for uncommitted files in a Workspace. */
  resetWorkspaceChanges(
    request: DeepPartial<ResetWorkspaceChangesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Fetches Git diff for an uncommitted file in a Workspace. */
  fetchFileDiff(
    request: DeepPartial<FetchFileDiffRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<FetchFileDiffResponse>;
  /** Returns the contents of a given Workspace directory. */
  queryDirectoryContents(
    request: DeepPartial<QueryDirectoryContentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<QueryDirectoryContentsResponse>;
  /** Creates a directory inside a Workspace. */
  makeDirectory(
    request: DeepPartial<MakeDirectoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<MakeDirectoryResponse>;
  /** Deletes a directory (inside a Workspace) and all of its contents. */
  removeDirectory(request: DeepPartial<RemoveDirectoryRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Moves a directory (inside a Workspace), and all of its contents, to a new
   * location.
   */
  moveDirectory(
    request: DeepPartial<MoveDirectoryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<MoveDirectoryResponse>;
  /** Returns the contents of a file (inside a Workspace). */
  readFile(request: DeepPartial<ReadFileRequest>, options?: CallOptions & CallOptionsExt): Promise<ReadFileResponse>;
  /** Deletes a file (inside a Workspace). */
  removeFile(request: DeepPartial<RemoveFileRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Moves a file (inside a Workspace) to a new location. */
  moveFile(request: DeepPartial<MoveFileRequest>, options?: CallOptions & CallOptionsExt): Promise<MoveFileResponse>;
  /** Writes to a file (inside a Workspace). */
  writeFile(request: DeepPartial<WriteFileRequest>, options?: CallOptions & CallOptionsExt): Promise<WriteFileResponse>;
  /** Lists ReleaseConfigs in a given Repository. */
  listReleaseConfigs(
    request: DeepPartial<ListReleaseConfigsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListReleaseConfigsResponse>;
  /** Fetches a single ReleaseConfig. */
  getReleaseConfig(
    request: DeepPartial<GetReleaseConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReleaseConfig>;
  /** Creates a new ReleaseConfig in a given Repository. */
  createReleaseConfig(
    request: DeepPartial<CreateReleaseConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReleaseConfig>;
  /** Updates a single ReleaseConfig. */
  updateReleaseConfig(
    request: DeepPartial<UpdateReleaseConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReleaseConfig>;
  /** Deletes a single ReleaseConfig. */
  deleteReleaseConfig(
    request: DeepPartial<DeleteReleaseConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Lists CompilationResults in a given Repository. */
  listCompilationResults(
    request: DeepPartial<ListCompilationResultsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListCompilationResultsResponse>;
  /** Fetches a single CompilationResult. */
  getCompilationResult(
    request: DeepPartial<GetCompilationResultRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CompilationResult>;
  /** Creates a new CompilationResult in a given project and location. */
  createCompilationResult(
    request: DeepPartial<CreateCompilationResultRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CompilationResult>;
  /** Returns CompilationResultActions in a given CompilationResult. */
  queryCompilationResultActions(
    request: DeepPartial<QueryCompilationResultActionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<QueryCompilationResultActionsResponse>;
  /** Lists WorkflowConfigs in a given Repository. */
  listWorkflowConfigs(
    request: DeepPartial<ListWorkflowConfigsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListWorkflowConfigsResponse>;
  /** Fetches a single WorkflowConfig. */
  getWorkflowConfig(
    request: DeepPartial<GetWorkflowConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowConfig>;
  /** Creates a new WorkflowConfig in a given Repository. */
  createWorkflowConfig(
    request: DeepPartial<CreateWorkflowConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowConfig>;
  /** Updates a single WorkflowConfig. */
  updateWorkflowConfig(
    request: DeepPartial<UpdateWorkflowConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowConfig>;
  /** Deletes a single WorkflowConfig. */
  deleteWorkflowConfig(
    request: DeepPartial<DeleteWorkflowConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Lists WorkflowInvocations in a given Repository. */
  listWorkflowInvocations(
    request: DeepPartial<ListWorkflowInvocationsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListWorkflowInvocationsResponse>;
  /** Fetches a single WorkflowInvocation. */
  getWorkflowInvocation(
    request: DeepPartial<GetWorkflowInvocationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowInvocation>;
  /** Creates a new WorkflowInvocation in a given Repository. */
  createWorkflowInvocation(
    request: DeepPartial<CreateWorkflowInvocationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkflowInvocation>;
  /** Deletes a single WorkflowInvocation. */
  deleteWorkflowInvocation(
    request: DeepPartial<DeleteWorkflowInvocationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Requests cancellation of a running WorkflowInvocation. */
  cancelWorkflowInvocation(
    request: DeepPartial<CancelWorkflowInvocationRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Returns WorkflowInvocationActions in a given WorkflowInvocation. */
  queryWorkflowInvocationActions(
    request: DeepPartial<QueryWorkflowInvocationActionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<QueryWorkflowInvocationActionsResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
