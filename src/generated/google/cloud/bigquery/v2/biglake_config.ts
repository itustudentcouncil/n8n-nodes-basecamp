// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/v2/biglake_config.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.cloud.bigquery.v2";

/** Configuration for BigLake managed tables. */
export interface BigLakeConfiguration {
  /**
   * Required. The connection specifying the credentials to be used to read and
   * write to external storage, such as Cloud Storage. The connection_id can
   * have the form `{project}.{location}.{connection_id}` or
   * `projects/{project}/locations/{location}/connections/{connection_id}".
   */
  connectionId: string;
  /**
   * Required. The fully qualified location prefix of the external folder where
   * table data is stored. The '*' wildcard character is not allowed. The URI
   * should be in the format `gs://bucket/path_to_table/`
   */
  storageUri: string;
  /** Required. The file format the table data is stored in. */
  fileFormat: BigLakeConfiguration_FileFormat;
  /** Required. The table format the metadata only snapshots are stored in. */
  tableFormat: BigLakeConfiguration_TableFormat;
}

/** Supported file formats for BigLake tables. */
export enum BigLakeConfiguration_FileFormat {
  /** FILE_FORMAT_UNSPECIFIED - Default Value. */
  FILE_FORMAT_UNSPECIFIED = 0,
  /** PARQUET - Apache Parquet format. */
  PARQUET = 1,
  UNRECOGNIZED = -1,
}

export function bigLakeConfiguration_FileFormatFromJSON(object: any): BigLakeConfiguration_FileFormat {
  switch (object) {
    case 0:
    case "FILE_FORMAT_UNSPECIFIED":
      return BigLakeConfiguration_FileFormat.FILE_FORMAT_UNSPECIFIED;
    case 1:
    case "PARQUET":
      return BigLakeConfiguration_FileFormat.PARQUET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigLakeConfiguration_FileFormat.UNRECOGNIZED;
  }
}

export function bigLakeConfiguration_FileFormatToJSON(object: BigLakeConfiguration_FileFormat): string {
  switch (object) {
    case BigLakeConfiguration_FileFormat.FILE_FORMAT_UNSPECIFIED:
      return "FILE_FORMAT_UNSPECIFIED";
    case BigLakeConfiguration_FileFormat.PARQUET:
      return "PARQUET";
    case BigLakeConfiguration_FileFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Supported table formats for BigLake tables. */
export enum BigLakeConfiguration_TableFormat {
  /** TABLE_FORMAT_UNSPECIFIED - Default Value. */
  TABLE_FORMAT_UNSPECIFIED = 0,
  /** ICEBERG - Apache Iceberg format. */
  ICEBERG = 1,
  UNRECOGNIZED = -1,
}

export function bigLakeConfiguration_TableFormatFromJSON(object: any): BigLakeConfiguration_TableFormat {
  switch (object) {
    case 0:
    case "TABLE_FORMAT_UNSPECIFIED":
      return BigLakeConfiguration_TableFormat.TABLE_FORMAT_UNSPECIFIED;
    case 1:
    case "ICEBERG":
      return BigLakeConfiguration_TableFormat.ICEBERG;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BigLakeConfiguration_TableFormat.UNRECOGNIZED;
  }
}

export function bigLakeConfiguration_TableFormatToJSON(object: BigLakeConfiguration_TableFormat): string {
  switch (object) {
    case BigLakeConfiguration_TableFormat.TABLE_FORMAT_UNSPECIFIED:
      return "TABLE_FORMAT_UNSPECIFIED";
    case BigLakeConfiguration_TableFormat.ICEBERG:
      return "ICEBERG";
    case BigLakeConfiguration_TableFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseBigLakeConfiguration(): BigLakeConfiguration {
  return { connectionId: "", storageUri: "", fileFormat: 0, tableFormat: 0 };
}

export const BigLakeConfiguration: MessageFns<BigLakeConfiguration> = {
  encode(message: BigLakeConfiguration, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.connectionId !== "") {
      writer.uint32(10).string(message.connectionId);
    }
    if (message.storageUri !== "") {
      writer.uint32(18).string(message.storageUri);
    }
    if (message.fileFormat !== 0) {
      writer.uint32(24).int32(message.fileFormat);
    }
    if (message.tableFormat !== 0) {
      writer.uint32(32).int32(message.tableFormat);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigLakeConfiguration {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigLakeConfiguration();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.connectionId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.storageUri = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.fileFormat = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.tableFormat = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigLakeConfiguration {
    return {
      connectionId: isSet(object.connectionId) ? globalThis.String(object.connectionId) : "",
      storageUri: isSet(object.storageUri) ? globalThis.String(object.storageUri) : "",
      fileFormat: isSet(object.fileFormat) ? bigLakeConfiguration_FileFormatFromJSON(object.fileFormat) : 0,
      tableFormat: isSet(object.tableFormat) ? bigLakeConfiguration_TableFormatFromJSON(object.tableFormat) : 0,
    };
  },

  toJSON(message: BigLakeConfiguration): unknown {
    const obj: any = {};
    if (message.connectionId !== "") {
      obj.connectionId = message.connectionId;
    }
    if (message.storageUri !== "") {
      obj.storageUri = message.storageUri;
    }
    if (message.fileFormat !== 0) {
      obj.fileFormat = bigLakeConfiguration_FileFormatToJSON(message.fileFormat);
    }
    if (message.tableFormat !== 0) {
      obj.tableFormat = bigLakeConfiguration_TableFormatToJSON(message.tableFormat);
    }
    return obj;
  },

  create(base?: DeepPartial<BigLakeConfiguration>): BigLakeConfiguration {
    return BigLakeConfiguration.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigLakeConfiguration>): BigLakeConfiguration {
    const message = createBaseBigLakeConfiguration();
    message.connectionId = object.connectionId ?? "";
    message.storageUri = object.storageUri ?? "";
    message.fileFormat = object.fileFormat ?? 0;
    message.tableFormat = object.tableFormat ?? 0;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
