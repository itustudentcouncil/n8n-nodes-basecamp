// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/v2/hive_partitioning.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { BoolValue } from "../../../protobuf/wrappers.js";

export const protobufPackage = "google.cloud.bigquery.v2";

/** Options for configuring hive partitioning detect. */
export interface HivePartitioningOptions {
  /**
   * Optional. When set, what mode of hive partitioning to use when reading
   * data.  The following modes are supported:
   *
   * * AUTO: automatically infer partition key name(s) and type(s).
   *
   * * STRINGS: automatically infer partition key name(s).  All types are
   * strings.
   *
   * * CUSTOM: partition key schema is encoded in the source URI prefix.
   *
   * Not all storage formats support hive partitioning. Requesting hive
   * partitioning on an unsupported format will lead to an error.
   * Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.
   */
  mode: string;
  /**
   * Optional. When hive partition detection is requested, a common prefix for
   * all source uris must be required.  The prefix must end immediately before
   * the partition key encoding begins. For example, consider files following
   * this data layout:
   *
   * gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
   *
   * gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro
   *
   * When hive partitioning is requested with either AUTO or STRINGS detection,
   * the common prefix can be either of gs://bucket/path_to_table or
   * gs://bucket/path_to_table/.
   *
   * CUSTOM detection requires encoding the partitioning schema immediately
   * after the common prefix.  For CUSTOM, any of
   *
   * * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:INTEGER}
   *
   * * gs://bucket/path_to_table/{dt:STRING}/{country:STRING}/{id:INTEGER}
   *
   * * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:STRING}
   *
   * would all be valid source URI prefixes.
   */
  sourceUriPrefix: string;
  /**
   * Optional. If set to true, queries over this table require a partition
   * filter that can be used for partition elimination to be specified.
   *
   * Note that this field should only be true when creating a permanent
   * external table or querying a temporary external table.
   *
   * Hive-partitioned loads with require_partition_filter explicitly set to
   * true will fail.
   */
  requirePartitionFilter:
    | boolean
    | undefined;
  /**
   * Output only. For permanent external tables, this field is populated with
   * the hive partition keys in the order they were inferred. The types of the
   * partition keys can be deduced by checking the table schema (which will
   * include the partition keys). Not every API will populate this field in the
   * output. For example, Tables.Get will populate it, but Tables.List will not
   * contain this field.
   */
  fields: string[];
}

function createBaseHivePartitioningOptions(): HivePartitioningOptions {
  return { mode: "", sourceUriPrefix: "", requirePartitionFilter: undefined, fields: [] };
}

export const HivePartitioningOptions: MessageFns<HivePartitioningOptions> = {
  encode(message: HivePartitioningOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mode !== "") {
      writer.uint32(10).string(message.mode);
    }
    if (message.sourceUriPrefix !== "") {
      writer.uint32(18).string(message.sourceUriPrefix);
    }
    if (message.requirePartitionFilter !== undefined) {
      BoolValue.encode({ value: message.requirePartitionFilter! }, writer.uint32(26).fork()).join();
    }
    for (const v of message.fields) {
      writer.uint32(34).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HivePartitioningOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHivePartitioningOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.mode = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceUriPrefix = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requirePartitionFilter = BoolValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.fields.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HivePartitioningOptions {
    return {
      mode: isSet(object.mode) ? globalThis.String(object.mode) : "",
      sourceUriPrefix: isSet(object.sourceUriPrefix) ? globalThis.String(object.sourceUriPrefix) : "",
      requirePartitionFilter: isSet(object.requirePartitionFilter) ? Boolean(object.requirePartitionFilter) : undefined,
      fields: globalThis.Array.isArray(object?.fields) ? object.fields.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: HivePartitioningOptions): unknown {
    const obj: any = {};
    if (message.mode !== "") {
      obj.mode = message.mode;
    }
    if (message.sourceUriPrefix !== "") {
      obj.sourceUriPrefix = message.sourceUriPrefix;
    }
    if (message.requirePartitionFilter !== undefined) {
      obj.requirePartitionFilter = message.requirePartitionFilter;
    }
    if (message.fields?.length) {
      obj.fields = message.fields;
    }
    return obj;
  },

  create(base?: DeepPartial<HivePartitioningOptions>): HivePartitioningOptions {
    return HivePartitioningOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HivePartitioningOptions>): HivePartitioningOptions {
    const message = createBaseHivePartitioningOptions();
    message.mode = object.mode ?? "";
    message.sourceUriPrefix = object.sourceUriPrefix ?? "";
    message.requirePartitionFilter = object.requirePartitionFilter ?? undefined;
    message.fields = object.fields?.map((e) => e) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
