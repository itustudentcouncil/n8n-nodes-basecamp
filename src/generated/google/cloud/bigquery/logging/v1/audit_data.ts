// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/bigquery/logging/v1/audit_data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { SetIamPolicyRequest } from "../../../../iam/v1/iam_policy.js";
import { Policy } from "../../../../iam/v1/policy.js";
import { Duration } from "../../../../protobuf/duration.js";
import { Timestamp } from "../../../../protobuf/timestamp.js";
import { Status } from "../../../../rpc/status.js";

export const protobufPackage = "google.cloud.bigquery.logging.v1";

/**
 * BigQuery request and response messages for audit log.
 * Note: `Table.schema` has been deprecated in favor of `Table.schemaJson`.
 * `Table.schema` may continue to be present in your logs during this
 * transition.
 */
export interface AuditData {
  /** Table insert request. */
  tableInsertRequest?:
    | TableInsertRequest
    | undefined;
  /** Table update request. */
  tableUpdateRequest?:
    | TableUpdateRequest
    | undefined;
  /** Dataset list request. */
  datasetListRequest?:
    | DatasetListRequest
    | undefined;
  /** Dataset insert request. */
  datasetInsertRequest?:
    | DatasetInsertRequest
    | undefined;
  /** Dataset update request. */
  datasetUpdateRequest?:
    | DatasetUpdateRequest
    | undefined;
  /** Job insert request. */
  jobInsertRequest?:
    | JobInsertRequest
    | undefined;
  /** Job query request. */
  jobQueryRequest?:
    | JobQueryRequest
    | undefined;
  /** Job get query results request. */
  jobGetQueryResultsRequest?:
    | JobGetQueryResultsRequest
    | undefined;
  /** Table data-list request. */
  tableDataListRequest?:
    | TableDataListRequest
    | undefined;
  /** Iam policy request. */
  setIamPolicyRequest?:
    | SetIamPolicyRequest
    | undefined;
  /** Table insert response. */
  tableInsertResponse?:
    | TableInsertResponse
    | undefined;
  /** Table update response. */
  tableUpdateResponse?:
    | TableUpdateResponse
    | undefined;
  /** Dataset insert response. */
  datasetInsertResponse?:
    | DatasetInsertResponse
    | undefined;
  /** Dataset update response. */
  datasetUpdateResponse?:
    | DatasetUpdateResponse
    | undefined;
  /** Job insert response. */
  jobInsertResponse?:
    | JobInsertResponse
    | undefined;
  /** Job query response. */
  jobQueryResponse?:
    | JobQueryResponse
    | undefined;
  /** Job get query results response. */
  jobGetQueryResultsResponse?:
    | JobGetQueryResultsResponse
    | undefined;
  /**
   * Deprecated: Job query-done response. Use this information for usage
   * analysis.
   */
  jobQueryDoneResponse?:
    | JobQueryDoneResponse
    | undefined;
  /** Iam Policy. */
  policyResponse?:
    | Policy
    | undefined;
  /** A job completion event. */
  jobCompletedEvent:
    | JobCompletedEvent
    | undefined;
  /** Information about the table access events. */
  tableDataReadEvents: TableDataReadEvent[];
}

/** Table insert request. */
export interface TableInsertRequest {
  /** The new table. */
  resource: Table | undefined;
}

/** Table update request. */
export interface TableUpdateRequest {
  /** The table to be updated. */
  resource: Table | undefined;
}

/** Table insert response. */
export interface TableInsertResponse {
  /** Final state of the inserted table. */
  resource: Table | undefined;
}

/** Table update response. */
export interface TableUpdateResponse {
  /** Final state of the updated table. */
  resource: Table | undefined;
}

/** Dataset list request. */
export interface DatasetListRequest {
  /** Whether to list all datasets, including hidden ones. */
  listAll: boolean;
}

/** Dataset insert request. */
export interface DatasetInsertRequest {
  /** The dataset to be inserted. */
  resource: Dataset | undefined;
}

/** Dataset insert response. */
export interface DatasetInsertResponse {
  /** Final state of the inserted dataset. */
  resource: Dataset | undefined;
}

/** Dataset update request. */
export interface DatasetUpdateRequest {
  /** The dataset to be updated. */
  resource: Dataset | undefined;
}

/** Dataset update response. */
export interface DatasetUpdateResponse {
  /** Final state of the updated dataset. */
  resource: Dataset | undefined;
}

/** Job insert request. */
export interface JobInsertRequest {
  /** Job insert request. */
  resource: Job | undefined;
}

/** Job insert response. */
export interface JobInsertResponse {
  /** Job insert response. */
  resource: Job | undefined;
}

/** Job query request. */
export interface JobQueryRequest {
  /** The query. */
  query: string;
  /** The maximum number of results. */
  maxResults: number;
  /** The default dataset for tables that do not have a dataset specified. */
  defaultDataset:
    | DatasetName
    | undefined;
  /** Project that the query should be charged to. */
  projectId: string;
  /** If true, don't actually run the job. Just check that it would run. */
  dryRun: boolean;
}

/** Job query response. */
export interface JobQueryResponse {
  /** The total number of rows in the full query result set. */
  totalResults: Long;
  /** Information about the queried job. */
  job: Job | undefined;
}

/** Job getQueryResults request. */
export interface JobGetQueryResultsRequest {
  /** Maximum number of results to return. */
  maxResults: number;
  /** Zero-based row number at which to start. */
  startRow: Long;
}

/** Job getQueryResults response. */
export interface JobGetQueryResultsResponse {
  /** Total number of results in query results. */
  totalResults: Long;
  /**
   * The job that was created to run the query.
   * It completed if `job.status.state` is `DONE`.
   * It failed if `job.status.errorResult` is also present.
   */
  job: Job | undefined;
}

/** Job getQueryDone response. */
export interface JobQueryDoneResponse {
  /**
   * The job and status information.
   * The job completed if `job.status.state` is `DONE`.
   */
  job: Job | undefined;
}

/** Query job completed event. */
export interface JobCompletedEvent {
  /** Name of the event. */
  eventName: string;
  /** Job information. */
  job: Job | undefined;
}

/**
 * Table data read event. Only present for tables, not views, and is only
 * included in the log record for the project that owns the table.
 */
export interface TableDataReadEvent {
  /** Name of the accessed table. */
  tableName:
    | TableName
    | undefined;
  /**
   * A list of referenced fields. This information is not included by default.
   * To enable this in the logs, please contact BigQuery support or open a bug
   * in the BigQuery issue tracker.
   */
  referencedFields: string[];
}

/** Table data-list request. */
export interface TableDataListRequest {
  /** Starting row offset. */
  startRow: Long;
  /** Maximum number of results to return. */
  maxResults: number;
}

/**
 * Describes a BigQuery table.
 * See the [Table](/bigquery/docs/reference/v2/tables) API resource
 * for more details on individual fields.
 * Note: `Table.schema` has been deprecated in favor of `Table.schemaJson`.
 * `Table.schema` may continue to be present in your logs during this
 * transition.
 */
export interface Table {
  /** The name of the table. */
  tableName:
    | TableName
    | undefined;
  /** User-provided metadata for the table. */
  info:
    | TableInfo
    | undefined;
  /** A JSON representation of the table's schema. */
  schemaJson: string;
  /** If present, this is a virtual table defined by a SQL query. */
  view:
    | TableViewDefinition
    | undefined;
  /**
   * The expiration date for the table, after which the table
   * is deleted and the storage reclaimed.
   * If not present, the table persists indefinitely.
   */
  expireTime:
    | Date
    | undefined;
  /** The time the table was created. */
  createTime:
    | Date
    | undefined;
  /**
   * The time the table was last truncated
   * by an operation with a `writeDisposition` of `WRITE_TRUNCATE`.
   */
  truncateTime:
    | Date
    | undefined;
  /** The time the table was last modified. */
  updateTime:
    | Date
    | undefined;
  /** The table encryption information. Set when non-default encryption is used. */
  encryption: EncryptionInfo | undefined;
}

/** User-provided metadata for a table. */
export interface TableInfo {
  /** A short name for the table, such as`"Analytics Data - Jan 2011"`. */
  friendlyName: string;
  /**
   * A long description, perhaps several paragraphs,
   * describing the table contents in detail.
   */
  description: string;
  /** Labels provided for the table. */
  labels: { [key: string]: string };
}

export interface TableInfo_LabelsEntry {
  key: string;
  value: string;
}

/** Describes a virtual table defined by a SQL query. */
export interface TableViewDefinition {
  /** SQL query defining the view. */
  query: string;
}

/**
 * BigQuery dataset information.
 * See the [Dataset](/bigquery/docs/reference/v2/datasets) API resource
 * for more details on individual fields.
 */
export interface Dataset {
  /** The name of the dataset. */
  datasetName:
    | DatasetName
    | undefined;
  /** User-provided metadata for the dataset. */
  info:
    | DatasetInfo
    | undefined;
  /** The time the dataset was created. */
  createTime:
    | Date
    | undefined;
  /** The time the dataset was last modified. */
  updateTime:
    | Date
    | undefined;
  /** The access control list for the dataset. */
  acl:
    | BigQueryAcl
    | undefined;
  /**
   * If this field is present, each table that does not specify an
   * expiration time is assigned an expiration time by adding this
   * duration to the table's `createTime`.  If this field is empty,
   * there is no default table expiration time.
   */
  defaultTableExpireDuration: Duration | undefined;
}

/** User-provided metadata for a dataset. */
export interface DatasetInfo {
  /** A short name for the dataset, such as`"Analytics Data 2011"`. */
  friendlyName: string;
  /**
   * A long description, perhaps several paragraphs,
   * describing the dataset contents in detail.
   */
  description: string;
  /** Labels provided for the dataset. */
  labels: { [key: string]: string };
}

export interface DatasetInfo_LabelsEntry {
  key: string;
  value: string;
}

/** An access control list. */
export interface BigQueryAcl {
  /** Access control entry list. */
  entries: BigQueryAcl_Entry[];
}

/** Access control entry. */
export interface BigQueryAcl_Entry {
  /** The granted role, which can be `READER`, `WRITER`, or `OWNER`. */
  role: string;
  /** Grants access to a group identified by an email address. */
  groupEmail: string;
  /** Grants access to a user identified by an email address. */
  userEmail: string;
  /** Grants access to all members of a domain. */
  domain: string;
  /**
   * Grants access to special groups. Valid groups are `PROJECT_OWNERS`,
   * `PROJECT_READERS`, `PROJECT_WRITERS` and `ALL_AUTHENTICATED_USERS`.
   */
  specialGroup: string;
  /** Grants access to a BigQuery View. */
  viewName: TableName | undefined;
}

/** Describes a job. */
export interface Job {
  /** Job name. */
  jobName:
    | JobName
    | undefined;
  /** Job configuration. */
  jobConfiguration:
    | JobConfiguration
    | undefined;
  /** Job status. */
  jobStatus:
    | JobStatus
    | undefined;
  /** Job statistics. */
  jobStatistics: JobStatistics | undefined;
}

/**
 * Job configuration information.
 * See the [Jobs](/bigquery/docs/reference/v2/jobs) API resource
 * for more details on individual fields.
 */
export interface JobConfiguration {
  /** Query job information. */
  query?:
    | JobConfiguration_Query
    | undefined;
  /** Load job information. */
  load?:
    | JobConfiguration_Load
    | undefined;
  /** Extract job information. */
  extract?:
    | JobConfiguration_Extract
    | undefined;
  /** TableCopy job information. */
  tableCopy?:
    | JobConfiguration_TableCopy
    | undefined;
  /** If true, don't actually run the job. Just check that it would run. */
  dryRun: boolean;
  /** Labels provided for the job. */
  labels: { [key: string]: string };
}

/** Describes a query job, which executes a SQL-like query. */
export interface JobConfiguration_Query {
  /** The SQL query to run. */
  query: string;
  /** The table where results are written. */
  destinationTable:
    | TableName
    | undefined;
  /**
   * Describes when a job is allowed to create a table:
   * `CREATE_IF_NEEDED`, `CREATE_NEVER`.
   */
  createDisposition: string;
  /**
   * Describes how writes affect existing tables:
   * `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
   */
  writeDisposition: string;
  /**
   * If a table name is specified without a dataset in a query,
   * this dataset will be added to table name.
   */
  defaultDataset:
    | DatasetName
    | undefined;
  /** Describes data sources outside BigQuery, if needed. */
  tableDefinitions: TableDefinition[];
  /**
   * Describes the priority given to the query:
   * `QUERY_INTERACTIVE` or `QUERY_BATCH`.
   */
  queryPriority: string;
  /**
   * Result table encryption information. Set when non-default encryption is
   * used.
   */
  destinationTableEncryption:
    | EncryptionInfo
    | undefined;
  /** Type of the statement (e.g. SELECT, INSERT, CREATE_TABLE, CREATE_MODEL..) */
  statementType: string;
}

/**
 * Describes a load job, which loads data from an external source via
 * the  import pipeline.
 */
export interface JobConfiguration_Load {
  /**
   * URIs for the data to be imported. Only Google Cloud Storage URIs are
   * supported.
   */
  sourceUris: string[];
  /** The table schema in JSON format representation of a TableSchema. */
  schemaJson: string;
  /** The table where the imported data is written. */
  destinationTable:
    | TableName
    | undefined;
  /**
   * Describes when a job is allowed to create a table:
   * `CREATE_IF_NEEDED`, `CREATE_NEVER`.
   */
  createDisposition: string;
  /**
   * Describes how writes affect existing tables:
   * `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
   */
  writeDisposition: string;
  /**
   * Result table encryption information. Set when non-default encryption is
   * used.
   */
  destinationTableEncryption: EncryptionInfo | undefined;
}

/**
 * Describes an extract job, which exports data to an external source
 * via the  export pipeline.
 */
export interface JobConfiguration_Extract {
  /** Google Cloud Storage URIs where extracted data should be written. */
  destinationUris: string[];
  /** The source table. */
  sourceTable: TableName | undefined;
}

/** Describes a copy job, which copies an existing table to another table. */
export interface JobConfiguration_TableCopy {
  /** Source tables. */
  sourceTables: TableName[];
  /** Destination table. */
  destinationTable:
    | TableName
    | undefined;
  /**
   * Describes when a job is allowed to create a table:
   * `CREATE_IF_NEEDED`, `CREATE_NEVER`.
   */
  createDisposition: string;
  /**
   * Describes how writes affect existing tables:
   * `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
   */
  writeDisposition: string;
  /**
   * Result table encryption information. Set when non-default encryption is
   * used.
   */
  destinationTableEncryption: EncryptionInfo | undefined;
}

export interface JobConfiguration_LabelsEntry {
  key: string;
  value: string;
}

/** Describes an external data source used in a query. */
export interface TableDefinition {
  /** Name of the table, used in queries. */
  name: string;
  /** Google Cloud Storage URIs for the data to be imported. */
  sourceUris: string[];
}

/** Running state of a job. */
export interface JobStatus {
  /** State of a job: `PENDING`, `RUNNING`, or `DONE`. */
  state: string;
  /** If the job did not complete successfully, this field describes why. */
  error:
    | Status
    | undefined;
  /**
   * Errors encountered during the running of the job. Do not necessarily mean
   * that the job has completed or was unsuccessful.
   */
  additionalErrors: Status[];
}

/** Job statistics that may change after a job starts. */
export interface JobStatistics {
  /** Time when the job was created. */
  createTime:
    | Date
    | undefined;
  /** Time when the job started. */
  startTime:
    | Date
    | undefined;
  /** Time when the job ended. */
  endTime:
    | Date
    | undefined;
  /** Total bytes processed for a job. */
  totalProcessedBytes: Long;
  /** Processed bytes, adjusted by the job's CPU usage. */
  totalBilledBytes: Long;
  /** The tier assigned by CPU-based billing. */
  billingTier: number;
  /** The total number of slot-ms consumed by the query job. */
  totalSlotMs: Long;
  /**
   * Reservation usage. This field reported misleading information and will
   * no longer be populated. Aggregate usage of all jobs submitted to a
   * reservation should provide a more reliable indicator of reservation
   * imbalance.
   *
   * @deprecated
   */
  reservationUsage: JobStatistics_ReservationResourceUsage[];
  /** Reservation name or "unreserved" for on-demand resource usage. */
  reservation: string;
  /**
   * The first N tables accessed by the query job. Older queries that
   * reference a large number of tables may not have all of their
   * tables in this list. You can use the total_tables_processed count to
   * know how many total tables were read in the query. For new queries,
   * there is currently no limit.
   */
  referencedTables: TableName[];
  /** Total number of unique tables referenced in the query. */
  totalTablesProcessed: number;
  /**
   * The first N views accessed by the query job. Older queries that
   * reference a large number of views may not have all of their
   * views in this list. You can use the total_tables_processed count to
   * know how many total tables were read in the query. For new queries,
   * there is currently no limit.
   */
  referencedViews: TableName[];
  /** Total number of unique views referenced in the query. */
  totalViewsProcessed: number;
  /** Number of output rows produced by the query job. */
  queryOutputRowCount: Long;
  /** Total bytes loaded for an import job. */
  totalLoadOutputBytes: Long;
}

/** Job resource usage breakdown by reservation. */
export interface JobStatistics_ReservationResourceUsage {
  /** Reservation name or "unreserved" for on-demand resources usage. */
  name: string;
  /** Total slot milliseconds used by the reservation for a particular job. */
  slotMs: Long;
}

/** The fully-qualified name for a dataset. */
export interface DatasetName {
  /** The project ID. */
  projectId: string;
  /** The dataset ID within the project. */
  datasetId: string;
}

/** The fully-qualified name for a table. */
export interface TableName {
  /** The project ID. */
  projectId: string;
  /** The dataset ID within the project. */
  datasetId: string;
  /** The table ID of the table within the dataset. */
  tableId: string;
}

/** The fully-qualified name for a job. */
export interface JobName {
  /** The project ID. */
  projectId: string;
  /** The job ID within the project. */
  jobId: string;
  /** The job location. */
  location: string;
}

/** Describes encryption properties for a table or a job */
export interface EncryptionInfo {
  /** unique identifier for cloud kms key */
  kmsKeyName: string;
}

function createBaseAuditData(): AuditData {
  return {
    tableInsertRequest: undefined,
    tableUpdateRequest: undefined,
    datasetListRequest: undefined,
    datasetInsertRequest: undefined,
    datasetUpdateRequest: undefined,
    jobInsertRequest: undefined,
    jobQueryRequest: undefined,
    jobGetQueryResultsRequest: undefined,
    tableDataListRequest: undefined,
    setIamPolicyRequest: undefined,
    tableInsertResponse: undefined,
    tableUpdateResponse: undefined,
    datasetInsertResponse: undefined,
    datasetUpdateResponse: undefined,
    jobInsertResponse: undefined,
    jobQueryResponse: undefined,
    jobGetQueryResultsResponse: undefined,
    jobQueryDoneResponse: undefined,
    policyResponse: undefined,
    jobCompletedEvent: undefined,
    tableDataReadEvents: [],
  };
}

export const AuditData: MessageFns<AuditData> = {
  encode(message: AuditData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableInsertRequest !== undefined) {
      TableInsertRequest.encode(message.tableInsertRequest, writer.uint32(10).fork()).join();
    }
    if (message.tableUpdateRequest !== undefined) {
      TableUpdateRequest.encode(message.tableUpdateRequest, writer.uint32(130).fork()).join();
    }
    if (message.datasetListRequest !== undefined) {
      DatasetListRequest.encode(message.datasetListRequest, writer.uint32(18).fork()).join();
    }
    if (message.datasetInsertRequest !== undefined) {
      DatasetInsertRequest.encode(message.datasetInsertRequest, writer.uint32(26).fork()).join();
    }
    if (message.datasetUpdateRequest !== undefined) {
      DatasetUpdateRequest.encode(message.datasetUpdateRequest, writer.uint32(34).fork()).join();
    }
    if (message.jobInsertRequest !== undefined) {
      JobInsertRequest.encode(message.jobInsertRequest, writer.uint32(42).fork()).join();
    }
    if (message.jobQueryRequest !== undefined) {
      JobQueryRequest.encode(message.jobQueryRequest, writer.uint32(50).fork()).join();
    }
    if (message.jobGetQueryResultsRequest !== undefined) {
      JobGetQueryResultsRequest.encode(message.jobGetQueryResultsRequest, writer.uint32(58).fork()).join();
    }
    if (message.tableDataListRequest !== undefined) {
      TableDataListRequest.encode(message.tableDataListRequest, writer.uint32(66).fork()).join();
    }
    if (message.setIamPolicyRequest !== undefined) {
      SetIamPolicyRequest.encode(message.setIamPolicyRequest, writer.uint32(162).fork()).join();
    }
    if (message.tableInsertResponse !== undefined) {
      TableInsertResponse.encode(message.tableInsertResponse, writer.uint32(74).fork()).join();
    }
    if (message.tableUpdateResponse !== undefined) {
      TableUpdateResponse.encode(message.tableUpdateResponse, writer.uint32(82).fork()).join();
    }
    if (message.datasetInsertResponse !== undefined) {
      DatasetInsertResponse.encode(message.datasetInsertResponse, writer.uint32(90).fork()).join();
    }
    if (message.datasetUpdateResponse !== undefined) {
      DatasetUpdateResponse.encode(message.datasetUpdateResponse, writer.uint32(98).fork()).join();
    }
    if (message.jobInsertResponse !== undefined) {
      JobInsertResponse.encode(message.jobInsertResponse, writer.uint32(146).fork()).join();
    }
    if (message.jobQueryResponse !== undefined) {
      JobQueryResponse.encode(message.jobQueryResponse, writer.uint32(106).fork()).join();
    }
    if (message.jobGetQueryResultsResponse !== undefined) {
      JobGetQueryResultsResponse.encode(message.jobGetQueryResultsResponse, writer.uint32(114).fork()).join();
    }
    if (message.jobQueryDoneResponse !== undefined) {
      JobQueryDoneResponse.encode(message.jobQueryDoneResponse, writer.uint32(122).fork()).join();
    }
    if (message.policyResponse !== undefined) {
      Policy.encode(message.policyResponse, writer.uint32(170).fork()).join();
    }
    if (message.jobCompletedEvent !== undefined) {
      JobCompletedEvent.encode(message.jobCompletedEvent, writer.uint32(138).fork()).join();
    }
    for (const v of message.tableDataReadEvents) {
      TableDataReadEvent.encode(v!, writer.uint32(154).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AuditData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAuditData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableInsertRequest = TableInsertRequest.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.tableUpdateRequest = TableUpdateRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetListRequest = DatasetListRequest.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.datasetInsertRequest = DatasetInsertRequest.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.datasetUpdateRequest = DatasetUpdateRequest.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.jobInsertRequest = JobInsertRequest.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.jobQueryRequest = JobQueryRequest.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.jobGetQueryResultsRequest = JobGetQueryResultsRequest.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.tableDataListRequest = TableDataListRequest.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.setIamPolicyRequest = SetIamPolicyRequest.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.tableInsertResponse = TableInsertResponse.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.tableUpdateResponse = TableUpdateResponse.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.datasetInsertResponse = DatasetInsertResponse.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.datasetUpdateResponse = DatasetUpdateResponse.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.jobInsertResponse = JobInsertResponse.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.jobQueryResponse = JobQueryResponse.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.jobGetQueryResultsResponse = JobGetQueryResultsResponse.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.jobQueryDoneResponse = JobQueryDoneResponse.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.policyResponse = Policy.decode(reader, reader.uint32());
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.jobCompletedEvent = JobCompletedEvent.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.tableDataReadEvents.push(TableDataReadEvent.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AuditData {
    return {
      tableInsertRequest: isSet(object.tableInsertRequest)
        ? TableInsertRequest.fromJSON(object.tableInsertRequest)
        : undefined,
      tableUpdateRequest: isSet(object.tableUpdateRequest)
        ? TableUpdateRequest.fromJSON(object.tableUpdateRequest)
        : undefined,
      datasetListRequest: isSet(object.datasetListRequest)
        ? DatasetListRequest.fromJSON(object.datasetListRequest)
        : undefined,
      datasetInsertRequest: isSet(object.datasetInsertRequest)
        ? DatasetInsertRequest.fromJSON(object.datasetInsertRequest)
        : undefined,
      datasetUpdateRequest: isSet(object.datasetUpdateRequest)
        ? DatasetUpdateRequest.fromJSON(object.datasetUpdateRequest)
        : undefined,
      jobInsertRequest: isSet(object.jobInsertRequest) ? JobInsertRequest.fromJSON(object.jobInsertRequest) : undefined,
      jobQueryRequest: isSet(object.jobQueryRequest) ? JobQueryRequest.fromJSON(object.jobQueryRequest) : undefined,
      jobGetQueryResultsRequest: isSet(object.jobGetQueryResultsRequest)
        ? JobGetQueryResultsRequest.fromJSON(object.jobGetQueryResultsRequest)
        : undefined,
      tableDataListRequest: isSet(object.tableDataListRequest)
        ? TableDataListRequest.fromJSON(object.tableDataListRequest)
        : undefined,
      setIamPolicyRequest: isSet(object.setIamPolicyRequest)
        ? SetIamPolicyRequest.fromJSON(object.setIamPolicyRequest)
        : undefined,
      tableInsertResponse: isSet(object.tableInsertResponse)
        ? TableInsertResponse.fromJSON(object.tableInsertResponse)
        : undefined,
      tableUpdateResponse: isSet(object.tableUpdateResponse)
        ? TableUpdateResponse.fromJSON(object.tableUpdateResponse)
        : undefined,
      datasetInsertResponse: isSet(object.datasetInsertResponse)
        ? DatasetInsertResponse.fromJSON(object.datasetInsertResponse)
        : undefined,
      datasetUpdateResponse: isSet(object.datasetUpdateResponse)
        ? DatasetUpdateResponse.fromJSON(object.datasetUpdateResponse)
        : undefined,
      jobInsertResponse: isSet(object.jobInsertResponse)
        ? JobInsertResponse.fromJSON(object.jobInsertResponse)
        : undefined,
      jobQueryResponse: isSet(object.jobQueryResponse) ? JobQueryResponse.fromJSON(object.jobQueryResponse) : undefined,
      jobGetQueryResultsResponse: isSet(object.jobGetQueryResultsResponse)
        ? JobGetQueryResultsResponse.fromJSON(object.jobGetQueryResultsResponse)
        : undefined,
      jobQueryDoneResponse: isSet(object.jobQueryDoneResponse)
        ? JobQueryDoneResponse.fromJSON(object.jobQueryDoneResponse)
        : undefined,
      policyResponse: isSet(object.policyResponse) ? Policy.fromJSON(object.policyResponse) : undefined,
      jobCompletedEvent: isSet(object.jobCompletedEvent)
        ? JobCompletedEvent.fromJSON(object.jobCompletedEvent)
        : undefined,
      tableDataReadEvents: globalThis.Array.isArray(object?.tableDataReadEvents)
        ? object.tableDataReadEvents.map((e: any) => TableDataReadEvent.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AuditData): unknown {
    const obj: any = {};
    if (message.tableInsertRequest !== undefined) {
      obj.tableInsertRequest = TableInsertRequest.toJSON(message.tableInsertRequest);
    }
    if (message.tableUpdateRequest !== undefined) {
      obj.tableUpdateRequest = TableUpdateRequest.toJSON(message.tableUpdateRequest);
    }
    if (message.datasetListRequest !== undefined) {
      obj.datasetListRequest = DatasetListRequest.toJSON(message.datasetListRequest);
    }
    if (message.datasetInsertRequest !== undefined) {
      obj.datasetInsertRequest = DatasetInsertRequest.toJSON(message.datasetInsertRequest);
    }
    if (message.datasetUpdateRequest !== undefined) {
      obj.datasetUpdateRequest = DatasetUpdateRequest.toJSON(message.datasetUpdateRequest);
    }
    if (message.jobInsertRequest !== undefined) {
      obj.jobInsertRequest = JobInsertRequest.toJSON(message.jobInsertRequest);
    }
    if (message.jobQueryRequest !== undefined) {
      obj.jobQueryRequest = JobQueryRequest.toJSON(message.jobQueryRequest);
    }
    if (message.jobGetQueryResultsRequest !== undefined) {
      obj.jobGetQueryResultsRequest = JobGetQueryResultsRequest.toJSON(message.jobGetQueryResultsRequest);
    }
    if (message.tableDataListRequest !== undefined) {
      obj.tableDataListRequest = TableDataListRequest.toJSON(message.tableDataListRequest);
    }
    if (message.setIamPolicyRequest !== undefined) {
      obj.setIamPolicyRequest = SetIamPolicyRequest.toJSON(message.setIamPolicyRequest);
    }
    if (message.tableInsertResponse !== undefined) {
      obj.tableInsertResponse = TableInsertResponse.toJSON(message.tableInsertResponse);
    }
    if (message.tableUpdateResponse !== undefined) {
      obj.tableUpdateResponse = TableUpdateResponse.toJSON(message.tableUpdateResponse);
    }
    if (message.datasetInsertResponse !== undefined) {
      obj.datasetInsertResponse = DatasetInsertResponse.toJSON(message.datasetInsertResponse);
    }
    if (message.datasetUpdateResponse !== undefined) {
      obj.datasetUpdateResponse = DatasetUpdateResponse.toJSON(message.datasetUpdateResponse);
    }
    if (message.jobInsertResponse !== undefined) {
      obj.jobInsertResponse = JobInsertResponse.toJSON(message.jobInsertResponse);
    }
    if (message.jobQueryResponse !== undefined) {
      obj.jobQueryResponse = JobQueryResponse.toJSON(message.jobQueryResponse);
    }
    if (message.jobGetQueryResultsResponse !== undefined) {
      obj.jobGetQueryResultsResponse = JobGetQueryResultsResponse.toJSON(message.jobGetQueryResultsResponse);
    }
    if (message.jobQueryDoneResponse !== undefined) {
      obj.jobQueryDoneResponse = JobQueryDoneResponse.toJSON(message.jobQueryDoneResponse);
    }
    if (message.policyResponse !== undefined) {
      obj.policyResponse = Policy.toJSON(message.policyResponse);
    }
    if (message.jobCompletedEvent !== undefined) {
      obj.jobCompletedEvent = JobCompletedEvent.toJSON(message.jobCompletedEvent);
    }
    if (message.tableDataReadEvents?.length) {
      obj.tableDataReadEvents = message.tableDataReadEvents.map((e) => TableDataReadEvent.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AuditData>): AuditData {
    return AuditData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AuditData>): AuditData {
    const message = createBaseAuditData();
    message.tableInsertRequest = (object.tableInsertRequest !== undefined && object.tableInsertRequest !== null)
      ? TableInsertRequest.fromPartial(object.tableInsertRequest)
      : undefined;
    message.tableUpdateRequest = (object.tableUpdateRequest !== undefined && object.tableUpdateRequest !== null)
      ? TableUpdateRequest.fromPartial(object.tableUpdateRequest)
      : undefined;
    message.datasetListRequest = (object.datasetListRequest !== undefined && object.datasetListRequest !== null)
      ? DatasetListRequest.fromPartial(object.datasetListRequest)
      : undefined;
    message.datasetInsertRequest = (object.datasetInsertRequest !== undefined && object.datasetInsertRequest !== null)
      ? DatasetInsertRequest.fromPartial(object.datasetInsertRequest)
      : undefined;
    message.datasetUpdateRequest = (object.datasetUpdateRequest !== undefined && object.datasetUpdateRequest !== null)
      ? DatasetUpdateRequest.fromPartial(object.datasetUpdateRequest)
      : undefined;
    message.jobInsertRequest = (object.jobInsertRequest !== undefined && object.jobInsertRequest !== null)
      ? JobInsertRequest.fromPartial(object.jobInsertRequest)
      : undefined;
    message.jobQueryRequest = (object.jobQueryRequest !== undefined && object.jobQueryRequest !== null)
      ? JobQueryRequest.fromPartial(object.jobQueryRequest)
      : undefined;
    message.jobGetQueryResultsRequest =
      (object.jobGetQueryResultsRequest !== undefined && object.jobGetQueryResultsRequest !== null)
        ? JobGetQueryResultsRequest.fromPartial(object.jobGetQueryResultsRequest)
        : undefined;
    message.tableDataListRequest = (object.tableDataListRequest !== undefined && object.tableDataListRequest !== null)
      ? TableDataListRequest.fromPartial(object.tableDataListRequest)
      : undefined;
    message.setIamPolicyRequest = (object.setIamPolicyRequest !== undefined && object.setIamPolicyRequest !== null)
      ? SetIamPolicyRequest.fromPartial(object.setIamPolicyRequest)
      : undefined;
    message.tableInsertResponse = (object.tableInsertResponse !== undefined && object.tableInsertResponse !== null)
      ? TableInsertResponse.fromPartial(object.tableInsertResponse)
      : undefined;
    message.tableUpdateResponse = (object.tableUpdateResponse !== undefined && object.tableUpdateResponse !== null)
      ? TableUpdateResponse.fromPartial(object.tableUpdateResponse)
      : undefined;
    message.datasetInsertResponse =
      (object.datasetInsertResponse !== undefined && object.datasetInsertResponse !== null)
        ? DatasetInsertResponse.fromPartial(object.datasetInsertResponse)
        : undefined;
    message.datasetUpdateResponse =
      (object.datasetUpdateResponse !== undefined && object.datasetUpdateResponse !== null)
        ? DatasetUpdateResponse.fromPartial(object.datasetUpdateResponse)
        : undefined;
    message.jobInsertResponse = (object.jobInsertResponse !== undefined && object.jobInsertResponse !== null)
      ? JobInsertResponse.fromPartial(object.jobInsertResponse)
      : undefined;
    message.jobQueryResponse = (object.jobQueryResponse !== undefined && object.jobQueryResponse !== null)
      ? JobQueryResponse.fromPartial(object.jobQueryResponse)
      : undefined;
    message.jobGetQueryResultsResponse =
      (object.jobGetQueryResultsResponse !== undefined && object.jobGetQueryResultsResponse !== null)
        ? JobGetQueryResultsResponse.fromPartial(object.jobGetQueryResultsResponse)
        : undefined;
    message.jobQueryDoneResponse = (object.jobQueryDoneResponse !== undefined && object.jobQueryDoneResponse !== null)
      ? JobQueryDoneResponse.fromPartial(object.jobQueryDoneResponse)
      : undefined;
    message.policyResponse = (object.policyResponse !== undefined && object.policyResponse !== null)
      ? Policy.fromPartial(object.policyResponse)
      : undefined;
    message.jobCompletedEvent = (object.jobCompletedEvent !== undefined && object.jobCompletedEvent !== null)
      ? JobCompletedEvent.fromPartial(object.jobCompletedEvent)
      : undefined;
    message.tableDataReadEvents = object.tableDataReadEvents?.map((e) => TableDataReadEvent.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTableInsertRequest(): TableInsertRequest {
  return { resource: undefined };
}

export const TableInsertRequest: MessageFns<TableInsertRequest> = {
  encode(message: TableInsertRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Table.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableInsertRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableInsertRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Table.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableInsertRequest {
    return { resource: isSet(object.resource) ? Table.fromJSON(object.resource) : undefined };
  },

  toJSON(message: TableInsertRequest): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Table.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<TableInsertRequest>): TableInsertRequest {
    return TableInsertRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableInsertRequest>): TableInsertRequest {
    const message = createBaseTableInsertRequest();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Table.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseTableUpdateRequest(): TableUpdateRequest {
  return { resource: undefined };
}

export const TableUpdateRequest: MessageFns<TableUpdateRequest> = {
  encode(message: TableUpdateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Table.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableUpdateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableUpdateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Table.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableUpdateRequest {
    return { resource: isSet(object.resource) ? Table.fromJSON(object.resource) : undefined };
  },

  toJSON(message: TableUpdateRequest): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Table.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<TableUpdateRequest>): TableUpdateRequest {
    return TableUpdateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableUpdateRequest>): TableUpdateRequest {
    const message = createBaseTableUpdateRequest();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Table.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseTableInsertResponse(): TableInsertResponse {
  return { resource: undefined };
}

export const TableInsertResponse: MessageFns<TableInsertResponse> = {
  encode(message: TableInsertResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Table.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableInsertResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableInsertResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Table.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableInsertResponse {
    return { resource: isSet(object.resource) ? Table.fromJSON(object.resource) : undefined };
  },

  toJSON(message: TableInsertResponse): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Table.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<TableInsertResponse>): TableInsertResponse {
    return TableInsertResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableInsertResponse>): TableInsertResponse {
    const message = createBaseTableInsertResponse();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Table.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseTableUpdateResponse(): TableUpdateResponse {
  return { resource: undefined };
}

export const TableUpdateResponse: MessageFns<TableUpdateResponse> = {
  encode(message: TableUpdateResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Table.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableUpdateResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableUpdateResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Table.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableUpdateResponse {
    return { resource: isSet(object.resource) ? Table.fromJSON(object.resource) : undefined };
  },

  toJSON(message: TableUpdateResponse): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Table.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<TableUpdateResponse>): TableUpdateResponse {
    return TableUpdateResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableUpdateResponse>): TableUpdateResponse {
    const message = createBaseTableUpdateResponse();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Table.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseDatasetListRequest(): DatasetListRequest {
  return { listAll: false };
}

export const DatasetListRequest: MessageFns<DatasetListRequest> = {
  encode(message: DatasetListRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.listAll !== false) {
      writer.uint32(8).bool(message.listAll);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetListRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetListRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.listAll = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetListRequest {
    return { listAll: isSet(object.listAll) ? globalThis.Boolean(object.listAll) : false };
  },

  toJSON(message: DatasetListRequest): unknown {
    const obj: any = {};
    if (message.listAll !== false) {
      obj.listAll = message.listAll;
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetListRequest>): DatasetListRequest {
    return DatasetListRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetListRequest>): DatasetListRequest {
    const message = createBaseDatasetListRequest();
    message.listAll = object.listAll ?? false;
    return message;
  },
};

function createBaseDatasetInsertRequest(): DatasetInsertRequest {
  return { resource: undefined };
}

export const DatasetInsertRequest: MessageFns<DatasetInsertRequest> = {
  encode(message: DatasetInsertRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Dataset.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetInsertRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetInsertRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Dataset.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetInsertRequest {
    return { resource: isSet(object.resource) ? Dataset.fromJSON(object.resource) : undefined };
  },

  toJSON(message: DatasetInsertRequest): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Dataset.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetInsertRequest>): DatasetInsertRequest {
    return DatasetInsertRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetInsertRequest>): DatasetInsertRequest {
    const message = createBaseDatasetInsertRequest();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Dataset.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseDatasetInsertResponse(): DatasetInsertResponse {
  return { resource: undefined };
}

export const DatasetInsertResponse: MessageFns<DatasetInsertResponse> = {
  encode(message: DatasetInsertResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Dataset.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetInsertResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetInsertResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Dataset.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetInsertResponse {
    return { resource: isSet(object.resource) ? Dataset.fromJSON(object.resource) : undefined };
  },

  toJSON(message: DatasetInsertResponse): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Dataset.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetInsertResponse>): DatasetInsertResponse {
    return DatasetInsertResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetInsertResponse>): DatasetInsertResponse {
    const message = createBaseDatasetInsertResponse();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Dataset.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseDatasetUpdateRequest(): DatasetUpdateRequest {
  return { resource: undefined };
}

export const DatasetUpdateRequest: MessageFns<DatasetUpdateRequest> = {
  encode(message: DatasetUpdateRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Dataset.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetUpdateRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetUpdateRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Dataset.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetUpdateRequest {
    return { resource: isSet(object.resource) ? Dataset.fromJSON(object.resource) : undefined };
  },

  toJSON(message: DatasetUpdateRequest): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Dataset.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetUpdateRequest>): DatasetUpdateRequest {
    return DatasetUpdateRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetUpdateRequest>): DatasetUpdateRequest {
    const message = createBaseDatasetUpdateRequest();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Dataset.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseDatasetUpdateResponse(): DatasetUpdateResponse {
  return { resource: undefined };
}

export const DatasetUpdateResponse: MessageFns<DatasetUpdateResponse> = {
  encode(message: DatasetUpdateResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Dataset.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetUpdateResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetUpdateResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Dataset.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetUpdateResponse {
    return { resource: isSet(object.resource) ? Dataset.fromJSON(object.resource) : undefined };
  },

  toJSON(message: DatasetUpdateResponse): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Dataset.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetUpdateResponse>): DatasetUpdateResponse {
    return DatasetUpdateResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetUpdateResponse>): DatasetUpdateResponse {
    const message = createBaseDatasetUpdateResponse();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Dataset.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseJobInsertRequest(): JobInsertRequest {
  return { resource: undefined };
}

export const JobInsertRequest: MessageFns<JobInsertRequest> = {
  encode(message: JobInsertRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Job.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobInsertRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobInsertRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobInsertRequest {
    return { resource: isSet(object.resource) ? Job.fromJSON(object.resource) : undefined };
  },

  toJSON(message: JobInsertRequest): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Job.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<JobInsertRequest>): JobInsertRequest {
    return JobInsertRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobInsertRequest>): JobInsertRequest {
    const message = createBaseJobInsertRequest();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Job.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseJobInsertResponse(): JobInsertResponse {
  return { resource: undefined };
}

export const JobInsertResponse: MessageFns<JobInsertResponse> = {
  encode(message: JobInsertResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Job.encode(message.resource, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobInsertResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobInsertResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobInsertResponse {
    return { resource: isSet(object.resource) ? Job.fromJSON(object.resource) : undefined };
  },

  toJSON(message: JobInsertResponse): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Job.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<JobInsertResponse>): JobInsertResponse {
    return JobInsertResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobInsertResponse>): JobInsertResponse {
    const message = createBaseJobInsertResponse();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Job.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseJobQueryRequest(): JobQueryRequest {
  return { query: "", maxResults: 0, defaultDataset: undefined, projectId: "", dryRun: false };
}

export const JobQueryRequest: MessageFns<JobQueryRequest> = {
  encode(message: JobQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.maxResults !== 0) {
      writer.uint32(16).uint32(message.maxResults);
    }
    if (message.defaultDataset !== undefined) {
      DatasetName.encode(message.defaultDataset, writer.uint32(26).fork()).join();
    }
    if (message.projectId !== "") {
      writer.uint32(34).string(message.projectId);
    }
    if (message.dryRun !== false) {
      writer.uint32(40).bool(message.dryRun);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxResults = reader.uint32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.defaultDataset = DatasetName.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.dryRun = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobQueryRequest {
    return {
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      maxResults: isSet(object.maxResults) ? globalThis.Number(object.maxResults) : 0,
      defaultDataset: isSet(object.defaultDataset) ? DatasetName.fromJSON(object.defaultDataset) : undefined,
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      dryRun: isSet(object.dryRun) ? globalThis.Boolean(object.dryRun) : false,
    };
  },

  toJSON(message: JobQueryRequest): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.maxResults !== 0) {
      obj.maxResults = Math.round(message.maxResults);
    }
    if (message.defaultDataset !== undefined) {
      obj.defaultDataset = DatasetName.toJSON(message.defaultDataset);
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.dryRun !== false) {
      obj.dryRun = message.dryRun;
    }
    return obj;
  },

  create(base?: DeepPartial<JobQueryRequest>): JobQueryRequest {
    return JobQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobQueryRequest>): JobQueryRequest {
    const message = createBaseJobQueryRequest();
    message.query = object.query ?? "";
    message.maxResults = object.maxResults ?? 0;
    message.defaultDataset = (object.defaultDataset !== undefined && object.defaultDataset !== null)
      ? DatasetName.fromPartial(object.defaultDataset)
      : undefined;
    message.projectId = object.projectId ?? "";
    message.dryRun = object.dryRun ?? false;
    return message;
  },
};

function createBaseJobQueryResponse(): JobQueryResponse {
  return { totalResults: Long.UZERO, job: undefined };
}

export const JobQueryResponse: MessageFns<JobQueryResponse> = {
  encode(message: JobQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.totalResults.equals(Long.UZERO)) {
      writer.uint32(8).uint64(message.totalResults.toString());
    }
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.totalResults = Long.fromString(reader.uint64().toString(), true);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobQueryResponse {
    return {
      totalResults: isSet(object.totalResults) ? Long.fromValue(object.totalResults) : Long.UZERO,
      job: isSet(object.job) ? Job.fromJSON(object.job) : undefined,
    };
  },

  toJSON(message: JobQueryResponse): unknown {
    const obj: any = {};
    if (!message.totalResults.equals(Long.UZERO)) {
      obj.totalResults = (message.totalResults || Long.UZERO).toString();
    }
    if (message.job !== undefined) {
      obj.job = Job.toJSON(message.job);
    }
    return obj;
  },

  create(base?: DeepPartial<JobQueryResponse>): JobQueryResponse {
    return JobQueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobQueryResponse>): JobQueryResponse {
    const message = createBaseJobQueryResponse();
    message.totalResults = (object.totalResults !== undefined && object.totalResults !== null)
      ? Long.fromValue(object.totalResults)
      : Long.UZERO;
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    return message;
  },
};

function createBaseJobGetQueryResultsRequest(): JobGetQueryResultsRequest {
  return { maxResults: 0, startRow: Long.UZERO };
}

export const JobGetQueryResultsRequest: MessageFns<JobGetQueryResultsRequest> = {
  encode(message: JobGetQueryResultsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxResults !== 0) {
      writer.uint32(8).uint32(message.maxResults);
    }
    if (!message.startRow.equals(Long.UZERO)) {
      writer.uint32(16).uint64(message.startRow.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobGetQueryResultsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobGetQueryResultsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.maxResults = reader.uint32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.startRow = Long.fromString(reader.uint64().toString(), true);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobGetQueryResultsRequest {
    return {
      maxResults: isSet(object.maxResults) ? globalThis.Number(object.maxResults) : 0,
      startRow: isSet(object.startRow) ? Long.fromValue(object.startRow) : Long.UZERO,
    };
  },

  toJSON(message: JobGetQueryResultsRequest): unknown {
    const obj: any = {};
    if (message.maxResults !== 0) {
      obj.maxResults = Math.round(message.maxResults);
    }
    if (!message.startRow.equals(Long.UZERO)) {
      obj.startRow = (message.startRow || Long.UZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<JobGetQueryResultsRequest>): JobGetQueryResultsRequest {
    return JobGetQueryResultsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobGetQueryResultsRequest>): JobGetQueryResultsRequest {
    const message = createBaseJobGetQueryResultsRequest();
    message.maxResults = object.maxResults ?? 0;
    message.startRow = (object.startRow !== undefined && object.startRow !== null)
      ? Long.fromValue(object.startRow)
      : Long.UZERO;
    return message;
  },
};

function createBaseJobGetQueryResultsResponse(): JobGetQueryResultsResponse {
  return { totalResults: Long.UZERO, job: undefined };
}

export const JobGetQueryResultsResponse: MessageFns<JobGetQueryResultsResponse> = {
  encode(message: JobGetQueryResultsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.totalResults.equals(Long.UZERO)) {
      writer.uint32(8).uint64(message.totalResults.toString());
    }
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobGetQueryResultsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobGetQueryResultsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.totalResults = Long.fromString(reader.uint64().toString(), true);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobGetQueryResultsResponse {
    return {
      totalResults: isSet(object.totalResults) ? Long.fromValue(object.totalResults) : Long.UZERO,
      job: isSet(object.job) ? Job.fromJSON(object.job) : undefined,
    };
  },

  toJSON(message: JobGetQueryResultsResponse): unknown {
    const obj: any = {};
    if (!message.totalResults.equals(Long.UZERO)) {
      obj.totalResults = (message.totalResults || Long.UZERO).toString();
    }
    if (message.job !== undefined) {
      obj.job = Job.toJSON(message.job);
    }
    return obj;
  },

  create(base?: DeepPartial<JobGetQueryResultsResponse>): JobGetQueryResultsResponse {
    return JobGetQueryResultsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobGetQueryResultsResponse>): JobGetQueryResultsResponse {
    const message = createBaseJobGetQueryResultsResponse();
    message.totalResults = (object.totalResults !== undefined && object.totalResults !== null)
      ? Long.fromValue(object.totalResults)
      : Long.UZERO;
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    return message;
  },
};

function createBaseJobQueryDoneResponse(): JobQueryDoneResponse {
  return { job: undefined };
}

export const JobQueryDoneResponse: MessageFns<JobQueryDoneResponse> = {
  encode(message: JobQueryDoneResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobQueryDoneResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobQueryDoneResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobQueryDoneResponse {
    return { job: isSet(object.job) ? Job.fromJSON(object.job) : undefined };
  },

  toJSON(message: JobQueryDoneResponse): unknown {
    const obj: any = {};
    if (message.job !== undefined) {
      obj.job = Job.toJSON(message.job);
    }
    return obj;
  },

  create(base?: DeepPartial<JobQueryDoneResponse>): JobQueryDoneResponse {
    return JobQueryDoneResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobQueryDoneResponse>): JobQueryDoneResponse {
    const message = createBaseJobQueryDoneResponse();
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    return message;
  },
};

function createBaseJobCompletedEvent(): JobCompletedEvent {
  return { eventName: "", job: undefined };
}

export const JobCompletedEvent: MessageFns<JobCompletedEvent> = {
  encode(message: JobCompletedEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.eventName !== "") {
      writer.uint32(10).string(message.eventName);
    }
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobCompletedEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobCompletedEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.eventName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobCompletedEvent {
    return {
      eventName: isSet(object.eventName) ? globalThis.String(object.eventName) : "",
      job: isSet(object.job) ? Job.fromJSON(object.job) : undefined,
    };
  },

  toJSON(message: JobCompletedEvent): unknown {
    const obj: any = {};
    if (message.eventName !== "") {
      obj.eventName = message.eventName;
    }
    if (message.job !== undefined) {
      obj.job = Job.toJSON(message.job);
    }
    return obj;
  },

  create(base?: DeepPartial<JobCompletedEvent>): JobCompletedEvent {
    return JobCompletedEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobCompletedEvent>): JobCompletedEvent {
    const message = createBaseJobCompletedEvent();
    message.eventName = object.eventName ?? "";
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    return message;
  },
};

function createBaseTableDataReadEvent(): TableDataReadEvent {
  return { tableName: undefined, referencedFields: [] };
}

export const TableDataReadEvent: MessageFns<TableDataReadEvent> = {
  encode(message: TableDataReadEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== undefined) {
      TableName.encode(message.tableName, writer.uint32(10).fork()).join();
    }
    for (const v of message.referencedFields) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableDataReadEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableDataReadEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = TableName.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.referencedFields.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableDataReadEvent {
    return {
      tableName: isSet(object.tableName) ? TableName.fromJSON(object.tableName) : undefined,
      referencedFields: globalThis.Array.isArray(object?.referencedFields)
        ? object.referencedFields.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: TableDataReadEvent): unknown {
    const obj: any = {};
    if (message.tableName !== undefined) {
      obj.tableName = TableName.toJSON(message.tableName);
    }
    if (message.referencedFields?.length) {
      obj.referencedFields = message.referencedFields;
    }
    return obj;
  },

  create(base?: DeepPartial<TableDataReadEvent>): TableDataReadEvent {
    return TableDataReadEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableDataReadEvent>): TableDataReadEvent {
    const message = createBaseTableDataReadEvent();
    message.tableName = (object.tableName !== undefined && object.tableName !== null)
      ? TableName.fromPartial(object.tableName)
      : undefined;
    message.referencedFields = object.referencedFields?.map((e) => e) || [];
    return message;
  },
};

function createBaseTableDataListRequest(): TableDataListRequest {
  return { startRow: Long.UZERO, maxResults: 0 };
}

export const TableDataListRequest: MessageFns<TableDataListRequest> = {
  encode(message: TableDataListRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.startRow.equals(Long.UZERO)) {
      writer.uint32(8).uint64(message.startRow.toString());
    }
    if (message.maxResults !== 0) {
      writer.uint32(16).uint32(message.maxResults);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableDataListRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableDataListRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.startRow = Long.fromString(reader.uint64().toString(), true);
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxResults = reader.uint32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableDataListRequest {
    return {
      startRow: isSet(object.startRow) ? Long.fromValue(object.startRow) : Long.UZERO,
      maxResults: isSet(object.maxResults) ? globalThis.Number(object.maxResults) : 0,
    };
  },

  toJSON(message: TableDataListRequest): unknown {
    const obj: any = {};
    if (!message.startRow.equals(Long.UZERO)) {
      obj.startRow = (message.startRow || Long.UZERO).toString();
    }
    if (message.maxResults !== 0) {
      obj.maxResults = Math.round(message.maxResults);
    }
    return obj;
  },

  create(base?: DeepPartial<TableDataListRequest>): TableDataListRequest {
    return TableDataListRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableDataListRequest>): TableDataListRequest {
    const message = createBaseTableDataListRequest();
    message.startRow = (object.startRow !== undefined && object.startRow !== null)
      ? Long.fromValue(object.startRow)
      : Long.UZERO;
    message.maxResults = object.maxResults ?? 0;
    return message;
  },
};

function createBaseTable(): Table {
  return {
    tableName: undefined,
    info: undefined,
    schemaJson: "",
    view: undefined,
    expireTime: undefined,
    createTime: undefined,
    truncateTime: undefined,
    updateTime: undefined,
    encryption: undefined,
  };
}

export const Table: MessageFns<Table> = {
  encode(message: Table, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== undefined) {
      TableName.encode(message.tableName, writer.uint32(10).fork()).join();
    }
    if (message.info !== undefined) {
      TableInfo.encode(message.info, writer.uint32(18).fork()).join();
    }
    if (message.schemaJson !== "") {
      writer.uint32(66).string(message.schemaJson);
    }
    if (message.view !== undefined) {
      TableViewDefinition.encode(message.view, writer.uint32(34).fork()).join();
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(42).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.truncateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.truncateTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(74).fork()).join();
    }
    if (message.encryption !== undefined) {
      EncryptionInfo.encode(message.encryption, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Table {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = TableName.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.info = TableInfo.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.schemaJson = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.view = TableViewDefinition.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.truncateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.encryption = EncryptionInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Table {
    return {
      tableName: isSet(object.tableName) ? TableName.fromJSON(object.tableName) : undefined,
      info: isSet(object.info) ? TableInfo.fromJSON(object.info) : undefined,
      schemaJson: isSet(object.schemaJson) ? globalThis.String(object.schemaJson) : "",
      view: isSet(object.view) ? TableViewDefinition.fromJSON(object.view) : undefined,
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      truncateTime: isSet(object.truncateTime) ? fromJsonTimestamp(object.truncateTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      encryption: isSet(object.encryption) ? EncryptionInfo.fromJSON(object.encryption) : undefined,
    };
  },

  toJSON(message: Table): unknown {
    const obj: any = {};
    if (message.tableName !== undefined) {
      obj.tableName = TableName.toJSON(message.tableName);
    }
    if (message.info !== undefined) {
      obj.info = TableInfo.toJSON(message.info);
    }
    if (message.schemaJson !== "") {
      obj.schemaJson = message.schemaJson;
    }
    if (message.view !== undefined) {
      obj.view = TableViewDefinition.toJSON(message.view);
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.truncateTime !== undefined) {
      obj.truncateTime = message.truncateTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.encryption !== undefined) {
      obj.encryption = EncryptionInfo.toJSON(message.encryption);
    }
    return obj;
  },

  create(base?: DeepPartial<Table>): Table {
    return Table.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Table>): Table {
    const message = createBaseTable();
    message.tableName = (object.tableName !== undefined && object.tableName !== null)
      ? TableName.fromPartial(object.tableName)
      : undefined;
    message.info = (object.info !== undefined && object.info !== null) ? TableInfo.fromPartial(object.info) : undefined;
    message.schemaJson = object.schemaJson ?? "";
    message.view = (object.view !== undefined && object.view !== null)
      ? TableViewDefinition.fromPartial(object.view)
      : undefined;
    message.expireTime = object.expireTime ?? undefined;
    message.createTime = object.createTime ?? undefined;
    message.truncateTime = object.truncateTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.encryption = (object.encryption !== undefined && object.encryption !== null)
      ? EncryptionInfo.fromPartial(object.encryption)
      : undefined;
    return message;
  },
};

function createBaseTableInfo(): TableInfo {
  return { friendlyName: "", description: "", labels: {} };
}

export const TableInfo: MessageFns<TableInfo> = {
  encode(message: TableInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.friendlyName !== "") {
      writer.uint32(10).string(message.friendlyName);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      TableInfo_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.friendlyName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = TableInfo_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableInfo {
    return {
      friendlyName: isSet(object.friendlyName) ? globalThis.String(object.friendlyName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: TableInfo): unknown {
    const obj: any = {};
    if (message.friendlyName !== "") {
      obj.friendlyName = message.friendlyName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<TableInfo>): TableInfo {
    return TableInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableInfo>): TableInfo {
    const message = createBaseTableInfo();
    message.friendlyName = object.friendlyName ?? "";
    message.description = object.description ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseTableInfo_LabelsEntry(): TableInfo_LabelsEntry {
  return { key: "", value: "" };
}

export const TableInfo_LabelsEntry: MessageFns<TableInfo_LabelsEntry> = {
  encode(message: TableInfo_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableInfo_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableInfo_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableInfo_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: TableInfo_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<TableInfo_LabelsEntry>): TableInfo_LabelsEntry {
    return TableInfo_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableInfo_LabelsEntry>): TableInfo_LabelsEntry {
    const message = createBaseTableInfo_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTableViewDefinition(): TableViewDefinition {
  return { query: "" };
}

export const TableViewDefinition: MessageFns<TableViewDefinition> = {
  encode(message: TableViewDefinition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableViewDefinition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableViewDefinition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableViewDefinition {
    return { query: isSet(object.query) ? globalThis.String(object.query) : "" };
  },

  toJSON(message: TableViewDefinition): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    return obj;
  },

  create(base?: DeepPartial<TableViewDefinition>): TableViewDefinition {
    return TableViewDefinition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableViewDefinition>): TableViewDefinition {
    const message = createBaseTableViewDefinition();
    message.query = object.query ?? "";
    return message;
  },
};

function createBaseDataset(): Dataset {
  return {
    datasetName: undefined,
    info: undefined,
    createTime: undefined,
    updateTime: undefined,
    acl: undefined,
    defaultTableExpireDuration: undefined,
  };
}

export const Dataset: MessageFns<Dataset> = {
  encode(message: Dataset, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.datasetName !== undefined) {
      DatasetName.encode(message.datasetName, writer.uint32(10).fork()).join();
    }
    if (message.info !== undefined) {
      DatasetInfo.encode(message.info, writer.uint32(18).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    if (message.acl !== undefined) {
      BigQueryAcl.encode(message.acl, writer.uint32(50).fork()).join();
    }
    if (message.defaultTableExpireDuration !== undefined) {
      Duration.encode(message.defaultTableExpireDuration, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Dataset {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.datasetName = DatasetName.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.info = DatasetInfo.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.acl = BigQueryAcl.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.defaultTableExpireDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Dataset {
    return {
      datasetName: isSet(object.datasetName) ? DatasetName.fromJSON(object.datasetName) : undefined,
      info: isSet(object.info) ? DatasetInfo.fromJSON(object.info) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      acl: isSet(object.acl) ? BigQueryAcl.fromJSON(object.acl) : undefined,
      defaultTableExpireDuration: isSet(object.defaultTableExpireDuration)
        ? Duration.fromJSON(object.defaultTableExpireDuration)
        : undefined,
    };
  },

  toJSON(message: Dataset): unknown {
    const obj: any = {};
    if (message.datasetName !== undefined) {
      obj.datasetName = DatasetName.toJSON(message.datasetName);
    }
    if (message.info !== undefined) {
      obj.info = DatasetInfo.toJSON(message.info);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.acl !== undefined) {
      obj.acl = BigQueryAcl.toJSON(message.acl);
    }
    if (message.defaultTableExpireDuration !== undefined) {
      obj.defaultTableExpireDuration = Duration.toJSON(message.defaultTableExpireDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<Dataset>): Dataset {
    return Dataset.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Dataset>): Dataset {
    const message = createBaseDataset();
    message.datasetName = (object.datasetName !== undefined && object.datasetName !== null)
      ? DatasetName.fromPartial(object.datasetName)
      : undefined;
    message.info = (object.info !== undefined && object.info !== null)
      ? DatasetInfo.fromPartial(object.info)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.acl = (object.acl !== undefined && object.acl !== null) ? BigQueryAcl.fromPartial(object.acl) : undefined;
    message.defaultTableExpireDuration =
      (object.defaultTableExpireDuration !== undefined && object.defaultTableExpireDuration !== null)
        ? Duration.fromPartial(object.defaultTableExpireDuration)
        : undefined;
    return message;
  },
};

function createBaseDatasetInfo(): DatasetInfo {
  return { friendlyName: "", description: "", labels: {} };
}

export const DatasetInfo: MessageFns<DatasetInfo> = {
  encode(message: DatasetInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.friendlyName !== "") {
      writer.uint32(10).string(message.friendlyName);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      DatasetInfo_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.friendlyName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = DatasetInfo_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetInfo {
    return {
      friendlyName: isSet(object.friendlyName) ? globalThis.String(object.friendlyName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: DatasetInfo): unknown {
    const obj: any = {};
    if (message.friendlyName !== "") {
      obj.friendlyName = message.friendlyName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetInfo>): DatasetInfo {
    return DatasetInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetInfo>): DatasetInfo {
    const message = createBaseDatasetInfo();
    message.friendlyName = object.friendlyName ?? "";
    message.description = object.description ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseDatasetInfo_LabelsEntry(): DatasetInfo_LabelsEntry {
  return { key: "", value: "" };
}

export const DatasetInfo_LabelsEntry: MessageFns<DatasetInfo_LabelsEntry> = {
  encode(message: DatasetInfo_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetInfo_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetInfo_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetInfo_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DatasetInfo_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetInfo_LabelsEntry>): DatasetInfo_LabelsEntry {
    return DatasetInfo_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetInfo_LabelsEntry>): DatasetInfo_LabelsEntry {
    const message = createBaseDatasetInfo_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBigQueryAcl(): BigQueryAcl {
  return { entries: [] };
}

export const BigQueryAcl: MessageFns<BigQueryAcl> = {
  encode(message: BigQueryAcl, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entries) {
      BigQueryAcl_Entry.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryAcl {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryAcl();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entries.push(BigQueryAcl_Entry.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryAcl {
    return {
      entries: globalThis.Array.isArray(object?.entries)
        ? object.entries.map((e: any) => BigQueryAcl_Entry.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BigQueryAcl): unknown {
    const obj: any = {};
    if (message.entries?.length) {
      obj.entries = message.entries.map((e) => BigQueryAcl_Entry.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryAcl>): BigQueryAcl {
    return BigQueryAcl.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryAcl>): BigQueryAcl {
    const message = createBaseBigQueryAcl();
    message.entries = object.entries?.map((e) => BigQueryAcl_Entry.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBigQueryAcl_Entry(): BigQueryAcl_Entry {
  return { role: "", groupEmail: "", userEmail: "", domain: "", specialGroup: "", viewName: undefined };
}

export const BigQueryAcl_Entry: MessageFns<BigQueryAcl_Entry> = {
  encode(message: BigQueryAcl_Entry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.role !== "") {
      writer.uint32(10).string(message.role);
    }
    if (message.groupEmail !== "") {
      writer.uint32(18).string(message.groupEmail);
    }
    if (message.userEmail !== "") {
      writer.uint32(26).string(message.userEmail);
    }
    if (message.domain !== "") {
      writer.uint32(34).string(message.domain);
    }
    if (message.specialGroup !== "") {
      writer.uint32(42).string(message.specialGroup);
    }
    if (message.viewName !== undefined) {
      TableName.encode(message.viewName, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryAcl_Entry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryAcl_Entry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.role = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.groupEmail = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.userEmail = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.domain = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.specialGroup = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.viewName = TableName.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryAcl_Entry {
    return {
      role: isSet(object.role) ? globalThis.String(object.role) : "",
      groupEmail: isSet(object.groupEmail) ? globalThis.String(object.groupEmail) : "",
      userEmail: isSet(object.userEmail) ? globalThis.String(object.userEmail) : "",
      domain: isSet(object.domain) ? globalThis.String(object.domain) : "",
      specialGroup: isSet(object.specialGroup) ? globalThis.String(object.specialGroup) : "",
      viewName: isSet(object.viewName) ? TableName.fromJSON(object.viewName) : undefined,
    };
  },

  toJSON(message: BigQueryAcl_Entry): unknown {
    const obj: any = {};
    if (message.role !== "") {
      obj.role = message.role;
    }
    if (message.groupEmail !== "") {
      obj.groupEmail = message.groupEmail;
    }
    if (message.userEmail !== "") {
      obj.userEmail = message.userEmail;
    }
    if (message.domain !== "") {
      obj.domain = message.domain;
    }
    if (message.specialGroup !== "") {
      obj.specialGroup = message.specialGroup;
    }
    if (message.viewName !== undefined) {
      obj.viewName = TableName.toJSON(message.viewName);
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryAcl_Entry>): BigQueryAcl_Entry {
    return BigQueryAcl_Entry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryAcl_Entry>): BigQueryAcl_Entry {
    const message = createBaseBigQueryAcl_Entry();
    message.role = object.role ?? "";
    message.groupEmail = object.groupEmail ?? "";
    message.userEmail = object.userEmail ?? "";
    message.domain = object.domain ?? "";
    message.specialGroup = object.specialGroup ?? "";
    message.viewName = (object.viewName !== undefined && object.viewName !== null)
      ? TableName.fromPartial(object.viewName)
      : undefined;
    return message;
  },
};

function createBaseJob(): Job {
  return { jobName: undefined, jobConfiguration: undefined, jobStatus: undefined, jobStatistics: undefined };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.jobName !== undefined) {
      JobName.encode(message.jobName, writer.uint32(10).fork()).join();
    }
    if (message.jobConfiguration !== undefined) {
      JobConfiguration.encode(message.jobConfiguration, writer.uint32(18).fork()).join();
    }
    if (message.jobStatus !== undefined) {
      JobStatus.encode(message.jobStatus, writer.uint32(26).fork()).join();
    }
    if (message.jobStatistics !== undefined) {
      JobStatistics.encode(message.jobStatistics, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobName = JobName.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobConfiguration = JobConfiguration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.jobStatus = JobStatus.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.jobStatistics = JobStatistics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job {
    return {
      jobName: isSet(object.jobName) ? JobName.fromJSON(object.jobName) : undefined,
      jobConfiguration: isSet(object.jobConfiguration) ? JobConfiguration.fromJSON(object.jobConfiguration) : undefined,
      jobStatus: isSet(object.jobStatus) ? JobStatus.fromJSON(object.jobStatus) : undefined,
      jobStatistics: isSet(object.jobStatistics) ? JobStatistics.fromJSON(object.jobStatistics) : undefined,
    };
  },

  toJSON(message: Job): unknown {
    const obj: any = {};
    if (message.jobName !== undefined) {
      obj.jobName = JobName.toJSON(message.jobName);
    }
    if (message.jobConfiguration !== undefined) {
      obj.jobConfiguration = JobConfiguration.toJSON(message.jobConfiguration);
    }
    if (message.jobStatus !== undefined) {
      obj.jobStatus = JobStatus.toJSON(message.jobStatus);
    }
    if (message.jobStatistics !== undefined) {
      obj.jobStatistics = JobStatistics.toJSON(message.jobStatistics);
    }
    return obj;
  },

  create(base?: DeepPartial<Job>): Job {
    return Job.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Job>): Job {
    const message = createBaseJob();
    message.jobName = (object.jobName !== undefined && object.jobName !== null)
      ? JobName.fromPartial(object.jobName)
      : undefined;
    message.jobConfiguration = (object.jobConfiguration !== undefined && object.jobConfiguration !== null)
      ? JobConfiguration.fromPartial(object.jobConfiguration)
      : undefined;
    message.jobStatus = (object.jobStatus !== undefined && object.jobStatus !== null)
      ? JobStatus.fromPartial(object.jobStatus)
      : undefined;
    message.jobStatistics = (object.jobStatistics !== undefined && object.jobStatistics !== null)
      ? JobStatistics.fromPartial(object.jobStatistics)
      : undefined;
    return message;
  },
};

function createBaseJobConfiguration(): JobConfiguration {
  return { query: undefined, load: undefined, extract: undefined, tableCopy: undefined, dryRun: false, labels: {} };
}

export const JobConfiguration: MessageFns<JobConfiguration> = {
  encode(message: JobConfiguration, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== undefined) {
      JobConfiguration_Query.encode(message.query, writer.uint32(42).fork()).join();
    }
    if (message.load !== undefined) {
      JobConfiguration_Load.encode(message.load, writer.uint32(50).fork()).join();
    }
    if (message.extract !== undefined) {
      JobConfiguration_Extract.encode(message.extract, writer.uint32(58).fork()).join();
    }
    if (message.tableCopy !== undefined) {
      JobConfiguration_TableCopy.encode(message.tableCopy, writer.uint32(66).fork()).join();
    }
    if (message.dryRun !== false) {
      writer.uint32(72).bool(message.dryRun);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      JobConfiguration_LabelsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobConfiguration {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobConfiguration();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.query = JobConfiguration_Query.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.load = JobConfiguration_Load.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.extract = JobConfiguration_Extract.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.tableCopy = JobConfiguration_TableCopy.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.dryRun = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = JobConfiguration_LabelsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.labels[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobConfiguration {
    return {
      query: isSet(object.query) ? JobConfiguration_Query.fromJSON(object.query) : undefined,
      load: isSet(object.load) ? JobConfiguration_Load.fromJSON(object.load) : undefined,
      extract: isSet(object.extract) ? JobConfiguration_Extract.fromJSON(object.extract) : undefined,
      tableCopy: isSet(object.tableCopy) ? JobConfiguration_TableCopy.fromJSON(object.tableCopy) : undefined,
      dryRun: isSet(object.dryRun) ? globalThis.Boolean(object.dryRun) : false,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: JobConfiguration): unknown {
    const obj: any = {};
    if (message.query !== undefined) {
      obj.query = JobConfiguration_Query.toJSON(message.query);
    }
    if (message.load !== undefined) {
      obj.load = JobConfiguration_Load.toJSON(message.load);
    }
    if (message.extract !== undefined) {
      obj.extract = JobConfiguration_Extract.toJSON(message.extract);
    }
    if (message.tableCopy !== undefined) {
      obj.tableCopy = JobConfiguration_TableCopy.toJSON(message.tableCopy);
    }
    if (message.dryRun !== false) {
      obj.dryRun = message.dryRun;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<JobConfiguration>): JobConfiguration {
    return JobConfiguration.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobConfiguration>): JobConfiguration {
    const message = createBaseJobConfiguration();
    message.query = (object.query !== undefined && object.query !== null)
      ? JobConfiguration_Query.fromPartial(object.query)
      : undefined;
    message.load = (object.load !== undefined && object.load !== null)
      ? JobConfiguration_Load.fromPartial(object.load)
      : undefined;
    message.extract = (object.extract !== undefined && object.extract !== null)
      ? JobConfiguration_Extract.fromPartial(object.extract)
      : undefined;
    message.tableCopy = (object.tableCopy !== undefined && object.tableCopy !== null)
      ? JobConfiguration_TableCopy.fromPartial(object.tableCopy)
      : undefined;
    message.dryRun = object.dryRun ?? false;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseJobConfiguration_Query(): JobConfiguration_Query {
  return {
    query: "",
    destinationTable: undefined,
    createDisposition: "",
    writeDisposition: "",
    defaultDataset: undefined,
    tableDefinitions: [],
    queryPriority: "",
    destinationTableEncryption: undefined,
    statementType: "",
  };
}

export const JobConfiguration_Query: MessageFns<JobConfiguration_Query> = {
  encode(message: JobConfiguration_Query, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.destinationTable !== undefined) {
      TableName.encode(message.destinationTable, writer.uint32(18).fork()).join();
    }
    if (message.createDisposition !== "") {
      writer.uint32(26).string(message.createDisposition);
    }
    if (message.writeDisposition !== "") {
      writer.uint32(34).string(message.writeDisposition);
    }
    if (message.defaultDataset !== undefined) {
      DatasetName.encode(message.defaultDataset, writer.uint32(42).fork()).join();
    }
    for (const v of message.tableDefinitions) {
      TableDefinition.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.queryPriority !== "") {
      writer.uint32(58).string(message.queryPriority);
    }
    if (message.destinationTableEncryption !== undefined) {
      EncryptionInfo.encode(message.destinationTableEncryption, writer.uint32(66).fork()).join();
    }
    if (message.statementType !== "") {
      writer.uint32(74).string(message.statementType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobConfiguration_Query {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobConfiguration_Query();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.destinationTable = TableName.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createDisposition = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.writeDisposition = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.defaultDataset = DatasetName.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.tableDefinitions.push(TableDefinition.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.queryPriority = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.destinationTableEncryption = EncryptionInfo.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.statementType = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobConfiguration_Query {
    return {
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      destinationTable: isSet(object.destinationTable) ? TableName.fromJSON(object.destinationTable) : undefined,
      createDisposition: isSet(object.createDisposition) ? globalThis.String(object.createDisposition) : "",
      writeDisposition: isSet(object.writeDisposition) ? globalThis.String(object.writeDisposition) : "",
      defaultDataset: isSet(object.defaultDataset) ? DatasetName.fromJSON(object.defaultDataset) : undefined,
      tableDefinitions: globalThis.Array.isArray(object?.tableDefinitions)
        ? object.tableDefinitions.map((e: any) => TableDefinition.fromJSON(e))
        : [],
      queryPriority: isSet(object.queryPriority) ? globalThis.String(object.queryPriority) : "",
      destinationTableEncryption: isSet(object.destinationTableEncryption)
        ? EncryptionInfo.fromJSON(object.destinationTableEncryption)
        : undefined,
      statementType: isSet(object.statementType) ? globalThis.String(object.statementType) : "",
    };
  },

  toJSON(message: JobConfiguration_Query): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.destinationTable !== undefined) {
      obj.destinationTable = TableName.toJSON(message.destinationTable);
    }
    if (message.createDisposition !== "") {
      obj.createDisposition = message.createDisposition;
    }
    if (message.writeDisposition !== "") {
      obj.writeDisposition = message.writeDisposition;
    }
    if (message.defaultDataset !== undefined) {
      obj.defaultDataset = DatasetName.toJSON(message.defaultDataset);
    }
    if (message.tableDefinitions?.length) {
      obj.tableDefinitions = message.tableDefinitions.map((e) => TableDefinition.toJSON(e));
    }
    if (message.queryPriority !== "") {
      obj.queryPriority = message.queryPriority;
    }
    if (message.destinationTableEncryption !== undefined) {
      obj.destinationTableEncryption = EncryptionInfo.toJSON(message.destinationTableEncryption);
    }
    if (message.statementType !== "") {
      obj.statementType = message.statementType;
    }
    return obj;
  },

  create(base?: DeepPartial<JobConfiguration_Query>): JobConfiguration_Query {
    return JobConfiguration_Query.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobConfiguration_Query>): JobConfiguration_Query {
    const message = createBaseJobConfiguration_Query();
    message.query = object.query ?? "";
    message.destinationTable = (object.destinationTable !== undefined && object.destinationTable !== null)
      ? TableName.fromPartial(object.destinationTable)
      : undefined;
    message.createDisposition = object.createDisposition ?? "";
    message.writeDisposition = object.writeDisposition ?? "";
    message.defaultDataset = (object.defaultDataset !== undefined && object.defaultDataset !== null)
      ? DatasetName.fromPartial(object.defaultDataset)
      : undefined;
    message.tableDefinitions = object.tableDefinitions?.map((e) => TableDefinition.fromPartial(e)) || [];
    message.queryPriority = object.queryPriority ?? "";
    message.destinationTableEncryption =
      (object.destinationTableEncryption !== undefined && object.destinationTableEncryption !== null)
        ? EncryptionInfo.fromPartial(object.destinationTableEncryption)
        : undefined;
    message.statementType = object.statementType ?? "";
    return message;
  },
};

function createBaseJobConfiguration_Load(): JobConfiguration_Load {
  return {
    sourceUris: [],
    schemaJson: "",
    destinationTable: undefined,
    createDisposition: "",
    writeDisposition: "",
    destinationTableEncryption: undefined,
  };
}

export const JobConfiguration_Load: MessageFns<JobConfiguration_Load> = {
  encode(message: JobConfiguration_Load, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sourceUris) {
      writer.uint32(10).string(v!);
    }
    if (message.schemaJson !== "") {
      writer.uint32(50).string(message.schemaJson);
    }
    if (message.destinationTable !== undefined) {
      TableName.encode(message.destinationTable, writer.uint32(26).fork()).join();
    }
    if (message.createDisposition !== "") {
      writer.uint32(34).string(message.createDisposition);
    }
    if (message.writeDisposition !== "") {
      writer.uint32(42).string(message.writeDisposition);
    }
    if (message.destinationTableEncryption !== undefined) {
      EncryptionInfo.encode(message.destinationTableEncryption, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobConfiguration_Load {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobConfiguration_Load();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sourceUris.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.schemaJson = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.destinationTable = TableName.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createDisposition = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.writeDisposition = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.destinationTableEncryption = EncryptionInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobConfiguration_Load {
    return {
      sourceUris: globalThis.Array.isArray(object?.sourceUris)
        ? object.sourceUris.map((e: any) => globalThis.String(e))
        : [],
      schemaJson: isSet(object.schemaJson) ? globalThis.String(object.schemaJson) : "",
      destinationTable: isSet(object.destinationTable) ? TableName.fromJSON(object.destinationTable) : undefined,
      createDisposition: isSet(object.createDisposition) ? globalThis.String(object.createDisposition) : "",
      writeDisposition: isSet(object.writeDisposition) ? globalThis.String(object.writeDisposition) : "",
      destinationTableEncryption: isSet(object.destinationTableEncryption)
        ? EncryptionInfo.fromJSON(object.destinationTableEncryption)
        : undefined,
    };
  },

  toJSON(message: JobConfiguration_Load): unknown {
    const obj: any = {};
    if (message.sourceUris?.length) {
      obj.sourceUris = message.sourceUris;
    }
    if (message.schemaJson !== "") {
      obj.schemaJson = message.schemaJson;
    }
    if (message.destinationTable !== undefined) {
      obj.destinationTable = TableName.toJSON(message.destinationTable);
    }
    if (message.createDisposition !== "") {
      obj.createDisposition = message.createDisposition;
    }
    if (message.writeDisposition !== "") {
      obj.writeDisposition = message.writeDisposition;
    }
    if (message.destinationTableEncryption !== undefined) {
      obj.destinationTableEncryption = EncryptionInfo.toJSON(message.destinationTableEncryption);
    }
    return obj;
  },

  create(base?: DeepPartial<JobConfiguration_Load>): JobConfiguration_Load {
    return JobConfiguration_Load.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobConfiguration_Load>): JobConfiguration_Load {
    const message = createBaseJobConfiguration_Load();
    message.sourceUris = object.sourceUris?.map((e) => e) || [];
    message.schemaJson = object.schemaJson ?? "";
    message.destinationTable = (object.destinationTable !== undefined && object.destinationTable !== null)
      ? TableName.fromPartial(object.destinationTable)
      : undefined;
    message.createDisposition = object.createDisposition ?? "";
    message.writeDisposition = object.writeDisposition ?? "";
    message.destinationTableEncryption =
      (object.destinationTableEncryption !== undefined && object.destinationTableEncryption !== null)
        ? EncryptionInfo.fromPartial(object.destinationTableEncryption)
        : undefined;
    return message;
  },
};

function createBaseJobConfiguration_Extract(): JobConfiguration_Extract {
  return { destinationUris: [], sourceTable: undefined };
}

export const JobConfiguration_Extract: MessageFns<JobConfiguration_Extract> = {
  encode(message: JobConfiguration_Extract, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.destinationUris) {
      writer.uint32(10).string(v!);
    }
    if (message.sourceTable !== undefined) {
      TableName.encode(message.sourceTable, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobConfiguration_Extract {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobConfiguration_Extract();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.destinationUris.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceTable = TableName.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobConfiguration_Extract {
    return {
      destinationUris: globalThis.Array.isArray(object?.destinationUris)
        ? object.destinationUris.map((e: any) => globalThis.String(e))
        : [],
      sourceTable: isSet(object.sourceTable) ? TableName.fromJSON(object.sourceTable) : undefined,
    };
  },

  toJSON(message: JobConfiguration_Extract): unknown {
    const obj: any = {};
    if (message.destinationUris?.length) {
      obj.destinationUris = message.destinationUris;
    }
    if (message.sourceTable !== undefined) {
      obj.sourceTable = TableName.toJSON(message.sourceTable);
    }
    return obj;
  },

  create(base?: DeepPartial<JobConfiguration_Extract>): JobConfiguration_Extract {
    return JobConfiguration_Extract.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobConfiguration_Extract>): JobConfiguration_Extract {
    const message = createBaseJobConfiguration_Extract();
    message.destinationUris = object.destinationUris?.map((e) => e) || [];
    message.sourceTable = (object.sourceTable !== undefined && object.sourceTable !== null)
      ? TableName.fromPartial(object.sourceTable)
      : undefined;
    return message;
  },
};

function createBaseJobConfiguration_TableCopy(): JobConfiguration_TableCopy {
  return {
    sourceTables: [],
    destinationTable: undefined,
    createDisposition: "",
    writeDisposition: "",
    destinationTableEncryption: undefined,
  };
}

export const JobConfiguration_TableCopy: MessageFns<JobConfiguration_TableCopy> = {
  encode(message: JobConfiguration_TableCopy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.sourceTables) {
      TableName.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.destinationTable !== undefined) {
      TableName.encode(message.destinationTable, writer.uint32(18).fork()).join();
    }
    if (message.createDisposition !== "") {
      writer.uint32(26).string(message.createDisposition);
    }
    if (message.writeDisposition !== "") {
      writer.uint32(34).string(message.writeDisposition);
    }
    if (message.destinationTableEncryption !== undefined) {
      EncryptionInfo.encode(message.destinationTableEncryption, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobConfiguration_TableCopy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobConfiguration_TableCopy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sourceTables.push(TableName.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.destinationTable = TableName.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createDisposition = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.writeDisposition = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.destinationTableEncryption = EncryptionInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobConfiguration_TableCopy {
    return {
      sourceTables: globalThis.Array.isArray(object?.sourceTables)
        ? object.sourceTables.map((e: any) => TableName.fromJSON(e))
        : [],
      destinationTable: isSet(object.destinationTable) ? TableName.fromJSON(object.destinationTable) : undefined,
      createDisposition: isSet(object.createDisposition) ? globalThis.String(object.createDisposition) : "",
      writeDisposition: isSet(object.writeDisposition) ? globalThis.String(object.writeDisposition) : "",
      destinationTableEncryption: isSet(object.destinationTableEncryption)
        ? EncryptionInfo.fromJSON(object.destinationTableEncryption)
        : undefined,
    };
  },

  toJSON(message: JobConfiguration_TableCopy): unknown {
    const obj: any = {};
    if (message.sourceTables?.length) {
      obj.sourceTables = message.sourceTables.map((e) => TableName.toJSON(e));
    }
    if (message.destinationTable !== undefined) {
      obj.destinationTable = TableName.toJSON(message.destinationTable);
    }
    if (message.createDisposition !== "") {
      obj.createDisposition = message.createDisposition;
    }
    if (message.writeDisposition !== "") {
      obj.writeDisposition = message.writeDisposition;
    }
    if (message.destinationTableEncryption !== undefined) {
      obj.destinationTableEncryption = EncryptionInfo.toJSON(message.destinationTableEncryption);
    }
    return obj;
  },

  create(base?: DeepPartial<JobConfiguration_TableCopy>): JobConfiguration_TableCopy {
    return JobConfiguration_TableCopy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobConfiguration_TableCopy>): JobConfiguration_TableCopy {
    const message = createBaseJobConfiguration_TableCopy();
    message.sourceTables = object.sourceTables?.map((e) => TableName.fromPartial(e)) || [];
    message.destinationTable = (object.destinationTable !== undefined && object.destinationTable !== null)
      ? TableName.fromPartial(object.destinationTable)
      : undefined;
    message.createDisposition = object.createDisposition ?? "";
    message.writeDisposition = object.writeDisposition ?? "";
    message.destinationTableEncryption =
      (object.destinationTableEncryption !== undefined && object.destinationTableEncryption !== null)
        ? EncryptionInfo.fromPartial(object.destinationTableEncryption)
        : undefined;
    return message;
  },
};

function createBaseJobConfiguration_LabelsEntry(): JobConfiguration_LabelsEntry {
  return { key: "", value: "" };
}

export const JobConfiguration_LabelsEntry: MessageFns<JobConfiguration_LabelsEntry> = {
  encode(message: JobConfiguration_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobConfiguration_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobConfiguration_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobConfiguration_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: JobConfiguration_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<JobConfiguration_LabelsEntry>): JobConfiguration_LabelsEntry {
    return JobConfiguration_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobConfiguration_LabelsEntry>): JobConfiguration_LabelsEntry {
    const message = createBaseJobConfiguration_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTableDefinition(): TableDefinition {
  return { name: "", sourceUris: [] };
}

export const TableDefinition: MessageFns<TableDefinition> = {
  encode(message: TableDefinition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.sourceUris) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableDefinition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableDefinition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceUris.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableDefinition {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sourceUris: globalThis.Array.isArray(object?.sourceUris)
        ? object.sourceUris.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: TableDefinition): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sourceUris?.length) {
      obj.sourceUris = message.sourceUris;
    }
    return obj;
  },

  create(base?: DeepPartial<TableDefinition>): TableDefinition {
    return TableDefinition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableDefinition>): TableDefinition {
    const message = createBaseTableDefinition();
    message.name = object.name ?? "";
    message.sourceUris = object.sourceUris?.map((e) => e) || [];
    return message;
  },
};

function createBaseJobStatus(): JobStatus {
  return { state: "", error: undefined, additionalErrors: [] };
}

export const JobStatus: MessageFns<JobStatus> = {
  encode(message: JobStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== "") {
      writer.uint32(10).string(message.state);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(18).fork()).join();
    }
    for (const v of message.additionalErrors) {
      Status.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.state = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.additionalErrors.push(Status.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatus {
    return {
      state: isSet(object.state) ? globalThis.String(object.state) : "",
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      additionalErrors: globalThis.Array.isArray(object?.additionalErrors)
        ? object.additionalErrors.map((e: any) => Status.fromJSON(e))
        : [],
    };
  },

  toJSON(message: JobStatus): unknown {
    const obj: any = {};
    if (message.state !== "") {
      obj.state = message.state;
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.additionalErrors?.length) {
      obj.additionalErrors = message.additionalErrors.map((e) => Status.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<JobStatus>): JobStatus {
    return JobStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobStatus>): JobStatus {
    const message = createBaseJobStatus();
    message.state = object.state ?? "";
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.additionalErrors = object.additionalErrors?.map((e) => Status.fromPartial(e)) || [];
    return message;
  },
};

function createBaseJobStatistics(): JobStatistics {
  return {
    createTime: undefined,
    startTime: undefined,
    endTime: undefined,
    totalProcessedBytes: Long.ZERO,
    totalBilledBytes: Long.ZERO,
    billingTier: 0,
    totalSlotMs: Long.ZERO,
    reservationUsage: [],
    reservation: "",
    referencedTables: [],
    totalTablesProcessed: 0,
    referencedViews: [],
    totalViewsProcessed: 0,
    queryOutputRowCount: Long.ZERO,
    totalLoadOutputBytes: Long.ZERO,
  };
}

export const JobStatistics: MessageFns<JobStatistics> = {
  encode(message: JobStatistics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    if (!message.totalProcessedBytes.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.totalProcessedBytes.toString());
    }
    if (!message.totalBilledBytes.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.totalBilledBytes.toString());
    }
    if (message.billingTier !== 0) {
      writer.uint32(56).int32(message.billingTier);
    }
    if (!message.totalSlotMs.equals(Long.ZERO)) {
      writer.uint32(64).int64(message.totalSlotMs.toString());
    }
    for (const v of message.reservationUsage) {
      JobStatistics_ReservationResourceUsage.encode(v!, writer.uint32(114).fork()).join();
    }
    if (message.reservation !== "") {
      writer.uint32(130).string(message.reservation);
    }
    for (const v of message.referencedTables) {
      TableName.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.totalTablesProcessed !== 0) {
      writer.uint32(80).int32(message.totalTablesProcessed);
    }
    for (const v of message.referencedViews) {
      TableName.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.totalViewsProcessed !== 0) {
      writer.uint32(96).int32(message.totalViewsProcessed);
    }
    if (!message.queryOutputRowCount.equals(Long.ZERO)) {
      writer.uint32(120).int64(message.queryOutputRowCount.toString());
    }
    if (!message.totalLoadOutputBytes.equals(Long.ZERO)) {
      writer.uint32(104).int64(message.totalLoadOutputBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatistics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatistics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.totalProcessedBytes = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.totalBilledBytes = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.billingTier = reader.int32();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.totalSlotMs = Long.fromString(reader.int64().toString());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.reservationUsage.push(JobStatistics_ReservationResourceUsage.decode(reader, reader.uint32()));
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.reservation = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.referencedTables.push(TableName.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.totalTablesProcessed = reader.int32();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.referencedViews.push(TableName.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.totalViewsProcessed = reader.int32();
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.queryOutputRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.totalLoadOutputBytes = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatistics {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      totalProcessedBytes: isSet(object.totalProcessedBytes) ? Long.fromValue(object.totalProcessedBytes) : Long.ZERO,
      totalBilledBytes: isSet(object.totalBilledBytes) ? Long.fromValue(object.totalBilledBytes) : Long.ZERO,
      billingTier: isSet(object.billingTier) ? globalThis.Number(object.billingTier) : 0,
      totalSlotMs: isSet(object.totalSlotMs) ? Long.fromValue(object.totalSlotMs) : Long.ZERO,
      reservationUsage: globalThis.Array.isArray(object?.reservationUsage)
        ? object.reservationUsage.map((e: any) => JobStatistics_ReservationResourceUsage.fromJSON(e))
        : [],
      reservation: isSet(object.reservation) ? globalThis.String(object.reservation) : "",
      referencedTables: globalThis.Array.isArray(object?.referencedTables)
        ? object.referencedTables.map((e: any) => TableName.fromJSON(e))
        : [],
      totalTablesProcessed: isSet(object.totalTablesProcessed) ? globalThis.Number(object.totalTablesProcessed) : 0,
      referencedViews: globalThis.Array.isArray(object?.referencedViews)
        ? object.referencedViews.map((e: any) => TableName.fromJSON(e))
        : [],
      totalViewsProcessed: isSet(object.totalViewsProcessed) ? globalThis.Number(object.totalViewsProcessed) : 0,
      queryOutputRowCount: isSet(object.queryOutputRowCount) ? Long.fromValue(object.queryOutputRowCount) : Long.ZERO,
      totalLoadOutputBytes: isSet(object.totalLoadOutputBytes)
        ? Long.fromValue(object.totalLoadOutputBytes)
        : Long.ZERO,
    };
  },

  toJSON(message: JobStatistics): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (!message.totalProcessedBytes.equals(Long.ZERO)) {
      obj.totalProcessedBytes = (message.totalProcessedBytes || Long.ZERO).toString();
    }
    if (!message.totalBilledBytes.equals(Long.ZERO)) {
      obj.totalBilledBytes = (message.totalBilledBytes || Long.ZERO).toString();
    }
    if (message.billingTier !== 0) {
      obj.billingTier = Math.round(message.billingTier);
    }
    if (!message.totalSlotMs.equals(Long.ZERO)) {
      obj.totalSlotMs = (message.totalSlotMs || Long.ZERO).toString();
    }
    if (message.reservationUsage?.length) {
      obj.reservationUsage = message.reservationUsage.map((e) => JobStatistics_ReservationResourceUsage.toJSON(e));
    }
    if (message.reservation !== "") {
      obj.reservation = message.reservation;
    }
    if (message.referencedTables?.length) {
      obj.referencedTables = message.referencedTables.map((e) => TableName.toJSON(e));
    }
    if (message.totalTablesProcessed !== 0) {
      obj.totalTablesProcessed = Math.round(message.totalTablesProcessed);
    }
    if (message.referencedViews?.length) {
      obj.referencedViews = message.referencedViews.map((e) => TableName.toJSON(e));
    }
    if (message.totalViewsProcessed !== 0) {
      obj.totalViewsProcessed = Math.round(message.totalViewsProcessed);
    }
    if (!message.queryOutputRowCount.equals(Long.ZERO)) {
      obj.queryOutputRowCount = (message.queryOutputRowCount || Long.ZERO).toString();
    }
    if (!message.totalLoadOutputBytes.equals(Long.ZERO)) {
      obj.totalLoadOutputBytes = (message.totalLoadOutputBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<JobStatistics>): JobStatistics {
    return JobStatistics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobStatistics>): JobStatistics {
    const message = createBaseJobStatistics();
    message.createTime = object.createTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.totalProcessedBytes = (object.totalProcessedBytes !== undefined && object.totalProcessedBytes !== null)
      ? Long.fromValue(object.totalProcessedBytes)
      : Long.ZERO;
    message.totalBilledBytes = (object.totalBilledBytes !== undefined && object.totalBilledBytes !== null)
      ? Long.fromValue(object.totalBilledBytes)
      : Long.ZERO;
    message.billingTier = object.billingTier ?? 0;
    message.totalSlotMs = (object.totalSlotMs !== undefined && object.totalSlotMs !== null)
      ? Long.fromValue(object.totalSlotMs)
      : Long.ZERO;
    message.reservationUsage =
      object.reservationUsage?.map((e) => JobStatistics_ReservationResourceUsage.fromPartial(e)) || [];
    message.reservation = object.reservation ?? "";
    message.referencedTables = object.referencedTables?.map((e) => TableName.fromPartial(e)) || [];
    message.totalTablesProcessed = object.totalTablesProcessed ?? 0;
    message.referencedViews = object.referencedViews?.map((e) => TableName.fromPartial(e)) || [];
    message.totalViewsProcessed = object.totalViewsProcessed ?? 0;
    message.queryOutputRowCount = (object.queryOutputRowCount !== undefined && object.queryOutputRowCount !== null)
      ? Long.fromValue(object.queryOutputRowCount)
      : Long.ZERO;
    message.totalLoadOutputBytes = (object.totalLoadOutputBytes !== undefined && object.totalLoadOutputBytes !== null)
      ? Long.fromValue(object.totalLoadOutputBytes)
      : Long.ZERO;
    return message;
  },
};

function createBaseJobStatistics_ReservationResourceUsage(): JobStatistics_ReservationResourceUsage {
  return { name: "", slotMs: Long.ZERO };
}

export const JobStatistics_ReservationResourceUsage: MessageFns<JobStatistics_ReservationResourceUsage> = {
  encode(message: JobStatistics_ReservationResourceUsage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (!message.slotMs.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.slotMs.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatistics_ReservationResourceUsage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatistics_ReservationResourceUsage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.slotMs = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatistics_ReservationResourceUsage {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      slotMs: isSet(object.slotMs) ? Long.fromValue(object.slotMs) : Long.ZERO,
    };
  },

  toJSON(message: JobStatistics_ReservationResourceUsage): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (!message.slotMs.equals(Long.ZERO)) {
      obj.slotMs = (message.slotMs || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<JobStatistics_ReservationResourceUsage>): JobStatistics_ReservationResourceUsage {
    return JobStatistics_ReservationResourceUsage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobStatistics_ReservationResourceUsage>): JobStatistics_ReservationResourceUsage {
    const message = createBaseJobStatistics_ReservationResourceUsage();
    message.name = object.name ?? "";
    message.slotMs = (object.slotMs !== undefined && object.slotMs !== null)
      ? Long.fromValue(object.slotMs)
      : Long.ZERO;
    return message;
  },
};

function createBaseDatasetName(): DatasetName {
  return { projectId: "", datasetId: "" };
}

export const DatasetName: MessageFns<DatasetName> = {
  encode(message: DatasetName, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetName {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetName();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetName {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
    };
  },

  toJSON(message: DatasetName): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetName>): DatasetName {
    return DatasetName.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetName>): DatasetName {
    const message = createBaseDatasetName();
    message.projectId = object.projectId ?? "";
    message.datasetId = object.datasetId ?? "";
    return message;
  },
};

function createBaseTableName(): TableName {
  return { projectId: "", datasetId: "", tableId: "" };
}

export const TableName: MessageFns<TableName> = {
  encode(message: TableName, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.datasetId !== "") {
      writer.uint32(18).string(message.datasetId);
    }
    if (message.tableId !== "") {
      writer.uint32(26).string(message.tableId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TableName {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTableName();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tableId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TableName {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      tableId: isSet(object.tableId) ? globalThis.String(object.tableId) : "",
    };
  },

  toJSON(message: TableName): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.tableId !== "") {
      obj.tableId = message.tableId;
    }
    return obj;
  },

  create(base?: DeepPartial<TableName>): TableName {
    return TableName.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TableName>): TableName {
    const message = createBaseTableName();
    message.projectId = object.projectId ?? "";
    message.datasetId = object.datasetId ?? "";
    message.tableId = object.tableId ?? "";
    return message;
  },
};

function createBaseJobName(): JobName {
  return { projectId: "", jobId: "", location: "" };
}

export const JobName: MessageFns<JobName> = {
  encode(message: JobName, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.location !== "") {
      writer.uint32(26).string(message.location);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobName {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobName();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.location = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobName {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      location: isSet(object.location) ? globalThis.String(object.location) : "",
    };
  },

  toJSON(message: JobName): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    return obj;
  },

  create(base?: DeepPartial<JobName>): JobName {
    return JobName.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobName>): JobName {
    const message = createBaseJobName();
    message.projectId = object.projectId ?? "";
    message.jobId = object.jobId ?? "";
    message.location = object.location ?? "";
    return message;
  },
};

function createBaseEncryptionInfo(): EncryptionInfo {
  return { kmsKeyName: "" };
}

export const EncryptionInfo: MessageFns<EncryptionInfo> = {
  encode(message: EncryptionInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKeyName !== "") {
      writer.uint32(10).string(message.kmsKeyName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EncryptionInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEncryptionInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EncryptionInfo {
    return { kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "" };
  },

  toJSON(message: EncryptionInfo): unknown {
    const obj: any = {};
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    return obj;
  },

  create(base?: DeepPartial<EncryptionInfo>): EncryptionInfo {
    return EncryptionInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EncryptionInfo>): EncryptionInfo {
    const message = createBaseEncryptionInfo();
    message.kmsKeyName = object.kmsKeyName ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
