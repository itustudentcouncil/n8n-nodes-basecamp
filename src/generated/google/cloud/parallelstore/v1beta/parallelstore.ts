// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/parallelstore/v1beta/parallelstore.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.parallelstore.v1beta";

/** Type of transfer that occurred. */
export enum TransferType {
  /** TRANSFER_TYPE_UNSPECIFIED - Zero is an illegal value. */
  TRANSFER_TYPE_UNSPECIFIED = 0,
  /** IMPORT - Imports to Parallelstore. */
  IMPORT = 1,
  /** EXPORT - Exports from Parallelstore. */
  EXPORT = 2,
  UNRECOGNIZED = -1,
}

export function transferTypeFromJSON(object: any): TransferType {
  switch (object) {
    case 0:
    case "TRANSFER_TYPE_UNSPECIFIED":
      return TransferType.TRANSFER_TYPE_UNSPECIFIED;
    case 1:
    case "IMPORT":
      return TransferType.IMPORT;
    case 2:
    case "EXPORT":
      return TransferType.EXPORT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TransferType.UNRECOGNIZED;
  }
}

export function transferTypeToJSON(object: TransferType): string {
  switch (object) {
    case TransferType.TRANSFER_TYPE_UNSPECIFIED:
      return "TRANSFER_TYPE_UNSPECIFIED";
    case TransferType.IMPORT:
      return "IMPORT";
    case TransferType.EXPORT:
      return "EXPORT";
    case TransferType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the striping options for files. */
export enum FileStripeLevel {
  /** FILE_STRIPE_LEVEL_UNSPECIFIED - If not set, FileStripeLevel will default to FILE_STRIPE_LEVEL_BALANCED */
  FILE_STRIPE_LEVEL_UNSPECIFIED = 0,
  /** FILE_STRIPE_LEVEL_MIN - Minimum file striping */
  FILE_STRIPE_LEVEL_MIN = 1,
  /** FILE_STRIPE_LEVEL_BALANCED - Medium file striping */
  FILE_STRIPE_LEVEL_BALANCED = 2,
  /** FILE_STRIPE_LEVEL_MAX - Maximum file striping */
  FILE_STRIPE_LEVEL_MAX = 3,
  UNRECOGNIZED = -1,
}

export function fileStripeLevelFromJSON(object: any): FileStripeLevel {
  switch (object) {
    case 0:
    case "FILE_STRIPE_LEVEL_UNSPECIFIED":
      return FileStripeLevel.FILE_STRIPE_LEVEL_UNSPECIFIED;
    case 1:
    case "FILE_STRIPE_LEVEL_MIN":
      return FileStripeLevel.FILE_STRIPE_LEVEL_MIN;
    case 2:
    case "FILE_STRIPE_LEVEL_BALANCED":
      return FileStripeLevel.FILE_STRIPE_LEVEL_BALANCED;
    case 3:
    case "FILE_STRIPE_LEVEL_MAX":
      return FileStripeLevel.FILE_STRIPE_LEVEL_MAX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return FileStripeLevel.UNRECOGNIZED;
  }
}

export function fileStripeLevelToJSON(object: FileStripeLevel): string {
  switch (object) {
    case FileStripeLevel.FILE_STRIPE_LEVEL_UNSPECIFIED:
      return "FILE_STRIPE_LEVEL_UNSPECIFIED";
    case FileStripeLevel.FILE_STRIPE_LEVEL_MIN:
      return "FILE_STRIPE_LEVEL_MIN";
    case FileStripeLevel.FILE_STRIPE_LEVEL_BALANCED:
      return "FILE_STRIPE_LEVEL_BALANCED";
    case FileStripeLevel.FILE_STRIPE_LEVEL_MAX:
      return "FILE_STRIPE_LEVEL_MAX";
    case FileStripeLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the striping options for directories. */
export enum DirectoryStripeLevel {
  /** DIRECTORY_STRIPE_LEVEL_UNSPECIFIED - If not set, DirectoryStripeLevel will default to DIRECTORY_STRIPE_LEVEL_MAX */
  DIRECTORY_STRIPE_LEVEL_UNSPECIFIED = 0,
  /** DIRECTORY_STRIPE_LEVEL_MIN - Minimum directory striping */
  DIRECTORY_STRIPE_LEVEL_MIN = 1,
  /** DIRECTORY_STRIPE_LEVEL_BALANCED - Medium directory striping */
  DIRECTORY_STRIPE_LEVEL_BALANCED = 2,
  /** DIRECTORY_STRIPE_LEVEL_MAX - Maximum directory striping */
  DIRECTORY_STRIPE_LEVEL_MAX = 3,
  UNRECOGNIZED = -1,
}

export function directoryStripeLevelFromJSON(object: any): DirectoryStripeLevel {
  switch (object) {
    case 0:
    case "DIRECTORY_STRIPE_LEVEL_UNSPECIFIED":
      return DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_UNSPECIFIED;
    case 1:
    case "DIRECTORY_STRIPE_LEVEL_MIN":
      return DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_MIN;
    case 2:
    case "DIRECTORY_STRIPE_LEVEL_BALANCED":
      return DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_BALANCED;
    case 3:
    case "DIRECTORY_STRIPE_LEVEL_MAX":
      return DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_MAX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DirectoryStripeLevel.UNRECOGNIZED;
  }
}

export function directoryStripeLevelToJSON(object: DirectoryStripeLevel): string {
  switch (object) {
    case DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_UNSPECIFIED:
      return "DIRECTORY_STRIPE_LEVEL_UNSPECIFIED";
    case DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_MIN:
      return "DIRECTORY_STRIPE_LEVEL_MIN";
    case DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_BALANCED:
      return "DIRECTORY_STRIPE_LEVEL_BALANCED";
    case DirectoryStripeLevel.DIRECTORY_STRIPE_LEVEL_MAX:
      return "DIRECTORY_STRIPE_LEVEL_MAX";
    case DirectoryStripeLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A Parallelstore instance. */
export interface Instance {
  /**
   * Identifier. The resource name of the instance, in the format
   * `projects/{project}/locations/{location}/instances/{instance_id}`.
   */
  name: string;
  /** Optional. The description of the instance. 2048 characters or less. */
  description: string;
  /** Output only. The instance state. */
  state: Instance_State;
  /** Output only. The time when the instance was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time when the instance was updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Optional. Cloud Labels are a flexible and lightweight mechanism for
   * organizing cloud resources into groups that reflect a customer's
   * organizational needs and deployment strategies. See
   * https://cloud.google.com/resource-manager/docs/labels-overview for details.
   */
  labels: { [key: string]: string };
  /**
   * Required. Immutable. The instance's storage capacity in Gibibytes (GiB).
   * Allowed values are between 12000 and 100000, in multiples of 4000; e.g.,
   * 12000, 16000, 20000, ...
   */
  capacityGib: Long;
  /** Output only. The version of DAOS software running in the instance. */
  daosVersion: string;
  /** Output only. A list of IPv4 addresses used for client side configuration. */
  accessPoints: string[];
  /**
   * Optional. Immutable. The name of the Compute Engine
   * [VPC network](https://cloud.google.com/vpc/docs/vpc) to which the
   * instance is connected.
   */
  network: string;
  /**
   * Optional. Immutable. The ID of the IP address range being used by the
   * instance's VPC network. See [Configure a VPC
   * network](https://cloud.google.com/parallelstore/docs/vpc#create_and_configure_the_vpc).
   * If no ID is provided, all ranges are considered.
   */
  reservedIpRange: string;
  /**
   * Output only. Immutable. The ID of the IP address range being used by the
   * instance's VPC network. This field is populated by the service and contains
   * the value currently used by the service.
   */
  effectiveReservedIpRange: string;
  /**
   * Optional. Stripe level for files. Allowed values are:
   *
   * * `FILE_STRIPE_LEVEL_MIN`: offers the best performance for small size
   *   files.
   * * `FILE_STRIPE_LEVEL_BALANCED`: balances performance for workloads
   *   involving a mix of small and large files.
   * * `FILE_STRIPE_LEVEL_MAX`: higher throughput performance for larger files.
   */
  fileStripeLevel: FileStripeLevel;
  /**
   * Optional. Stripe level for directories. Allowed values are:
   *
   * * `DIRECTORY_STRIPE_LEVEL_MIN`: recommended when directories contain a
   *   small number of files.
   * * `DIRECTORY_STRIPE_LEVEL_BALANCED`: balances performance for workloads
   *   involving a mix of small and large directories.
   * * `DIRECTORY_STRIPE_LEVEL_MAX`: recommended for directories with a large
   *   number of files.
   */
  directoryStripeLevel: DirectoryStripeLevel;
}

/** The possible states of a Parallelstore instance. */
export enum Instance_State {
  /** STATE_UNSPECIFIED - Not set. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The instance is being created. */
  CREATING = 1,
  /** ACTIVE - The instance is available for use. */
  ACTIVE = 2,
  /** DELETING - The instance is being deleted. */
  DELETING = 3,
  /** FAILED - The instance is not usable. */
  FAILED = 4,
  /** UPGRADING - The instance is being upgraded. */
  UPGRADING = 5,
  UNRECOGNIZED = -1,
}

export function instance_StateFromJSON(object: any): Instance_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Instance_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Instance_State.CREATING;
    case 2:
    case "ACTIVE":
      return Instance_State.ACTIVE;
    case 3:
    case "DELETING":
      return Instance_State.DELETING;
    case 4:
    case "FAILED":
      return Instance_State.FAILED;
    case 5:
    case "UPGRADING":
      return Instance_State.UPGRADING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Instance_State.UNRECOGNIZED;
  }
}

export function instance_StateToJSON(object: Instance_State): string {
  switch (object) {
    case Instance_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Instance_State.CREATING:
      return "CREATING";
    case Instance_State.ACTIVE:
      return "ACTIVE";
    case Instance_State.DELETING:
      return "DELETING";
    case Instance_State.FAILED:
      return "FAILED";
    case Instance_State.UPGRADING:
      return "UPGRADING";
    case Instance_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Instance_LabelsEntry {
  key: string;
  value: string;
}

/** List instances request. */
export interface ListInstancesRequest {
  /**
   * Required. The project and location for which to retrieve instance
   * information, in the format `projects/{project_id}/locations/{location}`.
   *
   * To retrieve instance information for all locations, use "-" as the value of
   * `{location}`.
   */
  parent: string;
  /**
   * Optional. Requested page size. Server may return fewer items than
   * requested. If unspecified, the server will pick an appropriate default.
   */
  pageSize: number;
  /** Optional. A token identifying a page of results the server should return. */
  pageToken: string;
  /** Optional. Filtering results. */
  filter: string;
  /** Optional. Hint for how to order the results. */
  orderBy: string;
}

/**
 * Response from
 * [ListInstances][google.cloud.parallelstore.v1beta.Parallelstore.ListInstances].
 */
export interface ListInstancesResponse {
  /** The list of Parallelstore instances. */
  instances: Instance[];
  /** A token identifying a page of results the server should return. */
  nextPageToken: string;
  /** Locations that could not be reached. */
  unreachable: string[];
}

/** Get an instance's details. */
export interface GetInstanceRequest {
  /**
   * Required. The instance resource name, in the format
   * `projects/{project_id}/locations/{location}/instances/{instance_id}`.
   */
  name: string;
}

/** Create a new Parallelstore instance. */
export interface CreateInstanceRequest {
  /**
   * Required. The instance's project and location, in the format
   * `projects/{project}/locations/{location}`.
   * Locations map to Google Cloud zones; for example, `us-west1-b`.
   */
  parent: string;
  /**
   * Required. The name of the Parallelstore instance.
   *
   * * Must contain only lowercase letters, numbers, and hyphens.
   * * Must start with a letter.
   * * Must be between 1-63 characters.
   * * Must end with a number or a letter.
   * * Must be unique within the customer project / location
   */
  instanceId: string;
  /** Required. The instance to create. */
  instance:
    | Instance
    | undefined;
  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   */
  requestId: string;
}

/** Update an instance. */
export interface UpdateInstanceRequest {
  /**
   * Required. Mask of fields to update. Field mask is used to specify the
   * fields to be overwritten in the Instance resource by the update. At least
   * one path must be supplied in this field. The fields specified in the
   * update_mask are relative to the resource, not the full request.
   */
  updateMask:
    | string[]
    | undefined;
  /** Required. The instance to update. */
  instance:
    | Instance
    | undefined;
  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   */
  requestId: string;
}

/** Delete an instance. */
export interface DeleteInstanceRequest {
  /** Required. Name of the resource */
  name: string;
  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   */
  requestId: string;
}

/** Long-running operation metadata. */
export interface OperationMetadata {
  /** Output only. The time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time the operation finished running. */
  endTime:
    | Date
    | undefined;
  /** Output only. Server-defined resource path for the target of the operation. */
  target: string;
  /** Output only. Name of the verb executed by the operation. */
  verb: string;
  /** Output only. Human-readable status of the operation, if any. */
  statusMessage: string;
  /**
   * Output only. Identifies whether the user has requested cancellation
   * of the operation. Operations that have been cancelled successfully
   * have [Operation.error][] value with a
   * [google.rpc.Status.code][google.rpc.Status.code] of 1, corresponding to
   * `Code.CANCELLED`.
   */
  requestedCancellation: boolean;
  /** Output only. API version used to start the operation. */
  apiVersion: string;
}

/** Cloud Storage as the source of a data transfer. */
export interface SourceGcsBucket {
  /**
   * Required. URI to a Cloud Storage bucket in the format:
   * `gs://<bucket_name>/<path_inside_bucket>`. The path inside the bucket is
   * optional.
   */
  uri: string;
}

/** Cloud Storage as the destination of a data transfer. */
export interface DestinationGcsBucket {
  /**
   * Required. URI to a Cloud Storage bucket in the format:
   * `gs://<bucket_name>/<path_inside_bucket>`. The path inside the bucket is
   * optional.
   */
  uri: string;
}

/** Parallelstore as the source of a data transfer. */
export interface SourceParallelstore {
  /**
   * Optional. Root directory path to the Paralellstore filesystem, starting
   * with `/`. Defaults to `/` if unset.
   */
  path: string;
}

/** Parallelstore as the destination of a data transfer. */
export interface DestinationParallelstore {
  /**
   * Optional. Root directory path to the Paralellstore filesystem, starting
   * with `/`. Defaults to `/` if unset.
   */
  path: string;
}

/** Import data from Cloud Storage into a Parallelstore instance. */
export interface ImportDataRequest {
  /** The Cloud Storage source bucket and, optionally, path inside the bucket. */
  sourceGcsBucket?:
    | SourceGcsBucket
    | undefined;
  /** Parallelstore destination. */
  destinationParallelstore?:
    | DestinationParallelstore
    | undefined;
  /** Required. Name of the resource. */
  name: string;
  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   */
  requestId: string;
  /**
   * Optional. User-specified service account credentials to be used when
   * performing the transfer.
   *
   * Use one of the following formats:
   *
   * * {EMAIL_ADDRESS_OR_UNIQUE_ID}
   * * `projects/{PROJECT_ID_OR_NUMBER}/serviceAccounts/{EMAIL_ADDRESS_OR_UNIQUE_ID}`
   * * `projects/-/serviceAccounts/{EMAIL_ADDRESS_OR_UNIQUE_ID}
   *
   * If unspecified, the Parallelstore service agent is used:
   * `service-<PROJECT_NUMBER>@gcp-sa-parallelstore.iam.gserviceaccount.com`
   */
  serviceAccount: string;
}

/** Export data from Parallelstore to Cloud Storage. */
export interface ExportDataRequest {
  /** Parallelstore source. */
  sourceParallelstore?:
    | SourceParallelstore
    | undefined;
  /** Cloud Storage destination. */
  destinationGcsBucket?:
    | DestinationGcsBucket
    | undefined;
  /** Required. Name of the resource. */
  name: string;
  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   */
  requestId: string;
  /**
   * Optional. User-specified Service Account (SA) credentials to be used when
   * performing the transfer.
   * Use one of the following formats:
   *
   * * {EMAIL_ADDRESS_OR_UNIQUE_ID}
   * * `projects/{PROJECT_ID_OR_NUMBER}/serviceAccounts/{EMAIL_ADDRESS_OR_UNIQUE_ID}`
   * * `projects/-/serviceAccounts/{EMAIL_ADDRESS_OR_UNIQUE_ID}
   *
   * If unspecified, the Parallelstore service agent is used:
   * `service-<PROJECT_NUMBER>@gcp-sa-parallelstore.iam.gserviceaccount.com`
   */
  serviceAccount: string;
}

/** The response to a request to import data to Parallelstore. */
export interface ImportDataResponse {
}

/** Metadata related to the data import operation. */
export interface ImportDataMetadata {
  /** Data transfer operation metadata. */
  operationMetadata:
    | TransferOperationMetadata
    | undefined;
  /** Output only. The time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time the operation finished running. */
  endTime:
    | Date
    | undefined;
  /** Output only. Server-defined resource path for the target of the operation. */
  target: string;
  /** Output only. Name of the verb executed by the operation. */
  verb: string;
  /** Output only. Human-readable status of the operation, if any. */
  statusMessage: string;
  /**
   * Output only. Identifies whether the user has requested cancellation
   * of the operation. Operations that have successfully been cancelled
   * have [Operation.error][] value with a
   * [google.rpc.Status.code][google.rpc.Status.code] of 1, corresponding to
   * `Code.CANCELLED`.
   */
  requestedCancellation: boolean;
  /** Output only. API version used to start the operation. */
  apiVersion: string;
}

/** The response to a request to export data from Parallelstore. */
export interface ExportDataResponse {
}

/** Metadata related to the data export operation. */
export interface ExportDataMetadata {
  /** Data transfer operation metadata. */
  operationMetadata:
    | TransferOperationMetadata
    | undefined;
  /** Output only. The time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time the operation finished running. */
  endTime:
    | Date
    | undefined;
  /** Output only. Server-defined resource path for the target of the operation. */
  target: string;
  /** Output only. Name of the verb executed by the operation. */
  verb: string;
  /** Output only. Human-readable status of the operation, if any. */
  statusMessage: string;
  /**
   * Output only. Identifies whether the user has requested cancellation
   * of the operation. Operations that have successfully been cancelled
   * have [Operation.error][] value with a
   * [google.rpc.Status.code][google.rpc.Status.code] of 1, corresponding to
   * `Code.CANCELLED`.
   */
  requestedCancellation: boolean;
  /** Output only. API version used to start the operation. */
  apiVersion: string;
}

/** Long-running operation metadata related to a data transfer. */
export interface TransferOperationMetadata {
  /** Output only. Parallelstore source. */
  sourceParallelstore?:
    | SourceParallelstore
    | undefined;
  /** Output only. Cloud Storage source. */
  sourceGcsBucket?:
    | SourceGcsBucket
    | undefined;
  /** Output only. Cloud Storage destination. */
  destinationGcsBucket?:
    | DestinationGcsBucket
    | undefined;
  /** Output only. Parallelstore destination. */
  destinationParallelstore?:
    | DestinationParallelstore
    | undefined;
  /** Output only. The progress of the transfer operation. */
  counters:
    | TransferCounters
    | undefined;
  /** Output only. The type of transfer occurring. */
  transferType: TransferType;
}

/** A collection of counters that report the progress of a transfer operation. */
export interface TransferCounters {
  /**
   * Objects found in the data source that are scheduled to be transferred,
   * excluding any that are filtered based on object conditions or skipped due
   * to sync.
   */
  objectsFound: Long;
  /**
   * Bytes found in the data source that are scheduled to be transferred,
   * excluding any that are filtered based on object conditions or skipped due
   * to sync.
   */
  bytesFound: Long;
  /**
   * Objects in the data source that are not transferred because they already
   * exist in the data destination.
   */
  objectsSkipped: Long;
  /**
   * Bytes in the data source that are not transferred because they already
   * exist in the data destination.
   */
  bytesSkipped: Long;
  /** Objects that are copied to the data destination. */
  objectsCopied: Long;
  /** Bytes that are copied to the data destination. */
  bytesCopied: Long;
}

function createBaseInstance(): Instance {
  return {
    name: "",
    description: "",
    state: 0,
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    capacityGib: Long.ZERO,
    daosVersion: "",
    accessPoints: [],
    network: "",
    reservedIpRange: "",
    effectiveReservedIpRange: "",
    fileStripeLevel: 0,
    directoryStripeLevel: 0,
  };
}

export const Instance: MessageFns<Instance> = {
  encode(message: Instance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Instance_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (!message.capacityGib.equals(Long.ZERO)) {
      writer.uint32(64).int64(message.capacityGib.toString());
    }
    if (message.daosVersion !== "") {
      writer.uint32(74).string(message.daosVersion);
    }
    for (const v of message.accessPoints) {
      writer.uint32(82).string(v!);
    }
    if (message.network !== "") {
      writer.uint32(90).string(message.network);
    }
    if (message.reservedIpRange !== "") {
      writer.uint32(98).string(message.reservedIpRange);
    }
    if (message.effectiveReservedIpRange !== "") {
      writer.uint32(114).string(message.effectiveReservedIpRange);
    }
    if (message.fileStripeLevel !== 0) {
      writer.uint32(120).int32(message.fileStripeLevel);
    }
    if (message.directoryStripeLevel !== 0) {
      writer.uint32(128).int32(message.directoryStripeLevel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Instance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = Instance_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.capacityGib = Long.fromString(reader.int64().toString());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.daosVersion = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.accessPoints.push(reader.string());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.network = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.reservedIpRange = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.effectiveReservedIpRange = reader.string();
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.fileStripeLevel = reader.int32() as any;
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.directoryStripeLevel = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Instance {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? instance_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      capacityGib: isSet(object.capacityGib) ? Long.fromValue(object.capacityGib) : Long.ZERO,
      daosVersion: isSet(object.daosVersion) ? globalThis.String(object.daosVersion) : "",
      accessPoints: globalThis.Array.isArray(object?.accessPoints)
        ? object.accessPoints.map((e: any) => globalThis.String(e))
        : [],
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      reservedIpRange: isSet(object.reservedIpRange) ? globalThis.String(object.reservedIpRange) : "",
      effectiveReservedIpRange: isSet(object.effectiveReservedIpRange)
        ? globalThis.String(object.effectiveReservedIpRange)
        : "",
      fileStripeLevel: isSet(object.fileStripeLevel) ? fileStripeLevelFromJSON(object.fileStripeLevel) : 0,
      directoryStripeLevel: isSet(object.directoryStripeLevel)
        ? directoryStripeLevelFromJSON(object.directoryStripeLevel)
        : 0,
    };
  },

  toJSON(message: Instance): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = instance_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (!message.capacityGib.equals(Long.ZERO)) {
      obj.capacityGib = (message.capacityGib || Long.ZERO).toString();
    }
    if (message.daosVersion !== "") {
      obj.daosVersion = message.daosVersion;
    }
    if (message.accessPoints?.length) {
      obj.accessPoints = message.accessPoints;
    }
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.reservedIpRange !== "") {
      obj.reservedIpRange = message.reservedIpRange;
    }
    if (message.effectiveReservedIpRange !== "") {
      obj.effectiveReservedIpRange = message.effectiveReservedIpRange;
    }
    if (message.fileStripeLevel !== 0) {
      obj.fileStripeLevel = fileStripeLevelToJSON(message.fileStripeLevel);
    }
    if (message.directoryStripeLevel !== 0) {
      obj.directoryStripeLevel = directoryStripeLevelToJSON(message.directoryStripeLevel);
    }
    return obj;
  },

  create(base?: DeepPartial<Instance>): Instance {
    return Instance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Instance>): Instance {
    const message = createBaseInstance();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.capacityGib = (object.capacityGib !== undefined && object.capacityGib !== null)
      ? Long.fromValue(object.capacityGib)
      : Long.ZERO;
    message.daosVersion = object.daosVersion ?? "";
    message.accessPoints = object.accessPoints?.map((e) => e) || [];
    message.network = object.network ?? "";
    message.reservedIpRange = object.reservedIpRange ?? "";
    message.effectiveReservedIpRange = object.effectiveReservedIpRange ?? "";
    message.fileStripeLevel = object.fileStripeLevel ?? 0;
    message.directoryStripeLevel = object.directoryStripeLevel ?? 0;
    return message;
  },
};

function createBaseInstance_LabelsEntry(): Instance_LabelsEntry {
  return { key: "", value: "" };
}

export const Instance_LabelsEntry: MessageFns<Instance_LabelsEntry> = {
  encode(message: Instance_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Instance_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstance_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Instance_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Instance_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Instance_LabelsEntry>): Instance_LabelsEntry {
    return Instance_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Instance_LabelsEntry>): Instance_LabelsEntry {
    const message = createBaseInstance_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseListInstancesRequest(): ListInstancesRequest {
  return { parent: "", pageSize: 0, pageToken: "", filter: "", orderBy: "" };
}

export const ListInstancesRequest: MessageFns<ListInstancesRequest> = {
  encode(message: ListInstancesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(34).string(message.filter);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInstancesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInstancesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInstancesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
    };
  },

  toJSON(message: ListInstancesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInstancesRequest>): ListInstancesRequest {
    return ListInstancesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInstancesRequest>): ListInstancesRequest {
    const message = createBaseListInstancesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    message.orderBy = object.orderBy ?? "";
    return message;
  },
};

function createBaseListInstancesResponse(): ListInstancesResponse {
  return { instances: [], nextPageToken: "", unreachable: [] };
}

export const ListInstancesResponse: MessageFns<ListInstancesResponse> = {
  encode(message: ListInstancesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.instances) {
      Instance.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListInstancesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListInstancesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instances.push(Instance.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListInstancesResponse {
    return {
      instances: globalThis.Array.isArray(object?.instances)
        ? object.instances.map((e: any) => Instance.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListInstancesResponse): unknown {
    const obj: any = {};
    if (message.instances?.length) {
      obj.instances = message.instances.map((e) => Instance.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListInstancesResponse>): ListInstancesResponse {
    return ListInstancesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListInstancesResponse>): ListInstancesResponse {
    const message = createBaseListInstancesResponse();
    message.instances = object.instances?.map((e) => Instance.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetInstanceRequest(): GetInstanceRequest {
  return { name: "" };
}

export const GetInstanceRequest: MessageFns<GetInstanceRequest> = {
  encode(message: GetInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetInstanceRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetInstanceRequest>): GetInstanceRequest {
    return GetInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetInstanceRequest>): GetInstanceRequest {
    const message = createBaseGetInstanceRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateInstanceRequest(): CreateInstanceRequest {
  return { parent: "", instanceId: "", instance: undefined, requestId: "" };
}

export const CreateInstanceRequest: MessageFns<CreateInstanceRequest> = {
  encode(message: CreateInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.instanceId !== "") {
      writer.uint32(18).string(message.instanceId);
    }
    if (message.instance !== undefined) {
      Instance.encode(message.instance, writer.uint32(26).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instanceId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.instance = Instance.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateInstanceRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      instanceId: isSet(object.instanceId) ? globalThis.String(object.instanceId) : "",
      instance: isSet(object.instance) ? Instance.fromJSON(object.instance) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: CreateInstanceRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.instanceId !== "") {
      obj.instanceId = message.instanceId;
    }
    if (message.instance !== undefined) {
      obj.instance = Instance.toJSON(message.instance);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateInstanceRequest>): CreateInstanceRequest {
    return CreateInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateInstanceRequest>): CreateInstanceRequest {
    const message = createBaseCreateInstanceRequest();
    message.parent = object.parent ?? "";
    message.instanceId = object.instanceId ?? "";
    message.instance = (object.instance !== undefined && object.instance !== null)
      ? Instance.fromPartial(object.instance)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseUpdateInstanceRequest(): UpdateInstanceRequest {
  return { updateMask: undefined, instance: undefined, requestId: "" };
}

export const UpdateInstanceRequest: MessageFns<UpdateInstanceRequest> = {
  encode(message: UpdateInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.instance !== undefined) {
      Instance.encode(message.instance, writer.uint32(18).fork()).join();
    }
    if (message.requestId !== "") {
      writer.uint32(26).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instance = Instance.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateInstanceRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      instance: isSet(object.instance) ? Instance.fromJSON(object.instance) : undefined,
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: UpdateInstanceRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.instance !== undefined) {
      obj.instance = Instance.toJSON(message.instance);
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateInstanceRequest>): UpdateInstanceRequest {
    return UpdateInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateInstanceRequest>): UpdateInstanceRequest {
    const message = createBaseUpdateInstanceRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.instance = (object.instance !== undefined && object.instance !== null)
      ? Instance.fromPartial(object.instance)
      : undefined;
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseDeleteInstanceRequest(): DeleteInstanceRequest {
  return { name: "", requestId: "" };
}

export const DeleteInstanceRequest: MessageFns<DeleteInstanceRequest> = {
  encode(message: DeleteInstanceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.requestId !== "") {
      writer.uint32(18).string(message.requestId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteInstanceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteInstanceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteInstanceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
    };
  },

  toJSON(message: DeleteInstanceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteInstanceRequest>): DeleteInstanceRequest {
    return DeleteInstanceRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteInstanceRequest>): DeleteInstanceRequest {
    const message = createBaseDeleteInstanceRequest();
    message.name = object.name ?? "";
    message.requestId = object.requestId ?? "";
    return message;
  },
};

function createBaseOperationMetadata(): OperationMetadata {
  return {
    createTime: undefined,
    endTime: undefined,
    target: "",
    verb: "",
    statusMessage: "",
    requestedCancellation: false,
    apiVersion: "",
  };
}

export const OperationMetadata: MessageFns<OperationMetadata> = {
  encode(message: OperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(26).string(message.target);
    }
    if (message.verb !== "") {
      writer.uint32(34).string(message.verb);
    }
    if (message.statusMessage !== "") {
      writer.uint32(42).string(message.statusMessage);
    }
    if (message.requestedCancellation !== false) {
      writer.uint32(48).bool(message.requestedCancellation);
    }
    if (message.apiVersion !== "") {
      writer.uint32(58).string(message.apiVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.target = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.statusMessage = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.requestedCancellation = reader.bool();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.apiVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OperationMetadata {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      statusMessage: isSet(object.statusMessage) ? globalThis.String(object.statusMessage) : "",
      requestedCancellation: isSet(object.requestedCancellation)
        ? globalThis.Boolean(object.requestedCancellation)
        : false,
      apiVersion: isSet(object.apiVersion) ? globalThis.String(object.apiVersion) : "",
    };
  },

  toJSON(message: OperationMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.statusMessage !== "") {
      obj.statusMessage = message.statusMessage;
    }
    if (message.requestedCancellation !== false) {
      obj.requestedCancellation = message.requestedCancellation;
    }
    if (message.apiVersion !== "") {
      obj.apiVersion = message.apiVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<OperationMetadata>): OperationMetadata {
    return OperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OperationMetadata>): OperationMetadata {
    const message = createBaseOperationMetadata();
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.verb = object.verb ?? "";
    message.statusMessage = object.statusMessage ?? "";
    message.requestedCancellation = object.requestedCancellation ?? false;
    message.apiVersion = object.apiVersion ?? "";
    return message;
  },
};

function createBaseSourceGcsBucket(): SourceGcsBucket {
  return { uri: "" };
}

export const SourceGcsBucket: MessageFns<SourceGcsBucket> = {
  encode(message: SourceGcsBucket, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceGcsBucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceGcsBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceGcsBucket {
    return { uri: isSet(object.uri) ? globalThis.String(object.uri) : "" };
  },

  toJSON(message: SourceGcsBucket): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<SourceGcsBucket>): SourceGcsBucket {
    return SourceGcsBucket.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceGcsBucket>): SourceGcsBucket {
    const message = createBaseSourceGcsBucket();
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseDestinationGcsBucket(): DestinationGcsBucket {
  return { uri: "" };
}

export const DestinationGcsBucket: MessageFns<DestinationGcsBucket> = {
  encode(message: DestinationGcsBucket, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DestinationGcsBucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDestinationGcsBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DestinationGcsBucket {
    return { uri: isSet(object.uri) ? globalThis.String(object.uri) : "" };
  },

  toJSON(message: DestinationGcsBucket): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    return obj;
  },

  create(base?: DeepPartial<DestinationGcsBucket>): DestinationGcsBucket {
    return DestinationGcsBucket.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DestinationGcsBucket>): DestinationGcsBucket {
    const message = createBaseDestinationGcsBucket();
    message.uri = object.uri ?? "";
    return message;
  },
};

function createBaseSourceParallelstore(): SourceParallelstore {
  return { path: "" };
}

export const SourceParallelstore: MessageFns<SourceParallelstore> = {
  encode(message: SourceParallelstore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceParallelstore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceParallelstore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceParallelstore {
    return { path: isSet(object.path) ? globalThis.String(object.path) : "" };
  },

  toJSON(message: SourceParallelstore): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<SourceParallelstore>): SourceParallelstore {
    return SourceParallelstore.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceParallelstore>): SourceParallelstore {
    const message = createBaseSourceParallelstore();
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseDestinationParallelstore(): DestinationParallelstore {
  return { path: "" };
}

export const DestinationParallelstore: MessageFns<DestinationParallelstore> = {
  encode(message: DestinationParallelstore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DestinationParallelstore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDestinationParallelstore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DestinationParallelstore {
    return { path: isSet(object.path) ? globalThis.String(object.path) : "" };
  },

  toJSON(message: DestinationParallelstore): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<DestinationParallelstore>): DestinationParallelstore {
    return DestinationParallelstore.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DestinationParallelstore>): DestinationParallelstore {
    const message = createBaseDestinationParallelstore();
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseImportDataRequest(): ImportDataRequest {
  return {
    sourceGcsBucket: undefined,
    destinationParallelstore: undefined,
    name: "",
    requestId: "",
    serviceAccount: "",
  };
}

export const ImportDataRequest: MessageFns<ImportDataRequest> = {
  encode(message: ImportDataRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sourceGcsBucket !== undefined) {
      SourceGcsBucket.encode(message.sourceGcsBucket, writer.uint32(18).fork()).join();
    }
    if (message.destinationParallelstore !== undefined) {
      DestinationParallelstore.encode(message.destinationParallelstore, writer.uint32(26).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(42).string(message.serviceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDataRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDataRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceGcsBucket = SourceGcsBucket.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.destinationParallelstore = DestinationParallelstore.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportDataRequest {
    return {
      sourceGcsBucket: isSet(object.sourceGcsBucket) ? SourceGcsBucket.fromJSON(object.sourceGcsBucket) : undefined,
      destinationParallelstore: isSet(object.destinationParallelstore)
        ? DestinationParallelstore.fromJSON(object.destinationParallelstore)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
    };
  },

  toJSON(message: ImportDataRequest): unknown {
    const obj: any = {};
    if (message.sourceGcsBucket !== undefined) {
      obj.sourceGcsBucket = SourceGcsBucket.toJSON(message.sourceGcsBucket);
    }
    if (message.destinationParallelstore !== undefined) {
      obj.destinationParallelstore = DestinationParallelstore.toJSON(message.destinationParallelstore);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportDataRequest>): ImportDataRequest {
    return ImportDataRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportDataRequest>): ImportDataRequest {
    const message = createBaseImportDataRequest();
    message.sourceGcsBucket = (object.sourceGcsBucket !== undefined && object.sourceGcsBucket !== null)
      ? SourceGcsBucket.fromPartial(object.sourceGcsBucket)
      : undefined;
    message.destinationParallelstore =
      (object.destinationParallelstore !== undefined && object.destinationParallelstore !== null)
        ? DestinationParallelstore.fromPartial(object.destinationParallelstore)
        : undefined;
    message.name = object.name ?? "";
    message.requestId = object.requestId ?? "";
    message.serviceAccount = object.serviceAccount ?? "";
    return message;
  },
};

function createBaseExportDataRequest(): ExportDataRequest {
  return {
    sourceParallelstore: undefined,
    destinationGcsBucket: undefined,
    name: "",
    requestId: "",
    serviceAccount: "",
  };
}

export const ExportDataRequest: MessageFns<ExportDataRequest> = {
  encode(message: ExportDataRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sourceParallelstore !== undefined) {
      SourceParallelstore.encode(message.sourceParallelstore, writer.uint32(18).fork()).join();
    }
    if (message.destinationGcsBucket !== undefined) {
      DestinationGcsBucket.encode(message.destinationGcsBucket, writer.uint32(26).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.requestId !== "") {
      writer.uint32(34).string(message.requestId);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(42).string(message.serviceAccount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDataRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDataRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceParallelstore = SourceParallelstore.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.destinationGcsBucket = DestinationGcsBucket.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDataRequest {
    return {
      sourceParallelstore: isSet(object.sourceParallelstore)
        ? SourceParallelstore.fromJSON(object.sourceParallelstore)
        : undefined,
      destinationGcsBucket: isSet(object.destinationGcsBucket)
        ? DestinationGcsBucket.fromJSON(object.destinationGcsBucket)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      requestId: isSet(object.requestId) ? globalThis.String(object.requestId) : "",
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
    };
  },

  toJSON(message: ExportDataRequest): unknown {
    const obj: any = {};
    if (message.sourceParallelstore !== undefined) {
      obj.sourceParallelstore = SourceParallelstore.toJSON(message.sourceParallelstore);
    }
    if (message.destinationGcsBucket !== undefined) {
      obj.destinationGcsBucket = DestinationGcsBucket.toJSON(message.destinationGcsBucket);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.requestId !== "") {
      obj.requestId = message.requestId;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDataRequest>): ExportDataRequest {
    return ExportDataRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDataRequest>): ExportDataRequest {
    const message = createBaseExportDataRequest();
    message.sourceParallelstore = (object.sourceParallelstore !== undefined && object.sourceParallelstore !== null)
      ? SourceParallelstore.fromPartial(object.sourceParallelstore)
      : undefined;
    message.destinationGcsBucket = (object.destinationGcsBucket !== undefined && object.destinationGcsBucket !== null)
      ? DestinationGcsBucket.fromPartial(object.destinationGcsBucket)
      : undefined;
    message.name = object.name ?? "";
    message.requestId = object.requestId ?? "";
    message.serviceAccount = object.serviceAccount ?? "";
    return message;
  },
};

function createBaseImportDataResponse(): ImportDataResponse {
  return {};
}

export const ImportDataResponse: MessageFns<ImportDataResponse> = {
  encode(_: ImportDataResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDataResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDataResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ImportDataResponse {
    return {};
  },

  toJSON(_: ImportDataResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ImportDataResponse>): ImportDataResponse {
    return ImportDataResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ImportDataResponse>): ImportDataResponse {
    const message = createBaseImportDataResponse();
    return message;
  },
};

function createBaseImportDataMetadata(): ImportDataMetadata {
  return {
    operationMetadata: undefined,
    createTime: undefined,
    endTime: undefined,
    target: "",
    verb: "",
    statusMessage: "",
    requestedCancellation: false,
    apiVersion: "",
  };
}

export const ImportDataMetadata: MessageFns<ImportDataMetadata> = {
  encode(message: ImportDataMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operationMetadata !== undefined) {
      TransferOperationMetadata.encode(message.operationMetadata, writer.uint32(10).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(34).string(message.target);
    }
    if (message.verb !== "") {
      writer.uint32(42).string(message.verb);
    }
    if (message.statusMessage !== "") {
      writer.uint32(50).string(message.statusMessage);
    }
    if (message.requestedCancellation !== false) {
      writer.uint32(56).bool(message.requestedCancellation);
    }
    if (message.apiVersion !== "") {
      writer.uint32(66).string(message.apiVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDataMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDataMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operationMetadata = TransferOperationMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.target = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.statusMessage = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.requestedCancellation = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.apiVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportDataMetadata {
    return {
      operationMetadata: isSet(object.operationMetadata)
        ? TransferOperationMetadata.fromJSON(object.operationMetadata)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      statusMessage: isSet(object.statusMessage) ? globalThis.String(object.statusMessage) : "",
      requestedCancellation: isSet(object.requestedCancellation)
        ? globalThis.Boolean(object.requestedCancellation)
        : false,
      apiVersion: isSet(object.apiVersion) ? globalThis.String(object.apiVersion) : "",
    };
  },

  toJSON(message: ImportDataMetadata): unknown {
    const obj: any = {};
    if (message.operationMetadata !== undefined) {
      obj.operationMetadata = TransferOperationMetadata.toJSON(message.operationMetadata);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.statusMessage !== "") {
      obj.statusMessage = message.statusMessage;
    }
    if (message.requestedCancellation !== false) {
      obj.requestedCancellation = message.requestedCancellation;
    }
    if (message.apiVersion !== "") {
      obj.apiVersion = message.apiVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportDataMetadata>): ImportDataMetadata {
    return ImportDataMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportDataMetadata>): ImportDataMetadata {
    const message = createBaseImportDataMetadata();
    message.operationMetadata = (object.operationMetadata !== undefined && object.operationMetadata !== null)
      ? TransferOperationMetadata.fromPartial(object.operationMetadata)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.verb = object.verb ?? "";
    message.statusMessage = object.statusMessage ?? "";
    message.requestedCancellation = object.requestedCancellation ?? false;
    message.apiVersion = object.apiVersion ?? "";
    return message;
  },
};

function createBaseExportDataResponse(): ExportDataResponse {
  return {};
}

export const ExportDataResponse: MessageFns<ExportDataResponse> = {
  encode(_: ExportDataResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDataResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDataResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ExportDataResponse {
    return {};
  },

  toJSON(_: ExportDataResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ExportDataResponse>): ExportDataResponse {
    return ExportDataResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ExportDataResponse>): ExportDataResponse {
    const message = createBaseExportDataResponse();
    return message;
  },
};

function createBaseExportDataMetadata(): ExportDataMetadata {
  return {
    operationMetadata: undefined,
    createTime: undefined,
    endTime: undefined,
    target: "",
    verb: "",
    statusMessage: "",
    requestedCancellation: false,
    apiVersion: "",
  };
}

export const ExportDataMetadata: MessageFns<ExportDataMetadata> = {
  encode(message: ExportDataMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operationMetadata !== undefined) {
      TransferOperationMetadata.encode(message.operationMetadata, writer.uint32(10).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(34).string(message.target);
    }
    if (message.verb !== "") {
      writer.uint32(42).string(message.verb);
    }
    if (message.statusMessage !== "") {
      writer.uint32(50).string(message.statusMessage);
    }
    if (message.requestedCancellation !== false) {
      writer.uint32(56).bool(message.requestedCancellation);
    }
    if (message.apiVersion !== "") {
      writer.uint32(66).string(message.apiVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDataMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDataMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operationMetadata = TransferOperationMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.target = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.statusMessage = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.requestedCancellation = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.apiVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDataMetadata {
    return {
      operationMetadata: isSet(object.operationMetadata)
        ? TransferOperationMetadata.fromJSON(object.operationMetadata)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      statusMessage: isSet(object.statusMessage) ? globalThis.String(object.statusMessage) : "",
      requestedCancellation: isSet(object.requestedCancellation)
        ? globalThis.Boolean(object.requestedCancellation)
        : false,
      apiVersion: isSet(object.apiVersion) ? globalThis.String(object.apiVersion) : "",
    };
  },

  toJSON(message: ExportDataMetadata): unknown {
    const obj: any = {};
    if (message.operationMetadata !== undefined) {
      obj.operationMetadata = TransferOperationMetadata.toJSON(message.operationMetadata);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.statusMessage !== "") {
      obj.statusMessage = message.statusMessage;
    }
    if (message.requestedCancellation !== false) {
      obj.requestedCancellation = message.requestedCancellation;
    }
    if (message.apiVersion !== "") {
      obj.apiVersion = message.apiVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDataMetadata>): ExportDataMetadata {
    return ExportDataMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDataMetadata>): ExportDataMetadata {
    const message = createBaseExportDataMetadata();
    message.operationMetadata = (object.operationMetadata !== undefined && object.operationMetadata !== null)
      ? TransferOperationMetadata.fromPartial(object.operationMetadata)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.verb = object.verb ?? "";
    message.statusMessage = object.statusMessage ?? "";
    message.requestedCancellation = object.requestedCancellation ?? false;
    message.apiVersion = object.apiVersion ?? "";
    return message;
  },
};

function createBaseTransferOperationMetadata(): TransferOperationMetadata {
  return {
    sourceParallelstore: undefined,
    sourceGcsBucket: undefined,
    destinationGcsBucket: undefined,
    destinationParallelstore: undefined,
    counters: undefined,
    transferType: 0,
  };
}

export const TransferOperationMetadata: MessageFns<TransferOperationMetadata> = {
  encode(message: TransferOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sourceParallelstore !== undefined) {
      SourceParallelstore.encode(message.sourceParallelstore, writer.uint32(58).fork()).join();
    }
    if (message.sourceGcsBucket !== undefined) {
      SourceGcsBucket.encode(message.sourceGcsBucket, writer.uint32(66).fork()).join();
    }
    if (message.destinationGcsBucket !== undefined) {
      DestinationGcsBucket.encode(message.destinationGcsBucket, writer.uint32(74).fork()).join();
    }
    if (message.destinationParallelstore !== undefined) {
      DestinationParallelstore.encode(message.destinationParallelstore, writer.uint32(82).fork()).join();
    }
    if (message.counters !== undefined) {
      TransferCounters.encode(message.counters, writer.uint32(26).fork()).join();
    }
    if (message.transferType !== 0) {
      writer.uint32(48).int32(message.transferType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransferOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransferOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 7:
          if (tag !== 58) {
            break;
          }

          message.sourceParallelstore = SourceParallelstore.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.sourceGcsBucket = SourceGcsBucket.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.destinationGcsBucket = DestinationGcsBucket.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.destinationParallelstore = DestinationParallelstore.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.counters = TransferCounters.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.transferType = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransferOperationMetadata {
    return {
      sourceParallelstore: isSet(object.sourceParallelstore)
        ? SourceParallelstore.fromJSON(object.sourceParallelstore)
        : undefined,
      sourceGcsBucket: isSet(object.sourceGcsBucket) ? SourceGcsBucket.fromJSON(object.sourceGcsBucket) : undefined,
      destinationGcsBucket: isSet(object.destinationGcsBucket)
        ? DestinationGcsBucket.fromJSON(object.destinationGcsBucket)
        : undefined,
      destinationParallelstore: isSet(object.destinationParallelstore)
        ? DestinationParallelstore.fromJSON(object.destinationParallelstore)
        : undefined,
      counters: isSet(object.counters) ? TransferCounters.fromJSON(object.counters) : undefined,
      transferType: isSet(object.transferType) ? transferTypeFromJSON(object.transferType) : 0,
    };
  },

  toJSON(message: TransferOperationMetadata): unknown {
    const obj: any = {};
    if (message.sourceParallelstore !== undefined) {
      obj.sourceParallelstore = SourceParallelstore.toJSON(message.sourceParallelstore);
    }
    if (message.sourceGcsBucket !== undefined) {
      obj.sourceGcsBucket = SourceGcsBucket.toJSON(message.sourceGcsBucket);
    }
    if (message.destinationGcsBucket !== undefined) {
      obj.destinationGcsBucket = DestinationGcsBucket.toJSON(message.destinationGcsBucket);
    }
    if (message.destinationParallelstore !== undefined) {
      obj.destinationParallelstore = DestinationParallelstore.toJSON(message.destinationParallelstore);
    }
    if (message.counters !== undefined) {
      obj.counters = TransferCounters.toJSON(message.counters);
    }
    if (message.transferType !== 0) {
      obj.transferType = transferTypeToJSON(message.transferType);
    }
    return obj;
  },

  create(base?: DeepPartial<TransferOperationMetadata>): TransferOperationMetadata {
    return TransferOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransferOperationMetadata>): TransferOperationMetadata {
    const message = createBaseTransferOperationMetadata();
    message.sourceParallelstore = (object.sourceParallelstore !== undefined && object.sourceParallelstore !== null)
      ? SourceParallelstore.fromPartial(object.sourceParallelstore)
      : undefined;
    message.sourceGcsBucket = (object.sourceGcsBucket !== undefined && object.sourceGcsBucket !== null)
      ? SourceGcsBucket.fromPartial(object.sourceGcsBucket)
      : undefined;
    message.destinationGcsBucket = (object.destinationGcsBucket !== undefined && object.destinationGcsBucket !== null)
      ? DestinationGcsBucket.fromPartial(object.destinationGcsBucket)
      : undefined;
    message.destinationParallelstore =
      (object.destinationParallelstore !== undefined && object.destinationParallelstore !== null)
        ? DestinationParallelstore.fromPartial(object.destinationParallelstore)
        : undefined;
    message.counters = (object.counters !== undefined && object.counters !== null)
      ? TransferCounters.fromPartial(object.counters)
      : undefined;
    message.transferType = object.transferType ?? 0;
    return message;
  },
};

function createBaseTransferCounters(): TransferCounters {
  return {
    objectsFound: Long.ZERO,
    bytesFound: Long.ZERO,
    objectsSkipped: Long.ZERO,
    bytesSkipped: Long.ZERO,
    objectsCopied: Long.ZERO,
    bytesCopied: Long.ZERO,
  };
}

export const TransferCounters: MessageFns<TransferCounters> = {
  encode(message: TransferCounters, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.objectsFound.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.objectsFound.toString());
    }
    if (!message.bytesFound.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.bytesFound.toString());
    }
    if (!message.objectsSkipped.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.objectsSkipped.toString());
    }
    if (!message.bytesSkipped.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.bytesSkipped.toString());
    }
    if (!message.objectsCopied.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.objectsCopied.toString());
    }
    if (!message.bytesCopied.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.bytesCopied.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransferCounters {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransferCounters();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.objectsFound = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.bytesFound = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.objectsSkipped = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.bytesSkipped = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.objectsCopied = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.bytesCopied = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransferCounters {
    return {
      objectsFound: isSet(object.objectsFound) ? Long.fromValue(object.objectsFound) : Long.ZERO,
      bytesFound: isSet(object.bytesFound) ? Long.fromValue(object.bytesFound) : Long.ZERO,
      objectsSkipped: isSet(object.objectsSkipped) ? Long.fromValue(object.objectsSkipped) : Long.ZERO,
      bytesSkipped: isSet(object.bytesSkipped) ? Long.fromValue(object.bytesSkipped) : Long.ZERO,
      objectsCopied: isSet(object.objectsCopied) ? Long.fromValue(object.objectsCopied) : Long.ZERO,
      bytesCopied: isSet(object.bytesCopied) ? Long.fromValue(object.bytesCopied) : Long.ZERO,
    };
  },

  toJSON(message: TransferCounters): unknown {
    const obj: any = {};
    if (!message.objectsFound.equals(Long.ZERO)) {
      obj.objectsFound = (message.objectsFound || Long.ZERO).toString();
    }
    if (!message.bytesFound.equals(Long.ZERO)) {
      obj.bytesFound = (message.bytesFound || Long.ZERO).toString();
    }
    if (!message.objectsSkipped.equals(Long.ZERO)) {
      obj.objectsSkipped = (message.objectsSkipped || Long.ZERO).toString();
    }
    if (!message.bytesSkipped.equals(Long.ZERO)) {
      obj.bytesSkipped = (message.bytesSkipped || Long.ZERO).toString();
    }
    if (!message.objectsCopied.equals(Long.ZERO)) {
      obj.objectsCopied = (message.objectsCopied || Long.ZERO).toString();
    }
    if (!message.bytesCopied.equals(Long.ZERO)) {
      obj.bytesCopied = (message.bytesCopied || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<TransferCounters>): TransferCounters {
    return TransferCounters.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransferCounters>): TransferCounters {
    const message = createBaseTransferCounters();
    message.objectsFound = (object.objectsFound !== undefined && object.objectsFound !== null)
      ? Long.fromValue(object.objectsFound)
      : Long.ZERO;
    message.bytesFound = (object.bytesFound !== undefined && object.bytesFound !== null)
      ? Long.fromValue(object.bytesFound)
      : Long.ZERO;
    message.objectsSkipped = (object.objectsSkipped !== undefined && object.objectsSkipped !== null)
      ? Long.fromValue(object.objectsSkipped)
      : Long.ZERO;
    message.bytesSkipped = (object.bytesSkipped !== undefined && object.bytesSkipped !== null)
      ? Long.fromValue(object.bytesSkipped)
      : Long.ZERO;
    message.objectsCopied = (object.objectsCopied !== undefined && object.objectsCopied !== null)
      ? Long.fromValue(object.objectsCopied)
      : Long.ZERO;
    message.bytesCopied = (object.bytesCopied !== undefined && object.bytesCopied !== null)
      ? Long.fromValue(object.bytesCopied)
      : Long.ZERO;
    return message;
  },
};

/**
 * Service describing handlers for resources
 * Configures and manages parallelstore resources.
 *
 * Parallelstore service.
 *
 * The `parallelstore.googleapis.com` service implements the parallelstore API
 * and defines the following resource model for managing instances:
 * * The service works with a collection of cloud projects, named: `/projects/*`
 * * Each project has a collection of available locations, named: `/locations/*`
 * * Each location has a collection of instances named `/instances/*`.
 * * Parallelstore instances are resources of the form:
 *   `/projects/{project_id}/locations/{location_id}/instances/{instance_id}`
 *
 * Note that location_id must be a Google Cloud `zone`; for example:
 * * `projects/12345/locations/us-central1-c/instances/my-parallelstore-share`
 */
export type ParallelstoreDefinition = typeof ParallelstoreDefinition;
export const ParallelstoreDefinition = {
  name: "Parallelstore",
  fullName: "google.cloud.parallelstore.v1beta.Parallelstore",
  methods: {
    /** Lists all instances in a given project and location. */
    listInstances: {
      name: "ListInstances",
      requestType: ListInstancesRequest,
      requestStream: false,
      responseType: ListInstancesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              51,
              18,
              49,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details of a single instance. */
    getInstance: {
      name: "GetInstance",
      requestType: GetInstanceRequest,
      requestStream: false,
      responseType: Instance,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              51,
              18,
              49,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a Parallelstore instance in a given project and location. */
    createInstance: {
      name: "CreateInstance",
      requestType: CreateInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              29,
              10,
              8,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              44,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              61,
              58,
              8,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              34,
              49,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates the parameters of a single instance. */
    updateInstance: {
      name: "UpdateInstance",
      requestType: UpdateInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              29,
              10,
              8,
              73,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              20,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              70,
              58,
              8,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              50,
              58,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a single instance. */
    deleteInstance: {
      name: "DeleteInstance",
      requestType: DeleteInstanceRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              42,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              17,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              51,
              42,
              49,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Copies data from Cloud Storage to Parallelstore. */
    importData: {
      name: "ImportData",
      requestType: ImportDataRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              40,
              10,
              18,
              73,
              109,
              112,
              111,
              114,
              116,
              68,
              97,
              116,
              97,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              18,
              73,
              109,
              112,
              111,
              114,
              116,
              68,
              97,
              116,
              97,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
              68,
              97,
              116,
              97,
            ]),
          ],
        },
      },
    },
    /** Copies data from Parallelstore to Cloud Storage. */
    exportData: {
      name: "ExportData",
      requestType: ExportDataRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              40,
              10,
              18,
              69,
              120,
              112,
              111,
              114,
              116,
              68,
              97,
              116,
              97,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              18,
              69,
              120,
              112,
              111,
              114,
              116,
              68,
              97,
              116,
              97,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
              68,
              97,
              116,
              97,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface ParallelstoreServiceImplementation<CallContextExt = {}> {
  /** Lists all instances in a given project and location. */
  listInstances(
    request: ListInstancesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListInstancesResponse>>;
  /** Gets details of a single instance. */
  getInstance(request: GetInstanceRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Instance>>;
  /** Creates a Parallelstore instance in a given project and location. */
  createInstance(
    request: CreateInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Updates the parameters of a single instance. */
  updateInstance(
    request: UpdateInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Deletes a single instance. */
  deleteInstance(
    request: DeleteInstanceRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Copies data from Cloud Storage to Parallelstore. */
  importData(request: ImportDataRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Copies data from Parallelstore to Cloud Storage. */
  exportData(request: ExportDataRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
}

export interface ParallelstoreClient<CallOptionsExt = {}> {
  /** Lists all instances in a given project and location. */
  listInstances(
    request: DeepPartial<ListInstancesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListInstancesResponse>;
  /** Gets details of a single instance. */
  getInstance(request: DeepPartial<GetInstanceRequest>, options?: CallOptions & CallOptionsExt): Promise<Instance>;
  /** Creates a Parallelstore instance in a given project and location. */
  createInstance(
    request: DeepPartial<CreateInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Updates the parameters of a single instance. */
  updateInstance(
    request: DeepPartial<UpdateInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Deletes a single instance. */
  deleteInstance(
    request: DeepPartial<DeleteInstanceRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Copies data from Cloud Storage to Parallelstore. */
  importData(request: DeepPartial<ImportDataRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Copies data from Parallelstore to Cloud Storage. */
  exportData(request: DeepPartial<ExportDataRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
