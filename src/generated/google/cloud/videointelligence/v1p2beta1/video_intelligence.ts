// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/videointelligence/v1p2beta1/video_intelligence.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";

export const protobufPackage = "google.cloud.videointelligence.v1p2beta1";

/** Video annotation feature. */
export enum Feature {
  /** FEATURE_UNSPECIFIED - Unspecified. */
  FEATURE_UNSPECIFIED = 0,
  /** LABEL_DETECTION - Label detection. Detect objects, such as dog or flower. */
  LABEL_DETECTION = 1,
  /** SHOT_CHANGE_DETECTION - Shot change detection. */
  SHOT_CHANGE_DETECTION = 2,
  /** EXPLICIT_CONTENT_DETECTION - Explicit content detection. */
  EXPLICIT_CONTENT_DETECTION = 3,
  /** TEXT_DETECTION - OCR text detection and tracking. */
  TEXT_DETECTION = 7,
  /** OBJECT_TRACKING - Object detection and tracking. */
  OBJECT_TRACKING = 9,
  UNRECOGNIZED = -1,
}

export function featureFromJSON(object: any): Feature {
  switch (object) {
    case 0:
    case "FEATURE_UNSPECIFIED":
      return Feature.FEATURE_UNSPECIFIED;
    case 1:
    case "LABEL_DETECTION":
      return Feature.LABEL_DETECTION;
    case 2:
    case "SHOT_CHANGE_DETECTION":
      return Feature.SHOT_CHANGE_DETECTION;
    case 3:
    case "EXPLICIT_CONTENT_DETECTION":
      return Feature.EXPLICIT_CONTENT_DETECTION;
    case 7:
    case "TEXT_DETECTION":
      return Feature.TEXT_DETECTION;
    case 9:
    case "OBJECT_TRACKING":
      return Feature.OBJECT_TRACKING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Feature.UNRECOGNIZED;
  }
}

export function featureToJSON(object: Feature): string {
  switch (object) {
    case Feature.FEATURE_UNSPECIFIED:
      return "FEATURE_UNSPECIFIED";
    case Feature.LABEL_DETECTION:
      return "LABEL_DETECTION";
    case Feature.SHOT_CHANGE_DETECTION:
      return "SHOT_CHANGE_DETECTION";
    case Feature.EXPLICIT_CONTENT_DETECTION:
      return "EXPLICIT_CONTENT_DETECTION";
    case Feature.TEXT_DETECTION:
      return "TEXT_DETECTION";
    case Feature.OBJECT_TRACKING:
      return "OBJECT_TRACKING";
    case Feature.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Label detection mode. */
export enum LabelDetectionMode {
  /** LABEL_DETECTION_MODE_UNSPECIFIED - Unspecified. */
  LABEL_DETECTION_MODE_UNSPECIFIED = 0,
  /** SHOT_MODE - Detect shot-level labels. */
  SHOT_MODE = 1,
  /** FRAME_MODE - Detect frame-level labels. */
  FRAME_MODE = 2,
  /** SHOT_AND_FRAME_MODE - Detect both shot-level and frame-level labels. */
  SHOT_AND_FRAME_MODE = 3,
  UNRECOGNIZED = -1,
}

export function labelDetectionModeFromJSON(object: any): LabelDetectionMode {
  switch (object) {
    case 0:
    case "LABEL_DETECTION_MODE_UNSPECIFIED":
      return LabelDetectionMode.LABEL_DETECTION_MODE_UNSPECIFIED;
    case 1:
    case "SHOT_MODE":
      return LabelDetectionMode.SHOT_MODE;
    case 2:
    case "FRAME_MODE":
      return LabelDetectionMode.FRAME_MODE;
    case 3:
    case "SHOT_AND_FRAME_MODE":
      return LabelDetectionMode.SHOT_AND_FRAME_MODE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return LabelDetectionMode.UNRECOGNIZED;
  }
}

export function labelDetectionModeToJSON(object: LabelDetectionMode): string {
  switch (object) {
    case LabelDetectionMode.LABEL_DETECTION_MODE_UNSPECIFIED:
      return "LABEL_DETECTION_MODE_UNSPECIFIED";
    case LabelDetectionMode.SHOT_MODE:
      return "SHOT_MODE";
    case LabelDetectionMode.FRAME_MODE:
      return "FRAME_MODE";
    case LabelDetectionMode.SHOT_AND_FRAME_MODE:
      return "SHOT_AND_FRAME_MODE";
    case LabelDetectionMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Bucketized representation of likelihood. */
export enum Likelihood {
  /** LIKELIHOOD_UNSPECIFIED - Unspecified likelihood. */
  LIKELIHOOD_UNSPECIFIED = 0,
  /** VERY_UNLIKELY - Very unlikely. */
  VERY_UNLIKELY = 1,
  /** UNLIKELY - Unlikely. */
  UNLIKELY = 2,
  /** POSSIBLE - Possible. */
  POSSIBLE = 3,
  /** LIKELY - Likely. */
  LIKELY = 4,
  /** VERY_LIKELY - Very likely. */
  VERY_LIKELY = 5,
  UNRECOGNIZED = -1,
}

export function likelihoodFromJSON(object: any): Likelihood {
  switch (object) {
    case 0:
    case "LIKELIHOOD_UNSPECIFIED":
      return Likelihood.LIKELIHOOD_UNSPECIFIED;
    case 1:
    case "VERY_UNLIKELY":
      return Likelihood.VERY_UNLIKELY;
    case 2:
    case "UNLIKELY":
      return Likelihood.UNLIKELY;
    case 3:
    case "POSSIBLE":
      return Likelihood.POSSIBLE;
    case 4:
    case "LIKELY":
      return Likelihood.LIKELY;
    case 5:
    case "VERY_LIKELY":
      return Likelihood.VERY_LIKELY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Likelihood.UNRECOGNIZED;
  }
}

export function likelihoodToJSON(object: Likelihood): string {
  switch (object) {
    case Likelihood.LIKELIHOOD_UNSPECIFIED:
      return "LIKELIHOOD_UNSPECIFIED";
    case Likelihood.VERY_UNLIKELY:
      return "VERY_UNLIKELY";
    case Likelihood.UNLIKELY:
      return "UNLIKELY";
    case Likelihood.POSSIBLE:
      return "POSSIBLE";
    case Likelihood.LIKELY:
      return "LIKELY";
    case Likelihood.VERY_LIKELY:
      return "VERY_LIKELY";
    case Likelihood.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Video annotation request. */
export interface AnnotateVideoRequest {
  /**
   * Input video location. Currently, only
   * [Google Cloud Storage](https://cloud.google.com/storage/) URIs are
   * supported, which must be specified in the following format:
   * `gs://bucket-id/object-id` (other URI formats return
   * [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see
   * [Request URIs](https://cloud.google.com/storage/docs/request-endpoints).
   * A video URI may include wildcards in `object-id`, and thus identify
   * multiple videos. Supported wildcards: '*' to match 0 or more characters;
   * '?' to match 1 character. If unset, the input video should be embedded
   * in the request as `input_content`. If set, `input_content` should be unset.
   */
  inputUri: string;
  /**
   * The video data bytes.
   * If unset, the input video(s) should be specified via `input_uri`.
   * If set, `input_uri` should be unset.
   */
  inputContent: Buffer;
  /** Required. Requested video annotation features. */
  features: Feature[];
  /** Additional video context and/or feature-specific parameters. */
  videoContext:
    | VideoContext
    | undefined;
  /**
   * Optional. Location where the output (in JSON format) should be stored.
   * Currently, only [Google Cloud Storage](https://cloud.google.com/storage/)
   * URIs are supported, which must be specified in the following format:
   * `gs://bucket-id/object-id` (other URI formats return
   * [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see
   * [Request URIs](https://cloud.google.com/storage/docs/request-endpoints).
   */
  outputUri: string;
  /**
   * Optional. Cloud region where annotation should take place. Supported cloud
   * regions: `us-east1`, `us-west1`, `europe-west1`, `asia-east1`. If no region
   * is specified, a region will be determined based on video file location.
   */
  locationId: string;
}

/** Video context and/or feature-specific parameters. */
export interface VideoContext {
  /**
   * Video segments to annotate. The segments may overlap and are not required
   * to be contiguous or span the whole video. If unspecified, each video is
   * treated as a single segment.
   */
  segments: VideoSegment[];
  /** Config for LABEL_DETECTION. */
  labelDetectionConfig:
    | LabelDetectionConfig
    | undefined;
  /** Config for SHOT_CHANGE_DETECTION. */
  shotChangeDetectionConfig:
    | ShotChangeDetectionConfig
    | undefined;
  /** Config for EXPLICIT_CONTENT_DETECTION. */
  explicitContentDetectionConfig:
    | ExplicitContentDetectionConfig
    | undefined;
  /** Config for TEXT_DETECTION. */
  textDetectionConfig: TextDetectionConfig | undefined;
}

/** Config for LABEL_DETECTION. */
export interface LabelDetectionConfig {
  /**
   * What labels should be detected with LABEL_DETECTION, in addition to
   * video-level labels or segment-level labels.
   * If unspecified, defaults to `SHOT_MODE`.
   */
  labelDetectionMode: LabelDetectionMode;
  /**
   * Whether the video has been shot from a stationary (i.e. non-moving) camera.
   * When set to true, might improve detection accuracy for moving objects.
   * Should be used with `SHOT_AND_FRAME_MODE` enabled.
   */
  stationaryCamera: boolean;
  /**
   * Model to use for label detection.
   * Supported values: "builtin/stable" (the default if unset) and
   * "builtin/latest".
   */
  model: string;
}

/** Config for SHOT_CHANGE_DETECTION. */
export interface ShotChangeDetectionConfig {
  /**
   * Model to use for shot change detection.
   * Supported values: "builtin/stable" (the default if unset) and
   * "builtin/latest".
   */
  model: string;
}

/** Config for EXPLICIT_CONTENT_DETECTION. */
export interface ExplicitContentDetectionConfig {
  /**
   * Model to use for explicit content detection.
   * Supported values: "builtin/stable" (the default if unset) and
   * "builtin/latest".
   */
  model: string;
}

/** Config for TEXT_DETECTION. */
export interface TextDetectionConfig {
  /**
   * Language hint can be specified if the language to be detected is known a
   * priori. It can increase the accuracy of the detection. Language hint must
   * be language code in BCP-47 format.
   *
   * Automatic language detection is performed if no hint is provided.
   */
  languageHints: string[];
}

/** Video segment. */
export interface VideoSegment {
  /**
   * Time-offset, relative to the beginning of the video,
   * corresponding to the start of the segment (inclusive).
   */
  startTimeOffset:
    | Duration
    | undefined;
  /**
   * Time-offset, relative to the beginning of the video,
   * corresponding to the end of the segment (inclusive).
   */
  endTimeOffset: Duration | undefined;
}

/** Video segment level annotation results for label detection. */
export interface LabelSegment {
  /** Video segment where a label was detected. */
  segment:
    | VideoSegment
    | undefined;
  /** Confidence that the label is accurate. Range: [0, 1]. */
  confidence: number;
}

/** Video frame level annotation results for label detection. */
export interface LabelFrame {
  /**
   * Time-offset, relative to the beginning of the video, corresponding to the
   * video frame for this location.
   */
  timeOffset:
    | Duration
    | undefined;
  /** Confidence that the label is accurate. Range: [0, 1]. */
  confidence: number;
}

/** Detected entity from video analysis. */
export interface Entity {
  /**
   * Opaque entity ID. Some IDs may be available in
   * [Google Knowledge Graph Search
   * API](https://developers.google.com/knowledge-graph/).
   */
  entityId: string;
  /** Textual description, e.g. `Fixed-gear bicycle`. */
  description: string;
  /** Language code for `description` in BCP-47 format. */
  languageCode: string;
}

/** Label annotation. */
export interface LabelAnnotation {
  /** Detected entity. */
  entity:
    | Entity
    | undefined;
  /**
   * Common categories for the detected entity.
   * E.g. when the label is `Terrier` the category is likely `dog`. And in some
   * cases there might be more than one categories e.g. `Terrier` could also be
   * a `pet`.
   */
  categoryEntities: Entity[];
  /** All video segments where a label was detected. */
  segments: LabelSegment[];
  /** All video frames where a label was detected. */
  frames: LabelFrame[];
}

/** Video frame level annotation results for explicit content. */
export interface ExplicitContentFrame {
  /**
   * Time-offset, relative to the beginning of the video, corresponding to the
   * video frame for this location.
   */
  timeOffset:
    | Duration
    | undefined;
  /** Likelihood of the pornography content.. */
  pornographyLikelihood: Likelihood;
}

/**
 * Explicit content annotation (based on per-frame visual signals only).
 * If no explicit content has been detected in a frame, no annotations are
 * present for that frame.
 */
export interface ExplicitContentAnnotation {
  /** All video frames where explicit content was detected. */
  frames: ExplicitContentFrame[];
}

/**
 * Normalized bounding box.
 * The normalized vertex coordinates are relative to the original image.
 * Range: [0, 1].
 */
export interface NormalizedBoundingBox {
  /** Left X coordinate. */
  left: number;
  /** Top Y coordinate. */
  top: number;
  /** Right X coordinate. */
  right: number;
  /** Bottom Y coordinate. */
  bottom: number;
}

/** Annotation results for a single video. */
export interface VideoAnnotationResults {
  /**
   * Video file location in
   * [Google Cloud Storage](https://cloud.google.com/storage/).
   */
  inputUri: string;
  /**
   * Label annotations on video level or user specified segment level.
   * There is exactly one element for each unique label.
   */
  segmentLabelAnnotations: LabelAnnotation[];
  /**
   * Label annotations on shot level.
   * There is exactly one element for each unique label.
   */
  shotLabelAnnotations: LabelAnnotation[];
  /**
   * Label annotations on frame level.
   * There is exactly one element for each unique label.
   */
  frameLabelAnnotations: LabelAnnotation[];
  /** Shot annotations. Each shot is represented as a video segment. */
  shotAnnotations: VideoSegment[];
  /** Explicit content annotation. */
  explicitAnnotation:
    | ExplicitContentAnnotation
    | undefined;
  /**
   * OCR text detection and tracking.
   * Annotations for list of detected text snippets. Each will have list of
   * frame information associated with it.
   */
  textAnnotations: TextAnnotation[];
  /** Annotations for list of objects detected and tracked in video. */
  objectAnnotations: ObjectTrackingAnnotation[];
  /**
   * If set, indicates an error. Note that for a single `AnnotateVideoRequest`
   * some videos may succeed and some may fail.
   */
  error: Status | undefined;
}

/**
 * Video annotation response. Included in the `response`
 * field of the `Operation` returned by the `GetOperation`
 * call of the `google::longrunning::Operations` service.
 */
export interface AnnotateVideoResponse {
  /** Annotation results for all videos specified in `AnnotateVideoRequest`. */
  annotationResults: VideoAnnotationResults[];
}

/** Annotation progress for a single video. */
export interface VideoAnnotationProgress {
  /**
   * Video file location in
   * [Google Cloud Storage](https://cloud.google.com/storage/).
   */
  inputUri: string;
  /**
   * Approximate percentage processed thus far. Guaranteed to be
   * 100 when fully processed.
   */
  progressPercent: number;
  /** Time when the request was received. */
  startTime:
    | Date
    | undefined;
  /** Time of the most recent update. */
  updateTime: Date | undefined;
}

/**
 * Video annotation progress. Included in the `metadata`
 * field of the `Operation` returned by the `GetOperation`
 * call of the `google::longrunning::Operations` service.
 */
export interface AnnotateVideoProgress {
  /** Progress metadata for all videos specified in `AnnotateVideoRequest`. */
  annotationProgress: VideoAnnotationProgress[];
}

/**
 * A vertex represents a 2D point in the image.
 * NOTE: the normalized vertex coordinates are relative to the original image
 * and range from 0 to 1.
 */
export interface NormalizedVertex {
  /** X coordinate. */
  x: number;
  /** Y coordinate. */
  y: number;
}

/**
 * Normalized bounding polygon for text (that might not be aligned with axis).
 * Contains list of the corner points in clockwise order starting from
 * top-left corner. For example, for a rectangular bounding box:
 * When the text is horizontal it might look like:
 *         0----1
 *         |    |
 *         3----2
 *
 * When it's clockwise rotated 180 degrees around the top-left corner it
 * becomes:
 *         2----3
 *         |    |
 *         1----0
 *
 * and the vertex order will still be (0, 1, 2, 3). Note that values can be less
 * than 0, or greater than 1 due to trignometric calculations for location of
 * the box.
 */
export interface NormalizedBoundingPoly {
  /** Normalized vertices of the bounding polygon. */
  vertices: NormalizedVertex[];
}

/** Video segment level annotation results for text detection. */
export interface TextSegment {
  /** Video segment where a text snippet was detected. */
  segment:
    | VideoSegment
    | undefined;
  /**
   * Confidence for the track of detected text. It is calculated as the highest
   * over all frames where OCR detected text appears.
   */
  confidence: number;
  /** Information related to the frames where OCR detected text appears. */
  frames: TextFrame[];
}

/**
 * Video frame level annotation results for text annotation (OCR).
 * Contains information regarding timestamp and bounding box locations for the
 * frames containing detected OCR text snippets.
 */
export interface TextFrame {
  /** Bounding polygon of the detected text for this frame. */
  rotatedBoundingBox:
    | NormalizedBoundingPoly
    | undefined;
  /** Timestamp of this frame. */
  timeOffset: Duration | undefined;
}

/**
 * Annotations related to one detected OCR text snippet. This will contain the
 * corresponding text, confidence value, and frame level information for each
 * detection.
 */
export interface TextAnnotation {
  /** The detected text. */
  text: string;
  /** All video segments where OCR detected text appears. */
  segments: TextSegment[];
}

/**
 * Video frame level annotations for object detection and tracking. This field
 * stores per frame location, time offset, and confidence.
 */
export interface ObjectTrackingFrame {
  /** The normalized bounding box location of this object track for the frame. */
  normalizedBoundingBox:
    | NormalizedBoundingBox
    | undefined;
  /** The timestamp of the frame in microseconds. */
  timeOffset: Duration | undefined;
}

/** Annotations corresponding to one tracked object. */
export interface ObjectTrackingAnnotation {
  /**
   * Non-streaming batch mode ONLY.
   * Each object track corresponds to one video segment where it appears.
   */
  segment?:
    | VideoSegment
    | undefined;
  /**
   * Streaming mode ONLY.
   * In streaming mode, we do not know the end time of a tracked object
   * before it is completed. Hence, there is no VideoSegment info returned.
   * Instead, we provide a unique identifiable integer track_id so that
   * the customers can correlate the results of the ongoing
   * ObjectTrackAnnotation of the same track_id over time.
   */
  trackId?:
    | Long
    | undefined;
  /** Entity to specify the object category that this track is labeled as. */
  entity:
    | Entity
    | undefined;
  /** Object category's labeling confidence of this track. */
  confidence: number;
  /** Information corresponding to all frames where this object track appears. */
  frames: ObjectTrackingFrame[];
}

function createBaseAnnotateVideoRequest(): AnnotateVideoRequest {
  return {
    inputUri: "",
    inputContent: Buffer.alloc(0),
    features: [],
    videoContext: undefined,
    outputUri: "",
    locationId: "",
  };
}

export const AnnotateVideoRequest: MessageFns<AnnotateVideoRequest> = {
  encode(message: AnnotateVideoRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.inputUri !== "") {
      writer.uint32(10).string(message.inputUri);
    }
    if (message.inputContent.length !== 0) {
      writer.uint32(50).bytes(message.inputContent);
    }
    writer.uint32(18).fork();
    for (const v of message.features) {
      writer.int32(v);
    }
    writer.join();
    if (message.videoContext !== undefined) {
      VideoContext.encode(message.videoContext, writer.uint32(26).fork()).join();
    }
    if (message.outputUri !== "") {
      writer.uint32(34).string(message.outputUri);
    }
    if (message.locationId !== "") {
      writer.uint32(42).string(message.locationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateVideoRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateVideoRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputUri = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.inputContent = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag === 16) {
            message.features.push(reader.int32() as any);

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.features.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.videoContext = VideoContext.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputUri = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.locationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateVideoRequest {
    return {
      inputUri: isSet(object.inputUri) ? globalThis.String(object.inputUri) : "",
      inputContent: isSet(object.inputContent) ? Buffer.from(bytesFromBase64(object.inputContent)) : Buffer.alloc(0),
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => featureFromJSON(e)) : [],
      videoContext: isSet(object.videoContext) ? VideoContext.fromJSON(object.videoContext) : undefined,
      outputUri: isSet(object.outputUri) ? globalThis.String(object.outputUri) : "",
      locationId: isSet(object.locationId) ? globalThis.String(object.locationId) : "",
    };
  },

  toJSON(message: AnnotateVideoRequest): unknown {
    const obj: any = {};
    if (message.inputUri !== "") {
      obj.inputUri = message.inputUri;
    }
    if (message.inputContent.length !== 0) {
      obj.inputContent = base64FromBytes(message.inputContent);
    }
    if (message.features?.length) {
      obj.features = message.features.map((e) => featureToJSON(e));
    }
    if (message.videoContext !== undefined) {
      obj.videoContext = VideoContext.toJSON(message.videoContext);
    }
    if (message.outputUri !== "") {
      obj.outputUri = message.outputUri;
    }
    if (message.locationId !== "") {
      obj.locationId = message.locationId;
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateVideoRequest>): AnnotateVideoRequest {
    return AnnotateVideoRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateVideoRequest>): AnnotateVideoRequest {
    const message = createBaseAnnotateVideoRequest();
    message.inputUri = object.inputUri ?? "";
    message.inputContent = object.inputContent ?? Buffer.alloc(0);
    message.features = object.features?.map((e) => e) || [];
    message.videoContext = (object.videoContext !== undefined && object.videoContext !== null)
      ? VideoContext.fromPartial(object.videoContext)
      : undefined;
    message.outputUri = object.outputUri ?? "";
    message.locationId = object.locationId ?? "";
    return message;
  },
};

function createBaseVideoContext(): VideoContext {
  return {
    segments: [],
    labelDetectionConfig: undefined,
    shotChangeDetectionConfig: undefined,
    explicitContentDetectionConfig: undefined,
    textDetectionConfig: undefined,
  };
}

export const VideoContext: MessageFns<VideoContext> = {
  encode(message: VideoContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.segments) {
      VideoSegment.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.labelDetectionConfig !== undefined) {
      LabelDetectionConfig.encode(message.labelDetectionConfig, writer.uint32(18).fork()).join();
    }
    if (message.shotChangeDetectionConfig !== undefined) {
      ShotChangeDetectionConfig.encode(message.shotChangeDetectionConfig, writer.uint32(26).fork()).join();
    }
    if (message.explicitContentDetectionConfig !== undefined) {
      ExplicitContentDetectionConfig.encode(message.explicitContentDetectionConfig, writer.uint32(34).fork()).join();
    }
    if (message.textDetectionConfig !== undefined) {
      TextDetectionConfig.encode(message.textDetectionConfig, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.segments.push(VideoSegment.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.labelDetectionConfig = LabelDetectionConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.shotChangeDetectionConfig = ShotChangeDetectionConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.explicitContentDetectionConfig = ExplicitContentDetectionConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.textDetectionConfig = TextDetectionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoContext {
    return {
      segments: globalThis.Array.isArray(object?.segments)
        ? object.segments.map((e: any) => VideoSegment.fromJSON(e))
        : [],
      labelDetectionConfig: isSet(object.labelDetectionConfig)
        ? LabelDetectionConfig.fromJSON(object.labelDetectionConfig)
        : undefined,
      shotChangeDetectionConfig: isSet(object.shotChangeDetectionConfig)
        ? ShotChangeDetectionConfig.fromJSON(object.shotChangeDetectionConfig)
        : undefined,
      explicitContentDetectionConfig: isSet(object.explicitContentDetectionConfig)
        ? ExplicitContentDetectionConfig.fromJSON(object.explicitContentDetectionConfig)
        : undefined,
      textDetectionConfig: isSet(object.textDetectionConfig)
        ? TextDetectionConfig.fromJSON(object.textDetectionConfig)
        : undefined,
    };
  },

  toJSON(message: VideoContext): unknown {
    const obj: any = {};
    if (message.segments?.length) {
      obj.segments = message.segments.map((e) => VideoSegment.toJSON(e));
    }
    if (message.labelDetectionConfig !== undefined) {
      obj.labelDetectionConfig = LabelDetectionConfig.toJSON(message.labelDetectionConfig);
    }
    if (message.shotChangeDetectionConfig !== undefined) {
      obj.shotChangeDetectionConfig = ShotChangeDetectionConfig.toJSON(message.shotChangeDetectionConfig);
    }
    if (message.explicitContentDetectionConfig !== undefined) {
      obj.explicitContentDetectionConfig = ExplicitContentDetectionConfig.toJSON(
        message.explicitContentDetectionConfig,
      );
    }
    if (message.textDetectionConfig !== undefined) {
      obj.textDetectionConfig = TextDetectionConfig.toJSON(message.textDetectionConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<VideoContext>): VideoContext {
    return VideoContext.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoContext>): VideoContext {
    const message = createBaseVideoContext();
    message.segments = object.segments?.map((e) => VideoSegment.fromPartial(e)) || [];
    message.labelDetectionConfig = (object.labelDetectionConfig !== undefined && object.labelDetectionConfig !== null)
      ? LabelDetectionConfig.fromPartial(object.labelDetectionConfig)
      : undefined;
    message.shotChangeDetectionConfig =
      (object.shotChangeDetectionConfig !== undefined && object.shotChangeDetectionConfig !== null)
        ? ShotChangeDetectionConfig.fromPartial(object.shotChangeDetectionConfig)
        : undefined;
    message.explicitContentDetectionConfig =
      (object.explicitContentDetectionConfig !== undefined && object.explicitContentDetectionConfig !== null)
        ? ExplicitContentDetectionConfig.fromPartial(object.explicitContentDetectionConfig)
        : undefined;
    message.textDetectionConfig = (object.textDetectionConfig !== undefined && object.textDetectionConfig !== null)
      ? TextDetectionConfig.fromPartial(object.textDetectionConfig)
      : undefined;
    return message;
  },
};

function createBaseLabelDetectionConfig(): LabelDetectionConfig {
  return { labelDetectionMode: 0, stationaryCamera: false, model: "" };
}

export const LabelDetectionConfig: MessageFns<LabelDetectionConfig> = {
  encode(message: LabelDetectionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.labelDetectionMode !== 0) {
      writer.uint32(8).int32(message.labelDetectionMode);
    }
    if (message.stationaryCamera !== false) {
      writer.uint32(16).bool(message.stationaryCamera);
    }
    if (message.model !== "") {
      writer.uint32(26).string(message.model);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LabelDetectionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLabelDetectionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.labelDetectionMode = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.stationaryCamera = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.model = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LabelDetectionConfig {
    return {
      labelDetectionMode: isSet(object.labelDetectionMode) ? labelDetectionModeFromJSON(object.labelDetectionMode) : 0,
      stationaryCamera: isSet(object.stationaryCamera) ? globalThis.Boolean(object.stationaryCamera) : false,
      model: isSet(object.model) ? globalThis.String(object.model) : "",
    };
  },

  toJSON(message: LabelDetectionConfig): unknown {
    const obj: any = {};
    if (message.labelDetectionMode !== 0) {
      obj.labelDetectionMode = labelDetectionModeToJSON(message.labelDetectionMode);
    }
    if (message.stationaryCamera !== false) {
      obj.stationaryCamera = message.stationaryCamera;
    }
    if (message.model !== "") {
      obj.model = message.model;
    }
    return obj;
  },

  create(base?: DeepPartial<LabelDetectionConfig>): LabelDetectionConfig {
    return LabelDetectionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LabelDetectionConfig>): LabelDetectionConfig {
    const message = createBaseLabelDetectionConfig();
    message.labelDetectionMode = object.labelDetectionMode ?? 0;
    message.stationaryCamera = object.stationaryCamera ?? false;
    message.model = object.model ?? "";
    return message;
  },
};

function createBaseShotChangeDetectionConfig(): ShotChangeDetectionConfig {
  return { model: "" };
}

export const ShotChangeDetectionConfig: MessageFns<ShotChangeDetectionConfig> = {
  encode(message: ShotChangeDetectionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ShotChangeDetectionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseShotChangeDetectionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ShotChangeDetectionConfig {
    return { model: isSet(object.model) ? globalThis.String(object.model) : "" };
  },

  toJSON(message: ShotChangeDetectionConfig): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    return obj;
  },

  create(base?: DeepPartial<ShotChangeDetectionConfig>): ShotChangeDetectionConfig {
    return ShotChangeDetectionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ShotChangeDetectionConfig>): ShotChangeDetectionConfig {
    const message = createBaseShotChangeDetectionConfig();
    message.model = object.model ?? "";
    return message;
  },
};

function createBaseExplicitContentDetectionConfig(): ExplicitContentDetectionConfig {
  return { model: "" };
}

export const ExplicitContentDetectionConfig: MessageFns<ExplicitContentDetectionConfig> = {
  encode(message: ExplicitContentDetectionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplicitContentDetectionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplicitContentDetectionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplicitContentDetectionConfig {
    return { model: isSet(object.model) ? globalThis.String(object.model) : "" };
  },

  toJSON(message: ExplicitContentDetectionConfig): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    return obj;
  },

  create(base?: DeepPartial<ExplicitContentDetectionConfig>): ExplicitContentDetectionConfig {
    return ExplicitContentDetectionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplicitContentDetectionConfig>): ExplicitContentDetectionConfig {
    const message = createBaseExplicitContentDetectionConfig();
    message.model = object.model ?? "";
    return message;
  },
};

function createBaseTextDetectionConfig(): TextDetectionConfig {
  return { languageHints: [] };
}

export const TextDetectionConfig: MessageFns<TextDetectionConfig> = {
  encode(message: TextDetectionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.languageHints) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextDetectionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextDetectionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.languageHints.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextDetectionConfig {
    return {
      languageHints: globalThis.Array.isArray(object?.languageHints)
        ? object.languageHints.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: TextDetectionConfig): unknown {
    const obj: any = {};
    if (message.languageHints?.length) {
      obj.languageHints = message.languageHints;
    }
    return obj;
  },

  create(base?: DeepPartial<TextDetectionConfig>): TextDetectionConfig {
    return TextDetectionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextDetectionConfig>): TextDetectionConfig {
    const message = createBaseTextDetectionConfig();
    message.languageHints = object.languageHints?.map((e) => e) || [];
    return message;
  },
};

function createBaseVideoSegment(): VideoSegment {
  return { startTimeOffset: undefined, endTimeOffset: undefined };
}

export const VideoSegment: MessageFns<VideoSegment> = {
  encode(message: VideoSegment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTimeOffset !== undefined) {
      Duration.encode(message.startTimeOffset, writer.uint32(10).fork()).join();
    }
    if (message.endTimeOffset !== undefined) {
      Duration.encode(message.endTimeOffset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoSegment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTimeOffset = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoSegment {
    return {
      startTimeOffset: isSet(object.startTimeOffset) ? Duration.fromJSON(object.startTimeOffset) : undefined,
      endTimeOffset: isSet(object.endTimeOffset) ? Duration.fromJSON(object.endTimeOffset) : undefined,
    };
  },

  toJSON(message: VideoSegment): unknown {
    const obj: any = {};
    if (message.startTimeOffset !== undefined) {
      obj.startTimeOffset = Duration.toJSON(message.startTimeOffset);
    }
    if (message.endTimeOffset !== undefined) {
      obj.endTimeOffset = Duration.toJSON(message.endTimeOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<VideoSegment>): VideoSegment {
    return VideoSegment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoSegment>): VideoSegment {
    const message = createBaseVideoSegment();
    message.startTimeOffset = (object.startTimeOffset !== undefined && object.startTimeOffset !== null)
      ? Duration.fromPartial(object.startTimeOffset)
      : undefined;
    message.endTimeOffset = (object.endTimeOffset !== undefined && object.endTimeOffset !== null)
      ? Duration.fromPartial(object.endTimeOffset)
      : undefined;
    return message;
  },
};

function createBaseLabelSegment(): LabelSegment {
  return { segment: undefined, confidence: 0 };
}

export const LabelSegment: MessageFns<LabelSegment> = {
  encode(message: LabelSegment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.segment !== undefined) {
      VideoSegment.encode(message.segment, writer.uint32(10).fork()).join();
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LabelSegment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLabelSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.segment = VideoSegment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LabelSegment {
    return {
      segment: isSet(object.segment) ? VideoSegment.fromJSON(object.segment) : undefined,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: LabelSegment): unknown {
    const obj: any = {};
    if (message.segment !== undefined) {
      obj.segment = VideoSegment.toJSON(message.segment);
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create(base?: DeepPartial<LabelSegment>): LabelSegment {
    return LabelSegment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LabelSegment>): LabelSegment {
    const message = createBaseLabelSegment();
    message.segment = (object.segment !== undefined && object.segment !== null)
      ? VideoSegment.fromPartial(object.segment)
      : undefined;
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseLabelFrame(): LabelFrame {
  return { timeOffset: undefined, confidence: 0 };
}

export const LabelFrame: MessageFns<LabelFrame> = {
  encode(message: LabelFrame, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(10).fork()).join();
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LabelFrame {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLabelFrame();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LabelFrame {
    return {
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: LabelFrame): unknown {
    const obj: any = {};
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create(base?: DeepPartial<LabelFrame>): LabelFrame {
    return LabelFrame.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LabelFrame>): LabelFrame {
    const message = createBaseLabelFrame();
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseEntity(): Entity {
  return { entityId: "", description: "", languageCode: "" };
}

export const Entity: MessageFns<Entity> = {
  encode(message: Entity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entityId !== "") {
      writer.uint32(10).string(message.entityId);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.languageCode !== "") {
      writer.uint32(26).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Entity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Entity {
    return {
      entityId: isSet(object.entityId) ? globalThis.String(object.entityId) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: Entity): unknown {
    const obj: any = {};
    if (message.entityId !== "") {
      obj.entityId = message.entityId;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create(base?: DeepPartial<Entity>): Entity {
    return Entity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Entity>): Entity {
    const message = createBaseEntity();
    message.entityId = object.entityId ?? "";
    message.description = object.description ?? "";
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseLabelAnnotation(): LabelAnnotation {
  return { entity: undefined, categoryEntities: [], segments: [], frames: [] };
}

export const LabelAnnotation: MessageFns<LabelAnnotation> = {
  encode(message: LabelAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== undefined) {
      Entity.encode(message.entity, writer.uint32(10).fork()).join();
    }
    for (const v of message.categoryEntities) {
      Entity.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.segments) {
      LabelSegment.encode(v!, writer.uint32(26).fork()).join();
    }
    for (const v of message.frames) {
      LabelFrame.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LabelAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLabelAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entity = Entity.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.categoryEntities.push(Entity.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.segments.push(LabelSegment.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.frames.push(LabelFrame.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LabelAnnotation {
    return {
      entity: isSet(object.entity) ? Entity.fromJSON(object.entity) : undefined,
      categoryEntities: globalThis.Array.isArray(object?.categoryEntities)
        ? object.categoryEntities.map((e: any) => Entity.fromJSON(e))
        : [],
      segments: globalThis.Array.isArray(object?.segments)
        ? object.segments.map((e: any) => LabelSegment.fromJSON(e))
        : [],
      frames: globalThis.Array.isArray(object?.frames) ? object.frames.map((e: any) => LabelFrame.fromJSON(e)) : [],
    };
  },

  toJSON(message: LabelAnnotation): unknown {
    const obj: any = {};
    if (message.entity !== undefined) {
      obj.entity = Entity.toJSON(message.entity);
    }
    if (message.categoryEntities?.length) {
      obj.categoryEntities = message.categoryEntities.map((e) => Entity.toJSON(e));
    }
    if (message.segments?.length) {
      obj.segments = message.segments.map((e) => LabelSegment.toJSON(e));
    }
    if (message.frames?.length) {
      obj.frames = message.frames.map((e) => LabelFrame.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<LabelAnnotation>): LabelAnnotation {
    return LabelAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LabelAnnotation>): LabelAnnotation {
    const message = createBaseLabelAnnotation();
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? Entity.fromPartial(object.entity)
      : undefined;
    message.categoryEntities = object.categoryEntities?.map((e) => Entity.fromPartial(e)) || [];
    message.segments = object.segments?.map((e) => LabelSegment.fromPartial(e)) || [];
    message.frames = object.frames?.map((e) => LabelFrame.fromPartial(e)) || [];
    return message;
  },
};

function createBaseExplicitContentFrame(): ExplicitContentFrame {
  return { timeOffset: undefined, pornographyLikelihood: 0 };
}

export const ExplicitContentFrame: MessageFns<ExplicitContentFrame> = {
  encode(message: ExplicitContentFrame, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(10).fork()).join();
    }
    if (message.pornographyLikelihood !== 0) {
      writer.uint32(16).int32(message.pornographyLikelihood);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplicitContentFrame {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplicitContentFrame();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pornographyLikelihood = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplicitContentFrame {
    return {
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
      pornographyLikelihood: isSet(object.pornographyLikelihood) ? likelihoodFromJSON(object.pornographyLikelihood) : 0,
    };
  },

  toJSON(message: ExplicitContentFrame): unknown {
    const obj: any = {};
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    if (message.pornographyLikelihood !== 0) {
      obj.pornographyLikelihood = likelihoodToJSON(message.pornographyLikelihood);
    }
    return obj;
  },

  create(base?: DeepPartial<ExplicitContentFrame>): ExplicitContentFrame {
    return ExplicitContentFrame.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplicitContentFrame>): ExplicitContentFrame {
    const message = createBaseExplicitContentFrame();
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    message.pornographyLikelihood = object.pornographyLikelihood ?? 0;
    return message;
  },
};

function createBaseExplicitContentAnnotation(): ExplicitContentAnnotation {
  return { frames: [] };
}

export const ExplicitContentAnnotation: MessageFns<ExplicitContentAnnotation> = {
  encode(message: ExplicitContentAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.frames) {
      ExplicitContentFrame.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExplicitContentAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExplicitContentAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.frames.push(ExplicitContentFrame.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExplicitContentAnnotation {
    return {
      frames: globalThis.Array.isArray(object?.frames)
        ? object.frames.map((e: any) => ExplicitContentFrame.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ExplicitContentAnnotation): unknown {
    const obj: any = {};
    if (message.frames?.length) {
      obj.frames = message.frames.map((e) => ExplicitContentFrame.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ExplicitContentAnnotation>): ExplicitContentAnnotation {
    return ExplicitContentAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExplicitContentAnnotation>): ExplicitContentAnnotation {
    const message = createBaseExplicitContentAnnotation();
    message.frames = object.frames?.map((e) => ExplicitContentFrame.fromPartial(e)) || [];
    return message;
  },
};

function createBaseNormalizedBoundingBox(): NormalizedBoundingBox {
  return { left: 0, top: 0, right: 0, bottom: 0 };
}

export const NormalizedBoundingBox: MessageFns<NormalizedBoundingBox> = {
  encode(message: NormalizedBoundingBox, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.left !== 0) {
      writer.uint32(13).float(message.left);
    }
    if (message.top !== 0) {
      writer.uint32(21).float(message.top);
    }
    if (message.right !== 0) {
      writer.uint32(29).float(message.right);
    }
    if (message.bottom !== 0) {
      writer.uint32(37).float(message.bottom);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NormalizedBoundingBox {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNormalizedBoundingBox();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.left = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.top = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.right = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.bottom = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NormalizedBoundingBox {
    return {
      left: isSet(object.left) ? globalThis.Number(object.left) : 0,
      top: isSet(object.top) ? globalThis.Number(object.top) : 0,
      right: isSet(object.right) ? globalThis.Number(object.right) : 0,
      bottom: isSet(object.bottom) ? globalThis.Number(object.bottom) : 0,
    };
  },

  toJSON(message: NormalizedBoundingBox): unknown {
    const obj: any = {};
    if (message.left !== 0) {
      obj.left = message.left;
    }
    if (message.top !== 0) {
      obj.top = message.top;
    }
    if (message.right !== 0) {
      obj.right = message.right;
    }
    if (message.bottom !== 0) {
      obj.bottom = message.bottom;
    }
    return obj;
  },

  create(base?: DeepPartial<NormalizedBoundingBox>): NormalizedBoundingBox {
    return NormalizedBoundingBox.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NormalizedBoundingBox>): NormalizedBoundingBox {
    const message = createBaseNormalizedBoundingBox();
    message.left = object.left ?? 0;
    message.top = object.top ?? 0;
    message.right = object.right ?? 0;
    message.bottom = object.bottom ?? 0;
    return message;
  },
};

function createBaseVideoAnnotationResults(): VideoAnnotationResults {
  return {
    inputUri: "",
    segmentLabelAnnotations: [],
    shotLabelAnnotations: [],
    frameLabelAnnotations: [],
    shotAnnotations: [],
    explicitAnnotation: undefined,
    textAnnotations: [],
    objectAnnotations: [],
    error: undefined,
  };
}

export const VideoAnnotationResults: MessageFns<VideoAnnotationResults> = {
  encode(message: VideoAnnotationResults, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.inputUri !== "") {
      writer.uint32(10).string(message.inputUri);
    }
    for (const v of message.segmentLabelAnnotations) {
      LabelAnnotation.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.shotLabelAnnotations) {
      LabelAnnotation.encode(v!, writer.uint32(26).fork()).join();
    }
    for (const v of message.frameLabelAnnotations) {
      LabelAnnotation.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.shotAnnotations) {
      VideoSegment.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.explicitAnnotation !== undefined) {
      ExplicitContentAnnotation.encode(message.explicitAnnotation, writer.uint32(58).fork()).join();
    }
    for (const v of message.textAnnotations) {
      TextAnnotation.encode(v!, writer.uint32(98).fork()).join();
    }
    for (const v of message.objectAnnotations) {
      ObjectTrackingAnnotation.encode(v!, writer.uint32(114).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoAnnotationResults {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoAnnotationResults();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputUri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.segmentLabelAnnotations.push(LabelAnnotation.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.shotLabelAnnotations.push(LabelAnnotation.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.frameLabelAnnotations.push(LabelAnnotation.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.shotAnnotations.push(VideoSegment.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.explicitAnnotation = ExplicitContentAnnotation.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.textAnnotations.push(TextAnnotation.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.objectAnnotations.push(ObjectTrackingAnnotation.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoAnnotationResults {
    return {
      inputUri: isSet(object.inputUri) ? globalThis.String(object.inputUri) : "",
      segmentLabelAnnotations: globalThis.Array.isArray(object?.segmentLabelAnnotations)
        ? object.segmentLabelAnnotations.map((e: any) => LabelAnnotation.fromJSON(e))
        : [],
      shotLabelAnnotations: globalThis.Array.isArray(object?.shotLabelAnnotations)
        ? object.shotLabelAnnotations.map((e: any) => LabelAnnotation.fromJSON(e))
        : [],
      frameLabelAnnotations: globalThis.Array.isArray(object?.frameLabelAnnotations)
        ? object.frameLabelAnnotations.map((e: any) => LabelAnnotation.fromJSON(e))
        : [],
      shotAnnotations: globalThis.Array.isArray(object?.shotAnnotations)
        ? object.shotAnnotations.map((e: any) => VideoSegment.fromJSON(e))
        : [],
      explicitAnnotation: isSet(object.explicitAnnotation)
        ? ExplicitContentAnnotation.fromJSON(object.explicitAnnotation)
        : undefined,
      textAnnotations: globalThis.Array.isArray(object?.textAnnotations)
        ? object.textAnnotations.map((e: any) => TextAnnotation.fromJSON(e))
        : [],
      objectAnnotations: globalThis.Array.isArray(object?.objectAnnotations)
        ? object.objectAnnotations.map((e: any) => ObjectTrackingAnnotation.fromJSON(e))
        : [],
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
    };
  },

  toJSON(message: VideoAnnotationResults): unknown {
    const obj: any = {};
    if (message.inputUri !== "") {
      obj.inputUri = message.inputUri;
    }
    if (message.segmentLabelAnnotations?.length) {
      obj.segmentLabelAnnotations = message.segmentLabelAnnotations.map((e) => LabelAnnotation.toJSON(e));
    }
    if (message.shotLabelAnnotations?.length) {
      obj.shotLabelAnnotations = message.shotLabelAnnotations.map((e) => LabelAnnotation.toJSON(e));
    }
    if (message.frameLabelAnnotations?.length) {
      obj.frameLabelAnnotations = message.frameLabelAnnotations.map((e) => LabelAnnotation.toJSON(e));
    }
    if (message.shotAnnotations?.length) {
      obj.shotAnnotations = message.shotAnnotations.map((e) => VideoSegment.toJSON(e));
    }
    if (message.explicitAnnotation !== undefined) {
      obj.explicitAnnotation = ExplicitContentAnnotation.toJSON(message.explicitAnnotation);
    }
    if (message.textAnnotations?.length) {
      obj.textAnnotations = message.textAnnotations.map((e) => TextAnnotation.toJSON(e));
    }
    if (message.objectAnnotations?.length) {
      obj.objectAnnotations = message.objectAnnotations.map((e) => ObjectTrackingAnnotation.toJSON(e));
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    return obj;
  },

  create(base?: DeepPartial<VideoAnnotationResults>): VideoAnnotationResults {
    return VideoAnnotationResults.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoAnnotationResults>): VideoAnnotationResults {
    const message = createBaseVideoAnnotationResults();
    message.inputUri = object.inputUri ?? "";
    message.segmentLabelAnnotations = object.segmentLabelAnnotations?.map((e) => LabelAnnotation.fromPartial(e)) || [];
    message.shotLabelAnnotations = object.shotLabelAnnotations?.map((e) => LabelAnnotation.fromPartial(e)) || [];
    message.frameLabelAnnotations = object.frameLabelAnnotations?.map((e) => LabelAnnotation.fromPartial(e)) || [];
    message.shotAnnotations = object.shotAnnotations?.map((e) => VideoSegment.fromPartial(e)) || [];
    message.explicitAnnotation = (object.explicitAnnotation !== undefined && object.explicitAnnotation !== null)
      ? ExplicitContentAnnotation.fromPartial(object.explicitAnnotation)
      : undefined;
    message.textAnnotations = object.textAnnotations?.map((e) => TextAnnotation.fromPartial(e)) || [];
    message.objectAnnotations = object.objectAnnotations?.map((e) => ObjectTrackingAnnotation.fromPartial(e)) || [];
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    return message;
  },
};

function createBaseAnnotateVideoResponse(): AnnotateVideoResponse {
  return { annotationResults: [] };
}

export const AnnotateVideoResponse: MessageFns<AnnotateVideoResponse> = {
  encode(message: AnnotateVideoResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.annotationResults) {
      VideoAnnotationResults.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateVideoResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateVideoResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationResults.push(VideoAnnotationResults.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateVideoResponse {
    return {
      annotationResults: globalThis.Array.isArray(object?.annotationResults)
        ? object.annotationResults.map((e: any) => VideoAnnotationResults.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnnotateVideoResponse): unknown {
    const obj: any = {};
    if (message.annotationResults?.length) {
      obj.annotationResults = message.annotationResults.map((e) => VideoAnnotationResults.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateVideoResponse>): AnnotateVideoResponse {
    return AnnotateVideoResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateVideoResponse>): AnnotateVideoResponse {
    const message = createBaseAnnotateVideoResponse();
    message.annotationResults = object.annotationResults?.map((e) => VideoAnnotationResults.fromPartial(e)) || [];
    return message;
  },
};

function createBaseVideoAnnotationProgress(): VideoAnnotationProgress {
  return { inputUri: "", progressPercent: 0, startTime: undefined, updateTime: undefined };
}

export const VideoAnnotationProgress: MessageFns<VideoAnnotationProgress> = {
  encode(message: VideoAnnotationProgress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.inputUri !== "") {
      writer.uint32(10).string(message.inputUri);
    }
    if (message.progressPercent !== 0) {
      writer.uint32(16).int32(message.progressPercent);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoAnnotationProgress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoAnnotationProgress();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputUri = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.progressPercent = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoAnnotationProgress {
    return {
      inputUri: isSet(object.inputUri) ? globalThis.String(object.inputUri) : "",
      progressPercent: isSet(object.progressPercent) ? globalThis.Number(object.progressPercent) : 0,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: VideoAnnotationProgress): unknown {
    const obj: any = {};
    if (message.inputUri !== "") {
      obj.inputUri = message.inputUri;
    }
    if (message.progressPercent !== 0) {
      obj.progressPercent = Math.round(message.progressPercent);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<VideoAnnotationProgress>): VideoAnnotationProgress {
    return VideoAnnotationProgress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoAnnotationProgress>): VideoAnnotationProgress {
    const message = createBaseVideoAnnotationProgress();
    message.inputUri = object.inputUri ?? "";
    message.progressPercent = object.progressPercent ?? 0;
    message.startTime = object.startTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseAnnotateVideoProgress(): AnnotateVideoProgress {
  return { annotationProgress: [] };
}

export const AnnotateVideoProgress: MessageFns<AnnotateVideoProgress> = {
  encode(message: AnnotateVideoProgress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.annotationProgress) {
      VideoAnnotationProgress.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnnotateVideoProgress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnnotateVideoProgress();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.annotationProgress.push(VideoAnnotationProgress.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnnotateVideoProgress {
    return {
      annotationProgress: globalThis.Array.isArray(object?.annotationProgress)
        ? object.annotationProgress.map((e: any) => VideoAnnotationProgress.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AnnotateVideoProgress): unknown {
    const obj: any = {};
    if (message.annotationProgress?.length) {
      obj.annotationProgress = message.annotationProgress.map((e) => VideoAnnotationProgress.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AnnotateVideoProgress>): AnnotateVideoProgress {
    return AnnotateVideoProgress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AnnotateVideoProgress>): AnnotateVideoProgress {
    const message = createBaseAnnotateVideoProgress();
    message.annotationProgress = object.annotationProgress?.map((e) => VideoAnnotationProgress.fromPartial(e)) || [];
    return message;
  },
};

function createBaseNormalizedVertex(): NormalizedVertex {
  return { x: 0, y: 0 };
}

export const NormalizedVertex: MessageFns<NormalizedVertex> = {
  encode(message: NormalizedVertex, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.x !== 0) {
      writer.uint32(13).float(message.x);
    }
    if (message.y !== 0) {
      writer.uint32(21).float(message.y);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NormalizedVertex {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNormalizedVertex();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.x = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.y = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NormalizedVertex {
    return {
      x: isSet(object.x) ? globalThis.Number(object.x) : 0,
      y: isSet(object.y) ? globalThis.Number(object.y) : 0,
    };
  },

  toJSON(message: NormalizedVertex): unknown {
    const obj: any = {};
    if (message.x !== 0) {
      obj.x = message.x;
    }
    if (message.y !== 0) {
      obj.y = message.y;
    }
    return obj;
  },

  create(base?: DeepPartial<NormalizedVertex>): NormalizedVertex {
    return NormalizedVertex.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NormalizedVertex>): NormalizedVertex {
    const message = createBaseNormalizedVertex();
    message.x = object.x ?? 0;
    message.y = object.y ?? 0;
    return message;
  },
};

function createBaseNormalizedBoundingPoly(): NormalizedBoundingPoly {
  return { vertices: [] };
}

export const NormalizedBoundingPoly: MessageFns<NormalizedBoundingPoly> = {
  encode(message: NormalizedBoundingPoly, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.vertices) {
      NormalizedVertex.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NormalizedBoundingPoly {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNormalizedBoundingPoly();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vertices.push(NormalizedVertex.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NormalizedBoundingPoly {
    return {
      vertices: globalThis.Array.isArray(object?.vertices)
        ? object.vertices.map((e: any) => NormalizedVertex.fromJSON(e))
        : [],
    };
  },

  toJSON(message: NormalizedBoundingPoly): unknown {
    const obj: any = {};
    if (message.vertices?.length) {
      obj.vertices = message.vertices.map((e) => NormalizedVertex.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<NormalizedBoundingPoly>): NormalizedBoundingPoly {
    return NormalizedBoundingPoly.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NormalizedBoundingPoly>): NormalizedBoundingPoly {
    const message = createBaseNormalizedBoundingPoly();
    message.vertices = object.vertices?.map((e) => NormalizedVertex.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTextSegment(): TextSegment {
  return { segment: undefined, confidence: 0, frames: [] };
}

export const TextSegment: MessageFns<TextSegment> = {
  encode(message: TextSegment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.segment !== undefined) {
      VideoSegment.encode(message.segment, writer.uint32(10).fork()).join();
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    for (const v of message.frames) {
      TextFrame.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextSegment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.segment = VideoSegment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.frames.push(TextFrame.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextSegment {
    return {
      segment: isSet(object.segment) ? VideoSegment.fromJSON(object.segment) : undefined,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      frames: globalThis.Array.isArray(object?.frames) ? object.frames.map((e: any) => TextFrame.fromJSON(e)) : [],
    };
  },

  toJSON(message: TextSegment): unknown {
    const obj: any = {};
    if (message.segment !== undefined) {
      obj.segment = VideoSegment.toJSON(message.segment);
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.frames?.length) {
      obj.frames = message.frames.map((e) => TextFrame.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TextSegment>): TextSegment {
    return TextSegment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextSegment>): TextSegment {
    const message = createBaseTextSegment();
    message.segment = (object.segment !== undefined && object.segment !== null)
      ? VideoSegment.fromPartial(object.segment)
      : undefined;
    message.confidence = object.confidence ?? 0;
    message.frames = object.frames?.map((e) => TextFrame.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTextFrame(): TextFrame {
  return { rotatedBoundingBox: undefined, timeOffset: undefined };
}

export const TextFrame: MessageFns<TextFrame> = {
  encode(message: TextFrame, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rotatedBoundingBox !== undefined) {
      NormalizedBoundingPoly.encode(message.rotatedBoundingBox, writer.uint32(10).fork()).join();
    }
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextFrame {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextFrame();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rotatedBoundingBox = NormalizedBoundingPoly.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextFrame {
    return {
      rotatedBoundingBox: isSet(object.rotatedBoundingBox)
        ? NormalizedBoundingPoly.fromJSON(object.rotatedBoundingBox)
        : undefined,
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
    };
  },

  toJSON(message: TextFrame): unknown {
    const obj: any = {};
    if (message.rotatedBoundingBox !== undefined) {
      obj.rotatedBoundingBox = NormalizedBoundingPoly.toJSON(message.rotatedBoundingBox);
    }
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<TextFrame>): TextFrame {
    return TextFrame.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextFrame>): TextFrame {
    const message = createBaseTextFrame();
    message.rotatedBoundingBox = (object.rotatedBoundingBox !== undefined && object.rotatedBoundingBox !== null)
      ? NormalizedBoundingPoly.fromPartial(object.rotatedBoundingBox)
      : undefined;
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    return message;
  },
};

function createBaseTextAnnotation(): TextAnnotation {
  return { text: "", segments: [] };
}

export const TextAnnotation: MessageFns<TextAnnotation> = {
  encode(message: TextAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    for (const v of message.segments) {
      TextSegment.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.segments.push(TextSegment.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextAnnotation {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : "",
      segments: globalThis.Array.isArray(object?.segments)
        ? object.segments.map((e: any) => TextSegment.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TextAnnotation): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    if (message.segments?.length) {
      obj.segments = message.segments.map((e) => TextSegment.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<TextAnnotation>): TextAnnotation {
    return TextAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextAnnotation>): TextAnnotation {
    const message = createBaseTextAnnotation();
    message.text = object.text ?? "";
    message.segments = object.segments?.map((e) => TextSegment.fromPartial(e)) || [];
    return message;
  },
};

function createBaseObjectTrackingFrame(): ObjectTrackingFrame {
  return { normalizedBoundingBox: undefined, timeOffset: undefined };
}

export const ObjectTrackingFrame: MessageFns<ObjectTrackingFrame> = {
  encode(message: ObjectTrackingFrame, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.normalizedBoundingBox !== undefined) {
      NormalizedBoundingBox.encode(message.normalizedBoundingBox, writer.uint32(10).fork()).join();
    }
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectTrackingFrame {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectTrackingFrame();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.normalizedBoundingBox = NormalizedBoundingBox.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectTrackingFrame {
    return {
      normalizedBoundingBox: isSet(object.normalizedBoundingBox)
        ? NormalizedBoundingBox.fromJSON(object.normalizedBoundingBox)
        : undefined,
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
    };
  },

  toJSON(message: ObjectTrackingFrame): unknown {
    const obj: any = {};
    if (message.normalizedBoundingBox !== undefined) {
      obj.normalizedBoundingBox = NormalizedBoundingBox.toJSON(message.normalizedBoundingBox);
    }
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectTrackingFrame>): ObjectTrackingFrame {
    return ObjectTrackingFrame.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectTrackingFrame>): ObjectTrackingFrame {
    const message = createBaseObjectTrackingFrame();
    message.normalizedBoundingBox =
      (object.normalizedBoundingBox !== undefined && object.normalizedBoundingBox !== null)
        ? NormalizedBoundingBox.fromPartial(object.normalizedBoundingBox)
        : undefined;
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    return message;
  },
};

function createBaseObjectTrackingAnnotation(): ObjectTrackingAnnotation {
  return { segment: undefined, trackId: undefined, entity: undefined, confidence: 0, frames: [] };
}

export const ObjectTrackingAnnotation: MessageFns<ObjectTrackingAnnotation> = {
  encode(message: ObjectTrackingAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.segment !== undefined) {
      VideoSegment.encode(message.segment, writer.uint32(26).fork()).join();
    }
    if (message.trackId !== undefined) {
      writer.uint32(40).int64(message.trackId.toString());
    }
    if (message.entity !== undefined) {
      Entity.encode(message.entity, writer.uint32(10).fork()).join();
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    for (const v of message.frames) {
      ObjectTrackingFrame.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectTrackingAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectTrackingAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.segment = VideoSegment.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.trackId = Long.fromString(reader.int64().toString());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entity = Entity.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.frames.push(ObjectTrackingFrame.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectTrackingAnnotation {
    return {
      segment: isSet(object.segment) ? VideoSegment.fromJSON(object.segment) : undefined,
      trackId: isSet(object.trackId) ? Long.fromValue(object.trackId) : undefined,
      entity: isSet(object.entity) ? Entity.fromJSON(object.entity) : undefined,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      frames: globalThis.Array.isArray(object?.frames)
        ? object.frames.map((e: any) => ObjectTrackingFrame.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ObjectTrackingAnnotation): unknown {
    const obj: any = {};
    if (message.segment !== undefined) {
      obj.segment = VideoSegment.toJSON(message.segment);
    }
    if (message.trackId !== undefined) {
      obj.trackId = (message.trackId || Long.ZERO).toString();
    }
    if (message.entity !== undefined) {
      obj.entity = Entity.toJSON(message.entity);
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.frames?.length) {
      obj.frames = message.frames.map((e) => ObjectTrackingFrame.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectTrackingAnnotation>): ObjectTrackingAnnotation {
    return ObjectTrackingAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectTrackingAnnotation>): ObjectTrackingAnnotation {
    const message = createBaseObjectTrackingAnnotation();
    message.segment = (object.segment !== undefined && object.segment !== null)
      ? VideoSegment.fromPartial(object.segment)
      : undefined;
    message.trackId = (object.trackId !== undefined && object.trackId !== null)
      ? Long.fromValue(object.trackId)
      : undefined;
    message.entity = (object.entity !== undefined && object.entity !== null)
      ? Entity.fromPartial(object.entity)
      : undefined;
    message.confidence = object.confidence ?? 0;
    message.frames = object.frames?.map((e) => ObjectTrackingFrame.fromPartial(e)) || [];
    return message;
  },
};

/** Service that implements Google Cloud Video Intelligence API. */
export type VideoIntelligenceServiceDefinition = typeof VideoIntelligenceServiceDefinition;
export const VideoIntelligenceServiceDefinition = {
  name: "VideoIntelligenceService",
  fullName: "google.cloud.videointelligence.v1p2beta1.VideoIntelligenceService",
  methods: {
    /**
     * Performs asynchronous video annotation. Progress and results can be
     * retrieved through the `google.longrunning.Operations` interface.
     * `Operation.metadata` contains `AnnotateVideoProgress` (progress).
     * `Operation.response` contains `AnnotateVideoResponse` (results).
     */
    annotateVideo: {
      name: "AnnotateVideo",
      requestType: AnnotateVideoRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              46,
              10,
              21,
              65,
              110,
              110,
              111,
              116,
              97,
              116,
              101,
              86,
              105,
              100,
              101,
              111,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              21,
              65,
              110,
              110,
              111,
              116,
              97,
              116,
              101,
              86,
              105,
              100,
              101,
              111,
              80,
              114,
              111,
              103,
              114,
              101,
              115,
              115,
            ]),
          ],
          8410: [
            Buffer.from([18, 105, 110, 112, 117, 116, 95, 117, 114, 105, 44, 102, 101, 97, 116, 117, 114, 101, 115]),
          ],
          578365826: [
            Buffer.from([
              31,
              58,
              1,
              42,
              34,
              26,
              47,
              118,
              49,
              112,
              50,
              98,
              101,
              116,
              97,
              49,
              47,
              118,
              105,
              100,
              101,
              111,
              115,
              58,
              97,
              110,
              110,
              111,
              116,
              97,
              116,
              101,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface VideoIntelligenceServiceImplementation<CallContextExt = {}> {
  /**
   * Performs asynchronous video annotation. Progress and results can be
   * retrieved through the `google.longrunning.Operations` interface.
   * `Operation.metadata` contains `AnnotateVideoProgress` (progress).
   * `Operation.response` contains `AnnotateVideoResponse` (results).
   */
  annotateVideo(request: AnnotateVideoRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
}

export interface VideoIntelligenceServiceClient<CallOptionsExt = {}> {
  /**
   * Performs asynchronous video annotation. Progress and results can be
   * retrieved through the `google.longrunning.Operations` interface.
   * `Operation.metadata` contains `AnnotateVideoProgress` (progress).
   * `Operation.response` contains `AnnotateVideoResponse` (results).
   */
  annotateVideo(request: DeepPartial<AnnotateVideoRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
