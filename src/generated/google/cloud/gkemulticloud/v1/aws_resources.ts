// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/gkemulticloud/v1/aws_resources.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { DateMessage } from "../../../type/date.js";
import {
  BinaryAuthorization,
  Fleet,
  Jwk,
  LoggingConfig,
  MaxPodsConstraint,
  MonitoringConfig,
  NodeKubeletConfig,
  NodeTaint,
  WorkloadIdentityConfig,
} from "./common_resources.js";

export const protobufPackage = "google.cloud.gkemulticloud.v1";

/** An Anthos cluster running on AWS. */
export interface AwsCluster {
  /**
   * The name of this resource.
   *
   * Cluster names are formatted as
   * `projects/<project-number>/locations/<region>/awsClusters/<cluster-id>`.
   *
   * See [Resource Names](https://cloud.google.com/apis/design/resource_names)
   * for more details on Google Cloud Platform resource names.
   */
  name: string;
  /**
   * Optional. A human readable description of this cluster.
   * Cannot be longer than 255 UTF-8 encoded bytes.
   */
  description: string;
  /** Required. Cluster-wide networking configuration. */
  networking:
    | AwsClusterNetworking
    | undefined;
  /**
   * Required. The AWS region where the cluster runs.
   *
   * Each Google Cloud region supports a subset of nearby AWS regions.
   * You can call
   * [GetAwsServerConfig][google.cloud.gkemulticloud.v1.AwsClusters.GetAwsServerConfig]
   * to list all supported AWS regions within a given Google Cloud region.
   */
  awsRegion: string;
  /** Required. Configuration related to the cluster control plane. */
  controlPlane:
    | AwsControlPlane
    | undefined;
  /** Required. Configuration related to the cluster RBAC settings. */
  authorization:
    | AwsAuthorization
    | undefined;
  /** Output only. The current state of the cluster. */
  state: AwsCluster_State;
  /** Output only. The endpoint of the cluster's API server. */
  endpoint: string;
  /** Output only. A globally unique identifier for the cluster. */
  uid: string;
  /** Output only. If set, there are currently changes in flight to the cluster. */
  reconciling: boolean;
  /** Output only. The time at which this cluster was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time at which this cluster was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Allows clients to perform consistent read-modify-writes
   * through optimistic concurrency control.
   *
   * Can be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Optional. Annotations on the cluster.
   *
   * This field has the same restrictions as Kubernetes annotations.
   * The total size of all keys and values combined is limited to 256k.
   * Key can have 2 segments: prefix (optional) and name (required),
   * separated by a slash (/).
   * Prefix must be a DNS subdomain.
   * Name must be 63 characters or less, begin and end with alphanumerics,
   * with dashes (-), underscores (_), dots (.), and alphanumerics between.
   */
  annotations: { [key: string]: string };
  /** Output only. Workload Identity settings. */
  workloadIdentityConfig:
    | WorkloadIdentityConfig
    | undefined;
  /** Output only. PEM encoded x509 certificate of the cluster root of trust. */
  clusterCaCertificate: string;
  /** Required. Fleet configuration. */
  fleet:
    | Fleet
    | undefined;
  /** Optional. Logging configuration for this cluster. */
  loggingConfig:
    | LoggingConfig
    | undefined;
  /** Output only. A set of errors found in the cluster. */
  errors: AwsClusterError[];
  /** Optional. Monitoring configuration for this cluster. */
  monitoringConfig:
    | MonitoringConfig
    | undefined;
  /** Optional. Binary Authorization configuration for this cluster. */
  binaryAuthorization: BinaryAuthorization | undefined;
}

/** The lifecycle state of the cluster. */
export enum AwsCluster_State {
  /** STATE_UNSPECIFIED - Not set. */
  STATE_UNSPECIFIED = 0,
  /** PROVISIONING - The PROVISIONING state indicates the cluster is being created. */
  PROVISIONING = 1,
  /**
   * RUNNING - The RUNNING state indicates the cluster has been created and is fully
   * usable.
   */
  RUNNING = 2,
  /**
   * RECONCILING - The RECONCILING state indicates that some work is actively being done on
   * the cluster, such as upgrading the control plane replicas.
   */
  RECONCILING = 3,
  /** STOPPING - The STOPPING state indicates the cluster is being deleted. */
  STOPPING = 4,
  /**
   * ERROR - The ERROR state indicates the cluster is in a broken unrecoverable
   * state.
   */
  ERROR = 5,
  /**
   * DEGRADED - The DEGRADED state indicates the cluster requires user action to
   * restore full functionality.
   */
  DEGRADED = 6,
  UNRECOGNIZED = -1,
}

export function awsCluster_StateFromJSON(object: any): AwsCluster_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return AwsCluster_State.STATE_UNSPECIFIED;
    case 1:
    case "PROVISIONING":
      return AwsCluster_State.PROVISIONING;
    case 2:
    case "RUNNING":
      return AwsCluster_State.RUNNING;
    case 3:
    case "RECONCILING":
      return AwsCluster_State.RECONCILING;
    case 4:
    case "STOPPING":
      return AwsCluster_State.STOPPING;
    case 5:
    case "ERROR":
      return AwsCluster_State.ERROR;
    case 6:
    case "DEGRADED":
      return AwsCluster_State.DEGRADED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AwsCluster_State.UNRECOGNIZED;
  }
}

export function awsCluster_StateToJSON(object: AwsCluster_State): string {
  switch (object) {
    case AwsCluster_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case AwsCluster_State.PROVISIONING:
      return "PROVISIONING";
    case AwsCluster_State.RUNNING:
      return "RUNNING";
    case AwsCluster_State.RECONCILING:
      return "RECONCILING";
    case AwsCluster_State.STOPPING:
      return "STOPPING";
    case AwsCluster_State.ERROR:
      return "ERROR";
    case AwsCluster_State.DEGRADED:
      return "DEGRADED";
    case AwsCluster_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface AwsCluster_AnnotationsEntry {
  key: string;
  value: string;
}

/** ControlPlane defines common parameters between control plane nodes. */
export interface AwsControlPlane {
  /**
   * Required. The Kubernetes version to run on control plane replicas
   * (e.g. `1.19.10-gke.1000`).
   *
   * You can list all supported versions on a given Google Cloud region by
   * calling
   * [GetAwsServerConfig][google.cloud.gkemulticloud.v1.AwsClusters.GetAwsServerConfig].
   */
  version: string;
  /**
   * Optional. The AWS instance type.
   *
   * When unspecified, it uses a default based on the cluster's version.
   */
  instanceType: string;
  /**
   * Optional. SSH configuration for how to access the underlying control plane
   * machines.
   */
  sshConfig:
    | AwsSshConfig
    | undefined;
  /**
   * Required. The list of subnets where control plane replicas will run.
   * A replica will be provisioned on each subnet and up to three values
   * can be provided.
   * Each subnet must be in a different AWS Availability Zone (AZ).
   */
  subnetIds: string[];
  /**
   * Optional. The IDs of additional security groups to add to control plane
   * replicas. The Anthos Multi-Cloud API will automatically create and manage
   * security groups with the minimum rules needed for a functioning cluster.
   */
  securityGroupIds: string[];
  /**
   * Required. The name or ARN of the AWS IAM instance profile to assign to each
   * control plane replica.
   */
  iamInstanceProfile: string;
  /**
   * Optional. Configuration related to the root volume provisioned for each
   * control plane replica.
   *
   * Volumes will be provisioned in the availability zone associated
   * with the corresponding subnet.
   *
   * When unspecified, it defaults to 32 GiB with the GP2 volume type.
   */
  rootVolume:
    | AwsVolumeTemplate
    | undefined;
  /**
   * Optional. Configuration related to the main volume provisioned for each
   * control plane replica.
   * The main volume is in charge of storing all of the cluster's etcd state.
   *
   * Volumes will be provisioned in the availability zone associated
   * with the corresponding subnet.
   *
   * When unspecified, it defaults to 8 GiB with the GP2 volume type.
   */
  mainVolume:
    | AwsVolumeTemplate
    | undefined;
  /** Required. The ARN of the AWS KMS key used to encrypt cluster secrets. */
  databaseEncryption:
    | AwsDatabaseEncryption
    | undefined;
  /**
   * Optional. A set of AWS resource tags to propagate to all underlying managed
   * AWS resources.
   *
   * Specify at most 50 pairs containing alphanumerics, spaces, and symbols
   * (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to
   * 255 Unicode characters.
   */
  tags: { [key: string]: string };
  /** Required. Authentication configuration for management of AWS resources. */
  awsServicesAuthentication:
    | AwsServicesAuthentication
    | undefined;
  /** Optional. Proxy configuration for outbound HTTP(S) traffic. */
  proxyConfig:
    | AwsProxyConfig
    | undefined;
  /** Required. Config encryption for user data. */
  configEncryption:
    | AwsConfigEncryption
    | undefined;
  /**
   * Optional. The placement to use on control plane instances.
   * When unspecified, the VPC's default tenancy will be used.
   */
  instancePlacement: AwsInstancePlacement | undefined;
}

export interface AwsControlPlane_TagsEntry {
  key: string;
  value: string;
}

/** Authentication configuration for the management of AWS resources. */
export interface AwsServicesAuthentication {
  /**
   * Required. The Amazon Resource Name (ARN) of the role that the Anthos
   * Multi-Cloud API will assume when managing AWS resources on your account.
   */
  roleArn: string;
  /**
   * Optional. An identifier for the assumed role session.
   *
   * When unspecified, it defaults to `multicloud-service-agent`.
   */
  roleSessionName: string;
}

/** Configuration related to the cluster RBAC settings. */
export interface AwsAuthorization {
  /**
   * Optional. Users that can perform operations as a cluster admin. A managed
   * ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
   * to the users. Up to ten admin users can be provided.
   *
   * For more info on RBAC, see
   * https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
   */
  adminUsers: AwsClusterUser[];
  /**
   * Optional. Groups of users that can perform operations as a cluster admin. A
   * managed ClusterRoleBinding will be created to grant the `cluster-admin`
   * ClusterRole to the groups. Up to ten admin groups can be provided.
   *
   * For more info on RBAC, see
   * https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
   */
  adminGroups: AwsClusterGroup[];
}

/** Identities of a user-type subject for AWS clusters. */
export interface AwsClusterUser {
  /** Required. The name of the user, e.g. `my-gcp-id@gmail.com`. */
  username: string;
}

/** Identities of a group-type subject for AWS clusters. */
export interface AwsClusterGroup {
  /** Required. The name of the group, e.g. `my-group@domain.com`. */
  group: string;
}

/** Configuration related to application-layer secrets encryption. */
export interface AwsDatabaseEncryption {
  /** Required. The ARN of the AWS KMS key used to encrypt cluster secrets. */
  kmsKeyArn: string;
}

/** Configuration template for AWS EBS volumes. */
export interface AwsVolumeTemplate {
  /**
   * Optional. The size of the volume, in GiBs.
   *
   * When unspecified, a default value is provided. See the specific reference
   * in the parent resource.
   */
  sizeGib: number;
  /**
   * Optional. Type of the EBS volume.
   *
   * When unspecified, it defaults to GP2 volume.
   */
  volumeType: AwsVolumeTemplate_VolumeType;
  /**
   * Optional. The number of I/O operations per second (IOPS) to provision for
   * GP3 volume.
   */
  iops: number;
  /**
   * Optional. The throughput that the volume supports, in MiB/s. Only valid if
   * volume_type is GP3.
   *
   * If the volume_type is GP3 and this is not speficied, it defaults to 125.
   */
  throughput: number;
  /**
   * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK)
   * used to encrypt AWS EBS volumes.
   *
   * If not specified, the default Amazon managed key associated to
   * the AWS region where this cluster runs will be used.
   */
  kmsKeyArn: string;
}

/**
 * Types of supported EBS volumes. We currently only support GP2 or GP3
 * volumes.
 * See https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html
 * for more information.
 */
export enum AwsVolumeTemplate_VolumeType {
  /** VOLUME_TYPE_UNSPECIFIED - Not set. */
  VOLUME_TYPE_UNSPECIFIED = 0,
  /** GP2 - GP2 (General Purpose SSD volume type). */
  GP2 = 1,
  /** GP3 - GP3 (General Purpose SSD volume type). */
  GP3 = 2,
  UNRECOGNIZED = -1,
}

export function awsVolumeTemplate_VolumeTypeFromJSON(object: any): AwsVolumeTemplate_VolumeType {
  switch (object) {
    case 0:
    case "VOLUME_TYPE_UNSPECIFIED":
      return AwsVolumeTemplate_VolumeType.VOLUME_TYPE_UNSPECIFIED;
    case 1:
    case "GP2":
      return AwsVolumeTemplate_VolumeType.GP2;
    case 2:
    case "GP3":
      return AwsVolumeTemplate_VolumeType.GP3;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AwsVolumeTemplate_VolumeType.UNRECOGNIZED;
  }
}

export function awsVolumeTemplate_VolumeTypeToJSON(object: AwsVolumeTemplate_VolumeType): string {
  switch (object) {
    case AwsVolumeTemplate_VolumeType.VOLUME_TYPE_UNSPECIFIED:
      return "VOLUME_TYPE_UNSPECIFIED";
    case AwsVolumeTemplate_VolumeType.GP2:
      return "GP2";
    case AwsVolumeTemplate_VolumeType.GP3:
      return "GP3";
    case AwsVolumeTemplate_VolumeType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * ClusterNetworking defines cluster-wide networking configuration.
 *
 * Anthos clusters on AWS run on a single VPC. This includes control
 * plane replicas and node pool nodes.
 */
export interface AwsClusterNetworking {
  /**
   * Required. The VPC associated with the cluster. All component clusters
   * (i.e. control plane and node pools) run on a single VPC.
   *
   * This field cannot be changed after creation.
   */
  vpcId: string;
  /**
   * Required. All pods in the cluster are assigned an IPv4 address from these
   * ranges. Only a single range is supported. This field cannot be changed
   * after creation.
   */
  podAddressCidrBlocks: string[];
  /**
   * Required. All services in the cluster are assigned an IPv4 address from
   * these ranges. Only a single range is supported. This field cannot be
   * changed after creation.
   */
  serviceAddressCidrBlocks: string[];
  /**
   * Optional. Disable the per node pool subnet security group rules on the
   * control plane security group. When set to true, you must also provide one
   * or more security groups that ensure node pools are able to send requests to
   * the control plane on TCP/443 and TCP/8132. Failure to do so may result in
   * unavailable node pools.
   */
  perNodePoolSgRulesDisabled: boolean;
}

/** An Anthos node pool running on AWS. */
export interface AwsNodePool {
  /**
   * The name of this resource.
   *
   * Node pool names are formatted as
   * `projects/<project-number>/locations/<region>/awsClusters/<cluster-id>/awsNodePools/<node-pool-id>`.
   *
   * For more details on Google Cloud resource names,
   * see [Resource Names](https://cloud.google.com/apis/design/resource_names)
   */
  name: string;
  /**
   * Required. The Kubernetes version to run on this node pool (e.g.
   * `1.19.10-gke.1000`).
   *
   * You can list all supported versions on a given Google Cloud region by
   * calling
   * [GetAwsServerConfig][google.cloud.gkemulticloud.v1.AwsClusters.GetAwsServerConfig].
   */
  version: string;
  /** Required. The configuration of the node pool. */
  config:
    | AwsNodeConfig
    | undefined;
  /** Required. Autoscaler configuration for this node pool. */
  autoscaling:
    | AwsNodePoolAutoscaling
    | undefined;
  /** Required. The subnet where the node pool node run. */
  subnetId: string;
  /** Output only. The lifecycle state of the node pool. */
  state: AwsNodePool_State;
  /** Output only. A globally unique identifier for the node pool. */
  uid: string;
  /**
   * Output only. If set, there are currently changes in flight to the node
   * pool.
   */
  reconciling: boolean;
  /** Output only. The time at which this node pool was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time at which this node pool was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Allows clients to perform consistent read-modify-writes
   * through optimistic concurrency control.
   *
   * Can be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Optional. Annotations on the node pool.
   *
   * This field has the same restrictions as Kubernetes annotations.
   * The total size of all keys and values combined is limited to 256k.
   * Key can have 2 segments: prefix (optional) and name (required),
   * separated by a slash (/).
   * Prefix must be a DNS subdomain.
   * Name must be 63 characters or less, begin and end with alphanumerics,
   * with dashes (-), underscores (_), dots (.), and alphanumerics between.
   */
  annotations: { [key: string]: string };
  /**
   * Required. The constraint on the maximum number of pods that can be run
   * simultaneously on a node in the node pool.
   */
  maxPodsConstraint:
    | MaxPodsConstraint
    | undefined;
  /** Output only. A set of errors found in the node pool. */
  errors: AwsNodePoolError[];
  /** Optional. The Management configuration for this node pool. */
  management:
    | AwsNodeManagement
    | undefined;
  /** Optional. Node kubelet configs. */
  kubeletConfig:
    | NodeKubeletConfig
    | undefined;
  /** Optional. Update settings control the speed and disruption of the update. */
  updateSettings: UpdateSettings | undefined;
}

/** The lifecycle state of the node pool. */
export enum AwsNodePool_State {
  /** STATE_UNSPECIFIED - Not set. */
  STATE_UNSPECIFIED = 0,
  /** PROVISIONING - The PROVISIONING state indicates the node pool is being created. */
  PROVISIONING = 1,
  /**
   * RUNNING - The RUNNING state indicates the node pool has been created
   * and is fully usable.
   */
  RUNNING = 2,
  /** RECONCILING - The RECONCILING state indicates that the node pool is being reconciled. */
  RECONCILING = 3,
  /** STOPPING - The STOPPING state indicates the node pool is being deleted. */
  STOPPING = 4,
  /**
   * ERROR - The ERROR state indicates the node pool is in a broken unrecoverable
   * state.
   */
  ERROR = 5,
  /**
   * DEGRADED - The DEGRADED state indicates the node pool requires user action to
   * restore full functionality.
   */
  DEGRADED = 6,
  UNRECOGNIZED = -1,
}

export function awsNodePool_StateFromJSON(object: any): AwsNodePool_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return AwsNodePool_State.STATE_UNSPECIFIED;
    case 1:
    case "PROVISIONING":
      return AwsNodePool_State.PROVISIONING;
    case 2:
    case "RUNNING":
      return AwsNodePool_State.RUNNING;
    case 3:
    case "RECONCILING":
      return AwsNodePool_State.RECONCILING;
    case 4:
    case "STOPPING":
      return AwsNodePool_State.STOPPING;
    case 5:
    case "ERROR":
      return AwsNodePool_State.ERROR;
    case 6:
    case "DEGRADED":
      return AwsNodePool_State.DEGRADED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AwsNodePool_State.UNRECOGNIZED;
  }
}

export function awsNodePool_StateToJSON(object: AwsNodePool_State): string {
  switch (object) {
    case AwsNodePool_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case AwsNodePool_State.PROVISIONING:
      return "PROVISIONING";
    case AwsNodePool_State.RUNNING:
      return "RUNNING";
    case AwsNodePool_State.RECONCILING:
      return "RECONCILING";
    case AwsNodePool_State.STOPPING:
      return "STOPPING";
    case AwsNodePool_State.ERROR:
      return "ERROR";
    case AwsNodePool_State.DEGRADED:
      return "DEGRADED";
    case AwsNodePool_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface AwsNodePool_AnnotationsEntry {
  key: string;
  value: string;
}

/**
 * UpdateSettings control the level of parallelism and the level of
 * disruption caused during the update of a node pool.
 *
 * These settings are applicable when the node pool update requires replacing
 * the existing node pool nodes with the updated ones.
 *
 * UpdateSettings are optional. When UpdateSettings are not specified during the
 * node pool creation, a default is chosen based on the parent cluster's
 * version. For clusters with minor version 1.27 and later, a default
 * surge_settings configuration with max_surge = 1 and max_unavailable = 0 is
 * used. For clusters with older versions, node pool updates use the traditional
 * rolling update mechanism of updating one node at a time in a
 * "terminate before create" fashion and update_settings is not applicable.
 *
 * Set the surge_settings parameter to use the Surge Update mechanism for
 * the rolling update of node pool nodes.
 * 1. max_surge controls the number of additional nodes that can be created
 * beyond the current size of the node pool temporarily for the time of the
 * update to increase the number of available nodes.
 * 2. max_unavailable controls the number of nodes that can be simultaneously
 * unavailable during the update.
 * 3. (max_surge + max_unavailable) determines the level of parallelism (i.e.,
 * the number of nodes being updated at the same time).
 */
export interface UpdateSettings {
  /** Optional. Settings for surge update. */
  surgeSettings: SurgeSettings | undefined;
}

/** SurgeSettings contains the parameters for Surge update. */
export interface SurgeSettings {
  /**
   * Optional. The maximum number of nodes that can be created beyond the
   * current size of the node pool during the update process.
   */
  maxSurge: number;
  /**
   * Optional. The maximum number of nodes that can be simultaneously
   * unavailable during the update process. A node is considered unavailable if
   * its status is not Ready.
   */
  maxUnavailable: number;
}

/**
 * AwsNodeManagement defines the set of node management features turned on for
 * an AWS node pool.
 */
export interface AwsNodeManagement {
  /**
   * Optional. Whether or not the nodes will be automatically repaired. When set
   * to true, the nodes in this node pool will be monitored and if they fail
   * health checks consistently over a period of time, an automatic repair
   * action will be triggered to replace them with new nodes.
   */
  autoRepair: boolean;
}

/** Parameters that describe the nodes in a cluster. */
export interface AwsNodeConfig {
  /**
   * Optional. The EC2 instance type when creating on-Demand instances.
   *
   * If unspecified during node pool creation, a default will be chosen based on
   * the node pool version, and assigned to this field.
   */
  instanceType: string;
  /**
   * Optional. Template for the root volume provisioned for node pool nodes.
   * Volumes will be provisioned in the availability zone assigned
   * to the node pool subnet.
   *
   * When unspecified, it defaults to 32 GiB with the GP2 volume type.
   */
  rootVolume:
    | AwsVolumeTemplate
    | undefined;
  /** Optional. The initial taints assigned to nodes of this node pool. */
  taints: NodeTaint[];
  /**
   * Optional. The initial labels assigned to nodes of this node pool. An object
   * containing a list of "key": value pairs. Example: { "name": "wrench",
   * "mass": "1.3kg", "count": "3" }.
   */
  labels: { [key: string]: string };
  /**
   * Optional. Key/value metadata to assign to each underlying AWS resource.
   * Specify at most 50 pairs containing alphanumerics, spaces, and symbols
   * (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to
   * 255 Unicode characters.
   */
  tags: { [key: string]: string };
  /**
   * Required. The name or ARN of the AWS IAM instance profile to assign to
   * nodes in the pool.
   */
  iamInstanceProfile: string;
  /**
   * Optional. The OS image type to use on node pool instances.
   * Can be unspecified, or have a value of `ubuntu`.
   *
   * When unspecified, it defaults to `ubuntu`.
   */
  imageType: string;
  /** Optional. The SSH configuration. */
  sshConfig:
    | AwsSshConfig
    | undefined;
  /**
   * Optional. The IDs of additional security groups to add to nodes in this
   * pool. The manager will automatically create security groups with minimum
   * rules needed for a functioning cluster.
   */
  securityGroupIds: string[];
  /** Optional. Proxy configuration for outbound HTTP(S) traffic. */
  proxyConfig:
    | AwsProxyConfig
    | undefined;
  /** Required. Config encryption for user data. */
  configEncryption:
    | AwsConfigEncryption
    | undefined;
  /**
   * Optional. Placement related info for this node.
   * When unspecified, the VPC's default tenancy will be used.
   */
  instancePlacement:
    | AwsInstancePlacement
    | undefined;
  /**
   * Optional. Configuration related to CloudWatch metrics collection on the
   * Auto Scaling group of the node pool.
   *
   * When unspecified, metrics collection is disabled.
   */
  autoscalingMetricsCollection:
    | AwsAutoscalingGroupMetricsCollection
    | undefined;
  /**
   * Optional. Configuration for provisioning EC2 Spot instances
   *
   * When specified, the node pool will provision Spot instances from the set
   * of spot_config.instance_types.
   * This field is mutually exclusive with `instance_type`.
   */
  spotConfig: SpotConfig | undefined;
}

export interface AwsNodeConfig_LabelsEntry {
  key: string;
  value: string;
}

export interface AwsNodeConfig_TagsEntry {
  key: string;
  value: string;
}

/**
 * AwsNodePoolAutoscaling contains information required by cluster autoscaler
 * to adjust the size of the node pool to the current cluster usage.
 */
export interface AwsNodePoolAutoscaling {
  /**
   * Required. Minimum number of nodes in the node pool. Must be greater than or
   * equal to 1 and less than or equal to max_node_count.
   */
  minNodeCount: number;
  /**
   * Required. Maximum number of nodes in the node pool. Must be greater than or
   * equal to min_node_count and less than or equal to 50.
   */
  maxNodeCount: number;
}

/**
 * AwsOpenIdConfig is an OIDC discovery document for the cluster.
 * See the OpenID Connect Discovery 1.0 specification for details.
 */
export interface AwsOpenIdConfig {
  /** OIDC Issuer. */
  issuer: string;
  /** JSON Web Key uri. */
  jwksUri: string;
  /** Supported response types. */
  responseTypesSupported: string[];
  /** Supported subject types. */
  subjectTypesSupported: string[];
  /** supported ID Token signing Algorithms. */
  idTokenSigningAlgValuesSupported: string[];
  /** Supported claims. */
  claimsSupported: string[];
  /** Supported grant types. */
  grantTypes: string[];
}

/** AwsJsonWebKeys is a valid JSON Web Key Set as specififed in RFC 7517. */
export interface AwsJsonWebKeys {
  /**
   * The public component of the keys used by the cluster to sign token
   * requests.
   */
  keys: Jwk[];
}

/** AwsServerConfig is the configuration of GKE cluster on AWS. */
export interface AwsServerConfig {
  /** The resource name of the config. */
  name: string;
  /**
   * List of all released Kubernetes versions, including ones which are end of
   * life and can no longer be used.  Filter by the `enabled`
   * property to limit to currently available versions.
   * Valid versions supported for both create and update operations
   */
  validVersions: AwsK8sVersionInfo[];
  /** The list of supported AWS regions. */
  supportedAwsRegions: string[];
}

/** Kubernetes version information of GKE cluster on AWS. */
export interface AwsK8sVersionInfo {
  /** Kubernetes version name. */
  version: string;
  /**
   * Optional. True if the version is available for cluster creation. If a
   * version is enabled for creation, it can be used to create new clusters.
   * Otherwise, cluster creation will fail. However, cluster upgrade operations
   * may succeed, even if the version is not enabled.
   */
  enabled: boolean;
  /**
   * Optional. True if this cluster version belongs to a minor version that has
   * reached its end of life and is no longer in scope to receive security and
   * bug fixes.
   */
  endOfLife: boolean;
  /**
   * Optional. The estimated date (in Pacific Time) when this cluster version
   * will reach its end of life. Or if this version is no longer supported (the
   * `end_of_life` field is true), this is the actual date (in Pacific time)
   * when the version reached its end of life.
   */
  endOfLifeDate:
    | DateMessage
    | undefined;
  /** Optional. The date (in Pacific Time) when the cluster version was released. */
  releaseDate: DateMessage | undefined;
}

/** SSH configuration for AWS resources. */
export interface AwsSshConfig {
  /** Required. The name of the EC2 key pair used to login into cluster machines. */
  ec2KeyPair: string;
}

/** Details of a proxy config stored in AWS Secret Manager. */
export interface AwsProxyConfig {
  /**
   * The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy
   * configuration.
   *
   * The secret must be a JSON encoded proxy configuration
   * as described in
   * https://cloud.google.com/kubernetes-engine/multi-cloud/docs/aws/how-to/use-a-proxy#create_a_proxy_configuration_file
   */
  secretArn: string;
  /**
   * The version string of the AWS Secret Manager secret that contains the
   * HTTP(S) proxy configuration.
   */
  secretVersion: string;
}

/** Config encryption for user data. */
export interface AwsConfigEncryption {
  /** Required. The ARN of the AWS KMS key used to encrypt user data. */
  kmsKeyArn: string;
}

/**
 * Details of placement information for an instance.
 * Limitations for using the `host` tenancy:
 *
 *  * T3 instances that use the unlimited CPU credit option don't support host
 *  tenancy.
 */
export interface AwsInstancePlacement {
  /** Required. The tenancy for instance. */
  tenancy: AwsInstancePlacement_Tenancy;
}

/** Tenancy defines how EC2 instances are distributed across physical hardware. */
export enum AwsInstancePlacement_Tenancy {
  /** TENANCY_UNSPECIFIED - Not set. */
  TENANCY_UNSPECIFIED = 0,
  /** DEFAULT - Use default VPC tenancy. */
  DEFAULT = 1,
  /** DEDICATED - Run a dedicated instance. */
  DEDICATED = 2,
  /** HOST - Launch this instance to a dedicated host. */
  HOST = 3,
  UNRECOGNIZED = -1,
}

export function awsInstancePlacement_TenancyFromJSON(object: any): AwsInstancePlacement_Tenancy {
  switch (object) {
    case 0:
    case "TENANCY_UNSPECIFIED":
      return AwsInstancePlacement_Tenancy.TENANCY_UNSPECIFIED;
    case 1:
    case "DEFAULT":
      return AwsInstancePlacement_Tenancy.DEFAULT;
    case 2:
    case "DEDICATED":
      return AwsInstancePlacement_Tenancy.DEDICATED;
    case 3:
    case "HOST":
      return AwsInstancePlacement_Tenancy.HOST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AwsInstancePlacement_Tenancy.UNRECOGNIZED;
  }
}

export function awsInstancePlacement_TenancyToJSON(object: AwsInstancePlacement_Tenancy): string {
  switch (object) {
    case AwsInstancePlacement_Tenancy.TENANCY_UNSPECIFIED:
      return "TENANCY_UNSPECIFIED";
    case AwsInstancePlacement_Tenancy.DEFAULT:
      return "DEFAULT";
    case AwsInstancePlacement_Tenancy.DEDICATED:
      return "DEDICATED";
    case AwsInstancePlacement_Tenancy.HOST:
      return "HOST";
    case AwsInstancePlacement_Tenancy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Configuration related to CloudWatch metrics collection in an AWS
 * Auto Scaling group.
 */
export interface AwsAutoscalingGroupMetricsCollection {
  /**
   * Required. The frequency at which EC2 Auto Scaling sends aggregated data to
   * AWS CloudWatch. The only valid value is "1Minute".
   */
  granularity: string;
  /**
   * Optional. The metrics to enable. For a list of valid metrics, see
   * https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html.
   * If you specify Granularity and don't specify any metrics, all metrics are
   * enabled.
   */
  metrics: string[];
}

/** SpotConfig has configuration info for Spot node. */
export interface SpotConfig {
  /** Required. A list of instance types for creating spot node pool. */
  instanceTypes: string[];
}

/** AwsClusterError describes errors found on AWS clusters. */
export interface AwsClusterError {
  /** Human-friendly description of the error. */
  message: string;
}

/** AwsNodePoolError describes errors found on AWS node pools. */
export interface AwsNodePoolError {
  /** Human-friendly description of the error. */
  message: string;
}

function createBaseAwsCluster(): AwsCluster {
  return {
    name: "",
    description: "",
    networking: undefined,
    awsRegion: "",
    controlPlane: undefined,
    authorization: undefined,
    state: 0,
    endpoint: "",
    uid: "",
    reconciling: false,
    createTime: undefined,
    updateTime: undefined,
    etag: "",
    annotations: {},
    workloadIdentityConfig: undefined,
    clusterCaCertificate: "",
    fleet: undefined,
    loggingConfig: undefined,
    errors: [],
    monitoringConfig: undefined,
    binaryAuthorization: undefined,
  };
}

export const AwsCluster: MessageFns<AwsCluster> = {
  encode(message: AwsCluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.networking !== undefined) {
      AwsClusterNetworking.encode(message.networking, writer.uint32(26).fork()).join();
    }
    if (message.awsRegion !== "") {
      writer.uint32(34).string(message.awsRegion);
    }
    if (message.controlPlane !== undefined) {
      AwsControlPlane.encode(message.controlPlane, writer.uint32(42).fork()).join();
    }
    if (message.authorization !== undefined) {
      AwsAuthorization.encode(message.authorization, writer.uint32(122).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(56).int32(message.state);
    }
    if (message.endpoint !== "") {
      writer.uint32(66).string(message.endpoint);
    }
    if (message.uid !== "") {
      writer.uint32(74).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(80).bool(message.reconciling);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(90).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(98).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(106).string(message.etag);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      AwsCluster_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(114).fork()).join();
    });
    if (message.workloadIdentityConfig !== undefined) {
      WorkloadIdentityConfig.encode(message.workloadIdentityConfig, writer.uint32(130).fork()).join();
    }
    if (message.clusterCaCertificate !== "") {
      writer.uint32(138).string(message.clusterCaCertificate);
    }
    if (message.fleet !== undefined) {
      Fleet.encode(message.fleet, writer.uint32(146).fork()).join();
    }
    if (message.loggingConfig !== undefined) {
      LoggingConfig.encode(message.loggingConfig, writer.uint32(154).fork()).join();
    }
    for (const v of message.errors) {
      AwsClusterError.encode(v!, writer.uint32(162).fork()).join();
    }
    if (message.monitoringConfig !== undefined) {
      MonitoringConfig.encode(message.monitoringConfig, writer.uint32(170).fork()).join();
    }
    if (message.binaryAuthorization !== undefined) {
      BinaryAuthorization.encode(message.binaryAuthorization, writer.uint32(178).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsCluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsCluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.networking = AwsClusterNetworking.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.awsRegion = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.controlPlane = AwsControlPlane.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.authorization = AwsAuthorization.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endpoint = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          const entry14 = AwsCluster_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry14.value !== undefined) {
            message.annotations[entry14.key] = entry14.value;
          }
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.workloadIdentityConfig = WorkloadIdentityConfig.decode(reader, reader.uint32());
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.clusterCaCertificate = reader.string();
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.fleet = Fleet.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.loggingConfig = LoggingConfig.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.errors.push(AwsClusterError.decode(reader, reader.uint32()));
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.monitoringConfig = MonitoringConfig.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.binaryAuthorization = BinaryAuthorization.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsCluster {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      networking: isSet(object.networking) ? AwsClusterNetworking.fromJSON(object.networking) : undefined,
      awsRegion: isSet(object.awsRegion) ? globalThis.String(object.awsRegion) : "",
      controlPlane: isSet(object.controlPlane) ? AwsControlPlane.fromJSON(object.controlPlane) : undefined,
      authorization: isSet(object.authorization) ? AwsAuthorization.fromJSON(object.authorization) : undefined,
      state: isSet(object.state) ? awsCluster_StateFromJSON(object.state) : 0,
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      workloadIdentityConfig: isSet(object.workloadIdentityConfig)
        ? WorkloadIdentityConfig.fromJSON(object.workloadIdentityConfig)
        : undefined,
      clusterCaCertificate: isSet(object.clusterCaCertificate) ? globalThis.String(object.clusterCaCertificate) : "",
      fleet: isSet(object.fleet) ? Fleet.fromJSON(object.fleet) : undefined,
      loggingConfig: isSet(object.loggingConfig) ? LoggingConfig.fromJSON(object.loggingConfig) : undefined,
      errors: globalThis.Array.isArray(object?.errors)
        ? object.errors.map((e: any) => AwsClusterError.fromJSON(e))
        : [],
      monitoringConfig: isSet(object.monitoringConfig) ? MonitoringConfig.fromJSON(object.monitoringConfig) : undefined,
      binaryAuthorization: isSet(object.binaryAuthorization)
        ? BinaryAuthorization.fromJSON(object.binaryAuthorization)
        : undefined,
    };
  },

  toJSON(message: AwsCluster): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.networking !== undefined) {
      obj.networking = AwsClusterNetworking.toJSON(message.networking);
    }
    if (message.awsRegion !== "") {
      obj.awsRegion = message.awsRegion;
    }
    if (message.controlPlane !== undefined) {
      obj.controlPlane = AwsControlPlane.toJSON(message.controlPlane);
    }
    if (message.authorization !== undefined) {
      obj.authorization = AwsAuthorization.toJSON(message.authorization);
    }
    if (message.state !== 0) {
      obj.state = awsCluster_StateToJSON(message.state);
    }
    if (message.endpoint !== "") {
      obj.endpoint = message.endpoint;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.workloadIdentityConfig !== undefined) {
      obj.workloadIdentityConfig = WorkloadIdentityConfig.toJSON(message.workloadIdentityConfig);
    }
    if (message.clusterCaCertificate !== "") {
      obj.clusterCaCertificate = message.clusterCaCertificate;
    }
    if (message.fleet !== undefined) {
      obj.fleet = Fleet.toJSON(message.fleet);
    }
    if (message.loggingConfig !== undefined) {
      obj.loggingConfig = LoggingConfig.toJSON(message.loggingConfig);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => AwsClusterError.toJSON(e));
    }
    if (message.monitoringConfig !== undefined) {
      obj.monitoringConfig = MonitoringConfig.toJSON(message.monitoringConfig);
    }
    if (message.binaryAuthorization !== undefined) {
      obj.binaryAuthorization = BinaryAuthorization.toJSON(message.binaryAuthorization);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsCluster>): AwsCluster {
    return AwsCluster.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsCluster>): AwsCluster {
    const message = createBaseAwsCluster();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.networking = (object.networking !== undefined && object.networking !== null)
      ? AwsClusterNetworking.fromPartial(object.networking)
      : undefined;
    message.awsRegion = object.awsRegion ?? "";
    message.controlPlane = (object.controlPlane !== undefined && object.controlPlane !== null)
      ? AwsControlPlane.fromPartial(object.controlPlane)
      : undefined;
    message.authorization = (object.authorization !== undefined && object.authorization !== null)
      ? AwsAuthorization.fromPartial(object.authorization)
      : undefined;
    message.state = object.state ?? 0;
    message.endpoint = object.endpoint ?? "";
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.etag = object.etag ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.workloadIdentityConfig =
      (object.workloadIdentityConfig !== undefined && object.workloadIdentityConfig !== null)
        ? WorkloadIdentityConfig.fromPartial(object.workloadIdentityConfig)
        : undefined;
    message.clusterCaCertificate = object.clusterCaCertificate ?? "";
    message.fleet = (object.fleet !== undefined && object.fleet !== null) ? Fleet.fromPartial(object.fleet) : undefined;
    message.loggingConfig = (object.loggingConfig !== undefined && object.loggingConfig !== null)
      ? LoggingConfig.fromPartial(object.loggingConfig)
      : undefined;
    message.errors = object.errors?.map((e) => AwsClusterError.fromPartial(e)) || [];
    message.monitoringConfig = (object.monitoringConfig !== undefined && object.monitoringConfig !== null)
      ? MonitoringConfig.fromPartial(object.monitoringConfig)
      : undefined;
    message.binaryAuthorization = (object.binaryAuthorization !== undefined && object.binaryAuthorization !== null)
      ? BinaryAuthorization.fromPartial(object.binaryAuthorization)
      : undefined;
    return message;
  },
};

function createBaseAwsCluster_AnnotationsEntry(): AwsCluster_AnnotationsEntry {
  return { key: "", value: "" };
}

export const AwsCluster_AnnotationsEntry: MessageFns<AwsCluster_AnnotationsEntry> = {
  encode(message: AwsCluster_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsCluster_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsCluster_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsCluster_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsCluster_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsCluster_AnnotationsEntry>): AwsCluster_AnnotationsEntry {
    return AwsCluster_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsCluster_AnnotationsEntry>): AwsCluster_AnnotationsEntry {
    const message = createBaseAwsCluster_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAwsControlPlane(): AwsControlPlane {
  return {
    version: "",
    instanceType: "",
    sshConfig: undefined,
    subnetIds: [],
    securityGroupIds: [],
    iamInstanceProfile: "",
    rootVolume: undefined,
    mainVolume: undefined,
    databaseEncryption: undefined,
    tags: {},
    awsServicesAuthentication: undefined,
    proxyConfig: undefined,
    configEncryption: undefined,
    instancePlacement: undefined,
  };
}

export const AwsControlPlane: MessageFns<AwsControlPlane> = {
  encode(message: AwsControlPlane, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.instanceType !== "") {
      writer.uint32(18).string(message.instanceType);
    }
    if (message.sshConfig !== undefined) {
      AwsSshConfig.encode(message.sshConfig, writer.uint32(114).fork()).join();
    }
    for (const v of message.subnetIds) {
      writer.uint32(34).string(v!);
    }
    for (const v of message.securityGroupIds) {
      writer.uint32(42).string(v!);
    }
    if (message.iamInstanceProfile !== "") {
      writer.uint32(58).string(message.iamInstanceProfile);
    }
    if (message.rootVolume !== undefined) {
      AwsVolumeTemplate.encode(message.rootVolume, writer.uint32(66).fork()).join();
    }
    if (message.mainVolume !== undefined) {
      AwsVolumeTemplate.encode(message.mainVolume, writer.uint32(74).fork()).join();
    }
    if (message.databaseEncryption !== undefined) {
      AwsDatabaseEncryption.encode(message.databaseEncryption, writer.uint32(82).fork()).join();
    }
    Object.entries(message.tags).forEach(([key, value]) => {
      AwsControlPlane_TagsEntry.encode({ key: key as any, value }, writer.uint32(90).fork()).join();
    });
    if (message.awsServicesAuthentication !== undefined) {
      AwsServicesAuthentication.encode(message.awsServicesAuthentication, writer.uint32(98).fork()).join();
    }
    if (message.proxyConfig !== undefined) {
      AwsProxyConfig.encode(message.proxyConfig, writer.uint32(130).fork()).join();
    }
    if (message.configEncryption !== undefined) {
      AwsConfigEncryption.encode(message.configEncryption, writer.uint32(138).fork()).join();
    }
    if (message.instancePlacement !== undefined) {
      AwsInstancePlacement.encode(message.instancePlacement, writer.uint32(146).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsControlPlane {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsControlPlane();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.instanceType = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.sshConfig = AwsSshConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.subnetIds.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.securityGroupIds.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.iamInstanceProfile = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.rootVolume = AwsVolumeTemplate.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.mainVolume = AwsVolumeTemplate.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.databaseEncryption = AwsDatabaseEncryption.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          const entry11 = AwsControlPlane_TagsEntry.decode(reader, reader.uint32());
          if (entry11.value !== undefined) {
            message.tags[entry11.key] = entry11.value;
          }
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.awsServicesAuthentication = AwsServicesAuthentication.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.proxyConfig = AwsProxyConfig.decode(reader, reader.uint32());
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.configEncryption = AwsConfigEncryption.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.instancePlacement = AwsInstancePlacement.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsControlPlane {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      instanceType: isSet(object.instanceType) ? globalThis.String(object.instanceType) : "",
      sshConfig: isSet(object.sshConfig) ? AwsSshConfig.fromJSON(object.sshConfig) : undefined,
      subnetIds: globalThis.Array.isArray(object?.subnetIds)
        ? object.subnetIds.map((e: any) => globalThis.String(e))
        : [],
      securityGroupIds: globalThis.Array.isArray(object?.securityGroupIds)
        ? object.securityGroupIds.map((e: any) => globalThis.String(e))
        : [],
      iamInstanceProfile: isSet(object.iamInstanceProfile) ? globalThis.String(object.iamInstanceProfile) : "",
      rootVolume: isSet(object.rootVolume) ? AwsVolumeTemplate.fromJSON(object.rootVolume) : undefined,
      mainVolume: isSet(object.mainVolume) ? AwsVolumeTemplate.fromJSON(object.mainVolume) : undefined,
      databaseEncryption: isSet(object.databaseEncryption)
        ? AwsDatabaseEncryption.fromJSON(object.databaseEncryption)
        : undefined,
      tags: isObject(object.tags)
        ? Object.entries(object.tags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      awsServicesAuthentication: isSet(object.awsServicesAuthentication)
        ? AwsServicesAuthentication.fromJSON(object.awsServicesAuthentication)
        : undefined,
      proxyConfig: isSet(object.proxyConfig) ? AwsProxyConfig.fromJSON(object.proxyConfig) : undefined,
      configEncryption: isSet(object.configEncryption)
        ? AwsConfigEncryption.fromJSON(object.configEncryption)
        : undefined,
      instancePlacement: isSet(object.instancePlacement)
        ? AwsInstancePlacement.fromJSON(object.instancePlacement)
        : undefined,
    };
  },

  toJSON(message: AwsControlPlane): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.instanceType !== "") {
      obj.instanceType = message.instanceType;
    }
    if (message.sshConfig !== undefined) {
      obj.sshConfig = AwsSshConfig.toJSON(message.sshConfig);
    }
    if (message.subnetIds?.length) {
      obj.subnetIds = message.subnetIds;
    }
    if (message.securityGroupIds?.length) {
      obj.securityGroupIds = message.securityGroupIds;
    }
    if (message.iamInstanceProfile !== "") {
      obj.iamInstanceProfile = message.iamInstanceProfile;
    }
    if (message.rootVolume !== undefined) {
      obj.rootVolume = AwsVolumeTemplate.toJSON(message.rootVolume);
    }
    if (message.mainVolume !== undefined) {
      obj.mainVolume = AwsVolumeTemplate.toJSON(message.mainVolume);
    }
    if (message.databaseEncryption !== undefined) {
      obj.databaseEncryption = AwsDatabaseEncryption.toJSON(message.databaseEncryption);
    }
    if (message.tags) {
      const entries = Object.entries(message.tags);
      if (entries.length > 0) {
        obj.tags = {};
        entries.forEach(([k, v]) => {
          obj.tags[k] = v;
        });
      }
    }
    if (message.awsServicesAuthentication !== undefined) {
      obj.awsServicesAuthentication = AwsServicesAuthentication.toJSON(message.awsServicesAuthentication);
    }
    if (message.proxyConfig !== undefined) {
      obj.proxyConfig = AwsProxyConfig.toJSON(message.proxyConfig);
    }
    if (message.configEncryption !== undefined) {
      obj.configEncryption = AwsConfigEncryption.toJSON(message.configEncryption);
    }
    if (message.instancePlacement !== undefined) {
      obj.instancePlacement = AwsInstancePlacement.toJSON(message.instancePlacement);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsControlPlane>): AwsControlPlane {
    return AwsControlPlane.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsControlPlane>): AwsControlPlane {
    const message = createBaseAwsControlPlane();
    message.version = object.version ?? "";
    message.instanceType = object.instanceType ?? "";
    message.sshConfig = (object.sshConfig !== undefined && object.sshConfig !== null)
      ? AwsSshConfig.fromPartial(object.sshConfig)
      : undefined;
    message.subnetIds = object.subnetIds?.map((e) => e) || [];
    message.securityGroupIds = object.securityGroupIds?.map((e) => e) || [];
    message.iamInstanceProfile = object.iamInstanceProfile ?? "";
    message.rootVolume = (object.rootVolume !== undefined && object.rootVolume !== null)
      ? AwsVolumeTemplate.fromPartial(object.rootVolume)
      : undefined;
    message.mainVolume = (object.mainVolume !== undefined && object.mainVolume !== null)
      ? AwsVolumeTemplate.fromPartial(object.mainVolume)
      : undefined;
    message.databaseEncryption = (object.databaseEncryption !== undefined && object.databaseEncryption !== null)
      ? AwsDatabaseEncryption.fromPartial(object.databaseEncryption)
      : undefined;
    message.tags = Object.entries(object.tags ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.awsServicesAuthentication =
      (object.awsServicesAuthentication !== undefined && object.awsServicesAuthentication !== null)
        ? AwsServicesAuthentication.fromPartial(object.awsServicesAuthentication)
        : undefined;
    message.proxyConfig = (object.proxyConfig !== undefined && object.proxyConfig !== null)
      ? AwsProxyConfig.fromPartial(object.proxyConfig)
      : undefined;
    message.configEncryption = (object.configEncryption !== undefined && object.configEncryption !== null)
      ? AwsConfigEncryption.fromPartial(object.configEncryption)
      : undefined;
    message.instancePlacement = (object.instancePlacement !== undefined && object.instancePlacement !== null)
      ? AwsInstancePlacement.fromPartial(object.instancePlacement)
      : undefined;
    return message;
  },
};

function createBaseAwsControlPlane_TagsEntry(): AwsControlPlane_TagsEntry {
  return { key: "", value: "" };
}

export const AwsControlPlane_TagsEntry: MessageFns<AwsControlPlane_TagsEntry> = {
  encode(message: AwsControlPlane_TagsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsControlPlane_TagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsControlPlane_TagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsControlPlane_TagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsControlPlane_TagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsControlPlane_TagsEntry>): AwsControlPlane_TagsEntry {
    return AwsControlPlane_TagsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsControlPlane_TagsEntry>): AwsControlPlane_TagsEntry {
    const message = createBaseAwsControlPlane_TagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAwsServicesAuthentication(): AwsServicesAuthentication {
  return { roleArn: "", roleSessionName: "" };
}

export const AwsServicesAuthentication: MessageFns<AwsServicesAuthentication> = {
  encode(message: AwsServicesAuthentication, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.roleArn !== "") {
      writer.uint32(10).string(message.roleArn);
    }
    if (message.roleSessionName !== "") {
      writer.uint32(18).string(message.roleSessionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsServicesAuthentication {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsServicesAuthentication();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.roleArn = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.roleSessionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsServicesAuthentication {
    return {
      roleArn: isSet(object.roleArn) ? globalThis.String(object.roleArn) : "",
      roleSessionName: isSet(object.roleSessionName) ? globalThis.String(object.roleSessionName) : "",
    };
  },

  toJSON(message: AwsServicesAuthentication): unknown {
    const obj: any = {};
    if (message.roleArn !== "") {
      obj.roleArn = message.roleArn;
    }
    if (message.roleSessionName !== "") {
      obj.roleSessionName = message.roleSessionName;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsServicesAuthentication>): AwsServicesAuthentication {
    return AwsServicesAuthentication.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsServicesAuthentication>): AwsServicesAuthentication {
    const message = createBaseAwsServicesAuthentication();
    message.roleArn = object.roleArn ?? "";
    message.roleSessionName = object.roleSessionName ?? "";
    return message;
  },
};

function createBaseAwsAuthorization(): AwsAuthorization {
  return { adminUsers: [], adminGroups: [] };
}

export const AwsAuthorization: MessageFns<AwsAuthorization> = {
  encode(message: AwsAuthorization, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.adminUsers) {
      AwsClusterUser.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.adminGroups) {
      AwsClusterGroup.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsAuthorization {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsAuthorization();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.adminUsers.push(AwsClusterUser.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.adminGroups.push(AwsClusterGroup.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsAuthorization {
    return {
      adminUsers: globalThis.Array.isArray(object?.adminUsers)
        ? object.adminUsers.map((e: any) => AwsClusterUser.fromJSON(e))
        : [],
      adminGroups: globalThis.Array.isArray(object?.adminGroups)
        ? object.adminGroups.map((e: any) => AwsClusterGroup.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AwsAuthorization): unknown {
    const obj: any = {};
    if (message.adminUsers?.length) {
      obj.adminUsers = message.adminUsers.map((e) => AwsClusterUser.toJSON(e));
    }
    if (message.adminGroups?.length) {
      obj.adminGroups = message.adminGroups.map((e) => AwsClusterGroup.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AwsAuthorization>): AwsAuthorization {
    return AwsAuthorization.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsAuthorization>): AwsAuthorization {
    const message = createBaseAwsAuthorization();
    message.adminUsers = object.adminUsers?.map((e) => AwsClusterUser.fromPartial(e)) || [];
    message.adminGroups = object.adminGroups?.map((e) => AwsClusterGroup.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAwsClusterUser(): AwsClusterUser {
  return { username: "" };
}

export const AwsClusterUser: MessageFns<AwsClusterUser> = {
  encode(message: AwsClusterUser, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.username !== "") {
      writer.uint32(10).string(message.username);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsClusterUser {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsClusterUser();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.username = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsClusterUser {
    return { username: isSet(object.username) ? globalThis.String(object.username) : "" };
  },

  toJSON(message: AwsClusterUser): unknown {
    const obj: any = {};
    if (message.username !== "") {
      obj.username = message.username;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsClusterUser>): AwsClusterUser {
    return AwsClusterUser.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsClusterUser>): AwsClusterUser {
    const message = createBaseAwsClusterUser();
    message.username = object.username ?? "";
    return message;
  },
};

function createBaseAwsClusterGroup(): AwsClusterGroup {
  return { group: "" };
}

export const AwsClusterGroup: MessageFns<AwsClusterGroup> = {
  encode(message: AwsClusterGroup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.group !== "") {
      writer.uint32(10).string(message.group);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsClusterGroup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsClusterGroup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.group = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsClusterGroup {
    return { group: isSet(object.group) ? globalThis.String(object.group) : "" };
  },

  toJSON(message: AwsClusterGroup): unknown {
    const obj: any = {};
    if (message.group !== "") {
      obj.group = message.group;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsClusterGroup>): AwsClusterGroup {
    return AwsClusterGroup.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsClusterGroup>): AwsClusterGroup {
    const message = createBaseAwsClusterGroup();
    message.group = object.group ?? "";
    return message;
  },
};

function createBaseAwsDatabaseEncryption(): AwsDatabaseEncryption {
  return { kmsKeyArn: "" };
}

export const AwsDatabaseEncryption: MessageFns<AwsDatabaseEncryption> = {
  encode(message: AwsDatabaseEncryption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKeyArn !== "") {
      writer.uint32(10).string(message.kmsKeyArn);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsDatabaseEncryption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsDatabaseEncryption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKeyArn = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsDatabaseEncryption {
    return { kmsKeyArn: isSet(object.kmsKeyArn) ? globalThis.String(object.kmsKeyArn) : "" };
  },

  toJSON(message: AwsDatabaseEncryption): unknown {
    const obj: any = {};
    if (message.kmsKeyArn !== "") {
      obj.kmsKeyArn = message.kmsKeyArn;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsDatabaseEncryption>): AwsDatabaseEncryption {
    return AwsDatabaseEncryption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsDatabaseEncryption>): AwsDatabaseEncryption {
    const message = createBaseAwsDatabaseEncryption();
    message.kmsKeyArn = object.kmsKeyArn ?? "";
    return message;
  },
};

function createBaseAwsVolumeTemplate(): AwsVolumeTemplate {
  return { sizeGib: 0, volumeType: 0, iops: 0, throughput: 0, kmsKeyArn: "" };
}

export const AwsVolumeTemplate: MessageFns<AwsVolumeTemplate> = {
  encode(message: AwsVolumeTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sizeGib !== 0) {
      writer.uint32(8).int32(message.sizeGib);
    }
    if (message.volumeType !== 0) {
      writer.uint32(16).int32(message.volumeType);
    }
    if (message.iops !== 0) {
      writer.uint32(24).int32(message.iops);
    }
    if (message.throughput !== 0) {
      writer.uint32(40).int32(message.throughput);
    }
    if (message.kmsKeyArn !== "") {
      writer.uint32(34).string(message.kmsKeyArn);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsVolumeTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsVolumeTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sizeGib = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.volumeType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.iops = reader.int32();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.throughput = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.kmsKeyArn = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsVolumeTemplate {
    return {
      sizeGib: isSet(object.sizeGib) ? globalThis.Number(object.sizeGib) : 0,
      volumeType: isSet(object.volumeType) ? awsVolumeTemplate_VolumeTypeFromJSON(object.volumeType) : 0,
      iops: isSet(object.iops) ? globalThis.Number(object.iops) : 0,
      throughput: isSet(object.throughput) ? globalThis.Number(object.throughput) : 0,
      kmsKeyArn: isSet(object.kmsKeyArn) ? globalThis.String(object.kmsKeyArn) : "",
    };
  },

  toJSON(message: AwsVolumeTemplate): unknown {
    const obj: any = {};
    if (message.sizeGib !== 0) {
      obj.sizeGib = Math.round(message.sizeGib);
    }
    if (message.volumeType !== 0) {
      obj.volumeType = awsVolumeTemplate_VolumeTypeToJSON(message.volumeType);
    }
    if (message.iops !== 0) {
      obj.iops = Math.round(message.iops);
    }
    if (message.throughput !== 0) {
      obj.throughput = Math.round(message.throughput);
    }
    if (message.kmsKeyArn !== "") {
      obj.kmsKeyArn = message.kmsKeyArn;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsVolumeTemplate>): AwsVolumeTemplate {
    return AwsVolumeTemplate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsVolumeTemplate>): AwsVolumeTemplate {
    const message = createBaseAwsVolumeTemplate();
    message.sizeGib = object.sizeGib ?? 0;
    message.volumeType = object.volumeType ?? 0;
    message.iops = object.iops ?? 0;
    message.throughput = object.throughput ?? 0;
    message.kmsKeyArn = object.kmsKeyArn ?? "";
    return message;
  },
};

function createBaseAwsClusterNetworking(): AwsClusterNetworking {
  return { vpcId: "", podAddressCidrBlocks: [], serviceAddressCidrBlocks: [], perNodePoolSgRulesDisabled: false };
}

export const AwsClusterNetworking: MessageFns<AwsClusterNetworking> = {
  encode(message: AwsClusterNetworking, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vpcId !== "") {
      writer.uint32(10).string(message.vpcId);
    }
    for (const v of message.podAddressCidrBlocks) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.serviceAddressCidrBlocks) {
      writer.uint32(26).string(v!);
    }
    if (message.perNodePoolSgRulesDisabled !== false) {
      writer.uint32(40).bool(message.perNodePoolSgRulesDisabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsClusterNetworking {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsClusterNetworking();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vpcId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.podAddressCidrBlocks.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.serviceAddressCidrBlocks.push(reader.string());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.perNodePoolSgRulesDisabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsClusterNetworking {
    return {
      vpcId: isSet(object.vpcId) ? globalThis.String(object.vpcId) : "",
      podAddressCidrBlocks: globalThis.Array.isArray(object?.podAddressCidrBlocks)
        ? object.podAddressCidrBlocks.map((e: any) => globalThis.String(e))
        : [],
      serviceAddressCidrBlocks: globalThis.Array.isArray(object?.serviceAddressCidrBlocks)
        ? object.serviceAddressCidrBlocks.map((e: any) => globalThis.String(e))
        : [],
      perNodePoolSgRulesDisabled: isSet(object.perNodePoolSgRulesDisabled)
        ? globalThis.Boolean(object.perNodePoolSgRulesDisabled)
        : false,
    };
  },

  toJSON(message: AwsClusterNetworking): unknown {
    const obj: any = {};
    if (message.vpcId !== "") {
      obj.vpcId = message.vpcId;
    }
    if (message.podAddressCidrBlocks?.length) {
      obj.podAddressCidrBlocks = message.podAddressCidrBlocks;
    }
    if (message.serviceAddressCidrBlocks?.length) {
      obj.serviceAddressCidrBlocks = message.serviceAddressCidrBlocks;
    }
    if (message.perNodePoolSgRulesDisabled !== false) {
      obj.perNodePoolSgRulesDisabled = message.perNodePoolSgRulesDisabled;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsClusterNetworking>): AwsClusterNetworking {
    return AwsClusterNetworking.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsClusterNetworking>): AwsClusterNetworking {
    const message = createBaseAwsClusterNetworking();
    message.vpcId = object.vpcId ?? "";
    message.podAddressCidrBlocks = object.podAddressCidrBlocks?.map((e) => e) || [];
    message.serviceAddressCidrBlocks = object.serviceAddressCidrBlocks?.map((e) => e) || [];
    message.perNodePoolSgRulesDisabled = object.perNodePoolSgRulesDisabled ?? false;
    return message;
  },
};

function createBaseAwsNodePool(): AwsNodePool {
  return {
    name: "",
    version: "",
    config: undefined,
    autoscaling: undefined,
    subnetId: "",
    state: 0,
    uid: "",
    reconciling: false,
    createTime: undefined,
    updateTime: undefined,
    etag: "",
    annotations: {},
    maxPodsConstraint: undefined,
    errors: [],
    management: undefined,
    kubeletConfig: undefined,
    updateSettings: undefined,
  };
}

export const AwsNodePool: MessageFns<AwsNodePool> = {
  encode(message: AwsNodePool, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.version !== "") {
      writer.uint32(26).string(message.version);
    }
    if (message.config !== undefined) {
      AwsNodeConfig.encode(message.config, writer.uint32(226).fork()).join();
    }
    if (message.autoscaling !== undefined) {
      AwsNodePoolAutoscaling.encode(message.autoscaling, writer.uint32(202).fork()).join();
    }
    if (message.subnetId !== "") {
      writer.uint32(50).string(message.subnetId);
    }
    if (message.state !== 0) {
      writer.uint32(128).int32(message.state);
    }
    if (message.uid !== "") {
      writer.uint32(138).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(144).bool(message.reconciling);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(154).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(162).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(170).string(message.etag);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      AwsNodePool_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(178).fork()).join();
    });
    if (message.maxPodsConstraint !== undefined) {
      MaxPodsConstraint.encode(message.maxPodsConstraint, writer.uint32(218).fork()).join();
    }
    for (const v of message.errors) {
      AwsNodePoolError.encode(v!, writer.uint32(234).fork()).join();
    }
    if (message.management !== undefined) {
      AwsNodeManagement.encode(message.management, writer.uint32(242).fork()).join();
    }
    if (message.kubeletConfig !== undefined) {
      NodeKubeletConfig.encode(message.kubeletConfig, writer.uint32(250).fork()).join();
    }
    if (message.updateSettings !== undefined) {
      UpdateSettings.encode(message.updateSettings, writer.uint32(258).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodePool {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodePool();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.version = reader.string();
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.config = AwsNodeConfig.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.autoscaling = AwsNodePoolAutoscaling.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.subnetId = reader.string();
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          const entry22 = AwsNodePool_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry22.value !== undefined) {
            message.annotations[entry22.key] = entry22.value;
          }
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.maxPodsConstraint = MaxPodsConstraint.decode(reader, reader.uint32());
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.errors.push(AwsNodePoolError.decode(reader, reader.uint32()));
          continue;
        case 30:
          if (tag !== 242) {
            break;
          }

          message.management = AwsNodeManagement.decode(reader, reader.uint32());
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.kubeletConfig = NodeKubeletConfig.decode(reader, reader.uint32());
          continue;
        case 32:
          if (tag !== 258) {
            break;
          }

          message.updateSettings = UpdateSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodePool {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      config: isSet(object.config) ? AwsNodeConfig.fromJSON(object.config) : undefined,
      autoscaling: isSet(object.autoscaling) ? AwsNodePoolAutoscaling.fromJSON(object.autoscaling) : undefined,
      subnetId: isSet(object.subnetId) ? globalThis.String(object.subnetId) : "",
      state: isSet(object.state) ? awsNodePool_StateFromJSON(object.state) : 0,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      maxPodsConstraint: isSet(object.maxPodsConstraint)
        ? MaxPodsConstraint.fromJSON(object.maxPodsConstraint)
        : undefined,
      errors: globalThis.Array.isArray(object?.errors)
        ? object.errors.map((e: any) => AwsNodePoolError.fromJSON(e))
        : [],
      management: isSet(object.management) ? AwsNodeManagement.fromJSON(object.management) : undefined,
      kubeletConfig: isSet(object.kubeletConfig) ? NodeKubeletConfig.fromJSON(object.kubeletConfig) : undefined,
      updateSettings: isSet(object.updateSettings) ? UpdateSettings.fromJSON(object.updateSettings) : undefined,
    };
  },

  toJSON(message: AwsNodePool): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.config !== undefined) {
      obj.config = AwsNodeConfig.toJSON(message.config);
    }
    if (message.autoscaling !== undefined) {
      obj.autoscaling = AwsNodePoolAutoscaling.toJSON(message.autoscaling);
    }
    if (message.subnetId !== "") {
      obj.subnetId = message.subnetId;
    }
    if (message.state !== 0) {
      obj.state = awsNodePool_StateToJSON(message.state);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.maxPodsConstraint !== undefined) {
      obj.maxPodsConstraint = MaxPodsConstraint.toJSON(message.maxPodsConstraint);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => AwsNodePoolError.toJSON(e));
    }
    if (message.management !== undefined) {
      obj.management = AwsNodeManagement.toJSON(message.management);
    }
    if (message.kubeletConfig !== undefined) {
      obj.kubeletConfig = NodeKubeletConfig.toJSON(message.kubeletConfig);
    }
    if (message.updateSettings !== undefined) {
      obj.updateSettings = UpdateSettings.toJSON(message.updateSettings);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodePool>): AwsNodePool {
    return AwsNodePool.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodePool>): AwsNodePool {
    const message = createBaseAwsNodePool();
    message.name = object.name ?? "";
    message.version = object.version ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? AwsNodeConfig.fromPartial(object.config)
      : undefined;
    message.autoscaling = (object.autoscaling !== undefined && object.autoscaling !== null)
      ? AwsNodePoolAutoscaling.fromPartial(object.autoscaling)
      : undefined;
    message.subnetId = object.subnetId ?? "";
    message.state = object.state ?? 0;
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.etag = object.etag ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.maxPodsConstraint = (object.maxPodsConstraint !== undefined && object.maxPodsConstraint !== null)
      ? MaxPodsConstraint.fromPartial(object.maxPodsConstraint)
      : undefined;
    message.errors = object.errors?.map((e) => AwsNodePoolError.fromPartial(e)) || [];
    message.management = (object.management !== undefined && object.management !== null)
      ? AwsNodeManagement.fromPartial(object.management)
      : undefined;
    message.kubeletConfig = (object.kubeletConfig !== undefined && object.kubeletConfig !== null)
      ? NodeKubeletConfig.fromPartial(object.kubeletConfig)
      : undefined;
    message.updateSettings = (object.updateSettings !== undefined && object.updateSettings !== null)
      ? UpdateSettings.fromPartial(object.updateSettings)
      : undefined;
    return message;
  },
};

function createBaseAwsNodePool_AnnotationsEntry(): AwsNodePool_AnnotationsEntry {
  return { key: "", value: "" };
}

export const AwsNodePool_AnnotationsEntry: MessageFns<AwsNodePool_AnnotationsEntry> = {
  encode(message: AwsNodePool_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodePool_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodePool_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodePool_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsNodePool_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodePool_AnnotationsEntry>): AwsNodePool_AnnotationsEntry {
    return AwsNodePool_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodePool_AnnotationsEntry>): AwsNodePool_AnnotationsEntry {
    const message = createBaseAwsNodePool_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseUpdateSettings(): UpdateSettings {
  return { surgeSettings: undefined };
}

export const UpdateSettings: MessageFns<UpdateSettings> = {
  encode(message: UpdateSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.surgeSettings !== undefined) {
      SurgeSettings.encode(message.surgeSettings, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.surgeSettings = SurgeSettings.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateSettings {
    return { surgeSettings: isSet(object.surgeSettings) ? SurgeSettings.fromJSON(object.surgeSettings) : undefined };
  },

  toJSON(message: UpdateSettings): unknown {
    const obj: any = {};
    if (message.surgeSettings !== undefined) {
      obj.surgeSettings = SurgeSettings.toJSON(message.surgeSettings);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateSettings>): UpdateSettings {
    return UpdateSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateSettings>): UpdateSettings {
    const message = createBaseUpdateSettings();
    message.surgeSettings = (object.surgeSettings !== undefined && object.surgeSettings !== null)
      ? SurgeSettings.fromPartial(object.surgeSettings)
      : undefined;
    return message;
  },
};

function createBaseSurgeSettings(): SurgeSettings {
  return { maxSurge: 0, maxUnavailable: 0 };
}

export const SurgeSettings: MessageFns<SurgeSettings> = {
  encode(message: SurgeSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxSurge !== 0) {
      writer.uint32(8).int32(message.maxSurge);
    }
    if (message.maxUnavailable !== 0) {
      writer.uint32(16).int32(message.maxUnavailable);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SurgeSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSurgeSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.maxSurge = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxUnavailable = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SurgeSettings {
    return {
      maxSurge: isSet(object.maxSurge) ? globalThis.Number(object.maxSurge) : 0,
      maxUnavailable: isSet(object.maxUnavailable) ? globalThis.Number(object.maxUnavailable) : 0,
    };
  },

  toJSON(message: SurgeSettings): unknown {
    const obj: any = {};
    if (message.maxSurge !== 0) {
      obj.maxSurge = Math.round(message.maxSurge);
    }
    if (message.maxUnavailable !== 0) {
      obj.maxUnavailable = Math.round(message.maxUnavailable);
    }
    return obj;
  },

  create(base?: DeepPartial<SurgeSettings>): SurgeSettings {
    return SurgeSettings.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SurgeSettings>): SurgeSettings {
    const message = createBaseSurgeSettings();
    message.maxSurge = object.maxSurge ?? 0;
    message.maxUnavailable = object.maxUnavailable ?? 0;
    return message;
  },
};

function createBaseAwsNodeManagement(): AwsNodeManagement {
  return { autoRepair: false };
}

export const AwsNodeManagement: MessageFns<AwsNodeManagement> = {
  encode(message: AwsNodeManagement, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.autoRepair !== false) {
      writer.uint32(8).bool(message.autoRepair);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodeManagement {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodeManagement();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.autoRepair = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodeManagement {
    return { autoRepair: isSet(object.autoRepair) ? globalThis.Boolean(object.autoRepair) : false };
  },

  toJSON(message: AwsNodeManagement): unknown {
    const obj: any = {};
    if (message.autoRepair !== false) {
      obj.autoRepair = message.autoRepair;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodeManagement>): AwsNodeManagement {
    return AwsNodeManagement.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodeManagement>): AwsNodeManagement {
    const message = createBaseAwsNodeManagement();
    message.autoRepair = object.autoRepair ?? false;
    return message;
  },
};

function createBaseAwsNodeConfig(): AwsNodeConfig {
  return {
    instanceType: "",
    rootVolume: undefined,
    taints: [],
    labels: {},
    tags: {},
    iamInstanceProfile: "",
    imageType: "",
    sshConfig: undefined,
    securityGroupIds: [],
    proxyConfig: undefined,
    configEncryption: undefined,
    instancePlacement: undefined,
    autoscalingMetricsCollection: undefined,
    spotConfig: undefined,
  };
}

export const AwsNodeConfig: MessageFns<AwsNodeConfig> = {
  encode(message: AwsNodeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instanceType !== "") {
      writer.uint32(10).string(message.instanceType);
    }
    if (message.rootVolume !== undefined) {
      AwsVolumeTemplate.encode(message.rootVolume, writer.uint32(18).fork()).join();
    }
    for (const v of message.taints) {
      NodeTaint.encode(v!, writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      AwsNodeConfig_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.tags).forEach(([key, value]) => {
      AwsNodeConfig_TagsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.iamInstanceProfile !== "") {
      writer.uint32(50).string(message.iamInstanceProfile);
    }
    if (message.imageType !== "") {
      writer.uint32(90).string(message.imageType);
    }
    if (message.sshConfig !== undefined) {
      AwsSshConfig.encode(message.sshConfig, writer.uint32(74).fork()).join();
    }
    for (const v of message.securityGroupIds) {
      writer.uint32(82).string(v!);
    }
    if (message.proxyConfig !== undefined) {
      AwsProxyConfig.encode(message.proxyConfig, writer.uint32(98).fork()).join();
    }
    if (message.configEncryption !== undefined) {
      AwsConfigEncryption.encode(message.configEncryption, writer.uint32(106).fork()).join();
    }
    if (message.instancePlacement !== undefined) {
      AwsInstancePlacement.encode(message.instancePlacement, writer.uint32(114).fork()).join();
    }
    if (message.autoscalingMetricsCollection !== undefined) {
      AwsAutoscalingGroupMetricsCollection.encode(message.autoscalingMetricsCollection, writer.uint32(122).fork())
        .join();
    }
    if (message.spotConfig !== undefined) {
      SpotConfig.encode(message.spotConfig, writer.uint32(130).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instanceType = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rootVolume = AwsVolumeTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.taints.push(NodeTaint.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = AwsNodeConfig_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = AwsNodeConfig_TagsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.tags[entry5.key] = entry5.value;
          }
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.iamInstanceProfile = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.imageType = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.sshConfig = AwsSshConfig.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.securityGroupIds.push(reader.string());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.proxyConfig = AwsProxyConfig.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.configEncryption = AwsConfigEncryption.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.instancePlacement = AwsInstancePlacement.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.autoscalingMetricsCollection = AwsAutoscalingGroupMetricsCollection.decode(reader, reader.uint32());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.spotConfig = SpotConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodeConfig {
    return {
      instanceType: isSet(object.instanceType) ? globalThis.String(object.instanceType) : "",
      rootVolume: isSet(object.rootVolume) ? AwsVolumeTemplate.fromJSON(object.rootVolume) : undefined,
      taints: globalThis.Array.isArray(object?.taints) ? object.taints.map((e: any) => NodeTaint.fromJSON(e)) : [],
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      tags: isObject(object.tags)
        ? Object.entries(object.tags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      iamInstanceProfile: isSet(object.iamInstanceProfile) ? globalThis.String(object.iamInstanceProfile) : "",
      imageType: isSet(object.imageType) ? globalThis.String(object.imageType) : "",
      sshConfig: isSet(object.sshConfig) ? AwsSshConfig.fromJSON(object.sshConfig) : undefined,
      securityGroupIds: globalThis.Array.isArray(object?.securityGroupIds)
        ? object.securityGroupIds.map((e: any) => globalThis.String(e))
        : [],
      proxyConfig: isSet(object.proxyConfig) ? AwsProxyConfig.fromJSON(object.proxyConfig) : undefined,
      configEncryption: isSet(object.configEncryption)
        ? AwsConfigEncryption.fromJSON(object.configEncryption)
        : undefined,
      instancePlacement: isSet(object.instancePlacement)
        ? AwsInstancePlacement.fromJSON(object.instancePlacement)
        : undefined,
      autoscalingMetricsCollection: isSet(object.autoscalingMetricsCollection)
        ? AwsAutoscalingGroupMetricsCollection.fromJSON(object.autoscalingMetricsCollection)
        : undefined,
      spotConfig: isSet(object.spotConfig) ? SpotConfig.fromJSON(object.spotConfig) : undefined,
    };
  },

  toJSON(message: AwsNodeConfig): unknown {
    const obj: any = {};
    if (message.instanceType !== "") {
      obj.instanceType = message.instanceType;
    }
    if (message.rootVolume !== undefined) {
      obj.rootVolume = AwsVolumeTemplate.toJSON(message.rootVolume);
    }
    if (message.taints?.length) {
      obj.taints = message.taints.map((e) => NodeTaint.toJSON(e));
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.tags) {
      const entries = Object.entries(message.tags);
      if (entries.length > 0) {
        obj.tags = {};
        entries.forEach(([k, v]) => {
          obj.tags[k] = v;
        });
      }
    }
    if (message.iamInstanceProfile !== "") {
      obj.iamInstanceProfile = message.iamInstanceProfile;
    }
    if (message.imageType !== "") {
      obj.imageType = message.imageType;
    }
    if (message.sshConfig !== undefined) {
      obj.sshConfig = AwsSshConfig.toJSON(message.sshConfig);
    }
    if (message.securityGroupIds?.length) {
      obj.securityGroupIds = message.securityGroupIds;
    }
    if (message.proxyConfig !== undefined) {
      obj.proxyConfig = AwsProxyConfig.toJSON(message.proxyConfig);
    }
    if (message.configEncryption !== undefined) {
      obj.configEncryption = AwsConfigEncryption.toJSON(message.configEncryption);
    }
    if (message.instancePlacement !== undefined) {
      obj.instancePlacement = AwsInstancePlacement.toJSON(message.instancePlacement);
    }
    if (message.autoscalingMetricsCollection !== undefined) {
      obj.autoscalingMetricsCollection = AwsAutoscalingGroupMetricsCollection.toJSON(
        message.autoscalingMetricsCollection,
      );
    }
    if (message.spotConfig !== undefined) {
      obj.spotConfig = SpotConfig.toJSON(message.spotConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodeConfig>): AwsNodeConfig {
    return AwsNodeConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodeConfig>): AwsNodeConfig {
    const message = createBaseAwsNodeConfig();
    message.instanceType = object.instanceType ?? "";
    message.rootVolume = (object.rootVolume !== undefined && object.rootVolume !== null)
      ? AwsVolumeTemplate.fromPartial(object.rootVolume)
      : undefined;
    message.taints = object.taints?.map((e) => NodeTaint.fromPartial(e)) || [];
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.tags = Object.entries(object.tags ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.iamInstanceProfile = object.iamInstanceProfile ?? "";
    message.imageType = object.imageType ?? "";
    message.sshConfig = (object.sshConfig !== undefined && object.sshConfig !== null)
      ? AwsSshConfig.fromPartial(object.sshConfig)
      : undefined;
    message.securityGroupIds = object.securityGroupIds?.map((e) => e) || [];
    message.proxyConfig = (object.proxyConfig !== undefined && object.proxyConfig !== null)
      ? AwsProxyConfig.fromPartial(object.proxyConfig)
      : undefined;
    message.configEncryption = (object.configEncryption !== undefined && object.configEncryption !== null)
      ? AwsConfigEncryption.fromPartial(object.configEncryption)
      : undefined;
    message.instancePlacement = (object.instancePlacement !== undefined && object.instancePlacement !== null)
      ? AwsInstancePlacement.fromPartial(object.instancePlacement)
      : undefined;
    message.autoscalingMetricsCollection =
      (object.autoscalingMetricsCollection !== undefined && object.autoscalingMetricsCollection !== null)
        ? AwsAutoscalingGroupMetricsCollection.fromPartial(object.autoscalingMetricsCollection)
        : undefined;
    message.spotConfig = (object.spotConfig !== undefined && object.spotConfig !== null)
      ? SpotConfig.fromPartial(object.spotConfig)
      : undefined;
    return message;
  },
};

function createBaseAwsNodeConfig_LabelsEntry(): AwsNodeConfig_LabelsEntry {
  return { key: "", value: "" };
}

export const AwsNodeConfig_LabelsEntry: MessageFns<AwsNodeConfig_LabelsEntry> = {
  encode(message: AwsNodeConfig_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodeConfig_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodeConfig_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodeConfig_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsNodeConfig_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodeConfig_LabelsEntry>): AwsNodeConfig_LabelsEntry {
    return AwsNodeConfig_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodeConfig_LabelsEntry>): AwsNodeConfig_LabelsEntry {
    const message = createBaseAwsNodeConfig_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAwsNodeConfig_TagsEntry(): AwsNodeConfig_TagsEntry {
  return { key: "", value: "" };
}

export const AwsNodeConfig_TagsEntry: MessageFns<AwsNodeConfig_TagsEntry> = {
  encode(message: AwsNodeConfig_TagsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodeConfig_TagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodeConfig_TagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodeConfig_TagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsNodeConfig_TagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodeConfig_TagsEntry>): AwsNodeConfig_TagsEntry {
    return AwsNodeConfig_TagsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodeConfig_TagsEntry>): AwsNodeConfig_TagsEntry {
    const message = createBaseAwsNodeConfig_TagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAwsNodePoolAutoscaling(): AwsNodePoolAutoscaling {
  return { minNodeCount: 0, maxNodeCount: 0 };
}

export const AwsNodePoolAutoscaling: MessageFns<AwsNodePoolAutoscaling> = {
  encode(message: AwsNodePoolAutoscaling, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minNodeCount !== 0) {
      writer.uint32(8).int32(message.minNodeCount);
    }
    if (message.maxNodeCount !== 0) {
      writer.uint32(16).int32(message.maxNodeCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodePoolAutoscaling {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodePoolAutoscaling();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.minNodeCount = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxNodeCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodePoolAutoscaling {
    return {
      minNodeCount: isSet(object.minNodeCount) ? globalThis.Number(object.minNodeCount) : 0,
      maxNodeCount: isSet(object.maxNodeCount) ? globalThis.Number(object.maxNodeCount) : 0,
    };
  },

  toJSON(message: AwsNodePoolAutoscaling): unknown {
    const obj: any = {};
    if (message.minNodeCount !== 0) {
      obj.minNodeCount = Math.round(message.minNodeCount);
    }
    if (message.maxNodeCount !== 0) {
      obj.maxNodeCount = Math.round(message.maxNodeCount);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodePoolAutoscaling>): AwsNodePoolAutoscaling {
    return AwsNodePoolAutoscaling.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodePoolAutoscaling>): AwsNodePoolAutoscaling {
    const message = createBaseAwsNodePoolAutoscaling();
    message.minNodeCount = object.minNodeCount ?? 0;
    message.maxNodeCount = object.maxNodeCount ?? 0;
    return message;
  },
};

function createBaseAwsOpenIdConfig(): AwsOpenIdConfig {
  return {
    issuer: "",
    jwksUri: "",
    responseTypesSupported: [],
    subjectTypesSupported: [],
    idTokenSigningAlgValuesSupported: [],
    claimsSupported: [],
    grantTypes: [],
  };
}

export const AwsOpenIdConfig: MessageFns<AwsOpenIdConfig> = {
  encode(message: AwsOpenIdConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.issuer !== "") {
      writer.uint32(10).string(message.issuer);
    }
    if (message.jwksUri !== "") {
      writer.uint32(18).string(message.jwksUri);
    }
    for (const v of message.responseTypesSupported) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.subjectTypesSupported) {
      writer.uint32(34).string(v!);
    }
    for (const v of message.idTokenSigningAlgValuesSupported) {
      writer.uint32(42).string(v!);
    }
    for (const v of message.claimsSupported) {
      writer.uint32(50).string(v!);
    }
    for (const v of message.grantTypes) {
      writer.uint32(58).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsOpenIdConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsOpenIdConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.issuer = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jwksUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.responseTypesSupported.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.subjectTypesSupported.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.idTokenSigningAlgValuesSupported.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.claimsSupported.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.grantTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsOpenIdConfig {
    return {
      issuer: isSet(object.issuer) ? globalThis.String(object.issuer) : "",
      jwksUri: isSet(object.jwksUri) ? globalThis.String(object.jwksUri) : "",
      responseTypesSupported: globalThis.Array.isArray(object?.responseTypesSupported)
        ? object.responseTypesSupported.map((e: any) => globalThis.String(e))
        : [],
      subjectTypesSupported: globalThis.Array.isArray(object?.subjectTypesSupported)
        ? object.subjectTypesSupported.map((e: any) => globalThis.String(e))
        : [],
      idTokenSigningAlgValuesSupported: globalThis.Array.isArray(object?.idTokenSigningAlgValuesSupported)
        ? object.idTokenSigningAlgValuesSupported.map((e: any) => globalThis.String(e))
        : [],
      claimsSupported: globalThis.Array.isArray(object?.claimsSupported)
        ? object.claimsSupported.map((e: any) => globalThis.String(e))
        : [],
      grantTypes: globalThis.Array.isArray(object?.grantTypes)
        ? object.grantTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: AwsOpenIdConfig): unknown {
    const obj: any = {};
    if (message.issuer !== "") {
      obj.issuer = message.issuer;
    }
    if (message.jwksUri !== "") {
      obj.jwksUri = message.jwksUri;
    }
    if (message.responseTypesSupported?.length) {
      obj.responseTypesSupported = message.responseTypesSupported;
    }
    if (message.subjectTypesSupported?.length) {
      obj.subjectTypesSupported = message.subjectTypesSupported;
    }
    if (message.idTokenSigningAlgValuesSupported?.length) {
      obj.idTokenSigningAlgValuesSupported = message.idTokenSigningAlgValuesSupported;
    }
    if (message.claimsSupported?.length) {
      obj.claimsSupported = message.claimsSupported;
    }
    if (message.grantTypes?.length) {
      obj.grantTypes = message.grantTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsOpenIdConfig>): AwsOpenIdConfig {
    return AwsOpenIdConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsOpenIdConfig>): AwsOpenIdConfig {
    const message = createBaseAwsOpenIdConfig();
    message.issuer = object.issuer ?? "";
    message.jwksUri = object.jwksUri ?? "";
    message.responseTypesSupported = object.responseTypesSupported?.map((e) => e) || [];
    message.subjectTypesSupported = object.subjectTypesSupported?.map((e) => e) || [];
    message.idTokenSigningAlgValuesSupported = object.idTokenSigningAlgValuesSupported?.map((e) => e) || [];
    message.claimsSupported = object.claimsSupported?.map((e) => e) || [];
    message.grantTypes = object.grantTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseAwsJsonWebKeys(): AwsJsonWebKeys {
  return { keys: [] };
}

export const AwsJsonWebKeys: MessageFns<AwsJsonWebKeys> = {
  encode(message: AwsJsonWebKeys, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.keys) {
      Jwk.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsJsonWebKeys {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsJsonWebKeys();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keys.push(Jwk.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsJsonWebKeys {
    return { keys: globalThis.Array.isArray(object?.keys) ? object.keys.map((e: any) => Jwk.fromJSON(e)) : [] };
  },

  toJSON(message: AwsJsonWebKeys): unknown {
    const obj: any = {};
    if (message.keys?.length) {
      obj.keys = message.keys.map((e) => Jwk.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AwsJsonWebKeys>): AwsJsonWebKeys {
    return AwsJsonWebKeys.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsJsonWebKeys>): AwsJsonWebKeys {
    const message = createBaseAwsJsonWebKeys();
    message.keys = object.keys?.map((e) => Jwk.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAwsServerConfig(): AwsServerConfig {
  return { name: "", validVersions: [], supportedAwsRegions: [] };
}

export const AwsServerConfig: MessageFns<AwsServerConfig> = {
  encode(message: AwsServerConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.validVersions) {
      AwsK8sVersionInfo.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.supportedAwsRegions) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsServerConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsServerConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.validVersions.push(AwsK8sVersionInfo.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.supportedAwsRegions.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsServerConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validVersions: globalThis.Array.isArray(object?.validVersions)
        ? object.validVersions.map((e: any) => AwsK8sVersionInfo.fromJSON(e))
        : [],
      supportedAwsRegions: globalThis.Array.isArray(object?.supportedAwsRegions)
        ? object.supportedAwsRegions.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: AwsServerConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validVersions?.length) {
      obj.validVersions = message.validVersions.map((e) => AwsK8sVersionInfo.toJSON(e));
    }
    if (message.supportedAwsRegions?.length) {
      obj.supportedAwsRegions = message.supportedAwsRegions;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsServerConfig>): AwsServerConfig {
    return AwsServerConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsServerConfig>): AwsServerConfig {
    const message = createBaseAwsServerConfig();
    message.name = object.name ?? "";
    message.validVersions = object.validVersions?.map((e) => AwsK8sVersionInfo.fromPartial(e)) || [];
    message.supportedAwsRegions = object.supportedAwsRegions?.map((e) => e) || [];
    return message;
  },
};

function createBaseAwsK8sVersionInfo(): AwsK8sVersionInfo {
  return { version: "", enabled: false, endOfLife: false, endOfLifeDate: undefined, releaseDate: undefined };
}

export const AwsK8sVersionInfo: MessageFns<AwsK8sVersionInfo> = {
  encode(message: AwsK8sVersionInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.enabled !== false) {
      writer.uint32(24).bool(message.enabled);
    }
    if (message.endOfLife !== false) {
      writer.uint32(32).bool(message.endOfLife);
    }
    if (message.endOfLifeDate !== undefined) {
      DateMessage.encode(message.endOfLifeDate, writer.uint32(42).fork()).join();
    }
    if (message.releaseDate !== undefined) {
      DateMessage.encode(message.releaseDate, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsK8sVersionInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsK8sVersionInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.endOfLife = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.endOfLifeDate = DateMessage.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.releaseDate = DateMessage.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsK8sVersionInfo {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      endOfLife: isSet(object.endOfLife) ? globalThis.Boolean(object.endOfLife) : false,
      endOfLifeDate: isSet(object.endOfLifeDate) ? DateMessage.fromJSON(object.endOfLifeDate) : undefined,
      releaseDate: isSet(object.releaseDate) ? DateMessage.fromJSON(object.releaseDate) : undefined,
    };
  },

  toJSON(message: AwsK8sVersionInfo): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.endOfLife !== false) {
      obj.endOfLife = message.endOfLife;
    }
    if (message.endOfLifeDate !== undefined) {
      obj.endOfLifeDate = DateMessage.toJSON(message.endOfLifeDate);
    }
    if (message.releaseDate !== undefined) {
      obj.releaseDate = DateMessage.toJSON(message.releaseDate);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsK8sVersionInfo>): AwsK8sVersionInfo {
    return AwsK8sVersionInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsK8sVersionInfo>): AwsK8sVersionInfo {
    const message = createBaseAwsK8sVersionInfo();
    message.version = object.version ?? "";
    message.enabled = object.enabled ?? false;
    message.endOfLife = object.endOfLife ?? false;
    message.endOfLifeDate = (object.endOfLifeDate !== undefined && object.endOfLifeDate !== null)
      ? DateMessage.fromPartial(object.endOfLifeDate)
      : undefined;
    message.releaseDate = (object.releaseDate !== undefined && object.releaseDate !== null)
      ? DateMessage.fromPartial(object.releaseDate)
      : undefined;
    return message;
  },
};

function createBaseAwsSshConfig(): AwsSshConfig {
  return { ec2KeyPair: "" };
}

export const AwsSshConfig: MessageFns<AwsSshConfig> = {
  encode(message: AwsSshConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.ec2KeyPair !== "") {
      writer.uint32(10).string(message.ec2KeyPair);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSshConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSshConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ec2KeyPair = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSshConfig {
    return { ec2KeyPair: isSet(object.ec2KeyPair) ? globalThis.String(object.ec2KeyPair) : "" };
  },

  toJSON(message: AwsSshConfig): unknown {
    const obj: any = {};
    if (message.ec2KeyPair !== "") {
      obj.ec2KeyPair = message.ec2KeyPair;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsSshConfig>): AwsSshConfig {
    return AwsSshConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsSshConfig>): AwsSshConfig {
    const message = createBaseAwsSshConfig();
    message.ec2KeyPair = object.ec2KeyPair ?? "";
    return message;
  },
};

function createBaseAwsProxyConfig(): AwsProxyConfig {
  return { secretArn: "", secretVersion: "" };
}

export const AwsProxyConfig: MessageFns<AwsProxyConfig> = {
  encode(message: AwsProxyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.secretArn !== "") {
      writer.uint32(10).string(message.secretArn);
    }
    if (message.secretVersion !== "") {
      writer.uint32(18).string(message.secretVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsProxyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsProxyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.secretArn = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.secretVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsProxyConfig {
    return {
      secretArn: isSet(object.secretArn) ? globalThis.String(object.secretArn) : "",
      secretVersion: isSet(object.secretVersion) ? globalThis.String(object.secretVersion) : "",
    };
  },

  toJSON(message: AwsProxyConfig): unknown {
    const obj: any = {};
    if (message.secretArn !== "") {
      obj.secretArn = message.secretArn;
    }
    if (message.secretVersion !== "") {
      obj.secretVersion = message.secretVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsProxyConfig>): AwsProxyConfig {
    return AwsProxyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsProxyConfig>): AwsProxyConfig {
    const message = createBaseAwsProxyConfig();
    message.secretArn = object.secretArn ?? "";
    message.secretVersion = object.secretVersion ?? "";
    return message;
  },
};

function createBaseAwsConfigEncryption(): AwsConfigEncryption {
  return { kmsKeyArn: "" };
}

export const AwsConfigEncryption: MessageFns<AwsConfigEncryption> = {
  encode(message: AwsConfigEncryption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKeyArn !== "") {
      writer.uint32(10).string(message.kmsKeyArn);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsConfigEncryption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsConfigEncryption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKeyArn = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsConfigEncryption {
    return { kmsKeyArn: isSet(object.kmsKeyArn) ? globalThis.String(object.kmsKeyArn) : "" };
  },

  toJSON(message: AwsConfigEncryption): unknown {
    const obj: any = {};
    if (message.kmsKeyArn !== "") {
      obj.kmsKeyArn = message.kmsKeyArn;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsConfigEncryption>): AwsConfigEncryption {
    return AwsConfigEncryption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsConfigEncryption>): AwsConfigEncryption {
    const message = createBaseAwsConfigEncryption();
    message.kmsKeyArn = object.kmsKeyArn ?? "";
    return message;
  },
};

function createBaseAwsInstancePlacement(): AwsInstancePlacement {
  return { tenancy: 0 };
}

export const AwsInstancePlacement: MessageFns<AwsInstancePlacement> = {
  encode(message: AwsInstancePlacement, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tenancy !== 0) {
      writer.uint32(8).int32(message.tenancy);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsInstancePlacement {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsInstancePlacement();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.tenancy = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsInstancePlacement {
    return { tenancy: isSet(object.tenancy) ? awsInstancePlacement_TenancyFromJSON(object.tenancy) : 0 };
  },

  toJSON(message: AwsInstancePlacement): unknown {
    const obj: any = {};
    if (message.tenancy !== 0) {
      obj.tenancy = awsInstancePlacement_TenancyToJSON(message.tenancy);
    }
    return obj;
  },

  create(base?: DeepPartial<AwsInstancePlacement>): AwsInstancePlacement {
    return AwsInstancePlacement.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsInstancePlacement>): AwsInstancePlacement {
    const message = createBaseAwsInstancePlacement();
    message.tenancy = object.tenancy ?? 0;
    return message;
  },
};

function createBaseAwsAutoscalingGroupMetricsCollection(): AwsAutoscalingGroupMetricsCollection {
  return { granularity: "", metrics: [] };
}

export const AwsAutoscalingGroupMetricsCollection: MessageFns<AwsAutoscalingGroupMetricsCollection> = {
  encode(message: AwsAutoscalingGroupMetricsCollection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.granularity !== "") {
      writer.uint32(10).string(message.granularity);
    }
    for (const v of message.metrics) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsAutoscalingGroupMetricsCollection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsAutoscalingGroupMetricsCollection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.granularity = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.metrics.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsAutoscalingGroupMetricsCollection {
    return {
      granularity: isSet(object.granularity) ? globalThis.String(object.granularity) : "",
      metrics: globalThis.Array.isArray(object?.metrics) ? object.metrics.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: AwsAutoscalingGroupMetricsCollection): unknown {
    const obj: any = {};
    if (message.granularity !== "") {
      obj.granularity = message.granularity;
    }
    if (message.metrics?.length) {
      obj.metrics = message.metrics;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsAutoscalingGroupMetricsCollection>): AwsAutoscalingGroupMetricsCollection {
    return AwsAutoscalingGroupMetricsCollection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsAutoscalingGroupMetricsCollection>): AwsAutoscalingGroupMetricsCollection {
    const message = createBaseAwsAutoscalingGroupMetricsCollection();
    message.granularity = object.granularity ?? "";
    message.metrics = object.metrics?.map((e) => e) || [];
    return message;
  },
};

function createBaseSpotConfig(): SpotConfig {
  return { instanceTypes: [] };
}

export const SpotConfig: MessageFns<SpotConfig> = {
  encode(message: SpotConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.instanceTypes) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpotConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpotConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instanceTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpotConfig {
    return {
      instanceTypes: globalThis.Array.isArray(object?.instanceTypes)
        ? object.instanceTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: SpotConfig): unknown {
    const obj: any = {};
    if (message.instanceTypes?.length) {
      obj.instanceTypes = message.instanceTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<SpotConfig>): SpotConfig {
    return SpotConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SpotConfig>): SpotConfig {
    const message = createBaseSpotConfig();
    message.instanceTypes = object.instanceTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseAwsClusterError(): AwsClusterError {
  return { message: "" };
}

export const AwsClusterError: MessageFns<AwsClusterError> = {
  encode(message: AwsClusterError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsClusterError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsClusterError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsClusterError {
    return { message: isSet(object.message) ? globalThis.String(object.message) : "" };
  },

  toJSON(message: AwsClusterError): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsClusterError>): AwsClusterError {
    return AwsClusterError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsClusterError>): AwsClusterError {
    const message = createBaseAwsClusterError();
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseAwsNodePoolError(): AwsNodePoolError {
  return { message: "" };
}

export const AwsNodePoolError: MessageFns<AwsNodePoolError> = {
  encode(message: AwsNodePoolError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsNodePoolError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsNodePoolError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsNodePoolError {
    return { message: isSet(object.message) ? globalThis.String(object.message) : "" };
  },

  toJSON(message: AwsNodePoolError): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsNodePoolError>): AwsNodePoolError {
    return AwsNodePoolError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsNodePoolError>): AwsNodePoolError {
    const message = createBaseAwsNodePoolError();
    message.message = object.message ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
