// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/gkemulticloud/v1/azure_resources.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { DateMessage } from "../../../type/date.js";
import {
  Fleet,
  Jwk,
  LoggingConfig,
  MaxPodsConstraint,
  MonitoringConfig,
  NodeTaint,
  WorkloadIdentityConfig,
} from "./common_resources.js";

export const protobufPackage = "google.cloud.gkemulticloud.v1";

/** An Anthos cluster running on Azure. */
export interface AzureCluster {
  /**
   * The name of this resource.
   *
   * Cluster names are formatted as
   * `projects/<project-number>/locations/<region>/azureClusters/<cluster-id>`.
   *
   * See [Resource Names](https://cloud.google.com/apis/design/resource_names)
   * for more details on Google Cloud Platform resource names.
   */
  name: string;
  /**
   * Optional. A human readable description of this cluster.
   * Cannot be longer than 255 UTF-8 encoded bytes.
   */
  description: string;
  /**
   * Required. The Azure region where the cluster runs.
   *
   * Each Google Cloud region supports a subset of nearby Azure regions.
   * You can call
   * [GetAzureServerConfig][google.cloud.gkemulticloud.v1.AzureClusters.GetAzureServerConfig]
   * to list all supported Azure regions within a given Google Cloud region.
   */
  azureRegion: string;
  /**
   * Required. The ARM ID of the resource group where the cluster resources are
   * deployed. For example:
   * `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
   */
  resourceGroupId: string;
  /**
   * Optional. Name of the
   * [AzureClient][google.cloud.gkemulticloud.v1.AzureClient] that contains
   * authentication configuration for how the Anthos Multi-Cloud API connects to
   * Azure APIs.
   *
   * Either azure_client or azure_services_authentication should be provided.
   *
   * The `AzureClient` resource must reside on the same Google Cloud Platform
   * project and region as the `AzureCluster`.
   *
   * `AzureClient` names are formatted as
   * `projects/<project-number>/locations/<region>/azureClients/<client-id>`.
   *
   * See [Resource Names](https://cloud.google.com/apis/design/resource_names)
   * for more details on Google Cloud resource names.
   */
  azureClient: string;
  /** Required. Cluster-wide networking configuration. */
  networking:
    | AzureClusterNetworking
    | undefined;
  /** Required. Configuration related to the cluster control plane. */
  controlPlane:
    | AzureControlPlane
    | undefined;
  /** Required. Configuration related to the cluster RBAC settings. */
  authorization:
    | AzureAuthorization
    | undefined;
  /**
   * Optional. Authentication configuration for management of Azure resources.
   *
   * Either azure_client or azure_services_authentication should be provided.
   */
  azureServicesAuthentication:
    | AzureServicesAuthentication
    | undefined;
  /** Output only. The current state of the cluster. */
  state: AzureCluster_State;
  /** Output only. The endpoint of the cluster's API server. */
  endpoint: string;
  /** Output only. A globally unique identifier for the cluster. */
  uid: string;
  /** Output only. If set, there are currently changes in flight to the cluster. */
  reconciling: boolean;
  /** Output only. The time at which this cluster was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time at which this cluster was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Allows clients to perform consistent read-modify-writes
   * through optimistic concurrency control.
   *
   * Can be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Optional. Annotations on the cluster.
   *
   * This field has the same restrictions as Kubernetes annotations.
   * The total size of all keys and values combined is limited to 256k.
   * Keys can have 2 segments: prefix (optional) and name (required),
   * separated by a slash (/).
   * Prefix must be a DNS subdomain.
   * Name must be 63 characters or less, begin and end with alphanumerics,
   * with dashes (-), underscores (_), dots (.), and alphanumerics between.
   */
  annotations: { [key: string]: string };
  /** Output only. Workload Identity settings. */
  workloadIdentityConfig:
    | WorkloadIdentityConfig
    | undefined;
  /** Output only. PEM encoded x509 certificate of the cluster root of trust. */
  clusterCaCertificate: string;
  /** Required. Fleet configuration. */
  fleet:
    | Fleet
    | undefined;
  /** Output only. Managed Azure resources for this cluster. */
  managedResources:
    | AzureClusterResources
    | undefined;
  /** Optional. Logging configuration for this cluster. */
  loggingConfig:
    | LoggingConfig
    | undefined;
  /** Output only. A set of errors found in the cluster. */
  errors: AzureClusterError[];
  /** Optional. Monitoring configuration for this cluster. */
  monitoringConfig: MonitoringConfig | undefined;
}

/** The lifecycle state of the cluster. */
export enum AzureCluster_State {
  /** STATE_UNSPECIFIED - Not set. */
  STATE_UNSPECIFIED = 0,
  /** PROVISIONING - The PROVISIONING state indicates the cluster is being created. */
  PROVISIONING = 1,
  /**
   * RUNNING - The RUNNING state indicates the cluster has been created and is fully
   * usable.
   */
  RUNNING = 2,
  /**
   * RECONCILING - The RECONCILING state indicates that some work is actively being done on
   * the cluster, such as upgrading the control plane replicas.
   */
  RECONCILING = 3,
  /** STOPPING - The STOPPING state indicates the cluster is being deleted. */
  STOPPING = 4,
  /**
   * ERROR - The ERROR state indicates the cluster is in a broken unrecoverable
   * state.
   */
  ERROR = 5,
  /**
   * DEGRADED - The DEGRADED state indicates the cluster requires user action to
   * restore full functionality.
   */
  DEGRADED = 6,
  UNRECOGNIZED = -1,
}

export function azureCluster_StateFromJSON(object: any): AzureCluster_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return AzureCluster_State.STATE_UNSPECIFIED;
    case 1:
    case "PROVISIONING":
      return AzureCluster_State.PROVISIONING;
    case 2:
    case "RUNNING":
      return AzureCluster_State.RUNNING;
    case 3:
    case "RECONCILING":
      return AzureCluster_State.RECONCILING;
    case 4:
    case "STOPPING":
      return AzureCluster_State.STOPPING;
    case 5:
    case "ERROR":
      return AzureCluster_State.ERROR;
    case 6:
    case "DEGRADED":
      return AzureCluster_State.DEGRADED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AzureCluster_State.UNRECOGNIZED;
  }
}

export function azureCluster_StateToJSON(object: AzureCluster_State): string {
  switch (object) {
    case AzureCluster_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case AzureCluster_State.PROVISIONING:
      return "PROVISIONING";
    case AzureCluster_State.RUNNING:
      return "RUNNING";
    case AzureCluster_State.RECONCILING:
      return "RECONCILING";
    case AzureCluster_State.STOPPING:
      return "STOPPING";
    case AzureCluster_State.ERROR:
      return "ERROR";
    case AzureCluster_State.DEGRADED:
      return "DEGRADED";
    case AzureCluster_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface AzureCluster_AnnotationsEntry {
  key: string;
  value: string;
}

/** ClusterNetworking contains cluster-wide networking configuration. */
export interface AzureClusterNetworking {
  /**
   * Required. The Azure Resource Manager (ARM) ID of the VNet associated with
   * your cluster.
   *
   * All components in the cluster (i.e. control plane and node pools) run on a
   * single VNet.
   *
   * Example:
   * `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.Network/virtualNetworks/<vnet-id>`
   *
   * This field cannot be changed after creation.
   */
  virtualNetworkId: string;
  /**
   * Required. The IP address range of the pods in this cluster, in CIDR
   * notation (e.g. `10.96.0.0/14`).
   *
   * All pods in the cluster get assigned a unique IPv4 address from these
   * ranges. Only a single range is supported.
   *
   * This field cannot be changed after creation.
   */
  podAddressCidrBlocks: string[];
  /**
   * Required. The IP address range for services in this cluster, in CIDR
   * notation (e.g. `10.96.0.0/14`).
   *
   * All services in the cluster get assigned a unique IPv4 address from these
   * ranges. Only a single range is supported.
   *
   * This field cannot be changed after creating a cluster.
   */
  serviceAddressCidrBlocks: string[];
  /**
   * Optional. The ARM ID of the subnet where Kubernetes private service type
   * load balancers are deployed. When unspecified, it defaults to
   * AzureControlPlane.subnet_id.
   *
   * Example:
   * "/subscriptions/d00494d6-6f3c-4280-bbb2-899e163d1d30/resourceGroups/anthos_cluster_gkeust4/providers/Microsoft.Network/virtualNetworks/gke-vnet-gkeust4/subnets/subnetid456"
   */
  serviceLoadBalancerSubnetId: string;
}

/** AzureControlPlane represents the control plane configurations. */
export interface AzureControlPlane {
  /**
   * Required. The Kubernetes version to run on control plane replicas
   * (e.g. `1.19.10-gke.1000`).
   *
   * You can list all supported versions on a given Google Cloud region by
   * calling
   * [GetAzureServerConfig][google.cloud.gkemulticloud.v1.AzureClusters.GetAzureServerConfig].
   */
  version: string;
  /**
   * Optional. The ARM ID of the default subnet for the control plane. The
   * control plane VMs are deployed in this subnet, unless
   * `AzureControlPlane.replica_placements` is specified. This subnet will also
   * be used as default for `AzureControlPlane.endpoint_subnet_id` if
   * `AzureControlPlane.endpoint_subnet_id` is not specified. Similarly it will
   * be used as default for
   * `AzureClusterNetworking.service_load_balancer_subnet_id`.
   *
   * Example:
   * `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.Network/virtualNetworks/<vnet-id>/subnets/default`.
   */
  subnetId: string;
  /**
   * Optional. The Azure VM size name. Example: `Standard_DS2_v2`.
   *
   * For available VM sizes, see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions.
   *
   * When unspecified, it defaults to `Standard_DS2_v2`.
   */
  vmSize: string;
  /**
   * Required. SSH configuration for how to access the underlying control plane
   * machines.
   */
  sshConfig:
    | AzureSshConfig
    | undefined;
  /**
   * Optional. Configuration related to the root volume provisioned for each
   * control plane replica.
   *
   * When unspecified, it defaults to 32-GiB Azure Disk.
   */
  rootVolume:
    | AzureDiskTemplate
    | undefined;
  /**
   * Optional. Configuration related to the main volume provisioned for each
   * control plane replica.
   * The main volume is in charge of storing all of the cluster's etcd state.
   *
   * When unspecified, it defaults to a 8-GiB Azure Disk.
   */
  mainVolume:
    | AzureDiskTemplate
    | undefined;
  /** Optional. Configuration related to application-layer secrets encryption. */
  databaseEncryption:
    | AzureDatabaseEncryption
    | undefined;
  /** Optional. Proxy configuration for outbound HTTP(S) traffic. */
  proxyConfig:
    | AzureProxyConfig
    | undefined;
  /** Optional. Configuration related to vm config encryption. */
  configEncryption:
    | AzureConfigEncryption
    | undefined;
  /**
   * Optional. A set of tags to apply to all underlying control plane Azure
   * resources.
   */
  tags: { [key: string]: string };
  /**
   * Optional. Configuration for where to place the control plane replicas.
   *
   * Up to three replica placement instances can be specified. If
   * replica_placements is set, the replica placement instances will be applied
   * to the three control plane replicas as evenly as possible.
   */
  replicaPlacements: ReplicaPlacement[];
  /**
   * Optional. The ARM ID of the subnet where the control plane load balancer is
   * deployed. When unspecified, it defaults to AzureControlPlane.subnet_id.
   *
   * Example:
   * "/subscriptions/d00494d6-6f3c-4280-bbb2-899e163d1d30/resourceGroups/anthos_cluster_gkeust4/providers/Microsoft.Network/virtualNetworks/gke-vnet-gkeust4/subnets/subnetid123"
   */
  endpointSubnetId: string;
}

export interface AzureControlPlane_TagsEntry {
  key: string;
  value: string;
}

/** Configuration for the placement of a control plane replica. */
export interface ReplicaPlacement {
  /**
   * Required. For a given replica, the ARM ID of the subnet where the control
   * plane VM is deployed. Make sure it's a subnet under the virtual network in
   * the cluster configuration.
   */
  subnetId: string;
  /**
   * Required. For a given replica, the Azure availability zone where to
   * provision the control plane VM and the ETCD disk.
   */
  azureAvailabilityZone: string;
}

/** Details of a proxy config stored in Azure Key Vault. */
export interface AzureProxyConfig {
  /**
   * The ARM ID the of the resource group containing proxy keyvault.
   *
   * Resource group ids are formatted as
   * `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`.
   */
  resourceGroupId: string;
  /**
   * The URL the of the proxy setting secret with its version.
   *
   * The secret must be a JSON encoded proxy configuration
   * as described in
   * https://cloud.google.com/kubernetes-engine/multi-cloud/docs/azure/how-to/use-a-proxy#create_a_proxy_configuration_file
   *
   * Secret ids are formatted as
   * `https://<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
   */
  secretId: string;
}

/**
 * Configuration related to application-layer secrets encryption.
 *
 * Anthos clusters on Azure encrypts your Kubernetes data at rest
 * in etcd using Azure Key Vault.
 */
export interface AzureDatabaseEncryption {
  /**
   * Required. The ARM ID of the Azure Key Vault key to encrypt / decrypt data.
   *
   * For example:
   * `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>`
   * Encryption will always take the latest version of the key and hence
   * specific version is not supported.
   */
  keyId: string;
}

/**
 * Configuration related to config data encryption.
 *
 * Azure VM bootstrap secret is envelope encrypted with the provided key vault
 * key.
 */
export interface AzureConfigEncryption {
  /**
   * Required. The ARM ID of the Azure Key Vault key to encrypt / decrypt config
   * data.
   *
   * For example:
   * `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>`
   */
  keyId: string;
  /**
   * Optional. RSA key of the Azure Key Vault public key to use for encrypting
   * the data.
   *
   * This key must be formatted as a PEM-encoded SubjectPublicKeyInfo (RFC 5280)
   * in ASN.1 DER form. The string must be comprised of a single PEM block of
   * type "PUBLIC KEY".
   */
  publicKey: string;
}

/** Configuration for Azure Disks. */
export interface AzureDiskTemplate {
  /**
   * Optional. The size of the disk, in GiBs.
   *
   * When unspecified, a default value is provided. See the specific reference
   * in the parent resource.
   */
  sizeGib: number;
}

/**
 * `AzureClient` resources hold client authentication information needed by the
 * Anthos Multi-Cloud API to manage Azure resources on your Azure subscription.
 *
 * When an [AzureCluster][google.cloud.gkemulticloud.v1.AzureCluster] is
 * created, an `AzureClient` resource needs to be provided and all operations on
 * Azure resources associated to that cluster will authenticate to Azure
 * services using the given client.
 *
 * `AzureClient` resources are immutable and cannot be modified upon creation.
 *
 * Each `AzureClient` resource is bound to a single Azure Active Directory
 * Application and tenant.
 */
export interface AzureClient {
  /**
   * The name of this resource.
   *
   * `AzureClient` resource names are formatted as
   * `projects/<project-number>/locations/<region>/azureClients/<client-id>`.
   *
   * See [Resource Names](https://cloud.google.com/apis/design/resource_names)
   * for more details on Google Cloud resource names.
   */
  name: string;
  /** Required. The Azure Active Directory Tenant ID. */
  tenantId: string;
  /** Required. The Azure Active Directory Application ID. */
  applicationId: string;
  /** Output only. If set, there are currently pending changes to the client. */
  reconciling: boolean;
  /**
   * Optional. Annotations on the resource.
   *
   * This field has the same restrictions as Kubernetes annotations.
   * The total size of all keys and values combined is limited to 256k.
   * Keys can have 2 segments: prefix (optional) and name (required),
   * separated by a slash (/).
   * Prefix must be a DNS subdomain.
   * Name must be 63 characters or less, begin and end with alphanumerics,
   * with dashes (-), underscores (_), dots (.), and alphanumerics between.
   */
  annotations: { [key: string]: string };
  /** Output only. The PEM encoded x509 certificate. */
  pemCertificate: string;
  /** Output only. A globally unique identifier for the client. */
  uid: string;
  /** Output only. The time at which this resource was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time at which this client was last updated. */
  updateTime: Date | undefined;
}

export interface AzureClient_AnnotationsEntry {
  key: string;
  value: string;
}

/** Configuration related to the cluster RBAC settings. */
export interface AzureAuthorization {
  /**
   * Optional. Users that can perform operations as a cluster admin. A managed
   * ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
   * to the users. Up to ten admin users can be provided.
   *
   * For more info on RBAC, see
   * https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
   */
  adminUsers: AzureClusterUser[];
  /**
   * Optional. Groups of users that can perform operations as a cluster admin. A
   * managed ClusterRoleBinding will be created to grant the `cluster-admin`
   * ClusterRole to the groups. Up to ten admin groups can be provided.
   *
   * For more info on RBAC, see
   * https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
   */
  adminGroups: AzureClusterGroup[];
}

/** Authentication configuration for the management of Azure resources. */
export interface AzureServicesAuthentication {
  /** Required. The Azure Active Directory Tenant ID. */
  tenantId: string;
  /** Required. The Azure Active Directory Application ID. */
  applicationId: string;
}

/** Identities of a user-type subject for Azure clusters. */
export interface AzureClusterUser {
  /** Required. The name of the user, e.g. `my-gcp-id@gmail.com`. */
  username: string;
}

/** Identities of a group-type subject for Azure clusters. */
export interface AzureClusterGroup {
  /** Required. The name of the group, e.g. `my-group@domain.com`. */
  group: string;
}

/** An Anthos node pool running on Azure. */
export interface AzureNodePool {
  /**
   * The name of this resource.
   *
   * Node pool names are formatted as
   * `projects/<project-number>/locations/<region>/azureClusters/<cluster-id>/azureNodePools/<node-pool-id>`.
   *
   * For more details on Google Cloud resource names,
   * see [Resource Names](https://cloud.google.com/apis/design/resource_names)
   */
  name: string;
  /**
   * Required. The Kubernetes version (e.g. `1.19.10-gke.1000`) running on this
   * node pool.
   */
  version: string;
  /** Required. The node configuration of the node pool. */
  config:
    | AzureNodeConfig
    | undefined;
  /**
   * Required. The ARM ID of the subnet where the node pool VMs run. Make sure
   * it's a subnet under the virtual network in the cluster configuration.
   */
  subnetId: string;
  /** Required. Autoscaler configuration for this node pool. */
  autoscaling:
    | AzureNodePoolAutoscaling
    | undefined;
  /** Output only. The current state of the node pool. */
  state: AzureNodePool_State;
  /** Output only. A globally unique identifier for the node pool. */
  uid: string;
  /**
   * Output only. If set, there are currently pending changes to the node
   * pool.
   */
  reconciling: boolean;
  /** Output only. The time at which this node pool was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time at which this node pool was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Allows clients to perform consistent read-modify-writes
   * through optimistic concurrency control.
   *
   * Can be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Optional. Annotations on the node pool.
   *
   * This field has the same restrictions as Kubernetes annotations.
   * The total size of all keys and values combined is limited to 256k.
   * Keys can have 2 segments: prefix (optional) and name (required),
   * separated by a slash (/).
   * Prefix must be a DNS subdomain.
   * Name must be 63 characters or less, begin and end with alphanumerics,
   * with dashes (-), underscores (_), dots (.), and alphanumerics between.
   */
  annotations: { [key: string]: string };
  /**
   * Required. The constraint on the maximum number of pods that can be run
   * simultaneously on a node in the node pool.
   */
  maxPodsConstraint:
    | MaxPodsConstraint
    | undefined;
  /**
   * Optional. The Azure availability zone of the nodes in this nodepool.
   *
   * When unspecified, it defaults to `1`.
   */
  azureAvailabilityZone: string;
  /** Output only. A set of errors found in the node pool. */
  errors: AzureNodePoolError[];
  /** Optional. The Management configuration for this node pool. */
  management: AzureNodeManagement | undefined;
}

/** The lifecycle state of the node pool. */
export enum AzureNodePool_State {
  /** STATE_UNSPECIFIED - Not set. */
  STATE_UNSPECIFIED = 0,
  /** PROVISIONING - The PROVISIONING state indicates the node pool is being created. */
  PROVISIONING = 1,
  /**
   * RUNNING - The RUNNING state indicates the node pool has been created and is fully
   * usable.
   */
  RUNNING = 2,
  /** RECONCILING - The RECONCILING state indicates that the node pool is being reconciled. */
  RECONCILING = 3,
  /** STOPPING - The STOPPING state indicates the node pool is being deleted. */
  STOPPING = 4,
  /**
   * ERROR - The ERROR state indicates the node pool is in a broken unrecoverable
   * state.
   */
  ERROR = 5,
  /**
   * DEGRADED - The DEGRADED state indicates the node pool requires user action to
   * restore full functionality.
   */
  DEGRADED = 6,
  UNRECOGNIZED = -1,
}

export function azureNodePool_StateFromJSON(object: any): AzureNodePool_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return AzureNodePool_State.STATE_UNSPECIFIED;
    case 1:
    case "PROVISIONING":
      return AzureNodePool_State.PROVISIONING;
    case 2:
    case "RUNNING":
      return AzureNodePool_State.RUNNING;
    case 3:
    case "RECONCILING":
      return AzureNodePool_State.RECONCILING;
    case 4:
    case "STOPPING":
      return AzureNodePool_State.STOPPING;
    case 5:
    case "ERROR":
      return AzureNodePool_State.ERROR;
    case 6:
    case "DEGRADED":
      return AzureNodePool_State.DEGRADED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AzureNodePool_State.UNRECOGNIZED;
  }
}

export function azureNodePool_StateToJSON(object: AzureNodePool_State): string {
  switch (object) {
    case AzureNodePool_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case AzureNodePool_State.PROVISIONING:
      return "PROVISIONING";
    case AzureNodePool_State.RUNNING:
      return "RUNNING";
    case AzureNodePool_State.RECONCILING:
      return "RECONCILING";
    case AzureNodePool_State.STOPPING:
      return "STOPPING";
    case AzureNodePool_State.ERROR:
      return "ERROR";
    case AzureNodePool_State.DEGRADED:
      return "DEGRADED";
    case AzureNodePool_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface AzureNodePool_AnnotationsEntry {
  key: string;
  value: string;
}

/**
 * AzureNodeManagement defines the set of node management features turned on for
 * an Azure node pool.
 */
export interface AzureNodeManagement {
  /**
   * Optional. Whether or not the nodes will be automatically repaired. When set
   * to true, the nodes in this node pool will be monitored and if they fail
   * health checks consistently over a period of time, an automatic repair
   * action will be triggered to replace them with new nodes.
   */
  autoRepair: boolean;
}

/**
 * Parameters that describe the configuration of all node machines
 * on a given node pool.
 */
export interface AzureNodeConfig {
  /**
   * Optional. The Azure VM size name. Example: `Standard_DS2_v2`.
   *
   * See [Supported VM
   * sizes](/anthos/clusters/docs/azure/reference/supported-vms) for options.
   *
   * When unspecified, it defaults to `Standard_DS2_v2`.
   */
  vmSize: string;
  /**
   * Optional. Configuration related to the root volume provisioned for each
   * node pool machine.
   *
   * When unspecified, it defaults to a 32-GiB Azure Disk.
   */
  rootVolume:
    | AzureDiskTemplate
    | undefined;
  /**
   * Optional. A set of tags to apply to all underlying Azure resources for this
   * node pool. This currently only includes Virtual Machine Scale Sets.
   *
   * Specify at most 50 pairs containing alphanumerics, spaces, and symbols
   * (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to
   * 255 Unicode characters.
   */
  tags: { [key: string]: string };
  /**
   * Optional. The OS image type to use on node pool instances.
   * Can be unspecified, or have a value of `ubuntu`.
   *
   * When unspecified, it defaults to `ubuntu`.
   */
  imageType: string;
  /** Required. SSH configuration for how to access the node pool machines. */
  sshConfig:
    | AzureSshConfig
    | undefined;
  /** Optional. Proxy configuration for outbound HTTP(S) traffic. */
  proxyConfig:
    | AzureProxyConfig
    | undefined;
  /** Optional. Configuration related to vm config encryption. */
  configEncryption:
    | AzureConfigEncryption
    | undefined;
  /** Optional. The initial taints assigned to nodes of this node pool. */
  taints: NodeTaint[];
  /**
   * Optional. The initial labels assigned to nodes of this node pool. An object
   * containing a list of "key": value pairs. Example: { "name": "wrench",
   * "mass": "1.3kg", "count": "3" }.
   */
  labels: { [key: string]: string };
}

export interface AzureNodeConfig_TagsEntry {
  key: string;
  value: string;
}

export interface AzureNodeConfig_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Configuration related to Kubernetes cluster autoscaler.
 *
 * The Kubernetes cluster autoscaler will automatically adjust the
 * size of the node pool based on the cluster load.
 */
export interface AzureNodePoolAutoscaling {
  /**
   * Required. Minimum number of nodes in the node pool. Must be greater than or
   * equal to 1 and less than or equal to max_node_count.
   */
  minNodeCount: number;
  /**
   * Required. Maximum number of nodes in the node pool. Must be greater than or
   * equal to min_node_count and less than or equal to 50.
   */
  maxNodeCount: number;
}

/**
 * AzureOpenIdConfig is an OIDC discovery document for the cluster.
 * See the OpenID Connect Discovery 1.0 specification for details.
 */
export interface AzureOpenIdConfig {
  /** OIDC Issuer. */
  issuer: string;
  /** JSON Web Key uri. */
  jwksUri: string;
  /** Supported response types. */
  responseTypesSupported: string[];
  /** Supported subject types. */
  subjectTypesSupported: string[];
  /** supported ID Token signing Algorithms. */
  idTokenSigningAlgValuesSupported: string[];
  /** Supported claims. */
  claimsSupported: string[];
  /** Supported grant types. */
  grantTypes: string[];
}

/** AzureJsonWebKeys is a valid JSON Web Key Set as specififed in RFC 7517. */
export interface AzureJsonWebKeys {
  /**
   * The public component of the keys used by the cluster to sign token
   * requests.
   */
  keys: Jwk[];
}

/**
 * AzureServerConfig contains information about a Google Cloud location, such as
 * supported Azure regions and Kubernetes versions.
 */
export interface AzureServerConfig {
  /**
   * The `AzureServerConfig` resource name.
   *
   * `AzureServerConfig` names are formatted as
   * `projects/<project-number>/locations/<region>/azureServerConfig`.
   *
   * See [Resource Names](https://cloud.google.com/apis/design/resource_names)
   * for more details on Google Cloud Platform resource names.
   */
  name: string;
  /**
   * List of all released Kubernetes versions, including ones which are end of
   * life and can no longer be used.  Filter by the `enabled`
   * property to limit to currently available versions.
   * Valid versions supported for both create and update operations
   */
  validVersions: AzureK8sVersionInfo[];
  /** The list of supported Azure regions. */
  supportedAzureRegions: string[];
}

/** Kubernetes version information of GKE cluster on Azure. */
export interface AzureK8sVersionInfo {
  /** Kubernetes version name (for example, `1.19.10-gke.1000`) */
  version: string;
  /**
   * Optional. True if the version is available for cluster creation. If a
   * version is enabled for creation, it can be used to create new clusters.
   * Otherwise, cluster creation will fail. However, cluster upgrade operations
   * may succeed, even if the version is not enabled.
   */
  enabled: boolean;
  /**
   * Optional. True if this cluster version belongs to a minor version that has
   * reached its end of life and is no longer in scope to receive security and
   * bug fixes.
   */
  endOfLife: boolean;
  /**
   * Optional. The estimated date (in Pacific Time) when this cluster version
   * will reach its end of life. Or if this version is no longer supported (the
   * `end_of_life` field is true), this is the actual date (in Pacific time)
   * when the version reached its end of life.
   */
  endOfLifeDate:
    | DateMessage
    | undefined;
  /** Optional. The date (in Pacific Time) when the cluster version was released. */
  releaseDate: DateMessage | undefined;
}

/** SSH configuration for Azure resources. */
export interface AzureSshConfig {
  /**
   * Required. The SSH public key data for VMs managed by Anthos. This accepts
   * the authorized_keys file format used in OpenSSH according to the sshd(8)
   * manual page.
   */
  authorizedKey: string;
}

/**
 * Managed Azure resources for the cluster.
 *
 * The values could change and be empty, depending on the state of the cluster.
 */
export interface AzureClusterResources {
  /** Output only. The ARM ID of the cluster network security group. */
  networkSecurityGroupId: string;
  /** Output only. The ARM ID of the control plane application security group. */
  controlPlaneApplicationSecurityGroupId: string;
}

/** AzureClusterError describes errors found on Azure clusters. */
export interface AzureClusterError {
  /** Human-friendly description of the error. */
  message: string;
}

/** AzureNodePoolError describes errors found on Azure node pools. */
export interface AzureNodePoolError {
  /** Human-friendly description of the error. */
  message: string;
}

function createBaseAzureCluster(): AzureCluster {
  return {
    name: "",
    description: "",
    azureRegion: "",
    resourceGroupId: "",
    azureClient: "",
    networking: undefined,
    controlPlane: undefined,
    authorization: undefined,
    azureServicesAuthentication: undefined,
    state: 0,
    endpoint: "",
    uid: "",
    reconciling: false,
    createTime: undefined,
    updateTime: undefined,
    etag: "",
    annotations: {},
    workloadIdentityConfig: undefined,
    clusterCaCertificate: "",
    fleet: undefined,
    managedResources: undefined,
    loggingConfig: undefined,
    errors: [],
    monitoringConfig: undefined,
  };
}

export const AzureCluster: MessageFns<AzureCluster> = {
  encode(message: AzureCluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.azureRegion !== "") {
      writer.uint32(26).string(message.azureRegion);
    }
    if (message.resourceGroupId !== "") {
      writer.uint32(138).string(message.resourceGroupId);
    }
    if (message.azureClient !== "") {
      writer.uint32(130).string(message.azureClient);
    }
    if (message.networking !== undefined) {
      AzureClusterNetworking.encode(message.networking, writer.uint32(34).fork()).join();
    }
    if (message.controlPlane !== undefined) {
      AzureControlPlane.encode(message.controlPlane, writer.uint32(42).fork()).join();
    }
    if (message.authorization !== undefined) {
      AzureAuthorization.encode(message.authorization, writer.uint32(50).fork()).join();
    }
    if (message.azureServicesAuthentication !== undefined) {
      AzureServicesAuthentication.encode(message.azureServicesAuthentication, writer.uint32(178).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(56).int32(message.state);
    }
    if (message.endpoint !== "") {
      writer.uint32(66).string(message.endpoint);
    }
    if (message.uid !== "") {
      writer.uint32(74).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(80).bool(message.reconciling);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(90).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(98).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(106).string(message.etag);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      AzureCluster_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(114).fork()).join();
    });
    if (message.workloadIdentityConfig !== undefined) {
      WorkloadIdentityConfig.encode(message.workloadIdentityConfig, writer.uint32(146).fork()).join();
    }
    if (message.clusterCaCertificate !== "") {
      writer.uint32(154).string(message.clusterCaCertificate);
    }
    if (message.fleet !== undefined) {
      Fleet.encode(message.fleet, writer.uint32(162).fork()).join();
    }
    if (message.managedResources !== undefined) {
      AzureClusterResources.encode(message.managedResources, writer.uint32(170).fork()).join();
    }
    if (message.loggingConfig !== undefined) {
      LoggingConfig.encode(message.loggingConfig, writer.uint32(186).fork()).join();
    }
    for (const v of message.errors) {
      AzureClusterError.encode(v!, writer.uint32(194).fork()).join();
    }
    if (message.monitoringConfig !== undefined) {
      MonitoringConfig.encode(message.monitoringConfig, writer.uint32(202).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureCluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureCluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.azureRegion = reader.string();
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.resourceGroupId = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.azureClient = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.networking = AzureClusterNetworking.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.controlPlane = AzureControlPlane.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.authorization = AzureAuthorization.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.azureServicesAuthentication = AzureServicesAuthentication.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endpoint = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          const entry14 = AzureCluster_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry14.value !== undefined) {
            message.annotations[entry14.key] = entry14.value;
          }
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.workloadIdentityConfig = WorkloadIdentityConfig.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.clusterCaCertificate = reader.string();
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.fleet = Fleet.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.managedResources = AzureClusterResources.decode(reader, reader.uint32());
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.loggingConfig = LoggingConfig.decode(reader, reader.uint32());
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.errors.push(AzureClusterError.decode(reader, reader.uint32()));
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.monitoringConfig = MonitoringConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureCluster {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      azureRegion: isSet(object.azureRegion) ? globalThis.String(object.azureRegion) : "",
      resourceGroupId: isSet(object.resourceGroupId) ? globalThis.String(object.resourceGroupId) : "",
      azureClient: isSet(object.azureClient) ? globalThis.String(object.azureClient) : "",
      networking: isSet(object.networking) ? AzureClusterNetworking.fromJSON(object.networking) : undefined,
      controlPlane: isSet(object.controlPlane) ? AzureControlPlane.fromJSON(object.controlPlane) : undefined,
      authorization: isSet(object.authorization) ? AzureAuthorization.fromJSON(object.authorization) : undefined,
      azureServicesAuthentication: isSet(object.azureServicesAuthentication)
        ? AzureServicesAuthentication.fromJSON(object.azureServicesAuthentication)
        : undefined,
      state: isSet(object.state) ? azureCluster_StateFromJSON(object.state) : 0,
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      workloadIdentityConfig: isSet(object.workloadIdentityConfig)
        ? WorkloadIdentityConfig.fromJSON(object.workloadIdentityConfig)
        : undefined,
      clusterCaCertificate: isSet(object.clusterCaCertificate) ? globalThis.String(object.clusterCaCertificate) : "",
      fleet: isSet(object.fleet) ? Fleet.fromJSON(object.fleet) : undefined,
      managedResources: isSet(object.managedResources)
        ? AzureClusterResources.fromJSON(object.managedResources)
        : undefined,
      loggingConfig: isSet(object.loggingConfig) ? LoggingConfig.fromJSON(object.loggingConfig) : undefined,
      errors: globalThis.Array.isArray(object?.errors)
        ? object.errors.map((e: any) => AzureClusterError.fromJSON(e))
        : [],
      monitoringConfig: isSet(object.monitoringConfig) ? MonitoringConfig.fromJSON(object.monitoringConfig) : undefined,
    };
  },

  toJSON(message: AzureCluster): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.azureRegion !== "") {
      obj.azureRegion = message.azureRegion;
    }
    if (message.resourceGroupId !== "") {
      obj.resourceGroupId = message.resourceGroupId;
    }
    if (message.azureClient !== "") {
      obj.azureClient = message.azureClient;
    }
    if (message.networking !== undefined) {
      obj.networking = AzureClusterNetworking.toJSON(message.networking);
    }
    if (message.controlPlane !== undefined) {
      obj.controlPlane = AzureControlPlane.toJSON(message.controlPlane);
    }
    if (message.authorization !== undefined) {
      obj.authorization = AzureAuthorization.toJSON(message.authorization);
    }
    if (message.azureServicesAuthentication !== undefined) {
      obj.azureServicesAuthentication = AzureServicesAuthentication.toJSON(message.azureServicesAuthentication);
    }
    if (message.state !== 0) {
      obj.state = azureCluster_StateToJSON(message.state);
    }
    if (message.endpoint !== "") {
      obj.endpoint = message.endpoint;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.workloadIdentityConfig !== undefined) {
      obj.workloadIdentityConfig = WorkloadIdentityConfig.toJSON(message.workloadIdentityConfig);
    }
    if (message.clusterCaCertificate !== "") {
      obj.clusterCaCertificate = message.clusterCaCertificate;
    }
    if (message.fleet !== undefined) {
      obj.fleet = Fleet.toJSON(message.fleet);
    }
    if (message.managedResources !== undefined) {
      obj.managedResources = AzureClusterResources.toJSON(message.managedResources);
    }
    if (message.loggingConfig !== undefined) {
      obj.loggingConfig = LoggingConfig.toJSON(message.loggingConfig);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => AzureClusterError.toJSON(e));
    }
    if (message.monitoringConfig !== undefined) {
      obj.monitoringConfig = MonitoringConfig.toJSON(message.monitoringConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<AzureCluster>): AzureCluster {
    return AzureCluster.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureCluster>): AzureCluster {
    const message = createBaseAzureCluster();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.azureRegion = object.azureRegion ?? "";
    message.resourceGroupId = object.resourceGroupId ?? "";
    message.azureClient = object.azureClient ?? "";
    message.networking = (object.networking !== undefined && object.networking !== null)
      ? AzureClusterNetworking.fromPartial(object.networking)
      : undefined;
    message.controlPlane = (object.controlPlane !== undefined && object.controlPlane !== null)
      ? AzureControlPlane.fromPartial(object.controlPlane)
      : undefined;
    message.authorization = (object.authorization !== undefined && object.authorization !== null)
      ? AzureAuthorization.fromPartial(object.authorization)
      : undefined;
    message.azureServicesAuthentication =
      (object.azureServicesAuthentication !== undefined && object.azureServicesAuthentication !== null)
        ? AzureServicesAuthentication.fromPartial(object.azureServicesAuthentication)
        : undefined;
    message.state = object.state ?? 0;
    message.endpoint = object.endpoint ?? "";
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.etag = object.etag ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.workloadIdentityConfig =
      (object.workloadIdentityConfig !== undefined && object.workloadIdentityConfig !== null)
        ? WorkloadIdentityConfig.fromPartial(object.workloadIdentityConfig)
        : undefined;
    message.clusterCaCertificate = object.clusterCaCertificate ?? "";
    message.fleet = (object.fleet !== undefined && object.fleet !== null) ? Fleet.fromPartial(object.fleet) : undefined;
    message.managedResources = (object.managedResources !== undefined && object.managedResources !== null)
      ? AzureClusterResources.fromPartial(object.managedResources)
      : undefined;
    message.loggingConfig = (object.loggingConfig !== undefined && object.loggingConfig !== null)
      ? LoggingConfig.fromPartial(object.loggingConfig)
      : undefined;
    message.errors = object.errors?.map((e) => AzureClusterError.fromPartial(e)) || [];
    message.monitoringConfig = (object.monitoringConfig !== undefined && object.monitoringConfig !== null)
      ? MonitoringConfig.fromPartial(object.monitoringConfig)
      : undefined;
    return message;
  },
};

function createBaseAzureCluster_AnnotationsEntry(): AzureCluster_AnnotationsEntry {
  return { key: "", value: "" };
}

export const AzureCluster_AnnotationsEntry: MessageFns<AzureCluster_AnnotationsEntry> = {
  encode(message: AzureCluster_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureCluster_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureCluster_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureCluster_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AzureCluster_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureCluster_AnnotationsEntry>): AzureCluster_AnnotationsEntry {
    return AzureCluster_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureCluster_AnnotationsEntry>): AzureCluster_AnnotationsEntry {
    const message = createBaseAzureCluster_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAzureClusterNetworking(): AzureClusterNetworking {
  return {
    virtualNetworkId: "",
    podAddressCidrBlocks: [],
    serviceAddressCidrBlocks: [],
    serviceLoadBalancerSubnetId: "",
  };
}

export const AzureClusterNetworking: MessageFns<AzureClusterNetworking> = {
  encode(message: AzureClusterNetworking, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.virtualNetworkId !== "") {
      writer.uint32(10).string(message.virtualNetworkId);
    }
    for (const v of message.podAddressCidrBlocks) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.serviceAddressCidrBlocks) {
      writer.uint32(26).string(v!);
    }
    if (message.serviceLoadBalancerSubnetId !== "") {
      writer.uint32(42).string(message.serviceLoadBalancerSubnetId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClusterNetworking {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClusterNetworking();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.virtualNetworkId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.podAddressCidrBlocks.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.serviceAddressCidrBlocks.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.serviceLoadBalancerSubnetId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClusterNetworking {
    return {
      virtualNetworkId: isSet(object.virtualNetworkId) ? globalThis.String(object.virtualNetworkId) : "",
      podAddressCidrBlocks: globalThis.Array.isArray(object?.podAddressCidrBlocks)
        ? object.podAddressCidrBlocks.map((e: any) => globalThis.String(e))
        : [],
      serviceAddressCidrBlocks: globalThis.Array.isArray(object?.serviceAddressCidrBlocks)
        ? object.serviceAddressCidrBlocks.map((e: any) => globalThis.String(e))
        : [],
      serviceLoadBalancerSubnetId: isSet(object.serviceLoadBalancerSubnetId)
        ? globalThis.String(object.serviceLoadBalancerSubnetId)
        : "",
    };
  },

  toJSON(message: AzureClusterNetworking): unknown {
    const obj: any = {};
    if (message.virtualNetworkId !== "") {
      obj.virtualNetworkId = message.virtualNetworkId;
    }
    if (message.podAddressCidrBlocks?.length) {
      obj.podAddressCidrBlocks = message.podAddressCidrBlocks;
    }
    if (message.serviceAddressCidrBlocks?.length) {
      obj.serviceAddressCidrBlocks = message.serviceAddressCidrBlocks;
    }
    if (message.serviceLoadBalancerSubnetId !== "") {
      obj.serviceLoadBalancerSubnetId = message.serviceLoadBalancerSubnetId;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClusterNetworking>): AzureClusterNetworking {
    return AzureClusterNetworking.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClusterNetworking>): AzureClusterNetworking {
    const message = createBaseAzureClusterNetworking();
    message.virtualNetworkId = object.virtualNetworkId ?? "";
    message.podAddressCidrBlocks = object.podAddressCidrBlocks?.map((e) => e) || [];
    message.serviceAddressCidrBlocks = object.serviceAddressCidrBlocks?.map((e) => e) || [];
    message.serviceLoadBalancerSubnetId = object.serviceLoadBalancerSubnetId ?? "";
    return message;
  },
};

function createBaseAzureControlPlane(): AzureControlPlane {
  return {
    version: "",
    subnetId: "",
    vmSize: "",
    sshConfig: undefined,
    rootVolume: undefined,
    mainVolume: undefined,
    databaseEncryption: undefined,
    proxyConfig: undefined,
    configEncryption: undefined,
    tags: {},
    replicaPlacements: [],
    endpointSubnetId: "",
  };
}

export const AzureControlPlane: MessageFns<AzureControlPlane> = {
  encode(message: AzureControlPlane, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.subnetId !== "") {
      writer.uint32(18).string(message.subnetId);
    }
    if (message.vmSize !== "") {
      writer.uint32(26).string(message.vmSize);
    }
    if (message.sshConfig !== undefined) {
      AzureSshConfig.encode(message.sshConfig, writer.uint32(90).fork()).join();
    }
    if (message.rootVolume !== undefined) {
      AzureDiskTemplate.encode(message.rootVolume, writer.uint32(34).fork()).join();
    }
    if (message.mainVolume !== undefined) {
      AzureDiskTemplate.encode(message.mainVolume, writer.uint32(42).fork()).join();
    }
    if (message.databaseEncryption !== undefined) {
      AzureDatabaseEncryption.encode(message.databaseEncryption, writer.uint32(82).fork()).join();
    }
    if (message.proxyConfig !== undefined) {
      AzureProxyConfig.encode(message.proxyConfig, writer.uint32(98).fork()).join();
    }
    if (message.configEncryption !== undefined) {
      AzureConfigEncryption.encode(message.configEncryption, writer.uint32(114).fork()).join();
    }
    Object.entries(message.tags).forEach(([key, value]) => {
      AzureControlPlane_TagsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    for (const v of message.replicaPlacements) {
      ReplicaPlacement.encode(v!, writer.uint32(106).fork()).join();
    }
    if (message.endpointSubnetId !== "") {
      writer.uint32(122).string(message.endpointSubnetId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureControlPlane {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureControlPlane();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subnetId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.vmSize = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.sshConfig = AzureSshConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.rootVolume = AzureDiskTemplate.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.mainVolume = AzureDiskTemplate.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.databaseEncryption = AzureDatabaseEncryption.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.proxyConfig = AzureProxyConfig.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.configEncryption = AzureConfigEncryption.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = AzureControlPlane_TagsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.tags[entry7.key] = entry7.value;
          }
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.replicaPlacements.push(ReplicaPlacement.decode(reader, reader.uint32()));
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.endpointSubnetId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureControlPlane {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      subnetId: isSet(object.subnetId) ? globalThis.String(object.subnetId) : "",
      vmSize: isSet(object.vmSize) ? globalThis.String(object.vmSize) : "",
      sshConfig: isSet(object.sshConfig) ? AzureSshConfig.fromJSON(object.sshConfig) : undefined,
      rootVolume: isSet(object.rootVolume) ? AzureDiskTemplate.fromJSON(object.rootVolume) : undefined,
      mainVolume: isSet(object.mainVolume) ? AzureDiskTemplate.fromJSON(object.mainVolume) : undefined,
      databaseEncryption: isSet(object.databaseEncryption)
        ? AzureDatabaseEncryption.fromJSON(object.databaseEncryption)
        : undefined,
      proxyConfig: isSet(object.proxyConfig) ? AzureProxyConfig.fromJSON(object.proxyConfig) : undefined,
      configEncryption: isSet(object.configEncryption)
        ? AzureConfigEncryption.fromJSON(object.configEncryption)
        : undefined,
      tags: isObject(object.tags)
        ? Object.entries(object.tags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      replicaPlacements: globalThis.Array.isArray(object?.replicaPlacements)
        ? object.replicaPlacements.map((e: any) => ReplicaPlacement.fromJSON(e))
        : [],
      endpointSubnetId: isSet(object.endpointSubnetId) ? globalThis.String(object.endpointSubnetId) : "",
    };
  },

  toJSON(message: AzureControlPlane): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.subnetId !== "") {
      obj.subnetId = message.subnetId;
    }
    if (message.vmSize !== "") {
      obj.vmSize = message.vmSize;
    }
    if (message.sshConfig !== undefined) {
      obj.sshConfig = AzureSshConfig.toJSON(message.sshConfig);
    }
    if (message.rootVolume !== undefined) {
      obj.rootVolume = AzureDiskTemplate.toJSON(message.rootVolume);
    }
    if (message.mainVolume !== undefined) {
      obj.mainVolume = AzureDiskTemplate.toJSON(message.mainVolume);
    }
    if (message.databaseEncryption !== undefined) {
      obj.databaseEncryption = AzureDatabaseEncryption.toJSON(message.databaseEncryption);
    }
    if (message.proxyConfig !== undefined) {
      obj.proxyConfig = AzureProxyConfig.toJSON(message.proxyConfig);
    }
    if (message.configEncryption !== undefined) {
      obj.configEncryption = AzureConfigEncryption.toJSON(message.configEncryption);
    }
    if (message.tags) {
      const entries = Object.entries(message.tags);
      if (entries.length > 0) {
        obj.tags = {};
        entries.forEach(([k, v]) => {
          obj.tags[k] = v;
        });
      }
    }
    if (message.replicaPlacements?.length) {
      obj.replicaPlacements = message.replicaPlacements.map((e) => ReplicaPlacement.toJSON(e));
    }
    if (message.endpointSubnetId !== "") {
      obj.endpointSubnetId = message.endpointSubnetId;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureControlPlane>): AzureControlPlane {
    return AzureControlPlane.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureControlPlane>): AzureControlPlane {
    const message = createBaseAzureControlPlane();
    message.version = object.version ?? "";
    message.subnetId = object.subnetId ?? "";
    message.vmSize = object.vmSize ?? "";
    message.sshConfig = (object.sshConfig !== undefined && object.sshConfig !== null)
      ? AzureSshConfig.fromPartial(object.sshConfig)
      : undefined;
    message.rootVolume = (object.rootVolume !== undefined && object.rootVolume !== null)
      ? AzureDiskTemplate.fromPartial(object.rootVolume)
      : undefined;
    message.mainVolume = (object.mainVolume !== undefined && object.mainVolume !== null)
      ? AzureDiskTemplate.fromPartial(object.mainVolume)
      : undefined;
    message.databaseEncryption = (object.databaseEncryption !== undefined && object.databaseEncryption !== null)
      ? AzureDatabaseEncryption.fromPartial(object.databaseEncryption)
      : undefined;
    message.proxyConfig = (object.proxyConfig !== undefined && object.proxyConfig !== null)
      ? AzureProxyConfig.fromPartial(object.proxyConfig)
      : undefined;
    message.configEncryption = (object.configEncryption !== undefined && object.configEncryption !== null)
      ? AzureConfigEncryption.fromPartial(object.configEncryption)
      : undefined;
    message.tags = Object.entries(object.tags ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.replicaPlacements = object.replicaPlacements?.map((e) => ReplicaPlacement.fromPartial(e)) || [];
    message.endpointSubnetId = object.endpointSubnetId ?? "";
    return message;
  },
};

function createBaseAzureControlPlane_TagsEntry(): AzureControlPlane_TagsEntry {
  return { key: "", value: "" };
}

export const AzureControlPlane_TagsEntry: MessageFns<AzureControlPlane_TagsEntry> = {
  encode(message: AzureControlPlane_TagsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureControlPlane_TagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureControlPlane_TagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureControlPlane_TagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AzureControlPlane_TagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureControlPlane_TagsEntry>): AzureControlPlane_TagsEntry {
    return AzureControlPlane_TagsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureControlPlane_TagsEntry>): AzureControlPlane_TagsEntry {
    const message = createBaseAzureControlPlane_TagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseReplicaPlacement(): ReplicaPlacement {
  return { subnetId: "", azureAvailabilityZone: "" };
}

export const ReplicaPlacement: MessageFns<ReplicaPlacement> = {
  encode(message: ReplicaPlacement, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subnetId !== "") {
      writer.uint32(10).string(message.subnetId);
    }
    if (message.azureAvailabilityZone !== "") {
      writer.uint32(18).string(message.azureAvailabilityZone);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplicaPlacement {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplicaPlacement();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subnetId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.azureAvailabilityZone = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplicaPlacement {
    return {
      subnetId: isSet(object.subnetId) ? globalThis.String(object.subnetId) : "",
      azureAvailabilityZone: isSet(object.azureAvailabilityZone) ? globalThis.String(object.azureAvailabilityZone) : "",
    };
  },

  toJSON(message: ReplicaPlacement): unknown {
    const obj: any = {};
    if (message.subnetId !== "") {
      obj.subnetId = message.subnetId;
    }
    if (message.azureAvailabilityZone !== "") {
      obj.azureAvailabilityZone = message.azureAvailabilityZone;
    }
    return obj;
  },

  create(base?: DeepPartial<ReplicaPlacement>): ReplicaPlacement {
    return ReplicaPlacement.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReplicaPlacement>): ReplicaPlacement {
    const message = createBaseReplicaPlacement();
    message.subnetId = object.subnetId ?? "";
    message.azureAvailabilityZone = object.azureAvailabilityZone ?? "";
    return message;
  },
};

function createBaseAzureProxyConfig(): AzureProxyConfig {
  return { resourceGroupId: "", secretId: "" };
}

export const AzureProxyConfig: MessageFns<AzureProxyConfig> = {
  encode(message: AzureProxyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resourceGroupId !== "") {
      writer.uint32(10).string(message.resourceGroupId);
    }
    if (message.secretId !== "") {
      writer.uint32(18).string(message.secretId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureProxyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureProxyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resourceGroupId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.secretId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureProxyConfig {
    return {
      resourceGroupId: isSet(object.resourceGroupId) ? globalThis.String(object.resourceGroupId) : "",
      secretId: isSet(object.secretId) ? globalThis.String(object.secretId) : "",
    };
  },

  toJSON(message: AzureProxyConfig): unknown {
    const obj: any = {};
    if (message.resourceGroupId !== "") {
      obj.resourceGroupId = message.resourceGroupId;
    }
    if (message.secretId !== "") {
      obj.secretId = message.secretId;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureProxyConfig>): AzureProxyConfig {
    return AzureProxyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureProxyConfig>): AzureProxyConfig {
    const message = createBaseAzureProxyConfig();
    message.resourceGroupId = object.resourceGroupId ?? "";
    message.secretId = object.secretId ?? "";
    return message;
  },
};

function createBaseAzureDatabaseEncryption(): AzureDatabaseEncryption {
  return { keyId: "" };
}

export const AzureDatabaseEncryption: MessageFns<AzureDatabaseEncryption> = {
  encode(message: AzureDatabaseEncryption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.keyId !== "") {
      writer.uint32(26).string(message.keyId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureDatabaseEncryption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureDatabaseEncryption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.keyId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureDatabaseEncryption {
    return { keyId: isSet(object.keyId) ? globalThis.String(object.keyId) : "" };
  },

  toJSON(message: AzureDatabaseEncryption): unknown {
    const obj: any = {};
    if (message.keyId !== "") {
      obj.keyId = message.keyId;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureDatabaseEncryption>): AzureDatabaseEncryption {
    return AzureDatabaseEncryption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureDatabaseEncryption>): AzureDatabaseEncryption {
    const message = createBaseAzureDatabaseEncryption();
    message.keyId = object.keyId ?? "";
    return message;
  },
};

function createBaseAzureConfigEncryption(): AzureConfigEncryption {
  return { keyId: "", publicKey: "" };
}

export const AzureConfigEncryption: MessageFns<AzureConfigEncryption> = {
  encode(message: AzureConfigEncryption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.keyId !== "") {
      writer.uint32(18).string(message.keyId);
    }
    if (message.publicKey !== "") {
      writer.uint32(26).string(message.publicKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureConfigEncryption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureConfigEncryption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.keyId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.publicKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureConfigEncryption {
    return {
      keyId: isSet(object.keyId) ? globalThis.String(object.keyId) : "",
      publicKey: isSet(object.publicKey) ? globalThis.String(object.publicKey) : "",
    };
  },

  toJSON(message: AzureConfigEncryption): unknown {
    const obj: any = {};
    if (message.keyId !== "") {
      obj.keyId = message.keyId;
    }
    if (message.publicKey !== "") {
      obj.publicKey = message.publicKey;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureConfigEncryption>): AzureConfigEncryption {
    return AzureConfigEncryption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureConfigEncryption>): AzureConfigEncryption {
    const message = createBaseAzureConfigEncryption();
    message.keyId = object.keyId ?? "";
    message.publicKey = object.publicKey ?? "";
    return message;
  },
};

function createBaseAzureDiskTemplate(): AzureDiskTemplate {
  return { sizeGib: 0 };
}

export const AzureDiskTemplate: MessageFns<AzureDiskTemplate> = {
  encode(message: AzureDiskTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sizeGib !== 0) {
      writer.uint32(8).int32(message.sizeGib);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureDiskTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureDiskTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sizeGib = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureDiskTemplate {
    return { sizeGib: isSet(object.sizeGib) ? globalThis.Number(object.sizeGib) : 0 };
  },

  toJSON(message: AzureDiskTemplate): unknown {
    const obj: any = {};
    if (message.sizeGib !== 0) {
      obj.sizeGib = Math.round(message.sizeGib);
    }
    return obj;
  },

  create(base?: DeepPartial<AzureDiskTemplate>): AzureDiskTemplate {
    return AzureDiskTemplate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureDiskTemplate>): AzureDiskTemplate {
    const message = createBaseAzureDiskTemplate();
    message.sizeGib = object.sizeGib ?? 0;
    return message;
  },
};

function createBaseAzureClient(): AzureClient {
  return {
    name: "",
    tenantId: "",
    applicationId: "",
    reconciling: false,
    annotations: {},
    pemCertificate: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
  };
}

export const AzureClient: MessageFns<AzureClient> = {
  encode(message: AzureClient, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.tenantId !== "") {
      writer.uint32(18).string(message.tenantId);
    }
    if (message.applicationId !== "") {
      writer.uint32(26).string(message.applicationId);
    }
    if (message.reconciling !== false) {
      writer.uint32(72).bool(message.reconciling);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      AzureClient_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.pemCertificate !== "") {
      writer.uint32(58).string(message.pemCertificate);
    }
    if (message.uid !== "") {
      writer.uint32(42).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClient {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClient();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tenantId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.applicationId = reader.string();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          const entry8 = AzureClient_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.annotations[entry8.key] = entry8.value;
          }
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.pemCertificate = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClient {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      tenantId: isSet(object.tenantId) ? globalThis.String(object.tenantId) : "",
      applicationId: isSet(object.applicationId) ? globalThis.String(object.applicationId) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      pemCertificate: isSet(object.pemCertificate) ? globalThis.String(object.pemCertificate) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: AzureClient): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.tenantId !== "") {
      obj.tenantId = message.tenantId;
    }
    if (message.applicationId !== "") {
      obj.applicationId = message.applicationId;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.pemCertificate !== "") {
      obj.pemCertificate = message.pemCertificate;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClient>): AzureClient {
    return AzureClient.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClient>): AzureClient {
    const message = createBaseAzureClient();
    message.name = object.name ?? "";
    message.tenantId = object.tenantId ?? "";
    message.applicationId = object.applicationId ?? "";
    message.reconciling = object.reconciling ?? false;
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.pemCertificate = object.pemCertificate ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseAzureClient_AnnotationsEntry(): AzureClient_AnnotationsEntry {
  return { key: "", value: "" };
}

export const AzureClient_AnnotationsEntry: MessageFns<AzureClient_AnnotationsEntry> = {
  encode(message: AzureClient_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClient_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClient_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClient_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AzureClient_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClient_AnnotationsEntry>): AzureClient_AnnotationsEntry {
    return AzureClient_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClient_AnnotationsEntry>): AzureClient_AnnotationsEntry {
    const message = createBaseAzureClient_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAzureAuthorization(): AzureAuthorization {
  return { adminUsers: [], adminGroups: [] };
}

export const AzureAuthorization: MessageFns<AzureAuthorization> = {
  encode(message: AzureAuthorization, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.adminUsers) {
      AzureClusterUser.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.adminGroups) {
      AzureClusterGroup.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureAuthorization {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureAuthorization();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.adminUsers.push(AzureClusterUser.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.adminGroups.push(AzureClusterGroup.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureAuthorization {
    return {
      adminUsers: globalThis.Array.isArray(object?.adminUsers)
        ? object.adminUsers.map((e: any) => AzureClusterUser.fromJSON(e))
        : [],
      adminGroups: globalThis.Array.isArray(object?.adminGroups)
        ? object.adminGroups.map((e: any) => AzureClusterGroup.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AzureAuthorization): unknown {
    const obj: any = {};
    if (message.adminUsers?.length) {
      obj.adminUsers = message.adminUsers.map((e) => AzureClusterUser.toJSON(e));
    }
    if (message.adminGroups?.length) {
      obj.adminGroups = message.adminGroups.map((e) => AzureClusterGroup.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AzureAuthorization>): AzureAuthorization {
    return AzureAuthorization.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureAuthorization>): AzureAuthorization {
    const message = createBaseAzureAuthorization();
    message.adminUsers = object.adminUsers?.map((e) => AzureClusterUser.fromPartial(e)) || [];
    message.adminGroups = object.adminGroups?.map((e) => AzureClusterGroup.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAzureServicesAuthentication(): AzureServicesAuthentication {
  return { tenantId: "", applicationId: "" };
}

export const AzureServicesAuthentication: MessageFns<AzureServicesAuthentication> = {
  encode(message: AzureServicesAuthentication, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tenantId !== "") {
      writer.uint32(10).string(message.tenantId);
    }
    if (message.applicationId !== "") {
      writer.uint32(18).string(message.applicationId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureServicesAuthentication {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureServicesAuthentication();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tenantId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.applicationId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureServicesAuthentication {
    return {
      tenantId: isSet(object.tenantId) ? globalThis.String(object.tenantId) : "",
      applicationId: isSet(object.applicationId) ? globalThis.String(object.applicationId) : "",
    };
  },

  toJSON(message: AzureServicesAuthentication): unknown {
    const obj: any = {};
    if (message.tenantId !== "") {
      obj.tenantId = message.tenantId;
    }
    if (message.applicationId !== "") {
      obj.applicationId = message.applicationId;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureServicesAuthentication>): AzureServicesAuthentication {
    return AzureServicesAuthentication.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureServicesAuthentication>): AzureServicesAuthentication {
    const message = createBaseAzureServicesAuthentication();
    message.tenantId = object.tenantId ?? "";
    message.applicationId = object.applicationId ?? "";
    return message;
  },
};

function createBaseAzureClusterUser(): AzureClusterUser {
  return { username: "" };
}

export const AzureClusterUser: MessageFns<AzureClusterUser> = {
  encode(message: AzureClusterUser, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.username !== "") {
      writer.uint32(10).string(message.username);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClusterUser {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClusterUser();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.username = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClusterUser {
    return { username: isSet(object.username) ? globalThis.String(object.username) : "" };
  },

  toJSON(message: AzureClusterUser): unknown {
    const obj: any = {};
    if (message.username !== "") {
      obj.username = message.username;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClusterUser>): AzureClusterUser {
    return AzureClusterUser.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClusterUser>): AzureClusterUser {
    const message = createBaseAzureClusterUser();
    message.username = object.username ?? "";
    return message;
  },
};

function createBaseAzureClusterGroup(): AzureClusterGroup {
  return { group: "" };
}

export const AzureClusterGroup: MessageFns<AzureClusterGroup> = {
  encode(message: AzureClusterGroup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.group !== "") {
      writer.uint32(10).string(message.group);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClusterGroup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClusterGroup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.group = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClusterGroup {
    return { group: isSet(object.group) ? globalThis.String(object.group) : "" };
  },

  toJSON(message: AzureClusterGroup): unknown {
    const obj: any = {};
    if (message.group !== "") {
      obj.group = message.group;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClusterGroup>): AzureClusterGroup {
    return AzureClusterGroup.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClusterGroup>): AzureClusterGroup {
    const message = createBaseAzureClusterGroup();
    message.group = object.group ?? "";
    return message;
  },
};

function createBaseAzureNodePool(): AzureNodePool {
  return {
    name: "",
    version: "",
    config: undefined,
    subnetId: "",
    autoscaling: undefined,
    state: 0,
    uid: "",
    reconciling: false,
    createTime: undefined,
    updateTime: undefined,
    etag: "",
    annotations: {},
    maxPodsConstraint: undefined,
    azureAvailabilityZone: "",
    errors: [],
    management: undefined,
  };
}

export const AzureNodePool: MessageFns<AzureNodePool> = {
  encode(message: AzureNodePool, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.version !== "") {
      writer.uint32(18).string(message.version);
    }
    if (message.config !== undefined) {
      AzureNodeConfig.encode(message.config, writer.uint32(178).fork()).join();
    }
    if (message.subnetId !== "") {
      writer.uint32(26).string(message.subnetId);
    }
    if (message.autoscaling !== undefined) {
      AzureNodePoolAutoscaling.encode(message.autoscaling, writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.uid !== "") {
      writer.uint32(66).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(72).bool(message.reconciling);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(82).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(90).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(98).string(message.etag);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      AzureNodePool_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(106).fork()).join();
    });
    if (message.maxPodsConstraint !== undefined) {
      MaxPodsConstraint.encode(message.maxPodsConstraint, writer.uint32(170).fork()).join();
    }
    if (message.azureAvailabilityZone !== "") {
      writer.uint32(186).string(message.azureAvailabilityZone);
    }
    for (const v of message.errors) {
      AzureNodePoolError.encode(v!, writer.uint32(234).fork()).join();
    }
    if (message.management !== undefined) {
      AzureNodeManagement.encode(message.management, writer.uint32(242).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodePool {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodePool();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.version = reader.string();
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.config = AzureNodeConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.subnetId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.autoscaling = AzureNodePoolAutoscaling.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          const entry13 = AzureNodePool_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry13.value !== undefined) {
            message.annotations[entry13.key] = entry13.value;
          }
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.maxPodsConstraint = MaxPodsConstraint.decode(reader, reader.uint32());
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.azureAvailabilityZone = reader.string();
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.errors.push(AzureNodePoolError.decode(reader, reader.uint32()));
          continue;
        case 30:
          if (tag !== 242) {
            break;
          }

          message.management = AzureNodeManagement.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodePool {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      config: isSet(object.config) ? AzureNodeConfig.fromJSON(object.config) : undefined,
      subnetId: isSet(object.subnetId) ? globalThis.String(object.subnetId) : "",
      autoscaling: isSet(object.autoscaling) ? AzureNodePoolAutoscaling.fromJSON(object.autoscaling) : undefined,
      state: isSet(object.state) ? azureNodePool_StateFromJSON(object.state) : 0,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      maxPodsConstraint: isSet(object.maxPodsConstraint)
        ? MaxPodsConstraint.fromJSON(object.maxPodsConstraint)
        : undefined,
      azureAvailabilityZone: isSet(object.azureAvailabilityZone) ? globalThis.String(object.azureAvailabilityZone) : "",
      errors: globalThis.Array.isArray(object?.errors)
        ? object.errors.map((e: any) => AzureNodePoolError.fromJSON(e))
        : [],
      management: isSet(object.management) ? AzureNodeManagement.fromJSON(object.management) : undefined,
    };
  },

  toJSON(message: AzureNodePool): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.config !== undefined) {
      obj.config = AzureNodeConfig.toJSON(message.config);
    }
    if (message.subnetId !== "") {
      obj.subnetId = message.subnetId;
    }
    if (message.autoscaling !== undefined) {
      obj.autoscaling = AzureNodePoolAutoscaling.toJSON(message.autoscaling);
    }
    if (message.state !== 0) {
      obj.state = azureNodePool_StateToJSON(message.state);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.maxPodsConstraint !== undefined) {
      obj.maxPodsConstraint = MaxPodsConstraint.toJSON(message.maxPodsConstraint);
    }
    if (message.azureAvailabilityZone !== "") {
      obj.azureAvailabilityZone = message.azureAvailabilityZone;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => AzureNodePoolError.toJSON(e));
    }
    if (message.management !== undefined) {
      obj.management = AzureNodeManagement.toJSON(message.management);
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodePool>): AzureNodePool {
    return AzureNodePool.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodePool>): AzureNodePool {
    const message = createBaseAzureNodePool();
    message.name = object.name ?? "";
    message.version = object.version ?? "";
    message.config = (object.config !== undefined && object.config !== null)
      ? AzureNodeConfig.fromPartial(object.config)
      : undefined;
    message.subnetId = object.subnetId ?? "";
    message.autoscaling = (object.autoscaling !== undefined && object.autoscaling !== null)
      ? AzureNodePoolAutoscaling.fromPartial(object.autoscaling)
      : undefined;
    message.state = object.state ?? 0;
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.etag = object.etag ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.maxPodsConstraint = (object.maxPodsConstraint !== undefined && object.maxPodsConstraint !== null)
      ? MaxPodsConstraint.fromPartial(object.maxPodsConstraint)
      : undefined;
    message.azureAvailabilityZone = object.azureAvailabilityZone ?? "";
    message.errors = object.errors?.map((e) => AzureNodePoolError.fromPartial(e)) || [];
    message.management = (object.management !== undefined && object.management !== null)
      ? AzureNodeManagement.fromPartial(object.management)
      : undefined;
    return message;
  },
};

function createBaseAzureNodePool_AnnotationsEntry(): AzureNodePool_AnnotationsEntry {
  return { key: "", value: "" };
}

export const AzureNodePool_AnnotationsEntry: MessageFns<AzureNodePool_AnnotationsEntry> = {
  encode(message: AzureNodePool_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodePool_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodePool_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodePool_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AzureNodePool_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodePool_AnnotationsEntry>): AzureNodePool_AnnotationsEntry {
    return AzureNodePool_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodePool_AnnotationsEntry>): AzureNodePool_AnnotationsEntry {
    const message = createBaseAzureNodePool_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAzureNodeManagement(): AzureNodeManagement {
  return { autoRepair: false };
}

export const AzureNodeManagement: MessageFns<AzureNodeManagement> = {
  encode(message: AzureNodeManagement, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.autoRepair !== false) {
      writer.uint32(8).bool(message.autoRepair);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodeManagement {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodeManagement();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.autoRepair = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodeManagement {
    return { autoRepair: isSet(object.autoRepair) ? globalThis.Boolean(object.autoRepair) : false };
  },

  toJSON(message: AzureNodeManagement): unknown {
    const obj: any = {};
    if (message.autoRepair !== false) {
      obj.autoRepair = message.autoRepair;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodeManagement>): AzureNodeManagement {
    return AzureNodeManagement.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodeManagement>): AzureNodeManagement {
    const message = createBaseAzureNodeManagement();
    message.autoRepair = object.autoRepair ?? false;
    return message;
  },
};

function createBaseAzureNodeConfig(): AzureNodeConfig {
  return {
    vmSize: "",
    rootVolume: undefined,
    tags: {},
    imageType: "",
    sshConfig: undefined,
    proxyConfig: undefined,
    configEncryption: undefined,
    taints: [],
    labels: {},
  };
}

export const AzureNodeConfig: MessageFns<AzureNodeConfig> = {
  encode(message: AzureNodeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmSize !== "") {
      writer.uint32(10).string(message.vmSize);
    }
    if (message.rootVolume !== undefined) {
      AzureDiskTemplate.encode(message.rootVolume, writer.uint32(18).fork()).join();
    }
    Object.entries(message.tags).forEach(([key, value]) => {
      AzureNodeConfig_TagsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.imageType !== "") {
      writer.uint32(66).string(message.imageType);
    }
    if (message.sshConfig !== undefined) {
      AzureSshConfig.encode(message.sshConfig, writer.uint32(58).fork()).join();
    }
    if (message.proxyConfig !== undefined) {
      AzureProxyConfig.encode(message.proxyConfig, writer.uint32(74).fork()).join();
    }
    if (message.configEncryption !== undefined) {
      AzureConfigEncryption.encode(message.configEncryption, writer.uint32(98).fork()).join();
    }
    for (const v of message.taints) {
      NodeTaint.encode(v!, writer.uint32(82).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      AzureNodeConfig_LabelsEntry.encode({ key: key as any, value }, writer.uint32(90).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vmSize = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rootVolume = AzureDiskTemplate.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = AzureNodeConfig_TagsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.tags[entry3.key] = entry3.value;
          }
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.imageType = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.sshConfig = AzureSshConfig.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.proxyConfig = AzureProxyConfig.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.configEncryption = AzureConfigEncryption.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.taints.push(NodeTaint.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          const entry11 = AzureNodeConfig_LabelsEntry.decode(reader, reader.uint32());
          if (entry11.value !== undefined) {
            message.labels[entry11.key] = entry11.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodeConfig {
    return {
      vmSize: isSet(object.vmSize) ? globalThis.String(object.vmSize) : "",
      rootVolume: isSet(object.rootVolume) ? AzureDiskTemplate.fromJSON(object.rootVolume) : undefined,
      tags: isObject(object.tags)
        ? Object.entries(object.tags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      imageType: isSet(object.imageType) ? globalThis.String(object.imageType) : "",
      sshConfig: isSet(object.sshConfig) ? AzureSshConfig.fromJSON(object.sshConfig) : undefined,
      proxyConfig: isSet(object.proxyConfig) ? AzureProxyConfig.fromJSON(object.proxyConfig) : undefined,
      configEncryption: isSet(object.configEncryption)
        ? AzureConfigEncryption.fromJSON(object.configEncryption)
        : undefined,
      taints: globalThis.Array.isArray(object?.taints) ? object.taints.map((e: any) => NodeTaint.fromJSON(e)) : [],
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: AzureNodeConfig): unknown {
    const obj: any = {};
    if (message.vmSize !== "") {
      obj.vmSize = message.vmSize;
    }
    if (message.rootVolume !== undefined) {
      obj.rootVolume = AzureDiskTemplate.toJSON(message.rootVolume);
    }
    if (message.tags) {
      const entries = Object.entries(message.tags);
      if (entries.length > 0) {
        obj.tags = {};
        entries.forEach(([k, v]) => {
          obj.tags[k] = v;
        });
      }
    }
    if (message.imageType !== "") {
      obj.imageType = message.imageType;
    }
    if (message.sshConfig !== undefined) {
      obj.sshConfig = AzureSshConfig.toJSON(message.sshConfig);
    }
    if (message.proxyConfig !== undefined) {
      obj.proxyConfig = AzureProxyConfig.toJSON(message.proxyConfig);
    }
    if (message.configEncryption !== undefined) {
      obj.configEncryption = AzureConfigEncryption.toJSON(message.configEncryption);
    }
    if (message.taints?.length) {
      obj.taints = message.taints.map((e) => NodeTaint.toJSON(e));
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodeConfig>): AzureNodeConfig {
    return AzureNodeConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodeConfig>): AzureNodeConfig {
    const message = createBaseAzureNodeConfig();
    message.vmSize = object.vmSize ?? "";
    message.rootVolume = (object.rootVolume !== undefined && object.rootVolume !== null)
      ? AzureDiskTemplate.fromPartial(object.rootVolume)
      : undefined;
    message.tags = Object.entries(object.tags ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.imageType = object.imageType ?? "";
    message.sshConfig = (object.sshConfig !== undefined && object.sshConfig !== null)
      ? AzureSshConfig.fromPartial(object.sshConfig)
      : undefined;
    message.proxyConfig = (object.proxyConfig !== undefined && object.proxyConfig !== null)
      ? AzureProxyConfig.fromPartial(object.proxyConfig)
      : undefined;
    message.configEncryption = (object.configEncryption !== undefined && object.configEncryption !== null)
      ? AzureConfigEncryption.fromPartial(object.configEncryption)
      : undefined;
    message.taints = object.taints?.map((e) => NodeTaint.fromPartial(e)) || [];
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseAzureNodeConfig_TagsEntry(): AzureNodeConfig_TagsEntry {
  return { key: "", value: "" };
}

export const AzureNodeConfig_TagsEntry: MessageFns<AzureNodeConfig_TagsEntry> = {
  encode(message: AzureNodeConfig_TagsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodeConfig_TagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodeConfig_TagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodeConfig_TagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AzureNodeConfig_TagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodeConfig_TagsEntry>): AzureNodeConfig_TagsEntry {
    return AzureNodeConfig_TagsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodeConfig_TagsEntry>): AzureNodeConfig_TagsEntry {
    const message = createBaseAzureNodeConfig_TagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAzureNodeConfig_LabelsEntry(): AzureNodeConfig_LabelsEntry {
  return { key: "", value: "" };
}

export const AzureNodeConfig_LabelsEntry: MessageFns<AzureNodeConfig_LabelsEntry> = {
  encode(message: AzureNodeConfig_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodeConfig_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodeConfig_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodeConfig_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AzureNodeConfig_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodeConfig_LabelsEntry>): AzureNodeConfig_LabelsEntry {
    return AzureNodeConfig_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodeConfig_LabelsEntry>): AzureNodeConfig_LabelsEntry {
    const message = createBaseAzureNodeConfig_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAzureNodePoolAutoscaling(): AzureNodePoolAutoscaling {
  return { minNodeCount: 0, maxNodeCount: 0 };
}

export const AzureNodePoolAutoscaling: MessageFns<AzureNodePoolAutoscaling> = {
  encode(message: AzureNodePoolAutoscaling, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minNodeCount !== 0) {
      writer.uint32(8).int32(message.minNodeCount);
    }
    if (message.maxNodeCount !== 0) {
      writer.uint32(16).int32(message.maxNodeCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodePoolAutoscaling {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodePoolAutoscaling();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.minNodeCount = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.maxNodeCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodePoolAutoscaling {
    return {
      minNodeCount: isSet(object.minNodeCount) ? globalThis.Number(object.minNodeCount) : 0,
      maxNodeCount: isSet(object.maxNodeCount) ? globalThis.Number(object.maxNodeCount) : 0,
    };
  },

  toJSON(message: AzureNodePoolAutoscaling): unknown {
    const obj: any = {};
    if (message.minNodeCount !== 0) {
      obj.minNodeCount = Math.round(message.minNodeCount);
    }
    if (message.maxNodeCount !== 0) {
      obj.maxNodeCount = Math.round(message.maxNodeCount);
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodePoolAutoscaling>): AzureNodePoolAutoscaling {
    return AzureNodePoolAutoscaling.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodePoolAutoscaling>): AzureNodePoolAutoscaling {
    const message = createBaseAzureNodePoolAutoscaling();
    message.minNodeCount = object.minNodeCount ?? 0;
    message.maxNodeCount = object.maxNodeCount ?? 0;
    return message;
  },
};

function createBaseAzureOpenIdConfig(): AzureOpenIdConfig {
  return {
    issuer: "",
    jwksUri: "",
    responseTypesSupported: [],
    subjectTypesSupported: [],
    idTokenSigningAlgValuesSupported: [],
    claimsSupported: [],
    grantTypes: [],
  };
}

export const AzureOpenIdConfig: MessageFns<AzureOpenIdConfig> = {
  encode(message: AzureOpenIdConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.issuer !== "") {
      writer.uint32(10).string(message.issuer);
    }
    if (message.jwksUri !== "") {
      writer.uint32(18).string(message.jwksUri);
    }
    for (const v of message.responseTypesSupported) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.subjectTypesSupported) {
      writer.uint32(34).string(v!);
    }
    for (const v of message.idTokenSigningAlgValuesSupported) {
      writer.uint32(42).string(v!);
    }
    for (const v of message.claimsSupported) {
      writer.uint32(50).string(v!);
    }
    for (const v of message.grantTypes) {
      writer.uint32(58).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureOpenIdConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureOpenIdConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.issuer = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jwksUri = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.responseTypesSupported.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.subjectTypesSupported.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.idTokenSigningAlgValuesSupported.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.claimsSupported.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.grantTypes.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureOpenIdConfig {
    return {
      issuer: isSet(object.issuer) ? globalThis.String(object.issuer) : "",
      jwksUri: isSet(object.jwksUri) ? globalThis.String(object.jwksUri) : "",
      responseTypesSupported: globalThis.Array.isArray(object?.responseTypesSupported)
        ? object.responseTypesSupported.map((e: any) => globalThis.String(e))
        : [],
      subjectTypesSupported: globalThis.Array.isArray(object?.subjectTypesSupported)
        ? object.subjectTypesSupported.map((e: any) => globalThis.String(e))
        : [],
      idTokenSigningAlgValuesSupported: globalThis.Array.isArray(object?.idTokenSigningAlgValuesSupported)
        ? object.idTokenSigningAlgValuesSupported.map((e: any) => globalThis.String(e))
        : [],
      claimsSupported: globalThis.Array.isArray(object?.claimsSupported)
        ? object.claimsSupported.map((e: any) => globalThis.String(e))
        : [],
      grantTypes: globalThis.Array.isArray(object?.grantTypes)
        ? object.grantTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: AzureOpenIdConfig): unknown {
    const obj: any = {};
    if (message.issuer !== "") {
      obj.issuer = message.issuer;
    }
    if (message.jwksUri !== "") {
      obj.jwksUri = message.jwksUri;
    }
    if (message.responseTypesSupported?.length) {
      obj.responseTypesSupported = message.responseTypesSupported;
    }
    if (message.subjectTypesSupported?.length) {
      obj.subjectTypesSupported = message.subjectTypesSupported;
    }
    if (message.idTokenSigningAlgValuesSupported?.length) {
      obj.idTokenSigningAlgValuesSupported = message.idTokenSigningAlgValuesSupported;
    }
    if (message.claimsSupported?.length) {
      obj.claimsSupported = message.claimsSupported;
    }
    if (message.grantTypes?.length) {
      obj.grantTypes = message.grantTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureOpenIdConfig>): AzureOpenIdConfig {
    return AzureOpenIdConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureOpenIdConfig>): AzureOpenIdConfig {
    const message = createBaseAzureOpenIdConfig();
    message.issuer = object.issuer ?? "";
    message.jwksUri = object.jwksUri ?? "";
    message.responseTypesSupported = object.responseTypesSupported?.map((e) => e) || [];
    message.subjectTypesSupported = object.subjectTypesSupported?.map((e) => e) || [];
    message.idTokenSigningAlgValuesSupported = object.idTokenSigningAlgValuesSupported?.map((e) => e) || [];
    message.claimsSupported = object.claimsSupported?.map((e) => e) || [];
    message.grantTypes = object.grantTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseAzureJsonWebKeys(): AzureJsonWebKeys {
  return { keys: [] };
}

export const AzureJsonWebKeys: MessageFns<AzureJsonWebKeys> = {
  encode(message: AzureJsonWebKeys, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.keys) {
      Jwk.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureJsonWebKeys {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureJsonWebKeys();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.keys.push(Jwk.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureJsonWebKeys {
    return { keys: globalThis.Array.isArray(object?.keys) ? object.keys.map((e: any) => Jwk.fromJSON(e)) : [] };
  },

  toJSON(message: AzureJsonWebKeys): unknown {
    const obj: any = {};
    if (message.keys?.length) {
      obj.keys = message.keys.map((e) => Jwk.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<AzureJsonWebKeys>): AzureJsonWebKeys {
    return AzureJsonWebKeys.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureJsonWebKeys>): AzureJsonWebKeys {
    const message = createBaseAzureJsonWebKeys();
    message.keys = object.keys?.map((e) => Jwk.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAzureServerConfig(): AzureServerConfig {
  return { name: "", validVersions: [], supportedAzureRegions: [] };
}

export const AzureServerConfig: MessageFns<AzureServerConfig> = {
  encode(message: AzureServerConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.validVersions) {
      AzureK8sVersionInfo.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.supportedAzureRegions) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureServerConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureServerConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.validVersions.push(AzureK8sVersionInfo.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.supportedAzureRegions.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureServerConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      validVersions: globalThis.Array.isArray(object?.validVersions)
        ? object.validVersions.map((e: any) => AzureK8sVersionInfo.fromJSON(e))
        : [],
      supportedAzureRegions: globalThis.Array.isArray(object?.supportedAzureRegions)
        ? object.supportedAzureRegions.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: AzureServerConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.validVersions?.length) {
      obj.validVersions = message.validVersions.map((e) => AzureK8sVersionInfo.toJSON(e));
    }
    if (message.supportedAzureRegions?.length) {
      obj.supportedAzureRegions = message.supportedAzureRegions;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureServerConfig>): AzureServerConfig {
    return AzureServerConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureServerConfig>): AzureServerConfig {
    const message = createBaseAzureServerConfig();
    message.name = object.name ?? "";
    message.validVersions = object.validVersions?.map((e) => AzureK8sVersionInfo.fromPartial(e)) || [];
    message.supportedAzureRegions = object.supportedAzureRegions?.map((e) => e) || [];
    return message;
  },
};

function createBaseAzureK8sVersionInfo(): AzureK8sVersionInfo {
  return { version: "", enabled: false, endOfLife: false, endOfLifeDate: undefined, releaseDate: undefined };
}

export const AzureK8sVersionInfo: MessageFns<AzureK8sVersionInfo> = {
  encode(message: AzureK8sVersionInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.enabled !== false) {
      writer.uint32(24).bool(message.enabled);
    }
    if (message.endOfLife !== false) {
      writer.uint32(32).bool(message.endOfLife);
    }
    if (message.endOfLifeDate !== undefined) {
      DateMessage.encode(message.endOfLifeDate, writer.uint32(42).fork()).join();
    }
    if (message.releaseDate !== undefined) {
      DateMessage.encode(message.releaseDate, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureK8sVersionInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureK8sVersionInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.endOfLife = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.endOfLifeDate = DateMessage.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.releaseDate = DateMessage.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureK8sVersionInfo {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      endOfLife: isSet(object.endOfLife) ? globalThis.Boolean(object.endOfLife) : false,
      endOfLifeDate: isSet(object.endOfLifeDate) ? DateMessage.fromJSON(object.endOfLifeDate) : undefined,
      releaseDate: isSet(object.releaseDate) ? DateMessage.fromJSON(object.releaseDate) : undefined,
    };
  },

  toJSON(message: AzureK8sVersionInfo): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.endOfLife !== false) {
      obj.endOfLife = message.endOfLife;
    }
    if (message.endOfLifeDate !== undefined) {
      obj.endOfLifeDate = DateMessage.toJSON(message.endOfLifeDate);
    }
    if (message.releaseDate !== undefined) {
      obj.releaseDate = DateMessage.toJSON(message.releaseDate);
    }
    return obj;
  },

  create(base?: DeepPartial<AzureK8sVersionInfo>): AzureK8sVersionInfo {
    return AzureK8sVersionInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureK8sVersionInfo>): AzureK8sVersionInfo {
    const message = createBaseAzureK8sVersionInfo();
    message.version = object.version ?? "";
    message.enabled = object.enabled ?? false;
    message.endOfLife = object.endOfLife ?? false;
    message.endOfLifeDate = (object.endOfLifeDate !== undefined && object.endOfLifeDate !== null)
      ? DateMessage.fromPartial(object.endOfLifeDate)
      : undefined;
    message.releaseDate = (object.releaseDate !== undefined && object.releaseDate !== null)
      ? DateMessage.fromPartial(object.releaseDate)
      : undefined;
    return message;
  },
};

function createBaseAzureSshConfig(): AzureSshConfig {
  return { authorizedKey: "" };
}

export const AzureSshConfig: MessageFns<AzureSshConfig> = {
  encode(message: AzureSshConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.authorizedKey !== "") {
      writer.uint32(10).string(message.authorizedKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureSshConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureSshConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.authorizedKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureSshConfig {
    return { authorizedKey: isSet(object.authorizedKey) ? globalThis.String(object.authorizedKey) : "" };
  },

  toJSON(message: AzureSshConfig): unknown {
    const obj: any = {};
    if (message.authorizedKey !== "") {
      obj.authorizedKey = message.authorizedKey;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureSshConfig>): AzureSshConfig {
    return AzureSshConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureSshConfig>): AzureSshConfig {
    const message = createBaseAzureSshConfig();
    message.authorizedKey = object.authorizedKey ?? "";
    return message;
  },
};

function createBaseAzureClusterResources(): AzureClusterResources {
  return { networkSecurityGroupId: "", controlPlaneApplicationSecurityGroupId: "" };
}

export const AzureClusterResources: MessageFns<AzureClusterResources> = {
  encode(message: AzureClusterResources, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.networkSecurityGroupId !== "") {
      writer.uint32(10).string(message.networkSecurityGroupId);
    }
    if (message.controlPlaneApplicationSecurityGroupId !== "") {
      writer.uint32(18).string(message.controlPlaneApplicationSecurityGroupId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClusterResources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClusterResources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.networkSecurityGroupId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.controlPlaneApplicationSecurityGroupId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClusterResources {
    return {
      networkSecurityGroupId: isSet(object.networkSecurityGroupId)
        ? globalThis.String(object.networkSecurityGroupId)
        : "",
      controlPlaneApplicationSecurityGroupId: isSet(object.controlPlaneApplicationSecurityGroupId)
        ? globalThis.String(object.controlPlaneApplicationSecurityGroupId)
        : "",
    };
  },

  toJSON(message: AzureClusterResources): unknown {
    const obj: any = {};
    if (message.networkSecurityGroupId !== "") {
      obj.networkSecurityGroupId = message.networkSecurityGroupId;
    }
    if (message.controlPlaneApplicationSecurityGroupId !== "") {
      obj.controlPlaneApplicationSecurityGroupId = message.controlPlaneApplicationSecurityGroupId;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClusterResources>): AzureClusterResources {
    return AzureClusterResources.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClusterResources>): AzureClusterResources {
    const message = createBaseAzureClusterResources();
    message.networkSecurityGroupId = object.networkSecurityGroupId ?? "";
    message.controlPlaneApplicationSecurityGroupId = object.controlPlaneApplicationSecurityGroupId ?? "";
    return message;
  },
};

function createBaseAzureClusterError(): AzureClusterError {
  return { message: "" };
}

export const AzureClusterError: MessageFns<AzureClusterError> = {
  encode(message: AzureClusterError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureClusterError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureClusterError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureClusterError {
    return { message: isSet(object.message) ? globalThis.String(object.message) : "" };
  },

  toJSON(message: AzureClusterError): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureClusterError>): AzureClusterError {
    return AzureClusterError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureClusterError>): AzureClusterError {
    const message = createBaseAzureClusterError();
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseAzureNodePoolError(): AzureNodePoolError {
  return { message: "" };
}

export const AzureNodePoolError: MessageFns<AzureNodePoolError> = {
  encode(message: AzureNodePoolError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureNodePoolError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureNodePoolError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureNodePoolError {
    return { message: isSet(object.message) ? globalThis.String(object.message) : "" };
  },

  toJSON(message: AzureNodePoolError): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureNodePoolError>): AzureNodePoolError {
    return AzureNodePoolError.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureNodePoolError>): AzureNodePoolError {
    const message = createBaseAzureNodePoolError();
    message.message = object.message ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
