// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/gkemulticloud/v1/common_resources.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.gkemulticloud.v1";

/** Jwk is a JSON Web Key as specified in RFC 7517. */
export interface Jwk {
  /** Key Type. */
  kty: string;
  /** Algorithm. */
  alg: string;
  /** Permitted uses for the public keys. */
  use: string;
  /** Key ID. */
  kid: string;
  /** Used for RSA keys. */
  n: string;
  /** Used for RSA keys. */
  e: string;
  /** Used for ECDSA keys. */
  x: string;
  /** Used for ECDSA keys. */
  y: string;
  /** Used for ECDSA keys. */
  crv: string;
}

/** Workload Identity settings. */
export interface WorkloadIdentityConfig {
  /** The OIDC issuer URL for this cluster. */
  issuerUri: string;
  /** The Workload Identity Pool associated to the cluster. */
  workloadPool: string;
  /**
   * The ID of the OIDC Identity Provider (IdP) associated to the Workload
   * Identity Pool.
   */
  identityProvider: string;
}

/** Constraints applied to pods. */
export interface MaxPodsConstraint {
  /** Required. The maximum number of pods to schedule on a single node. */
  maxPodsPerNode: Long;
}

/** Metadata about a long-running operation. */
export interface OperationMetadata {
  /** Output only. The time at which this operation was created. */
  createTime:
    | Date
    | undefined;
  /** Output only. The time at which this operation was completed. */
  endTime:
    | Date
    | undefined;
  /** Output only. The name of the resource associated to this operation. */
  target: string;
  /** Output only. Human-readable status of the operation, if any. */
  statusDetail: string;
  /**
   * Output only. Human-readable status of any error that occurred during the
   * operation.
   */
  errorDetail: string;
  /**
   * Output only. The verb associated with the API method which triggered this
   * operation. Possible values are "create", "delete", "update" and "import".
   */
  verb: string;
  /**
   * Output only. Identifies whether it has been requested cancellation
   * for the operation. Operations that have successfully been cancelled
   * have [Operation.error][] value with a
   * [google.rpc.Status.code][google.rpc.Status.code] of 1, corresponding to
   * `Code.CANCELLED`.
   */
  requestedCancellation: boolean;
}

/** The taint content for the node taint. */
export interface NodeTaint {
  /** Required. Key for the taint. */
  key: string;
  /** Required. Value for the taint. */
  value: string;
  /** Required. The taint effect. */
  effect: NodeTaint_Effect;
}

/** The taint effect. */
export enum NodeTaint_Effect {
  /** EFFECT_UNSPECIFIED - Not set. */
  EFFECT_UNSPECIFIED = 0,
  /**
   * NO_SCHEDULE - Do not allow new pods to schedule onto the node unless they tolerate the
   * taint, but allow all pods submitted to Kubelet without going through the
   * scheduler to start, and allow all already-running pods to continue
   * running. Enforced by the scheduler.
   */
  NO_SCHEDULE = 1,
  /**
   * PREFER_NO_SCHEDULE - Like TaintEffectNoSchedule, but the scheduler tries not to schedule
   * new pods onto the node, rather than prohibiting new pods from scheduling
   * onto the node entirely. Enforced by the scheduler.
   */
  PREFER_NO_SCHEDULE = 2,
  /**
   * NO_EXECUTE - Evict any already-running pods that do not tolerate the taint.
   * Currently enforced by NodeController.
   */
  NO_EXECUTE = 3,
  UNRECOGNIZED = -1,
}

export function nodeTaint_EffectFromJSON(object: any): NodeTaint_Effect {
  switch (object) {
    case 0:
    case "EFFECT_UNSPECIFIED":
      return NodeTaint_Effect.EFFECT_UNSPECIFIED;
    case 1:
    case "NO_SCHEDULE":
      return NodeTaint_Effect.NO_SCHEDULE;
    case 2:
    case "PREFER_NO_SCHEDULE":
      return NodeTaint_Effect.PREFER_NO_SCHEDULE;
    case 3:
    case "NO_EXECUTE":
      return NodeTaint_Effect.NO_EXECUTE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return NodeTaint_Effect.UNRECOGNIZED;
  }
}

export function nodeTaint_EffectToJSON(object: NodeTaint_Effect): string {
  switch (object) {
    case NodeTaint_Effect.EFFECT_UNSPECIFIED:
      return "EFFECT_UNSPECIFIED";
    case NodeTaint_Effect.NO_SCHEDULE:
      return "NO_SCHEDULE";
    case NodeTaint_Effect.PREFER_NO_SCHEDULE:
      return "PREFER_NO_SCHEDULE";
    case NodeTaint_Effect.NO_EXECUTE:
      return "NO_EXECUTE";
    case NodeTaint_Effect.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Configuration for node pool kubelet options. */
export interface NodeKubeletConfig {
  /** Optional. Enable the insecure kubelet read only port. */
  insecureKubeletReadonlyPortEnabled: boolean;
  /**
   * Optional. Control the CPU management policy on the node.
   * See
   * https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/
   *
   * The following values are allowed.
   * * "none": the default, which represents the existing scheduling behavior.
   * * "static": allows pods with certain resource characteristics to be granted
   * increased CPU affinity and exclusivity on the node.
   * The default value is 'none' if unspecified.
   */
  cpuManagerPolicy?:
    | string
    | undefined;
  /**
   * Optional. Enable CPU CFS quota enforcement for containers that specify CPU
   * limits.
   *
   * This option is enabled by default which makes kubelet use CFS quota
   * (https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt) to
   * enforce container CPU limits. Otherwise, CPU limits will not be enforced at
   * all.
   *
   * Disable this option to mitigate CPU throttling problems while still having
   * your pods to be in Guaranteed QoS class by specifying the CPU limits.
   *
   * The default value is 'true' if unspecified.
   */
  cpuCfsQuota?:
    | boolean
    | undefined;
  /**
   * Optional. Set the CPU CFS quota period value 'cpu.cfs_period_us'.
   *
   * The string must be a sequence of decimal numbers, each with optional
   * fraction and a unit suffix, such as "300ms".
   * Valid time units are "ns", "us" (or "Âµs"), "ms", "s", "m", "h".
   * The value must be a positive duration.
   *
   * The default value is '100ms' if unspecified.
   */
  cpuCfsQuotaPeriod?:
    | string
    | undefined;
  /**
   * Optional. Set the Pod PID limits. See
   * https://kubernetes.io/docs/concepts/policy/pid-limiting/#pod-pid-limits
   *
   * Controls the maximum number of processes allowed to run in a pod. The value
   * must be greater than or equal to 1024 and less than 4194304.
   */
  podPidsLimit?: Long | undefined;
}

/**
 * Fleet related configuration.
 *
 * Fleets are a Google Cloud concept for logically organizing clusters,
 * letting you use and manage multi-cluster capabilities and apply
 * consistent policies across your systems.
 *
 * See [Anthos
 * Fleets](https://cloud.google.com/anthos/multicluster-management/fleets) for
 * more details on Anthos multi-cluster capabilities using Fleets.
 */
export interface Fleet {
  /**
   * Required. The name of the Fleet host project where this cluster will be
   * registered.
   *
   * Project names are formatted as
   * `projects/<project-number>`.
   */
  project: string;
  /**
   * Output only. The name of the managed Hub Membership resource associated to
   * this cluster.
   *
   * Membership names are formatted as
   * `projects/<project-number>/locations/global/membership/<cluster-id>`.
   */
  membership: string;
}

/** Parameters that describe the Logging configuration in a cluster. */
export interface LoggingConfig {
  /** The configuration of the logging components; */
  componentConfig: LoggingComponentConfig | undefined;
}

/** Parameters that describe the Logging component configuration in a cluster. */
export interface LoggingComponentConfig {
  /** The components to be enabled. */
  enableComponents: LoggingComponentConfig_Component[];
}

/** The components of the logging configuration; */
export enum LoggingComponentConfig_Component {
  /** COMPONENT_UNSPECIFIED - No component is specified */
  COMPONENT_UNSPECIFIED = 0,
  /** SYSTEM_COMPONENTS - This indicates that system logging components is enabled. */
  SYSTEM_COMPONENTS = 1,
  /** WORKLOADS - This indicates that user workload logging component is enabled. */
  WORKLOADS = 2,
  UNRECOGNIZED = -1,
}

export function loggingComponentConfig_ComponentFromJSON(object: any): LoggingComponentConfig_Component {
  switch (object) {
    case 0:
    case "COMPONENT_UNSPECIFIED":
      return LoggingComponentConfig_Component.COMPONENT_UNSPECIFIED;
    case 1:
    case "SYSTEM_COMPONENTS":
      return LoggingComponentConfig_Component.SYSTEM_COMPONENTS;
    case 2:
    case "WORKLOADS":
      return LoggingComponentConfig_Component.WORKLOADS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return LoggingComponentConfig_Component.UNRECOGNIZED;
  }
}

export function loggingComponentConfig_ComponentToJSON(object: LoggingComponentConfig_Component): string {
  switch (object) {
    case LoggingComponentConfig_Component.COMPONENT_UNSPECIFIED:
      return "COMPONENT_UNSPECIFIED";
    case LoggingComponentConfig_Component.SYSTEM_COMPONENTS:
      return "SYSTEM_COMPONENTS";
    case LoggingComponentConfig_Component.WORKLOADS:
      return "WORKLOADS";
    case LoggingComponentConfig_Component.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Parameters that describe the Monitoring configuration in a cluster. */
export interface MonitoringConfig {
  /** Enable Google Cloud Managed Service for Prometheus in the cluster. */
  managedPrometheusConfig: ManagedPrometheusConfig | undefined;
}

/**
 * ManagedPrometheusConfig defines the configuration for
 * Google Cloud Managed Service for Prometheus.
 */
export interface ManagedPrometheusConfig {
  /** Enable Managed Collection. */
  enabled: boolean;
}

/** Configuration for Binary Authorization. */
export interface BinaryAuthorization {
  /**
   * Mode of operation for binauthz policy evaluation. If unspecified, defaults
   * to DISABLED.
   */
  evaluationMode: BinaryAuthorization_EvaluationMode;
}

/** Binary Authorization mode of operation. */
export enum BinaryAuthorization_EvaluationMode {
  /** EVALUATION_MODE_UNSPECIFIED - Default value */
  EVALUATION_MODE_UNSPECIFIED = 0,
  /** DISABLED - Disable BinaryAuthorization */
  DISABLED = 1,
  /**
   * PROJECT_SINGLETON_POLICY_ENFORCE - Enforce Kubernetes admission requests with BinaryAuthorization using the
   * project's singleton policy.
   */
  PROJECT_SINGLETON_POLICY_ENFORCE = 2,
  UNRECOGNIZED = -1,
}

export function binaryAuthorization_EvaluationModeFromJSON(object: any): BinaryAuthorization_EvaluationMode {
  switch (object) {
    case 0:
    case "EVALUATION_MODE_UNSPECIFIED":
      return BinaryAuthorization_EvaluationMode.EVALUATION_MODE_UNSPECIFIED;
    case 1:
    case "DISABLED":
      return BinaryAuthorization_EvaluationMode.DISABLED;
    case 2:
    case "PROJECT_SINGLETON_POLICY_ENFORCE":
      return BinaryAuthorization_EvaluationMode.PROJECT_SINGLETON_POLICY_ENFORCE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BinaryAuthorization_EvaluationMode.UNRECOGNIZED;
  }
}

export function binaryAuthorization_EvaluationModeToJSON(object: BinaryAuthorization_EvaluationMode): string {
  switch (object) {
    case BinaryAuthorization_EvaluationMode.EVALUATION_MODE_UNSPECIFIED:
      return "EVALUATION_MODE_UNSPECIFIED";
    case BinaryAuthorization_EvaluationMode.DISABLED:
      return "DISABLED";
    case BinaryAuthorization_EvaluationMode.PROJECT_SINGLETON_POLICY_ENFORCE:
      return "PROJECT_SINGLETON_POLICY_ENFORCE";
    case BinaryAuthorization_EvaluationMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * SecurityPostureConfig defines the flags needed to enable/disable features for
 * the Security Posture API.
 */
export interface SecurityPostureConfig {
  /** Sets which mode to use for vulnerability scanning. */
  vulnerabilityMode: SecurityPostureConfig_VulnerabilityMode;
}

/** VulnerabilityMode defines enablement mode for vulnerability scanning. */
export enum SecurityPostureConfig_VulnerabilityMode {
  /** VULNERABILITY_MODE_UNSPECIFIED - Default value not specified. */
  VULNERABILITY_MODE_UNSPECIFIED = 0,
  /** VULNERABILITY_DISABLED - Disables vulnerability scanning on the cluster. */
  VULNERABILITY_DISABLED = 1,
  /**
   * VULNERABILITY_ENTERPRISE - Applies the Security Posture's vulnerability on cluster Enterprise level
   * features.
   */
  VULNERABILITY_ENTERPRISE = 2,
  UNRECOGNIZED = -1,
}

export function securityPostureConfig_VulnerabilityModeFromJSON(object: any): SecurityPostureConfig_VulnerabilityMode {
  switch (object) {
    case 0:
    case "VULNERABILITY_MODE_UNSPECIFIED":
      return SecurityPostureConfig_VulnerabilityMode.VULNERABILITY_MODE_UNSPECIFIED;
    case 1:
    case "VULNERABILITY_DISABLED":
      return SecurityPostureConfig_VulnerabilityMode.VULNERABILITY_DISABLED;
    case 2:
    case "VULNERABILITY_ENTERPRISE":
      return SecurityPostureConfig_VulnerabilityMode.VULNERABILITY_ENTERPRISE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SecurityPostureConfig_VulnerabilityMode.UNRECOGNIZED;
  }
}

export function securityPostureConfig_VulnerabilityModeToJSON(object: SecurityPostureConfig_VulnerabilityMode): string {
  switch (object) {
    case SecurityPostureConfig_VulnerabilityMode.VULNERABILITY_MODE_UNSPECIFIED:
      return "VULNERABILITY_MODE_UNSPECIFIED";
    case SecurityPostureConfig_VulnerabilityMode.VULNERABILITY_DISABLED:
      return "VULNERABILITY_DISABLED";
    case SecurityPostureConfig_VulnerabilityMode.VULNERABILITY_ENTERPRISE:
      return "VULNERABILITY_ENTERPRISE";
    case SecurityPostureConfig_VulnerabilityMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseJwk(): Jwk {
  return { kty: "", alg: "", use: "", kid: "", n: "", e: "", x: "", y: "", crv: "" };
}

export const Jwk: MessageFns<Jwk> = {
  encode(message: Jwk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kty !== "") {
      writer.uint32(10).string(message.kty);
    }
    if (message.alg !== "") {
      writer.uint32(18).string(message.alg);
    }
    if (message.use !== "") {
      writer.uint32(26).string(message.use);
    }
    if (message.kid !== "") {
      writer.uint32(34).string(message.kid);
    }
    if (message.n !== "") {
      writer.uint32(42).string(message.n);
    }
    if (message.e !== "") {
      writer.uint32(50).string(message.e);
    }
    if (message.x !== "") {
      writer.uint32(58).string(message.x);
    }
    if (message.y !== "") {
      writer.uint32(66).string(message.y);
    }
    if (message.crv !== "") {
      writer.uint32(74).string(message.crv);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Jwk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJwk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kty = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.alg = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.use = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.kid = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.n = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.e = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.x = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.y = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.crv = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Jwk {
    return {
      kty: isSet(object.kty) ? globalThis.String(object.kty) : "",
      alg: isSet(object.alg) ? globalThis.String(object.alg) : "",
      use: isSet(object.use) ? globalThis.String(object.use) : "",
      kid: isSet(object.kid) ? globalThis.String(object.kid) : "",
      n: isSet(object.n) ? globalThis.String(object.n) : "",
      e: isSet(object.e) ? globalThis.String(object.e) : "",
      x: isSet(object.x) ? globalThis.String(object.x) : "",
      y: isSet(object.y) ? globalThis.String(object.y) : "",
      crv: isSet(object.crv) ? globalThis.String(object.crv) : "",
    };
  },

  toJSON(message: Jwk): unknown {
    const obj: any = {};
    if (message.kty !== "") {
      obj.kty = message.kty;
    }
    if (message.alg !== "") {
      obj.alg = message.alg;
    }
    if (message.use !== "") {
      obj.use = message.use;
    }
    if (message.kid !== "") {
      obj.kid = message.kid;
    }
    if (message.n !== "") {
      obj.n = message.n;
    }
    if (message.e !== "") {
      obj.e = message.e;
    }
    if (message.x !== "") {
      obj.x = message.x;
    }
    if (message.y !== "") {
      obj.y = message.y;
    }
    if (message.crv !== "") {
      obj.crv = message.crv;
    }
    return obj;
  },

  create(base?: DeepPartial<Jwk>): Jwk {
    return Jwk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Jwk>): Jwk {
    const message = createBaseJwk();
    message.kty = object.kty ?? "";
    message.alg = object.alg ?? "";
    message.use = object.use ?? "";
    message.kid = object.kid ?? "";
    message.n = object.n ?? "";
    message.e = object.e ?? "";
    message.x = object.x ?? "";
    message.y = object.y ?? "";
    message.crv = object.crv ?? "";
    return message;
  },
};

function createBaseWorkloadIdentityConfig(): WorkloadIdentityConfig {
  return { issuerUri: "", workloadPool: "", identityProvider: "" };
}

export const WorkloadIdentityConfig: MessageFns<WorkloadIdentityConfig> = {
  encode(message: WorkloadIdentityConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.issuerUri !== "") {
      writer.uint32(10).string(message.issuerUri);
    }
    if (message.workloadPool !== "") {
      writer.uint32(18).string(message.workloadPool);
    }
    if (message.identityProvider !== "") {
      writer.uint32(26).string(message.identityProvider);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkloadIdentityConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkloadIdentityConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.issuerUri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workloadPool = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.identityProvider = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkloadIdentityConfig {
    return {
      issuerUri: isSet(object.issuerUri) ? globalThis.String(object.issuerUri) : "",
      workloadPool: isSet(object.workloadPool) ? globalThis.String(object.workloadPool) : "",
      identityProvider: isSet(object.identityProvider) ? globalThis.String(object.identityProvider) : "",
    };
  },

  toJSON(message: WorkloadIdentityConfig): unknown {
    const obj: any = {};
    if (message.issuerUri !== "") {
      obj.issuerUri = message.issuerUri;
    }
    if (message.workloadPool !== "") {
      obj.workloadPool = message.workloadPool;
    }
    if (message.identityProvider !== "") {
      obj.identityProvider = message.identityProvider;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkloadIdentityConfig>): WorkloadIdentityConfig {
    return WorkloadIdentityConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkloadIdentityConfig>): WorkloadIdentityConfig {
    const message = createBaseWorkloadIdentityConfig();
    message.issuerUri = object.issuerUri ?? "";
    message.workloadPool = object.workloadPool ?? "";
    message.identityProvider = object.identityProvider ?? "";
    return message;
  },
};

function createBaseMaxPodsConstraint(): MaxPodsConstraint {
  return { maxPodsPerNode: Long.ZERO };
}

export const MaxPodsConstraint: MessageFns<MaxPodsConstraint> = {
  encode(message: MaxPodsConstraint, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.maxPodsPerNode.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.maxPodsPerNode.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MaxPodsConstraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMaxPodsConstraint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.maxPodsPerNode = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MaxPodsConstraint {
    return { maxPodsPerNode: isSet(object.maxPodsPerNode) ? Long.fromValue(object.maxPodsPerNode) : Long.ZERO };
  },

  toJSON(message: MaxPodsConstraint): unknown {
    const obj: any = {};
    if (!message.maxPodsPerNode.equals(Long.ZERO)) {
      obj.maxPodsPerNode = (message.maxPodsPerNode || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<MaxPodsConstraint>): MaxPodsConstraint {
    return MaxPodsConstraint.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MaxPodsConstraint>): MaxPodsConstraint {
    const message = createBaseMaxPodsConstraint();
    message.maxPodsPerNode = (object.maxPodsPerNode !== undefined && object.maxPodsPerNode !== null)
      ? Long.fromValue(object.maxPodsPerNode)
      : Long.ZERO;
    return message;
  },
};

function createBaseOperationMetadata(): OperationMetadata {
  return {
    createTime: undefined,
    endTime: undefined,
    target: "",
    statusDetail: "",
    errorDetail: "",
    verb: "",
    requestedCancellation: false,
  };
}

export const OperationMetadata: MessageFns<OperationMetadata> = {
  encode(message: OperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.target !== "") {
      writer.uint32(26).string(message.target);
    }
    if (message.statusDetail !== "") {
      writer.uint32(34).string(message.statusDetail);
    }
    if (message.errorDetail !== "") {
      writer.uint32(42).string(message.errorDetail);
    }
    if (message.verb !== "") {
      writer.uint32(58).string(message.verb);
    }
    if (message.requestedCancellation !== false) {
      writer.uint32(48).bool(message.requestedCancellation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.target = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.statusDetail = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.errorDetail = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.verb = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.requestedCancellation = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OperationMetadata {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      target: isSet(object.target) ? globalThis.String(object.target) : "",
      statusDetail: isSet(object.statusDetail) ? globalThis.String(object.statusDetail) : "",
      errorDetail: isSet(object.errorDetail) ? globalThis.String(object.errorDetail) : "",
      verb: isSet(object.verb) ? globalThis.String(object.verb) : "",
      requestedCancellation: isSet(object.requestedCancellation)
        ? globalThis.Boolean(object.requestedCancellation)
        : false,
    };
  },

  toJSON(message: OperationMetadata): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.target !== "") {
      obj.target = message.target;
    }
    if (message.statusDetail !== "") {
      obj.statusDetail = message.statusDetail;
    }
    if (message.errorDetail !== "") {
      obj.errorDetail = message.errorDetail;
    }
    if (message.verb !== "") {
      obj.verb = message.verb;
    }
    if (message.requestedCancellation !== false) {
      obj.requestedCancellation = message.requestedCancellation;
    }
    return obj;
  },

  create(base?: DeepPartial<OperationMetadata>): OperationMetadata {
    return OperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OperationMetadata>): OperationMetadata {
    const message = createBaseOperationMetadata();
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.target = object.target ?? "";
    message.statusDetail = object.statusDetail ?? "";
    message.errorDetail = object.errorDetail ?? "";
    message.verb = object.verb ?? "";
    message.requestedCancellation = object.requestedCancellation ?? false;
    return message;
  },
};

function createBaseNodeTaint(): NodeTaint {
  return { key: "", value: "", effect: 0 };
}

export const NodeTaint: MessageFns<NodeTaint> = {
  encode(message: NodeTaint, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    if (message.effect !== 0) {
      writer.uint32(24).int32(message.effect);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NodeTaint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNodeTaint();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.effect = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NodeTaint {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      effect: isSet(object.effect) ? nodeTaint_EffectFromJSON(object.effect) : 0,
    };
  },

  toJSON(message: NodeTaint): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (message.effect !== 0) {
      obj.effect = nodeTaint_EffectToJSON(message.effect);
    }
    return obj;
  },

  create(base?: DeepPartial<NodeTaint>): NodeTaint {
    return NodeTaint.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NodeTaint>): NodeTaint {
    const message = createBaseNodeTaint();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    message.effect = object.effect ?? 0;
    return message;
  },
};

function createBaseNodeKubeletConfig(): NodeKubeletConfig {
  return {
    insecureKubeletReadonlyPortEnabled: false,
    cpuManagerPolicy: undefined,
    cpuCfsQuota: undefined,
    cpuCfsQuotaPeriod: undefined,
    podPidsLimit: undefined,
  };
}

export const NodeKubeletConfig: MessageFns<NodeKubeletConfig> = {
  encode(message: NodeKubeletConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.insecureKubeletReadonlyPortEnabled !== false) {
      writer.uint32(8).bool(message.insecureKubeletReadonlyPortEnabled);
    }
    if (message.cpuManagerPolicy !== undefined) {
      writer.uint32(18).string(message.cpuManagerPolicy);
    }
    if (message.cpuCfsQuota !== undefined) {
      writer.uint32(24).bool(message.cpuCfsQuota);
    }
    if (message.cpuCfsQuotaPeriod !== undefined) {
      writer.uint32(34).string(message.cpuCfsQuotaPeriod);
    }
    if (message.podPidsLimit !== undefined) {
      writer.uint32(40).int64(message.podPidsLimit.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NodeKubeletConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNodeKubeletConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.insecureKubeletReadonlyPortEnabled = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cpuManagerPolicy = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.cpuCfsQuota = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.cpuCfsQuotaPeriod = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.podPidsLimit = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NodeKubeletConfig {
    return {
      insecureKubeletReadonlyPortEnabled: isSet(object.insecureKubeletReadonlyPortEnabled)
        ? globalThis.Boolean(object.insecureKubeletReadonlyPortEnabled)
        : false,
      cpuManagerPolicy: isSet(object.cpuManagerPolicy) ? globalThis.String(object.cpuManagerPolicy) : undefined,
      cpuCfsQuota: isSet(object.cpuCfsQuota) ? globalThis.Boolean(object.cpuCfsQuota) : undefined,
      cpuCfsQuotaPeriod: isSet(object.cpuCfsQuotaPeriod) ? globalThis.String(object.cpuCfsQuotaPeriod) : undefined,
      podPidsLimit: isSet(object.podPidsLimit) ? Long.fromValue(object.podPidsLimit) : undefined,
    };
  },

  toJSON(message: NodeKubeletConfig): unknown {
    const obj: any = {};
    if (message.insecureKubeletReadonlyPortEnabled !== false) {
      obj.insecureKubeletReadonlyPortEnabled = message.insecureKubeletReadonlyPortEnabled;
    }
    if (message.cpuManagerPolicy !== undefined) {
      obj.cpuManagerPolicy = message.cpuManagerPolicy;
    }
    if (message.cpuCfsQuota !== undefined) {
      obj.cpuCfsQuota = message.cpuCfsQuota;
    }
    if (message.cpuCfsQuotaPeriod !== undefined) {
      obj.cpuCfsQuotaPeriod = message.cpuCfsQuotaPeriod;
    }
    if (message.podPidsLimit !== undefined) {
      obj.podPidsLimit = (message.podPidsLimit || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<NodeKubeletConfig>): NodeKubeletConfig {
    return NodeKubeletConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NodeKubeletConfig>): NodeKubeletConfig {
    const message = createBaseNodeKubeletConfig();
    message.insecureKubeletReadonlyPortEnabled = object.insecureKubeletReadonlyPortEnabled ?? false;
    message.cpuManagerPolicy = object.cpuManagerPolicy ?? undefined;
    message.cpuCfsQuota = object.cpuCfsQuota ?? undefined;
    message.cpuCfsQuotaPeriod = object.cpuCfsQuotaPeriod ?? undefined;
    message.podPidsLimit = (object.podPidsLimit !== undefined && object.podPidsLimit !== null)
      ? Long.fromValue(object.podPidsLimit)
      : undefined;
    return message;
  },
};

function createBaseFleet(): Fleet {
  return { project: "", membership: "" };
}

export const Fleet: MessageFns<Fleet> = {
  encode(message: Fleet, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.membership !== "") {
      writer.uint32(18).string(message.membership);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Fleet {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFleet();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.membership = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Fleet {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      membership: isSet(object.membership) ? globalThis.String(object.membership) : "",
    };
  },

  toJSON(message: Fleet): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.membership !== "") {
      obj.membership = message.membership;
    }
    return obj;
  },

  create(base?: DeepPartial<Fleet>): Fleet {
    return Fleet.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Fleet>): Fleet {
    const message = createBaseFleet();
    message.project = object.project ?? "";
    message.membership = object.membership ?? "";
    return message;
  },
};

function createBaseLoggingConfig(): LoggingConfig {
  return { componentConfig: undefined };
}

export const LoggingConfig: MessageFns<LoggingConfig> = {
  encode(message: LoggingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.componentConfig !== undefined) {
      LoggingComponentConfig.encode(message.componentConfig, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LoggingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLoggingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.componentConfig = LoggingComponentConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LoggingConfig {
    return {
      componentConfig: isSet(object.componentConfig)
        ? LoggingComponentConfig.fromJSON(object.componentConfig)
        : undefined,
    };
  },

  toJSON(message: LoggingConfig): unknown {
    const obj: any = {};
    if (message.componentConfig !== undefined) {
      obj.componentConfig = LoggingComponentConfig.toJSON(message.componentConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<LoggingConfig>): LoggingConfig {
    return LoggingConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LoggingConfig>): LoggingConfig {
    const message = createBaseLoggingConfig();
    message.componentConfig = (object.componentConfig !== undefined && object.componentConfig !== null)
      ? LoggingComponentConfig.fromPartial(object.componentConfig)
      : undefined;
    return message;
  },
};

function createBaseLoggingComponentConfig(): LoggingComponentConfig {
  return { enableComponents: [] };
}

export const LoggingComponentConfig: MessageFns<LoggingComponentConfig> = {
  encode(message: LoggingComponentConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.enableComponents) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LoggingComponentConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLoggingComponentConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.enableComponents.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.enableComponents.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LoggingComponentConfig {
    return {
      enableComponents: globalThis.Array.isArray(object?.enableComponents)
        ? object.enableComponents.map((e: any) => loggingComponentConfig_ComponentFromJSON(e))
        : [],
    };
  },

  toJSON(message: LoggingComponentConfig): unknown {
    const obj: any = {};
    if (message.enableComponents?.length) {
      obj.enableComponents = message.enableComponents.map((e) => loggingComponentConfig_ComponentToJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<LoggingComponentConfig>): LoggingComponentConfig {
    return LoggingComponentConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LoggingComponentConfig>): LoggingComponentConfig {
    const message = createBaseLoggingComponentConfig();
    message.enableComponents = object.enableComponents?.map((e) => e) || [];
    return message;
  },
};

function createBaseMonitoringConfig(): MonitoringConfig {
  return { managedPrometheusConfig: undefined };
}

export const MonitoringConfig: MessageFns<MonitoringConfig> = {
  encode(message: MonitoringConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.managedPrometheusConfig !== undefined) {
      ManagedPrometheusConfig.encode(message.managedPrometheusConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MonitoringConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMonitoringConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.managedPrometheusConfig = ManagedPrometheusConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MonitoringConfig {
    return {
      managedPrometheusConfig: isSet(object.managedPrometheusConfig)
        ? ManagedPrometheusConfig.fromJSON(object.managedPrometheusConfig)
        : undefined,
    };
  },

  toJSON(message: MonitoringConfig): unknown {
    const obj: any = {};
    if (message.managedPrometheusConfig !== undefined) {
      obj.managedPrometheusConfig = ManagedPrometheusConfig.toJSON(message.managedPrometheusConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<MonitoringConfig>): MonitoringConfig {
    return MonitoringConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MonitoringConfig>): MonitoringConfig {
    const message = createBaseMonitoringConfig();
    message.managedPrometheusConfig =
      (object.managedPrometheusConfig !== undefined && object.managedPrometheusConfig !== null)
        ? ManagedPrometheusConfig.fromPartial(object.managedPrometheusConfig)
        : undefined;
    return message;
  },
};

function createBaseManagedPrometheusConfig(): ManagedPrometheusConfig {
  return { enabled: false };
}

export const ManagedPrometheusConfig: MessageFns<ManagedPrometheusConfig> = {
  encode(message: ManagedPrometheusConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ManagedPrometheusConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseManagedPrometheusConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ManagedPrometheusConfig {
    return { enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false };
  },

  toJSON(message: ManagedPrometheusConfig): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    return obj;
  },

  create(base?: DeepPartial<ManagedPrometheusConfig>): ManagedPrometheusConfig {
    return ManagedPrometheusConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ManagedPrometheusConfig>): ManagedPrometheusConfig {
    const message = createBaseManagedPrometheusConfig();
    message.enabled = object.enabled ?? false;
    return message;
  },
};

function createBaseBinaryAuthorization(): BinaryAuthorization {
  return { evaluationMode: 0 };
}

export const BinaryAuthorization: MessageFns<BinaryAuthorization> = {
  encode(message: BinaryAuthorization, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.evaluationMode !== 0) {
      writer.uint32(8).int32(message.evaluationMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BinaryAuthorization {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBinaryAuthorization();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.evaluationMode = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BinaryAuthorization {
    return {
      evaluationMode: isSet(object.evaluationMode)
        ? binaryAuthorization_EvaluationModeFromJSON(object.evaluationMode)
        : 0,
    };
  },

  toJSON(message: BinaryAuthorization): unknown {
    const obj: any = {};
    if (message.evaluationMode !== 0) {
      obj.evaluationMode = binaryAuthorization_EvaluationModeToJSON(message.evaluationMode);
    }
    return obj;
  },

  create(base?: DeepPartial<BinaryAuthorization>): BinaryAuthorization {
    return BinaryAuthorization.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BinaryAuthorization>): BinaryAuthorization {
    const message = createBaseBinaryAuthorization();
    message.evaluationMode = object.evaluationMode ?? 0;
    return message;
  },
};

function createBaseSecurityPostureConfig(): SecurityPostureConfig {
  return { vulnerabilityMode: 0 };
}

export const SecurityPostureConfig: MessageFns<SecurityPostureConfig> = {
  encode(message: SecurityPostureConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vulnerabilityMode !== 0) {
      writer.uint32(8).int32(message.vulnerabilityMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecurityPostureConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecurityPostureConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.vulnerabilityMode = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecurityPostureConfig {
    return {
      vulnerabilityMode: isSet(object.vulnerabilityMode)
        ? securityPostureConfig_VulnerabilityModeFromJSON(object.vulnerabilityMode)
        : 0,
    };
  },

  toJSON(message: SecurityPostureConfig): unknown {
    const obj: any = {};
    if (message.vulnerabilityMode !== 0) {
      obj.vulnerabilityMode = securityPostureConfig_VulnerabilityModeToJSON(message.vulnerabilityMode);
    }
    return obj;
  },

  create(base?: DeepPartial<SecurityPostureConfig>): SecurityPostureConfig {
    return SecurityPostureConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecurityPostureConfig>): SecurityPostureConfig {
    const message = createBaseSecurityPostureConfig();
    message.vulnerabilityMode = object.vulnerabilityMode ?? 0;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
