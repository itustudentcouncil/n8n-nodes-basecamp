// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/automl/v1beta1/detection.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { BoundingPoly } from "./geometry.js";

export const protobufPackage = "google.cloud.automl.v1beta1";

/** Annotation details for image object detection. */
export interface ImageObjectDetectionAnnotation {
  /** Output only. The rectangle representing the object location. */
  boundingBox:
    | BoundingPoly
    | undefined;
  /**
   * Output only. The confidence that this annotation is positive for the parent example,
   * value in [0, 1], higher means higher positivity confidence.
   */
  score: number;
}

/** Annotation details for video object tracking. */
export interface VideoObjectTrackingAnnotation {
  /**
   * Optional. The instance of the object, expressed as a positive integer. Used to tell
   * apart objects of the same type (i.e. AnnotationSpec) when multiple are
   * present on a single example.
   * NOTE: Instance ID prediction quality is not a part of model evaluation and
   * is done as best effort. Especially in cases when an entity goes
   * off-screen for a longer time (minutes), when it comes back it may be given
   * a new instance ID.
   */
  instanceId: string;
  /**
   * Required. A time (frame) of a video to which this annotation pertains.
   * Represented as the duration since the video's start.
   */
  timeOffset:
    | Duration
    | undefined;
  /**
   * Required. The rectangle representing the object location on the frame (i.e.
   * at the time_offset of the video).
   */
  boundingBox:
    | BoundingPoly
    | undefined;
  /**
   * Output only. The confidence that this annotation is positive for the video at
   * the time_offset, value in [0, 1], higher means higher positivity
   * confidence. For annotations created by the user the score is 1. When
   * user approves an annotation, the original float score is kept (and not
   * changed to 1).
   */
  score: number;
}

/**
 * Bounding box matching model metrics for a single intersection-over-union
 * threshold and multiple label match confidence thresholds.
 */
export interface BoundingBoxMetricsEntry {
  /**
   * Output only. The intersection-over-union threshold value used to compute
   * this metrics entry.
   */
  iouThreshold: number;
  /** Output only. The mean average precision, most often close to au_prc. */
  meanAveragePrecision: number;
  /**
   * Output only. Metrics for each label-match confidence_threshold from
   * 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99. Precision-recall curve is
   * derived from them.
   */
  confidenceMetricsEntries: BoundingBoxMetricsEntry_ConfidenceMetricsEntry[];
}

/** Metrics for a single confidence threshold. */
export interface BoundingBoxMetricsEntry_ConfidenceMetricsEntry {
  /** Output only. The confidence threshold value used to compute the metrics. */
  confidenceThreshold: number;
  /** Output only. Recall under the given confidence threshold. */
  recall: number;
  /** Output only. Precision under the given confidence threshold. */
  precision: number;
  /** Output only. The harmonic mean of recall and precision. */
  f1Score: number;
}

/**
 * Model evaluation metrics for image object detection problems.
 * Evaluates prediction quality of labeled bounding boxes.
 */
export interface ImageObjectDetectionEvaluationMetrics {
  /**
   * Output only. The total number of bounding boxes (i.e. summed over all
   * images) the ground truth used to create this evaluation had.
   */
  evaluatedBoundingBoxCount: number;
  /**
   * Output only. The bounding boxes match metrics for each
   * Intersection-over-union threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * and each label confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * pair.
   */
  boundingBoxMetricsEntries: BoundingBoxMetricsEntry[];
  /**
   * Output only. The single metric for bounding boxes evaluation:
   * the mean_average_precision averaged over all bounding_box_metrics_entries.
   */
  boundingBoxMeanAveragePrecision: number;
}

/**
 * Model evaluation metrics for video object tracking problems.
 * Evaluates prediction quality of both labeled bounding boxes and labeled
 * tracks (i.e. series of bounding boxes sharing same label and instance ID).
 */
export interface VideoObjectTrackingEvaluationMetrics {
  /** Output only. The number of video frames used to create this evaluation. */
  evaluatedFrameCount: number;
  /**
   * Output only. The total number of bounding boxes (i.e. summed over all
   * frames) the ground truth used to create this evaluation had.
   */
  evaluatedBoundingBoxCount: number;
  /**
   * Output only. The bounding boxes match metrics for each
   * Intersection-over-union threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * and each label confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * pair.
   */
  boundingBoxMetricsEntries: BoundingBoxMetricsEntry[];
  /**
   * Output only. The single metric for bounding boxes evaluation:
   * the mean_average_precision averaged over all bounding_box_metrics_entries.
   */
  boundingBoxMeanAveragePrecision: number;
}

function createBaseImageObjectDetectionAnnotation(): ImageObjectDetectionAnnotation {
  return { boundingBox: undefined, score: 0 };
}

export const ImageObjectDetectionAnnotation: MessageFns<ImageObjectDetectionAnnotation> = {
  encode(message: ImageObjectDetectionAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.boundingBox !== undefined) {
      BoundingPoly.encode(message.boundingBox, writer.uint32(10).fork()).join();
    }
    if (message.score !== 0) {
      writer.uint32(21).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageObjectDetectionAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageObjectDetectionAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.boundingBox = BoundingPoly.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageObjectDetectionAnnotation {
    return {
      boundingBox: isSet(object.boundingBox) ? BoundingPoly.fromJSON(object.boundingBox) : undefined,
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
    };
  },

  toJSON(message: ImageObjectDetectionAnnotation): unknown {
    const obj: any = {};
    if (message.boundingBox !== undefined) {
      obj.boundingBox = BoundingPoly.toJSON(message.boundingBox);
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    return obj;
  },

  create(base?: DeepPartial<ImageObjectDetectionAnnotation>): ImageObjectDetectionAnnotation {
    return ImageObjectDetectionAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageObjectDetectionAnnotation>): ImageObjectDetectionAnnotation {
    const message = createBaseImageObjectDetectionAnnotation();
    message.boundingBox = (object.boundingBox !== undefined && object.boundingBox !== null)
      ? BoundingPoly.fromPartial(object.boundingBox)
      : undefined;
    message.score = object.score ?? 0;
    return message;
  },
};

function createBaseVideoObjectTrackingAnnotation(): VideoObjectTrackingAnnotation {
  return { instanceId: "", timeOffset: undefined, boundingBox: undefined, score: 0 };
}

export const VideoObjectTrackingAnnotation: MessageFns<VideoObjectTrackingAnnotation> = {
  encode(message: VideoObjectTrackingAnnotation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instanceId !== "") {
      writer.uint32(10).string(message.instanceId);
    }
    if (message.timeOffset !== undefined) {
      Duration.encode(message.timeOffset, writer.uint32(18).fork()).join();
    }
    if (message.boundingBox !== undefined) {
      BoundingPoly.encode(message.boundingBox, writer.uint32(26).fork()).join();
    }
    if (message.score !== 0) {
      writer.uint32(37).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoObjectTrackingAnnotation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoObjectTrackingAnnotation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instanceId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.timeOffset = Duration.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.boundingBox = BoundingPoly.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoObjectTrackingAnnotation {
    return {
      instanceId: isSet(object.instanceId) ? globalThis.String(object.instanceId) : "",
      timeOffset: isSet(object.timeOffset) ? Duration.fromJSON(object.timeOffset) : undefined,
      boundingBox: isSet(object.boundingBox) ? BoundingPoly.fromJSON(object.boundingBox) : undefined,
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
    };
  },

  toJSON(message: VideoObjectTrackingAnnotation): unknown {
    const obj: any = {};
    if (message.instanceId !== "") {
      obj.instanceId = message.instanceId;
    }
    if (message.timeOffset !== undefined) {
      obj.timeOffset = Duration.toJSON(message.timeOffset);
    }
    if (message.boundingBox !== undefined) {
      obj.boundingBox = BoundingPoly.toJSON(message.boundingBox);
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoObjectTrackingAnnotation>): VideoObjectTrackingAnnotation {
    return VideoObjectTrackingAnnotation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoObjectTrackingAnnotation>): VideoObjectTrackingAnnotation {
    const message = createBaseVideoObjectTrackingAnnotation();
    message.instanceId = object.instanceId ?? "";
    message.timeOffset = (object.timeOffset !== undefined && object.timeOffset !== null)
      ? Duration.fromPartial(object.timeOffset)
      : undefined;
    message.boundingBox = (object.boundingBox !== undefined && object.boundingBox !== null)
      ? BoundingPoly.fromPartial(object.boundingBox)
      : undefined;
    message.score = object.score ?? 0;
    return message;
  },
};

function createBaseBoundingBoxMetricsEntry(): BoundingBoxMetricsEntry {
  return { iouThreshold: 0, meanAveragePrecision: 0, confidenceMetricsEntries: [] };
}

export const BoundingBoxMetricsEntry: MessageFns<BoundingBoxMetricsEntry> = {
  encode(message: BoundingBoxMetricsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.iouThreshold !== 0) {
      writer.uint32(13).float(message.iouThreshold);
    }
    if (message.meanAveragePrecision !== 0) {
      writer.uint32(21).float(message.meanAveragePrecision);
    }
    for (const v of message.confidenceMetricsEntries) {
      BoundingBoxMetricsEntry_ConfidenceMetricsEntry.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoundingBoxMetricsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoundingBoxMetricsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.iouThreshold = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.meanAveragePrecision = reader.float();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.confidenceMetricsEntries.push(
            BoundingBoxMetricsEntry_ConfidenceMetricsEntry.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoundingBoxMetricsEntry {
    return {
      iouThreshold: isSet(object.iouThreshold) ? globalThis.Number(object.iouThreshold) : 0,
      meanAveragePrecision: isSet(object.meanAveragePrecision) ? globalThis.Number(object.meanAveragePrecision) : 0,
      confidenceMetricsEntries: globalThis.Array.isArray(object?.confidenceMetricsEntries)
        ? object.confidenceMetricsEntries.map((e: any) => BoundingBoxMetricsEntry_ConfidenceMetricsEntry.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BoundingBoxMetricsEntry): unknown {
    const obj: any = {};
    if (message.iouThreshold !== 0) {
      obj.iouThreshold = message.iouThreshold;
    }
    if (message.meanAveragePrecision !== 0) {
      obj.meanAveragePrecision = message.meanAveragePrecision;
    }
    if (message.confidenceMetricsEntries?.length) {
      obj.confidenceMetricsEntries = message.confidenceMetricsEntries.map((e) =>
        BoundingBoxMetricsEntry_ConfidenceMetricsEntry.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<BoundingBoxMetricsEntry>): BoundingBoxMetricsEntry {
    return BoundingBoxMetricsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BoundingBoxMetricsEntry>): BoundingBoxMetricsEntry {
    const message = createBaseBoundingBoxMetricsEntry();
    message.iouThreshold = object.iouThreshold ?? 0;
    message.meanAveragePrecision = object.meanAveragePrecision ?? 0;
    message.confidenceMetricsEntries =
      object.confidenceMetricsEntries?.map((e) => BoundingBoxMetricsEntry_ConfidenceMetricsEntry.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBoundingBoxMetricsEntry_ConfidenceMetricsEntry(): BoundingBoxMetricsEntry_ConfidenceMetricsEntry {
  return { confidenceThreshold: 0, recall: 0, precision: 0, f1Score: 0 };
}

export const BoundingBoxMetricsEntry_ConfidenceMetricsEntry: MessageFns<
  BoundingBoxMetricsEntry_ConfidenceMetricsEntry
> = {
  encode(
    message: BoundingBoxMetricsEntry_ConfidenceMetricsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.confidenceThreshold !== 0) {
      writer.uint32(13).float(message.confidenceThreshold);
    }
    if (message.recall !== 0) {
      writer.uint32(21).float(message.recall);
    }
    if (message.precision !== 0) {
      writer.uint32(29).float(message.precision);
    }
    if (message.f1Score !== 0) {
      writer.uint32(37).float(message.f1Score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BoundingBoxMetricsEntry_ConfidenceMetricsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBoundingBoxMetricsEntry_ConfidenceMetricsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.confidenceThreshold = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.recall = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.precision = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.f1Score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BoundingBoxMetricsEntry_ConfidenceMetricsEntry {
    return {
      confidenceThreshold: isSet(object.confidenceThreshold) ? globalThis.Number(object.confidenceThreshold) : 0,
      recall: isSet(object.recall) ? globalThis.Number(object.recall) : 0,
      precision: isSet(object.precision) ? globalThis.Number(object.precision) : 0,
      f1Score: isSet(object.f1Score) ? globalThis.Number(object.f1Score) : 0,
    };
  },

  toJSON(message: BoundingBoxMetricsEntry_ConfidenceMetricsEntry): unknown {
    const obj: any = {};
    if (message.confidenceThreshold !== 0) {
      obj.confidenceThreshold = message.confidenceThreshold;
    }
    if (message.recall !== 0) {
      obj.recall = message.recall;
    }
    if (message.precision !== 0) {
      obj.precision = message.precision;
    }
    if (message.f1Score !== 0) {
      obj.f1Score = message.f1Score;
    }
    return obj;
  },

  create(
    base?: DeepPartial<BoundingBoxMetricsEntry_ConfidenceMetricsEntry>,
  ): BoundingBoxMetricsEntry_ConfidenceMetricsEntry {
    return BoundingBoxMetricsEntry_ConfidenceMetricsEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BoundingBoxMetricsEntry_ConfidenceMetricsEntry>,
  ): BoundingBoxMetricsEntry_ConfidenceMetricsEntry {
    const message = createBaseBoundingBoxMetricsEntry_ConfidenceMetricsEntry();
    message.confidenceThreshold = object.confidenceThreshold ?? 0;
    message.recall = object.recall ?? 0;
    message.precision = object.precision ?? 0;
    message.f1Score = object.f1Score ?? 0;
    return message;
  },
};

function createBaseImageObjectDetectionEvaluationMetrics(): ImageObjectDetectionEvaluationMetrics {
  return { evaluatedBoundingBoxCount: 0, boundingBoxMetricsEntries: [], boundingBoxMeanAveragePrecision: 0 };
}

export const ImageObjectDetectionEvaluationMetrics: MessageFns<ImageObjectDetectionEvaluationMetrics> = {
  encode(message: ImageObjectDetectionEvaluationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.evaluatedBoundingBoxCount !== 0) {
      writer.uint32(8).int32(message.evaluatedBoundingBoxCount);
    }
    for (const v of message.boundingBoxMetricsEntries) {
      BoundingBoxMetricsEntry.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.boundingBoxMeanAveragePrecision !== 0) {
      writer.uint32(29).float(message.boundingBoxMeanAveragePrecision);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImageObjectDetectionEvaluationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImageObjectDetectionEvaluationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.evaluatedBoundingBoxCount = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.boundingBoxMetricsEntries.push(BoundingBoxMetricsEntry.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.boundingBoxMeanAveragePrecision = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImageObjectDetectionEvaluationMetrics {
    return {
      evaluatedBoundingBoxCount: isSet(object.evaluatedBoundingBoxCount)
        ? globalThis.Number(object.evaluatedBoundingBoxCount)
        : 0,
      boundingBoxMetricsEntries: globalThis.Array.isArray(object?.boundingBoxMetricsEntries)
        ? object.boundingBoxMetricsEntries.map((e: any) => BoundingBoxMetricsEntry.fromJSON(e))
        : [],
      boundingBoxMeanAveragePrecision: isSet(object.boundingBoxMeanAveragePrecision)
        ? globalThis.Number(object.boundingBoxMeanAveragePrecision)
        : 0,
    };
  },

  toJSON(message: ImageObjectDetectionEvaluationMetrics): unknown {
    const obj: any = {};
    if (message.evaluatedBoundingBoxCount !== 0) {
      obj.evaluatedBoundingBoxCount = Math.round(message.evaluatedBoundingBoxCount);
    }
    if (message.boundingBoxMetricsEntries?.length) {
      obj.boundingBoxMetricsEntries = message.boundingBoxMetricsEntries.map((e) => BoundingBoxMetricsEntry.toJSON(e));
    }
    if (message.boundingBoxMeanAveragePrecision !== 0) {
      obj.boundingBoxMeanAveragePrecision = message.boundingBoxMeanAveragePrecision;
    }
    return obj;
  },

  create(base?: DeepPartial<ImageObjectDetectionEvaluationMetrics>): ImageObjectDetectionEvaluationMetrics {
    return ImageObjectDetectionEvaluationMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImageObjectDetectionEvaluationMetrics>): ImageObjectDetectionEvaluationMetrics {
    const message = createBaseImageObjectDetectionEvaluationMetrics();
    message.evaluatedBoundingBoxCount = object.evaluatedBoundingBoxCount ?? 0;
    message.boundingBoxMetricsEntries =
      object.boundingBoxMetricsEntries?.map((e) => BoundingBoxMetricsEntry.fromPartial(e)) || [];
    message.boundingBoxMeanAveragePrecision = object.boundingBoxMeanAveragePrecision ?? 0;
    return message;
  },
};

function createBaseVideoObjectTrackingEvaluationMetrics(): VideoObjectTrackingEvaluationMetrics {
  return {
    evaluatedFrameCount: 0,
    evaluatedBoundingBoxCount: 0,
    boundingBoxMetricsEntries: [],
    boundingBoxMeanAveragePrecision: 0,
  };
}

export const VideoObjectTrackingEvaluationMetrics: MessageFns<VideoObjectTrackingEvaluationMetrics> = {
  encode(message: VideoObjectTrackingEvaluationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.evaluatedFrameCount !== 0) {
      writer.uint32(8).int32(message.evaluatedFrameCount);
    }
    if (message.evaluatedBoundingBoxCount !== 0) {
      writer.uint32(16).int32(message.evaluatedBoundingBoxCount);
    }
    for (const v of message.boundingBoxMetricsEntries) {
      BoundingBoxMetricsEntry.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.boundingBoxMeanAveragePrecision !== 0) {
      writer.uint32(53).float(message.boundingBoxMeanAveragePrecision);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VideoObjectTrackingEvaluationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVideoObjectTrackingEvaluationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.evaluatedFrameCount = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.evaluatedBoundingBoxCount = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.boundingBoxMetricsEntries.push(BoundingBoxMetricsEntry.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 53) {
            break;
          }

          message.boundingBoxMeanAveragePrecision = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VideoObjectTrackingEvaluationMetrics {
    return {
      evaluatedFrameCount: isSet(object.evaluatedFrameCount) ? globalThis.Number(object.evaluatedFrameCount) : 0,
      evaluatedBoundingBoxCount: isSet(object.evaluatedBoundingBoxCount)
        ? globalThis.Number(object.evaluatedBoundingBoxCount)
        : 0,
      boundingBoxMetricsEntries: globalThis.Array.isArray(object?.boundingBoxMetricsEntries)
        ? object.boundingBoxMetricsEntries.map((e: any) => BoundingBoxMetricsEntry.fromJSON(e))
        : [],
      boundingBoxMeanAveragePrecision: isSet(object.boundingBoxMeanAveragePrecision)
        ? globalThis.Number(object.boundingBoxMeanAveragePrecision)
        : 0,
    };
  },

  toJSON(message: VideoObjectTrackingEvaluationMetrics): unknown {
    const obj: any = {};
    if (message.evaluatedFrameCount !== 0) {
      obj.evaluatedFrameCount = Math.round(message.evaluatedFrameCount);
    }
    if (message.evaluatedBoundingBoxCount !== 0) {
      obj.evaluatedBoundingBoxCount = Math.round(message.evaluatedBoundingBoxCount);
    }
    if (message.boundingBoxMetricsEntries?.length) {
      obj.boundingBoxMetricsEntries = message.boundingBoxMetricsEntries.map((e) => BoundingBoxMetricsEntry.toJSON(e));
    }
    if (message.boundingBoxMeanAveragePrecision !== 0) {
      obj.boundingBoxMeanAveragePrecision = message.boundingBoxMeanAveragePrecision;
    }
    return obj;
  },

  create(base?: DeepPartial<VideoObjectTrackingEvaluationMetrics>): VideoObjectTrackingEvaluationMetrics {
    return VideoObjectTrackingEvaluationMetrics.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VideoObjectTrackingEvaluationMetrics>): VideoObjectTrackingEvaluationMetrics {
    const message = createBaseVideoObjectTrackingEvaluationMetrics();
    message.evaluatedFrameCount = object.evaluatedFrameCount ?? 0;
    message.evaluatedBoundingBoxCount = object.evaluatedBoundingBoxCount ?? 0;
    message.boundingBoxMetricsEntries =
      object.boundingBoxMetricsEntries?.map((e) => BoundingBoxMetricsEntry.fromPartial(e)) || [];
    message.boundingBoxMeanAveragePrecision = object.boundingBoxMeanAveragePrecision ?? 0;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
