// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/automl/v1beta1/model.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { ImageClassificationModelMetadata, ImageObjectDetectionModelMetadata } from "./image.js";
import { TablesModelMetadata } from "./tables.js";
import { TextClassificationModelMetadata, TextExtractionModelMetadata, TextSentimentModelMetadata } from "./text.js";
import { TranslationModelMetadata } from "./translation.js";
import { VideoClassificationModelMetadata, VideoObjectTrackingModelMetadata } from "./video.js";

export const protobufPackage = "google.cloud.automl.v1beta1";

/** API proto representing a trained machine learning model. */
export interface Model {
  /** Metadata for translation models. */
  translationModelMetadata?:
    | TranslationModelMetadata
    | undefined;
  /** Metadata for image classification models. */
  imageClassificationModelMetadata?:
    | ImageClassificationModelMetadata
    | undefined;
  /** Metadata for text classification models. */
  textClassificationModelMetadata?:
    | TextClassificationModelMetadata
    | undefined;
  /** Metadata for image object detection models. */
  imageObjectDetectionModelMetadata?:
    | ImageObjectDetectionModelMetadata
    | undefined;
  /** Metadata for video classification models. */
  videoClassificationModelMetadata?:
    | VideoClassificationModelMetadata
    | undefined;
  /** Metadata for video object tracking models. */
  videoObjectTrackingModelMetadata?:
    | VideoObjectTrackingModelMetadata
    | undefined;
  /** Metadata for text extraction models. */
  textExtractionModelMetadata?:
    | TextExtractionModelMetadata
    | undefined;
  /** Metadata for Tables models. */
  tablesModelMetadata?:
    | TablesModelMetadata
    | undefined;
  /** Metadata for text sentiment models. */
  textSentimentModelMetadata?:
    | TextSentimentModelMetadata
    | undefined;
  /**
   * Output only. Resource name of the model.
   * Format: `projects/{project_id}/locations/{location_id}/models/{model_id}`
   */
  name: string;
  /**
   * Required. The name of the model to show in the interface. The name can be
   * up to 32 characters long and can consist only of ASCII Latin letters A-Z
   * and a-z, underscores
   * (_), and ASCII digits 0-9. It must start with a letter.
   */
  displayName: string;
  /**
   * Required. The resource ID of the dataset used to create the model. The dataset must
   * come from the same ancestor project and location.
   */
  datasetId: string;
  /** Output only. Timestamp when the model training finished  and can be used for prediction. */
  createTime:
    | Date
    | undefined;
  /** Output only. Timestamp when this model was last updated. */
  updateTime:
    | Date
    | undefined;
  /**
   * Output only. Deployment state of the model. A model can only serve
   * prediction requests after it gets deployed.
   */
  deploymentState: Model_DeploymentState;
}

/** Deployment state of the model. */
export enum Model_DeploymentState {
  /** DEPLOYMENT_STATE_UNSPECIFIED - Should not be used, an un-set enum has this value by default. */
  DEPLOYMENT_STATE_UNSPECIFIED = 0,
  /** DEPLOYED - Model is deployed. */
  DEPLOYED = 1,
  /** UNDEPLOYED - Model is not deployed. */
  UNDEPLOYED = 2,
  UNRECOGNIZED = -1,
}

export function model_DeploymentStateFromJSON(object: any): Model_DeploymentState {
  switch (object) {
    case 0:
    case "DEPLOYMENT_STATE_UNSPECIFIED":
      return Model_DeploymentState.DEPLOYMENT_STATE_UNSPECIFIED;
    case 1:
    case "DEPLOYED":
      return Model_DeploymentState.DEPLOYED;
    case 2:
    case "UNDEPLOYED":
      return Model_DeploymentState.UNDEPLOYED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Model_DeploymentState.UNRECOGNIZED;
  }
}

export function model_DeploymentStateToJSON(object: Model_DeploymentState): string {
  switch (object) {
    case Model_DeploymentState.DEPLOYMENT_STATE_UNSPECIFIED:
      return "DEPLOYMENT_STATE_UNSPECIFIED";
    case Model_DeploymentState.DEPLOYED:
      return "DEPLOYED";
    case Model_DeploymentState.UNDEPLOYED:
      return "UNDEPLOYED";
    case Model_DeploymentState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseModel(): Model {
  return {
    translationModelMetadata: undefined,
    imageClassificationModelMetadata: undefined,
    textClassificationModelMetadata: undefined,
    imageObjectDetectionModelMetadata: undefined,
    videoClassificationModelMetadata: undefined,
    videoObjectTrackingModelMetadata: undefined,
    textExtractionModelMetadata: undefined,
    tablesModelMetadata: undefined,
    textSentimentModelMetadata: undefined,
    name: "",
    displayName: "",
    datasetId: "",
    createTime: undefined,
    updateTime: undefined,
    deploymentState: 0,
  };
}

export const Model: MessageFns<Model> = {
  encode(message: Model, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.translationModelMetadata !== undefined) {
      TranslationModelMetadata.encode(message.translationModelMetadata, writer.uint32(122).fork()).join();
    }
    if (message.imageClassificationModelMetadata !== undefined) {
      ImageClassificationModelMetadata.encode(message.imageClassificationModelMetadata, writer.uint32(106).fork())
        .join();
    }
    if (message.textClassificationModelMetadata !== undefined) {
      TextClassificationModelMetadata.encode(message.textClassificationModelMetadata, writer.uint32(114).fork()).join();
    }
    if (message.imageObjectDetectionModelMetadata !== undefined) {
      ImageObjectDetectionModelMetadata.encode(message.imageObjectDetectionModelMetadata, writer.uint32(162).fork())
        .join();
    }
    if (message.videoClassificationModelMetadata !== undefined) {
      VideoClassificationModelMetadata.encode(message.videoClassificationModelMetadata, writer.uint32(186).fork())
        .join();
    }
    if (message.videoObjectTrackingModelMetadata !== undefined) {
      VideoObjectTrackingModelMetadata.encode(message.videoObjectTrackingModelMetadata, writer.uint32(170).fork())
        .join();
    }
    if (message.textExtractionModelMetadata !== undefined) {
      TextExtractionModelMetadata.encode(message.textExtractionModelMetadata, writer.uint32(154).fork()).join();
    }
    if (message.tablesModelMetadata !== undefined) {
      TablesModelMetadata.encode(message.tablesModelMetadata, writer.uint32(194).fork()).join();
    }
    if (message.textSentimentModelMetadata !== undefined) {
      TextSentimentModelMetadata.encode(message.textSentimentModelMetadata, writer.uint32(178).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.datasetId !== "") {
      writer.uint32(26).string(message.datasetId);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(90).fork()).join();
    }
    if (message.deploymentState !== 0) {
      writer.uint32(64).int32(message.deploymentState);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 15:
          if (tag !== 122) {
            break;
          }

          message.translationModelMetadata = TranslationModelMetadata.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.imageClassificationModelMetadata = ImageClassificationModelMetadata.decode(reader, reader.uint32());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.textClassificationModelMetadata = TextClassificationModelMetadata.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.imageObjectDetectionModelMetadata = ImageObjectDetectionModelMetadata.decode(reader, reader.uint32());
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.videoClassificationModelMetadata = VideoClassificationModelMetadata.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.videoObjectTrackingModelMetadata = VideoObjectTrackingModelMetadata.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.textExtractionModelMetadata = TextExtractionModelMetadata.decode(reader, reader.uint32());
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.tablesModelMetadata = TablesModelMetadata.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.textSentimentModelMetadata = TextSentimentModelMetadata.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.deploymentState = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model {
    return {
      translationModelMetadata: isSet(object.translationModelMetadata)
        ? TranslationModelMetadata.fromJSON(object.translationModelMetadata)
        : undefined,
      imageClassificationModelMetadata: isSet(object.imageClassificationModelMetadata)
        ? ImageClassificationModelMetadata.fromJSON(object.imageClassificationModelMetadata)
        : undefined,
      textClassificationModelMetadata: isSet(object.textClassificationModelMetadata)
        ? TextClassificationModelMetadata.fromJSON(object.textClassificationModelMetadata)
        : undefined,
      imageObjectDetectionModelMetadata: isSet(object.imageObjectDetectionModelMetadata)
        ? ImageObjectDetectionModelMetadata.fromJSON(object.imageObjectDetectionModelMetadata)
        : undefined,
      videoClassificationModelMetadata: isSet(object.videoClassificationModelMetadata)
        ? VideoClassificationModelMetadata.fromJSON(object.videoClassificationModelMetadata)
        : undefined,
      videoObjectTrackingModelMetadata: isSet(object.videoObjectTrackingModelMetadata)
        ? VideoObjectTrackingModelMetadata.fromJSON(object.videoObjectTrackingModelMetadata)
        : undefined,
      textExtractionModelMetadata: isSet(object.textExtractionModelMetadata)
        ? TextExtractionModelMetadata.fromJSON(object.textExtractionModelMetadata)
        : undefined,
      tablesModelMetadata: isSet(object.tablesModelMetadata)
        ? TablesModelMetadata.fromJSON(object.tablesModelMetadata)
        : undefined,
      textSentimentModelMetadata: isSet(object.textSentimentModelMetadata)
        ? TextSentimentModelMetadata.fromJSON(object.textSentimentModelMetadata)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      deploymentState: isSet(object.deploymentState) ? model_DeploymentStateFromJSON(object.deploymentState) : 0,
    };
  },

  toJSON(message: Model): unknown {
    const obj: any = {};
    if (message.translationModelMetadata !== undefined) {
      obj.translationModelMetadata = TranslationModelMetadata.toJSON(message.translationModelMetadata);
    }
    if (message.imageClassificationModelMetadata !== undefined) {
      obj.imageClassificationModelMetadata = ImageClassificationModelMetadata.toJSON(
        message.imageClassificationModelMetadata,
      );
    }
    if (message.textClassificationModelMetadata !== undefined) {
      obj.textClassificationModelMetadata = TextClassificationModelMetadata.toJSON(
        message.textClassificationModelMetadata,
      );
    }
    if (message.imageObjectDetectionModelMetadata !== undefined) {
      obj.imageObjectDetectionModelMetadata = ImageObjectDetectionModelMetadata.toJSON(
        message.imageObjectDetectionModelMetadata,
      );
    }
    if (message.videoClassificationModelMetadata !== undefined) {
      obj.videoClassificationModelMetadata = VideoClassificationModelMetadata.toJSON(
        message.videoClassificationModelMetadata,
      );
    }
    if (message.videoObjectTrackingModelMetadata !== undefined) {
      obj.videoObjectTrackingModelMetadata = VideoObjectTrackingModelMetadata.toJSON(
        message.videoObjectTrackingModelMetadata,
      );
    }
    if (message.textExtractionModelMetadata !== undefined) {
      obj.textExtractionModelMetadata = TextExtractionModelMetadata.toJSON(message.textExtractionModelMetadata);
    }
    if (message.tablesModelMetadata !== undefined) {
      obj.tablesModelMetadata = TablesModelMetadata.toJSON(message.tablesModelMetadata);
    }
    if (message.textSentimentModelMetadata !== undefined) {
      obj.textSentimentModelMetadata = TextSentimentModelMetadata.toJSON(message.textSentimentModelMetadata);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.deploymentState !== 0) {
      obj.deploymentState = model_DeploymentStateToJSON(message.deploymentState);
    }
    return obj;
  },

  create(base?: DeepPartial<Model>): Model {
    return Model.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Model>): Model {
    const message = createBaseModel();
    message.translationModelMetadata =
      (object.translationModelMetadata !== undefined && object.translationModelMetadata !== null)
        ? TranslationModelMetadata.fromPartial(object.translationModelMetadata)
        : undefined;
    message.imageClassificationModelMetadata =
      (object.imageClassificationModelMetadata !== undefined && object.imageClassificationModelMetadata !== null)
        ? ImageClassificationModelMetadata.fromPartial(object.imageClassificationModelMetadata)
        : undefined;
    message.textClassificationModelMetadata =
      (object.textClassificationModelMetadata !== undefined && object.textClassificationModelMetadata !== null)
        ? TextClassificationModelMetadata.fromPartial(object.textClassificationModelMetadata)
        : undefined;
    message.imageObjectDetectionModelMetadata =
      (object.imageObjectDetectionModelMetadata !== undefined && object.imageObjectDetectionModelMetadata !== null)
        ? ImageObjectDetectionModelMetadata.fromPartial(object.imageObjectDetectionModelMetadata)
        : undefined;
    message.videoClassificationModelMetadata =
      (object.videoClassificationModelMetadata !== undefined && object.videoClassificationModelMetadata !== null)
        ? VideoClassificationModelMetadata.fromPartial(object.videoClassificationModelMetadata)
        : undefined;
    message.videoObjectTrackingModelMetadata =
      (object.videoObjectTrackingModelMetadata !== undefined && object.videoObjectTrackingModelMetadata !== null)
        ? VideoObjectTrackingModelMetadata.fromPartial(object.videoObjectTrackingModelMetadata)
        : undefined;
    message.textExtractionModelMetadata =
      (object.textExtractionModelMetadata !== undefined && object.textExtractionModelMetadata !== null)
        ? TextExtractionModelMetadata.fromPartial(object.textExtractionModelMetadata)
        : undefined;
    message.tablesModelMetadata = (object.tablesModelMetadata !== undefined && object.tablesModelMetadata !== null)
      ? TablesModelMetadata.fromPartial(object.tablesModelMetadata)
      : undefined;
    message.textSentimentModelMetadata =
      (object.textSentimentModelMetadata !== undefined && object.textSentimentModelMetadata !== null)
        ? TextSentimentModelMetadata.fromPartial(object.textSentimentModelMetadata)
        : undefined;
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.datasetId = object.datasetId ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.deploymentState = object.deploymentState ?? 0;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
