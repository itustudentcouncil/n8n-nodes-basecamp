// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/netapp/v1/backup.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.netapp.v1";

/** A NetApp Backup. */
export interface Backup {
  /**
   * Identifier. The resource name of the backup.
   * Format:
   * `projects/{project_id}/locations/{location}/backupVaults/{backup_vault_id}/backups/{backup_id}`.
   */
  name: string;
  /** Output only. The backup state. */
  state: Backup_State;
  /**
   * A description of the backup with 2048 characters or less.
   * Requests with longer descriptions will be rejected.
   */
  description: string;
  /**
   * Output only. Size of the file system when the backup was created. When
   * creating a new volume from the backup, the volume capacity will have to be
   * at least as big.
   */
  volumeUsageBytes: Long;
  /**
   * Output only. Type of backup, manually created or created by a backup
   * policy.
   */
  backupType: Backup_Type;
  /**
   * Volume full name of this backup belongs to.
   * Format:
   * `projects/{projects_id}/locations/{location}/volumes/{volume_id}`
   */
  sourceVolume: string;
  /**
   * If specified, backup will be created from the given snapshot.
   * If not specified, there will be a new snapshot taken to initiate the backup
   * creation. Format:
   * `projects/{project_id}/locations/{location}/volumes/{volume_id}/snapshots/{snapshot_id}`
   */
  sourceSnapshot?:
    | string
    | undefined;
  /** Output only. The time when the backup was created. */
  createTime:
    | Date
    | undefined;
  /** Resource labels to represent user provided metadata. */
  labels: { [key: string]: string };
  /**
   * Output only. Total size of all backups in a chain in bytes = baseline
   * backup size + sum(incremental backup size)
   */
  chainStorageBytes: Long;
}

/** The Backup States */
export enum Backup_State {
  /** STATE_UNSPECIFIED - State not set. */
  STATE_UNSPECIFIED = 0,
  /**
   * CREATING - Backup is being created. While in this state, the snapshot for the backup
   * point-in-time may not have been created yet, and so the point-in-time may
   * not have been fixed.
   */
  CREATING = 1,
  /**
   * UPLOADING - Backup is being uploaded. While in this state, none of the writes to the
   * volume will be included in the backup.
   */
  UPLOADING = 2,
  /** READY - Backup is available for use. */
  READY = 3,
  /** DELETING - Backup is being deleted. */
  DELETING = 4,
  /**
   * ERROR - Backup is not valid and cannot be used for creating new volumes or
   * restoring existing volumes.
   */
  ERROR = 5,
  /** UPDATING - Backup is being updated. */
  UPDATING = 6,
  UNRECOGNIZED = -1,
}

export function backup_StateFromJSON(object: any): Backup_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Backup_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Backup_State.CREATING;
    case 2:
    case "UPLOADING":
      return Backup_State.UPLOADING;
    case 3:
    case "READY":
      return Backup_State.READY;
    case 4:
    case "DELETING":
      return Backup_State.DELETING;
    case 5:
    case "ERROR":
      return Backup_State.ERROR;
    case 6:
    case "UPDATING":
      return Backup_State.UPDATING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Backup_State.UNRECOGNIZED;
  }
}

export function backup_StateToJSON(object: Backup_State): string {
  switch (object) {
    case Backup_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Backup_State.CREATING:
      return "CREATING";
    case Backup_State.UPLOADING:
      return "UPLOADING";
    case Backup_State.READY:
      return "READY";
    case Backup_State.DELETING:
      return "DELETING";
    case Backup_State.ERROR:
      return "ERROR";
    case Backup_State.UPDATING:
      return "UPDATING";
    case Backup_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Backup types. */
export enum Backup_Type {
  /** TYPE_UNSPECIFIED - Unspecified backup type. */
  TYPE_UNSPECIFIED = 0,
  /** MANUAL - Manual backup type. */
  MANUAL = 1,
  /** SCHEDULED - Scheduled backup type. */
  SCHEDULED = 2,
  UNRECOGNIZED = -1,
}

export function backup_TypeFromJSON(object: any): Backup_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Backup_Type.TYPE_UNSPECIFIED;
    case 1:
    case "MANUAL":
      return Backup_Type.MANUAL;
    case 2:
    case "SCHEDULED":
      return Backup_Type.SCHEDULED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Backup_Type.UNRECOGNIZED;
  }
}

export function backup_TypeToJSON(object: Backup_Type): string {
  switch (object) {
    case Backup_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Backup_Type.MANUAL:
      return "MANUAL";
    case Backup_Type.SCHEDULED:
      return "SCHEDULED";
    case Backup_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Backup_LabelsEntry {
  key: string;
  value: string;
}

/** ListBackupsRequest lists backups. */
export interface ListBackupsRequest {
  /**
   * Required. The backupVault for which to retrieve backup information,
   * in the format
   * `projects/{project_id}/locations/{location}/backupVaults/{backup_vault_id}`.
   * To retrieve backup information for all locations, use "-" for the
   * `{location}` value.
   * To retrieve backup information for all backupVaults, use "-" for the
   * `{backup_vault_id}` value.
   * To retrieve backup information for a volume, use "-" for the
   * `{backup_vault_id}` value and specify volume full name with the filter.
   */
  parent: string;
  /**
   * The maximum number of items to return. The service may return fewer
   * than this value. The maximum value
   * is 1000; values above 1000 will be coerced to 1000.
   */
  pageSize: number;
  /**
   * The next_page_token value to use if there are additional
   * results to retrieve for this list request.
   */
  pageToken: string;
  /** Sort results. Supported values are "name", "name desc" or "" (unsorted). */
  orderBy: string;
  /**
   * The standard list filter.
   * If specified, backups will be returned based on the attribute name that
   * matches the filter expression. If empty, then no backups are filtered out.
   * See https://google.aip.dev/160
   */
  filter: string;
}

/** ListBackupsResponse is the result of ListBackupsRequest. */
export interface ListBackupsResponse {
  /** A list of backups in the project. */
  backups: Backup[];
  /**
   * The token you can use to retrieve the next page of results. Not returned
   * if there are no more results in the list.
   */
  nextPageToken: string;
  /** Locations that could not be reached. */
  unreachable: string[];
}

/** GetBackupRequest gets the state of a backup. */
export interface GetBackupRequest {
  /**
   * Required. The backup resource name, in the format
   * `projects/{project_id}/locations/{location}/backupVaults/{backup_vault_id}/backups/{backup_id}`
   */
  name: string;
}

/** CreateBackupRequest creates a backup. */
export interface CreateBackupRequest {
  /**
   * Required. The NetApp backupVault to create the backups of, in the format
   * `projects/* /locations/* /backupVaults/{backup_vault_id}`
   */
  parent: string;
  /**
   * Required. The ID to use for the backup.
   * The ID must be unique within the specified backupVault.
   * Must contain only letters, numbers, underscore and hyphen, with the first
   * character a letter or underscore, the last a letter or underscore or a
   * number, and a 63 character maximum.
   */
  backupId: string;
  /** Required. A backup resource */
  backup: Backup | undefined;
}

/** DeleteBackupRequest deletes a backup. */
export interface DeleteBackupRequest {
  /**
   * Required. The backup resource name, in the format
   * `projects/{project_id}/locations/{location}/backupVaults/{backup_vault_id}/backups/{backup_id}`
   */
  name: string;
}

/** UpdateBackupRequest updates description and/or labels for a backup. */
export interface UpdateBackupRequest {
  /**
   * Required. Field mask is used to specify the fields to be overwritten in the
   * Backup resource to be updated.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   */
  updateMask:
    | string[]
    | undefined;
  /** Required. The backup being updated */
  backup: Backup | undefined;
}

function createBaseBackup(): Backup {
  return {
    name: "",
    state: 0,
    description: "",
    volumeUsageBytes: Long.ZERO,
    backupType: 0,
    sourceVolume: "",
    sourceSnapshot: undefined,
    createTime: undefined,
    labels: {},
    chainStorageBytes: Long.ZERO,
  };
}

export const Backup: MessageFns<Backup> = {
  encode(message: Backup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (!message.volumeUsageBytes.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.volumeUsageBytes.toString());
    }
    if (message.backupType !== 0) {
      writer.uint32(40).int32(message.backupType);
    }
    if (message.sourceVolume !== "") {
      writer.uint32(50).string(message.sourceVolume);
    }
    if (message.sourceSnapshot !== undefined) {
      writer.uint32(58).string(message.sourceSnapshot);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(66).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Backup_LabelsEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    if (!message.chainStorageBytes.equals(Long.ZERO)) {
      writer.uint32(80).int64(message.chainStorageBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.volumeUsageBytes = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.backupType = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.sourceVolume = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.sourceSnapshot = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          const entry9 = Backup_LabelsEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.labels[entry9.key] = entry9.value;
          }
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.chainStorageBytes = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      state: isSet(object.state) ? backup_StateFromJSON(object.state) : 0,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      volumeUsageBytes: isSet(object.volumeUsageBytes) ? Long.fromValue(object.volumeUsageBytes) : Long.ZERO,
      backupType: isSet(object.backupType) ? backup_TypeFromJSON(object.backupType) : 0,
      sourceVolume: isSet(object.sourceVolume) ? globalThis.String(object.sourceVolume) : "",
      sourceSnapshot: isSet(object.sourceSnapshot) ? globalThis.String(object.sourceSnapshot) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      chainStorageBytes: isSet(object.chainStorageBytes) ? Long.fromValue(object.chainStorageBytes) : Long.ZERO,
    };
  },

  toJSON(message: Backup): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.state !== 0) {
      obj.state = backup_StateToJSON(message.state);
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (!message.volumeUsageBytes.equals(Long.ZERO)) {
      obj.volumeUsageBytes = (message.volumeUsageBytes || Long.ZERO).toString();
    }
    if (message.backupType !== 0) {
      obj.backupType = backup_TypeToJSON(message.backupType);
    }
    if (message.sourceVolume !== "") {
      obj.sourceVolume = message.sourceVolume;
    }
    if (message.sourceSnapshot !== undefined) {
      obj.sourceSnapshot = message.sourceSnapshot;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (!message.chainStorageBytes.equals(Long.ZERO)) {
      obj.chainStorageBytes = (message.chainStorageBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<Backup>): Backup {
    return Backup.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Backup>): Backup {
    const message = createBaseBackup();
    message.name = object.name ?? "";
    message.state = object.state ?? 0;
    message.description = object.description ?? "";
    message.volumeUsageBytes = (object.volumeUsageBytes !== undefined && object.volumeUsageBytes !== null)
      ? Long.fromValue(object.volumeUsageBytes)
      : Long.ZERO;
    message.backupType = object.backupType ?? 0;
    message.sourceVolume = object.sourceVolume ?? "";
    message.sourceSnapshot = object.sourceSnapshot ?? undefined;
    message.createTime = object.createTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.chainStorageBytes = (object.chainStorageBytes !== undefined && object.chainStorageBytes !== null)
      ? Long.fromValue(object.chainStorageBytes)
      : Long.ZERO;
    return message;
  },
};

function createBaseBackup_LabelsEntry(): Backup_LabelsEntry {
  return { key: "", value: "" };
}

export const Backup_LabelsEntry: MessageFns<Backup_LabelsEntry> = {
  encode(message: Backup_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Backup_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Backup_LabelsEntry>): Backup_LabelsEntry {
    return Backup_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Backup_LabelsEntry>): Backup_LabelsEntry {
    const message = createBaseBackup_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseListBackupsRequest(): ListBackupsRequest {
  return { parent: "", pageSize: 0, pageToken: "", orderBy: "", filter: "" };
}

export const ListBackupsRequest: MessageFns<ListBackupsRequest> = {
  encode(message: ListBackupsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(34).string(message.orderBy);
    }
    if (message.filter !== "") {
      writer.uint32(42).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListBackupsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    return ListBackupsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    const message = createBaseListBackupsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListBackupsResponse(): ListBackupsResponse {
  return { backups: [], nextPageToken: "", unreachable: [] };
}

export const ListBackupsResponse: MessageFns<ListBackupsResponse> = {
  encode(message: ListBackupsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.backups) {
      Backup.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backups.push(Backup.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsResponse {
    return {
      backups: globalThis.Array.isArray(object?.backups) ? object.backups.map((e: any) => Backup.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListBackupsResponse): unknown {
    const obj: any = {};
    if (message.backups?.length) {
      obj.backups = message.backups.map((e) => Backup.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    return ListBackupsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    const message = createBaseListBackupsResponse();
    message.backups = object.backups?.map((e) => Backup.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetBackupRequest(): GetBackupRequest {
  return { name: "" };
}

export const GetBackupRequest: MessageFns<GetBackupRequest> = {
  encode(message: GetBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBackupRequest>): GetBackupRequest {
    return GetBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBackupRequest>): GetBackupRequest {
    const message = createBaseGetBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateBackupRequest(): CreateBackupRequest {
  return { parent: "", backupId: "", backup: undefined };
}

export const CreateBackupRequest: MessageFns<CreateBackupRequest> = {
  encode(message: CreateBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.backupId !== "") {
      writer.uint32(18).string(message.backupId);
    }
    if (message.backup !== undefined) {
      Backup.encode(message.backup, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backupId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backup = Backup.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBackupRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      backupId: isSet(object.backupId) ? globalThis.String(object.backupId) : "",
      backup: isSet(object.backup) ? Backup.fromJSON(object.backup) : undefined,
    };
  },

  toJSON(message: CreateBackupRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.backupId !== "") {
      obj.backupId = message.backupId;
    }
    if (message.backup !== undefined) {
      obj.backup = Backup.toJSON(message.backup);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBackupRequest>): CreateBackupRequest {
    return CreateBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBackupRequest>): CreateBackupRequest {
    const message = createBaseCreateBackupRequest();
    message.parent = object.parent ?? "";
    message.backupId = object.backupId ?? "";
    message.backup = (object.backup !== undefined && object.backup !== null)
      ? Backup.fromPartial(object.backup)
      : undefined;
    return message;
  },
};

function createBaseDeleteBackupRequest(): DeleteBackupRequest {
  return { name: "" };
}

export const DeleteBackupRequest: MessageFns<DeleteBackupRequest> = {
  encode(message: DeleteBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    return DeleteBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    const message = createBaseDeleteBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateBackupRequest(): UpdateBackupRequest {
  return { updateMask: undefined, backup: undefined };
}

export const UpdateBackupRequest: MessageFns<UpdateBackupRequest> = {
  encode(message: UpdateBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(10).fork()).join();
    }
    if (message.backup !== undefined) {
      Backup.encode(message.backup, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backup = Backup.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateBackupRequest {
    return {
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      backup: isSet(object.backup) ? Backup.fromJSON(object.backup) : undefined,
    };
  },

  toJSON(message: UpdateBackupRequest): unknown {
    const obj: any = {};
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.backup !== undefined) {
      obj.backup = Backup.toJSON(message.backup);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateBackupRequest>): UpdateBackupRequest {
    return UpdateBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateBackupRequest>): UpdateBackupRequest {
    const message = createBaseUpdateBackupRequest();
    message.updateMask = object.updateMask ?? undefined;
    message.backup = (object.backup !== undefined && object.backup !== null)
      ? Backup.fromPartial(object.backup)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
