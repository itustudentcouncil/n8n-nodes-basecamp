// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/storage/v2/storage.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import {
  GetIamPolicyRequest,
  SetIamPolicyRequest,
  TestIamPermissionsRequest,
  TestIamPermissionsResponse,
} from "../../iam/v1/iam_policy.js";
import { Policy } from "../../iam/v1/policy.js";
import { Duration } from "../../protobuf/duration.js";
import { Empty } from "../../protobuf/empty.js";
import { FieldMask } from "../../protobuf/field_mask.js";
import { Timestamp } from "../../protobuf/timestamp.js";
import { DateMessage } from "../../type/date.js";

export const protobufPackage = "google.storage.v2";

/** Request message for DeleteBucket. */
export interface DeleteBucketRequest {
  /** Required. Name of a bucket to delete. */
  name: string;
  /** If set, only deletes the bucket if its metageneration matches this value. */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * If set, only deletes the bucket if its metageneration does not match this
   * value.
   */
  ifMetagenerationNotMatch?: Long | undefined;
}

/** Request message for GetBucket. */
export interface GetBucketRequest {
  /** Required. Name of a bucket. */
  name: string;
  /**
   * If set, and if the bucket's current metageneration does not match the
   * specified value, the request will return an error.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * If set, and if the bucket's current metageneration matches the specified
   * value, the request will return an error.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Mask specifying which fields to read.
   * A "*" field may be used to indicate all fields.
   * If no mask is specified, will default to all fields.
   */
  readMask?: string[] | undefined;
}

/** Request message for CreateBucket. */
export interface CreateBucketRequest {
  /** Required. The project to which this bucket will belong. */
  parent: string;
  /**
   * Properties of the new bucket being inserted.
   * The name of the bucket is specified in the `bucket_id` field. Populating
   * `bucket.name` field will result in an error.
   * The project of the bucket must be specified in the `bucket.project` field.
   * This field must be in `projects/{projectIdentifier}` format,
   * {projectIdentifier} can be the project ID or project number. The `parent`
   * field must be either empty or `projects/_`.
   */
  bucket:
    | Bucket
    | undefined;
  /**
   * Required. The ID to use for this bucket, which will become the final
   * component of the bucket's resource name. For example, the value `foo` might
   * result in a bucket with the name `projects/123456/buckets/foo`.
   */
  bucketId: string;
  /**
   * Apply a predefined set of access controls to this bucket.
   * Valid values are "authenticatedRead", "private", "projectPrivate",
   * "publicRead", or "publicReadWrite".
   */
  predefinedAcl: string;
  /**
   * Apply a predefined set of default object access controls to this bucket.
   * Valid values are "authenticatedRead", "bucketOwnerFullControl",
   * "bucketOwnerRead", "private", "projectPrivate", or "publicRead".
   */
  predefinedDefaultObjectAcl: string;
}

/** Request message for ListBuckets. */
export interface ListBucketsRequest {
  /** Required. The project whose buckets we are listing. */
  parent: string;
  /**
   * Maximum number of buckets to return in a single response. The service will
   * use this parameter or 1,000 items, whichever is smaller. If "acl" is
   * present in the read_mask, the service will use this parameter of 200 items,
   * whichever is smaller.
   */
  pageSize: number;
  /**
   * A previously-returned page token representing part of the larger set of
   * results to view.
   */
  pageToken: string;
  /** Filter results to buckets whose names begin with this prefix. */
  prefix: string;
  /**
   * Mask specifying which fields to read from each result.
   * If no mask is specified, will default to all fields except items.owner,
   * items.acl, and items.default_object_acl.
   * * may be used to mean "all fields".
   */
  readMask?: string[] | undefined;
}

/** The result of a call to Buckets.ListBuckets */
export interface ListBucketsResponse {
  /** The list of items. */
  buckets: Bucket[];
  /**
   * The continuation token, used to page through large result sets. Provide
   * this value in a subsequent request to return the next page of results.
   */
  nextPageToken: string;
}

/** Request message for LockBucketRetentionPolicyRequest. */
export interface LockBucketRetentionPolicyRequest {
  /** Required. Name of a bucket. */
  bucket: string;
  /**
   * Required. Makes the operation conditional on whether bucket's current
   * metageneration matches the given value. Must be positive.
   */
  ifMetagenerationMatch: Long;
}

/** Request for UpdateBucket method. */
export interface UpdateBucketRequest {
  /**
   * Required. The bucket to update.
   * The bucket's `name` field will be used to identify the bucket.
   */
  bucket:
    | Bucket
    | undefined;
  /**
   * If set, will only modify the bucket if its metageneration matches this
   * value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * If set, will only modify the bucket if its metageneration does not match
   * this value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Apply a predefined set of access controls to this bucket.
   * Valid values are "authenticatedRead", "private", "projectPrivate",
   * "publicRead", or "publicReadWrite".
   */
  predefinedAcl: string;
  /**
   * Apply a predefined set of default object access controls to this bucket.
   * Valid values are "authenticatedRead", "bucketOwnerFullControl",
   * "bucketOwnerRead", "private", "projectPrivate", or "publicRead".
   */
  predefinedDefaultObjectAcl: string;
  /**
   * Required. List of fields to be updated.
   *
   * To specify ALL fields, equivalent to the JSON API's "update" function,
   * specify a single field with the value `*`. Note: not recommended. If a new
   * field is introduced at a later time, an older client updating with the `*`
   * may accidentally reset the new field's value.
   *
   * Not specifying any fields is an error.
   */
  updateMask: string[] | undefined;
}

/** Request message for ComposeObject. */
export interface ComposeObjectRequest {
  /** Required. Properties of the resulting object. */
  destination:
    | Object
    | undefined;
  /** The list of source objects that will be concatenated into a single object. */
  sourceObjects: ComposeObjectRequest_SourceObject[];
  /**
   * Apply a predefined set of access controls to the destination object.
   * Valid values are "authenticatedRead", "bucketOwnerFullControl",
   * "bucketOwnerRead", "private", "projectPrivate", or "publicRead".
   */
  destinationPredefinedAcl: string;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Resource name of the Cloud KMS key, of the form
   * `projects/my-project/locations/my-location/keyRings/my-kr/cryptoKeys/my-key`,
   * that will be used to encrypt the object. Overrides the object
   * metadata's `kms_key_name` value, if any.
   */
  kmsKey: string;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams:
    | CommonObjectRequestParams
    | undefined;
  /**
   * The checksums of the complete object. This will be validated against the
   * combined checksums of the component objects.
   */
  objectChecksums: ObjectChecksums | undefined;
}

/** Description of a source object for a composition request. */
export interface ComposeObjectRequest_SourceObject {
  /**
   * Required. The source object's name. All source objects must reside in the
   * same bucket.
   */
  name: string;
  /** The generation of this object to use as the source. */
  generation: Long;
  /** Conditions that must be met for this operation to execute. */
  objectPreconditions: ComposeObjectRequest_SourceObject_ObjectPreconditions | undefined;
}

/** Preconditions for a source object of a composition request. */
export interface ComposeObjectRequest_SourceObject_ObjectPreconditions {
  /**
   * Only perform the composition if the generation of the source object
   * that would be used matches this value.  If this value and a generation
   * are both specified, they must be the same value or the call will fail.
   */
  ifGenerationMatch?: Long | undefined;
}

/**
 * Message for deleting an object.
 * `bucket` and `object` **must** be set.
 */
export interface DeleteObjectRequest {
  /** Required. Name of the bucket in which the object resides. */
  bucket: string;
  /**
   * Required. The name of the finalized object to delete.
   * Note: If you want to delete an unfinalized resumable upload please use
   * `CancelResumableWrite`.
   */
  object: string;
  /**
   * If present, permanently deletes a specific revision of this object (as
   * opposed to the latest version, the default).
   */
  generation: Long;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live generation
   * does not match the given value. If no live object exists, the precondition
   * fails. Setting to 0 makes the operation succeed only if there is a live
   * version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams: CommonObjectRequestParams | undefined;
}

/**
 * Message for restoring an object.
 * `bucket`, `object`, and `generation` **must** be set.
 */
export interface RestoreObjectRequest {
  /** Required. Name of the bucket in which the object resides. */
  bucket: string;
  /** Required. The name of the object to restore. */
  object: string;
  /** Required. The specific revision of the object to restore. */
  generation: Long;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live generation
   * does not match the given value. If no live object exists, the precondition
   * fails. Setting to 0 makes the operation succeed only if there is a live
   * version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * If false or unset, the bucket's default object ACL will be used.
   * If true, copy the source object's access controls.
   * Return an error if bucket has UBLA enabled.
   */
  copySourceAcl?:
    | boolean
    | undefined;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams: CommonObjectRequestParams | undefined;
}

/**
 * Message for canceling an in-progress resumable upload.
 * `upload_id` **must** be set.
 */
export interface CancelResumableWriteRequest {
  /**
   * Required. The upload_id of the resumable upload to cancel. This should be
   * copied from the `upload_id` field of `StartResumableWriteResponse`.
   */
  uploadId: string;
}

/**
 * Empty response message for canceling an in-progress resumable upload, will be
 * extended as needed.
 */
export interface CancelResumableWriteResponse {
}

/** Request message for ReadObject. */
export interface ReadObjectRequest {
  /** Required. The name of the bucket containing the object to read. */
  bucket: string;
  /** Required. The name of the object to read. */
  object: string;
  /**
   * If present, selects a specific revision of this object (as opposed
   * to the latest version, the default).
   */
  generation: Long;
  /**
   * The offset for the first byte to return in the read, relative to the start
   * of the object.
   *
   * A negative `read_offset` value will be interpreted as the number of bytes
   * back from the end of the object to be returned. For example, if an object's
   * length is 15 bytes, a ReadObjectRequest with `read_offset` = -5 and
   * `read_limit` = 3 would return bytes 10 through 12 of the object. Requesting
   * a negative offset with magnitude larger than the size of the object will
   * return the entire object.
   */
  readOffset: Long;
  /**
   * The maximum number of `data` bytes the server is allowed to return in the
   * sum of all `Object` messages. A `read_limit` of zero indicates that there
   * is no limit, and a negative `read_limit` will cause an error.
   *
   * If the stream returns fewer bytes than allowed by the `read_limit` and no
   * error occurred, the stream includes all data from the `read_offset` to the
   * end of the resource.
   */
  readLimit: Long;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live generation
   * does not match the given value. If no live object exists, the precondition
   * fails. Setting to 0 makes the operation succeed only if there is a live
   * version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams:
    | CommonObjectRequestParams
    | undefined;
  /**
   * Mask specifying which fields to read.
   * The checksummed_data field and its children will always be present.
   * If no mask is specified, will default to all fields except metadata.owner
   * and metadata.acl.
   * * may be used to mean "all fields".
   */
  readMask?: string[] | undefined;
}

/** Request message for GetObject. */
export interface GetObjectRequest {
  /** Required. Name of the bucket in which the object resides. */
  bucket: string;
  /** Required. Name of the object. */
  object: string;
  /**
   * If present, selects a specific revision of this object (as opposed to the
   * latest version, the default).
   */
  generation: Long;
  /** If true, return the soft-deleted version of this object. */
  softDeleted?:
    | boolean
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live generation
   * does not match the given value. If no live object exists, the precondition
   * fails. Setting to 0 makes the operation succeed only if there is a live
   * version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams:
    | CommonObjectRequestParams
    | undefined;
  /**
   * Mask specifying which fields to read.
   * If no mask is specified, will default to all fields except metadata.acl and
   * metadata.owner.
   * * may be used to mean "all fields".
   */
  readMask?: string[] | undefined;
}

/** Response message for ReadObject. */
export interface ReadObjectResponse {
  /**
   * A portion of the data for the object. The service **may** leave `data`
   * empty for any given `ReadResponse`. This enables the service to inform the
   * client that the request is still live while it is running an operation to
   * generate more data.
   */
  checksummedData:
    | ChecksummedData
    | undefined;
  /**
   * The checksums of the complete object. If the object is downloaded in full,
   * the client should compute one of these checksums over the downloaded object
   * and compare it against the value provided here.
   */
  objectChecksums:
    | ObjectChecksums
    | undefined;
  /**
   * If read_offset and or read_limit was specified on the
   * ReadObjectRequest, ContentRange will be populated on the first
   * ReadObjectResponse message of the read stream.
   */
  contentRange:
    | ContentRange
    | undefined;
  /**
   * Metadata of the object whose media is being returned.
   * Only populated in the first response in the stream.
   */
  metadata: Object | undefined;
}

/** Describes an attempt to insert an object, possibly over multiple requests. */
export interface WriteObjectSpec {
  /** Required. Destination object, including its name and its metadata. */
  resource:
    | Object
    | undefined;
  /**
   * Apply a predefined set of access controls to this object.
   * Valid values are "authenticatedRead", "bucketOwnerFullControl",
   * "bucketOwnerRead", "private", "projectPrivate", or "publicRead".
   */
  predefinedAcl: string;
  /**
   * Makes the operation conditional on whether the object's current
   * generation matches the given value. Setting to 0 makes the operation
   * succeed only if there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live
   * generation does not match the given value. If no live object exists, the
   * precondition fails. Setting to 0 makes the operation succeed only if
   * there is a live version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * The expected final object size being uploaded.
   * If this value is set, closing the stream after writing fewer or more than
   * `object_size` bytes will result in an OUT_OF_RANGE error.
   *
   * This situation is considered a client error, and if such an error occurs
   * you must start the upload over from scratch, this time sending the correct
   * number of bytes.
   */
  objectSize?: Long | undefined;
}

/** Request message for WriteObject. */
export interface WriteObjectRequest {
  /**
   * For resumable uploads. This should be the `upload_id` returned from a
   * call to `StartResumableWriteResponse`.
   */
  uploadId?:
    | string
    | undefined;
  /**
   * For non-resumable uploads. Describes the overall upload, including the
   * destination bucket and object name, preconditions, etc.
   */
  writeObjectSpec?:
    | WriteObjectSpec
    | undefined;
  /**
   * Required. The offset from the beginning of the object at which the data
   * should be written.
   *
   * In the first `WriteObjectRequest` of a `WriteObject()` action, it
   * indicates the initial offset for the `Write()` call. The value **must** be
   * equal to the `persisted_size` that a call to `QueryWriteStatus()` would
   * return (0 if this is the first write to the object).
   *
   * On subsequent calls, this value **must** be no larger than the sum of the
   * first `write_offset` and the sizes of all `data` chunks sent previously on
   * this stream.
   *
   * An incorrect value will cause an error.
   */
  writeOffset: Long;
  /**
   * The data to insert. If a crc32c checksum is provided that doesn't match
   * the checksum computed by the service, the request will fail.
   */
  checksummedData?:
    | ChecksummedData
    | undefined;
  /**
   * Checksums for the complete object. If the checksums computed by the service
   * don't match the specified checksums the call will fail. May only be
   * provided in the first or last request (either with first_message, or
   * finish_write set).
   */
  objectChecksums:
    | ObjectChecksums
    | undefined;
  /**
   * If `true`, this indicates that the write is complete. Sending any
   * `WriteObjectRequest`s subsequent to one in which `finish_write` is `true`
   * will cause an error.
   * For a non-resumable write (where the upload_id was not set in the first
   * message), it is an error not to set this field in the final message of the
   * stream.
   */
  finishWrite: boolean;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams: CommonObjectRequestParams | undefined;
}

/** Response message for WriteObject. */
export interface WriteObjectResponse {
  /**
   * The total number of bytes that have been processed for the given object
   * from all `WriteObject` calls. Only set if the upload has not finalized.
   */
  persistedSize?:
    | Long
    | undefined;
  /**
   * A resource containing the metadata for the uploaded object. Only set if
   * the upload has finalized.
   */
  resource?: Object | undefined;
}

/** Request message for BidiWriteObject. */
export interface BidiWriteObjectRequest {
  /**
   * For resumable uploads. This should be the `upload_id` returned from a
   * call to `StartResumableWriteResponse`.
   */
  uploadId?:
    | string
    | undefined;
  /**
   * For non-resumable uploads. Describes the overall upload, including the
   * destination bucket and object name, preconditions, etc.
   */
  writeObjectSpec?:
    | WriteObjectSpec
    | undefined;
  /**
   * Required. The offset from the beginning of the object at which the data
   * should be written.
   *
   * In the first `WriteObjectRequest` of a `WriteObject()` action, it
   * indicates the initial offset for the `Write()` call. The value **must** be
   * equal to the `persisted_size` that a call to `QueryWriteStatus()` would
   * return (0 if this is the first write to the object).
   *
   * On subsequent calls, this value **must** be no larger than the sum of the
   * first `write_offset` and the sizes of all `data` chunks sent previously on
   * this stream.
   *
   * An invalid value will cause an error.
   */
  writeOffset: Long;
  /**
   * The data to insert. If a crc32c checksum is provided that doesn't match
   * the checksum computed by the service, the request will fail.
   */
  checksummedData?:
    | ChecksummedData
    | undefined;
  /**
   * Checksums for the complete object. If the checksums computed by the service
   * don't match the specified checksums the call will fail. May only be
   * provided in last request (with finish_write set).
   */
  objectChecksums:
    | ObjectChecksums
    | undefined;
  /**
   * For each BidiWriteObjectRequest where state_lookup is `true` or the client
   * closes the stream, the service will send a BidiWriteObjectResponse
   * containing the current persisted size. The persisted size sent in responses
   * covers all the bytes the server has persisted thus far and can be used to
   * decide what data is safe for the client to drop. Note that the object's
   * current size reported by the BidiWriteObjectResponse may lag behind the
   * number of bytes written by the client. This field is ignored if
   * `finish_write` is set to true.
   */
  stateLookup: boolean;
  /**
   * Persists data written on the stream, up to and including the current
   * message, to permanent storage. This option should be used sparingly as it
   * may reduce performance. Ongoing writes will periodically be persisted on
   * the server even when `flush` is not set. This field is ignored if
   * `finish_write` is set to true since there's no need to checkpoint or flush
   * if this message completes the write.
   */
  flush: boolean;
  /**
   * If `true`, this indicates that the write is complete. Sending any
   * `WriteObjectRequest`s subsequent to one in which `finish_write` is `true`
   * will cause an error.
   * For a non-resumable write (where the upload_id was not set in the first
   * message), it is an error not to set this field in the final message of the
   * stream.
   */
  finishWrite: boolean;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams: CommonObjectRequestParams | undefined;
}

/** Response message for BidiWriteObject. */
export interface BidiWriteObjectResponse {
  /**
   * The total number of bytes that have been processed for the given object
   * from all `WriteObject` calls. Only set if the upload has not finalized.
   */
  persistedSize?:
    | Long
    | undefined;
  /**
   * A resource containing the metadata for the uploaded object. Only set if
   * the upload has finalized.
   */
  resource?: Object | undefined;
}

/** Request message for ListObjects. */
export interface ListObjectsRequest {
  /** Required. Name of the bucket in which to look for objects. */
  parent: string;
  /**
   * Maximum number of `items` plus `prefixes` to return
   * in a single page of responses. As duplicate `prefixes` are
   * omitted, fewer total results may be returned than requested. The service
   * will use this parameter or 1,000 items, whichever is smaller.
   */
  pageSize: number;
  /**
   * A previously-returned page token representing part of the larger set of
   * results to view.
   */
  pageToken: string;
  /**
   * If set, returns results in a directory-like mode. `items` will contain
   * only objects whose names, aside from the `prefix`, do not
   * contain `delimiter`. Objects whose names, aside from the
   * `prefix`, contain `delimiter` will have their name,
   * truncated after the `delimiter`, returned in
   * `prefixes`. Duplicate `prefixes` are omitted.
   */
  delimiter: string;
  /**
   * If true, objects that end in exactly one instance of `delimiter`
   * will have their metadata included in `items` in addition to
   * `prefixes`.
   */
  includeTrailingDelimiter: boolean;
  /** Filter results to objects whose names begin with this prefix. */
  prefix: string;
  /**
   * If `true`, lists all versions of an object as distinct results.
   * For more information, see
   * [Object
   * Versioning](https://cloud.google.com/storage/docs/object-versioning).
   */
  versions: boolean;
  /**
   * Mask specifying which fields to read from each result.
   * If no mask is specified, will default to all fields except items.acl and
   * items.owner.
   * * may be used to mean "all fields".
   */
  readMask?:
    | string[]
    | undefined;
  /**
   * Optional. Filter results to objects whose names are lexicographically equal
   * to or after lexicographic_start. If lexicographic_end is also set, the
   * objects listed have names between lexicographic_start (inclusive) and
   * lexicographic_end (exclusive).
   */
  lexicographicStart: string;
  /**
   * Optional. Filter results to objects whose names are lexicographically
   * before lexicographic_end. If lexicographic_start is also set, the objects
   * listed have names between lexicographic_start (inclusive) and
   * lexicographic_end (exclusive).
   */
  lexicographicEnd: string;
  /**
   * Optional. If true, only list all soft-deleted versions of the object.
   * Soft delete policy is required to set this option.
   */
  softDeleted: boolean;
  /**
   * Optional. If true, will also include folders and managed folders (besides
   * objects) in the returned `prefixes`. Requires `delimiter` to be set to '/'.
   */
  includeFoldersAsPrefixes: boolean;
  /**
   * Optional. Filter results to objects and prefixes that match this glob
   * pattern. See [List Objects Using
   * Glob](https://cloud.google.com/storage/docs/json_api/v1/objects/list#list-objects-and-prefixes-using-glob)
   * for the full syntax.
   */
  matchGlob: string;
}

/** Request object for `QueryWriteStatus`. */
export interface QueryWriteStatusRequest {
  /**
   * Required. The name of the resume token for the object whose write status is
   * being requested.
   */
  uploadId: string;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams: CommonObjectRequestParams | undefined;
}

/** Response object for `QueryWriteStatus`. */
export interface QueryWriteStatusResponse {
  /**
   * The total number of bytes that have been processed for the given object
   * from all `WriteObject` calls. This is the correct value for the
   * 'write_offset' field to use when resuming the `WriteObject` operation.
   * Only set if the upload has not finalized.
   */
  persistedSize?:
    | Long
    | undefined;
  /**
   * A resource containing the metadata for the uploaded object. Only set if
   * the upload has finalized.
   */
  resource?: Object | undefined;
}

/**
 * Request message for RewriteObject.
 * If the source object is encrypted using a Customer-Supplied Encryption Key
 * the key information must be provided in the copy_source_encryption_algorithm,
 * copy_source_encryption_key_bytes, and copy_source_encryption_key_sha256_bytes
 * fields. If the destination object should be encrypted the keying information
 * should be provided in the encryption_algorithm, encryption_key_bytes, and
 * encryption_key_sha256_bytes fields of the
 * common_object_request_params.customer_encryption field.
 */
export interface RewriteObjectRequest {
  /**
   * Required. Immutable. The name of the destination object.
   * See the
   * [Naming Guidelines](https://cloud.google.com/storage/docs/objects#naming).
   * Example: `test.txt`
   * The `name` field by itself does not uniquely identify a Cloud Storage
   * object. A Cloud Storage object is uniquely identified by the tuple of
   * (bucket, object, generation).
   */
  destinationName: string;
  /**
   * Required. Immutable. The name of the bucket containing the destination
   * object.
   */
  destinationBucket: string;
  /**
   * The name of the Cloud KMS key that will be used to encrypt the destination
   * object. The Cloud KMS key must be located in same location as the object.
   * If the parameter is not specified, the request uses the destination
   * bucket's default encryption key, if any, or else the Google-managed
   * encryption key.
   */
  destinationKmsKey: string;
  /**
   * Properties of the destination, post-rewrite object.
   * The `name`, `bucket` and `kms_key` fields must not be populated (these
   * values are specified in the `destination_name`, `destination_bucket`, and
   * `destination_kms_key` fields).
   * If `destination` is present it will be used to construct the destination
   * object's metadata; otherwise the destination object's metadata will be
   * copied from the source object.
   */
  destination:
    | Object
    | undefined;
  /** Required. Name of the bucket in which to find the source object. */
  sourceBucket: string;
  /** Required. Name of the source object. */
  sourceObject: string;
  /**
   * If present, selects a specific revision of the source object (as opposed to
   * the latest version, the default).
   */
  sourceGeneration: Long;
  /**
   * Include this field (from the previous rewrite response) on each rewrite
   * request after the first one, until the rewrite response 'done' flag is
   * true. Calls that provide a rewriteToken can omit all other request fields,
   * but if included those fields must match the values provided in the first
   * rewrite request.
   */
  rewriteToken: string;
  /**
   * Apply a predefined set of access controls to the destination object.
   * Valid values are "authenticatedRead", "bucketOwnerFullControl",
   * "bucketOwnerRead", "private", "projectPrivate", or "publicRead".
   */
  destinationPredefinedAcl: string;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live generation
   * does not match the given value. If no live object exists, the precondition
   * fails. Setting to 0 makes the operation succeed only if there is a live
   * version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the destination object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the destination object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the source object's live
   * generation matches the given value.
   */
  ifSourceGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the source object's live
   * generation does not match the given value.
   */
  ifSourceGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the source object's current
   * metageneration matches the given value.
   */
  ifSourceMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the source object's current
   * metageneration does not match the given value.
   */
  ifSourceMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * The maximum number of bytes that will be rewritten per rewrite request.
   * Most callers
   * shouldn't need to specify this parameter - it is primarily in place to
   * support testing. If specified the value must be an integral multiple of
   * 1 MiB (1048576). Also, this only applies to requests where the source and
   * destination span locations and/or storage classes. Finally, this value must
   * not change across rewrite calls else you'll get an error that the
   * `rewriteToken` is invalid.
   */
  maxBytesRewrittenPerCall: Long;
  /**
   * The algorithm used to encrypt the source object, if any. Used if the source
   * object was encrypted with a Customer-Supplied Encryption Key.
   */
  copySourceEncryptionAlgorithm: string;
  /**
   * The raw bytes (not base64-encoded) AES-256 encryption key used to encrypt
   * the source object, if it was encrypted with a Customer-Supplied Encryption
   * Key.
   */
  copySourceEncryptionKeyBytes: Buffer;
  /**
   * The raw bytes (not base64-encoded) SHA256 hash of the encryption key used
   * to encrypt the source object, if it was encrypted with a Customer-Supplied
   * Encryption Key.
   */
  copySourceEncryptionKeySha256Bytes: Buffer;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams:
    | CommonObjectRequestParams
    | undefined;
  /**
   * The checksums of the complete object. This will be used to validate the
   * destination object after rewriting.
   */
  objectChecksums: ObjectChecksums | undefined;
}

/** A rewrite response. */
export interface RewriteResponse {
  /**
   * The total bytes written so far, which can be used to provide a waiting user
   * with a progress indicator. This property is always present in the response.
   */
  totalBytesRewritten: Long;
  /**
   * The total size of the object being copied in bytes. This property is always
   * present in the response.
   */
  objectSize: Long;
  /**
   * `true` if the copy is finished; otherwise, `false` if
   * the copy is in progress. This property is always present in the response.
   */
  done: boolean;
  /**
   * A token to use in subsequent requests to continue copying data. This token
   * is present in the response only when there is more data to copy.
   */
  rewriteToken: string;
  /**
   * A resource containing the metadata for the copied-to object. This property
   * is present in the response only when copying completes.
   */
  resource: Object | undefined;
}

/** Request message StartResumableWrite. */
export interface StartResumableWriteRequest {
  /**
   * Required. The destination bucket, object, and metadata, as well as any
   * preconditions.
   */
  writeObjectSpec:
    | WriteObjectSpec
    | undefined;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams:
    | CommonObjectRequestParams
    | undefined;
  /**
   * The checksums of the complete object. This will be used to validate the
   * uploaded object. For each upload, object_checksums can be provided with
   * either StartResumableWriteRequest or the WriteObjectRequest with
   * finish_write set to `true`.
   */
  objectChecksums: ObjectChecksums | undefined;
}

/** Response object for `StartResumableWrite`. */
export interface StartResumableWriteResponse {
  /**
   * The upload_id of the newly started resumable write operation. This
   * value should be copied into the `WriteObjectRequest.upload_id` field.
   */
  uploadId: string;
}

/** Request message for UpdateObject. */
export interface UpdateObjectRequest {
  /**
   * Required. The object to update.
   * The object's bucket and name fields are used to identify the object to
   * update. If present, the object's generation field selects a specific
   * revision of this object whose metadata should be updated. Otherwise,
   * assumes the live version of the object.
   */
  object:
    | Object
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current generation
   * matches the given value. Setting to 0 makes the operation succeed only if
   * there are no live versions of the object.
   */
  ifGenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's live generation
   * does not match the given value. If no live object exists, the precondition
   * fails. Setting to 0 makes the operation succeed only if there is a live
   * version of the object.
   */
  ifGenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration matches the given value.
   */
  ifMetagenerationMatch?:
    | Long
    | undefined;
  /**
   * Makes the operation conditional on whether the object's current
   * metageneration does not match the given value.
   */
  ifMetagenerationNotMatch?:
    | Long
    | undefined;
  /**
   * Apply a predefined set of access controls to this object.
   * Valid values are "authenticatedRead", "bucketOwnerFullControl",
   * "bucketOwnerRead", "private", "projectPrivate", or "publicRead".
   */
  predefinedAcl: string;
  /**
   * Required. List of fields to be updated.
   *
   * To specify ALL fields, equivalent to the JSON API's "update" function,
   * specify a single field with the value `*`. Note: not recommended. If a new
   * field is introduced at a later time, an older client updating with the `*`
   * may accidentally reset the new field's value.
   *
   * Not specifying any fields is an error.
   */
  updateMask:
    | string[]
    | undefined;
  /** A set of parameters common to Storage API requests concerning an object. */
  commonObjectRequestParams: CommonObjectRequestParams | undefined;
}

/** Request message for GetServiceAccount. */
export interface GetServiceAccountRequest {
  /**
   * Required. Project ID, in the format of "projects/{projectIdentifier}".
   * {projectIdentifier} can be the project ID or project number.
   */
  project: string;
}

/**
 * A service account, owned by Cloud Storage, which may be used when taking
 * action on behalf of a given project, for example to publish Pub/Sub
 * notifications or to retrieve security keys.
 */
export interface ServiceAccount {
  /** The ID of the notification. */
  emailAddress: string;
}

/** Request message for CreateHmacKey. */
export interface CreateHmacKeyRequest {
  /**
   * Required. The project that the HMAC-owning service account lives in, in the
   * format of "projects/{projectIdentifier}". {projectIdentifier} can be the
   * project ID or project number.
   */
  project: string;
  /** Required. The service account to create the HMAC for. */
  serviceAccountEmail: string;
}

/** Create hmac response.  The only time the secret for an HMAC will be returned. */
export interface CreateHmacKeyResponse {
  /** Key metadata. */
  metadata:
    | HmacKeyMetadata
    | undefined;
  /**
   * HMAC key secret material.
   * In raw bytes format (not base64-encoded).
   */
  secretKeyBytes: Buffer;
}

/** Request object to delete a given HMAC key. */
export interface DeleteHmacKeyRequest {
  /** Required. The identifying key for the HMAC to delete. */
  accessId: string;
  /**
   * Required. The project that owns the HMAC key, in the format of
   * "projects/{projectIdentifier}".
   * {projectIdentifier} can be the project ID or project number.
   */
  project: string;
}

/** Request object to get metadata on a given HMAC key. */
export interface GetHmacKeyRequest {
  /** Required. The identifying key for the HMAC to delete. */
  accessId: string;
  /**
   * Required. The project the HMAC key lies in, in the format of
   * "projects/{projectIdentifier}".
   * {projectIdentifier} can be the project ID or project number.
   */
  project: string;
}

/** Request to fetch a list of HMAC keys under a given project. */
export interface ListHmacKeysRequest {
  /**
   * Required. The project to list HMAC keys for, in the format of
   * "projects/{projectIdentifier}".
   * {projectIdentifier} can be the project ID or project number.
   */
  project: string;
  /** The maximum number of keys to return. */
  pageSize: number;
  /** A previously returned token from ListHmacKeysResponse to get the next page. */
  pageToken: string;
  /** If set, filters to only return HMAC keys for specified service account. */
  serviceAccountEmail: string;
  /** If set, return deleted keys that have not yet been wiped out. */
  showDeletedKeys: boolean;
}

/** Hmac key list response with next page information. */
export interface ListHmacKeysResponse {
  /** The list of items. */
  hmacKeys: HmacKeyMetadata[];
  /**
   * The continuation token, used to page through large result sets. Provide
   * this value in a subsequent request to return the next page of results.
   */
  nextPageToken: string;
}

/**
 * Request object to update an HMAC key state.
 * HmacKeyMetadata.state is required and the only writable field in
 * UpdateHmacKey operation. Specifying fields other than state will result in an
 * error.
 */
export interface UpdateHmacKeyRequest {
  /**
   * Required. The HMAC key to update.
   * If present, the hmac_key's `id` field will be used to identify the key.
   * Otherwise, the hmac_key's access_id and project fields will be used to
   * identify the key.
   */
  hmacKey:
    | HmacKeyMetadata
    | undefined;
  /**
   * Update mask for hmac_key.
   * Not specifying any fields will mean only the `state` field is updated to
   * the value specified in `hmac_key`.
   */
  updateMask: string[] | undefined;
}

/** Hmac Key Metadata, which includes all information other than the secret. */
export interface HmacKeyMetadata {
  /**
   * Immutable. Resource name ID of the key in the format
   * {projectIdentifier}/{accessId}.
   * {projectIdentifier} can be the project ID or project number.
   */
  id: string;
  /** Immutable. Globally unique id for keys. */
  accessId: string;
  /**
   * Immutable. Identifies the project that owns the service account of the
   * specified HMAC key, in the format "projects/{projectIdentifier}".
   * {projectIdentifier} can be the project ID or project number.
   */
  project: string;
  /** Output only. Email of the service account the key authenticates as. */
  serviceAccountEmail: string;
  /**
   * Optional. State of the key. One of ACTIVE, INACTIVE, or DELETED.
   * Writable, can be updated by UpdateHmacKey operation.
   */
  state: string;
  /** Output only. The creation time of the HMAC key. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last modification time of the HMAC key metadata. */
  updateTime:
    | Date
    | undefined;
  /** Optional. The etag of the HMAC key. */
  etag: string;
}

/** Parameters that can be passed to any object request. */
export interface CommonObjectRequestParams {
  /**
   * Encryption algorithm used with the Customer-Supplied Encryption Keys
   * feature.
   */
  encryptionAlgorithm: string;
  /**
   * Encryption key used with the Customer-Supplied Encryption Keys feature.
   * In raw bytes format (not base64-encoded).
   */
  encryptionKeyBytes: Buffer;
  /**
   * SHA256 hash of encryption key used with the Customer-Supplied Encryption
   * Keys feature.
   */
  encryptionKeySha256Bytes: Buffer;
}

/** Shared constants. */
export interface ServiceConstants {
}

/** A collection of constant values meaningful to the Storage API. */
export enum ServiceConstants_Values {
  /** VALUES_UNSPECIFIED - Unused. Proto3 requires first enum to be 0. */
  VALUES_UNSPECIFIED = 0,
  /**
   * MAX_READ_CHUNK_BYTES - The maximum size chunk that can will be returned in a single
   * ReadRequest.
   * 2 MiB.
   */
  MAX_READ_CHUNK_BYTES = 2097152,
  /**
   * MAX_WRITE_CHUNK_BYTES - The maximum size chunk that can be sent in a single WriteObjectRequest.
   * 2 MiB.
   */
  MAX_WRITE_CHUNK_BYTES = 2097152,
  /**
   * MAX_OBJECT_SIZE_MB - The maximum size of an object in MB - whether written in a single stream
   * or composed from multiple other objects.
   * 5 TiB.
   */
  MAX_OBJECT_SIZE_MB = 5242880,
  /**
   * MAX_CUSTOM_METADATA_FIELD_NAME_BYTES - The maximum length field name that can be sent in a single
   * custom metadata field.
   * 1 KiB.
   */
  MAX_CUSTOM_METADATA_FIELD_NAME_BYTES = 1024,
  /**
   * MAX_CUSTOM_METADATA_FIELD_VALUE_BYTES - The maximum length field value that can be sent in a single
   * custom_metadata field.
   * 4 KiB.
   */
  MAX_CUSTOM_METADATA_FIELD_VALUE_BYTES = 4096,
  /**
   * MAX_CUSTOM_METADATA_TOTAL_SIZE_BYTES - The maximum total bytes that can be populated into all field names and
   * values of the custom_metadata for one object.
   * 8 KiB.
   */
  MAX_CUSTOM_METADATA_TOTAL_SIZE_BYTES = 8192,
  /**
   * MAX_BUCKET_METADATA_TOTAL_SIZE_BYTES - The maximum total bytes that can be populated into all bucket metadata
   * fields.
   * 20 KiB.
   */
  MAX_BUCKET_METADATA_TOTAL_SIZE_BYTES = 20480,
  /**
   * MAX_NOTIFICATION_CONFIGS_PER_BUCKET - The maximum number of NotificationConfigs that can be registered
   * for a given bucket.
   */
  MAX_NOTIFICATION_CONFIGS_PER_BUCKET = 100,
  /**
   * MAX_LIFECYCLE_RULES_PER_BUCKET - The maximum number of LifecycleRules that can be registered for a given
   * bucket.
   */
  MAX_LIFECYCLE_RULES_PER_BUCKET = 100,
  /** MAX_NOTIFICATION_CUSTOM_ATTRIBUTES - The maximum number of custom attributes per NotificationConfigs. */
  MAX_NOTIFICATION_CUSTOM_ATTRIBUTES = 5,
  /**
   * MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_KEY_LENGTH - The maximum length of a custom attribute key included in
   * NotificationConfig.
   */
  MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_KEY_LENGTH = 256,
  /**
   * MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_VALUE_LENGTH - The maximum length of a custom attribute value included in a
   * NotificationConfig.
   */
  MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_VALUE_LENGTH = 1024,
  /** MAX_LABELS_ENTRIES_COUNT - The maximum number of key/value entries per bucket label. */
  MAX_LABELS_ENTRIES_COUNT = 64,
  /**
   * MAX_LABELS_KEY_VALUE_LENGTH - The maximum character length of the key or value in a bucket
   * label map.
   */
  MAX_LABELS_KEY_VALUE_LENGTH = 63,
  /**
   * MAX_LABELS_KEY_VALUE_BYTES - The maximum byte size of the key or value in a bucket label
   * map.
   */
  MAX_LABELS_KEY_VALUE_BYTES = 128,
  /**
   * MAX_OBJECT_IDS_PER_DELETE_OBJECTS_REQUEST - The maximum number of object IDs that can be included in a
   * DeleteObjectsRequest.
   */
  MAX_OBJECT_IDS_PER_DELETE_OBJECTS_REQUEST = 1000,
  /**
   * SPLIT_TOKEN_MAX_VALID_DAYS - The maximum number of days for which a token returned by the
   * GetListObjectsSplitPoints RPC is valid.
   */
  SPLIT_TOKEN_MAX_VALID_DAYS = 14,
  UNRECOGNIZED = -1,
}

export function serviceConstants_ValuesFromJSON(object: any): ServiceConstants_Values {
  switch (object) {
    case 0:
    case "VALUES_UNSPECIFIED":
      return ServiceConstants_Values.VALUES_UNSPECIFIED;
    case 2097152:
    case "MAX_READ_CHUNK_BYTES":
      return ServiceConstants_Values.MAX_READ_CHUNK_BYTES;
    case 2097152:
    case "MAX_WRITE_CHUNK_BYTES":
      return ServiceConstants_Values.MAX_WRITE_CHUNK_BYTES;
    case 5242880:
    case "MAX_OBJECT_SIZE_MB":
      return ServiceConstants_Values.MAX_OBJECT_SIZE_MB;
    case 1024:
    case "MAX_CUSTOM_METADATA_FIELD_NAME_BYTES":
      return ServiceConstants_Values.MAX_CUSTOM_METADATA_FIELD_NAME_BYTES;
    case 4096:
    case "MAX_CUSTOM_METADATA_FIELD_VALUE_BYTES":
      return ServiceConstants_Values.MAX_CUSTOM_METADATA_FIELD_VALUE_BYTES;
    case 8192:
    case "MAX_CUSTOM_METADATA_TOTAL_SIZE_BYTES":
      return ServiceConstants_Values.MAX_CUSTOM_METADATA_TOTAL_SIZE_BYTES;
    case 20480:
    case "MAX_BUCKET_METADATA_TOTAL_SIZE_BYTES":
      return ServiceConstants_Values.MAX_BUCKET_METADATA_TOTAL_SIZE_BYTES;
    case 100:
    case "MAX_NOTIFICATION_CONFIGS_PER_BUCKET":
      return ServiceConstants_Values.MAX_NOTIFICATION_CONFIGS_PER_BUCKET;
    case 100:
    case "MAX_LIFECYCLE_RULES_PER_BUCKET":
      return ServiceConstants_Values.MAX_LIFECYCLE_RULES_PER_BUCKET;
    case 5:
    case "MAX_NOTIFICATION_CUSTOM_ATTRIBUTES":
      return ServiceConstants_Values.MAX_NOTIFICATION_CUSTOM_ATTRIBUTES;
    case 256:
    case "MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_KEY_LENGTH":
      return ServiceConstants_Values.MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_KEY_LENGTH;
    case 1024:
    case "MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_VALUE_LENGTH":
      return ServiceConstants_Values.MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_VALUE_LENGTH;
    case 64:
    case "MAX_LABELS_ENTRIES_COUNT":
      return ServiceConstants_Values.MAX_LABELS_ENTRIES_COUNT;
    case 63:
    case "MAX_LABELS_KEY_VALUE_LENGTH":
      return ServiceConstants_Values.MAX_LABELS_KEY_VALUE_LENGTH;
    case 128:
    case "MAX_LABELS_KEY_VALUE_BYTES":
      return ServiceConstants_Values.MAX_LABELS_KEY_VALUE_BYTES;
    case 1000:
    case "MAX_OBJECT_IDS_PER_DELETE_OBJECTS_REQUEST":
      return ServiceConstants_Values.MAX_OBJECT_IDS_PER_DELETE_OBJECTS_REQUEST;
    case 14:
    case "SPLIT_TOKEN_MAX_VALID_DAYS":
      return ServiceConstants_Values.SPLIT_TOKEN_MAX_VALID_DAYS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConstants_Values.UNRECOGNIZED;
  }
}

export function serviceConstants_ValuesToJSON(object: ServiceConstants_Values): string {
  switch (object) {
    case ServiceConstants_Values.VALUES_UNSPECIFIED:
      return "VALUES_UNSPECIFIED";
    case ServiceConstants_Values.MAX_READ_CHUNK_BYTES:
      return "MAX_READ_CHUNK_BYTES";
    case ServiceConstants_Values.MAX_WRITE_CHUNK_BYTES:
      return "MAX_WRITE_CHUNK_BYTES";
    case ServiceConstants_Values.MAX_OBJECT_SIZE_MB:
      return "MAX_OBJECT_SIZE_MB";
    case ServiceConstants_Values.MAX_CUSTOM_METADATA_FIELD_NAME_BYTES:
      return "MAX_CUSTOM_METADATA_FIELD_NAME_BYTES";
    case ServiceConstants_Values.MAX_CUSTOM_METADATA_FIELD_VALUE_BYTES:
      return "MAX_CUSTOM_METADATA_FIELD_VALUE_BYTES";
    case ServiceConstants_Values.MAX_CUSTOM_METADATA_TOTAL_SIZE_BYTES:
      return "MAX_CUSTOM_METADATA_TOTAL_SIZE_BYTES";
    case ServiceConstants_Values.MAX_BUCKET_METADATA_TOTAL_SIZE_BYTES:
      return "MAX_BUCKET_METADATA_TOTAL_SIZE_BYTES";
    case ServiceConstants_Values.MAX_NOTIFICATION_CONFIGS_PER_BUCKET:
      return "MAX_NOTIFICATION_CONFIGS_PER_BUCKET";
    case ServiceConstants_Values.MAX_LIFECYCLE_RULES_PER_BUCKET:
      return "MAX_LIFECYCLE_RULES_PER_BUCKET";
    case ServiceConstants_Values.MAX_NOTIFICATION_CUSTOM_ATTRIBUTES:
      return "MAX_NOTIFICATION_CUSTOM_ATTRIBUTES";
    case ServiceConstants_Values.MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_KEY_LENGTH:
      return "MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_KEY_LENGTH";
    case ServiceConstants_Values.MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_VALUE_LENGTH:
      return "MAX_NOTIFICATION_CUSTOM_ATTRIBUTE_VALUE_LENGTH";
    case ServiceConstants_Values.MAX_LABELS_ENTRIES_COUNT:
      return "MAX_LABELS_ENTRIES_COUNT";
    case ServiceConstants_Values.MAX_LABELS_KEY_VALUE_LENGTH:
      return "MAX_LABELS_KEY_VALUE_LENGTH";
    case ServiceConstants_Values.MAX_LABELS_KEY_VALUE_BYTES:
      return "MAX_LABELS_KEY_VALUE_BYTES";
    case ServiceConstants_Values.MAX_OBJECT_IDS_PER_DELETE_OBJECTS_REQUEST:
      return "MAX_OBJECT_IDS_PER_DELETE_OBJECTS_REQUEST";
    case ServiceConstants_Values.SPLIT_TOKEN_MAX_VALID_DAYS:
      return "SPLIT_TOKEN_MAX_VALID_DAYS";
    case ServiceConstants_Values.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A bucket. */
export interface Bucket {
  /**
   * Immutable. The name of the bucket.
   * Format: `projects/{project}/buckets/{bucket}`
   */
  name: string;
  /**
   * Output only. The user-chosen part of the bucket name. The `{bucket}`
   * portion of the `name` field. For globally unique buckets, this is equal to
   * the "bucket name" of other Cloud Storage APIs. Example: "pub".
   */
  bucketId: string;
  /**
   * The etag of the bucket.
   * If included in the metadata of an UpdateBucketRequest, the operation will
   * only be performed if the etag matches that of the bucket.
   */
  etag: string;
  /**
   * Immutable. The project which owns this bucket, in the format of
   * "projects/{projectIdentifier}".
   * {projectIdentifier} can be the project ID or project number.
   */
  project: string;
  /** Output only. The metadata generation of this bucket. */
  metageneration: Long;
  /**
   * Immutable. The location of the bucket. Object data for objects in the
   * bucket resides in physical storage within this region.  Defaults to `US`.
   * See the
   * [https://developers.google.com/storage/docs/concepts-techniques#specifyinglocations"][developer's
   * guide] for the authoritative list. Attempting to update this field after
   * the bucket is created will result in an error.
   */
  location: string;
  /**
   * Output only. The location type of the bucket (region, dual-region,
   * multi-region, etc).
   */
  locationType: string;
  /**
   * The bucket's default storage class, used whenever no storageClass is
   * specified for a newly-created object. This defines how objects in the
   * bucket are stored and determines the SLA and the cost of storage.
   * If this value is not specified when the bucket is created, it will default
   * to `STANDARD`. For more information, see
   * https://developers.google.com/storage/docs/storage-classes.
   */
  storageClass: string;
  /**
   * The recovery point objective for cross-region replication of the bucket.
   * Applicable only for dual- and multi-region buckets. "DEFAULT" uses default
   * replication. "ASYNC_TURBO" enables turbo replication, valid for dual-region
   * buckets only. If rpo is not specified when the bucket is created, it
   * defaults to "DEFAULT". For more information, see
   * https://cloud.google.com/storage/docs/availability-durability#turbo-replication.
   */
  rpo: string;
  /**
   * Access controls on the bucket.
   * If iam_config.uniform_bucket_level_access is enabled on this bucket,
   * requests to set, read, or modify acl is an error.
   */
  acl: BucketAccessControl[];
  /**
   * Default access controls to apply to new objects when no ACL is provided.
   * If iam_config.uniform_bucket_level_access is enabled on this bucket,
   * requests to set, read, or modify acl is an error.
   */
  defaultObjectAcl: ObjectAccessControl[];
  /**
   * The bucket's lifecycle config. See
   * [https://developers.google.com/storage/docs/lifecycle]Lifecycle Management]
   * for more information.
   */
  lifecycle:
    | Bucket_Lifecycle
    | undefined;
  /** Output only. The creation time of the bucket. */
  createTime:
    | Date
    | undefined;
  /**
   * The bucket's [https://www.w3.org/TR/cors/][Cross-Origin Resource Sharing]
   * (CORS) config.
   */
  cors: Bucket_Cors[];
  /** Output only. The modification time of the bucket. */
  updateTime:
    | Date
    | undefined;
  /**
   * The default value for event-based hold on newly created objects in this
   * bucket.  Event-based hold is a way to retain objects indefinitely until an
   * event occurs, signified by the
   * hold's release. After being released, such objects will be subject to
   * bucket-level retention (if any).  One sample use case of this flag is for
   * banks to hold loan documents for at least 3 years after loan is paid in
   * full. Here, bucket-level retention is 3 years and the event is loan being
   * paid in full. In this example, these objects will be held intact for any
   * number of years until the event has occurred (event-based hold on the
   * object is released) and then 3 more years after that. That means retention
   * duration of the objects begins from the moment event-based hold
   * transitioned from true to false.  Objects under event-based hold cannot be
   * deleted, overwritten or archived until the hold is removed.
   */
  defaultEventBasedHold: boolean;
  /** User-provided labels, in key/value pairs. */
  labels: { [key: string]: string };
  /**
   * The bucket's website config, controlling how the service behaves
   * when accessing bucket contents as a web site. See the
   * [https://cloud.google.com/storage/docs/static-website][Static Website
   * Examples] for more information.
   */
  website:
    | Bucket_Website
    | undefined;
  /** The bucket's versioning config. */
  versioning:
    | Bucket_Versioning
    | undefined;
  /**
   * The bucket's logging config, which defines the destination bucket
   * and name prefix (if any) for the current bucket's logs.
   */
  logging:
    | Bucket_Logging
    | undefined;
  /**
   * Output only. The owner of the bucket. This is always the project team's
   * owner group.
   */
  owner:
    | Owner
    | undefined;
  /** Encryption config for a bucket. */
  encryption:
    | Bucket_Encryption
    | undefined;
  /** The bucket's billing config. */
  billing:
    | Bucket_Billing
    | undefined;
  /**
   * The bucket's retention policy. The retention policy enforces a minimum
   * retention time for all objects contained in the bucket, based on their
   * creation time. Any attempt to overwrite or delete objects younger than the
   * retention period will result in a PERMISSION_DENIED error.  An unlocked
   * retention policy can be modified or removed from the bucket via a
   * storage.buckets.update operation. A locked retention policy cannot be
   * removed or shortened in duration for the lifetime of the bucket.
   * Attempting to remove or decrease period of a locked retention policy will
   * result in a PERMISSION_DENIED error.
   */
  retentionPolicy:
    | Bucket_RetentionPolicy
    | undefined;
  /** The bucket's IAM config. */
  iamConfig:
    | Bucket_IamConfig
    | undefined;
  /** Reserved for future use. */
  satisfiesPzs: boolean;
  /**
   * Configuration that, if present, specifies the data placement for a
   * [https://cloud.google.com/storage/docs/locations#location-dr][configurable
   * dual-region].
   */
  customPlacementConfig:
    | Bucket_CustomPlacementConfig
    | undefined;
  /**
   * The bucket's Autoclass configuration. If there is no configuration, the
   * Autoclass feature will be disabled and have no effect on the bucket.
   */
  autoclass:
    | Bucket_Autoclass
    | undefined;
  /**
   * Optional. The bucket's hierarchical namespace configuration. If there is no
   * configuration, the hierarchical namespace feature will be disabled and have
   * no effect on the bucket.
   */
  hierarchicalNamespace:
    | Bucket_HierarchicalNamespace
    | undefined;
  /**
   * Optional. The bucket's soft delete policy. The soft delete policy prevents
   * soft-deleted objects from being permanently deleted.
   */
  softDeletePolicy: Bucket_SoftDeletePolicy | undefined;
}

/** Billing properties of a bucket. */
export interface Bucket_Billing {
  /** When set to true, Requester Pays is enabled for this bucket. */
  requesterPays: boolean;
}

/**
 * Cross-Origin Response sharing (CORS) properties for a bucket.
 * For more on Cloud Storage and CORS, see
 * https://cloud.google.com/storage/docs/cross-origin.
 * For more on CORS in general, see https://tools.ietf.org/html/rfc6454.
 */
export interface Bucket_Cors {
  /**
   * The list of Origins eligible to receive CORS response headers. See
   * [https://tools.ietf.org/html/rfc6454][RFC 6454] for more on origins.
   * Note: "*" is permitted in the list of origins, and means "any Origin".
   */
  origin: string[];
  /**
   * The list of HTTP methods on which to include CORS response headers,
   * (`GET`, `OPTIONS`, `POST`, etc) Note: "*" is permitted in the list of
   * methods, and means "any method".
   */
  method: string[];
  /**
   * The list of HTTP headers other than the
   * [https://www.w3.org/TR/cors/#simple-response-header][simple response
   * headers] to give permission for the user-agent to share across domains.
   */
  responseHeader: string[];
  /**
   * The value, in seconds, to return in the
   * [https://www.w3.org/TR/cors/#access-control-max-age-response-header][Access-Control-Max-Age
   * header] used in preflight responses.
   */
  maxAgeSeconds: number;
}

/** Encryption properties of a bucket. */
export interface Bucket_Encryption {
  /**
   * The name of the Cloud KMS key that will be used to encrypt objects
   * inserted into this bucket, if no encryption method is specified.
   */
  defaultKmsKey: string;
}

/** Bucket restriction options. */
export interface Bucket_IamConfig {
  /** Bucket restriction options currently enforced on the bucket. */
  uniformBucketLevelAccess:
    | Bucket_IamConfig_UniformBucketLevelAccess
    | undefined;
  /**
   * Whether IAM will enforce public access prevention. Valid values are
   * "enforced" or "inherited".
   */
  publicAccessPrevention: string;
}

/**
 * Settings for Uniform Bucket level access.
 * See https://cloud.google.com/storage/docs/uniform-bucket-level-access.
 */
export interface Bucket_IamConfig_UniformBucketLevelAccess {
  /** If set, access checks only use bucket-level IAM policies or above. */
  enabled: boolean;
  /**
   * The deadline time for changing
   * `iam_config.uniform_bucket_level_access.enabled` from `true` to
   * `false`. Mutable until the specified deadline is reached, but not
   * afterward.
   */
  lockTime: Date | undefined;
}

/**
 * Lifecycle properties of a bucket.
 * For more information, see https://cloud.google.com/storage/docs/lifecycle.
 */
export interface Bucket_Lifecycle {
  /**
   * A lifecycle management rule, which is made of an action to take and the
   * condition(s) under which the action will be taken.
   */
  rule: Bucket_Lifecycle_Rule[];
}

/**
 * A lifecycle Rule, combining an action to take on an object and a
 * condition which will trigger that action.
 */
export interface Bucket_Lifecycle_Rule {
  /** The action to take. */
  action:
    | Bucket_Lifecycle_Rule_Action
    | undefined;
  /** The condition(s) under which the action will be taken. */
  condition: Bucket_Lifecycle_Rule_Condition | undefined;
}

/** An action to take on an object. */
export interface Bucket_Lifecycle_Rule_Action {
  /**
   * Type of the action. Currently, only `Delete`, `SetStorageClass`, and
   * `AbortIncompleteMultipartUpload` are supported.
   */
  type: string;
  /**
   * Target storage class. Required iff the type of the action is
   * SetStorageClass.
   */
  storageClass: string;
}

/** A condition of an object which triggers some action. */
export interface Bucket_Lifecycle_Rule_Condition {
  /**
   * Age of an object (in days). This condition is satisfied when an
   * object reaches the specified age.
   * A value of 0 indicates that all objects immediately match this
   * condition.
   */
  ageDays?:
    | number
    | undefined;
  /**
   * This condition is satisfied when an object is created before midnight
   * of the specified date in UTC.
   */
  createdBefore:
    | DateMessage
    | undefined;
  /**
   * Relevant only for versioned objects. If the value is
   * `true`, this condition matches live objects; if the value
   * is `false`, it matches archived objects.
   */
  isLive?:
    | boolean
    | undefined;
  /**
   * Relevant only for versioned objects. If the value is N, this
   * condition is satisfied when there are at least N versions (including
   * the live version) newer than this version of the object.
   */
  numNewerVersions?:
    | number
    | undefined;
  /**
   * Objects having any of the storage classes specified by this condition
   * will be matched. Values include `MULTI_REGIONAL`, `REGIONAL`,
   * `NEARLINE`, `COLDLINE`, `STANDARD`, and
   * `DURABLE_REDUCED_AVAILABILITY`.
   */
  matchesStorageClass: string[];
  /**
   * Number of days that have elapsed since the custom timestamp set on an
   * object.
   * The value of the field must be a nonnegative integer.
   */
  daysSinceCustomTime?:
    | number
    | undefined;
  /**
   * An object matches this condition if the custom timestamp set on the
   * object is before the specified date in UTC.
   */
  customTimeBefore:
    | DateMessage
    | undefined;
  /**
   * This condition is relevant only for versioned objects. An object
   * version satisfies this condition only if these many days have been
   * passed since it became noncurrent. The value of the field must be a
   * nonnegative integer. If it's zero, the object version will become
   * eligible for Lifecycle action as soon as it becomes noncurrent.
   */
  daysSinceNoncurrentTime?:
    | number
    | undefined;
  /**
   * This condition is relevant only for versioned objects. An object
   * version satisfies this condition only if it became noncurrent before
   * the specified date in UTC.
   */
  noncurrentTimeBefore:
    | DateMessage
    | undefined;
  /**
   * List of object name prefixes. If any prefix exactly matches the
   * beginning of the object name, the condition evaluates to true.
   */
  matchesPrefix: string[];
  /**
   * List of object name suffixes. If any suffix exactly matches the
   * end of the object name, the condition evaluates to true.
   */
  matchesSuffix: string[];
}

/** Logging-related properties of a bucket. */
export interface Bucket_Logging {
  /**
   * The destination bucket where the current bucket's logs should be placed,
   * using path format (like `projects/123456/buckets/foo`).
   */
  logBucket: string;
  /** A prefix for log object names. */
  logObjectPrefix: string;
}

/** Retention policy properties of a bucket. */
export interface Bucket_RetentionPolicy {
  /**
   * Server-determined value that indicates the time from which policy was
   * enforced and effective.
   */
  effectiveTime:
    | Date
    | undefined;
  /** Once locked, an object retention policy cannot be modified. */
  isLocked: boolean;
  /**
   * The duration that objects need to be retained. Retention duration must be
   * greater than zero and less than 100 years. Note that enforcement of
   * retention periods less than a day is not guaranteed. Such periods should
   * only be used for testing purposes. Any `nanos` value specified will be
   * rounded down to the nearest second.
   */
  retentionDuration: Duration | undefined;
}

/** Soft delete policy properties of a bucket. */
export interface Bucket_SoftDeletePolicy {
  /**
   * The period of time that soft-deleted objects in the bucket must be
   * retained and cannot be permanently deleted. The duration must be greater
   * than or equal to 7 days and less than 1 year.
   */
  retentionDuration?:
    | Duration
    | undefined;
  /** Time from which the policy was effective. This is service-provided. */
  effectiveTime?: Date | undefined;
}

/**
 * Properties of a bucket related to versioning.
 * For more on Cloud Storage versioning, see
 * https://cloud.google.com/storage/docs/object-versioning.
 */
export interface Bucket_Versioning {
  /** While set to true, versioning is fully enabled for this bucket. */
  enabled: boolean;
}

/**
 * Properties of a bucket related to accessing the contents as a static
 * website. For more on hosting a static website via Cloud Storage, see
 * https://cloud.google.com/storage/docs/hosting-static-website.
 */
export interface Bucket_Website {
  /**
   * If the requested object path is missing, the service will ensure the path
   * has a trailing '/', append this suffix, and attempt to retrieve the
   * resulting object. This allows the creation of `index.html`
   * objects to represent directory pages.
   */
  mainPageSuffix: string;
  /**
   * If the requested object path is missing, and any
   * `mainPageSuffix` object is missing, if applicable, the service
   * will return the named object from this bucket as the content for a
   * [https://tools.ietf.org/html/rfc7231#section-6.5.4][404 Not Found]
   * result.
   */
  notFoundPage: string;
}

/**
 * Configuration for Custom Dual Regions.  It should specify precisely two
 * eligible regions within the same Multiregion. More information on regions
 * may be found [https://cloud.google.com/storage/docs/locations][here].
 */
export interface Bucket_CustomPlacementConfig {
  /** List of locations to use for data placement. */
  dataLocations: string[];
}

/** Configuration for a bucket's Autoclass feature. */
export interface Bucket_Autoclass {
  /** Enables Autoclass. */
  enabled: boolean;
  /**
   * Output only. Latest instant at which the `enabled` field was set to true
   * after being disabled/unconfigured or set to false after being enabled. If
   * Autoclass is enabled when the bucket is created, the toggle_time is set
   * to the bucket creation time.
   */
  toggleTime:
    | Date
    | undefined;
  /**
   * An object in an Autoclass bucket will eventually cool down to the
   * terminal storage class if there is no access to the object.
   * The only valid values are NEARLINE and ARCHIVE.
   */
  terminalStorageClass?:
    | string
    | undefined;
  /**
   * Output only. Latest instant at which the autoclass terminal storage class
   * was updated.
   */
  terminalStorageClassUpdateTime?: Date | undefined;
}

/** Configuration for a bucket's hierarchical namespace feature. */
export interface Bucket_HierarchicalNamespace {
  /** Optional. Enables the hierarchical namespace feature. */
  enabled: boolean;
}

export interface Bucket_LabelsEntry {
  key: string;
  value: string;
}

/** An access-control entry. */
export interface BucketAccessControl {
  /** The access permission for the entity. */
  role: string;
  /** The ID of the access-control entry. */
  id: string;
  /**
   * The entity holding the permission, in one of the following forms:
   * * `user-{userid}`
   * * `user-{email}`
   * * `group-{groupid}`
   * * `group-{email}`
   * * `domain-{domain}`
   * * `project-{team}-{projectnumber}`
   * * `project-{team}-{projectid}`
   * * `allUsers`
   * * `allAuthenticatedUsers`
   * Examples:
   * * The user `liz@example.com` would be `user-liz@example.com`.
   * * The group `example@googlegroups.com` would be
   * `group-example@googlegroups.com`
   * * All members of the Google Apps for Business domain `example.com` would be
   * `domain-example.com`
   * For project entities, `project-{team}-{projectnumber}` format will be
   * returned on response.
   */
  entity: string;
  /**
   * Output only. The alternative entity format, if exists. For project
   * entities, `project-{team}-{projectid}` format will be returned on response.
   */
  entityAlt: string;
  /** The ID for the entity, if any. */
  entityId: string;
  /**
   * The etag of the BucketAccessControl.
   * If included in the metadata of an update or delete request message, the
   * operation operation will only be performed if the etag matches that of the
   * bucket's BucketAccessControl.
   */
  etag: string;
  /** The email address associated with the entity, if any. */
  email: string;
  /** The domain associated with the entity, if any. */
  domain: string;
  /** The project team associated with the entity, if any. */
  projectTeam: ProjectTeam | undefined;
}

/**
 * Message used to convey content being read or written, along with an optional
 * checksum.
 */
export interface ChecksummedData {
  /** Optional. The data. */
  content: Buffer;
  /** If set, the CRC32C digest of the content field. */
  crc32c?: number | undefined;
}

/** Message used for storing full (not subrange) object checksums. */
export interface ObjectChecksums {
  /**
   * CRC32C digest of the object data. Computed by the Cloud Storage service for
   * all written objects.
   * If set in a WriteObjectRequest, service will validate that the stored
   * object matches this checksum.
   */
  crc32c?:
    | number
    | undefined;
  /**
   * 128 bit MD5 hash of the object data.
   * For more information about using the MD5 hash, see
   * [https://cloud.google.com/storage/docs/hashes-etags#json-api][Hashes and
   * ETags: Best Practices].
   * Not all objects will provide an MD5 hash. For example, composite objects
   * provide only crc32c hashes. This value is equivalent to running `cat
   * object.txt | openssl md5 -binary`
   */
  md5Hash: Buffer;
}

/**
 * Describes the Customer-Supplied Encryption Key mechanism used to store an
 * Object's data at rest.
 */
export interface CustomerEncryption {
  /** The encryption algorithm. */
  encryptionAlgorithm: string;
  /**
   * SHA256 hash value of the encryption key.
   * In raw bytes format (not base64-encoded).
   */
  keySha256Bytes: Buffer;
}

/** An object. */
export interface Object {
  /**
   * Immutable. The name of this object. Nearly any sequence of unicode
   * characters is valid. See
   * [Guidelines](https://cloud.google.com/storage/docs/objects#naming).
   * Example: `test.txt`
   * The `name` field by itself does not uniquely identify a Cloud Storage
   * object. A Cloud Storage object is uniquely identified by the tuple of
   * (bucket, object, generation).
   */
  name: string;
  /** Immutable. The name of the bucket containing this object. */
  bucket: string;
  /**
   * The etag of the object.
   * If included in the metadata of an update or delete request message, the
   * operation will only be performed if the etag matches that of the live
   * object.
   */
  etag: string;
  /**
   * Immutable. The content generation of this object. Used for object
   * versioning.
   */
  generation: Long;
  /**
   * Output only. The version of the metadata for this generation of this
   * object. Used for preconditions and for detecting changes in metadata. A
   * metageneration number is only meaningful in the context of a particular
   * generation of a particular object.
   */
  metageneration: Long;
  /** Storage class of the object. */
  storageClass: string;
  /**
   * Output only. Content-Length of the object data in bytes, matching
   * [https://tools.ietf.org/html/rfc7230#section-3.3.2][RFC 7230 3.3.2].
   */
  size: Long;
  /**
   * Content-Encoding of the object data, matching
   * [https://tools.ietf.org/html/rfc7231#section-3.1.2.2][RFC 7231 3.1.2.2]
   */
  contentEncoding: string;
  /**
   * Content-Disposition of the object data, matching
   * [https://tools.ietf.org/html/rfc6266][RFC 6266].
   */
  contentDisposition: string;
  /**
   * Cache-Control directive for the object data, matching
   * [https://tools.ietf.org/html/rfc7234#section-5.2"][RFC 7234 5.2].
   * If omitted, and the object is accessible to all anonymous users, the
   * default will be `public, max-age=3600`.
   */
  cacheControl: string;
  /**
   * Access controls on the object.
   * If iam_config.uniform_bucket_level_access is enabled on the parent
   * bucket, requests to set, read, or modify acl is an error.
   */
  acl: ObjectAccessControl[];
  /**
   * Content-Language of the object data, matching
   * [https://tools.ietf.org/html/rfc7231#section-3.1.3.2][RFC 7231 3.1.3.2].
   */
  contentLanguage: string;
  /**
   * Output only. If this object is noncurrent, this is the time when the object
   * became noncurrent.
   */
  deleteTime:
    | Date
    | undefined;
  /**
   * Content-Type of the object data, matching
   * [https://tools.ietf.org/html/rfc7231#section-3.1.1.5][RFC 7231 3.1.1.5].
   * If an object is stored without a Content-Type, it is served as
   * `application/octet-stream`.
   */
  contentType: string;
  /** Output only. The creation time of the object. */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Number of underlying components that make up this object.
   * Components are accumulated by compose operations.
   */
  componentCount: number;
  /**
   * Output only. Hashes for the data part of this object. This field is used
   * for output only and will be silently ignored if provided in requests. The
   * checksums of the complete object regardless of data range. If the object is
   * downloaded in full, the client should compute one of these checksums over
   * the downloaded object and compare it against the value provided here.
   */
  checksums:
    | ObjectChecksums
    | undefined;
  /**
   * Output only. The modification time of the object metadata.
   * Set initially to object creation time and then updated whenever any
   * metadata of the object changes. This includes changes made by a requester,
   * such as modifying custom metadata, as well as changes made by Cloud Storage
   * on behalf of a requester, such as changing the storage class based on an
   * Object Lifecycle Configuration.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * Cloud KMS Key used to encrypt this object, if the object is encrypted by
   * such a key.
   */
  kmsKey: string;
  /**
   * Output only. The time at which the object's storage class was last changed.
   * When the object is initially created, it will be set to time_created.
   */
  updateStorageClassTime:
    | Date
    | undefined;
  /**
   * Whether an object is under temporary hold. While this flag is set to true,
   * the object is protected against deletion and overwrites.  A common use case
   * of this flag is regulatory investigations where objects need to be retained
   * while the investigation is ongoing. Note that unlike event-based hold,
   * temporary hold does not impact retention expiration time of an object.
   */
  temporaryHold: boolean;
  /**
   * A server-determined value that specifies the earliest time that the
   * object's retention period expires.
   * Note 1: This field is not provided for objects with an active event-based
   * hold, since retention expiration is unknown until the hold is removed.
   * Note 2: This value can be provided even when temporary hold is set (so that
   * the user can reason about policy without having to first unset the
   * temporary hold).
   */
  retentionExpireTime:
    | Date
    | undefined;
  /** User-provided metadata, in key/value pairs. */
  metadata: { [key: string]: string };
  /**
   * Whether an object is under event-based hold.
   * An event-based hold is a way to force the retention of an object until
   * after some event occurs. Once the hold is released by explicitly setting
   * this field to false, the object will become subject to any bucket-level
   * retention policy, except that the retention duration will be calculated
   * from the time the event based hold was lifted, rather than the time the
   * object was created.
   *
   * In a WriteObject request, not setting this field implies that the value
   * should be taken from the parent bucket's "default_event_based_hold" field.
   * In a response, this field will always be set to true or false.
   */
  eventBasedHold?:
    | boolean
    | undefined;
  /**
   * Output only. The owner of the object. This will always be the uploader of
   * the object.
   */
  owner:
    | Owner
    | undefined;
  /**
   * Metadata of Customer-Supplied Encryption Key, if the object is encrypted by
   * such a key.
   */
  customerEncryption:
    | CustomerEncryption
    | undefined;
  /** A user-specified timestamp set on an object. */
  customTime:
    | Date
    | undefined;
  /**
   * Output only. This is the time when the object became soft-deleted.
   *
   * Soft-deleted objects are only accessible if a soft_delete_policy is
   * enabled. Also see hard_delete_time.
   */
  softDeleteTime?:
    | Date
    | undefined;
  /**
   * Output only. The time when the object will be permanently deleted.
   *
   * Only set when an object becomes soft-deleted with a soft_delete_policy.
   * Otherwise, the object will not be accessible.
   */
  hardDeleteTime?: Date | undefined;
}

export interface Object_MetadataEntry {
  key: string;
  value: string;
}

/** An access-control entry. */
export interface ObjectAccessControl {
  /**
   * The access permission for the entity. One of the following values:
   * * `READER`
   * * `WRITER`
   * * `OWNER`
   */
  role: string;
  /** The ID of the access-control entry. */
  id: string;
  /**
   * The entity holding the permission, in one of the following forms:
   * * `user-{userid}`
   * * `user-{email}`
   * * `group-{groupid}`
   * * `group-{email}`
   * * `domain-{domain}`
   * * `project-{team}-{projectnumber}`
   * * `project-{team}-{projectid}`
   * * `allUsers`
   * * `allAuthenticatedUsers`
   * Examples:
   * * The user `liz@example.com` would be `user-liz@example.com`.
   * * The group `example@googlegroups.com` would be
   * `group-example@googlegroups.com`.
   * * All members of the Google Apps for Business domain `example.com` would be
   * `domain-example.com`.
   * For project entities, `project-{team}-{projectnumber}` format will be
   * returned on response.
   */
  entity: string;
  /**
   * Output only. The alternative entity format, if exists. For project
   * entities, `project-{team}-{projectid}` format will be returned on response.
   */
  entityAlt: string;
  /** The ID for the entity, if any. */
  entityId: string;
  /**
   * The etag of the ObjectAccessControl.
   * If included in the metadata of an update or delete request message, the
   * operation will only be performed if the etag matches that of the live
   * object's ObjectAccessControl.
   */
  etag: string;
  /** The email address associated with the entity, if any. */
  email: string;
  /** The domain associated with the entity, if any. */
  domain: string;
  /** The project team associated with the entity, if any. */
  projectTeam: ProjectTeam | undefined;
}

/** The result of a call to Objects.ListObjects */
export interface ListObjectsResponse {
  /** The list of items. */
  objects: Object[];
  /**
   * The list of prefixes of objects matching-but-not-listed up to and including
   * the requested delimiter.
   */
  prefixes: string[];
  /**
   * The continuation token, used to page through large result sets. Provide
   * this value in a subsequent request to return the next page of results.
   */
  nextPageToken: string;
}

/** Represents the Viewers, Editors, or Owners of a given project. */
export interface ProjectTeam {
  /** The project number. */
  projectNumber: string;
  /** The team. */
  team: string;
}

/** The owner of a specific resource. */
export interface Owner {
  /** The entity, in the form `user-`*userId*. */
  entity: string;
  /** The ID for the entity. */
  entityId: string;
}

/** Specifies a requested range of bytes to download. */
export interface ContentRange {
  /** The starting offset of the object data. This value is inclusive. */
  start: Long;
  /** The ending offset of the object data. This value is exclusive. */
  end: Long;
  /** The complete length of the object data. */
  completeLength: Long;
}

/** Request message for DeleteNotificationConfig. */
export interface DeleteNotificationConfigRequest {
  /** Required. The parent bucket of the NotificationConfig. */
  name: string;
}

/** Request message for GetNotificationConfig. */
export interface GetNotificationConfigRequest {
  /**
   * Required. The parent bucket of the NotificationConfig.
   * Format:
   * `projects/{project}/buckets/{bucket}/notificationConfigs/{notificationConfig}`
   */
  name: string;
}

/** Request message for CreateNotificationConfig. */
export interface CreateNotificationConfigRequest {
  /** Required. The bucket to which this NotificationConfig belongs. */
  parent: string;
  /** Required. Properties of the NotificationConfig to be inserted. */
  notificationConfig: NotificationConfig | undefined;
}

/** Request message for ListNotifications. */
export interface ListNotificationConfigsRequest {
  /** Required. Name of a Google Cloud Storage bucket. */
  parent: string;
  /**
   * Optional. The maximum number of NotificationConfigs to return. The service
   * may return fewer than this value. The default value is 100. Specifying a
   * value above 100 will result in a page_size of 100.
   */
  pageSize: number;
  /**
   * Optional. A page token, received from a previous `ListNotificationConfigs`
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to `ListNotificationConfigs`
   * must match the call that provided the page token.
   */
  pageToken: string;
}

/** The result of a call to ListNotificationConfigs */
export interface ListNotificationConfigsResponse {
  /** The list of items. */
  notificationConfigs: NotificationConfig[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   * If this field is omitted, there are no subsequent pages.
   */
  nextPageToken: string;
}

/** A directive to publish Pub/Sub notifications upon changes to a bucket. */
export interface NotificationConfig {
  /**
   * Required. The resource name of this NotificationConfig.
   * Format:
   * `projects/{project}/buckets/{bucket}/notificationConfigs/{notificationConfig}`
   * The `{project}` portion may be `_` for globally unique buckets.
   */
  name: string;
  /**
   * Required. The Pub/Sub topic to which this subscription publishes. Formatted
   * as:
   * '//pubsub.googleapis.com/projects/{project-identifier}/topics/{my-topic}'
   */
  topic: string;
  /**
   * Optional. The etag of the NotificationConfig.
   * If included in the metadata of GetNotificationConfigRequest, the operation
   * will only be performed if the etag matches that of the NotificationConfig.
   */
  etag: string;
  /**
   * Optional. If present, only send notifications about listed event types. If
   * empty, sent notifications for all event types.
   */
  eventTypes: string[];
  /**
   * Optional. A list of additional attributes to attach to each Pub/Sub
   * message published for this NotificationConfig.
   */
  customAttributes: { [key: string]: string };
  /**
   * Optional. If present, only apply this NotificationConfig to object names
   * that begin with this prefix.
   */
  objectNamePrefix: string;
  /** Required. The desired content of the Payload. */
  payloadFormat: string;
}

export interface NotificationConfig_CustomAttributesEntry {
  key: string;
  value: string;
}

function createBaseDeleteBucketRequest(): DeleteBucketRequest {
  return { name: "", ifMetagenerationMatch: undefined, ifMetagenerationNotMatch: undefined };
}

export const DeleteBucketRequest: MessageFns<DeleteBucketRequest> = {
  encode(message: DeleteBucketRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(16).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(24).int64(message.ifMetagenerationNotMatch.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBucketRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBucketRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBucketRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
    };
  },

  toJSON(message: DeleteBucketRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBucketRequest>): DeleteBucketRequest {
    return DeleteBucketRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBucketRequest>): DeleteBucketRequest {
    const message = createBaseDeleteBucketRequest();
    message.name = object.name ?? "";
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    return message;
  },
};

function createBaseGetBucketRequest(): GetBucketRequest {
  return { name: "", ifMetagenerationMatch: undefined, ifMetagenerationNotMatch: undefined, readMask: undefined };
}

export const GetBucketRequest: MessageFns<GetBucketRequest> = {
  encode(message: GetBucketRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(16).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(24).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBucketRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBucketRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBucketRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: GetBucketRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<GetBucketRequest>): GetBucketRequest {
    return GetBucketRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBucketRequest>): GetBucketRequest {
    const message = createBaseGetBucketRequest();
    message.name = object.name ?? "";
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseCreateBucketRequest(): CreateBucketRequest {
  return { parent: "", bucket: undefined, bucketId: "", predefinedAcl: "", predefinedDefaultObjectAcl: "" };
}

export const CreateBucketRequest: MessageFns<CreateBucketRequest> = {
  encode(message: CreateBucketRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.bucket !== undefined) {
      Bucket.encode(message.bucket, writer.uint32(18).fork()).join();
    }
    if (message.bucketId !== "") {
      writer.uint32(26).string(message.bucketId);
    }
    if (message.predefinedAcl !== "") {
      writer.uint32(50).string(message.predefinedAcl);
    }
    if (message.predefinedDefaultObjectAcl !== "") {
      writer.uint32(58).string(message.predefinedDefaultObjectAcl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBucketRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBucketRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucket = Bucket.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.bucketId = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.predefinedAcl = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.predefinedDefaultObjectAcl = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBucketRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      bucket: isSet(object.bucket) ? Bucket.fromJSON(object.bucket) : undefined,
      bucketId: isSet(object.bucketId) ? globalThis.String(object.bucketId) : "",
      predefinedAcl: isSet(object.predefinedAcl) ? globalThis.String(object.predefinedAcl) : "",
      predefinedDefaultObjectAcl: isSet(object.predefinedDefaultObjectAcl)
        ? globalThis.String(object.predefinedDefaultObjectAcl)
        : "",
    };
  },

  toJSON(message: CreateBucketRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.bucket !== undefined) {
      obj.bucket = Bucket.toJSON(message.bucket);
    }
    if (message.bucketId !== "") {
      obj.bucketId = message.bucketId;
    }
    if (message.predefinedAcl !== "") {
      obj.predefinedAcl = message.predefinedAcl;
    }
    if (message.predefinedDefaultObjectAcl !== "") {
      obj.predefinedDefaultObjectAcl = message.predefinedDefaultObjectAcl;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBucketRequest>): CreateBucketRequest {
    return CreateBucketRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBucketRequest>): CreateBucketRequest {
    const message = createBaseCreateBucketRequest();
    message.parent = object.parent ?? "";
    message.bucket = (object.bucket !== undefined && object.bucket !== null)
      ? Bucket.fromPartial(object.bucket)
      : undefined;
    message.bucketId = object.bucketId ?? "";
    message.predefinedAcl = object.predefinedAcl ?? "";
    message.predefinedDefaultObjectAcl = object.predefinedDefaultObjectAcl ?? "";
    return message;
  },
};

function createBaseListBucketsRequest(): ListBucketsRequest {
  return { parent: "", pageSize: 0, pageToken: "", prefix: "", readMask: undefined };
}

export const ListBucketsRequest: MessageFns<ListBucketsRequest> = {
  encode(message: ListBucketsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.prefix !== "") {
      writer.uint32(34).string(message.prefix);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBucketsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBucketsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.prefix = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBucketsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      prefix: isSet(object.prefix) ? globalThis.String(object.prefix) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListBucketsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.prefix !== "") {
      obj.prefix = message.prefix;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListBucketsRequest>): ListBucketsRequest {
    return ListBucketsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBucketsRequest>): ListBucketsRequest {
    const message = createBaseListBucketsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.prefix = object.prefix ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListBucketsResponse(): ListBucketsResponse {
  return { buckets: [], nextPageToken: "" };
}

export const ListBucketsResponse: MessageFns<ListBucketsResponse> = {
  encode(message: ListBucketsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.buckets) {
      Bucket.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBucketsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBucketsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.buckets.push(Bucket.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBucketsResponse {
    return {
      buckets: globalThis.Array.isArray(object?.buckets) ? object.buckets.map((e: any) => Bucket.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListBucketsResponse): unknown {
    const obj: any = {};
    if (message.buckets?.length) {
      obj.buckets = message.buckets.map((e) => Bucket.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBucketsResponse>): ListBucketsResponse {
    return ListBucketsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBucketsResponse>): ListBucketsResponse {
    const message = createBaseListBucketsResponse();
    message.buckets = object.buckets?.map((e) => Bucket.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseLockBucketRetentionPolicyRequest(): LockBucketRetentionPolicyRequest {
  return { bucket: "", ifMetagenerationMatch: Long.ZERO };
}

export const LockBucketRetentionPolicyRequest: MessageFns<LockBucketRetentionPolicyRequest> = {
  encode(message: LockBucketRetentionPolicyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (!message.ifMetagenerationMatch.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.ifMetagenerationMatch.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LockBucketRetentionPolicyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLockBucketRetentionPolicyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LockBucketRetentionPolicyRequest {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : Long.ZERO,
    };
  },

  toJSON(message: LockBucketRetentionPolicyRequest): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (!message.ifMetagenerationMatch.equals(Long.ZERO)) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<LockBucketRetentionPolicyRequest>): LockBucketRetentionPolicyRequest {
    return LockBucketRetentionPolicyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<LockBucketRetentionPolicyRequest>): LockBucketRetentionPolicyRequest {
    const message = createBaseLockBucketRetentionPolicyRequest();
    message.bucket = object.bucket ?? "";
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : Long.ZERO;
    return message;
  },
};

function createBaseUpdateBucketRequest(): UpdateBucketRequest {
  return {
    bucket: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    predefinedAcl: "",
    predefinedDefaultObjectAcl: "",
    updateMask: undefined,
  };
}

export const UpdateBucketRequest: MessageFns<UpdateBucketRequest> = {
  encode(message: UpdateBucketRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== undefined) {
      Bucket.encode(message.bucket, writer.uint32(10).fork()).join();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(16).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(24).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.predefinedAcl !== "") {
      writer.uint32(66).string(message.predefinedAcl);
    }
    if (message.predefinedDefaultObjectAcl !== "") {
      writer.uint32(74).string(message.predefinedDefaultObjectAcl);
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateBucketRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateBucketRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = Bucket.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.predefinedAcl = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.predefinedDefaultObjectAcl = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateBucketRequest {
    return {
      bucket: isSet(object.bucket) ? Bucket.fromJSON(object.bucket) : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      predefinedAcl: isSet(object.predefinedAcl) ? globalThis.String(object.predefinedAcl) : "",
      predefinedDefaultObjectAcl: isSet(object.predefinedDefaultObjectAcl)
        ? globalThis.String(object.predefinedDefaultObjectAcl)
        : "",
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateBucketRequest): unknown {
    const obj: any = {};
    if (message.bucket !== undefined) {
      obj.bucket = Bucket.toJSON(message.bucket);
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.predefinedAcl !== "") {
      obj.predefinedAcl = message.predefinedAcl;
    }
    if (message.predefinedDefaultObjectAcl !== "") {
      obj.predefinedDefaultObjectAcl = message.predefinedDefaultObjectAcl;
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateBucketRequest>): UpdateBucketRequest {
    return UpdateBucketRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateBucketRequest>): UpdateBucketRequest {
    const message = createBaseUpdateBucketRequest();
    message.bucket = (object.bucket !== undefined && object.bucket !== null)
      ? Bucket.fromPartial(object.bucket)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.predefinedAcl = object.predefinedAcl ?? "";
    message.predefinedDefaultObjectAcl = object.predefinedDefaultObjectAcl ?? "";
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseComposeObjectRequest(): ComposeObjectRequest {
  return {
    destination: undefined,
    sourceObjects: [],
    destinationPredefinedAcl: "",
    ifGenerationMatch: undefined,
    ifMetagenerationMatch: undefined,
    kmsKey: "",
    commonObjectRequestParams: undefined,
    objectChecksums: undefined,
  };
}

export const ComposeObjectRequest: MessageFns<ComposeObjectRequest> = {
  encode(message: ComposeObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destination !== undefined) {
      Object.encode(message.destination, writer.uint32(10).fork()).join();
    }
    for (const v of message.sourceObjects) {
      ComposeObjectRequest_SourceObject.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.destinationPredefinedAcl !== "") {
      writer.uint32(74).string(message.destinationPredefinedAcl);
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(32).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(40).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.kmsKey !== "") {
      writer.uint32(50).string(message.kmsKey);
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(58).fork()).join();
    }
    if (message.objectChecksums !== undefined) {
      ObjectChecksums.encode(message.objectChecksums, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComposeObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComposeObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.destination = Object.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceObjects.push(ComposeObjectRequest_SourceObject.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.destinationPredefinedAcl = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.objectChecksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComposeObjectRequest {
    return {
      destination: isSet(object.destination) ? Object.fromJSON(object.destination) : undefined,
      sourceObjects: globalThis.Array.isArray(object?.sourceObjects)
        ? object.sourceObjects.map((e: any) => ComposeObjectRequest_SourceObject.fromJSON(e))
        : [],
      destinationPredefinedAcl: isSet(object.destinationPredefinedAcl)
        ? globalThis.String(object.destinationPredefinedAcl)
        : "",
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "",
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
      objectChecksums: isSet(object.objectChecksums) ? ObjectChecksums.fromJSON(object.objectChecksums) : undefined,
    };
  },

  toJSON(message: ComposeObjectRequest): unknown {
    const obj: any = {};
    if (message.destination !== undefined) {
      obj.destination = Object.toJSON(message.destination);
    }
    if (message.sourceObjects?.length) {
      obj.sourceObjects = message.sourceObjects.map((e) => ComposeObjectRequest_SourceObject.toJSON(e));
    }
    if (message.destinationPredefinedAcl !== "") {
      obj.destinationPredefinedAcl = message.destinationPredefinedAcl;
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    if (message.objectChecksums !== undefined) {
      obj.objectChecksums = ObjectChecksums.toJSON(message.objectChecksums);
    }
    return obj;
  },

  create(base?: DeepPartial<ComposeObjectRequest>): ComposeObjectRequest {
    return ComposeObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ComposeObjectRequest>): ComposeObjectRequest {
    const message = createBaseComposeObjectRequest();
    message.destination = (object.destination !== undefined && object.destination !== null)
      ? Object.fromPartial(object.destination)
      : undefined;
    message.sourceObjects = object.sourceObjects?.map((e) => ComposeObjectRequest_SourceObject.fromPartial(e)) || [];
    message.destinationPredefinedAcl = object.destinationPredefinedAcl ?? "";
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.kmsKey = object.kmsKey ?? "";
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    message.objectChecksums = (object.objectChecksums !== undefined && object.objectChecksums !== null)
      ? ObjectChecksums.fromPartial(object.objectChecksums)
      : undefined;
    return message;
  },
};

function createBaseComposeObjectRequest_SourceObject(): ComposeObjectRequest_SourceObject {
  return { name: "", generation: Long.ZERO, objectPreconditions: undefined };
}

export const ComposeObjectRequest_SourceObject: MessageFns<ComposeObjectRequest_SourceObject> = {
  encode(message: ComposeObjectRequest_SourceObject, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.generation.toString());
    }
    if (message.objectPreconditions !== undefined) {
      ComposeObjectRequest_SourceObject_ObjectPreconditions.encode(
        message.objectPreconditions,
        writer.uint32(26).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComposeObjectRequest_SourceObject {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComposeObjectRequest_SourceObject();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.objectPreconditions = ComposeObjectRequest_SourceObject_ObjectPreconditions.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComposeObjectRequest_SourceObject {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      objectPreconditions: isSet(object.objectPreconditions)
        ? ComposeObjectRequest_SourceObject_ObjectPreconditions.fromJSON(object.objectPreconditions)
        : undefined,
    };
  },

  toJSON(message: ComposeObjectRequest_SourceObject): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (message.objectPreconditions !== undefined) {
      obj.objectPreconditions = ComposeObjectRequest_SourceObject_ObjectPreconditions.toJSON(
        message.objectPreconditions,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<ComposeObjectRequest_SourceObject>): ComposeObjectRequest_SourceObject {
    return ComposeObjectRequest_SourceObject.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ComposeObjectRequest_SourceObject>): ComposeObjectRequest_SourceObject {
    const message = createBaseComposeObjectRequest_SourceObject();
    message.name = object.name ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.objectPreconditions = (object.objectPreconditions !== undefined && object.objectPreconditions !== null)
      ? ComposeObjectRequest_SourceObject_ObjectPreconditions.fromPartial(object.objectPreconditions)
      : undefined;
    return message;
  },
};

function createBaseComposeObjectRequest_SourceObject_ObjectPreconditions(): ComposeObjectRequest_SourceObject_ObjectPreconditions {
  return { ifGenerationMatch: undefined };
}

export const ComposeObjectRequest_SourceObject_ObjectPreconditions: MessageFns<
  ComposeObjectRequest_SourceObject_ObjectPreconditions
> = {
  encode(
    message: ComposeObjectRequest_SourceObject_ObjectPreconditions,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(8).int64(message.ifGenerationMatch.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComposeObjectRequest_SourceObject_ObjectPreconditions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComposeObjectRequest_SourceObject_ObjectPreconditions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComposeObjectRequest_SourceObject_ObjectPreconditions {
    return {
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
    };
  },

  toJSON(message: ComposeObjectRequest_SourceObject_ObjectPreconditions): unknown {
    const obj: any = {};
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<ComposeObjectRequest_SourceObject_ObjectPreconditions>,
  ): ComposeObjectRequest_SourceObject_ObjectPreconditions {
    return ComposeObjectRequest_SourceObject_ObjectPreconditions.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ComposeObjectRequest_SourceObject_ObjectPreconditions>,
  ): ComposeObjectRequest_SourceObject_ObjectPreconditions {
    const message = createBaseComposeObjectRequest_SourceObject_ObjectPreconditions();
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    return message;
  },
};

function createBaseDeleteObjectRequest(): DeleteObjectRequest {
  return {
    bucket: "",
    object: "",
    generation: Long.ZERO,
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    commonObjectRequestParams: undefined,
  };
}

export const DeleteObjectRequest: MessageFns<DeleteObjectRequest> = {
  encode(message: DeleteObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.generation.toString());
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(40).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(48).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(56).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(64).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteObjectRequest {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
    };
  },

  toJSON(message: DeleteObjectRequest): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteObjectRequest>): DeleteObjectRequest {
    return DeleteObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteObjectRequest>): DeleteObjectRequest {
    const message = createBaseDeleteObjectRequest();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    return message;
  },
};

function createBaseRestoreObjectRequest(): RestoreObjectRequest {
  return {
    bucket: "",
    object: "",
    generation: Long.ZERO,
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    copySourceAcl: undefined,
    commonObjectRequestParams: undefined,
  };
}

export const RestoreObjectRequest: MessageFns<RestoreObjectRequest> = {
  encode(message: RestoreObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(32).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(40).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(48).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(56).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.copySourceAcl !== undefined) {
      writer.uint32(72).bool(message.copySourceAcl);
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.copySourceAcl = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreObjectRequest {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      copySourceAcl: isSet(object.copySourceAcl) ? globalThis.Boolean(object.copySourceAcl) : undefined,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
    };
  },

  toJSON(message: RestoreObjectRequest): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.copySourceAcl !== undefined) {
      obj.copySourceAcl = message.copySourceAcl;
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreObjectRequest>): RestoreObjectRequest {
    return RestoreObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreObjectRequest>): RestoreObjectRequest {
    const message = createBaseRestoreObjectRequest();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.copySourceAcl = object.copySourceAcl ?? undefined;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    return message;
  },
};

function createBaseCancelResumableWriteRequest(): CancelResumableWriteRequest {
  return { uploadId: "" };
}

export const CancelResumableWriteRequest: MessageFns<CancelResumableWriteRequest> = {
  encode(message: CancelResumableWriteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadId !== "") {
      writer.uint32(10).string(message.uploadId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelResumableWriteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelResumableWriteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelResumableWriteRequest {
    return { uploadId: isSet(object.uploadId) ? globalThis.String(object.uploadId) : "" };
  },

  toJSON(message: CancelResumableWriteRequest): unknown {
    const obj: any = {};
    if (message.uploadId !== "") {
      obj.uploadId = message.uploadId;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelResumableWriteRequest>): CancelResumableWriteRequest {
    return CancelResumableWriteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelResumableWriteRequest>): CancelResumableWriteRequest {
    const message = createBaseCancelResumableWriteRequest();
    message.uploadId = object.uploadId ?? "";
    return message;
  },
};

function createBaseCancelResumableWriteResponse(): CancelResumableWriteResponse {
  return {};
}

export const CancelResumableWriteResponse: MessageFns<CancelResumableWriteResponse> = {
  encode(_: CancelResumableWriteResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelResumableWriteResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelResumableWriteResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CancelResumableWriteResponse {
    return {};
  },

  toJSON(_: CancelResumableWriteResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<CancelResumableWriteResponse>): CancelResumableWriteResponse {
    return CancelResumableWriteResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<CancelResumableWriteResponse>): CancelResumableWriteResponse {
    const message = createBaseCancelResumableWriteResponse();
    return message;
  },
};

function createBaseReadObjectRequest(): ReadObjectRequest {
  return {
    bucket: "",
    object: "",
    generation: Long.ZERO,
    readOffset: Long.ZERO,
    readLimit: Long.ZERO,
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    commonObjectRequestParams: undefined,
    readMask: undefined,
  };
}

export const ReadObjectRequest: MessageFns<ReadObjectRequest> = {
  encode(message: ReadObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    if (!message.readOffset.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.readOffset.toString());
    }
    if (!message.readLimit.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.readLimit.toString());
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(48).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(56).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(64).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(72).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(82).fork()).join();
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.readOffset = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.readLimit = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadObjectRequest {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      readOffset: isSet(object.readOffset) ? Long.fromValue(object.readOffset) : Long.ZERO,
      readLimit: isSet(object.readLimit) ? Long.fromValue(object.readLimit) : Long.ZERO,
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ReadObjectRequest): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (!message.readOffset.equals(Long.ZERO)) {
      obj.readOffset = (message.readOffset || Long.ZERO).toString();
    }
    if (!message.readLimit.equals(Long.ZERO)) {
      obj.readLimit = (message.readLimit || Long.ZERO).toString();
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ReadObjectRequest>): ReadObjectRequest {
    return ReadObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadObjectRequest>): ReadObjectRequest {
    const message = createBaseReadObjectRequest();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.readOffset = (object.readOffset !== undefined && object.readOffset !== null)
      ? Long.fromValue(object.readOffset)
      : Long.ZERO;
    message.readLimit = (object.readLimit !== undefined && object.readLimit !== null)
      ? Long.fromValue(object.readLimit)
      : Long.ZERO;
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseGetObjectRequest(): GetObjectRequest {
  return {
    bucket: "",
    object: "",
    generation: Long.ZERO,
    softDeleted: undefined,
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    commonObjectRequestParams: undefined,
    readMask: undefined,
  };
}

export const GetObjectRequest: MessageFns<GetObjectRequest> = {
  encode(message: GetObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    if (message.softDeleted !== undefined) {
      writer.uint32(88).bool(message.softDeleted);
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(32).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(40).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(48).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(56).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(66).fork()).join();
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.softDeleted = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetObjectRequest {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      softDeleted: isSet(object.softDeleted) ? globalThis.Boolean(object.softDeleted) : undefined,
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: GetObjectRequest): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (message.softDeleted !== undefined) {
      obj.softDeleted = message.softDeleted;
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<GetObjectRequest>): GetObjectRequest {
    return GetObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetObjectRequest>): GetObjectRequest {
    const message = createBaseGetObjectRequest();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.softDeleted = object.softDeleted ?? undefined;
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseReadObjectResponse(): ReadObjectResponse {
  return { checksummedData: undefined, objectChecksums: undefined, contentRange: undefined, metadata: undefined };
}

export const ReadObjectResponse: MessageFns<ReadObjectResponse> = {
  encode(message: ReadObjectResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.checksummedData !== undefined) {
      ChecksummedData.encode(message.checksummedData, writer.uint32(10).fork()).join();
    }
    if (message.objectChecksums !== undefined) {
      ObjectChecksums.encode(message.objectChecksums, writer.uint32(18).fork()).join();
    }
    if (message.contentRange !== undefined) {
      ContentRange.encode(message.contentRange, writer.uint32(26).fork()).join();
    }
    if (message.metadata !== undefined) {
      Object.encode(message.metadata, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadObjectResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadObjectResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.checksummedData = ChecksummedData.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.objectChecksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.contentRange = ContentRange.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.metadata = Object.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadObjectResponse {
    return {
      checksummedData: isSet(object.checksummedData) ? ChecksummedData.fromJSON(object.checksummedData) : undefined,
      objectChecksums: isSet(object.objectChecksums) ? ObjectChecksums.fromJSON(object.objectChecksums) : undefined,
      contentRange: isSet(object.contentRange) ? ContentRange.fromJSON(object.contentRange) : undefined,
      metadata: isSet(object.metadata) ? Object.fromJSON(object.metadata) : undefined,
    };
  },

  toJSON(message: ReadObjectResponse): unknown {
    const obj: any = {};
    if (message.checksummedData !== undefined) {
      obj.checksummedData = ChecksummedData.toJSON(message.checksummedData);
    }
    if (message.objectChecksums !== undefined) {
      obj.objectChecksums = ObjectChecksums.toJSON(message.objectChecksums);
    }
    if (message.contentRange !== undefined) {
      obj.contentRange = ContentRange.toJSON(message.contentRange);
    }
    if (message.metadata !== undefined) {
      obj.metadata = Object.toJSON(message.metadata);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadObjectResponse>): ReadObjectResponse {
    return ReadObjectResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadObjectResponse>): ReadObjectResponse {
    const message = createBaseReadObjectResponse();
    message.checksummedData = (object.checksummedData !== undefined && object.checksummedData !== null)
      ? ChecksummedData.fromPartial(object.checksummedData)
      : undefined;
    message.objectChecksums = (object.objectChecksums !== undefined && object.objectChecksums !== null)
      ? ObjectChecksums.fromPartial(object.objectChecksums)
      : undefined;
    message.contentRange = (object.contentRange !== undefined && object.contentRange !== null)
      ? ContentRange.fromPartial(object.contentRange)
      : undefined;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? Object.fromPartial(object.metadata)
      : undefined;
    return message;
  },
};

function createBaseWriteObjectSpec(): WriteObjectSpec {
  return {
    resource: undefined,
    predefinedAcl: "",
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    objectSize: undefined,
  };
}

export const WriteObjectSpec: MessageFns<WriteObjectSpec> = {
  encode(message: WriteObjectSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resource !== undefined) {
      Object.encode(message.resource, writer.uint32(10).fork()).join();
    }
    if (message.predefinedAcl !== "") {
      writer.uint32(58).string(message.predefinedAcl);
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(24).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(32).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(40).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(48).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.objectSize !== undefined) {
      writer.uint32(64).int64(message.objectSize.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteObjectSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteObjectSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.resource = Object.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.predefinedAcl = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.objectSize = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteObjectSpec {
    return {
      resource: isSet(object.resource) ? Object.fromJSON(object.resource) : undefined,
      predefinedAcl: isSet(object.predefinedAcl) ? globalThis.String(object.predefinedAcl) : "",
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      objectSize: isSet(object.objectSize) ? Long.fromValue(object.objectSize) : undefined,
    };
  },

  toJSON(message: WriteObjectSpec): unknown {
    const obj: any = {};
    if (message.resource !== undefined) {
      obj.resource = Object.toJSON(message.resource);
    }
    if (message.predefinedAcl !== "") {
      obj.predefinedAcl = message.predefinedAcl;
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.objectSize !== undefined) {
      obj.objectSize = (message.objectSize || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<WriteObjectSpec>): WriteObjectSpec {
    return WriteObjectSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteObjectSpec>): WriteObjectSpec {
    const message = createBaseWriteObjectSpec();
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Object.fromPartial(object.resource)
      : undefined;
    message.predefinedAcl = object.predefinedAcl ?? "";
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.objectSize = (object.objectSize !== undefined && object.objectSize !== null)
      ? Long.fromValue(object.objectSize)
      : undefined;
    return message;
  },
};

function createBaseWriteObjectRequest(): WriteObjectRequest {
  return {
    uploadId: undefined,
    writeObjectSpec: undefined,
    writeOffset: Long.ZERO,
    checksummedData: undefined,
    objectChecksums: undefined,
    finishWrite: false,
    commonObjectRequestParams: undefined,
  };
}

export const WriteObjectRequest: MessageFns<WriteObjectRequest> = {
  encode(message: WriteObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadId !== undefined) {
      writer.uint32(10).string(message.uploadId);
    }
    if (message.writeObjectSpec !== undefined) {
      WriteObjectSpec.encode(message.writeObjectSpec, writer.uint32(18).fork()).join();
    }
    if (!message.writeOffset.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.writeOffset.toString());
    }
    if (message.checksummedData !== undefined) {
      ChecksummedData.encode(message.checksummedData, writer.uint32(34).fork()).join();
    }
    if (message.objectChecksums !== undefined) {
      ObjectChecksums.encode(message.objectChecksums, writer.uint32(50).fork()).join();
    }
    if (message.finishWrite !== false) {
      writer.uint32(56).bool(message.finishWrite);
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.writeObjectSpec = WriteObjectSpec.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.writeOffset = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.checksummedData = ChecksummedData.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.objectChecksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.finishWrite = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteObjectRequest {
    return {
      uploadId: isSet(object.uploadId) ? globalThis.String(object.uploadId) : undefined,
      writeObjectSpec: isSet(object.writeObjectSpec) ? WriteObjectSpec.fromJSON(object.writeObjectSpec) : undefined,
      writeOffset: isSet(object.writeOffset) ? Long.fromValue(object.writeOffset) : Long.ZERO,
      checksummedData: isSet(object.checksummedData) ? ChecksummedData.fromJSON(object.checksummedData) : undefined,
      objectChecksums: isSet(object.objectChecksums) ? ObjectChecksums.fromJSON(object.objectChecksums) : undefined,
      finishWrite: isSet(object.finishWrite) ? globalThis.Boolean(object.finishWrite) : false,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
    };
  },

  toJSON(message: WriteObjectRequest): unknown {
    const obj: any = {};
    if (message.uploadId !== undefined) {
      obj.uploadId = message.uploadId;
    }
    if (message.writeObjectSpec !== undefined) {
      obj.writeObjectSpec = WriteObjectSpec.toJSON(message.writeObjectSpec);
    }
    if (!message.writeOffset.equals(Long.ZERO)) {
      obj.writeOffset = (message.writeOffset || Long.ZERO).toString();
    }
    if (message.checksummedData !== undefined) {
      obj.checksummedData = ChecksummedData.toJSON(message.checksummedData);
    }
    if (message.objectChecksums !== undefined) {
      obj.objectChecksums = ObjectChecksums.toJSON(message.objectChecksums);
    }
    if (message.finishWrite !== false) {
      obj.finishWrite = message.finishWrite;
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteObjectRequest>): WriteObjectRequest {
    return WriteObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteObjectRequest>): WriteObjectRequest {
    const message = createBaseWriteObjectRequest();
    message.uploadId = object.uploadId ?? undefined;
    message.writeObjectSpec = (object.writeObjectSpec !== undefined && object.writeObjectSpec !== null)
      ? WriteObjectSpec.fromPartial(object.writeObjectSpec)
      : undefined;
    message.writeOffset = (object.writeOffset !== undefined && object.writeOffset !== null)
      ? Long.fromValue(object.writeOffset)
      : Long.ZERO;
    message.checksummedData = (object.checksummedData !== undefined && object.checksummedData !== null)
      ? ChecksummedData.fromPartial(object.checksummedData)
      : undefined;
    message.objectChecksums = (object.objectChecksums !== undefined && object.objectChecksums !== null)
      ? ObjectChecksums.fromPartial(object.objectChecksums)
      : undefined;
    message.finishWrite = object.finishWrite ?? false;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    return message;
  },
};

function createBaseWriteObjectResponse(): WriteObjectResponse {
  return { persistedSize: undefined, resource: undefined };
}

export const WriteObjectResponse: MessageFns<WriteObjectResponse> = {
  encode(message: WriteObjectResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.persistedSize !== undefined) {
      writer.uint32(8).int64(message.persistedSize.toString());
    }
    if (message.resource !== undefined) {
      Object.encode(message.resource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteObjectResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteObjectResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.persistedSize = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resource = Object.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteObjectResponse {
    return {
      persistedSize: isSet(object.persistedSize) ? Long.fromValue(object.persistedSize) : undefined,
      resource: isSet(object.resource) ? Object.fromJSON(object.resource) : undefined,
    };
  },

  toJSON(message: WriteObjectResponse): unknown {
    const obj: any = {};
    if (message.persistedSize !== undefined) {
      obj.persistedSize = (message.persistedSize || Long.ZERO).toString();
    }
    if (message.resource !== undefined) {
      obj.resource = Object.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteObjectResponse>): WriteObjectResponse {
    return WriteObjectResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteObjectResponse>): WriteObjectResponse {
    const message = createBaseWriteObjectResponse();
    message.persistedSize = (object.persistedSize !== undefined && object.persistedSize !== null)
      ? Long.fromValue(object.persistedSize)
      : undefined;
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Object.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseBidiWriteObjectRequest(): BidiWriteObjectRequest {
  return {
    uploadId: undefined,
    writeObjectSpec: undefined,
    writeOffset: Long.ZERO,
    checksummedData: undefined,
    objectChecksums: undefined,
    stateLookup: false,
    flush: false,
    finishWrite: false,
    commonObjectRequestParams: undefined,
  };
}

export const BidiWriteObjectRequest: MessageFns<BidiWriteObjectRequest> = {
  encode(message: BidiWriteObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadId !== undefined) {
      writer.uint32(10).string(message.uploadId);
    }
    if (message.writeObjectSpec !== undefined) {
      WriteObjectSpec.encode(message.writeObjectSpec, writer.uint32(18).fork()).join();
    }
    if (!message.writeOffset.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.writeOffset.toString());
    }
    if (message.checksummedData !== undefined) {
      ChecksummedData.encode(message.checksummedData, writer.uint32(34).fork()).join();
    }
    if (message.objectChecksums !== undefined) {
      ObjectChecksums.encode(message.objectChecksums, writer.uint32(50).fork()).join();
    }
    if (message.stateLookup !== false) {
      writer.uint32(56).bool(message.stateLookup);
    }
    if (message.flush !== false) {
      writer.uint32(64).bool(message.flush);
    }
    if (message.finishWrite !== false) {
      writer.uint32(72).bool(message.finishWrite);
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BidiWriteObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBidiWriteObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.writeObjectSpec = WriteObjectSpec.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.writeOffset = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.checksummedData = ChecksummedData.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.objectChecksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.stateLookup = reader.bool();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.flush = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.finishWrite = reader.bool();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BidiWriteObjectRequest {
    return {
      uploadId: isSet(object.uploadId) ? globalThis.String(object.uploadId) : undefined,
      writeObjectSpec: isSet(object.writeObjectSpec) ? WriteObjectSpec.fromJSON(object.writeObjectSpec) : undefined,
      writeOffset: isSet(object.writeOffset) ? Long.fromValue(object.writeOffset) : Long.ZERO,
      checksummedData: isSet(object.checksummedData) ? ChecksummedData.fromJSON(object.checksummedData) : undefined,
      objectChecksums: isSet(object.objectChecksums) ? ObjectChecksums.fromJSON(object.objectChecksums) : undefined,
      stateLookup: isSet(object.stateLookup) ? globalThis.Boolean(object.stateLookup) : false,
      flush: isSet(object.flush) ? globalThis.Boolean(object.flush) : false,
      finishWrite: isSet(object.finishWrite) ? globalThis.Boolean(object.finishWrite) : false,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
    };
  },

  toJSON(message: BidiWriteObjectRequest): unknown {
    const obj: any = {};
    if (message.uploadId !== undefined) {
      obj.uploadId = message.uploadId;
    }
    if (message.writeObjectSpec !== undefined) {
      obj.writeObjectSpec = WriteObjectSpec.toJSON(message.writeObjectSpec);
    }
    if (!message.writeOffset.equals(Long.ZERO)) {
      obj.writeOffset = (message.writeOffset || Long.ZERO).toString();
    }
    if (message.checksummedData !== undefined) {
      obj.checksummedData = ChecksummedData.toJSON(message.checksummedData);
    }
    if (message.objectChecksums !== undefined) {
      obj.objectChecksums = ObjectChecksums.toJSON(message.objectChecksums);
    }
    if (message.stateLookup !== false) {
      obj.stateLookup = message.stateLookup;
    }
    if (message.flush !== false) {
      obj.flush = message.flush;
    }
    if (message.finishWrite !== false) {
      obj.finishWrite = message.finishWrite;
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    return obj;
  },

  create(base?: DeepPartial<BidiWriteObjectRequest>): BidiWriteObjectRequest {
    return BidiWriteObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BidiWriteObjectRequest>): BidiWriteObjectRequest {
    const message = createBaseBidiWriteObjectRequest();
    message.uploadId = object.uploadId ?? undefined;
    message.writeObjectSpec = (object.writeObjectSpec !== undefined && object.writeObjectSpec !== null)
      ? WriteObjectSpec.fromPartial(object.writeObjectSpec)
      : undefined;
    message.writeOffset = (object.writeOffset !== undefined && object.writeOffset !== null)
      ? Long.fromValue(object.writeOffset)
      : Long.ZERO;
    message.checksummedData = (object.checksummedData !== undefined && object.checksummedData !== null)
      ? ChecksummedData.fromPartial(object.checksummedData)
      : undefined;
    message.objectChecksums = (object.objectChecksums !== undefined && object.objectChecksums !== null)
      ? ObjectChecksums.fromPartial(object.objectChecksums)
      : undefined;
    message.stateLookup = object.stateLookup ?? false;
    message.flush = object.flush ?? false;
    message.finishWrite = object.finishWrite ?? false;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    return message;
  },
};

function createBaseBidiWriteObjectResponse(): BidiWriteObjectResponse {
  return { persistedSize: undefined, resource: undefined };
}

export const BidiWriteObjectResponse: MessageFns<BidiWriteObjectResponse> = {
  encode(message: BidiWriteObjectResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.persistedSize !== undefined) {
      writer.uint32(8).int64(message.persistedSize.toString());
    }
    if (message.resource !== undefined) {
      Object.encode(message.resource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BidiWriteObjectResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBidiWriteObjectResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.persistedSize = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resource = Object.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BidiWriteObjectResponse {
    return {
      persistedSize: isSet(object.persistedSize) ? Long.fromValue(object.persistedSize) : undefined,
      resource: isSet(object.resource) ? Object.fromJSON(object.resource) : undefined,
    };
  },

  toJSON(message: BidiWriteObjectResponse): unknown {
    const obj: any = {};
    if (message.persistedSize !== undefined) {
      obj.persistedSize = (message.persistedSize || Long.ZERO).toString();
    }
    if (message.resource !== undefined) {
      obj.resource = Object.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<BidiWriteObjectResponse>): BidiWriteObjectResponse {
    return BidiWriteObjectResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BidiWriteObjectResponse>): BidiWriteObjectResponse {
    const message = createBaseBidiWriteObjectResponse();
    message.persistedSize = (object.persistedSize !== undefined && object.persistedSize !== null)
      ? Long.fromValue(object.persistedSize)
      : undefined;
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Object.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseListObjectsRequest(): ListObjectsRequest {
  return {
    parent: "",
    pageSize: 0,
    pageToken: "",
    delimiter: "",
    includeTrailingDelimiter: false,
    prefix: "",
    versions: false,
    readMask: undefined,
    lexicographicStart: "",
    lexicographicEnd: "",
    softDeleted: false,
    includeFoldersAsPrefixes: false,
    matchGlob: "",
  };
}

export const ListObjectsRequest: MessageFns<ListObjectsRequest> = {
  encode(message: ListObjectsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.delimiter !== "") {
      writer.uint32(34).string(message.delimiter);
    }
    if (message.includeTrailingDelimiter !== false) {
      writer.uint32(40).bool(message.includeTrailingDelimiter);
    }
    if (message.prefix !== "") {
      writer.uint32(50).string(message.prefix);
    }
    if (message.versions !== false) {
      writer.uint32(56).bool(message.versions);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(66).fork()).join();
    }
    if (message.lexicographicStart !== "") {
      writer.uint32(82).string(message.lexicographicStart);
    }
    if (message.lexicographicEnd !== "") {
      writer.uint32(90).string(message.lexicographicEnd);
    }
    if (message.softDeleted !== false) {
      writer.uint32(96).bool(message.softDeleted);
    }
    if (message.includeFoldersAsPrefixes !== false) {
      writer.uint32(104).bool(message.includeFoldersAsPrefixes);
    }
    if (message.matchGlob !== "") {
      writer.uint32(114).string(message.matchGlob);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListObjectsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListObjectsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.delimiter = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.includeTrailingDelimiter = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.prefix = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.versions = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.lexicographicStart = reader.string();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.lexicographicEnd = reader.string();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.softDeleted = reader.bool();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.includeFoldersAsPrefixes = reader.bool();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.matchGlob = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListObjectsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
      includeTrailingDelimiter: isSet(object.includeTrailingDelimiter)
        ? globalThis.Boolean(object.includeTrailingDelimiter)
        : false,
      prefix: isSet(object.prefix) ? globalThis.String(object.prefix) : "",
      versions: isSet(object.versions) ? globalThis.Boolean(object.versions) : false,
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
      lexicographicStart: isSet(object.lexicographicStart) ? globalThis.String(object.lexicographicStart) : "",
      lexicographicEnd: isSet(object.lexicographicEnd) ? globalThis.String(object.lexicographicEnd) : "",
      softDeleted: isSet(object.softDeleted) ? globalThis.Boolean(object.softDeleted) : false,
      includeFoldersAsPrefixes: isSet(object.includeFoldersAsPrefixes)
        ? globalThis.Boolean(object.includeFoldersAsPrefixes)
        : false,
      matchGlob: isSet(object.matchGlob) ? globalThis.String(object.matchGlob) : "",
    };
  },

  toJSON(message: ListObjectsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    if (message.includeTrailingDelimiter !== false) {
      obj.includeTrailingDelimiter = message.includeTrailingDelimiter;
    }
    if (message.prefix !== "") {
      obj.prefix = message.prefix;
    }
    if (message.versions !== false) {
      obj.versions = message.versions;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    if (message.lexicographicStart !== "") {
      obj.lexicographicStart = message.lexicographicStart;
    }
    if (message.lexicographicEnd !== "") {
      obj.lexicographicEnd = message.lexicographicEnd;
    }
    if (message.softDeleted !== false) {
      obj.softDeleted = message.softDeleted;
    }
    if (message.includeFoldersAsPrefixes !== false) {
      obj.includeFoldersAsPrefixes = message.includeFoldersAsPrefixes;
    }
    if (message.matchGlob !== "") {
      obj.matchGlob = message.matchGlob;
    }
    return obj;
  },

  create(base?: DeepPartial<ListObjectsRequest>): ListObjectsRequest {
    return ListObjectsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListObjectsRequest>): ListObjectsRequest {
    const message = createBaseListObjectsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.delimiter = object.delimiter ?? "";
    message.includeTrailingDelimiter = object.includeTrailingDelimiter ?? false;
    message.prefix = object.prefix ?? "";
    message.versions = object.versions ?? false;
    message.readMask = object.readMask ?? undefined;
    message.lexicographicStart = object.lexicographicStart ?? "";
    message.lexicographicEnd = object.lexicographicEnd ?? "";
    message.softDeleted = object.softDeleted ?? false;
    message.includeFoldersAsPrefixes = object.includeFoldersAsPrefixes ?? false;
    message.matchGlob = object.matchGlob ?? "";
    return message;
  },
};

function createBaseQueryWriteStatusRequest(): QueryWriteStatusRequest {
  return { uploadId: "", commonObjectRequestParams: undefined };
}

export const QueryWriteStatusRequest: MessageFns<QueryWriteStatusRequest> = {
  encode(message: QueryWriteStatusRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadId !== "") {
      writer.uint32(10).string(message.uploadId);
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryWriteStatusRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryWriteStatusRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryWriteStatusRequest {
    return {
      uploadId: isSet(object.uploadId) ? globalThis.String(object.uploadId) : "",
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
    };
  },

  toJSON(message: QueryWriteStatusRequest): unknown {
    const obj: any = {};
    if (message.uploadId !== "") {
      obj.uploadId = message.uploadId;
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryWriteStatusRequest>): QueryWriteStatusRequest {
    return QueryWriteStatusRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryWriteStatusRequest>): QueryWriteStatusRequest {
    const message = createBaseQueryWriteStatusRequest();
    message.uploadId = object.uploadId ?? "";
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    return message;
  },
};

function createBaseQueryWriteStatusResponse(): QueryWriteStatusResponse {
  return { persistedSize: undefined, resource: undefined };
}

export const QueryWriteStatusResponse: MessageFns<QueryWriteStatusResponse> = {
  encode(message: QueryWriteStatusResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.persistedSize !== undefined) {
      writer.uint32(8).int64(message.persistedSize.toString());
    }
    if (message.resource !== undefined) {
      Object.encode(message.resource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryWriteStatusResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryWriteStatusResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.persistedSize = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.resource = Object.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryWriteStatusResponse {
    return {
      persistedSize: isSet(object.persistedSize) ? Long.fromValue(object.persistedSize) : undefined,
      resource: isSet(object.resource) ? Object.fromJSON(object.resource) : undefined,
    };
  },

  toJSON(message: QueryWriteStatusResponse): unknown {
    const obj: any = {};
    if (message.persistedSize !== undefined) {
      obj.persistedSize = (message.persistedSize || Long.ZERO).toString();
    }
    if (message.resource !== undefined) {
      obj.resource = Object.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryWriteStatusResponse>): QueryWriteStatusResponse {
    return QueryWriteStatusResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryWriteStatusResponse>): QueryWriteStatusResponse {
    const message = createBaseQueryWriteStatusResponse();
    message.persistedSize = (object.persistedSize !== undefined && object.persistedSize !== null)
      ? Long.fromValue(object.persistedSize)
      : undefined;
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Object.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseRewriteObjectRequest(): RewriteObjectRequest {
  return {
    destinationName: "",
    destinationBucket: "",
    destinationKmsKey: "",
    destination: undefined,
    sourceBucket: "",
    sourceObject: "",
    sourceGeneration: Long.ZERO,
    rewriteToken: "",
    destinationPredefinedAcl: "",
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    ifSourceGenerationMatch: undefined,
    ifSourceGenerationNotMatch: undefined,
    ifSourceMetagenerationMatch: undefined,
    ifSourceMetagenerationNotMatch: undefined,
    maxBytesRewrittenPerCall: Long.ZERO,
    copySourceEncryptionAlgorithm: "",
    copySourceEncryptionKeyBytes: Buffer.alloc(0),
    copySourceEncryptionKeySha256Bytes: Buffer.alloc(0),
    commonObjectRequestParams: undefined,
    objectChecksums: undefined,
  };
}

export const RewriteObjectRequest: MessageFns<RewriteObjectRequest> = {
  encode(message: RewriteObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destinationName !== "") {
      writer.uint32(194).string(message.destinationName);
    }
    if (message.destinationBucket !== "") {
      writer.uint32(202).string(message.destinationBucket);
    }
    if (message.destinationKmsKey !== "") {
      writer.uint32(218).string(message.destinationKmsKey);
    }
    if (message.destination !== undefined) {
      Object.encode(message.destination, writer.uint32(10).fork()).join();
    }
    if (message.sourceBucket !== "") {
      writer.uint32(18).string(message.sourceBucket);
    }
    if (message.sourceObject !== "") {
      writer.uint32(26).string(message.sourceObject);
    }
    if (!message.sourceGeneration.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.sourceGeneration.toString());
    }
    if (message.rewriteToken !== "") {
      writer.uint32(42).string(message.rewriteToken);
    }
    if (message.destinationPredefinedAcl !== "") {
      writer.uint32(226).string(message.destinationPredefinedAcl);
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(56).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(64).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(72).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(80).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.ifSourceGenerationMatch !== undefined) {
      writer.uint32(88).int64(message.ifSourceGenerationMatch.toString());
    }
    if (message.ifSourceGenerationNotMatch !== undefined) {
      writer.uint32(96).int64(message.ifSourceGenerationNotMatch.toString());
    }
    if (message.ifSourceMetagenerationMatch !== undefined) {
      writer.uint32(104).int64(message.ifSourceMetagenerationMatch.toString());
    }
    if (message.ifSourceMetagenerationNotMatch !== undefined) {
      writer.uint32(112).int64(message.ifSourceMetagenerationNotMatch.toString());
    }
    if (!message.maxBytesRewrittenPerCall.equals(Long.ZERO)) {
      writer.uint32(120).int64(message.maxBytesRewrittenPerCall.toString());
    }
    if (message.copySourceEncryptionAlgorithm !== "") {
      writer.uint32(130).string(message.copySourceEncryptionAlgorithm);
    }
    if (message.copySourceEncryptionKeyBytes.length !== 0) {
      writer.uint32(170).bytes(message.copySourceEncryptionKeyBytes);
    }
    if (message.copySourceEncryptionKeySha256Bytes.length !== 0) {
      writer.uint32(178).bytes(message.copySourceEncryptionKeySha256Bytes);
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(154).fork()).join();
    }
    if (message.objectChecksums !== undefined) {
      ObjectChecksums.encode(message.objectChecksums, writer.uint32(234).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RewriteObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRewriteObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 24:
          if (tag !== 194) {
            break;
          }

          message.destinationName = reader.string();
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.destinationBucket = reader.string();
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.destinationKmsKey = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.destination = Object.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceBucket = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sourceObject = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.sourceGeneration = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.rewriteToken = reader.string();
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.destinationPredefinedAcl = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.ifSourceGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.ifSourceGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.ifSourceMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.ifSourceMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.maxBytesRewrittenPerCall = Long.fromString(reader.int64().toString());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.copySourceEncryptionAlgorithm = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.copySourceEncryptionKeyBytes = Buffer.from(reader.bytes());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.copySourceEncryptionKeySha256Bytes = Buffer.from(reader.bytes());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.objectChecksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RewriteObjectRequest {
    return {
      destinationName: isSet(object.destinationName) ? globalThis.String(object.destinationName) : "",
      destinationBucket: isSet(object.destinationBucket) ? globalThis.String(object.destinationBucket) : "",
      destinationKmsKey: isSet(object.destinationKmsKey) ? globalThis.String(object.destinationKmsKey) : "",
      destination: isSet(object.destination) ? Object.fromJSON(object.destination) : undefined,
      sourceBucket: isSet(object.sourceBucket) ? globalThis.String(object.sourceBucket) : "",
      sourceObject: isSet(object.sourceObject) ? globalThis.String(object.sourceObject) : "",
      sourceGeneration: isSet(object.sourceGeneration) ? Long.fromValue(object.sourceGeneration) : Long.ZERO,
      rewriteToken: isSet(object.rewriteToken) ? globalThis.String(object.rewriteToken) : "",
      destinationPredefinedAcl: isSet(object.destinationPredefinedAcl)
        ? globalThis.String(object.destinationPredefinedAcl)
        : "",
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      ifSourceGenerationMatch: isSet(object.ifSourceGenerationMatch)
        ? Long.fromValue(object.ifSourceGenerationMatch)
        : undefined,
      ifSourceGenerationNotMatch: isSet(object.ifSourceGenerationNotMatch)
        ? Long.fromValue(object.ifSourceGenerationNotMatch)
        : undefined,
      ifSourceMetagenerationMatch: isSet(object.ifSourceMetagenerationMatch)
        ? Long.fromValue(object.ifSourceMetagenerationMatch)
        : undefined,
      ifSourceMetagenerationNotMatch: isSet(object.ifSourceMetagenerationNotMatch)
        ? Long.fromValue(object.ifSourceMetagenerationNotMatch)
        : undefined,
      maxBytesRewrittenPerCall: isSet(object.maxBytesRewrittenPerCall)
        ? Long.fromValue(object.maxBytesRewrittenPerCall)
        : Long.ZERO,
      copySourceEncryptionAlgorithm: isSet(object.copySourceEncryptionAlgorithm)
        ? globalThis.String(object.copySourceEncryptionAlgorithm)
        : "",
      copySourceEncryptionKeyBytes: isSet(object.copySourceEncryptionKeyBytes)
        ? Buffer.from(bytesFromBase64(object.copySourceEncryptionKeyBytes))
        : Buffer.alloc(0),
      copySourceEncryptionKeySha256Bytes: isSet(object.copySourceEncryptionKeySha256Bytes)
        ? Buffer.from(bytesFromBase64(object.copySourceEncryptionKeySha256Bytes))
        : Buffer.alloc(0),
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
      objectChecksums: isSet(object.objectChecksums) ? ObjectChecksums.fromJSON(object.objectChecksums) : undefined,
    };
  },

  toJSON(message: RewriteObjectRequest): unknown {
    const obj: any = {};
    if (message.destinationName !== "") {
      obj.destinationName = message.destinationName;
    }
    if (message.destinationBucket !== "") {
      obj.destinationBucket = message.destinationBucket;
    }
    if (message.destinationKmsKey !== "") {
      obj.destinationKmsKey = message.destinationKmsKey;
    }
    if (message.destination !== undefined) {
      obj.destination = Object.toJSON(message.destination);
    }
    if (message.sourceBucket !== "") {
      obj.sourceBucket = message.sourceBucket;
    }
    if (message.sourceObject !== "") {
      obj.sourceObject = message.sourceObject;
    }
    if (!message.sourceGeneration.equals(Long.ZERO)) {
      obj.sourceGeneration = (message.sourceGeneration || Long.ZERO).toString();
    }
    if (message.rewriteToken !== "") {
      obj.rewriteToken = message.rewriteToken;
    }
    if (message.destinationPredefinedAcl !== "") {
      obj.destinationPredefinedAcl = message.destinationPredefinedAcl;
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifSourceGenerationMatch !== undefined) {
      obj.ifSourceGenerationMatch = (message.ifSourceGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifSourceGenerationNotMatch !== undefined) {
      obj.ifSourceGenerationNotMatch = (message.ifSourceGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifSourceMetagenerationMatch !== undefined) {
      obj.ifSourceMetagenerationMatch = (message.ifSourceMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifSourceMetagenerationNotMatch !== undefined) {
      obj.ifSourceMetagenerationNotMatch = (message.ifSourceMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (!message.maxBytesRewrittenPerCall.equals(Long.ZERO)) {
      obj.maxBytesRewrittenPerCall = (message.maxBytesRewrittenPerCall || Long.ZERO).toString();
    }
    if (message.copySourceEncryptionAlgorithm !== "") {
      obj.copySourceEncryptionAlgorithm = message.copySourceEncryptionAlgorithm;
    }
    if (message.copySourceEncryptionKeyBytes.length !== 0) {
      obj.copySourceEncryptionKeyBytes = base64FromBytes(message.copySourceEncryptionKeyBytes);
    }
    if (message.copySourceEncryptionKeySha256Bytes.length !== 0) {
      obj.copySourceEncryptionKeySha256Bytes = base64FromBytes(message.copySourceEncryptionKeySha256Bytes);
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    if (message.objectChecksums !== undefined) {
      obj.objectChecksums = ObjectChecksums.toJSON(message.objectChecksums);
    }
    return obj;
  },

  create(base?: DeepPartial<RewriteObjectRequest>): RewriteObjectRequest {
    return RewriteObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RewriteObjectRequest>): RewriteObjectRequest {
    const message = createBaseRewriteObjectRequest();
    message.destinationName = object.destinationName ?? "";
    message.destinationBucket = object.destinationBucket ?? "";
    message.destinationKmsKey = object.destinationKmsKey ?? "";
    message.destination = (object.destination !== undefined && object.destination !== null)
      ? Object.fromPartial(object.destination)
      : undefined;
    message.sourceBucket = object.sourceBucket ?? "";
    message.sourceObject = object.sourceObject ?? "";
    message.sourceGeneration = (object.sourceGeneration !== undefined && object.sourceGeneration !== null)
      ? Long.fromValue(object.sourceGeneration)
      : Long.ZERO;
    message.rewriteToken = object.rewriteToken ?? "";
    message.destinationPredefinedAcl = object.destinationPredefinedAcl ?? "";
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.ifSourceGenerationMatch =
      (object.ifSourceGenerationMatch !== undefined && object.ifSourceGenerationMatch !== null)
        ? Long.fromValue(object.ifSourceGenerationMatch)
        : undefined;
    message.ifSourceGenerationNotMatch =
      (object.ifSourceGenerationNotMatch !== undefined && object.ifSourceGenerationNotMatch !== null)
        ? Long.fromValue(object.ifSourceGenerationNotMatch)
        : undefined;
    message.ifSourceMetagenerationMatch =
      (object.ifSourceMetagenerationMatch !== undefined && object.ifSourceMetagenerationMatch !== null)
        ? Long.fromValue(object.ifSourceMetagenerationMatch)
        : undefined;
    message.ifSourceMetagenerationNotMatch =
      (object.ifSourceMetagenerationNotMatch !== undefined && object.ifSourceMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifSourceMetagenerationNotMatch)
        : undefined;
    message.maxBytesRewrittenPerCall =
      (object.maxBytesRewrittenPerCall !== undefined && object.maxBytesRewrittenPerCall !== null)
        ? Long.fromValue(object.maxBytesRewrittenPerCall)
        : Long.ZERO;
    message.copySourceEncryptionAlgorithm = object.copySourceEncryptionAlgorithm ?? "";
    message.copySourceEncryptionKeyBytes = object.copySourceEncryptionKeyBytes ?? Buffer.alloc(0);
    message.copySourceEncryptionKeySha256Bytes = object.copySourceEncryptionKeySha256Bytes ?? Buffer.alloc(0);
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    message.objectChecksums = (object.objectChecksums !== undefined && object.objectChecksums !== null)
      ? ObjectChecksums.fromPartial(object.objectChecksums)
      : undefined;
    return message;
  },
};

function createBaseRewriteResponse(): RewriteResponse {
  return { totalBytesRewritten: Long.ZERO, objectSize: Long.ZERO, done: false, rewriteToken: "", resource: undefined };
}

export const RewriteResponse: MessageFns<RewriteResponse> = {
  encode(message: RewriteResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.totalBytesRewritten.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.totalBytesRewritten.toString());
    }
    if (!message.objectSize.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.objectSize.toString());
    }
    if (message.done !== false) {
      writer.uint32(24).bool(message.done);
    }
    if (message.rewriteToken !== "") {
      writer.uint32(34).string(message.rewriteToken);
    }
    if (message.resource !== undefined) {
      Object.encode(message.resource, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RewriteResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRewriteResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.totalBytesRewritten = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.objectSize = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.done = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.rewriteToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.resource = Object.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RewriteResponse {
    return {
      totalBytesRewritten: isSet(object.totalBytesRewritten) ? Long.fromValue(object.totalBytesRewritten) : Long.ZERO,
      objectSize: isSet(object.objectSize) ? Long.fromValue(object.objectSize) : Long.ZERO,
      done: isSet(object.done) ? globalThis.Boolean(object.done) : false,
      rewriteToken: isSet(object.rewriteToken) ? globalThis.String(object.rewriteToken) : "",
      resource: isSet(object.resource) ? Object.fromJSON(object.resource) : undefined,
    };
  },

  toJSON(message: RewriteResponse): unknown {
    const obj: any = {};
    if (!message.totalBytesRewritten.equals(Long.ZERO)) {
      obj.totalBytesRewritten = (message.totalBytesRewritten || Long.ZERO).toString();
    }
    if (!message.objectSize.equals(Long.ZERO)) {
      obj.objectSize = (message.objectSize || Long.ZERO).toString();
    }
    if (message.done !== false) {
      obj.done = message.done;
    }
    if (message.rewriteToken !== "") {
      obj.rewriteToken = message.rewriteToken;
    }
    if (message.resource !== undefined) {
      obj.resource = Object.toJSON(message.resource);
    }
    return obj;
  },

  create(base?: DeepPartial<RewriteResponse>): RewriteResponse {
    return RewriteResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RewriteResponse>): RewriteResponse {
    const message = createBaseRewriteResponse();
    message.totalBytesRewritten = (object.totalBytesRewritten !== undefined && object.totalBytesRewritten !== null)
      ? Long.fromValue(object.totalBytesRewritten)
      : Long.ZERO;
    message.objectSize = (object.objectSize !== undefined && object.objectSize !== null)
      ? Long.fromValue(object.objectSize)
      : Long.ZERO;
    message.done = object.done ?? false;
    message.rewriteToken = object.rewriteToken ?? "";
    message.resource = (object.resource !== undefined && object.resource !== null)
      ? Object.fromPartial(object.resource)
      : undefined;
    return message;
  },
};

function createBaseStartResumableWriteRequest(): StartResumableWriteRequest {
  return { writeObjectSpec: undefined, commonObjectRequestParams: undefined, objectChecksums: undefined };
}

export const StartResumableWriteRequest: MessageFns<StartResumableWriteRequest> = {
  encode(message: StartResumableWriteRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.writeObjectSpec !== undefined) {
      WriteObjectSpec.encode(message.writeObjectSpec, writer.uint32(10).fork()).join();
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(26).fork()).join();
    }
    if (message.objectChecksums !== undefined) {
      ObjectChecksums.encode(message.objectChecksums, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StartResumableWriteRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStartResumableWriteRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.writeObjectSpec = WriteObjectSpec.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.objectChecksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StartResumableWriteRequest {
    return {
      writeObjectSpec: isSet(object.writeObjectSpec) ? WriteObjectSpec.fromJSON(object.writeObjectSpec) : undefined,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
      objectChecksums: isSet(object.objectChecksums) ? ObjectChecksums.fromJSON(object.objectChecksums) : undefined,
    };
  },

  toJSON(message: StartResumableWriteRequest): unknown {
    const obj: any = {};
    if (message.writeObjectSpec !== undefined) {
      obj.writeObjectSpec = WriteObjectSpec.toJSON(message.writeObjectSpec);
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    if (message.objectChecksums !== undefined) {
      obj.objectChecksums = ObjectChecksums.toJSON(message.objectChecksums);
    }
    return obj;
  },

  create(base?: DeepPartial<StartResumableWriteRequest>): StartResumableWriteRequest {
    return StartResumableWriteRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StartResumableWriteRequest>): StartResumableWriteRequest {
    const message = createBaseStartResumableWriteRequest();
    message.writeObjectSpec = (object.writeObjectSpec !== undefined && object.writeObjectSpec !== null)
      ? WriteObjectSpec.fromPartial(object.writeObjectSpec)
      : undefined;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    message.objectChecksums = (object.objectChecksums !== undefined && object.objectChecksums !== null)
      ? ObjectChecksums.fromPartial(object.objectChecksums)
      : undefined;
    return message;
  },
};

function createBaseStartResumableWriteResponse(): StartResumableWriteResponse {
  return { uploadId: "" };
}

export const StartResumableWriteResponse: MessageFns<StartResumableWriteResponse> = {
  encode(message: StartResumableWriteResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uploadId !== "") {
      writer.uint32(10).string(message.uploadId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StartResumableWriteResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStartResumableWriteResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uploadId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StartResumableWriteResponse {
    return { uploadId: isSet(object.uploadId) ? globalThis.String(object.uploadId) : "" };
  },

  toJSON(message: StartResumableWriteResponse): unknown {
    const obj: any = {};
    if (message.uploadId !== "") {
      obj.uploadId = message.uploadId;
    }
    return obj;
  },

  create(base?: DeepPartial<StartResumableWriteResponse>): StartResumableWriteResponse {
    return StartResumableWriteResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StartResumableWriteResponse>): StartResumableWriteResponse {
    const message = createBaseStartResumableWriteResponse();
    message.uploadId = object.uploadId ?? "";
    return message;
  },
};

function createBaseUpdateObjectRequest(): UpdateObjectRequest {
  return {
    object: undefined,
    ifGenerationMatch: undefined,
    ifGenerationNotMatch: undefined,
    ifMetagenerationMatch: undefined,
    ifMetagenerationNotMatch: undefined,
    predefinedAcl: "",
    updateMask: undefined,
    commonObjectRequestParams: undefined,
  };
}

export const UpdateObjectRequest: MessageFns<UpdateObjectRequest> = {
  encode(message: UpdateObjectRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.object !== undefined) {
      Object.encode(message.object, writer.uint32(10).fork()).join();
    }
    if (message.ifGenerationMatch !== undefined) {
      writer.uint32(16).int64(message.ifGenerationMatch.toString());
    }
    if (message.ifGenerationNotMatch !== undefined) {
      writer.uint32(24).int64(message.ifGenerationNotMatch.toString());
    }
    if (message.ifMetagenerationMatch !== undefined) {
      writer.uint32(32).int64(message.ifMetagenerationMatch.toString());
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      writer.uint32(40).int64(message.ifMetagenerationNotMatch.toString());
    }
    if (message.predefinedAcl !== "") {
      writer.uint32(82).string(message.predefinedAcl);
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(58).fork()).join();
    }
    if (message.commonObjectRequestParams !== undefined) {
      CommonObjectRequestParams.encode(message.commonObjectRequestParams, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateObjectRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateObjectRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.object = Object.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.ifGenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ifGenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.ifMetagenerationMatch = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.ifMetagenerationNotMatch = Long.fromString(reader.int64().toString());
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.predefinedAcl = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.commonObjectRequestParams = CommonObjectRequestParams.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateObjectRequest {
    return {
      object: isSet(object.object) ? Object.fromJSON(object.object) : undefined,
      ifGenerationMatch: isSet(object.ifGenerationMatch) ? Long.fromValue(object.ifGenerationMatch) : undefined,
      ifGenerationNotMatch: isSet(object.ifGenerationNotMatch)
        ? Long.fromValue(object.ifGenerationNotMatch)
        : undefined,
      ifMetagenerationMatch: isSet(object.ifMetagenerationMatch)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined,
      ifMetagenerationNotMatch: isSet(object.ifMetagenerationNotMatch)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined,
      predefinedAcl: isSet(object.predefinedAcl) ? globalThis.String(object.predefinedAcl) : "",
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      commonObjectRequestParams: isSet(object.commonObjectRequestParams)
        ? CommonObjectRequestParams.fromJSON(object.commonObjectRequestParams)
        : undefined,
    };
  },

  toJSON(message: UpdateObjectRequest): unknown {
    const obj: any = {};
    if (message.object !== undefined) {
      obj.object = Object.toJSON(message.object);
    }
    if (message.ifGenerationMatch !== undefined) {
      obj.ifGenerationMatch = (message.ifGenerationMatch || Long.ZERO).toString();
    }
    if (message.ifGenerationNotMatch !== undefined) {
      obj.ifGenerationNotMatch = (message.ifGenerationNotMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationMatch !== undefined) {
      obj.ifMetagenerationMatch = (message.ifMetagenerationMatch || Long.ZERO).toString();
    }
    if (message.ifMetagenerationNotMatch !== undefined) {
      obj.ifMetagenerationNotMatch = (message.ifMetagenerationNotMatch || Long.ZERO).toString();
    }
    if (message.predefinedAcl !== "") {
      obj.predefinedAcl = message.predefinedAcl;
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.commonObjectRequestParams !== undefined) {
      obj.commonObjectRequestParams = CommonObjectRequestParams.toJSON(message.commonObjectRequestParams);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateObjectRequest>): UpdateObjectRequest {
    return UpdateObjectRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateObjectRequest>): UpdateObjectRequest {
    const message = createBaseUpdateObjectRequest();
    message.object = (object.object !== undefined && object.object !== null)
      ? Object.fromPartial(object.object)
      : undefined;
    message.ifGenerationMatch = (object.ifGenerationMatch !== undefined && object.ifGenerationMatch !== null)
      ? Long.fromValue(object.ifGenerationMatch)
      : undefined;
    message.ifGenerationNotMatch = (object.ifGenerationNotMatch !== undefined && object.ifGenerationNotMatch !== null)
      ? Long.fromValue(object.ifGenerationNotMatch)
      : undefined;
    message.ifMetagenerationMatch =
      (object.ifMetagenerationMatch !== undefined && object.ifMetagenerationMatch !== null)
        ? Long.fromValue(object.ifMetagenerationMatch)
        : undefined;
    message.ifMetagenerationNotMatch =
      (object.ifMetagenerationNotMatch !== undefined && object.ifMetagenerationNotMatch !== null)
        ? Long.fromValue(object.ifMetagenerationNotMatch)
        : undefined;
    message.predefinedAcl = object.predefinedAcl ?? "";
    message.updateMask = object.updateMask ?? undefined;
    message.commonObjectRequestParams =
      (object.commonObjectRequestParams !== undefined && object.commonObjectRequestParams !== null)
        ? CommonObjectRequestParams.fromPartial(object.commonObjectRequestParams)
        : undefined;
    return message;
  },
};

function createBaseGetServiceAccountRequest(): GetServiceAccountRequest {
  return { project: "" };
}

export const GetServiceAccountRequest: MessageFns<GetServiceAccountRequest> = {
  encode(message: GetServiceAccountRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetServiceAccountRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetServiceAccountRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetServiceAccountRequest {
    return { project: isSet(object.project) ? globalThis.String(object.project) : "" };
  },

  toJSON(message: GetServiceAccountRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<GetServiceAccountRequest>): GetServiceAccountRequest {
    return GetServiceAccountRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetServiceAccountRequest>): GetServiceAccountRequest {
    const message = createBaseGetServiceAccountRequest();
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseServiceAccount(): ServiceAccount {
  return { emailAddress: "" };
}

export const ServiceAccount: MessageFns<ServiceAccount> = {
  encode(message: ServiceAccount, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.emailAddress !== "") {
      writer.uint32(10).string(message.emailAddress);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceAccount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceAccount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.emailAddress = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceAccount {
    return { emailAddress: isSet(object.emailAddress) ? globalThis.String(object.emailAddress) : "" };
  },

  toJSON(message: ServiceAccount): unknown {
    const obj: any = {};
    if (message.emailAddress !== "") {
      obj.emailAddress = message.emailAddress;
    }
    return obj;
  },

  create(base?: DeepPartial<ServiceAccount>): ServiceAccount {
    return ServiceAccount.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ServiceAccount>): ServiceAccount {
    const message = createBaseServiceAccount();
    message.emailAddress = object.emailAddress ?? "";
    return message;
  },
};

function createBaseCreateHmacKeyRequest(): CreateHmacKeyRequest {
  return { project: "", serviceAccountEmail: "" };
}

export const CreateHmacKeyRequest: MessageFns<CreateHmacKeyRequest> = {
  encode(message: CreateHmacKeyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(18).string(message.serviceAccountEmail);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateHmacKeyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateHmacKeyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateHmacKeyRequest {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
    };
  },

  toJSON(message: CreateHmacKeyRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateHmacKeyRequest>): CreateHmacKeyRequest {
    return CreateHmacKeyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateHmacKeyRequest>): CreateHmacKeyRequest {
    const message = createBaseCreateHmacKeyRequest();
    message.project = object.project ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    return message;
  },
};

function createBaseCreateHmacKeyResponse(): CreateHmacKeyResponse {
  return { metadata: undefined, secretKeyBytes: Buffer.alloc(0) };
}

export const CreateHmacKeyResponse: MessageFns<CreateHmacKeyResponse> = {
  encode(message: CreateHmacKeyResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metadata !== undefined) {
      HmacKeyMetadata.encode(message.metadata, writer.uint32(10).fork()).join();
    }
    if (message.secretKeyBytes.length !== 0) {
      writer.uint32(26).bytes(message.secretKeyBytes);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateHmacKeyResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateHmacKeyResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metadata = HmacKeyMetadata.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secretKeyBytes = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateHmacKeyResponse {
    return {
      metadata: isSet(object.metadata) ? HmacKeyMetadata.fromJSON(object.metadata) : undefined,
      secretKeyBytes: isSet(object.secretKeyBytes)
        ? Buffer.from(bytesFromBase64(object.secretKeyBytes))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: CreateHmacKeyResponse): unknown {
    const obj: any = {};
    if (message.metadata !== undefined) {
      obj.metadata = HmacKeyMetadata.toJSON(message.metadata);
    }
    if (message.secretKeyBytes.length !== 0) {
      obj.secretKeyBytes = base64FromBytes(message.secretKeyBytes);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateHmacKeyResponse>): CreateHmacKeyResponse {
    return CreateHmacKeyResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateHmacKeyResponse>): CreateHmacKeyResponse {
    const message = createBaseCreateHmacKeyResponse();
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? HmacKeyMetadata.fromPartial(object.metadata)
      : undefined;
    message.secretKeyBytes = object.secretKeyBytes ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseDeleteHmacKeyRequest(): DeleteHmacKeyRequest {
  return { accessId: "", project: "" };
}

export const DeleteHmacKeyRequest: MessageFns<DeleteHmacKeyRequest> = {
  encode(message: DeleteHmacKeyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accessId !== "") {
      writer.uint32(10).string(message.accessId);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteHmacKeyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteHmacKeyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.accessId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteHmacKeyRequest {
    return {
      accessId: isSet(object.accessId) ? globalThis.String(object.accessId) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: DeleteHmacKeyRequest): unknown {
    const obj: any = {};
    if (message.accessId !== "") {
      obj.accessId = message.accessId;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteHmacKeyRequest>): DeleteHmacKeyRequest {
    return DeleteHmacKeyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteHmacKeyRequest>): DeleteHmacKeyRequest {
    const message = createBaseDeleteHmacKeyRequest();
    message.accessId = object.accessId ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseGetHmacKeyRequest(): GetHmacKeyRequest {
  return { accessId: "", project: "" };
}

export const GetHmacKeyRequest: MessageFns<GetHmacKeyRequest> = {
  encode(message: GetHmacKeyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accessId !== "") {
      writer.uint32(10).string(message.accessId);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetHmacKeyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetHmacKeyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.accessId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetHmacKeyRequest {
    return {
      accessId: isSet(object.accessId) ? globalThis.String(object.accessId) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
    };
  },

  toJSON(message: GetHmacKeyRequest): unknown {
    const obj: any = {};
    if (message.accessId !== "") {
      obj.accessId = message.accessId;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    return obj;
  },

  create(base?: DeepPartial<GetHmacKeyRequest>): GetHmacKeyRequest {
    return GetHmacKeyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetHmacKeyRequest>): GetHmacKeyRequest {
    const message = createBaseGetHmacKeyRequest();
    message.accessId = object.accessId ?? "";
    message.project = object.project ?? "";
    return message;
  },
};

function createBaseListHmacKeysRequest(): ListHmacKeysRequest {
  return { project: "", pageSize: 0, pageToken: "", serviceAccountEmail: "", showDeletedKeys: false };
}

export const ListHmacKeysRequest: MessageFns<ListHmacKeysRequest> = {
  encode(message: ListHmacKeysRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.project !== "") {
      writer.uint32(10).string(message.project);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(34).string(message.serviceAccountEmail);
    }
    if (message.showDeletedKeys !== false) {
      writer.uint32(40).bool(message.showDeletedKeys);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListHmacKeysRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListHmacKeysRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.project = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.showDeletedKeys = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListHmacKeysRequest {
    return {
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      showDeletedKeys: isSet(object.showDeletedKeys) ? globalThis.Boolean(object.showDeletedKeys) : false,
    };
  },

  toJSON(message: ListHmacKeysRequest): unknown {
    const obj: any = {};
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.showDeletedKeys !== false) {
      obj.showDeletedKeys = message.showDeletedKeys;
    }
    return obj;
  },

  create(base?: DeepPartial<ListHmacKeysRequest>): ListHmacKeysRequest {
    return ListHmacKeysRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListHmacKeysRequest>): ListHmacKeysRequest {
    const message = createBaseListHmacKeysRequest();
    message.project = object.project ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.showDeletedKeys = object.showDeletedKeys ?? false;
    return message;
  },
};

function createBaseListHmacKeysResponse(): ListHmacKeysResponse {
  return { hmacKeys: [], nextPageToken: "" };
}

export const ListHmacKeysResponse: MessageFns<ListHmacKeysResponse> = {
  encode(message: ListHmacKeysResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.hmacKeys) {
      HmacKeyMetadata.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListHmacKeysResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListHmacKeysResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hmacKeys.push(HmacKeyMetadata.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListHmacKeysResponse {
    return {
      hmacKeys: globalThis.Array.isArray(object?.hmacKeys)
        ? object.hmacKeys.map((e: any) => HmacKeyMetadata.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListHmacKeysResponse): unknown {
    const obj: any = {};
    if (message.hmacKeys?.length) {
      obj.hmacKeys = message.hmacKeys.map((e) => HmacKeyMetadata.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListHmacKeysResponse>): ListHmacKeysResponse {
    return ListHmacKeysResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListHmacKeysResponse>): ListHmacKeysResponse {
    const message = createBaseListHmacKeysResponse();
    message.hmacKeys = object.hmacKeys?.map((e) => HmacKeyMetadata.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateHmacKeyRequest(): UpdateHmacKeyRequest {
  return { hmacKey: undefined, updateMask: undefined };
}

export const UpdateHmacKeyRequest: MessageFns<UpdateHmacKeyRequest> = {
  encode(message: UpdateHmacKeyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hmacKey !== undefined) {
      HmacKeyMetadata.encode(message.hmacKey, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateHmacKeyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateHmacKeyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hmacKey = HmacKeyMetadata.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateHmacKeyRequest {
    return {
      hmacKey: isSet(object.hmacKey) ? HmacKeyMetadata.fromJSON(object.hmacKey) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateHmacKeyRequest): unknown {
    const obj: any = {};
    if (message.hmacKey !== undefined) {
      obj.hmacKey = HmacKeyMetadata.toJSON(message.hmacKey);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateHmacKeyRequest>): UpdateHmacKeyRequest {
    return UpdateHmacKeyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateHmacKeyRequest>): UpdateHmacKeyRequest {
    const message = createBaseUpdateHmacKeyRequest();
    message.hmacKey = (object.hmacKey !== undefined && object.hmacKey !== null)
      ? HmacKeyMetadata.fromPartial(object.hmacKey)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseHmacKeyMetadata(): HmacKeyMetadata {
  return {
    id: "",
    accessId: "",
    project: "",
    serviceAccountEmail: "",
    state: "",
    createTime: undefined,
    updateTime: undefined,
    etag: "",
  };
}

export const HmacKeyMetadata: MessageFns<HmacKeyMetadata> = {
  encode(message: HmacKeyMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.accessId !== "") {
      writer.uint32(18).string(message.accessId);
    }
    if (message.project !== "") {
      writer.uint32(26).string(message.project);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(34).string(message.serviceAccountEmail);
    }
    if (message.state !== "") {
      writer.uint32(42).string(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(66).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HmacKeyMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHmacKeyMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.accessId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.project = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.state = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HmacKeyMetadata {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      accessId: isSet(object.accessId) ? globalThis.String(object.accessId) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      state: isSet(object.state) ? globalThis.String(object.state) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: HmacKeyMetadata): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.accessId !== "") {
      obj.accessId = message.accessId;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.state !== "") {
      obj.state = message.state;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<HmacKeyMetadata>): HmacKeyMetadata {
    return HmacKeyMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HmacKeyMetadata>): HmacKeyMetadata {
    const message = createBaseHmacKeyMetadata();
    message.id = object.id ?? "";
    message.accessId = object.accessId ?? "";
    message.project = object.project ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.state = object.state ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseCommonObjectRequestParams(): CommonObjectRequestParams {
  return { encryptionAlgorithm: "", encryptionKeyBytes: Buffer.alloc(0), encryptionKeySha256Bytes: Buffer.alloc(0) };
}

export const CommonObjectRequestParams: MessageFns<CommonObjectRequestParams> = {
  encode(message: CommonObjectRequestParams, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encryptionAlgorithm !== "") {
      writer.uint32(10).string(message.encryptionAlgorithm);
    }
    if (message.encryptionKeyBytes.length !== 0) {
      writer.uint32(34).bytes(message.encryptionKeyBytes);
    }
    if (message.encryptionKeySha256Bytes.length !== 0) {
      writer.uint32(42).bytes(message.encryptionKeySha256Bytes);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommonObjectRequestParams {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommonObjectRequestParams();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.encryptionAlgorithm = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.encryptionKeyBytes = Buffer.from(reader.bytes());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.encryptionKeySha256Bytes = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommonObjectRequestParams {
    return {
      encryptionAlgorithm: isSet(object.encryptionAlgorithm) ? globalThis.String(object.encryptionAlgorithm) : "",
      encryptionKeyBytes: isSet(object.encryptionKeyBytes)
        ? Buffer.from(bytesFromBase64(object.encryptionKeyBytes))
        : Buffer.alloc(0),
      encryptionKeySha256Bytes: isSet(object.encryptionKeySha256Bytes)
        ? Buffer.from(bytesFromBase64(object.encryptionKeySha256Bytes))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: CommonObjectRequestParams): unknown {
    const obj: any = {};
    if (message.encryptionAlgorithm !== "") {
      obj.encryptionAlgorithm = message.encryptionAlgorithm;
    }
    if (message.encryptionKeyBytes.length !== 0) {
      obj.encryptionKeyBytes = base64FromBytes(message.encryptionKeyBytes);
    }
    if (message.encryptionKeySha256Bytes.length !== 0) {
      obj.encryptionKeySha256Bytes = base64FromBytes(message.encryptionKeySha256Bytes);
    }
    return obj;
  },

  create(base?: DeepPartial<CommonObjectRequestParams>): CommonObjectRequestParams {
    return CommonObjectRequestParams.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CommonObjectRequestParams>): CommonObjectRequestParams {
    const message = createBaseCommonObjectRequestParams();
    message.encryptionAlgorithm = object.encryptionAlgorithm ?? "";
    message.encryptionKeyBytes = object.encryptionKeyBytes ?? Buffer.alloc(0);
    message.encryptionKeySha256Bytes = object.encryptionKeySha256Bytes ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseServiceConstants(): ServiceConstants {
  return {};
}

export const ServiceConstants: MessageFns<ServiceConstants> = {
  encode(_: ServiceConstants, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceConstants {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceConstants();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ServiceConstants {
    return {};
  },

  toJSON(_: ServiceConstants): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ServiceConstants>): ServiceConstants {
    return ServiceConstants.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ServiceConstants>): ServiceConstants {
    const message = createBaseServiceConstants();
    return message;
  },
};

function createBaseBucket(): Bucket {
  return {
    name: "",
    bucketId: "",
    etag: "",
    project: "",
    metageneration: Long.ZERO,
    location: "",
    locationType: "",
    storageClass: "",
    rpo: "",
    acl: [],
    defaultObjectAcl: [],
    lifecycle: undefined,
    createTime: undefined,
    cors: [],
    updateTime: undefined,
    defaultEventBasedHold: false,
    labels: {},
    website: undefined,
    versioning: undefined,
    logging: undefined,
    owner: undefined,
    encryption: undefined,
    billing: undefined,
    retentionPolicy: undefined,
    iamConfig: undefined,
    satisfiesPzs: false,
    customPlacementConfig: undefined,
    autoclass: undefined,
    hierarchicalNamespace: undefined,
    softDeletePolicy: undefined,
  };
}

export const Bucket: MessageFns<Bucket> = {
  encode(message: Bucket, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.bucketId !== "") {
      writer.uint32(18).string(message.bucketId);
    }
    if (message.etag !== "") {
      writer.uint32(234).string(message.etag);
    }
    if (message.project !== "") {
      writer.uint32(26).string(message.project);
    }
    if (!message.metageneration.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.metageneration.toString());
    }
    if (message.location !== "") {
      writer.uint32(42).string(message.location);
    }
    if (message.locationType !== "") {
      writer.uint32(50).string(message.locationType);
    }
    if (message.storageClass !== "") {
      writer.uint32(58).string(message.storageClass);
    }
    if (message.rpo !== "") {
      writer.uint32(218).string(message.rpo);
    }
    for (const v of message.acl) {
      BucketAccessControl.encode(v!, writer.uint32(66).fork()).join();
    }
    for (const v of message.defaultObjectAcl) {
      ObjectAccessControl.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.lifecycle !== undefined) {
      Bucket_Lifecycle.encode(message.lifecycle, writer.uint32(82).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(90).fork()).join();
    }
    for (const v of message.cors) {
      Bucket_Cors.encode(v!, writer.uint32(98).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(106).fork()).join();
    }
    if (message.defaultEventBasedHold !== false) {
      writer.uint32(112).bool(message.defaultEventBasedHold);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Bucket_LabelsEntry.encode({ key: key as any, value }, writer.uint32(122).fork()).join();
    });
    if (message.website !== undefined) {
      Bucket_Website.encode(message.website, writer.uint32(130).fork()).join();
    }
    if (message.versioning !== undefined) {
      Bucket_Versioning.encode(message.versioning, writer.uint32(138).fork()).join();
    }
    if (message.logging !== undefined) {
      Bucket_Logging.encode(message.logging, writer.uint32(146).fork()).join();
    }
    if (message.owner !== undefined) {
      Owner.encode(message.owner, writer.uint32(154).fork()).join();
    }
    if (message.encryption !== undefined) {
      Bucket_Encryption.encode(message.encryption, writer.uint32(162).fork()).join();
    }
    if (message.billing !== undefined) {
      Bucket_Billing.encode(message.billing, writer.uint32(170).fork()).join();
    }
    if (message.retentionPolicy !== undefined) {
      Bucket_RetentionPolicy.encode(message.retentionPolicy, writer.uint32(178).fork()).join();
    }
    if (message.iamConfig !== undefined) {
      Bucket_IamConfig.encode(message.iamConfig, writer.uint32(186).fork()).join();
    }
    if (message.satisfiesPzs !== false) {
      writer.uint32(200).bool(message.satisfiesPzs);
    }
    if (message.customPlacementConfig !== undefined) {
      Bucket_CustomPlacementConfig.encode(message.customPlacementConfig, writer.uint32(210).fork()).join();
    }
    if (message.autoclass !== undefined) {
      Bucket_Autoclass.encode(message.autoclass, writer.uint32(226).fork()).join();
    }
    if (message.hierarchicalNamespace !== undefined) {
      Bucket_HierarchicalNamespace.encode(message.hierarchicalNamespace, writer.uint32(258).fork()).join();
    }
    if (message.softDeletePolicy !== undefined) {
      Bucket_SoftDeletePolicy.encode(message.softDeletePolicy, writer.uint32(250).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucketId = reader.string();
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.project = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.metageneration = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.location = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.locationType = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.storageClass = reader.string();
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.rpo = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.acl.push(BucketAccessControl.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.defaultObjectAcl.push(ObjectAccessControl.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.lifecycle = Bucket_Lifecycle.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.cors.push(Bucket_Cors.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.defaultEventBasedHold = reader.bool();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          const entry15 = Bucket_LabelsEntry.decode(reader, reader.uint32());
          if (entry15.value !== undefined) {
            message.labels[entry15.key] = entry15.value;
          }
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.website = Bucket_Website.decode(reader, reader.uint32());
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.versioning = Bucket_Versioning.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.logging = Bucket_Logging.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.owner = Owner.decode(reader, reader.uint32());
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.encryption = Bucket_Encryption.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.billing = Bucket_Billing.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.retentionPolicy = Bucket_RetentionPolicy.decode(reader, reader.uint32());
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.iamConfig = Bucket_IamConfig.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 200) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.customPlacementConfig = Bucket_CustomPlacementConfig.decode(reader, reader.uint32());
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.autoclass = Bucket_Autoclass.decode(reader, reader.uint32());
          continue;
        case 32:
          if (tag !== 258) {
            break;
          }

          message.hierarchicalNamespace = Bucket_HierarchicalNamespace.decode(reader, reader.uint32());
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.softDeletePolicy = Bucket_SoftDeletePolicy.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      bucketId: isSet(object.bucketId) ? globalThis.String(object.bucketId) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      metageneration: isSet(object.metageneration) ? Long.fromValue(object.metageneration) : Long.ZERO,
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      locationType: isSet(object.locationType) ? globalThis.String(object.locationType) : "",
      storageClass: isSet(object.storageClass) ? globalThis.String(object.storageClass) : "",
      rpo: isSet(object.rpo) ? globalThis.String(object.rpo) : "",
      acl: globalThis.Array.isArray(object?.acl) ? object.acl.map((e: any) => BucketAccessControl.fromJSON(e)) : [],
      defaultObjectAcl: globalThis.Array.isArray(object?.defaultObjectAcl)
        ? object.defaultObjectAcl.map((e: any) => ObjectAccessControl.fromJSON(e))
        : [],
      lifecycle: isSet(object.lifecycle) ? Bucket_Lifecycle.fromJSON(object.lifecycle) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      cors: globalThis.Array.isArray(object?.cors) ? object.cors.map((e: any) => Bucket_Cors.fromJSON(e)) : [],
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      defaultEventBasedHold: isSet(object.defaultEventBasedHold)
        ? globalThis.Boolean(object.defaultEventBasedHold)
        : false,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      website: isSet(object.website) ? Bucket_Website.fromJSON(object.website) : undefined,
      versioning: isSet(object.versioning) ? Bucket_Versioning.fromJSON(object.versioning) : undefined,
      logging: isSet(object.logging) ? Bucket_Logging.fromJSON(object.logging) : undefined,
      owner: isSet(object.owner) ? Owner.fromJSON(object.owner) : undefined,
      encryption: isSet(object.encryption) ? Bucket_Encryption.fromJSON(object.encryption) : undefined,
      billing: isSet(object.billing) ? Bucket_Billing.fromJSON(object.billing) : undefined,
      retentionPolicy: isSet(object.retentionPolicy)
        ? Bucket_RetentionPolicy.fromJSON(object.retentionPolicy)
        : undefined,
      iamConfig: isSet(object.iamConfig) ? Bucket_IamConfig.fromJSON(object.iamConfig) : undefined,
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : false,
      customPlacementConfig: isSet(object.customPlacementConfig)
        ? Bucket_CustomPlacementConfig.fromJSON(object.customPlacementConfig)
        : undefined,
      autoclass: isSet(object.autoclass) ? Bucket_Autoclass.fromJSON(object.autoclass) : undefined,
      hierarchicalNamespace: isSet(object.hierarchicalNamespace)
        ? Bucket_HierarchicalNamespace.fromJSON(object.hierarchicalNamespace)
        : undefined,
      softDeletePolicy: isSet(object.softDeletePolicy)
        ? Bucket_SoftDeletePolicy.fromJSON(object.softDeletePolicy)
        : undefined,
    };
  },

  toJSON(message: Bucket): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.bucketId !== "") {
      obj.bucketId = message.bucketId;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (!message.metageneration.equals(Long.ZERO)) {
      obj.metageneration = (message.metageneration || Long.ZERO).toString();
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.locationType !== "") {
      obj.locationType = message.locationType;
    }
    if (message.storageClass !== "") {
      obj.storageClass = message.storageClass;
    }
    if (message.rpo !== "") {
      obj.rpo = message.rpo;
    }
    if (message.acl?.length) {
      obj.acl = message.acl.map((e) => BucketAccessControl.toJSON(e));
    }
    if (message.defaultObjectAcl?.length) {
      obj.defaultObjectAcl = message.defaultObjectAcl.map((e) => ObjectAccessControl.toJSON(e));
    }
    if (message.lifecycle !== undefined) {
      obj.lifecycle = Bucket_Lifecycle.toJSON(message.lifecycle);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.cors?.length) {
      obj.cors = message.cors.map((e) => Bucket_Cors.toJSON(e));
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.defaultEventBasedHold !== false) {
      obj.defaultEventBasedHold = message.defaultEventBasedHold;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.website !== undefined) {
      obj.website = Bucket_Website.toJSON(message.website);
    }
    if (message.versioning !== undefined) {
      obj.versioning = Bucket_Versioning.toJSON(message.versioning);
    }
    if (message.logging !== undefined) {
      obj.logging = Bucket_Logging.toJSON(message.logging);
    }
    if (message.owner !== undefined) {
      obj.owner = Owner.toJSON(message.owner);
    }
    if (message.encryption !== undefined) {
      obj.encryption = Bucket_Encryption.toJSON(message.encryption);
    }
    if (message.billing !== undefined) {
      obj.billing = Bucket_Billing.toJSON(message.billing);
    }
    if (message.retentionPolicy !== undefined) {
      obj.retentionPolicy = Bucket_RetentionPolicy.toJSON(message.retentionPolicy);
    }
    if (message.iamConfig !== undefined) {
      obj.iamConfig = Bucket_IamConfig.toJSON(message.iamConfig);
    }
    if (message.satisfiesPzs !== false) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.customPlacementConfig !== undefined) {
      obj.customPlacementConfig = Bucket_CustomPlacementConfig.toJSON(message.customPlacementConfig);
    }
    if (message.autoclass !== undefined) {
      obj.autoclass = Bucket_Autoclass.toJSON(message.autoclass);
    }
    if (message.hierarchicalNamespace !== undefined) {
      obj.hierarchicalNamespace = Bucket_HierarchicalNamespace.toJSON(message.hierarchicalNamespace);
    }
    if (message.softDeletePolicy !== undefined) {
      obj.softDeletePolicy = Bucket_SoftDeletePolicy.toJSON(message.softDeletePolicy);
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket>): Bucket {
    return Bucket.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket>): Bucket {
    const message = createBaseBucket();
    message.name = object.name ?? "";
    message.bucketId = object.bucketId ?? "";
    message.etag = object.etag ?? "";
    message.project = object.project ?? "";
    message.metageneration = (object.metageneration !== undefined && object.metageneration !== null)
      ? Long.fromValue(object.metageneration)
      : Long.ZERO;
    message.location = object.location ?? "";
    message.locationType = object.locationType ?? "";
    message.storageClass = object.storageClass ?? "";
    message.rpo = object.rpo ?? "";
    message.acl = object.acl?.map((e) => BucketAccessControl.fromPartial(e)) || [];
    message.defaultObjectAcl = object.defaultObjectAcl?.map((e) => ObjectAccessControl.fromPartial(e)) || [];
    message.lifecycle = (object.lifecycle !== undefined && object.lifecycle !== null)
      ? Bucket_Lifecycle.fromPartial(object.lifecycle)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.cors = object.cors?.map((e) => Bucket_Cors.fromPartial(e)) || [];
    message.updateTime = object.updateTime ?? undefined;
    message.defaultEventBasedHold = object.defaultEventBasedHold ?? false;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.website = (object.website !== undefined && object.website !== null)
      ? Bucket_Website.fromPartial(object.website)
      : undefined;
    message.versioning = (object.versioning !== undefined && object.versioning !== null)
      ? Bucket_Versioning.fromPartial(object.versioning)
      : undefined;
    message.logging = (object.logging !== undefined && object.logging !== null)
      ? Bucket_Logging.fromPartial(object.logging)
      : undefined;
    message.owner = (object.owner !== undefined && object.owner !== null) ? Owner.fromPartial(object.owner) : undefined;
    message.encryption = (object.encryption !== undefined && object.encryption !== null)
      ? Bucket_Encryption.fromPartial(object.encryption)
      : undefined;
    message.billing = (object.billing !== undefined && object.billing !== null)
      ? Bucket_Billing.fromPartial(object.billing)
      : undefined;
    message.retentionPolicy = (object.retentionPolicy !== undefined && object.retentionPolicy !== null)
      ? Bucket_RetentionPolicy.fromPartial(object.retentionPolicy)
      : undefined;
    message.iamConfig = (object.iamConfig !== undefined && object.iamConfig !== null)
      ? Bucket_IamConfig.fromPartial(object.iamConfig)
      : undefined;
    message.satisfiesPzs = object.satisfiesPzs ?? false;
    message.customPlacementConfig =
      (object.customPlacementConfig !== undefined && object.customPlacementConfig !== null)
        ? Bucket_CustomPlacementConfig.fromPartial(object.customPlacementConfig)
        : undefined;
    message.autoclass = (object.autoclass !== undefined && object.autoclass !== null)
      ? Bucket_Autoclass.fromPartial(object.autoclass)
      : undefined;
    message.hierarchicalNamespace =
      (object.hierarchicalNamespace !== undefined && object.hierarchicalNamespace !== null)
        ? Bucket_HierarchicalNamespace.fromPartial(object.hierarchicalNamespace)
        : undefined;
    message.softDeletePolicy = (object.softDeletePolicy !== undefined && object.softDeletePolicy !== null)
      ? Bucket_SoftDeletePolicy.fromPartial(object.softDeletePolicy)
      : undefined;
    return message;
  },
};

function createBaseBucket_Billing(): Bucket_Billing {
  return { requesterPays: false };
}

export const Bucket_Billing: MessageFns<Bucket_Billing> = {
  encode(message: Bucket_Billing, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requesterPays !== false) {
      writer.uint32(8).bool(message.requesterPays);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Billing {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Billing();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.requesterPays = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Billing {
    return { requesterPays: isSet(object.requesterPays) ? globalThis.Boolean(object.requesterPays) : false };
  },

  toJSON(message: Bucket_Billing): unknown {
    const obj: any = {};
    if (message.requesterPays !== false) {
      obj.requesterPays = message.requesterPays;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Billing>): Bucket_Billing {
    return Bucket_Billing.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Billing>): Bucket_Billing {
    const message = createBaseBucket_Billing();
    message.requesterPays = object.requesterPays ?? false;
    return message;
  },
};

function createBaseBucket_Cors(): Bucket_Cors {
  return { origin: [], method: [], responseHeader: [], maxAgeSeconds: 0 };
}

export const Bucket_Cors: MessageFns<Bucket_Cors> = {
  encode(message: Bucket_Cors, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.origin) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.method) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.responseHeader) {
      writer.uint32(26).string(v!);
    }
    if (message.maxAgeSeconds !== 0) {
      writer.uint32(32).int32(message.maxAgeSeconds);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Cors {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Cors();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.origin.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.method.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.responseHeader.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.maxAgeSeconds = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Cors {
    return {
      origin: globalThis.Array.isArray(object?.origin) ? object.origin.map((e: any) => globalThis.String(e)) : [],
      method: globalThis.Array.isArray(object?.method) ? object.method.map((e: any) => globalThis.String(e)) : [],
      responseHeader: globalThis.Array.isArray(object?.responseHeader)
        ? object.responseHeader.map((e: any) => globalThis.String(e))
        : [],
      maxAgeSeconds: isSet(object.maxAgeSeconds) ? globalThis.Number(object.maxAgeSeconds) : 0,
    };
  },

  toJSON(message: Bucket_Cors): unknown {
    const obj: any = {};
    if (message.origin?.length) {
      obj.origin = message.origin;
    }
    if (message.method?.length) {
      obj.method = message.method;
    }
    if (message.responseHeader?.length) {
      obj.responseHeader = message.responseHeader;
    }
    if (message.maxAgeSeconds !== 0) {
      obj.maxAgeSeconds = Math.round(message.maxAgeSeconds);
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Cors>): Bucket_Cors {
    return Bucket_Cors.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Cors>): Bucket_Cors {
    const message = createBaseBucket_Cors();
    message.origin = object.origin?.map((e) => e) || [];
    message.method = object.method?.map((e) => e) || [];
    message.responseHeader = object.responseHeader?.map((e) => e) || [];
    message.maxAgeSeconds = object.maxAgeSeconds ?? 0;
    return message;
  },
};

function createBaseBucket_Encryption(): Bucket_Encryption {
  return { defaultKmsKey: "" };
}

export const Bucket_Encryption: MessageFns<Bucket_Encryption> = {
  encode(message: Bucket_Encryption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.defaultKmsKey !== "") {
      writer.uint32(10).string(message.defaultKmsKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Encryption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Encryption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.defaultKmsKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Encryption {
    return { defaultKmsKey: isSet(object.defaultKmsKey) ? globalThis.String(object.defaultKmsKey) : "" };
  },

  toJSON(message: Bucket_Encryption): unknown {
    const obj: any = {};
    if (message.defaultKmsKey !== "") {
      obj.defaultKmsKey = message.defaultKmsKey;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Encryption>): Bucket_Encryption {
    return Bucket_Encryption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Encryption>): Bucket_Encryption {
    const message = createBaseBucket_Encryption();
    message.defaultKmsKey = object.defaultKmsKey ?? "";
    return message;
  },
};

function createBaseBucket_IamConfig(): Bucket_IamConfig {
  return { uniformBucketLevelAccess: undefined, publicAccessPrevention: "" };
}

export const Bucket_IamConfig: MessageFns<Bucket_IamConfig> = {
  encode(message: Bucket_IamConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uniformBucketLevelAccess !== undefined) {
      Bucket_IamConfig_UniformBucketLevelAccess.encode(message.uniformBucketLevelAccess, writer.uint32(10).fork())
        .join();
    }
    if (message.publicAccessPrevention !== "") {
      writer.uint32(26).string(message.publicAccessPrevention);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_IamConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_IamConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uniformBucketLevelAccess = Bucket_IamConfig_UniformBucketLevelAccess.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.publicAccessPrevention = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_IamConfig {
    return {
      uniformBucketLevelAccess: isSet(object.uniformBucketLevelAccess)
        ? Bucket_IamConfig_UniformBucketLevelAccess.fromJSON(object.uniformBucketLevelAccess)
        : undefined,
      publicAccessPrevention: isSet(object.publicAccessPrevention)
        ? globalThis.String(object.publicAccessPrevention)
        : "",
    };
  },

  toJSON(message: Bucket_IamConfig): unknown {
    const obj: any = {};
    if (message.uniformBucketLevelAccess !== undefined) {
      obj.uniformBucketLevelAccess = Bucket_IamConfig_UniformBucketLevelAccess.toJSON(message.uniformBucketLevelAccess);
    }
    if (message.publicAccessPrevention !== "") {
      obj.publicAccessPrevention = message.publicAccessPrevention;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_IamConfig>): Bucket_IamConfig {
    return Bucket_IamConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_IamConfig>): Bucket_IamConfig {
    const message = createBaseBucket_IamConfig();
    message.uniformBucketLevelAccess =
      (object.uniformBucketLevelAccess !== undefined && object.uniformBucketLevelAccess !== null)
        ? Bucket_IamConfig_UniformBucketLevelAccess.fromPartial(object.uniformBucketLevelAccess)
        : undefined;
    message.publicAccessPrevention = object.publicAccessPrevention ?? "";
    return message;
  },
};

function createBaseBucket_IamConfig_UniformBucketLevelAccess(): Bucket_IamConfig_UniformBucketLevelAccess {
  return { enabled: false, lockTime: undefined };
}

export const Bucket_IamConfig_UniformBucketLevelAccess: MessageFns<Bucket_IamConfig_UniformBucketLevelAccess> = {
  encode(message: Bucket_IamConfig_UniformBucketLevelAccess, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    if (message.lockTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lockTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_IamConfig_UniformBucketLevelAccess {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_IamConfig_UniformBucketLevelAccess();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.lockTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_IamConfig_UniformBucketLevelAccess {
    return {
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      lockTime: isSet(object.lockTime) ? fromJsonTimestamp(object.lockTime) : undefined,
    };
  },

  toJSON(message: Bucket_IamConfig_UniformBucketLevelAccess): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.lockTime !== undefined) {
      obj.lockTime = message.lockTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_IamConfig_UniformBucketLevelAccess>): Bucket_IamConfig_UniformBucketLevelAccess {
    return Bucket_IamConfig_UniformBucketLevelAccess.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<Bucket_IamConfig_UniformBucketLevelAccess>,
  ): Bucket_IamConfig_UniformBucketLevelAccess {
    const message = createBaseBucket_IamConfig_UniformBucketLevelAccess();
    message.enabled = object.enabled ?? false;
    message.lockTime = object.lockTime ?? undefined;
    return message;
  },
};

function createBaseBucket_Lifecycle(): Bucket_Lifecycle {
  return { rule: [] };
}

export const Bucket_Lifecycle: MessageFns<Bucket_Lifecycle> = {
  encode(message: Bucket_Lifecycle, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.rule) {
      Bucket_Lifecycle_Rule.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Lifecycle {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Lifecycle();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rule.push(Bucket_Lifecycle_Rule.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Lifecycle {
    return {
      rule: globalThis.Array.isArray(object?.rule)
        ? object.rule.map((e: any) => Bucket_Lifecycle_Rule.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Bucket_Lifecycle): unknown {
    const obj: any = {};
    if (message.rule?.length) {
      obj.rule = message.rule.map((e) => Bucket_Lifecycle_Rule.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Lifecycle>): Bucket_Lifecycle {
    return Bucket_Lifecycle.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Lifecycle>): Bucket_Lifecycle {
    const message = createBaseBucket_Lifecycle();
    message.rule = object.rule?.map((e) => Bucket_Lifecycle_Rule.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBucket_Lifecycle_Rule(): Bucket_Lifecycle_Rule {
  return { action: undefined, condition: undefined };
}

export const Bucket_Lifecycle_Rule: MessageFns<Bucket_Lifecycle_Rule> = {
  encode(message: Bucket_Lifecycle_Rule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.action !== undefined) {
      Bucket_Lifecycle_Rule_Action.encode(message.action, writer.uint32(10).fork()).join();
    }
    if (message.condition !== undefined) {
      Bucket_Lifecycle_Rule_Condition.encode(message.condition, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Lifecycle_Rule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Lifecycle_Rule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.action = Bucket_Lifecycle_Rule_Action.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.condition = Bucket_Lifecycle_Rule_Condition.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Lifecycle_Rule {
    return {
      action: isSet(object.action) ? Bucket_Lifecycle_Rule_Action.fromJSON(object.action) : undefined,
      condition: isSet(object.condition) ? Bucket_Lifecycle_Rule_Condition.fromJSON(object.condition) : undefined,
    };
  },

  toJSON(message: Bucket_Lifecycle_Rule): unknown {
    const obj: any = {};
    if (message.action !== undefined) {
      obj.action = Bucket_Lifecycle_Rule_Action.toJSON(message.action);
    }
    if (message.condition !== undefined) {
      obj.condition = Bucket_Lifecycle_Rule_Condition.toJSON(message.condition);
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Lifecycle_Rule>): Bucket_Lifecycle_Rule {
    return Bucket_Lifecycle_Rule.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Lifecycle_Rule>): Bucket_Lifecycle_Rule {
    const message = createBaseBucket_Lifecycle_Rule();
    message.action = (object.action !== undefined && object.action !== null)
      ? Bucket_Lifecycle_Rule_Action.fromPartial(object.action)
      : undefined;
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? Bucket_Lifecycle_Rule_Condition.fromPartial(object.condition)
      : undefined;
    return message;
  },
};

function createBaseBucket_Lifecycle_Rule_Action(): Bucket_Lifecycle_Rule_Action {
  return { type: "", storageClass: "" };
}

export const Bucket_Lifecycle_Rule_Action: MessageFns<Bucket_Lifecycle_Rule_Action> = {
  encode(message: Bucket_Lifecycle_Rule_Action, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    if (message.storageClass !== "") {
      writer.uint32(18).string(message.storageClass);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Lifecycle_Rule_Action {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Lifecycle_Rule_Action();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.storageClass = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Lifecycle_Rule_Action {
    return {
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      storageClass: isSet(object.storageClass) ? globalThis.String(object.storageClass) : "",
    };
  },

  toJSON(message: Bucket_Lifecycle_Rule_Action): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.storageClass !== "") {
      obj.storageClass = message.storageClass;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Lifecycle_Rule_Action>): Bucket_Lifecycle_Rule_Action {
    return Bucket_Lifecycle_Rule_Action.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Lifecycle_Rule_Action>): Bucket_Lifecycle_Rule_Action {
    const message = createBaseBucket_Lifecycle_Rule_Action();
    message.type = object.type ?? "";
    message.storageClass = object.storageClass ?? "";
    return message;
  },
};

function createBaseBucket_Lifecycle_Rule_Condition(): Bucket_Lifecycle_Rule_Condition {
  return {
    ageDays: undefined,
    createdBefore: undefined,
    isLive: undefined,
    numNewerVersions: undefined,
    matchesStorageClass: [],
    daysSinceCustomTime: undefined,
    customTimeBefore: undefined,
    daysSinceNoncurrentTime: undefined,
    noncurrentTimeBefore: undefined,
    matchesPrefix: [],
    matchesSuffix: [],
  };
}

export const Bucket_Lifecycle_Rule_Condition: MessageFns<Bucket_Lifecycle_Rule_Condition> = {
  encode(message: Bucket_Lifecycle_Rule_Condition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.ageDays !== undefined) {
      writer.uint32(8).int32(message.ageDays);
    }
    if (message.createdBefore !== undefined) {
      DateMessage.encode(message.createdBefore, writer.uint32(18).fork()).join();
    }
    if (message.isLive !== undefined) {
      writer.uint32(24).bool(message.isLive);
    }
    if (message.numNewerVersions !== undefined) {
      writer.uint32(32).int32(message.numNewerVersions);
    }
    for (const v of message.matchesStorageClass) {
      writer.uint32(42).string(v!);
    }
    if (message.daysSinceCustomTime !== undefined) {
      writer.uint32(56).int32(message.daysSinceCustomTime);
    }
    if (message.customTimeBefore !== undefined) {
      DateMessage.encode(message.customTimeBefore, writer.uint32(66).fork()).join();
    }
    if (message.daysSinceNoncurrentTime !== undefined) {
      writer.uint32(72).int32(message.daysSinceNoncurrentTime);
    }
    if (message.noncurrentTimeBefore !== undefined) {
      DateMessage.encode(message.noncurrentTimeBefore, writer.uint32(82).fork()).join();
    }
    for (const v of message.matchesPrefix) {
      writer.uint32(90).string(v!);
    }
    for (const v of message.matchesSuffix) {
      writer.uint32(98).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Lifecycle_Rule_Condition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Lifecycle_Rule_Condition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.ageDays = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createdBefore = DateMessage.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.isLive = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.numNewerVersions = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.matchesStorageClass.push(reader.string());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.daysSinceCustomTime = reader.int32();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.customTimeBefore = DateMessage.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.daysSinceNoncurrentTime = reader.int32();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.noncurrentTimeBefore = DateMessage.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.matchesPrefix.push(reader.string());
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.matchesSuffix.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Lifecycle_Rule_Condition {
    return {
      ageDays: isSet(object.ageDays) ? globalThis.Number(object.ageDays) : undefined,
      createdBefore: isSet(object.createdBefore) ? DateMessage.fromJSON(object.createdBefore) : undefined,
      isLive: isSet(object.isLive) ? globalThis.Boolean(object.isLive) : undefined,
      numNewerVersions: isSet(object.numNewerVersions) ? globalThis.Number(object.numNewerVersions) : undefined,
      matchesStorageClass: globalThis.Array.isArray(object?.matchesStorageClass)
        ? object.matchesStorageClass.map((e: any) => globalThis.String(e))
        : [],
      daysSinceCustomTime: isSet(object.daysSinceCustomTime)
        ? globalThis.Number(object.daysSinceCustomTime)
        : undefined,
      customTimeBefore: isSet(object.customTimeBefore) ? DateMessage.fromJSON(object.customTimeBefore) : undefined,
      daysSinceNoncurrentTime: isSet(object.daysSinceNoncurrentTime)
        ? globalThis.Number(object.daysSinceNoncurrentTime)
        : undefined,
      noncurrentTimeBefore: isSet(object.noncurrentTimeBefore)
        ? DateMessage.fromJSON(object.noncurrentTimeBefore)
        : undefined,
      matchesPrefix: globalThis.Array.isArray(object?.matchesPrefix)
        ? object.matchesPrefix.map((e: any) => globalThis.String(e))
        : [],
      matchesSuffix: globalThis.Array.isArray(object?.matchesSuffix)
        ? object.matchesSuffix.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Bucket_Lifecycle_Rule_Condition): unknown {
    const obj: any = {};
    if (message.ageDays !== undefined) {
      obj.ageDays = Math.round(message.ageDays);
    }
    if (message.createdBefore !== undefined) {
      obj.createdBefore = DateMessage.toJSON(message.createdBefore);
    }
    if (message.isLive !== undefined) {
      obj.isLive = message.isLive;
    }
    if (message.numNewerVersions !== undefined) {
      obj.numNewerVersions = Math.round(message.numNewerVersions);
    }
    if (message.matchesStorageClass?.length) {
      obj.matchesStorageClass = message.matchesStorageClass;
    }
    if (message.daysSinceCustomTime !== undefined) {
      obj.daysSinceCustomTime = Math.round(message.daysSinceCustomTime);
    }
    if (message.customTimeBefore !== undefined) {
      obj.customTimeBefore = DateMessage.toJSON(message.customTimeBefore);
    }
    if (message.daysSinceNoncurrentTime !== undefined) {
      obj.daysSinceNoncurrentTime = Math.round(message.daysSinceNoncurrentTime);
    }
    if (message.noncurrentTimeBefore !== undefined) {
      obj.noncurrentTimeBefore = DateMessage.toJSON(message.noncurrentTimeBefore);
    }
    if (message.matchesPrefix?.length) {
      obj.matchesPrefix = message.matchesPrefix;
    }
    if (message.matchesSuffix?.length) {
      obj.matchesSuffix = message.matchesSuffix;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Lifecycle_Rule_Condition>): Bucket_Lifecycle_Rule_Condition {
    return Bucket_Lifecycle_Rule_Condition.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Lifecycle_Rule_Condition>): Bucket_Lifecycle_Rule_Condition {
    const message = createBaseBucket_Lifecycle_Rule_Condition();
    message.ageDays = object.ageDays ?? undefined;
    message.createdBefore = (object.createdBefore !== undefined && object.createdBefore !== null)
      ? DateMessage.fromPartial(object.createdBefore)
      : undefined;
    message.isLive = object.isLive ?? undefined;
    message.numNewerVersions = object.numNewerVersions ?? undefined;
    message.matchesStorageClass = object.matchesStorageClass?.map((e) => e) || [];
    message.daysSinceCustomTime = object.daysSinceCustomTime ?? undefined;
    message.customTimeBefore = (object.customTimeBefore !== undefined && object.customTimeBefore !== null)
      ? DateMessage.fromPartial(object.customTimeBefore)
      : undefined;
    message.daysSinceNoncurrentTime = object.daysSinceNoncurrentTime ?? undefined;
    message.noncurrentTimeBefore = (object.noncurrentTimeBefore !== undefined && object.noncurrentTimeBefore !== null)
      ? DateMessage.fromPartial(object.noncurrentTimeBefore)
      : undefined;
    message.matchesPrefix = object.matchesPrefix?.map((e) => e) || [];
    message.matchesSuffix = object.matchesSuffix?.map((e) => e) || [];
    return message;
  },
};

function createBaseBucket_Logging(): Bucket_Logging {
  return { logBucket: "", logObjectPrefix: "" };
}

export const Bucket_Logging: MessageFns<Bucket_Logging> = {
  encode(message: Bucket_Logging, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.logBucket !== "") {
      writer.uint32(10).string(message.logBucket);
    }
    if (message.logObjectPrefix !== "") {
      writer.uint32(18).string(message.logObjectPrefix);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Logging {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Logging();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.logBucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.logObjectPrefix = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Logging {
    return {
      logBucket: isSet(object.logBucket) ? globalThis.String(object.logBucket) : "",
      logObjectPrefix: isSet(object.logObjectPrefix) ? globalThis.String(object.logObjectPrefix) : "",
    };
  },

  toJSON(message: Bucket_Logging): unknown {
    const obj: any = {};
    if (message.logBucket !== "") {
      obj.logBucket = message.logBucket;
    }
    if (message.logObjectPrefix !== "") {
      obj.logObjectPrefix = message.logObjectPrefix;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Logging>): Bucket_Logging {
    return Bucket_Logging.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Logging>): Bucket_Logging {
    const message = createBaseBucket_Logging();
    message.logBucket = object.logBucket ?? "";
    message.logObjectPrefix = object.logObjectPrefix ?? "";
    return message;
  },
};

function createBaseBucket_RetentionPolicy(): Bucket_RetentionPolicy {
  return { effectiveTime: undefined, isLocked: false, retentionDuration: undefined };
}

export const Bucket_RetentionPolicy: MessageFns<Bucket_RetentionPolicy> = {
  encode(message: Bucket_RetentionPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.effectiveTime !== undefined) {
      Timestamp.encode(toTimestamp(message.effectiveTime), writer.uint32(10).fork()).join();
    }
    if (message.isLocked !== false) {
      writer.uint32(16).bool(message.isLocked);
    }
    if (message.retentionDuration !== undefined) {
      Duration.encode(message.retentionDuration, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_RetentionPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_RetentionPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.effectiveTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.isLocked = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.retentionDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_RetentionPolicy {
    return {
      effectiveTime: isSet(object.effectiveTime) ? fromJsonTimestamp(object.effectiveTime) : undefined,
      isLocked: isSet(object.isLocked) ? globalThis.Boolean(object.isLocked) : false,
      retentionDuration: isSet(object.retentionDuration) ? Duration.fromJSON(object.retentionDuration) : undefined,
    };
  },

  toJSON(message: Bucket_RetentionPolicy): unknown {
    const obj: any = {};
    if (message.effectiveTime !== undefined) {
      obj.effectiveTime = message.effectiveTime.toISOString();
    }
    if (message.isLocked !== false) {
      obj.isLocked = message.isLocked;
    }
    if (message.retentionDuration !== undefined) {
      obj.retentionDuration = Duration.toJSON(message.retentionDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_RetentionPolicy>): Bucket_RetentionPolicy {
    return Bucket_RetentionPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_RetentionPolicy>): Bucket_RetentionPolicy {
    const message = createBaseBucket_RetentionPolicy();
    message.effectiveTime = object.effectiveTime ?? undefined;
    message.isLocked = object.isLocked ?? false;
    message.retentionDuration = (object.retentionDuration !== undefined && object.retentionDuration !== null)
      ? Duration.fromPartial(object.retentionDuration)
      : undefined;
    return message;
  },
};

function createBaseBucket_SoftDeletePolicy(): Bucket_SoftDeletePolicy {
  return { retentionDuration: undefined, effectiveTime: undefined };
}

export const Bucket_SoftDeletePolicy: MessageFns<Bucket_SoftDeletePolicy> = {
  encode(message: Bucket_SoftDeletePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.retentionDuration !== undefined) {
      Duration.encode(message.retentionDuration, writer.uint32(10).fork()).join();
    }
    if (message.effectiveTime !== undefined) {
      Timestamp.encode(toTimestamp(message.effectiveTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_SoftDeletePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_SoftDeletePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.retentionDuration = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.effectiveTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_SoftDeletePolicy {
    return {
      retentionDuration: isSet(object.retentionDuration) ? Duration.fromJSON(object.retentionDuration) : undefined,
      effectiveTime: isSet(object.effectiveTime) ? fromJsonTimestamp(object.effectiveTime) : undefined,
    };
  },

  toJSON(message: Bucket_SoftDeletePolicy): unknown {
    const obj: any = {};
    if (message.retentionDuration !== undefined) {
      obj.retentionDuration = Duration.toJSON(message.retentionDuration);
    }
    if (message.effectiveTime !== undefined) {
      obj.effectiveTime = message.effectiveTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_SoftDeletePolicy>): Bucket_SoftDeletePolicy {
    return Bucket_SoftDeletePolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_SoftDeletePolicy>): Bucket_SoftDeletePolicy {
    const message = createBaseBucket_SoftDeletePolicy();
    message.retentionDuration = (object.retentionDuration !== undefined && object.retentionDuration !== null)
      ? Duration.fromPartial(object.retentionDuration)
      : undefined;
    message.effectiveTime = object.effectiveTime ?? undefined;
    return message;
  },
};

function createBaseBucket_Versioning(): Bucket_Versioning {
  return { enabled: false };
}

export const Bucket_Versioning: MessageFns<Bucket_Versioning> = {
  encode(message: Bucket_Versioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Versioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Versioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Versioning {
    return { enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false };
  },

  toJSON(message: Bucket_Versioning): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Versioning>): Bucket_Versioning {
    return Bucket_Versioning.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Versioning>): Bucket_Versioning {
    const message = createBaseBucket_Versioning();
    message.enabled = object.enabled ?? false;
    return message;
  },
};

function createBaseBucket_Website(): Bucket_Website {
  return { mainPageSuffix: "", notFoundPage: "" };
}

export const Bucket_Website: MessageFns<Bucket_Website> = {
  encode(message: Bucket_Website, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mainPageSuffix !== "") {
      writer.uint32(10).string(message.mainPageSuffix);
    }
    if (message.notFoundPage !== "") {
      writer.uint32(18).string(message.notFoundPage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Website {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Website();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.mainPageSuffix = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.notFoundPage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Website {
    return {
      mainPageSuffix: isSet(object.mainPageSuffix) ? globalThis.String(object.mainPageSuffix) : "",
      notFoundPage: isSet(object.notFoundPage) ? globalThis.String(object.notFoundPage) : "",
    };
  },

  toJSON(message: Bucket_Website): unknown {
    const obj: any = {};
    if (message.mainPageSuffix !== "") {
      obj.mainPageSuffix = message.mainPageSuffix;
    }
    if (message.notFoundPage !== "") {
      obj.notFoundPage = message.notFoundPage;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Website>): Bucket_Website {
    return Bucket_Website.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Website>): Bucket_Website {
    const message = createBaseBucket_Website();
    message.mainPageSuffix = object.mainPageSuffix ?? "";
    message.notFoundPage = object.notFoundPage ?? "";
    return message;
  },
};

function createBaseBucket_CustomPlacementConfig(): Bucket_CustomPlacementConfig {
  return { dataLocations: [] };
}

export const Bucket_CustomPlacementConfig: MessageFns<Bucket_CustomPlacementConfig> = {
  encode(message: Bucket_CustomPlacementConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.dataLocations) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_CustomPlacementConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_CustomPlacementConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataLocations.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_CustomPlacementConfig {
    return {
      dataLocations: globalThis.Array.isArray(object?.dataLocations)
        ? object.dataLocations.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Bucket_CustomPlacementConfig): unknown {
    const obj: any = {};
    if (message.dataLocations?.length) {
      obj.dataLocations = message.dataLocations;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_CustomPlacementConfig>): Bucket_CustomPlacementConfig {
    return Bucket_CustomPlacementConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_CustomPlacementConfig>): Bucket_CustomPlacementConfig {
    const message = createBaseBucket_CustomPlacementConfig();
    message.dataLocations = object.dataLocations?.map((e) => e) || [];
    return message;
  },
};

function createBaseBucket_Autoclass(): Bucket_Autoclass {
  return {
    enabled: false,
    toggleTime: undefined,
    terminalStorageClass: undefined,
    terminalStorageClassUpdateTime: undefined,
  };
}

export const Bucket_Autoclass: MessageFns<Bucket_Autoclass> = {
  encode(message: Bucket_Autoclass, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    if (message.toggleTime !== undefined) {
      Timestamp.encode(toTimestamp(message.toggleTime), writer.uint32(18).fork()).join();
    }
    if (message.terminalStorageClass !== undefined) {
      writer.uint32(26).string(message.terminalStorageClass);
    }
    if (message.terminalStorageClassUpdateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.terminalStorageClassUpdateTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_Autoclass {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_Autoclass();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.toggleTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.terminalStorageClass = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.terminalStorageClassUpdateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_Autoclass {
    return {
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      toggleTime: isSet(object.toggleTime) ? fromJsonTimestamp(object.toggleTime) : undefined,
      terminalStorageClass: isSet(object.terminalStorageClass)
        ? globalThis.String(object.terminalStorageClass)
        : undefined,
      terminalStorageClassUpdateTime: isSet(object.terminalStorageClassUpdateTime)
        ? fromJsonTimestamp(object.terminalStorageClassUpdateTime)
        : undefined,
    };
  },

  toJSON(message: Bucket_Autoclass): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.toggleTime !== undefined) {
      obj.toggleTime = message.toggleTime.toISOString();
    }
    if (message.terminalStorageClass !== undefined) {
      obj.terminalStorageClass = message.terminalStorageClass;
    }
    if (message.terminalStorageClassUpdateTime !== undefined) {
      obj.terminalStorageClassUpdateTime = message.terminalStorageClassUpdateTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_Autoclass>): Bucket_Autoclass {
    return Bucket_Autoclass.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_Autoclass>): Bucket_Autoclass {
    const message = createBaseBucket_Autoclass();
    message.enabled = object.enabled ?? false;
    message.toggleTime = object.toggleTime ?? undefined;
    message.terminalStorageClass = object.terminalStorageClass ?? undefined;
    message.terminalStorageClassUpdateTime = object.terminalStorageClassUpdateTime ?? undefined;
    return message;
  },
};

function createBaseBucket_HierarchicalNamespace(): Bucket_HierarchicalNamespace {
  return { enabled: false };
}

export const Bucket_HierarchicalNamespace: MessageFns<Bucket_HierarchicalNamespace> = {
  encode(message: Bucket_HierarchicalNamespace, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_HierarchicalNamespace {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_HierarchicalNamespace();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_HierarchicalNamespace {
    return { enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false };
  },

  toJSON(message: Bucket_HierarchicalNamespace): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_HierarchicalNamespace>): Bucket_HierarchicalNamespace {
    return Bucket_HierarchicalNamespace.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_HierarchicalNamespace>): Bucket_HierarchicalNamespace {
    const message = createBaseBucket_HierarchicalNamespace();
    message.enabled = object.enabled ?? false;
    return message;
  },
};

function createBaseBucket_LabelsEntry(): Bucket_LabelsEntry {
  return { key: "", value: "" };
}

export const Bucket_LabelsEntry: MessageFns<Bucket_LabelsEntry> = {
  encode(message: Bucket_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Bucket_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucket_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Bucket_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Bucket_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Bucket_LabelsEntry>): Bucket_LabelsEntry {
    return Bucket_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Bucket_LabelsEntry>): Bucket_LabelsEntry {
    const message = createBaseBucket_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBucketAccessControl(): BucketAccessControl {
  return {
    role: "",
    id: "",
    entity: "",
    entityAlt: "",
    entityId: "",
    etag: "",
    email: "",
    domain: "",
    projectTeam: undefined,
  };
}

export const BucketAccessControl: MessageFns<BucketAccessControl> = {
  encode(message: BucketAccessControl, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.role !== "") {
      writer.uint32(10).string(message.role);
    }
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    if (message.entity !== "") {
      writer.uint32(26).string(message.entity);
    }
    if (message.entityAlt !== "") {
      writer.uint32(74).string(message.entityAlt);
    }
    if (message.entityId !== "") {
      writer.uint32(34).string(message.entityId);
    }
    if (message.etag !== "") {
      writer.uint32(66).string(message.etag);
    }
    if (message.email !== "") {
      writer.uint32(42).string(message.email);
    }
    if (message.domain !== "") {
      writer.uint32(50).string(message.domain);
    }
    if (message.projectTeam !== undefined) {
      ProjectTeam.encode(message.projectTeam, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BucketAccessControl {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBucketAccessControl();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.role = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.entityAlt = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.entityId = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.email = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.domain = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.projectTeam = ProjectTeam.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BucketAccessControl {
    return {
      role: isSet(object.role) ? globalThis.String(object.role) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      entity: isSet(object.entity) ? globalThis.String(object.entity) : "",
      entityAlt: isSet(object.entityAlt) ? globalThis.String(object.entityAlt) : "",
      entityId: isSet(object.entityId) ? globalThis.String(object.entityId) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      email: isSet(object.email) ? globalThis.String(object.email) : "",
      domain: isSet(object.domain) ? globalThis.String(object.domain) : "",
      projectTeam: isSet(object.projectTeam) ? ProjectTeam.fromJSON(object.projectTeam) : undefined,
    };
  },

  toJSON(message: BucketAccessControl): unknown {
    const obj: any = {};
    if (message.role !== "") {
      obj.role = message.role;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.entity !== "") {
      obj.entity = message.entity;
    }
    if (message.entityAlt !== "") {
      obj.entityAlt = message.entityAlt;
    }
    if (message.entityId !== "") {
      obj.entityId = message.entityId;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.email !== "") {
      obj.email = message.email;
    }
    if (message.domain !== "") {
      obj.domain = message.domain;
    }
    if (message.projectTeam !== undefined) {
      obj.projectTeam = ProjectTeam.toJSON(message.projectTeam);
    }
    return obj;
  },

  create(base?: DeepPartial<BucketAccessControl>): BucketAccessControl {
    return BucketAccessControl.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BucketAccessControl>): BucketAccessControl {
    const message = createBaseBucketAccessControl();
    message.role = object.role ?? "";
    message.id = object.id ?? "";
    message.entity = object.entity ?? "";
    message.entityAlt = object.entityAlt ?? "";
    message.entityId = object.entityId ?? "";
    message.etag = object.etag ?? "";
    message.email = object.email ?? "";
    message.domain = object.domain ?? "";
    message.projectTeam = (object.projectTeam !== undefined && object.projectTeam !== null)
      ? ProjectTeam.fromPartial(object.projectTeam)
      : undefined;
    return message;
  },
};

function createBaseChecksummedData(): ChecksummedData {
  return { content: Buffer.alloc(0), crc32c: undefined };
}

export const ChecksummedData: MessageFns<ChecksummedData> = {
  encode(message: ChecksummedData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.content.length !== 0) {
      writer.uint32(10).bytes(message.content);
    }
    if (message.crc32c !== undefined) {
      writer.uint32(21).fixed32(message.crc32c);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ChecksummedData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChecksummedData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.content = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.crc32c = reader.fixed32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ChecksummedData {
    return {
      content: isSet(object.content) ? Buffer.from(bytesFromBase64(object.content)) : Buffer.alloc(0),
      crc32c: isSet(object.crc32c) ? globalThis.Number(object.crc32c) : undefined,
    };
  },

  toJSON(message: ChecksummedData): unknown {
    const obj: any = {};
    if (message.content.length !== 0) {
      obj.content = base64FromBytes(message.content);
    }
    if (message.crc32c !== undefined) {
      obj.crc32c = Math.round(message.crc32c);
    }
    return obj;
  },

  create(base?: DeepPartial<ChecksummedData>): ChecksummedData {
    return ChecksummedData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ChecksummedData>): ChecksummedData {
    const message = createBaseChecksummedData();
    message.content = object.content ?? Buffer.alloc(0);
    message.crc32c = object.crc32c ?? undefined;
    return message;
  },
};

function createBaseObjectChecksums(): ObjectChecksums {
  return { crc32c: undefined, md5Hash: Buffer.alloc(0) };
}

export const ObjectChecksums: MessageFns<ObjectChecksums> = {
  encode(message: ObjectChecksums, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.crc32c !== undefined) {
      writer.uint32(13).fixed32(message.crc32c);
    }
    if (message.md5Hash.length !== 0) {
      writer.uint32(18).bytes(message.md5Hash);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectChecksums {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectChecksums();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.crc32c = reader.fixed32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.md5Hash = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectChecksums {
    return {
      crc32c: isSet(object.crc32c) ? globalThis.Number(object.crc32c) : undefined,
      md5Hash: isSet(object.md5Hash) ? Buffer.from(bytesFromBase64(object.md5Hash)) : Buffer.alloc(0),
    };
  },

  toJSON(message: ObjectChecksums): unknown {
    const obj: any = {};
    if (message.crc32c !== undefined) {
      obj.crc32c = Math.round(message.crc32c);
    }
    if (message.md5Hash.length !== 0) {
      obj.md5Hash = base64FromBytes(message.md5Hash);
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectChecksums>): ObjectChecksums {
    return ObjectChecksums.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectChecksums>): ObjectChecksums {
    const message = createBaseObjectChecksums();
    message.crc32c = object.crc32c ?? undefined;
    message.md5Hash = object.md5Hash ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCustomerEncryption(): CustomerEncryption {
  return { encryptionAlgorithm: "", keySha256Bytes: Buffer.alloc(0) };
}

export const CustomerEncryption: MessageFns<CustomerEncryption> = {
  encode(message: CustomerEncryption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encryptionAlgorithm !== "") {
      writer.uint32(10).string(message.encryptionAlgorithm);
    }
    if (message.keySha256Bytes.length !== 0) {
      writer.uint32(26).bytes(message.keySha256Bytes);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomerEncryption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomerEncryption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.encryptionAlgorithm = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.keySha256Bytes = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomerEncryption {
    return {
      encryptionAlgorithm: isSet(object.encryptionAlgorithm) ? globalThis.String(object.encryptionAlgorithm) : "",
      keySha256Bytes: isSet(object.keySha256Bytes)
        ? Buffer.from(bytesFromBase64(object.keySha256Bytes))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: CustomerEncryption): unknown {
    const obj: any = {};
    if (message.encryptionAlgorithm !== "") {
      obj.encryptionAlgorithm = message.encryptionAlgorithm;
    }
    if (message.keySha256Bytes.length !== 0) {
      obj.keySha256Bytes = base64FromBytes(message.keySha256Bytes);
    }
    return obj;
  },

  create(base?: DeepPartial<CustomerEncryption>): CustomerEncryption {
    return CustomerEncryption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomerEncryption>): CustomerEncryption {
    const message = createBaseCustomerEncryption();
    message.encryptionAlgorithm = object.encryptionAlgorithm ?? "";
    message.keySha256Bytes = object.keySha256Bytes ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseObject(): Object {
  return {
    name: "",
    bucket: "",
    etag: "",
    generation: Long.ZERO,
    metageneration: Long.ZERO,
    storageClass: "",
    size: Long.ZERO,
    contentEncoding: "",
    contentDisposition: "",
    cacheControl: "",
    acl: [],
    contentLanguage: "",
    deleteTime: undefined,
    contentType: "",
    createTime: undefined,
    componentCount: 0,
    checksums: undefined,
    updateTime: undefined,
    kmsKey: "",
    updateStorageClassTime: undefined,
    temporaryHold: false,
    retentionExpireTime: undefined,
    metadata: {},
    eventBasedHold: undefined,
    owner: undefined,
    customerEncryption: undefined,
    customTime: undefined,
    softDeleteTime: undefined,
    hardDeleteTime: undefined,
  };
}

export const Object: MessageFns<Object> = {
  encode(message: Object, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.bucket !== "") {
      writer.uint32(18).string(message.bucket);
    }
    if (message.etag !== "") {
      writer.uint32(218).string(message.etag);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    if (!message.metageneration.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.metageneration.toString());
    }
    if (message.storageClass !== "") {
      writer.uint32(42).string(message.storageClass);
    }
    if (!message.size.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.size.toString());
    }
    if (message.contentEncoding !== "") {
      writer.uint32(58).string(message.contentEncoding);
    }
    if (message.contentDisposition !== "") {
      writer.uint32(66).string(message.contentDisposition);
    }
    if (message.cacheControl !== "") {
      writer.uint32(74).string(message.cacheControl);
    }
    for (const v of message.acl) {
      ObjectAccessControl.encode(v!, writer.uint32(82).fork()).join();
    }
    if (message.contentLanguage !== "") {
      writer.uint32(90).string(message.contentLanguage);
    }
    if (message.deleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deleteTime), writer.uint32(98).fork()).join();
    }
    if (message.contentType !== "") {
      writer.uint32(106).string(message.contentType);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(114).fork()).join();
    }
    if (message.componentCount !== 0) {
      writer.uint32(120).int32(message.componentCount);
    }
    if (message.checksums !== undefined) {
      ObjectChecksums.encode(message.checksums, writer.uint32(130).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(138).fork()).join();
    }
    if (message.kmsKey !== "") {
      writer.uint32(146).string(message.kmsKey);
    }
    if (message.updateStorageClassTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateStorageClassTime), writer.uint32(154).fork()).join();
    }
    if (message.temporaryHold !== false) {
      writer.uint32(160).bool(message.temporaryHold);
    }
    if (message.retentionExpireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.retentionExpireTime), writer.uint32(170).fork()).join();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      Object_MetadataEntry.encode({ key: key as any, value }, writer.uint32(178).fork()).join();
    });
    if (message.eventBasedHold !== undefined) {
      writer.uint32(184).bool(message.eventBasedHold);
    }
    if (message.owner !== undefined) {
      Owner.encode(message.owner, writer.uint32(194).fork()).join();
    }
    if (message.customerEncryption !== undefined) {
      CustomerEncryption.encode(message.customerEncryption, writer.uint32(202).fork()).join();
    }
    if (message.customTime !== undefined) {
      Timestamp.encode(toTimestamp(message.customTime), writer.uint32(210).fork()).join();
    }
    if (message.softDeleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.softDeleteTime), writer.uint32(226).fork()).join();
    }
    if (message.hardDeleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.hardDeleteTime), writer.uint32(234).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Object {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObject();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 27:
          if (tag !== 218) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.metageneration = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.storageClass = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.size = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.contentEncoding = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.contentDisposition = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.cacheControl = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.acl.push(ObjectAccessControl.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.contentLanguage = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.deleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.contentType = reader.string();
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 15:
          if (tag !== 120) {
            break;
          }

          message.componentCount = reader.int32();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.checksums = ObjectChecksums.decode(reader, reader.uint32());
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 18:
          if (tag !== 146) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.updateStorageClassTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 20:
          if (tag !== 160) {
            break;
          }

          message.temporaryHold = reader.bool();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.retentionExpireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          const entry22 = Object_MetadataEntry.decode(reader, reader.uint32());
          if (entry22.value !== undefined) {
            message.metadata[entry22.key] = entry22.value;
          }
          continue;
        case 23:
          if (tag !== 184) {
            break;
          }

          message.eventBasedHold = reader.bool();
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.owner = Owner.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.customerEncryption = CustomerEncryption.decode(reader, reader.uint32());
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.customTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 28:
          if (tag !== 226) {
            break;
          }

          message.softDeleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.hardDeleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Object {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      metageneration: isSet(object.metageneration) ? Long.fromValue(object.metageneration) : Long.ZERO,
      storageClass: isSet(object.storageClass) ? globalThis.String(object.storageClass) : "",
      size: isSet(object.size) ? Long.fromValue(object.size) : Long.ZERO,
      contentEncoding: isSet(object.contentEncoding) ? globalThis.String(object.contentEncoding) : "",
      contentDisposition: isSet(object.contentDisposition) ? globalThis.String(object.contentDisposition) : "",
      cacheControl: isSet(object.cacheControl) ? globalThis.String(object.cacheControl) : "",
      acl: globalThis.Array.isArray(object?.acl) ? object.acl.map((e: any) => ObjectAccessControl.fromJSON(e)) : [],
      contentLanguage: isSet(object.contentLanguage) ? globalThis.String(object.contentLanguage) : "",
      deleteTime: isSet(object.deleteTime) ? fromJsonTimestamp(object.deleteTime) : undefined,
      contentType: isSet(object.contentType) ? globalThis.String(object.contentType) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      componentCount: isSet(object.componentCount) ? globalThis.Number(object.componentCount) : 0,
      checksums: isSet(object.checksums) ? ObjectChecksums.fromJSON(object.checksums) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "",
      updateStorageClassTime: isSet(object.updateStorageClassTime)
        ? fromJsonTimestamp(object.updateStorageClassTime)
        : undefined,
      temporaryHold: isSet(object.temporaryHold) ? globalThis.Boolean(object.temporaryHold) : false,
      retentionExpireTime: isSet(object.retentionExpireTime)
        ? fromJsonTimestamp(object.retentionExpireTime)
        : undefined,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      eventBasedHold: isSet(object.eventBasedHold) ? globalThis.Boolean(object.eventBasedHold) : undefined,
      owner: isSet(object.owner) ? Owner.fromJSON(object.owner) : undefined,
      customerEncryption: isSet(object.customerEncryption)
        ? CustomerEncryption.fromJSON(object.customerEncryption)
        : undefined,
      customTime: isSet(object.customTime) ? fromJsonTimestamp(object.customTime) : undefined,
      softDeleteTime: isSet(object.softDeleteTime) ? fromJsonTimestamp(object.softDeleteTime) : undefined,
      hardDeleteTime: isSet(object.hardDeleteTime) ? fromJsonTimestamp(object.hardDeleteTime) : undefined,
    };
  },

  toJSON(message: Object): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (!message.metageneration.equals(Long.ZERO)) {
      obj.metageneration = (message.metageneration || Long.ZERO).toString();
    }
    if (message.storageClass !== "") {
      obj.storageClass = message.storageClass;
    }
    if (!message.size.equals(Long.ZERO)) {
      obj.size = (message.size || Long.ZERO).toString();
    }
    if (message.contentEncoding !== "") {
      obj.contentEncoding = message.contentEncoding;
    }
    if (message.contentDisposition !== "") {
      obj.contentDisposition = message.contentDisposition;
    }
    if (message.cacheControl !== "") {
      obj.cacheControl = message.cacheControl;
    }
    if (message.acl?.length) {
      obj.acl = message.acl.map((e) => ObjectAccessControl.toJSON(e));
    }
    if (message.contentLanguage !== "") {
      obj.contentLanguage = message.contentLanguage;
    }
    if (message.deleteTime !== undefined) {
      obj.deleteTime = message.deleteTime.toISOString();
    }
    if (message.contentType !== "") {
      obj.contentType = message.contentType;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.componentCount !== 0) {
      obj.componentCount = Math.round(message.componentCount);
    }
    if (message.checksums !== undefined) {
      obj.checksums = ObjectChecksums.toJSON(message.checksums);
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    if (message.updateStorageClassTime !== undefined) {
      obj.updateStorageClassTime = message.updateStorageClassTime.toISOString();
    }
    if (message.temporaryHold !== false) {
      obj.temporaryHold = message.temporaryHold;
    }
    if (message.retentionExpireTime !== undefined) {
      obj.retentionExpireTime = message.retentionExpireTime.toISOString();
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    if (message.eventBasedHold !== undefined) {
      obj.eventBasedHold = message.eventBasedHold;
    }
    if (message.owner !== undefined) {
      obj.owner = Owner.toJSON(message.owner);
    }
    if (message.customerEncryption !== undefined) {
      obj.customerEncryption = CustomerEncryption.toJSON(message.customerEncryption);
    }
    if (message.customTime !== undefined) {
      obj.customTime = message.customTime.toISOString();
    }
    if (message.softDeleteTime !== undefined) {
      obj.softDeleteTime = message.softDeleteTime.toISOString();
    }
    if (message.hardDeleteTime !== undefined) {
      obj.hardDeleteTime = message.hardDeleteTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<Object>): Object {
    return Object.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Object>): Object {
    const message = createBaseObject();
    message.name = object.name ?? "";
    message.bucket = object.bucket ?? "";
    message.etag = object.etag ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.metageneration = (object.metageneration !== undefined && object.metageneration !== null)
      ? Long.fromValue(object.metageneration)
      : Long.ZERO;
    message.storageClass = object.storageClass ?? "";
    message.size = (object.size !== undefined && object.size !== null) ? Long.fromValue(object.size) : Long.ZERO;
    message.contentEncoding = object.contentEncoding ?? "";
    message.contentDisposition = object.contentDisposition ?? "";
    message.cacheControl = object.cacheControl ?? "";
    message.acl = object.acl?.map((e) => ObjectAccessControl.fromPartial(e)) || [];
    message.contentLanguage = object.contentLanguage ?? "";
    message.deleteTime = object.deleteTime ?? undefined;
    message.contentType = object.contentType ?? "";
    message.createTime = object.createTime ?? undefined;
    message.componentCount = object.componentCount ?? 0;
    message.checksums = (object.checksums !== undefined && object.checksums !== null)
      ? ObjectChecksums.fromPartial(object.checksums)
      : undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.kmsKey = object.kmsKey ?? "";
    message.updateStorageClassTime = object.updateStorageClassTime ?? undefined;
    message.temporaryHold = object.temporaryHold ?? false;
    message.retentionExpireTime = object.retentionExpireTime ?? undefined;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.eventBasedHold = object.eventBasedHold ?? undefined;
    message.owner = (object.owner !== undefined && object.owner !== null) ? Owner.fromPartial(object.owner) : undefined;
    message.customerEncryption = (object.customerEncryption !== undefined && object.customerEncryption !== null)
      ? CustomerEncryption.fromPartial(object.customerEncryption)
      : undefined;
    message.customTime = object.customTime ?? undefined;
    message.softDeleteTime = object.softDeleteTime ?? undefined;
    message.hardDeleteTime = object.hardDeleteTime ?? undefined;
    return message;
  },
};

function createBaseObject_MetadataEntry(): Object_MetadataEntry {
  return { key: "", value: "" };
}

export const Object_MetadataEntry: MessageFns<Object_MetadataEntry> = {
  encode(message: Object_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Object_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObject_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Object_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Object_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Object_MetadataEntry>): Object_MetadataEntry {
    return Object_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Object_MetadataEntry>): Object_MetadataEntry {
    const message = createBaseObject_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseObjectAccessControl(): ObjectAccessControl {
  return {
    role: "",
    id: "",
    entity: "",
    entityAlt: "",
    entityId: "",
    etag: "",
    email: "",
    domain: "",
    projectTeam: undefined,
  };
}

export const ObjectAccessControl: MessageFns<ObjectAccessControl> = {
  encode(message: ObjectAccessControl, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.role !== "") {
      writer.uint32(10).string(message.role);
    }
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    if (message.entity !== "") {
      writer.uint32(26).string(message.entity);
    }
    if (message.entityAlt !== "") {
      writer.uint32(74).string(message.entityAlt);
    }
    if (message.entityId !== "") {
      writer.uint32(34).string(message.entityId);
    }
    if (message.etag !== "") {
      writer.uint32(66).string(message.etag);
    }
    if (message.email !== "") {
      writer.uint32(42).string(message.email);
    }
    if (message.domain !== "") {
      writer.uint32(50).string(message.domain);
    }
    if (message.projectTeam !== undefined) {
      ProjectTeam.encode(message.projectTeam, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectAccessControl {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectAccessControl();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.role = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.entityAlt = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.entityId = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.email = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.domain = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.projectTeam = ProjectTeam.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectAccessControl {
    return {
      role: isSet(object.role) ? globalThis.String(object.role) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      entity: isSet(object.entity) ? globalThis.String(object.entity) : "",
      entityAlt: isSet(object.entityAlt) ? globalThis.String(object.entityAlt) : "",
      entityId: isSet(object.entityId) ? globalThis.String(object.entityId) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      email: isSet(object.email) ? globalThis.String(object.email) : "",
      domain: isSet(object.domain) ? globalThis.String(object.domain) : "",
      projectTeam: isSet(object.projectTeam) ? ProjectTeam.fromJSON(object.projectTeam) : undefined,
    };
  },

  toJSON(message: ObjectAccessControl): unknown {
    const obj: any = {};
    if (message.role !== "") {
      obj.role = message.role;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.entity !== "") {
      obj.entity = message.entity;
    }
    if (message.entityAlt !== "") {
      obj.entityAlt = message.entityAlt;
    }
    if (message.entityId !== "") {
      obj.entityId = message.entityId;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.email !== "") {
      obj.email = message.email;
    }
    if (message.domain !== "") {
      obj.domain = message.domain;
    }
    if (message.projectTeam !== undefined) {
      obj.projectTeam = ProjectTeam.toJSON(message.projectTeam);
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectAccessControl>): ObjectAccessControl {
    return ObjectAccessControl.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectAccessControl>): ObjectAccessControl {
    const message = createBaseObjectAccessControl();
    message.role = object.role ?? "";
    message.id = object.id ?? "";
    message.entity = object.entity ?? "";
    message.entityAlt = object.entityAlt ?? "";
    message.entityId = object.entityId ?? "";
    message.etag = object.etag ?? "";
    message.email = object.email ?? "";
    message.domain = object.domain ?? "";
    message.projectTeam = (object.projectTeam !== undefined && object.projectTeam !== null)
      ? ProjectTeam.fromPartial(object.projectTeam)
      : undefined;
    return message;
  },
};

function createBaseListObjectsResponse(): ListObjectsResponse {
  return { objects: [], prefixes: [], nextPageToken: "" };
}

export const ListObjectsResponse: MessageFns<ListObjectsResponse> = {
  encode(message: ListObjectsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.objects) {
      Object.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.prefixes) {
      writer.uint32(18).string(v!);
    }
    if (message.nextPageToken !== "") {
      writer.uint32(26).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListObjectsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListObjectsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.objects.push(Object.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.prefixes.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListObjectsResponse {
    return {
      objects: globalThis.Array.isArray(object?.objects) ? object.objects.map((e: any) => Object.fromJSON(e)) : [],
      prefixes: globalThis.Array.isArray(object?.prefixes) ? object.prefixes.map((e: any) => globalThis.String(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListObjectsResponse): unknown {
    const obj: any = {};
    if (message.objects?.length) {
      obj.objects = message.objects.map((e) => Object.toJSON(e));
    }
    if (message.prefixes?.length) {
      obj.prefixes = message.prefixes;
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListObjectsResponse>): ListObjectsResponse {
    return ListObjectsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListObjectsResponse>): ListObjectsResponse {
    const message = createBaseListObjectsResponse();
    message.objects = object.objects?.map((e) => Object.fromPartial(e)) || [];
    message.prefixes = object.prefixes?.map((e) => e) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseProjectTeam(): ProjectTeam {
  return { projectNumber: "", team: "" };
}

export const ProjectTeam: MessageFns<ProjectTeam> = {
  encode(message: ProjectTeam, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectNumber !== "") {
      writer.uint32(10).string(message.projectNumber);
    }
    if (message.team !== "") {
      writer.uint32(18).string(message.team);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ProjectTeam {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProjectTeam();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectNumber = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.team = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProjectTeam {
    return {
      projectNumber: isSet(object.projectNumber) ? globalThis.String(object.projectNumber) : "",
      team: isSet(object.team) ? globalThis.String(object.team) : "",
    };
  },

  toJSON(message: ProjectTeam): unknown {
    const obj: any = {};
    if (message.projectNumber !== "") {
      obj.projectNumber = message.projectNumber;
    }
    if (message.team !== "") {
      obj.team = message.team;
    }
    return obj;
  },

  create(base?: DeepPartial<ProjectTeam>): ProjectTeam {
    return ProjectTeam.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ProjectTeam>): ProjectTeam {
    const message = createBaseProjectTeam();
    message.projectNumber = object.projectNumber ?? "";
    message.team = object.team ?? "";
    return message;
  },
};

function createBaseOwner(): Owner {
  return { entity: "", entityId: "" };
}

export const Owner: MessageFns<Owner> = {
  encode(message: Owner, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== "") {
      writer.uint32(10).string(message.entity);
    }
    if (message.entityId !== "") {
      writer.uint32(18).string(message.entityId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Owner {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOwner();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entity = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entityId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Owner {
    return {
      entity: isSet(object.entity) ? globalThis.String(object.entity) : "",
      entityId: isSet(object.entityId) ? globalThis.String(object.entityId) : "",
    };
  },

  toJSON(message: Owner): unknown {
    const obj: any = {};
    if (message.entity !== "") {
      obj.entity = message.entity;
    }
    if (message.entityId !== "") {
      obj.entityId = message.entityId;
    }
    return obj;
  },

  create(base?: DeepPartial<Owner>): Owner {
    return Owner.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Owner>): Owner {
    const message = createBaseOwner();
    message.entity = object.entity ?? "";
    message.entityId = object.entityId ?? "";
    return message;
  },
};

function createBaseContentRange(): ContentRange {
  return { start: Long.ZERO, end: Long.ZERO, completeLength: Long.ZERO };
}

export const ContentRange: MessageFns<ContentRange> = {
  encode(message: ContentRange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.start.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.start.toString());
    }
    if (!message.end.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.end.toString());
    }
    if (!message.completeLength.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.completeLength.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContentRange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContentRange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.start = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.end = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.completeLength = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContentRange {
    return {
      start: isSet(object.start) ? Long.fromValue(object.start) : Long.ZERO,
      end: isSet(object.end) ? Long.fromValue(object.end) : Long.ZERO,
      completeLength: isSet(object.completeLength) ? Long.fromValue(object.completeLength) : Long.ZERO,
    };
  },

  toJSON(message: ContentRange): unknown {
    const obj: any = {};
    if (!message.start.equals(Long.ZERO)) {
      obj.start = (message.start || Long.ZERO).toString();
    }
    if (!message.end.equals(Long.ZERO)) {
      obj.end = (message.end || Long.ZERO).toString();
    }
    if (!message.completeLength.equals(Long.ZERO)) {
      obj.completeLength = (message.completeLength || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<ContentRange>): ContentRange {
    return ContentRange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContentRange>): ContentRange {
    const message = createBaseContentRange();
    message.start = (object.start !== undefined && object.start !== null) ? Long.fromValue(object.start) : Long.ZERO;
    message.end = (object.end !== undefined && object.end !== null) ? Long.fromValue(object.end) : Long.ZERO;
    message.completeLength = (object.completeLength !== undefined && object.completeLength !== null)
      ? Long.fromValue(object.completeLength)
      : Long.ZERO;
    return message;
  },
};

function createBaseDeleteNotificationConfigRequest(): DeleteNotificationConfigRequest {
  return { name: "" };
}

export const DeleteNotificationConfigRequest: MessageFns<DeleteNotificationConfigRequest> = {
  encode(message: DeleteNotificationConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteNotificationConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteNotificationConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteNotificationConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteNotificationConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteNotificationConfigRequest>): DeleteNotificationConfigRequest {
    return DeleteNotificationConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteNotificationConfigRequest>): DeleteNotificationConfigRequest {
    const message = createBaseDeleteNotificationConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGetNotificationConfigRequest(): GetNotificationConfigRequest {
  return { name: "" };
}

export const GetNotificationConfigRequest: MessageFns<GetNotificationConfigRequest> = {
  encode(message: GetNotificationConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetNotificationConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetNotificationConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetNotificationConfigRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetNotificationConfigRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetNotificationConfigRequest>): GetNotificationConfigRequest {
    return GetNotificationConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetNotificationConfigRequest>): GetNotificationConfigRequest {
    const message = createBaseGetNotificationConfigRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateNotificationConfigRequest(): CreateNotificationConfigRequest {
  return { parent: "", notificationConfig: undefined };
}

export const CreateNotificationConfigRequest: MessageFns<CreateNotificationConfigRequest> = {
  encode(message: CreateNotificationConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.notificationConfig !== undefined) {
      NotificationConfig.encode(message.notificationConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateNotificationConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateNotificationConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.notificationConfig = NotificationConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateNotificationConfigRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      notificationConfig: isSet(object.notificationConfig)
        ? NotificationConfig.fromJSON(object.notificationConfig)
        : undefined,
    };
  },

  toJSON(message: CreateNotificationConfigRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.notificationConfig !== undefined) {
      obj.notificationConfig = NotificationConfig.toJSON(message.notificationConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateNotificationConfigRequest>): CreateNotificationConfigRequest {
    return CreateNotificationConfigRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateNotificationConfigRequest>): CreateNotificationConfigRequest {
    const message = createBaseCreateNotificationConfigRequest();
    message.parent = object.parent ?? "";
    message.notificationConfig = (object.notificationConfig !== undefined && object.notificationConfig !== null)
      ? NotificationConfig.fromPartial(object.notificationConfig)
      : undefined;
    return message;
  },
};

function createBaseListNotificationConfigsRequest(): ListNotificationConfigsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListNotificationConfigsRequest: MessageFns<ListNotificationConfigsRequest> = {
  encode(message: ListNotificationConfigsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListNotificationConfigsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListNotificationConfigsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListNotificationConfigsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListNotificationConfigsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListNotificationConfigsRequest>): ListNotificationConfigsRequest {
    return ListNotificationConfigsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListNotificationConfigsRequest>): ListNotificationConfigsRequest {
    const message = createBaseListNotificationConfigsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListNotificationConfigsResponse(): ListNotificationConfigsResponse {
  return { notificationConfigs: [], nextPageToken: "" };
}

export const ListNotificationConfigsResponse: MessageFns<ListNotificationConfigsResponse> = {
  encode(message: ListNotificationConfigsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.notificationConfigs) {
      NotificationConfig.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListNotificationConfigsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListNotificationConfigsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.notificationConfigs.push(NotificationConfig.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListNotificationConfigsResponse {
    return {
      notificationConfigs: globalThis.Array.isArray(object?.notificationConfigs)
        ? object.notificationConfigs.map((e: any) => NotificationConfig.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListNotificationConfigsResponse): unknown {
    const obj: any = {};
    if (message.notificationConfigs?.length) {
      obj.notificationConfigs = message.notificationConfigs.map((e) => NotificationConfig.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListNotificationConfigsResponse>): ListNotificationConfigsResponse {
    return ListNotificationConfigsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListNotificationConfigsResponse>): ListNotificationConfigsResponse {
    const message = createBaseListNotificationConfigsResponse();
    message.notificationConfigs = object.notificationConfigs?.map((e) => NotificationConfig.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseNotificationConfig(): NotificationConfig {
  return {
    name: "",
    topic: "",
    etag: "",
    eventTypes: [],
    customAttributes: {},
    objectNamePrefix: "",
    payloadFormat: "",
  };
}

export const NotificationConfig: MessageFns<NotificationConfig> = {
  encode(message: NotificationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.topic !== "") {
      writer.uint32(18).string(message.topic);
    }
    if (message.etag !== "") {
      writer.uint32(58).string(message.etag);
    }
    for (const v of message.eventTypes) {
      writer.uint32(26).string(v!);
    }
    Object.entries(message.customAttributes).forEach(([key, value]) => {
      NotificationConfig_CustomAttributesEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.objectNamePrefix !== "") {
      writer.uint32(42).string(message.objectNamePrefix);
    }
    if (message.payloadFormat !== "") {
      writer.uint32(50).string(message.payloadFormat);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NotificationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNotificationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.eventTypes.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = NotificationConfig_CustomAttributesEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.customAttributes[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.objectNamePrefix = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.payloadFormat = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NotificationConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      eventTypes: globalThis.Array.isArray(object?.eventTypes)
        ? object.eventTypes.map((e: any) => globalThis.String(e))
        : [],
      customAttributes: isObject(object.customAttributes)
        ? Object.entries(object.customAttributes).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      objectNamePrefix: isSet(object.objectNamePrefix) ? globalThis.String(object.objectNamePrefix) : "",
      payloadFormat: isSet(object.payloadFormat) ? globalThis.String(object.payloadFormat) : "",
    };
  },

  toJSON(message: NotificationConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.eventTypes?.length) {
      obj.eventTypes = message.eventTypes;
    }
    if (message.customAttributes) {
      const entries = Object.entries(message.customAttributes);
      if (entries.length > 0) {
        obj.customAttributes = {};
        entries.forEach(([k, v]) => {
          obj.customAttributes[k] = v;
        });
      }
    }
    if (message.objectNamePrefix !== "") {
      obj.objectNamePrefix = message.objectNamePrefix;
    }
    if (message.payloadFormat !== "") {
      obj.payloadFormat = message.payloadFormat;
    }
    return obj;
  },

  create(base?: DeepPartial<NotificationConfig>): NotificationConfig {
    return NotificationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NotificationConfig>): NotificationConfig {
    const message = createBaseNotificationConfig();
    message.name = object.name ?? "";
    message.topic = object.topic ?? "";
    message.etag = object.etag ?? "";
    message.eventTypes = object.eventTypes?.map((e) => e) || [];
    message.customAttributes = Object.entries(object.customAttributes ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.objectNamePrefix = object.objectNamePrefix ?? "";
    message.payloadFormat = object.payloadFormat ?? "";
    return message;
  },
};

function createBaseNotificationConfig_CustomAttributesEntry(): NotificationConfig_CustomAttributesEntry {
  return { key: "", value: "" };
}

export const NotificationConfig_CustomAttributesEntry: MessageFns<NotificationConfig_CustomAttributesEntry> = {
  encode(message: NotificationConfig_CustomAttributesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NotificationConfig_CustomAttributesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNotificationConfig_CustomAttributesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NotificationConfig_CustomAttributesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: NotificationConfig_CustomAttributesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<NotificationConfig_CustomAttributesEntry>): NotificationConfig_CustomAttributesEntry {
    return NotificationConfig_CustomAttributesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NotificationConfig_CustomAttributesEntry>): NotificationConfig_CustomAttributesEntry {
    const message = createBaseNotificationConfig_CustomAttributesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

/**
 * ## API Overview and Naming Syntax
 *
 * The Cloud Storage gRPC API allows applications to read and write data through
 * the abstractions of buckets and objects. For a description of these
 * abstractions please see https://cloud.google.com/storage/docs.
 *
 * Resources are named as follows:
 *   - Projects are referred to as they are defined by the Resource Manager API,
 *     using strings like `projects/123456` or `projects/my-string-id`.
 *   - Buckets are named using string names of the form:
 *     `projects/{project}/buckets/{bucket}`
 *     For globally unique buckets, `_` may be substituted for the project.
 *   - Objects are uniquely identified by their name along with the name of the
 *     bucket they belong to, as separate strings in this API. For example:
 *
 *       ReadObjectRequest {
 *         bucket: 'projects/_/buckets/my-bucket'
 *         object: 'my-object'
 *       }
 *     Note that object names can contain `/` characters, which are treated as
 *     any other character (no special directory semantics).
 */
export type StorageDefinition = typeof StorageDefinition;
export const StorageDefinition = {
  name: "Storage",
  fullName: "google.storage.v2.Storage",
  methods: {
    /** Permanently deletes an empty bucket. */
    deleteBucket: {
      name: "DeleteBucket",
      requestType: DeleteBucketRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365834: [
            Buffer.from([
              21,
              18,
              19,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Returns metadata for the specified bucket. */
    getBucket: {
      name: "GetBucket",
      requestType: GetBucketRequest,
      requestStream: false,
      responseType: Bucket,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365834: [
            Buffer.from([
              21,
              18,
              19,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new bucket. */
    createBucket: {
      name: "CreateBucket",
      requestType: CreateBucketRequest,
      requestStream: false,
      responseType: Bucket,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              117,
              99,
              107,
              101,
              116,
              44,
              98,
              117,
              99,
              107,
              101,
              116,
              95,
              105,
              100,
            ]),
          ],
          578365834: [
            Buffer.from([
              56,
              18,
              22,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              12,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              42,
              42,
              125,
              18,
              30,
              10,
              14,
              98,
              117,
              99,
              107,
              101,
              116,
              46,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              18,
              12,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Retrieves a list of buckets for a given project. */
    listBuckets: {
      name: "ListBuckets",
      requestType: ListBucketsRequest,
      requestStream: false,
      responseType: ListBucketsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365834: [
            Buffer.from([
              24,
              18,
              22,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              12,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Locks retention policy on a bucket. */
    lockBucketRetentionPolicy: {
      name: "LockBucketRetentionPolicy",
      requestType: LockBucketRetentionPolicyRequest,
      requestStream: false,
      responseType: Bucket,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 98, 117, 99, 107, 101, 116])],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the IAM policy for a specified bucket.
     * The `resource` field in the request should be
     * `projects/_/buckets/{bucket}`.
     */
    getIamPolicy: {
      name: "GetIamPolicy",
      requestType: GetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 114, 101, 115, 111, 117, 114, 99, 101])],
          578365834: [
            Buffer.from([
              25,
              18,
              23,
              10,
              8,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates an IAM policy for the specified bucket.
     * The `resource` field in the request should be
     * `projects/_/buckets/{bucket}`.
     */
    setIamPolicy: {
      name: "SetIamPolicy",
      requestType: SetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 114, 101, 115, 111, 117, 114, 99, 101, 44, 112, 111, 108, 105, 99, 121])],
          578365834: [
            Buffer.from([
              25,
              18,
              23,
              10,
              8,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Tests a set of permissions on the given bucket, object, or managed folder
     * to see which, if any, are held by the caller.
     * The `resource` field in the request should be
     * `projects/_/buckets/{bucket}` for a bucket,
     * `projects/_/buckets/{bucket}/objects/{object}` for an object, or
     * `projects/_/buckets/{bucket}/managedFolders/{managedFolder}`
     * for a managed folder.
     */
    testIamPermissions: {
      name: "TestIamPermissions",
      requestType: TestIamPermissionsRequest,
      requestStream: false,
      responseType: TestIamPermissionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              44,
              112,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              140,
              1,
              18,
              23,
              10,
              8,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
              18,
              52,
              10,
              8,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              18,
              40,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              99,
              107,
              101,
              116,
              115,
              47,
              42,
              125,
              47,
              111,
              98,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              42,
              18,
              59,
              10,
              8,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              18,
              47,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              99,
              107,
              101,
              116,
              115,
              47,
              42,
              125,
              47,
              109,
              97,
              110,
              97,
              103,
              101,
              100,
              70,
              111,
              108,
              100,
              101,
              114,
              115,
              47,
              42,
              42,
            ]),
          ],
        },
      },
    },
    /** Updates a bucket. Equivalent to JSON API's storage.buckets.patch method. */
    updateBucket: {
      name: "UpdateBucket",
      requestType: UpdateBucketRequest,
      requestStream: false,
      responseType: Bucket,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([18, 98, 117, 99, 107, 101, 116, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365834: [
            Buffer.from([
              28,
              18,
              26,
              10,
              11,
              98,
              117,
              99,
              107,
              101,
              116,
              46,
              110,
              97,
              109,
              101,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Concatenates a list of existing objects into a new object in the same
     * bucket.
     */
    composeObject: {
      name: "ComposeObject",
      requestType: ComposeObjectRequest,
      requestStream: false,
      responseType: Object,
      responseStream: false,
      options: {
        _unknownFields: {
          578365834: [
            Buffer.from([
              35,
              18,
              33,
              10,
              18,
              100,
              101,
              115,
              116,
              105,
              110,
              97,
              116,
              105,
              111,
              110,
              46,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes an object and its metadata.
     *
     * Deletions are normally permanent when versioning is disabled or whenever
     * the generation parameter is used. However, if soft delete is enabled for
     * the bucket, deleted objects can be restored using RestoreObject until the
     * soft delete retention period has passed.
     */
    deleteObject: {
      name: "DeleteObject",
      requestType: DeleteObjectRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([13, 98, 117, 99, 107, 101, 116, 44, 111, 98, 106, 101, 99, 116]),
            Buffer.from([
              24,
              98,
              117,
              99,
              107,
              101,
              116,
              44,
              111,
              98,
              106,
              101,
              99,
              116,
              44,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Restores a soft-deleted object. */
    restoreObject: {
      name: "RestoreObject",
      requestType: RestoreObjectRequest,
      requestStream: false,
      responseType: Object,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              24,
              98,
              117,
              99,
              107,
              101,
              116,
              44,
              111,
              98,
              106,
              101,
              99,
              116,
              44,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Cancels an in-progress resumable upload.
     *
     * Any attempts to write to the resumable upload after cancelling the upload
     * will fail.
     *
     * The behavior for currently in progress write operations is not guaranteed -
     * they could either complete before the cancellation or fail if the
     * cancellation completes first.
     */
    cancelResumableWrite: {
      name: "CancelResumableWrite",
      requestType: CancelResumableWriteRequest,
      requestStream: false,
      responseType: CancelResumableWriteResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([9, 117, 112, 108, 111, 97, 100, 95, 105, 100])],
          578365834: [
            Buffer.from([
              47,
              18,
              45,
              10,
              9,
              117,
              112,
              108,
              111,
              97,
              100,
              95,
              105,
              100,
              18,
              32,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              99,
              107,
              101,
              116,
              115,
              47,
              42,
              125,
              47,
              42,
              42,
            ]),
          ],
        },
      },
    },
    /** Retrieves an object's metadata. */
    getObject: {
      name: "GetObject",
      requestType: GetObjectRequest,
      requestStream: false,
      responseType: Object,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([13, 98, 117, 99, 107, 101, 116, 44, 111, 98, 106, 101, 99, 116]),
            Buffer.from([
              24,
              98,
              117,
              99,
              107,
              101,
              116,
              44,
              111,
              98,
              106,
              101,
              99,
              116,
              44,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Reads an object's data. */
    readObject: {
      name: "ReadObject",
      requestType: ReadObjectRequest,
      requestStream: false,
      responseType: ReadObjectResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([13, 98, 117, 99, 107, 101, 116, 44, 111, 98, 106, 101, 99, 116]),
            Buffer.from([
              24,
              98,
              117,
              99,
              107,
              101,
              116,
              44,
              111,
              98,
              106,
              101,
              99,
              116,
              44,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates an object's metadata.
     * Equivalent to JSON API's storage.objects.patch.
     */
    updateObject: {
      name: "UpdateObject",
      requestType: UpdateObjectRequest,
      requestStream: false,
      responseType: Object,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([18, 111, 98, 106, 101, 99, 116, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365834: [
            Buffer.from([
              30,
              18,
              28,
              10,
              13,
              111,
              98,
              106,
              101,
              99,
              116,
              46,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Stores a new object and metadata.
     *
     * An object can be written either in a single message stream or in a
     * resumable sequence of message streams. To write using a single stream,
     * the client should include in the first message of the stream an
     * `WriteObjectSpec` describing the destination bucket, object, and any
     * preconditions. Additionally, the final message must set 'finish_write' to
     * true, or else it is an error.
     *
     * For a resumable write, the client should instead call
     * `StartResumableWrite()`, populating a `WriteObjectSpec` into that request.
     * They should then attach the returned `upload_id` to the first message of
     * each following call to `WriteObject`. If the stream is closed before
     * finishing the upload (either explicitly by the client or due to a network
     * error or an error response from the server), the client should do as
     * follows:
     *   - Check the result Status of the stream, to determine if writing can be
     *     resumed on this stream or must be restarted from scratch (by calling
     *     `StartResumableWrite()`). The resumable errors are DEADLINE_EXCEEDED,
     *     INTERNAL, and UNAVAILABLE. For each case, the client should use binary
     *     exponential backoff before retrying.  Additionally, writes can be
     *     resumed after RESOURCE_EXHAUSTED errors, but only after taking
     *     appropriate measures, which may include reducing aggregate send rate
     *     across clients and/or requesting a quota increase for your project.
     *   - If the call to `WriteObject` returns `ABORTED`, that indicates
     *     concurrent attempts to update the resumable write, caused either by
     *     multiple racing clients or by a single client where the previous
     *     request was timed out on the client side but nonetheless reached the
     *     server. In this case the client should take steps to prevent further
     *     concurrent writes (e.g., increase the timeouts, stop using more than
     *     one process to perform the upload, etc.), and then should follow the
     *     steps below for resuming the upload.
     *   - For resumable errors, the client should call `QueryWriteStatus()` and
     *     then continue writing from the returned `persisted_size`. This may be
     *     less than the amount of data the client previously sent. Note also that
     *     it is acceptable to send data starting at an offset earlier than the
     *     returned `persisted_size`; in this case, the service will skip data at
     *     offsets that were already persisted (without checking that it matches
     *     the previously written data), and write only the data starting from the
     *     persisted offset. Even though the data isn't written, it may still
     *     incur a performance cost over resuming at the correct write offset.
     *     This behavior can make client-side handling simpler in some cases.
     *   - Clients must only send data that is a multiple of 256 KiB per message,
     *     unless the object is being finished with `finish_write` set to `true`.
     *
     * The service will not view the object as complete until the client has
     * sent a `WriteObjectRequest` with `finish_write` set to `true`. Sending any
     * requests on a stream after sending a request with `finish_write` set to
     * `true` will cause an error. The client **should** check the response it
     * receives to determine how much data the service was able to commit and
     * whether the service views the object as complete.
     *
     * Attempting to resume an already finalized object will result in an OK
     * status, with a WriteObjectResponse containing the finalized object's
     * metadata.
     *
     * Alternatively, the BidiWriteObject operation may be used to write an
     * object with controls over flushing and the ability to fetch the ability to
     * determine the current persisted size.
     */
    writeObject: {
      name: "WriteObject",
      requestType: WriteObjectRequest,
      requestStream: true,
      responseType: WriteObjectResponse,
      responseStream: false,
      options: {},
    },
    /**
     * Stores a new object and metadata.
     *
     * This is similar to the WriteObject call with the added support for
     * manual flushing of persisted state, and the ability to determine current
     * persisted size without closing the stream.
     *
     * The client may specify one or both of the `state_lookup` and `flush` fields
     * in each BidiWriteObjectRequest. If `flush` is specified, the data written
     * so far will be persisted to storage. If `state_lookup` is specified, the
     * service will respond with a BidiWriteObjectResponse that contains the
     * persisted size. If both `flush` and `state_lookup` are specified, the flush
     * will always occur before a `state_lookup`, so that both may be set in the
     * same request and the returned state will be the state of the object
     * post-flush. When the stream is closed, a BidiWriteObjectResponse will
     * always be sent to the client, regardless of the value of `state_lookup`.
     */
    bidiWriteObject: {
      name: "BidiWriteObject",
      requestType: BidiWriteObjectRequest,
      requestStream: true,
      responseType: BidiWriteObjectResponse,
      responseStream: true,
      options: {},
    },
    /** Retrieves a list of objects matching the criteria. */
    listObjects: {
      name: "ListObjects",
      requestType: ListObjectsRequest,
      requestStream: false,
      responseType: ListObjectsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Rewrites a source object to a destination object. Optionally overrides
     * metadata.
     */
    rewriteObject: {
      name: "RewriteObject",
      requestType: RewriteObjectRequest,
      requestStream: false,
      responseType: RewriteResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365834: [
            Buffer.from([
              52,
              18,
              15,
              10,
              13,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              33,
              10,
              18,
              100,
              101,
              115,
              116,
              105,
              110,
              97,
              116,
              105,
              111,
              110,
              95,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Starts a resumable write. How long the write operation remains valid, and
     * what happens when the write operation becomes invalid, are
     * service-dependent.
     */
    startResumableWrite: {
      name: "StartResumableWrite",
      requestType: StartResumableWriteRequest,
      requestStream: false,
      responseType: StartResumableWriteResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365834: [
            Buffer.from([
              50,
              18,
              48,
              10,
              33,
              119,
              114,
              105,
              116,
              101,
              95,
              111,
              98,
              106,
              101,
              99,
              116,
              95,
              115,
              112,
              101,
              99,
              46,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              46,
              98,
              117,
              99,
              107,
              101,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Determines the `persisted_size` for an object that is being written, which
     * can then be used as the `write_offset` for the next `Write()` call.
     *
     * If the object does not exist (i.e., the object has been deleted, or the
     * first `Write()` has not yet reached the service), this method returns the
     * error `NOT_FOUND`.
     *
     * The client **may** call `QueryWriteStatus()` at any time to determine how
     * much data has been processed for this object. This is useful if the
     * client is buffering data and needs to know which data can be safely
     * evicted. For any sequence of `QueryWriteStatus()` calls for a given
     * object name, the sequence of returned `persisted_size` values will be
     * non-decreasing.
     */
    queryWriteStatus: {
      name: "QueryWriteStatus",
      requestType: QueryWriteStatusRequest,
      requestStream: false,
      responseType: QueryWriteStatusResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([9, 117, 112, 108, 111, 97, 100, 95, 105, 100])],
          578365834: [
            Buffer.from([
              47,
              18,
              45,
              10,
              9,
              117,
              112,
              108,
              111,
              97,
              100,
              95,
              105,
              100,
              18,
              32,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              99,
              107,
              101,
              116,
              115,
              47,
              42,
              125,
              47,
              42,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Retrieves the name of a project's Google Cloud Storage service account.
     *
     * @deprecated
     */
    getServiceAccount: {
      name: "GetServiceAccount",
      requestType: GetServiceAccountRequest,
      requestStream: false,
      responseType: ServiceAccount,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([7, 112, 114, 111, 106, 101, 99, 116])],
          578365834: [Buffer.from([11, 18, 9, 10, 7, 112, 114, 111, 106, 101, 99, 116])],
        },
      },
    },
    /**
     * Creates a new HMAC key for the given service account.
     *
     * @deprecated
     */
    createHmacKey: {
      name: "CreateHmacKey",
      requestType: CreateHmacKeyRequest,
      requestStream: false,
      responseType: CreateHmacKeyResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              29,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              44,
              115,
              101,
              114,
              118,
              105,
              99,
              101,
              95,
              97,
              99,
              99,
              111,
              117,
              110,
              116,
              95,
              101,
              109,
              97,
              105,
              108,
            ]),
          ],
          578365834: [Buffer.from([11, 18, 9, 10, 7, 112, 114, 111, 106, 101, 99, 116])],
        },
      },
    },
    /**
     * Deletes a given HMAC key.  Key must be in an INACTIVE state.
     *
     * @deprecated
     */
    deleteHmacKey: {
      name: "DeleteHmacKey",
      requestType: DeleteHmacKeyRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([17, 97, 99, 99, 101, 115, 115, 95, 105, 100, 44, 112, 114, 111, 106, 101, 99, 116])],
          578365834: [Buffer.from([11, 18, 9, 10, 7, 112, 114, 111, 106, 101, 99, 116])],
        },
      },
    },
    /**
     * Gets an existing HMAC key metadata for the given id.
     *
     * @deprecated
     */
    getHmacKey: {
      name: "GetHmacKey",
      requestType: GetHmacKeyRequest,
      requestStream: false,
      responseType: HmacKeyMetadata,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([17, 97, 99, 99, 101, 115, 115, 95, 105, 100, 44, 112, 114, 111, 106, 101, 99, 116])],
          578365834: [Buffer.from([11, 18, 9, 10, 7, 112, 114, 111, 106, 101, 99, 116])],
        },
      },
    },
    /**
     * Lists HMAC keys under a given project with the additional filters provided.
     *
     * @deprecated
     */
    listHmacKeys: {
      name: "ListHmacKeys",
      requestType: ListHmacKeysRequest,
      requestStream: false,
      responseType: ListHmacKeysResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([7, 112, 114, 111, 106, 101, 99, 116])],
          578365834: [Buffer.from([11, 18, 9, 10, 7, 112, 114, 111, 106, 101, 99, 116])],
        },
      },
    },
    /**
     * Updates a given HMAC key state between ACTIVE and INACTIVE.
     *
     * @deprecated
     */
    updateHmacKey: {
      name: "UpdateHmacKey",
      requestType: UpdateHmacKeyRequest,
      requestStream: false,
      responseType: HmacKeyMetadata,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              104,
              109,
              97,
              99,
              95,
              107,
              101,
              121,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365834: [
            Buffer.from([
              34,
              18,
              32,
              10,
              16,
              104,
              109,
              97,
              99,
              95,
              107,
              101,
              121,
              46,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              18,
              12,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Permanently deletes a NotificationConfig.
     *
     * @deprecated
     */
    deleteNotificationConfig: {
      name: "DeleteNotificationConfig",
      requestType: DeleteNotificationConfigRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365834: [
            Buffer.from([
              42,
              18,
              40,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              32,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              99,
              107,
              101,
              116,
              115,
              47,
              42,
              125,
              47,
              42,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * View a NotificationConfig.
     *
     * @deprecated
     */
    getNotificationConfig: {
      name: "GetNotificationConfig",
      requestType: GetNotificationConfigRequest,
      requestStream: false,
      responseType: NotificationConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365834: [
            Buffer.from([
              42,
              18,
              40,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              32,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              99,
              107,
              101,
              116,
              115,
              47,
              42,
              125,
              47,
              42,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a NotificationConfig for a given bucket.
     * These NotificationConfigs, when triggered, publish messages to the
     * specified Pub/Sub topics. See
     * https://cloud.google.com/storage/docs/pubsub-notifications.
     *
     * @deprecated
     */
    createNotificationConfig: {
      name: "CreateNotificationConfig",
      requestType: CreateNotificationConfigRequest,
      requestStream: false,
      responseType: NotificationConfig,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              26,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              110,
              111,
              116,
              105,
              102,
              105,
              99,
              97,
              116,
              105,
              111,
              110,
              95,
              99,
              111,
              110,
              102,
              105,
              103,
            ]),
          ],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Retrieves a list of NotificationConfigs for a given bucket.
     *
     * @deprecated
     */
    listNotificationConfigs: {
      name: "ListNotificationConfigs",
      requestType: ListNotificationConfigsRequest,
      requestStream: false,
      responseType: ListNotificationConfigsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365834: [
            Buffer.from([
              23,
              18,
              21,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              11,
              123,
              98,
              117,
              99,
              107,
              101,
              116,
              61,
              42,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface StorageServiceImplementation<CallContextExt = {}> {
  /** Permanently deletes an empty bucket. */
  deleteBucket(request: DeleteBucketRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Returns metadata for the specified bucket. */
  getBucket(request: GetBucketRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Bucket>>;
  /** Creates a new bucket. */
  createBucket(request: CreateBucketRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Bucket>>;
  /** Retrieves a list of buckets for a given project. */
  listBuckets(
    request: ListBucketsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBucketsResponse>>;
  /** Locks retention policy on a bucket. */
  lockBucketRetentionPolicy(
    request: LockBucketRetentionPolicyRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Bucket>>;
  /**
   * Gets the IAM policy for a specified bucket.
   * The `resource` field in the request should be
   * `projects/_/buckets/{bucket}`.
   */
  getIamPolicy(request: GetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Updates an IAM policy for the specified bucket.
   * The `resource` field in the request should be
   * `projects/_/buckets/{bucket}`.
   */
  setIamPolicy(request: SetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Tests a set of permissions on the given bucket, object, or managed folder
   * to see which, if any, are held by the caller.
   * The `resource` field in the request should be
   * `projects/_/buckets/{bucket}` for a bucket,
   * `projects/_/buckets/{bucket}/objects/{object}` for an object, or
   * `projects/_/buckets/{bucket}/managedFolders/{managedFolder}`
   * for a managed folder.
   */
  testIamPermissions(
    request: TestIamPermissionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TestIamPermissionsResponse>>;
  /** Updates a bucket. Equivalent to JSON API's storage.buckets.patch method. */
  updateBucket(request: UpdateBucketRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Bucket>>;
  /**
   * Concatenates a list of existing objects into a new object in the same
   * bucket.
   */
  composeObject(request: ComposeObjectRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Object>>;
  /**
   * Deletes an object and its metadata.
   *
   * Deletions are normally permanent when versioning is disabled or whenever
   * the generation parameter is used. However, if soft delete is enabled for
   * the bucket, deleted objects can be restored using RestoreObject until the
   * soft delete retention period has passed.
   */
  deleteObject(request: DeleteObjectRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Restores a soft-deleted object. */
  restoreObject(request: RestoreObjectRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Object>>;
  /**
   * Cancels an in-progress resumable upload.
   *
   * Any attempts to write to the resumable upload after cancelling the upload
   * will fail.
   *
   * The behavior for currently in progress write operations is not guaranteed -
   * they could either complete before the cancellation or fail if the
   * cancellation completes first.
   */
  cancelResumableWrite(
    request: CancelResumableWriteRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CancelResumableWriteResponse>>;
  /** Retrieves an object's metadata. */
  getObject(request: GetObjectRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Object>>;
  /** Reads an object's data. */
  readObject(
    request: ReadObjectRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<ReadObjectResponse>>;
  /**
   * Updates an object's metadata.
   * Equivalent to JSON API's storage.objects.patch.
   */
  updateObject(request: UpdateObjectRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Object>>;
  /**
   * Stores a new object and metadata.
   *
   * An object can be written either in a single message stream or in a
   * resumable sequence of message streams. To write using a single stream,
   * the client should include in the first message of the stream an
   * `WriteObjectSpec` describing the destination bucket, object, and any
   * preconditions. Additionally, the final message must set 'finish_write' to
   * true, or else it is an error.
   *
   * For a resumable write, the client should instead call
   * `StartResumableWrite()`, populating a `WriteObjectSpec` into that request.
   * They should then attach the returned `upload_id` to the first message of
   * each following call to `WriteObject`. If the stream is closed before
   * finishing the upload (either explicitly by the client or due to a network
   * error or an error response from the server), the client should do as
   * follows:
   *   - Check the result Status of the stream, to determine if writing can be
   *     resumed on this stream or must be restarted from scratch (by calling
   *     `StartResumableWrite()`). The resumable errors are DEADLINE_EXCEEDED,
   *     INTERNAL, and UNAVAILABLE. For each case, the client should use binary
   *     exponential backoff before retrying.  Additionally, writes can be
   *     resumed after RESOURCE_EXHAUSTED errors, but only after taking
   *     appropriate measures, which may include reducing aggregate send rate
   *     across clients and/or requesting a quota increase for your project.
   *   - If the call to `WriteObject` returns `ABORTED`, that indicates
   *     concurrent attempts to update the resumable write, caused either by
   *     multiple racing clients or by a single client where the previous
   *     request was timed out on the client side but nonetheless reached the
   *     server. In this case the client should take steps to prevent further
   *     concurrent writes (e.g., increase the timeouts, stop using more than
   *     one process to perform the upload, etc.), and then should follow the
   *     steps below for resuming the upload.
   *   - For resumable errors, the client should call `QueryWriteStatus()` and
   *     then continue writing from the returned `persisted_size`. This may be
   *     less than the amount of data the client previously sent. Note also that
   *     it is acceptable to send data starting at an offset earlier than the
   *     returned `persisted_size`; in this case, the service will skip data at
   *     offsets that were already persisted (without checking that it matches
   *     the previously written data), and write only the data starting from the
   *     persisted offset. Even though the data isn't written, it may still
   *     incur a performance cost over resuming at the correct write offset.
   *     This behavior can make client-side handling simpler in some cases.
   *   - Clients must only send data that is a multiple of 256 KiB per message,
   *     unless the object is being finished with `finish_write` set to `true`.
   *
   * The service will not view the object as complete until the client has
   * sent a `WriteObjectRequest` with `finish_write` set to `true`. Sending any
   * requests on a stream after sending a request with `finish_write` set to
   * `true` will cause an error. The client **should** check the response it
   * receives to determine how much data the service was able to commit and
   * whether the service views the object as complete.
   *
   * Attempting to resume an already finalized object will result in an OK
   * status, with a WriteObjectResponse containing the finalized object's
   * metadata.
   *
   * Alternatively, the BidiWriteObject operation may be used to write an
   * object with controls over flushing and the ability to fetch the ability to
   * determine the current persisted size.
   */
  writeObject(
    request: AsyncIterable<WriteObjectRequest>,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<WriteObjectResponse>>;
  /**
   * Stores a new object and metadata.
   *
   * This is similar to the WriteObject call with the added support for
   * manual flushing of persisted state, and the ability to determine current
   * persisted size without closing the stream.
   *
   * The client may specify one or both of the `state_lookup` and `flush` fields
   * in each BidiWriteObjectRequest. If `flush` is specified, the data written
   * so far will be persisted to storage. If `state_lookup` is specified, the
   * service will respond with a BidiWriteObjectResponse that contains the
   * persisted size. If both `flush` and `state_lookup` are specified, the flush
   * will always occur before a `state_lookup`, so that both may be set in the
   * same request and the returned state will be the state of the object
   * post-flush. When the stream is closed, a BidiWriteObjectResponse will
   * always be sent to the client, regardless of the value of `state_lookup`.
   */
  bidiWriteObject(
    request: AsyncIterable<BidiWriteObjectRequest>,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<BidiWriteObjectResponse>>;
  /** Retrieves a list of objects matching the criteria. */
  listObjects(
    request: ListObjectsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListObjectsResponse>>;
  /**
   * Rewrites a source object to a destination object. Optionally overrides
   * metadata.
   */
  rewriteObject(
    request: RewriteObjectRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<RewriteResponse>>;
  /**
   * Starts a resumable write. How long the write operation remains valid, and
   * what happens when the write operation becomes invalid, are
   * service-dependent.
   */
  startResumableWrite(
    request: StartResumableWriteRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<StartResumableWriteResponse>>;
  /**
   * Determines the `persisted_size` for an object that is being written, which
   * can then be used as the `write_offset` for the next `Write()` call.
   *
   * If the object does not exist (i.e., the object has been deleted, or the
   * first `Write()` has not yet reached the service), this method returns the
   * error `NOT_FOUND`.
   *
   * The client **may** call `QueryWriteStatus()` at any time to determine how
   * much data has been processed for this object. This is useful if the
   * client is buffering data and needs to know which data can be safely
   * evicted. For any sequence of `QueryWriteStatus()` calls for a given
   * object name, the sequence of returned `persisted_size` values will be
   * non-decreasing.
   */
  queryWriteStatus(
    request: QueryWriteStatusRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<QueryWriteStatusResponse>>;
  /**
   * Retrieves the name of a project's Google Cloud Storage service account.
   *
   * @deprecated
   */
  getServiceAccount(
    request: GetServiceAccountRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ServiceAccount>>;
  /**
   * Creates a new HMAC key for the given service account.
   *
   * @deprecated
   */
  createHmacKey(
    request: CreateHmacKeyRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CreateHmacKeyResponse>>;
  /**
   * Deletes a given HMAC key.  Key must be in an INACTIVE state.
   *
   * @deprecated
   */
  deleteHmacKey(request: DeleteHmacKeyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Gets an existing HMAC key metadata for the given id.
   *
   * @deprecated
   */
  getHmacKey(request: GetHmacKeyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<HmacKeyMetadata>>;
  /**
   * Lists HMAC keys under a given project with the additional filters provided.
   *
   * @deprecated
   */
  listHmacKeys(
    request: ListHmacKeysRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListHmacKeysResponse>>;
  /**
   * Updates a given HMAC key state between ACTIVE and INACTIVE.
   *
   * @deprecated
   */
  updateHmacKey(
    request: UpdateHmacKeyRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<HmacKeyMetadata>>;
  /**
   * Permanently deletes a NotificationConfig.
   *
   * @deprecated
   */
  deleteNotificationConfig(
    request: DeleteNotificationConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * View a NotificationConfig.
   *
   * @deprecated
   */
  getNotificationConfig(
    request: GetNotificationConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<NotificationConfig>>;
  /**
   * Creates a NotificationConfig for a given bucket.
   * These NotificationConfigs, when triggered, publish messages to the
   * specified Pub/Sub topics. See
   * https://cloud.google.com/storage/docs/pubsub-notifications.
   *
   * @deprecated
   */
  createNotificationConfig(
    request: CreateNotificationConfigRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<NotificationConfig>>;
  /**
   * Retrieves a list of NotificationConfigs for a given bucket.
   *
   * @deprecated
   */
  listNotificationConfigs(
    request: ListNotificationConfigsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListNotificationConfigsResponse>>;
}

export interface StorageClient<CallOptionsExt = {}> {
  /** Permanently deletes an empty bucket. */
  deleteBucket(request: DeepPartial<DeleteBucketRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Returns metadata for the specified bucket. */
  getBucket(request: DeepPartial<GetBucketRequest>, options?: CallOptions & CallOptionsExt): Promise<Bucket>;
  /** Creates a new bucket. */
  createBucket(request: DeepPartial<CreateBucketRequest>, options?: CallOptions & CallOptionsExt): Promise<Bucket>;
  /** Retrieves a list of buckets for a given project. */
  listBuckets(
    request: DeepPartial<ListBucketsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBucketsResponse>;
  /** Locks retention policy on a bucket. */
  lockBucketRetentionPolicy(
    request: DeepPartial<LockBucketRetentionPolicyRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Bucket>;
  /**
   * Gets the IAM policy for a specified bucket.
   * The `resource` field in the request should be
   * `projects/_/buckets/{bucket}`.
   */
  getIamPolicy(request: DeepPartial<GetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Updates an IAM policy for the specified bucket.
   * The `resource` field in the request should be
   * `projects/_/buckets/{bucket}`.
   */
  setIamPolicy(request: DeepPartial<SetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Tests a set of permissions on the given bucket, object, or managed folder
   * to see which, if any, are held by the caller.
   * The `resource` field in the request should be
   * `projects/_/buckets/{bucket}` for a bucket,
   * `projects/_/buckets/{bucket}/objects/{object}` for an object, or
   * `projects/_/buckets/{bucket}/managedFolders/{managedFolder}`
   * for a managed folder.
   */
  testIamPermissions(
    request: DeepPartial<TestIamPermissionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TestIamPermissionsResponse>;
  /** Updates a bucket. Equivalent to JSON API's storage.buckets.patch method. */
  updateBucket(request: DeepPartial<UpdateBucketRequest>, options?: CallOptions & CallOptionsExt): Promise<Bucket>;
  /**
   * Concatenates a list of existing objects into a new object in the same
   * bucket.
   */
  composeObject(request: DeepPartial<ComposeObjectRequest>, options?: CallOptions & CallOptionsExt): Promise<Object>;
  /**
   * Deletes an object and its metadata.
   *
   * Deletions are normally permanent when versioning is disabled or whenever
   * the generation parameter is used. However, if soft delete is enabled for
   * the bucket, deleted objects can be restored using RestoreObject until the
   * soft delete retention period has passed.
   */
  deleteObject(request: DeepPartial<DeleteObjectRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Restores a soft-deleted object. */
  restoreObject(request: DeepPartial<RestoreObjectRequest>, options?: CallOptions & CallOptionsExt): Promise<Object>;
  /**
   * Cancels an in-progress resumable upload.
   *
   * Any attempts to write to the resumable upload after cancelling the upload
   * will fail.
   *
   * The behavior for currently in progress write operations is not guaranteed -
   * they could either complete before the cancellation or fail if the
   * cancellation completes first.
   */
  cancelResumableWrite(
    request: DeepPartial<CancelResumableWriteRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CancelResumableWriteResponse>;
  /** Retrieves an object's metadata. */
  getObject(request: DeepPartial<GetObjectRequest>, options?: CallOptions & CallOptionsExt): Promise<Object>;
  /** Reads an object's data. */
  readObject(
    request: DeepPartial<ReadObjectRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<ReadObjectResponse>;
  /**
   * Updates an object's metadata.
   * Equivalent to JSON API's storage.objects.patch.
   */
  updateObject(request: DeepPartial<UpdateObjectRequest>, options?: CallOptions & CallOptionsExt): Promise<Object>;
  /**
   * Stores a new object and metadata.
   *
   * An object can be written either in a single message stream or in a
   * resumable sequence of message streams. To write using a single stream,
   * the client should include in the first message of the stream an
   * `WriteObjectSpec` describing the destination bucket, object, and any
   * preconditions. Additionally, the final message must set 'finish_write' to
   * true, or else it is an error.
   *
   * For a resumable write, the client should instead call
   * `StartResumableWrite()`, populating a `WriteObjectSpec` into that request.
   * They should then attach the returned `upload_id` to the first message of
   * each following call to `WriteObject`. If the stream is closed before
   * finishing the upload (either explicitly by the client or due to a network
   * error or an error response from the server), the client should do as
   * follows:
   *   - Check the result Status of the stream, to determine if writing can be
   *     resumed on this stream or must be restarted from scratch (by calling
   *     `StartResumableWrite()`). The resumable errors are DEADLINE_EXCEEDED,
   *     INTERNAL, and UNAVAILABLE. For each case, the client should use binary
   *     exponential backoff before retrying.  Additionally, writes can be
   *     resumed after RESOURCE_EXHAUSTED errors, but only after taking
   *     appropriate measures, which may include reducing aggregate send rate
   *     across clients and/or requesting a quota increase for your project.
   *   - If the call to `WriteObject` returns `ABORTED`, that indicates
   *     concurrent attempts to update the resumable write, caused either by
   *     multiple racing clients or by a single client where the previous
   *     request was timed out on the client side but nonetheless reached the
   *     server. In this case the client should take steps to prevent further
   *     concurrent writes (e.g., increase the timeouts, stop using more than
   *     one process to perform the upload, etc.), and then should follow the
   *     steps below for resuming the upload.
   *   - For resumable errors, the client should call `QueryWriteStatus()` and
   *     then continue writing from the returned `persisted_size`. This may be
   *     less than the amount of data the client previously sent. Note also that
   *     it is acceptable to send data starting at an offset earlier than the
   *     returned `persisted_size`; in this case, the service will skip data at
   *     offsets that were already persisted (without checking that it matches
   *     the previously written data), and write only the data starting from the
   *     persisted offset. Even though the data isn't written, it may still
   *     incur a performance cost over resuming at the correct write offset.
   *     This behavior can make client-side handling simpler in some cases.
   *   - Clients must only send data that is a multiple of 256 KiB per message,
   *     unless the object is being finished with `finish_write` set to `true`.
   *
   * The service will not view the object as complete until the client has
   * sent a `WriteObjectRequest` with `finish_write` set to `true`. Sending any
   * requests on a stream after sending a request with `finish_write` set to
   * `true` will cause an error. The client **should** check the response it
   * receives to determine how much data the service was able to commit and
   * whether the service views the object as complete.
   *
   * Attempting to resume an already finalized object will result in an OK
   * status, with a WriteObjectResponse containing the finalized object's
   * metadata.
   *
   * Alternatively, the BidiWriteObject operation may be used to write an
   * object with controls over flushing and the ability to fetch the ability to
   * determine the current persisted size.
   */
  writeObject(
    request: AsyncIterable<DeepPartial<WriteObjectRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WriteObjectResponse>;
  /**
   * Stores a new object and metadata.
   *
   * This is similar to the WriteObject call with the added support for
   * manual flushing of persisted state, and the ability to determine current
   * persisted size without closing the stream.
   *
   * The client may specify one or both of the `state_lookup` and `flush` fields
   * in each BidiWriteObjectRequest. If `flush` is specified, the data written
   * so far will be persisted to storage. If `state_lookup` is specified, the
   * service will respond with a BidiWriteObjectResponse that contains the
   * persisted size. If both `flush` and `state_lookup` are specified, the flush
   * will always occur before a `state_lookup`, so that both may be set in the
   * same request and the returned state will be the state of the object
   * post-flush. When the stream is closed, a BidiWriteObjectResponse will
   * always be sent to the client, regardless of the value of `state_lookup`.
   */
  bidiWriteObject(
    request: AsyncIterable<DeepPartial<BidiWriteObjectRequest>>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<BidiWriteObjectResponse>;
  /** Retrieves a list of objects matching the criteria. */
  listObjects(
    request: DeepPartial<ListObjectsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListObjectsResponse>;
  /**
   * Rewrites a source object to a destination object. Optionally overrides
   * metadata.
   */
  rewriteObject(
    request: DeepPartial<RewriteObjectRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<RewriteResponse>;
  /**
   * Starts a resumable write. How long the write operation remains valid, and
   * what happens when the write operation becomes invalid, are
   * service-dependent.
   */
  startResumableWrite(
    request: DeepPartial<StartResumableWriteRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<StartResumableWriteResponse>;
  /**
   * Determines the `persisted_size` for an object that is being written, which
   * can then be used as the `write_offset` for the next `Write()` call.
   *
   * If the object does not exist (i.e., the object has been deleted, or the
   * first `Write()` has not yet reached the service), this method returns the
   * error `NOT_FOUND`.
   *
   * The client **may** call `QueryWriteStatus()` at any time to determine how
   * much data has been processed for this object. This is useful if the
   * client is buffering data and needs to know which data can be safely
   * evicted. For any sequence of `QueryWriteStatus()` calls for a given
   * object name, the sequence of returned `persisted_size` values will be
   * non-decreasing.
   */
  queryWriteStatus(
    request: DeepPartial<QueryWriteStatusRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<QueryWriteStatusResponse>;
  /**
   * Retrieves the name of a project's Google Cloud Storage service account.
   *
   * @deprecated
   */
  getServiceAccount(
    request: DeepPartial<GetServiceAccountRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ServiceAccount>;
  /**
   * Creates a new HMAC key for the given service account.
   *
   * @deprecated
   */
  createHmacKey(
    request: DeepPartial<CreateHmacKeyRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CreateHmacKeyResponse>;
  /**
   * Deletes a given HMAC key.  Key must be in an INACTIVE state.
   *
   * @deprecated
   */
  deleteHmacKey(request: DeepPartial<DeleteHmacKeyRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Gets an existing HMAC key metadata for the given id.
   *
   * @deprecated
   */
  getHmacKey(request: DeepPartial<GetHmacKeyRequest>, options?: CallOptions & CallOptionsExt): Promise<HmacKeyMetadata>;
  /**
   * Lists HMAC keys under a given project with the additional filters provided.
   *
   * @deprecated
   */
  listHmacKeys(
    request: DeepPartial<ListHmacKeysRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListHmacKeysResponse>;
  /**
   * Updates a given HMAC key state between ACTIVE and INACTIVE.
   *
   * @deprecated
   */
  updateHmacKey(
    request: DeepPartial<UpdateHmacKeyRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<HmacKeyMetadata>;
  /**
   * Permanently deletes a NotificationConfig.
   *
   * @deprecated
   */
  deleteNotificationConfig(
    request: DeepPartial<DeleteNotificationConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * View a NotificationConfig.
   *
   * @deprecated
   */
  getNotificationConfig(
    request: DeepPartial<GetNotificationConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<NotificationConfig>;
  /**
   * Creates a NotificationConfig for a given bucket.
   * These NotificationConfigs, when triggered, publish messages to the
   * specified Pub/Sub topics. See
   * https://cloud.google.com/storage/docs/pubsub-notifications.
   *
   * @deprecated
   */
  createNotificationConfig(
    request: DeepPartial<CreateNotificationConfigRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<NotificationConfig>;
  /**
   * Retrieves a list of NotificationConfigs for a given bucket.
   *
   * @deprecated
   */
  listNotificationConfigs(
    request: DeepPartial<ListNotificationConfigsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListNotificationConfigsResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export type ServerStreamingMethodResult<Response> = { [Symbol.asyncIterator](): AsyncIterator<Response, void> };

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
