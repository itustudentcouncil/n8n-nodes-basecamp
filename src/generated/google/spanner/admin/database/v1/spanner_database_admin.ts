// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/spanner/admin/database/v1/spanner_database_admin.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import {
  GetIamPolicyRequest,
  SetIamPolicyRequest,
  TestIamPermissionsRequest,
  TestIamPermissionsResponse,
} from "../../../../iam/v1/iam_policy.js";
import { Policy } from "../../../../iam/v1/policy.js";
import { Operation } from "../../../../longrunning/operations.js";
import { Empty } from "../../../../protobuf/empty.js";
import { FieldMask } from "../../../../protobuf/field_mask.js";
import { Timestamp } from "../../../../protobuf/timestamp.js";
import {
  Backup,
  BackupInfo,
  CopyBackupRequest,
  CreateBackupRequest,
  DeleteBackupRequest,
  GetBackupRequest,
  ListBackupOperationsRequest,
  ListBackupOperationsResponse,
  ListBackupsRequest,
  ListBackupsResponse,
  UpdateBackupRequest,
} from "./backup.js";
import {
  BackupSchedule,
  CreateBackupScheduleRequest,
  DeleteBackupScheduleRequest,
  GetBackupScheduleRequest,
  ListBackupSchedulesRequest,
  ListBackupSchedulesResponse,
  UpdateBackupScheduleRequest,
} from "./backup_schedule.js";
import {
  DatabaseDialect,
  databaseDialectFromJSON,
  databaseDialectToJSON,
  EncryptionConfig,
  EncryptionInfo,
  OperationProgress,
} from "./common.js";

export const protobufPackage = "google.spanner.admin.database.v1";

/** Indicates the type of the restore source. */
export enum RestoreSourceType {
  /** TYPE_UNSPECIFIED - No restore associated. */
  TYPE_UNSPECIFIED = 0,
  /** BACKUP - A backup was used as the source of the restore. */
  BACKUP = 1,
  UNRECOGNIZED = -1,
}

export function restoreSourceTypeFromJSON(object: any): RestoreSourceType {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return RestoreSourceType.TYPE_UNSPECIFIED;
    case 1:
    case "BACKUP":
      return RestoreSourceType.BACKUP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RestoreSourceType.UNRECOGNIZED;
  }
}

export function restoreSourceTypeToJSON(object: RestoreSourceType): string {
  switch (object) {
    case RestoreSourceType.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case RestoreSourceType.BACKUP:
      return "BACKUP";
    case RestoreSourceType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about the database restore. */
export interface RestoreInfo {
  /** The type of the restore source. */
  sourceType: RestoreSourceType;
  /**
   * Information about the backup used to restore the database. The backup
   * may no longer exist.
   */
  backupInfo?: BackupInfo | undefined;
}

/** A Cloud Spanner database. */
export interface Database {
  /**
   * Required. The name of the database. Values are of the form
   * `projects/<project>/instances/<instance>/databases/<database>`,
   * where `<database>` is as specified in the `CREATE DATABASE`
   * statement. This name can be passed to other API methods to
   * identify the database.
   */
  name: string;
  /** Output only. The current database state. */
  state: Database_State;
  /** Output only. If exists, the time at which the database creation started. */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Applicable only for restored databases. Contains information
   * about the restore source.
   */
  restoreInfo:
    | RestoreInfo
    | undefined;
  /**
   * Output only. For databases that are using customer managed encryption, this
   * field contains the encryption configuration for the database.
   * For databases that are using Google default or other types of encryption,
   * this field is empty.
   */
  encryptionConfig:
    | EncryptionConfig
    | undefined;
  /**
   * Output only. For databases that are using customer managed encryption, this
   * field contains the encryption information for the database, such as
   * all Cloud KMS key versions that are in use. The `encryption_status' field
   * inside of each `EncryptionInfo` is not populated.
   *
   * For databases that are using Google default or other types of encryption,
   * this field is empty.
   *
   * This field is propagated lazily from the backend. There might be a delay
   * from when a key version is being used and when it appears in this field.
   */
  encryptionInfo: EncryptionInfo[];
  /**
   * Output only. The period in which Cloud Spanner retains all versions of data
   * for the database. This is the same as the value of version_retention_period
   * database option set using
   * [UpdateDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabaseDdl].
   * Defaults to 1 hour, if not set.
   */
  versionRetentionPeriod: string;
  /**
   * Output only. Earliest timestamp at which older versions of the data can be
   * read. This value is continuously updated by Cloud Spanner and becomes stale
   * the moment it is queried. If you are using this value to recover data, make
   * sure to account for the time from the moment when the value is queried to
   * the moment when you initiate the recovery.
   */
  earliestVersionTime:
    | Date
    | undefined;
  /**
   * Output only. The read-write region which contains the database's leader
   * replicas.
   *
   * This is the same as the value of default_leader
   * database option set using DatabaseAdmin.CreateDatabase or
   * DatabaseAdmin.UpdateDatabaseDdl. If not explicitly set, this is empty.
   */
  defaultLeader: string;
  /** Output only. The dialect of the Cloud Spanner Database. */
  databaseDialect: DatabaseDialect;
  /**
   * Whether drop protection is enabled for this database. Defaults to false,
   * if not set. For more details, please see how to [prevent accidental
   * database
   * deletion](https://cloud.google.com/spanner/docs/prevent-database-deletion).
   */
  enableDropProtection: boolean;
  /**
   * Output only. If true, the database is being updated. If false, there are no
   * ongoing update operations for the database.
   */
  reconciling: boolean;
}

/** Indicates the current state of the database. */
export enum Database_State {
  /** STATE_UNSPECIFIED - Not specified. */
  STATE_UNSPECIFIED = 0,
  /**
   * CREATING - The database is still being created. Operations on the database may fail
   * with `FAILED_PRECONDITION` in this state.
   */
  CREATING = 1,
  /** READY - The database is fully created and ready for use. */
  READY = 2,
  /**
   * READY_OPTIMIZING - The database is fully created and ready for use, but is still
   * being optimized for performance and cannot handle full load.
   *
   * In this state, the database still references the backup
   * it was restore from, preventing the backup
   * from being deleted. When optimizations are complete, the full performance
   * of the database will be restored, and the database will transition to
   * `READY` state.
   */
  READY_OPTIMIZING = 3,
  UNRECOGNIZED = -1,
}

export function database_StateFromJSON(object: any): Database_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Database_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Database_State.CREATING;
    case 2:
    case "READY":
      return Database_State.READY;
    case 3:
    case "READY_OPTIMIZING":
      return Database_State.READY_OPTIMIZING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Database_State.UNRECOGNIZED;
  }
}

export function database_StateToJSON(object: Database_State): string {
  switch (object) {
    case Database_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Database_State.CREATING:
      return "CREATING";
    case Database_State.READY:
      return "READY";
    case Database_State.READY_OPTIMIZING:
      return "READY_OPTIMIZING";
    case Database_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The request for
 * [ListDatabases][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabases].
 */
export interface ListDatabasesRequest {
  /**
   * Required. The instance whose databases should be listed.
   * Values are of the form `projects/<project>/instances/<instance>`.
   */
  parent: string;
  /**
   * Number of databases to be returned in the response. If 0 or less,
   * defaults to the server's maximum allowed page size.
   */
  pageSize: number;
  /**
   * If non-empty, `page_token` should contain a
   * [next_page_token][google.spanner.admin.database.v1.ListDatabasesResponse.next_page_token]
   * from a previous
   * [ListDatabasesResponse][google.spanner.admin.database.v1.ListDatabasesResponse].
   */
  pageToken: string;
}

/**
 * The response for
 * [ListDatabases][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabases].
 */
export interface ListDatabasesResponse {
  /** Databases that matched the request. */
  databases: Database[];
  /**
   * `next_page_token` can be sent in a subsequent
   * [ListDatabases][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabases]
   * call to fetch more of the matching databases.
   */
  nextPageToken: string;
}

/**
 * The request for
 * [CreateDatabase][google.spanner.admin.database.v1.DatabaseAdmin.CreateDatabase].
 */
export interface CreateDatabaseRequest {
  /**
   * Required. The name of the instance that will serve the new database.
   * Values are of the form `projects/<project>/instances/<instance>`.
   */
  parent: string;
  /**
   * Required. A `CREATE DATABASE` statement, which specifies the ID of the
   * new database.  The database ID must conform to the regular expression
   * `[a-z][a-z0-9_\-]*[a-z0-9]` and be between 2 and 30 characters in length.
   * If the database ID is a reserved word or if it contains a hyphen, the
   * database ID must be enclosed in backticks (`` ` ``).
   */
  createStatement: string;
  /**
   * Optional. A list of DDL statements to run inside the newly created
   * database. Statements can create tables, indexes, etc. These
   * statements execute atomically with the creation of the database:
   * if there is an error in any statement, the database is not created.
   */
  extraStatements: string[];
  /**
   * Optional. The encryption configuration for the database. If this field is
   * not specified, Cloud Spanner will encrypt/decrypt all data at rest using
   * Google default encryption.
   */
  encryptionConfig:
    | EncryptionConfig
    | undefined;
  /** Optional. The dialect of the Cloud Spanner Database. */
  databaseDialect: DatabaseDialect;
  /**
   * Optional. Proto descriptors used by CREATE/ALTER PROTO BUNDLE statements in
   * 'extra_statements' above.
   * Contains a protobuf-serialized
   * [google.protobuf.FileDescriptorSet](https://github.com/protocolbuffers/protobuf/blob/main/src/google/protobuf/descriptor.proto).
   * To generate it, [install](https://grpc.io/docs/protoc-installation/) and
   * run `protoc` with --include_imports and --descriptor_set_out. For example,
   * to generate for moon/shot/app.proto, run
   * ```
   * $protoc  --proto_path=/app_path --proto_path=/lib_path \
   *          --include_imports \
   *          --descriptor_set_out=descriptors.data \
   *          moon/shot/app.proto
   * ```
   * For more details, see protobuffer [self
   * description](https://developers.google.com/protocol-buffers/docs/techniques#self-description).
   */
  protoDescriptors: Buffer;
}

/**
 * Metadata type for the operation returned by
 * [CreateDatabase][google.spanner.admin.database.v1.DatabaseAdmin.CreateDatabase].
 */
export interface CreateDatabaseMetadata {
  /** The database being created. */
  database: string;
}

/**
 * The request for
 * [GetDatabase][google.spanner.admin.database.v1.DatabaseAdmin.GetDatabase].
 */
export interface GetDatabaseRequest {
  /**
   * Required. The name of the requested database. Values are of the form
   * `projects/<project>/instances/<instance>/databases/<database>`.
   */
  name: string;
}

/**
 * The request for
 * [UpdateDatabase][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabase].
 */
export interface UpdateDatabaseRequest {
  /**
   * Required. The database to update.
   * The `name` field of the database is of the form
   * `projects/<project>/instances/<instance>/databases/<database>`.
   */
  database:
    | Database
    | undefined;
  /**
   * Required. The list of fields to update. Currently, only
   * `enable_drop_protection` field can be updated.
   */
  updateMask: string[] | undefined;
}

/**
 * Metadata type for the operation returned by
 * [UpdateDatabase][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabase].
 */
export interface UpdateDatabaseMetadata {
  /**
   * The request for
   * [UpdateDatabase][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabase].
   */
  request:
    | UpdateDatabaseRequest
    | undefined;
  /**
   * The progress of the
   * [UpdateDatabase][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabase]
   * operation.
   */
  progress:
    | OperationProgress
    | undefined;
  /**
   * The time at which this operation was cancelled. If set, this operation is
   * in the process of undoing itself (which is best-effort).
   */
  cancelTime: Date | undefined;
}

/**
 * Enqueues the given DDL statements to be applied, in order but not
 * necessarily all at once, to the database schema at some point (or
 * points) in the future. The server checks that the statements
 * are executable (syntactically valid, name tables that exist, etc.)
 * before enqueueing them, but they may still fail upon
 * later execution (e.g., if a statement from another batch of
 * statements is applied first and it conflicts in some way, or if
 * there is some data-related problem like a `NULL` value in a column to
 * which `NOT NULL` would be added). If a statement fails, all
 * subsequent statements in the batch are automatically cancelled.
 *
 * Each batch of statements is assigned a name which can be used with
 * the [Operations][google.longrunning.Operations] API to monitor
 * progress. See the
 * [operation_id][google.spanner.admin.database.v1.UpdateDatabaseDdlRequest.operation_id]
 * field for more details.
 */
export interface UpdateDatabaseDdlRequest {
  /** Required. The database to update. */
  database: string;
  /** Required. DDL statements to be applied to the database. */
  statements: string[];
  /**
   * If empty, the new update request is assigned an
   * automatically-generated operation ID. Otherwise, `operation_id`
   * is used to construct the name of the resulting
   * [Operation][google.longrunning.Operation].
   *
   * Specifying an explicit operation ID simplifies determining
   * whether the statements were executed in the event that the
   * [UpdateDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabaseDdl]
   * call is replayed, or the return value is otherwise lost: the
   * [database][google.spanner.admin.database.v1.UpdateDatabaseDdlRequest.database]
   * and `operation_id` fields can be combined to form the
   * [name][google.longrunning.Operation.name] of the resulting
   * [longrunning.Operation][google.longrunning.Operation]:
   * `<database>/operations/<operation_id>`.
   *
   * `operation_id` should be unique within the database, and must be
   * a valid identifier: `[a-z][a-z0-9_]*`. Note that
   * automatically-generated operation IDs always begin with an
   * underscore. If the named operation already exists,
   * [UpdateDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabaseDdl]
   * returns `ALREADY_EXISTS`.
   */
  operationId: string;
  /**
   * Optional. Proto descriptors used by CREATE/ALTER PROTO BUNDLE statements.
   * Contains a protobuf-serialized
   * [google.protobuf.FileDescriptorSet](https://github.com/protocolbuffers/protobuf/blob/main/src/google/protobuf/descriptor.proto).
   * To generate it, [install](https://grpc.io/docs/protoc-installation/) and
   * run `protoc` with --include_imports and --descriptor_set_out. For example,
   * to generate for moon/shot/app.proto, run
   * ```
   * $protoc  --proto_path=/app_path --proto_path=/lib_path \
   *          --include_imports \
   *          --descriptor_set_out=descriptors.data \
   *          moon/shot/app.proto
   * ```
   * For more details, see protobuffer [self
   * description](https://developers.google.com/protocol-buffers/docs/techniques#self-description).
   */
  protoDescriptors: Buffer;
}

/**
 * Action information extracted from a DDL statement. This proto is used to
 * display the brief info of the DDL statement for the operation
 * [UpdateDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabaseDdl].
 */
export interface DdlStatementActionInfo {
  /**
   * The action for the DDL statement, e.g. CREATE, ALTER, DROP, GRANT, etc.
   * This field is a non-empty string.
   */
  action: string;
  /**
   * The entity type for the DDL statement, e.g. TABLE, INDEX, VIEW, etc.
   * This field can be empty string for some DDL statement,
   * e.g. for statement "ANALYZE", `entity_type` = "".
   */
  entityType: string;
  /**
   * The entity name(s) being operated on the DDL statement.
   * E.g.
   * 1. For statement "CREATE TABLE t1(...)", `entity_names` = ["t1"].
   * 2. For statement "GRANT ROLE r1, r2 ...", `entity_names` = ["r1", "r2"].
   * 3. For statement "ANALYZE", `entity_names` = [].
   */
  entityNames: string[];
}

/**
 * Metadata type for the operation returned by
 * [UpdateDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabaseDdl].
 */
export interface UpdateDatabaseDdlMetadata {
  /** The database being modified. */
  database: string;
  /**
   * For an update this list contains all the statements. For an
   * individual statement, this list contains only that statement.
   */
  statements: string[];
  /**
   * Reports the commit timestamps of all statements that have
   * succeeded so far, where `commit_timestamps[i]` is the commit
   * timestamp for the statement `statements[i]`.
   */
  commitTimestamps: Date[];
  /**
   * Output only. When true, indicates that the operation is throttled e.g.
   * due to resource constraints. When resources become available the operation
   * will resume and this field will be false again.
   */
  throttled: boolean;
  /**
   * The progress of the
   * [UpdateDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.UpdateDatabaseDdl]
   * operations. All DDL statements will have continuously updating progress,
   * and `progress[i]` is the operation progress for `statements[i]`. Also,
   * `progress[i]` will have start time and end time populated with commit
   * timestamp of operation, as well as a progress of 100% once the operation
   * has completed.
   */
  progress: OperationProgress[];
  /**
   * The brief action info for the DDL statements.
   * `actions[i]` is the brief info for `statements[i]`.
   */
  actions: DdlStatementActionInfo[];
}

/**
 * The request for
 * [DropDatabase][google.spanner.admin.database.v1.DatabaseAdmin.DropDatabase].
 */
export interface DropDatabaseRequest {
  /** Required. The database to be dropped. */
  database: string;
}

/**
 * The request for
 * [GetDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.GetDatabaseDdl].
 */
export interface GetDatabaseDdlRequest {
  /**
   * Required. The database whose schema we wish to get.
   * Values are of the form
   * `projects/<project>/instances/<instance>/databases/<database>`
   */
  database: string;
}

/**
 * The response for
 * [GetDatabaseDdl][google.spanner.admin.database.v1.DatabaseAdmin.GetDatabaseDdl].
 */
export interface GetDatabaseDdlResponse {
  /**
   * A list of formatted DDL statements defining the schema of the database
   * specified in the request.
   */
  statements: string[];
  /**
   * Proto descriptors stored in the database.
   * Contains a protobuf-serialized
   * [google.protobuf.FileDescriptorSet](https://github.com/protocolbuffers/protobuf/blob/main/src/google/protobuf/descriptor.proto).
   * For more details, see protobuffer [self
   * description](https://developers.google.com/protocol-buffers/docs/techniques#self-description).
   */
  protoDescriptors: Buffer;
}

/**
 * The request for
 * [ListDatabaseOperations][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabaseOperations].
 */
export interface ListDatabaseOperationsRequest {
  /**
   * Required. The instance of the database operations.
   * Values are of the form `projects/<project>/instances/<instance>`.
   */
  parent: string;
  /**
   * An expression that filters the list of returned operations.
   *
   * A filter expression consists of a field name, a
   * comparison operator, and a value for filtering.
   * The value must be a string, a number, or a boolean. The comparison operator
   * must be one of: `<`, `>`, `<=`, `>=`, `!=`, `=`, or `:`.
   * Colon `:` is the contains operator. Filter rules are not case sensitive.
   *
   * The following fields in the [Operation][google.longrunning.Operation]
   * are eligible for filtering:
   *
   *   * `name` - The name of the long-running operation
   *   * `done` - False if the operation is in progress, else true.
   *   * `metadata.@type` - the type of metadata. For example, the type string
   *      for
   *      [RestoreDatabaseMetadata][google.spanner.admin.database.v1.RestoreDatabaseMetadata]
   *      is
   *      `type.googleapis.com/google.spanner.admin.database.v1.RestoreDatabaseMetadata`.
   *   * `metadata.<field_name>` - any field in metadata.value.
   *      `metadata.@type` must be specified first, if filtering on metadata
   *      fields.
   *   * `error` - Error associated with the long-running operation.
   *   * `response.@type` - the type of response.
   *   * `response.<field_name>` - any field in response.value.
   *
   * You can combine multiple expressions by enclosing each expression in
   * parentheses. By default, expressions are combined with AND logic. However,
   * you can specify AND, OR, and NOT logic explicitly.
   *
   * Here are a few examples:
   *
   *   * `done:true` - The operation is complete.
   *   * `(metadata.@type=type.googleapis.com/google.spanner.admin.database.v1.RestoreDatabaseMetadata) AND` \
   *     `(metadata.source_type:BACKUP) AND` \
   *     `(metadata.backup_info.backup:backup_howl) AND` \
   *     `(metadata.name:restored_howl) AND` \
   *     `(metadata.progress.start_time < \"2018-03-28T14:50:00Z\") AND` \
   *     `(error:*)` - Return operations where:
   *     * The operation's metadata type is
   *     [RestoreDatabaseMetadata][google.spanner.admin.database.v1.RestoreDatabaseMetadata].
   *     * The database is restored from a backup.
   *     * The backup name contains "backup_howl".
   *     * The restored database's name contains "restored_howl".
   *     * The operation started before 2018-03-28T14:50:00Z.
   *     * The operation resulted in an error.
   */
  filter: string;
  /**
   * Number of operations to be returned in the response. If 0 or
   * less, defaults to the server's maximum allowed page size.
   */
  pageSize: number;
  /**
   * If non-empty, `page_token` should contain a
   * [next_page_token][google.spanner.admin.database.v1.ListDatabaseOperationsResponse.next_page_token]
   * from a previous
   * [ListDatabaseOperationsResponse][google.spanner.admin.database.v1.ListDatabaseOperationsResponse]
   * to the same `parent` and with the same `filter`.
   */
  pageToken: string;
}

/**
 * The response for
 * [ListDatabaseOperations][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabaseOperations].
 */
export interface ListDatabaseOperationsResponse {
  /**
   * The list of matching database [long-running
   * operations][google.longrunning.Operation]. Each operation's name will be
   * prefixed by the database's name. The operation's
   * [metadata][google.longrunning.Operation.metadata] field type
   * `metadata.type_url` describes the type of the metadata.
   */
  operations: Operation[];
  /**
   * `next_page_token` can be sent in a subsequent
   * [ListDatabaseOperations][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabaseOperations]
   * call to fetch more of the matching metadata.
   */
  nextPageToken: string;
}

/**
 * The request for
 * [RestoreDatabase][google.spanner.admin.database.v1.DatabaseAdmin.RestoreDatabase].
 */
export interface RestoreDatabaseRequest {
  /**
   * Required. The name of the instance in which to create the
   * restored database. This instance must be in the same project and
   * have the same instance configuration as the instance containing
   * the source backup. Values are of the form
   * `projects/<project>/instances/<instance>`.
   */
  parent: string;
  /**
   * Required. The id of the database to create and restore to. This
   * database must not already exist. The `database_id` appended to
   * `parent` forms the full database name of the form
   * `projects/<project>/instances/<instance>/databases/<database_id>`.
   */
  databaseId: string;
  /**
   * Name of the backup from which to restore.  Values are of the form
   * `projects/<project>/instances/<instance>/backups/<backup>`.
   */
  backup?:
    | string
    | undefined;
  /**
   * Optional. An encryption configuration describing the encryption type and
   * key resources in Cloud KMS used to encrypt/decrypt the database to restore
   * to. If this field is not specified, the restored database will use the same
   * encryption configuration as the backup by default, namely
   * [encryption_type][google.spanner.admin.database.v1.RestoreDatabaseEncryptionConfig.encryption_type]
   * = `USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION`.
   */
  encryptionConfig: RestoreDatabaseEncryptionConfig | undefined;
}

/** Encryption configuration for the restored database. */
export interface RestoreDatabaseEncryptionConfig {
  /** Required. The encryption type of the restored database. */
  encryptionType: RestoreDatabaseEncryptionConfig_EncryptionType;
  /**
   * Optional. The Cloud KMS key that will be used to encrypt/decrypt the
   * restored database. This field should be set only when
   * [encryption_type][google.spanner.admin.database.v1.RestoreDatabaseEncryptionConfig.encryption_type]
   * is `CUSTOMER_MANAGED_ENCRYPTION`. Values are of the form
   * `projects/<project>/locations/<location>/keyRings/<key_ring>/cryptoKeys/<kms_key_name>`.
   */
  kmsKeyName: string;
  /**
   * Optional. Specifies the KMS configuration for the one or more keys used to
   * encrypt the database. Values are of the form
   * `projects/<project>/locations/<location>/keyRings/<key_ring>/cryptoKeys/<kms_key_name>`.
   *
   * The keys referenced by kms_key_names must fully cover all
   * regions of the database instance configuration. Some examples:
   * * For single region database instance configs, specify a single regional
   * location KMS key.
   * * For multi-regional database instance configs of type GOOGLE_MANAGED,
   * either specify a multi-regional location KMS key or multiple regional
   * location KMS keys that cover all regions in the instance config.
   * * For a database instance config of type USER_MANAGED, please specify only
   * regional location KMS keys to cover each region in the instance config.
   * Multi-regional location KMS keys are not supported for USER_MANAGED
   * instance configs.
   */
  kmsKeyNames: string[];
}

/** Encryption types for the database to be restored. */
export enum RestoreDatabaseEncryptionConfig_EncryptionType {
  /** ENCRYPTION_TYPE_UNSPECIFIED - Unspecified. Do not use. */
  ENCRYPTION_TYPE_UNSPECIFIED = 0,
  /**
   * USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION - This is the default option when
   * [encryption_config][google.spanner.admin.database.v1.RestoreDatabaseEncryptionConfig]
   * is not specified.
   */
  USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION = 1,
  /** GOOGLE_DEFAULT_ENCRYPTION - Use Google default encryption. */
  GOOGLE_DEFAULT_ENCRYPTION = 2,
  /**
   * CUSTOMER_MANAGED_ENCRYPTION - Use customer managed encryption. If specified, `kms_key_name` must
   * must contain a valid Cloud KMS key.
   */
  CUSTOMER_MANAGED_ENCRYPTION = 3,
  UNRECOGNIZED = -1,
}

export function restoreDatabaseEncryptionConfig_EncryptionTypeFromJSON(
  object: any,
): RestoreDatabaseEncryptionConfig_EncryptionType {
  switch (object) {
    case 0:
    case "ENCRYPTION_TYPE_UNSPECIFIED":
      return RestoreDatabaseEncryptionConfig_EncryptionType.ENCRYPTION_TYPE_UNSPECIFIED;
    case 1:
    case "USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION":
      return RestoreDatabaseEncryptionConfig_EncryptionType.USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION;
    case 2:
    case "GOOGLE_DEFAULT_ENCRYPTION":
      return RestoreDatabaseEncryptionConfig_EncryptionType.GOOGLE_DEFAULT_ENCRYPTION;
    case 3:
    case "CUSTOMER_MANAGED_ENCRYPTION":
      return RestoreDatabaseEncryptionConfig_EncryptionType.CUSTOMER_MANAGED_ENCRYPTION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RestoreDatabaseEncryptionConfig_EncryptionType.UNRECOGNIZED;
  }
}

export function restoreDatabaseEncryptionConfig_EncryptionTypeToJSON(
  object: RestoreDatabaseEncryptionConfig_EncryptionType,
): string {
  switch (object) {
    case RestoreDatabaseEncryptionConfig_EncryptionType.ENCRYPTION_TYPE_UNSPECIFIED:
      return "ENCRYPTION_TYPE_UNSPECIFIED";
    case RestoreDatabaseEncryptionConfig_EncryptionType.USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION:
      return "USE_CONFIG_DEFAULT_OR_BACKUP_ENCRYPTION";
    case RestoreDatabaseEncryptionConfig_EncryptionType.GOOGLE_DEFAULT_ENCRYPTION:
      return "GOOGLE_DEFAULT_ENCRYPTION";
    case RestoreDatabaseEncryptionConfig_EncryptionType.CUSTOMER_MANAGED_ENCRYPTION:
      return "CUSTOMER_MANAGED_ENCRYPTION";
    case RestoreDatabaseEncryptionConfig_EncryptionType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Metadata type for the long-running operation returned by
 * [RestoreDatabase][google.spanner.admin.database.v1.DatabaseAdmin.RestoreDatabase].
 */
export interface RestoreDatabaseMetadata {
  /** Name of the database being created and restored to. */
  name: string;
  /** The type of the restore source. */
  sourceType: RestoreSourceType;
  /** Information about the backup used to restore the database. */
  backupInfo?:
    | BackupInfo
    | undefined;
  /**
   * The progress of the
   * [RestoreDatabase][google.spanner.admin.database.v1.DatabaseAdmin.RestoreDatabase]
   * operation.
   */
  progress:
    | OperationProgress
    | undefined;
  /**
   * The time at which cancellation of this operation was received.
   * [Operations.CancelOperation][google.longrunning.Operations.CancelOperation]
   * starts asynchronous cancellation on a long-running operation. The server
   * makes a best effort to cancel the operation, but success is not guaranteed.
   * Clients can use
   * [Operations.GetOperation][google.longrunning.Operations.GetOperation] or
   * other methods to check whether the cancellation succeeded or whether the
   * operation completed despite cancellation. On successful cancellation,
   * the operation is not deleted; instead, it becomes an operation with
   * an [Operation.error][google.longrunning.Operation.error] value with a
   * [google.rpc.Status.code][google.rpc.Status.code] of 1, corresponding to
   * `Code.CANCELLED`.
   */
  cancelTime:
    | Date
    | undefined;
  /**
   * If exists, the name of the long-running operation that will be used to
   * track the post-restore optimization process to optimize the performance of
   * the restored database, and remove the dependency on the restore source.
   * The name is of the form
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation>`
   * where the <database> is the name of database being created and restored to.
   * The metadata type of the  long-running operation is
   * [OptimizeRestoredDatabaseMetadata][google.spanner.admin.database.v1.OptimizeRestoredDatabaseMetadata].
   * This long-running operation will be automatically created by the system
   * after the RestoreDatabase long-running operation completes successfully.
   * This operation will not be created if the restore was not successful.
   */
  optimizeDatabaseOperationName: string;
}

/**
 * Metadata type for the long-running operation used to track the progress
 * of optimizations performed on a newly restored database. This long-running
 * operation is automatically created by the system after the successful
 * completion of a database restore, and cannot be cancelled.
 */
export interface OptimizeRestoredDatabaseMetadata {
  /** Name of the restored database being optimized. */
  name: string;
  /** The progress of the post-restore optimizations. */
  progress: OperationProgress | undefined;
}

/** A Cloud Spanner database role. */
export interface DatabaseRole {
  /**
   * Required. The name of the database role. Values are of the form
   * `projects/<project>/instances/<instance>/databases/<database>/databaseRoles/<role>`
   * where `<role>` is as specified in the `CREATE ROLE` DDL statement.
   */
  name: string;
}

/**
 * The request for
 * [ListDatabaseRoles][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabaseRoles].
 */
export interface ListDatabaseRolesRequest {
  /**
   * Required. The database whose roles should be listed.
   * Values are of the form
   * `projects/<project>/instances/<instance>/databases/<database>`.
   */
  parent: string;
  /**
   * Number of database roles to be returned in the response. If 0 or less,
   * defaults to the server's maximum allowed page size.
   */
  pageSize: number;
  /**
   * If non-empty, `page_token` should contain a
   * [next_page_token][google.spanner.admin.database.v1.ListDatabaseRolesResponse.next_page_token]
   * from a previous
   * [ListDatabaseRolesResponse][google.spanner.admin.database.v1.ListDatabaseRolesResponse].
   */
  pageToken: string;
}

/**
 * The response for
 * [ListDatabaseRoles][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabaseRoles].
 */
export interface ListDatabaseRolesResponse {
  /** Database roles that matched the request. */
  databaseRoles: DatabaseRole[];
  /**
   * `next_page_token` can be sent in a subsequent
   * [ListDatabaseRoles][google.spanner.admin.database.v1.DatabaseAdmin.ListDatabaseRoles]
   * call to fetch more of the matching roles.
   */
  nextPageToken: string;
}

function createBaseRestoreInfo(): RestoreInfo {
  return { sourceType: 0, backupInfo: undefined };
}

export const RestoreInfo: MessageFns<RestoreInfo> = {
  encode(message: RestoreInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sourceType !== 0) {
      writer.uint32(8).int32(message.sourceType);
    }
    if (message.backupInfo !== undefined) {
      BackupInfo.encode(message.backupInfo, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.sourceType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backupInfo = BackupInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreInfo {
    return {
      sourceType: isSet(object.sourceType) ? restoreSourceTypeFromJSON(object.sourceType) : 0,
      backupInfo: isSet(object.backupInfo) ? BackupInfo.fromJSON(object.backupInfo) : undefined,
    };
  },

  toJSON(message: RestoreInfo): unknown {
    const obj: any = {};
    if (message.sourceType !== 0) {
      obj.sourceType = restoreSourceTypeToJSON(message.sourceType);
    }
    if (message.backupInfo !== undefined) {
      obj.backupInfo = BackupInfo.toJSON(message.backupInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreInfo>): RestoreInfo {
    return RestoreInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreInfo>): RestoreInfo {
    const message = createBaseRestoreInfo();
    message.sourceType = object.sourceType ?? 0;
    message.backupInfo = (object.backupInfo !== undefined && object.backupInfo !== null)
      ? BackupInfo.fromPartial(object.backupInfo)
      : undefined;
    return message;
  },
};

function createBaseDatabase(): Database {
  return {
    name: "",
    state: 0,
    createTime: undefined,
    restoreInfo: undefined,
    encryptionConfig: undefined,
    encryptionInfo: [],
    versionRetentionPeriod: "",
    earliestVersionTime: undefined,
    defaultLeader: "",
    databaseDialect: 0,
    enableDropProtection: false,
    reconciling: false,
  };
}

export const Database: MessageFns<Database> = {
  encode(message: Database, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.restoreInfo !== undefined) {
      RestoreInfo.encode(message.restoreInfo, writer.uint32(34).fork()).join();
    }
    if (message.encryptionConfig !== undefined) {
      EncryptionConfig.encode(message.encryptionConfig, writer.uint32(42).fork()).join();
    }
    for (const v of message.encryptionInfo) {
      EncryptionInfo.encode(v!, writer.uint32(66).fork()).join();
    }
    if (message.versionRetentionPeriod !== "") {
      writer.uint32(50).string(message.versionRetentionPeriod);
    }
    if (message.earliestVersionTime !== undefined) {
      Timestamp.encode(toTimestamp(message.earliestVersionTime), writer.uint32(58).fork()).join();
    }
    if (message.defaultLeader !== "") {
      writer.uint32(74).string(message.defaultLeader);
    }
    if (message.databaseDialect !== 0) {
      writer.uint32(80).int32(message.databaseDialect);
    }
    if (message.enableDropProtection !== false) {
      writer.uint32(88).bool(message.enableDropProtection);
    }
    if (message.reconciling !== false) {
      writer.uint32(96).bool(message.reconciling);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Database {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabase();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.restoreInfo = RestoreInfo.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.encryptionConfig = EncryptionConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.encryptionInfo.push(EncryptionInfo.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.versionRetentionPeriod = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.earliestVersionTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.defaultLeader = reader.string();
          continue;
        case 10:
          if (tag !== 80) {
            break;
          }

          message.databaseDialect = reader.int32() as any;
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.enableDropProtection = reader.bool();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Database {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      state: isSet(object.state) ? database_StateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      restoreInfo: isSet(object.restoreInfo) ? RestoreInfo.fromJSON(object.restoreInfo) : undefined,
      encryptionConfig: isSet(object.encryptionConfig) ? EncryptionConfig.fromJSON(object.encryptionConfig) : undefined,
      encryptionInfo: globalThis.Array.isArray(object?.encryptionInfo)
        ? object.encryptionInfo.map((e: any) => EncryptionInfo.fromJSON(e))
        : [],
      versionRetentionPeriod: isSet(object.versionRetentionPeriod)
        ? globalThis.String(object.versionRetentionPeriod)
        : "",
      earliestVersionTime: isSet(object.earliestVersionTime)
        ? fromJsonTimestamp(object.earliestVersionTime)
        : undefined,
      defaultLeader: isSet(object.defaultLeader) ? globalThis.String(object.defaultLeader) : "",
      databaseDialect: isSet(object.databaseDialect) ? databaseDialectFromJSON(object.databaseDialect) : 0,
      enableDropProtection: isSet(object.enableDropProtection)
        ? globalThis.Boolean(object.enableDropProtection)
        : false,
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
    };
  },

  toJSON(message: Database): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.state !== 0) {
      obj.state = database_StateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.restoreInfo !== undefined) {
      obj.restoreInfo = RestoreInfo.toJSON(message.restoreInfo);
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = EncryptionConfig.toJSON(message.encryptionConfig);
    }
    if (message.encryptionInfo?.length) {
      obj.encryptionInfo = message.encryptionInfo.map((e) => EncryptionInfo.toJSON(e));
    }
    if (message.versionRetentionPeriod !== "") {
      obj.versionRetentionPeriod = message.versionRetentionPeriod;
    }
    if (message.earliestVersionTime !== undefined) {
      obj.earliestVersionTime = message.earliestVersionTime.toISOString();
    }
    if (message.defaultLeader !== "") {
      obj.defaultLeader = message.defaultLeader;
    }
    if (message.databaseDialect !== 0) {
      obj.databaseDialect = databaseDialectToJSON(message.databaseDialect);
    }
    if (message.enableDropProtection !== false) {
      obj.enableDropProtection = message.enableDropProtection;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    return obj;
  },

  create(base?: DeepPartial<Database>): Database {
    return Database.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Database>): Database {
    const message = createBaseDatabase();
    message.name = object.name ?? "";
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.restoreInfo = (object.restoreInfo !== undefined && object.restoreInfo !== null)
      ? RestoreInfo.fromPartial(object.restoreInfo)
      : undefined;
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    message.encryptionInfo = object.encryptionInfo?.map((e) => EncryptionInfo.fromPartial(e)) || [];
    message.versionRetentionPeriod = object.versionRetentionPeriod ?? "";
    message.earliestVersionTime = object.earliestVersionTime ?? undefined;
    message.defaultLeader = object.defaultLeader ?? "";
    message.databaseDialect = object.databaseDialect ?? 0;
    message.enableDropProtection = object.enableDropProtection ?? false;
    message.reconciling = object.reconciling ?? false;
    return message;
  },
};

function createBaseListDatabasesRequest(): ListDatabasesRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListDatabasesRequest: MessageFns<ListDatabasesRequest> = {
  encode(message: ListDatabasesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabasesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabasesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabasesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListDatabasesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabasesRequest>): ListDatabasesRequest {
    return ListDatabasesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabasesRequest>): ListDatabasesRequest {
    const message = createBaseListDatabasesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListDatabasesResponse(): ListDatabasesResponse {
  return { databases: [], nextPageToken: "" };
}

export const ListDatabasesResponse: MessageFns<ListDatabasesResponse> = {
  encode(message: ListDatabasesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.databases) {
      Database.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabasesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabasesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.databases.push(Database.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabasesResponse {
    return {
      databases: globalThis.Array.isArray(object?.databases)
        ? object.databases.map((e: any) => Database.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDatabasesResponse): unknown {
    const obj: any = {};
    if (message.databases?.length) {
      obj.databases = message.databases.map((e) => Database.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabasesResponse>): ListDatabasesResponse {
    return ListDatabasesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabasesResponse>): ListDatabasesResponse {
    const message = createBaseListDatabasesResponse();
    message.databases = object.databases?.map((e) => Database.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCreateDatabaseRequest(): CreateDatabaseRequest {
  return {
    parent: "",
    createStatement: "",
    extraStatements: [],
    encryptionConfig: undefined,
    databaseDialect: 0,
    protoDescriptors: Buffer.alloc(0),
  };
}

export const CreateDatabaseRequest: MessageFns<CreateDatabaseRequest> = {
  encode(message: CreateDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.createStatement !== "") {
      writer.uint32(18).string(message.createStatement);
    }
    for (const v of message.extraStatements) {
      writer.uint32(26).string(v!);
    }
    if (message.encryptionConfig !== undefined) {
      EncryptionConfig.encode(message.encryptionConfig, writer.uint32(34).fork()).join();
    }
    if (message.databaseDialect !== 0) {
      writer.uint32(40).int32(message.databaseDialect);
    }
    if (message.protoDescriptors.length !== 0) {
      writer.uint32(50).bytes(message.protoDescriptors);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createStatement = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.extraStatements.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.encryptionConfig = EncryptionConfig.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.databaseDialect = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.protoDescriptors = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDatabaseRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      createStatement: isSet(object.createStatement) ? globalThis.String(object.createStatement) : "",
      extraStatements: globalThis.Array.isArray(object?.extraStatements)
        ? object.extraStatements.map((e: any) => globalThis.String(e))
        : [],
      encryptionConfig: isSet(object.encryptionConfig) ? EncryptionConfig.fromJSON(object.encryptionConfig) : undefined,
      databaseDialect: isSet(object.databaseDialect) ? databaseDialectFromJSON(object.databaseDialect) : 0,
      protoDescriptors: isSet(object.protoDescriptors)
        ? Buffer.from(bytesFromBase64(object.protoDescriptors))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: CreateDatabaseRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.createStatement !== "") {
      obj.createStatement = message.createStatement;
    }
    if (message.extraStatements?.length) {
      obj.extraStatements = message.extraStatements;
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = EncryptionConfig.toJSON(message.encryptionConfig);
    }
    if (message.databaseDialect !== 0) {
      obj.databaseDialect = databaseDialectToJSON(message.databaseDialect);
    }
    if (message.protoDescriptors.length !== 0) {
      obj.protoDescriptors = base64FromBytes(message.protoDescriptors);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDatabaseRequest>): CreateDatabaseRequest {
    return CreateDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDatabaseRequest>): CreateDatabaseRequest {
    const message = createBaseCreateDatabaseRequest();
    message.parent = object.parent ?? "";
    message.createStatement = object.createStatement ?? "";
    message.extraStatements = object.extraStatements?.map((e) => e) || [];
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    message.databaseDialect = object.databaseDialect ?? 0;
    message.protoDescriptors = object.protoDescriptors ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCreateDatabaseMetadata(): CreateDatabaseMetadata {
  return { database: "" };
}

export const CreateDatabaseMetadata: MessageFns<CreateDatabaseMetadata> = {
  encode(message: CreateDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDatabaseMetadata {
    return { database: isSet(object.database) ? globalThis.String(object.database) : "" };
  },

  toJSON(message: CreateDatabaseMetadata): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDatabaseMetadata>): CreateDatabaseMetadata {
    return CreateDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDatabaseMetadata>): CreateDatabaseMetadata {
    const message = createBaseCreateDatabaseMetadata();
    message.database = object.database ?? "";
    return message;
  },
};

function createBaseGetDatabaseRequest(): GetDatabaseRequest {
  return { name: "" };
}

export const GetDatabaseRequest: MessageFns<GetDatabaseRequest> = {
  encode(message: GetDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatabaseRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetDatabaseRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDatabaseRequest>): GetDatabaseRequest {
    return GetDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDatabaseRequest>): GetDatabaseRequest {
    const message = createBaseGetDatabaseRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateDatabaseRequest(): UpdateDatabaseRequest {
  return { database: undefined, updateMask: undefined };
}

export const UpdateDatabaseRequest: MessageFns<UpdateDatabaseRequest> = {
  encode(message: UpdateDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== undefined) {
      Database.encode(message.database, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = Database.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDatabaseRequest {
    return {
      database: isSet(object.database) ? Database.fromJSON(object.database) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateDatabaseRequest): unknown {
    const obj: any = {};
    if (message.database !== undefined) {
      obj.database = Database.toJSON(message.database);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDatabaseRequest>): UpdateDatabaseRequest {
    return UpdateDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDatabaseRequest>): UpdateDatabaseRequest {
    const message = createBaseUpdateDatabaseRequest();
    message.database = (object.database !== undefined && object.database !== null)
      ? Database.fromPartial(object.database)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseUpdateDatabaseMetadata(): UpdateDatabaseMetadata {
  return { request: undefined, progress: undefined, cancelTime: undefined };
}

export const UpdateDatabaseMetadata: MessageFns<UpdateDatabaseMetadata> = {
  encode(message: UpdateDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.request !== undefined) {
      UpdateDatabaseRequest.encode(message.request, writer.uint32(10).fork()).join();
    }
    if (message.progress !== undefined) {
      OperationProgress.encode(message.progress, writer.uint32(18).fork()).join();
    }
    if (message.cancelTime !== undefined) {
      Timestamp.encode(toTimestamp(message.cancelTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.request = UpdateDatabaseRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.progress = OperationProgress.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.cancelTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDatabaseMetadata {
    return {
      request: isSet(object.request) ? UpdateDatabaseRequest.fromJSON(object.request) : undefined,
      progress: isSet(object.progress) ? OperationProgress.fromJSON(object.progress) : undefined,
      cancelTime: isSet(object.cancelTime) ? fromJsonTimestamp(object.cancelTime) : undefined,
    };
  },

  toJSON(message: UpdateDatabaseMetadata): unknown {
    const obj: any = {};
    if (message.request !== undefined) {
      obj.request = UpdateDatabaseRequest.toJSON(message.request);
    }
    if (message.progress !== undefined) {
      obj.progress = OperationProgress.toJSON(message.progress);
    }
    if (message.cancelTime !== undefined) {
      obj.cancelTime = message.cancelTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDatabaseMetadata>): UpdateDatabaseMetadata {
    return UpdateDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDatabaseMetadata>): UpdateDatabaseMetadata {
    const message = createBaseUpdateDatabaseMetadata();
    message.request = (object.request !== undefined && object.request !== null)
      ? UpdateDatabaseRequest.fromPartial(object.request)
      : undefined;
    message.progress = (object.progress !== undefined && object.progress !== null)
      ? OperationProgress.fromPartial(object.progress)
      : undefined;
    message.cancelTime = object.cancelTime ?? undefined;
    return message;
  },
};

function createBaseUpdateDatabaseDdlRequest(): UpdateDatabaseDdlRequest {
  return { database: "", statements: [], operationId: "", protoDescriptors: Buffer.alloc(0) };
}

export const UpdateDatabaseDdlRequest: MessageFns<UpdateDatabaseDdlRequest> = {
  encode(message: UpdateDatabaseDdlRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    for (const v of message.statements) {
      writer.uint32(18).string(v!);
    }
    if (message.operationId !== "") {
      writer.uint32(26).string(message.operationId);
    }
    if (message.protoDescriptors.length !== 0) {
      writer.uint32(34).bytes(message.protoDescriptors);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDatabaseDdlRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDatabaseDdlRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.statements.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.operationId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.protoDescriptors = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDatabaseDdlRequest {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      statements: globalThis.Array.isArray(object?.statements)
        ? object.statements.map((e: any) => globalThis.String(e))
        : [],
      operationId: isSet(object.operationId) ? globalThis.String(object.operationId) : "",
      protoDescriptors: isSet(object.protoDescriptors)
        ? Buffer.from(bytesFromBase64(object.protoDescriptors))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: UpdateDatabaseDdlRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.statements?.length) {
      obj.statements = message.statements;
    }
    if (message.operationId !== "") {
      obj.operationId = message.operationId;
    }
    if (message.protoDescriptors.length !== 0) {
      obj.protoDescriptors = base64FromBytes(message.protoDescriptors);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDatabaseDdlRequest>): UpdateDatabaseDdlRequest {
    return UpdateDatabaseDdlRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDatabaseDdlRequest>): UpdateDatabaseDdlRequest {
    const message = createBaseUpdateDatabaseDdlRequest();
    message.database = object.database ?? "";
    message.statements = object.statements?.map((e) => e) || [];
    message.operationId = object.operationId ?? "";
    message.protoDescriptors = object.protoDescriptors ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseDdlStatementActionInfo(): DdlStatementActionInfo {
  return { action: "", entityType: "", entityNames: [] };
}

export const DdlStatementActionInfo: MessageFns<DdlStatementActionInfo> = {
  encode(message: DdlStatementActionInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.action !== "") {
      writer.uint32(10).string(message.action);
    }
    if (message.entityType !== "") {
      writer.uint32(18).string(message.entityType);
    }
    for (const v of message.entityNames) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DdlStatementActionInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDdlStatementActionInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.action = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entityType = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entityNames.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DdlStatementActionInfo {
    return {
      action: isSet(object.action) ? globalThis.String(object.action) : "",
      entityType: isSet(object.entityType) ? globalThis.String(object.entityType) : "",
      entityNames: globalThis.Array.isArray(object?.entityNames)
        ? object.entityNames.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: DdlStatementActionInfo): unknown {
    const obj: any = {};
    if (message.action !== "") {
      obj.action = message.action;
    }
    if (message.entityType !== "") {
      obj.entityType = message.entityType;
    }
    if (message.entityNames?.length) {
      obj.entityNames = message.entityNames;
    }
    return obj;
  },

  create(base?: DeepPartial<DdlStatementActionInfo>): DdlStatementActionInfo {
    return DdlStatementActionInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DdlStatementActionInfo>): DdlStatementActionInfo {
    const message = createBaseDdlStatementActionInfo();
    message.action = object.action ?? "";
    message.entityType = object.entityType ?? "";
    message.entityNames = object.entityNames?.map((e) => e) || [];
    return message;
  },
};

function createBaseUpdateDatabaseDdlMetadata(): UpdateDatabaseDdlMetadata {
  return { database: "", statements: [], commitTimestamps: [], throttled: false, progress: [], actions: [] };
}

export const UpdateDatabaseDdlMetadata: MessageFns<UpdateDatabaseDdlMetadata> = {
  encode(message: UpdateDatabaseDdlMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    for (const v of message.statements) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.commitTimestamps) {
      Timestamp.encode(toTimestamp(v!), writer.uint32(26).fork()).join();
    }
    if (message.throttled !== false) {
      writer.uint32(32).bool(message.throttled);
    }
    for (const v of message.progress) {
      OperationProgress.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.actions) {
      DdlStatementActionInfo.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDatabaseDdlMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDatabaseDdlMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.statements.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.commitTimestamps.push(fromTimestamp(Timestamp.decode(reader, reader.uint32())));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.throttled = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progress.push(OperationProgress.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.actions.push(DdlStatementActionInfo.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDatabaseDdlMetadata {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      statements: globalThis.Array.isArray(object?.statements)
        ? object.statements.map((e: any) => globalThis.String(e))
        : [],
      commitTimestamps: globalThis.Array.isArray(object?.commitTimestamps)
        ? object.commitTimestamps.map((e: any) => fromJsonTimestamp(e))
        : [],
      throttled: isSet(object.throttled) ? globalThis.Boolean(object.throttled) : false,
      progress: globalThis.Array.isArray(object?.progress)
        ? object.progress.map((e: any) => OperationProgress.fromJSON(e))
        : [],
      actions: globalThis.Array.isArray(object?.actions)
        ? object.actions.map((e: any) => DdlStatementActionInfo.fromJSON(e))
        : [],
    };
  },

  toJSON(message: UpdateDatabaseDdlMetadata): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.statements?.length) {
      obj.statements = message.statements;
    }
    if (message.commitTimestamps?.length) {
      obj.commitTimestamps = message.commitTimestamps.map((e) => e.toISOString());
    }
    if (message.throttled !== false) {
      obj.throttled = message.throttled;
    }
    if (message.progress?.length) {
      obj.progress = message.progress.map((e) => OperationProgress.toJSON(e));
    }
    if (message.actions?.length) {
      obj.actions = message.actions.map((e) => DdlStatementActionInfo.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDatabaseDdlMetadata>): UpdateDatabaseDdlMetadata {
    return UpdateDatabaseDdlMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDatabaseDdlMetadata>): UpdateDatabaseDdlMetadata {
    const message = createBaseUpdateDatabaseDdlMetadata();
    message.database = object.database ?? "";
    message.statements = object.statements?.map((e) => e) || [];
    message.commitTimestamps = object.commitTimestamps?.map((e) => e) || [];
    message.throttled = object.throttled ?? false;
    message.progress = object.progress?.map((e) => OperationProgress.fromPartial(e)) || [];
    message.actions = object.actions?.map((e) => DdlStatementActionInfo.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDropDatabaseRequest(): DropDatabaseRequest {
  return { database: "" };
}

export const DropDatabaseRequest: MessageFns<DropDatabaseRequest> = {
  encode(message: DropDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DropDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDropDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DropDatabaseRequest {
    return { database: isSet(object.database) ? globalThis.String(object.database) : "" };
  },

  toJSON(message: DropDatabaseRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    return obj;
  },

  create(base?: DeepPartial<DropDatabaseRequest>): DropDatabaseRequest {
    return DropDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DropDatabaseRequest>): DropDatabaseRequest {
    const message = createBaseDropDatabaseRequest();
    message.database = object.database ?? "";
    return message;
  },
};

function createBaseGetDatabaseDdlRequest(): GetDatabaseDdlRequest {
  return { database: "" };
}

export const GetDatabaseDdlRequest: MessageFns<GetDatabaseDdlRequest> = {
  encode(message: GetDatabaseDdlRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatabaseDdlRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatabaseDdlRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatabaseDdlRequest {
    return { database: isSet(object.database) ? globalThis.String(object.database) : "" };
  },

  toJSON(message: GetDatabaseDdlRequest): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDatabaseDdlRequest>): GetDatabaseDdlRequest {
    return GetDatabaseDdlRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDatabaseDdlRequest>): GetDatabaseDdlRequest {
    const message = createBaseGetDatabaseDdlRequest();
    message.database = object.database ?? "";
    return message;
  },
};

function createBaseGetDatabaseDdlResponse(): GetDatabaseDdlResponse {
  return { statements: [], protoDescriptors: Buffer.alloc(0) };
}

export const GetDatabaseDdlResponse: MessageFns<GetDatabaseDdlResponse> = {
  encode(message: GetDatabaseDdlResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.statements) {
      writer.uint32(10).string(v!);
    }
    if (message.protoDescriptors.length !== 0) {
      writer.uint32(18).bytes(message.protoDescriptors);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatabaseDdlResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatabaseDdlResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.statements.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.protoDescriptors = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatabaseDdlResponse {
    return {
      statements: globalThis.Array.isArray(object?.statements)
        ? object.statements.map((e: any) => globalThis.String(e))
        : [],
      protoDescriptors: isSet(object.protoDescriptors)
        ? Buffer.from(bytesFromBase64(object.protoDescriptors))
        : Buffer.alloc(0),
    };
  },

  toJSON(message: GetDatabaseDdlResponse): unknown {
    const obj: any = {};
    if (message.statements?.length) {
      obj.statements = message.statements;
    }
    if (message.protoDescriptors.length !== 0) {
      obj.protoDescriptors = base64FromBytes(message.protoDescriptors);
    }
    return obj;
  },

  create(base?: DeepPartial<GetDatabaseDdlResponse>): GetDatabaseDdlResponse {
    return GetDatabaseDdlResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDatabaseDdlResponse>): GetDatabaseDdlResponse {
    const message = createBaseGetDatabaseDdlResponse();
    message.statements = object.statements?.map((e) => e) || [];
    message.protoDescriptors = object.protoDescriptors ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseListDatabaseOperationsRequest(): ListDatabaseOperationsRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "" };
}

export const ListDatabaseOperationsRequest: MessageFns<ListDatabaseOperationsRequest> = {
  encode(message: ListDatabaseOperationsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabaseOperationsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabaseOperationsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabaseOperationsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListDatabaseOperationsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabaseOperationsRequest>): ListDatabaseOperationsRequest {
    return ListDatabaseOperationsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabaseOperationsRequest>): ListDatabaseOperationsRequest {
    const message = createBaseListDatabaseOperationsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListDatabaseOperationsResponse(): ListDatabaseOperationsResponse {
  return { operations: [], nextPageToken: "" };
}

export const ListDatabaseOperationsResponse: MessageFns<ListDatabaseOperationsResponse> = {
  encode(message: ListDatabaseOperationsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.operations) {
      Operation.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabaseOperationsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabaseOperationsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operations.push(Operation.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabaseOperationsResponse {
    return {
      operations: globalThis.Array.isArray(object?.operations)
        ? object.operations.map((e: any) => Operation.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDatabaseOperationsResponse): unknown {
    const obj: any = {};
    if (message.operations?.length) {
      obj.operations = message.operations.map((e) => Operation.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabaseOperationsResponse>): ListDatabaseOperationsResponse {
    return ListDatabaseOperationsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabaseOperationsResponse>): ListDatabaseOperationsResponse {
    const message = createBaseListDatabaseOperationsResponse();
    message.operations = object.operations?.map((e) => Operation.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseRestoreDatabaseRequest(): RestoreDatabaseRequest {
  return { parent: "", databaseId: "", backup: undefined, encryptionConfig: undefined };
}

export const RestoreDatabaseRequest: MessageFns<RestoreDatabaseRequest> = {
  encode(message: RestoreDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.databaseId !== "") {
      writer.uint32(18).string(message.databaseId);
    }
    if (message.backup !== undefined) {
      writer.uint32(26).string(message.backup);
    }
    if (message.encryptionConfig !== undefined) {
      RestoreDatabaseEncryptionConfig.encode(message.encryptionConfig, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backup = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.encryptionConfig = RestoreDatabaseEncryptionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreDatabaseRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      backup: isSet(object.backup) ? globalThis.String(object.backup) : undefined,
      encryptionConfig: isSet(object.encryptionConfig)
        ? RestoreDatabaseEncryptionConfig.fromJSON(object.encryptionConfig)
        : undefined,
    };
  },

  toJSON(message: RestoreDatabaseRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.backup !== undefined) {
      obj.backup = message.backup;
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = RestoreDatabaseEncryptionConfig.toJSON(message.encryptionConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreDatabaseRequest>): RestoreDatabaseRequest {
    return RestoreDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreDatabaseRequest>): RestoreDatabaseRequest {
    const message = createBaseRestoreDatabaseRequest();
    message.parent = object.parent ?? "";
    message.databaseId = object.databaseId ?? "";
    message.backup = object.backup ?? undefined;
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? RestoreDatabaseEncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    return message;
  },
};

function createBaseRestoreDatabaseEncryptionConfig(): RestoreDatabaseEncryptionConfig {
  return { encryptionType: 0, kmsKeyName: "", kmsKeyNames: [] };
}

export const RestoreDatabaseEncryptionConfig: MessageFns<RestoreDatabaseEncryptionConfig> = {
  encode(message: RestoreDatabaseEncryptionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encryptionType !== 0) {
      writer.uint32(8).int32(message.encryptionType);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(18).string(message.kmsKeyName);
    }
    for (const v of message.kmsKeyNames) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreDatabaseEncryptionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreDatabaseEncryptionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.encryptionType = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kmsKeyNames.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreDatabaseEncryptionConfig {
    return {
      encryptionType: isSet(object.encryptionType)
        ? restoreDatabaseEncryptionConfig_EncryptionTypeFromJSON(object.encryptionType)
        : 0,
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      kmsKeyNames: globalThis.Array.isArray(object?.kmsKeyNames)
        ? object.kmsKeyNames.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: RestoreDatabaseEncryptionConfig): unknown {
    const obj: any = {};
    if (message.encryptionType !== 0) {
      obj.encryptionType = restoreDatabaseEncryptionConfig_EncryptionTypeToJSON(message.encryptionType);
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.kmsKeyNames?.length) {
      obj.kmsKeyNames = message.kmsKeyNames;
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreDatabaseEncryptionConfig>): RestoreDatabaseEncryptionConfig {
    return RestoreDatabaseEncryptionConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreDatabaseEncryptionConfig>): RestoreDatabaseEncryptionConfig {
    const message = createBaseRestoreDatabaseEncryptionConfig();
    message.encryptionType = object.encryptionType ?? 0;
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.kmsKeyNames = object.kmsKeyNames?.map((e) => e) || [];
    return message;
  },
};

function createBaseRestoreDatabaseMetadata(): RestoreDatabaseMetadata {
  return {
    name: "",
    sourceType: 0,
    backupInfo: undefined,
    progress: undefined,
    cancelTime: undefined,
    optimizeDatabaseOperationName: "",
  };
}

export const RestoreDatabaseMetadata: MessageFns<RestoreDatabaseMetadata> = {
  encode(message: RestoreDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sourceType !== 0) {
      writer.uint32(16).int32(message.sourceType);
    }
    if (message.backupInfo !== undefined) {
      BackupInfo.encode(message.backupInfo, writer.uint32(26).fork()).join();
    }
    if (message.progress !== undefined) {
      OperationProgress.encode(message.progress, writer.uint32(34).fork()).join();
    }
    if (message.cancelTime !== undefined) {
      Timestamp.encode(toTimestamp(message.cancelTime), writer.uint32(42).fork()).join();
    }
    if (message.optimizeDatabaseOperationName !== "") {
      writer.uint32(50).string(message.optimizeDatabaseOperationName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sourceType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backupInfo = BackupInfo.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.progress = OperationProgress.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.cancelTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.optimizeDatabaseOperationName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreDatabaseMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sourceType: isSet(object.sourceType) ? restoreSourceTypeFromJSON(object.sourceType) : 0,
      backupInfo: isSet(object.backupInfo) ? BackupInfo.fromJSON(object.backupInfo) : undefined,
      progress: isSet(object.progress) ? OperationProgress.fromJSON(object.progress) : undefined,
      cancelTime: isSet(object.cancelTime) ? fromJsonTimestamp(object.cancelTime) : undefined,
      optimizeDatabaseOperationName: isSet(object.optimizeDatabaseOperationName)
        ? globalThis.String(object.optimizeDatabaseOperationName)
        : "",
    };
  },

  toJSON(message: RestoreDatabaseMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sourceType !== 0) {
      obj.sourceType = restoreSourceTypeToJSON(message.sourceType);
    }
    if (message.backupInfo !== undefined) {
      obj.backupInfo = BackupInfo.toJSON(message.backupInfo);
    }
    if (message.progress !== undefined) {
      obj.progress = OperationProgress.toJSON(message.progress);
    }
    if (message.cancelTime !== undefined) {
      obj.cancelTime = message.cancelTime.toISOString();
    }
    if (message.optimizeDatabaseOperationName !== "") {
      obj.optimizeDatabaseOperationName = message.optimizeDatabaseOperationName;
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreDatabaseMetadata>): RestoreDatabaseMetadata {
    return RestoreDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreDatabaseMetadata>): RestoreDatabaseMetadata {
    const message = createBaseRestoreDatabaseMetadata();
    message.name = object.name ?? "";
    message.sourceType = object.sourceType ?? 0;
    message.backupInfo = (object.backupInfo !== undefined && object.backupInfo !== null)
      ? BackupInfo.fromPartial(object.backupInfo)
      : undefined;
    message.progress = (object.progress !== undefined && object.progress !== null)
      ? OperationProgress.fromPartial(object.progress)
      : undefined;
    message.cancelTime = object.cancelTime ?? undefined;
    message.optimizeDatabaseOperationName = object.optimizeDatabaseOperationName ?? "";
    return message;
  },
};

function createBaseOptimizeRestoredDatabaseMetadata(): OptimizeRestoredDatabaseMetadata {
  return { name: "", progress: undefined };
}

export const OptimizeRestoredDatabaseMetadata: MessageFns<OptimizeRestoredDatabaseMetadata> = {
  encode(message: OptimizeRestoredDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.progress !== undefined) {
      OperationProgress.encode(message.progress, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OptimizeRestoredDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOptimizeRestoredDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.progress = OperationProgress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OptimizeRestoredDatabaseMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      progress: isSet(object.progress) ? OperationProgress.fromJSON(object.progress) : undefined,
    };
  },

  toJSON(message: OptimizeRestoredDatabaseMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.progress !== undefined) {
      obj.progress = OperationProgress.toJSON(message.progress);
    }
    return obj;
  },

  create(base?: DeepPartial<OptimizeRestoredDatabaseMetadata>): OptimizeRestoredDatabaseMetadata {
    return OptimizeRestoredDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OptimizeRestoredDatabaseMetadata>): OptimizeRestoredDatabaseMetadata {
    const message = createBaseOptimizeRestoredDatabaseMetadata();
    message.name = object.name ?? "";
    message.progress = (object.progress !== undefined && object.progress !== null)
      ? OperationProgress.fromPartial(object.progress)
      : undefined;
    return message;
  },
};

function createBaseDatabaseRole(): DatabaseRole {
  return { name: "" };
}

export const DatabaseRole: MessageFns<DatabaseRole> = {
  encode(message: DatabaseRole, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseRole {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseRole();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatabaseRole {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DatabaseRole): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DatabaseRole>): DatabaseRole {
    return DatabaseRole.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatabaseRole>): DatabaseRole {
    const message = createBaseDatabaseRole();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListDatabaseRolesRequest(): ListDatabaseRolesRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListDatabaseRolesRequest: MessageFns<ListDatabaseRolesRequest> = {
  encode(message: ListDatabaseRolesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabaseRolesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabaseRolesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabaseRolesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListDatabaseRolesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabaseRolesRequest>): ListDatabaseRolesRequest {
    return ListDatabaseRolesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabaseRolesRequest>): ListDatabaseRolesRequest {
    const message = createBaseListDatabaseRolesRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListDatabaseRolesResponse(): ListDatabaseRolesResponse {
  return { databaseRoles: [], nextPageToken: "" };
}

export const ListDatabaseRolesResponse: MessageFns<ListDatabaseRolesResponse> = {
  encode(message: ListDatabaseRolesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.databaseRoles) {
      DatabaseRole.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabaseRolesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabaseRolesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.databaseRoles.push(DatabaseRole.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabaseRolesResponse {
    return {
      databaseRoles: globalThis.Array.isArray(object?.databaseRoles)
        ? object.databaseRoles.map((e: any) => DatabaseRole.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListDatabaseRolesResponse): unknown {
    const obj: any = {};
    if (message.databaseRoles?.length) {
      obj.databaseRoles = message.databaseRoles.map((e) => DatabaseRole.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabaseRolesResponse>): ListDatabaseRolesResponse {
    return ListDatabaseRolesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabaseRolesResponse>): ListDatabaseRolesResponse {
    const message = createBaseListDatabaseRolesResponse();
    message.databaseRoles = object.databaseRoles?.map((e) => DatabaseRole.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

/**
 * Cloud Spanner Database Admin API
 *
 * The Cloud Spanner Database Admin API can be used to:
 *   * create, drop, and list databases
 *   * update the schema of pre-existing databases
 *   * create, delete, copy and list backups for a database
 *   * restore a database from an existing backup
 */
export type DatabaseAdminDefinition = typeof DatabaseAdminDefinition;
export const DatabaseAdminDefinition = {
  name: "DatabaseAdmin",
  fullName: "google.spanner.admin.database.v1.DatabaseAdmin",
  methods: {
    /** Lists Cloud Spanner databases. */
    listDatabases: {
      name: "ListDatabases",
      requestType: ListDatabasesRequest,
      requestStream: false,
      responseType: ListDatabasesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new Cloud Spanner database and starts to prepare it for serving.
     * The returned [long-running operation][google.longrunning.Operation] will
     * have a name of the format `<database_name>/operations/<operation_id>` and
     * can be used to track preparation of the database. The
     * [metadata][google.longrunning.Operation.metadata] field type is
     * [CreateDatabaseMetadata][google.spanner.admin.database.v1.CreateDatabaseMetadata].
     * The [response][google.longrunning.Operation.response] field type is
     * [Database][google.spanner.admin.database.v1.Database], if successful.
     */
    createDatabase: {
      name: "CreateDatabase",
      requestType: CreateDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              100,
              10,
              41,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              55,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              67,
              114,
              101,
              97,
              116,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              99,
              114,
              101,
              97,
              116,
              101,
              95,
              115,
              116,
              97,
              116,
              101,
              109,
              101,
              110,
              116,
            ]),
          ],
          578365826: [
            Buffer.from([
              50,
              58,
              1,
              42,
              34,
              45,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets the state of a Cloud Spanner database. */
    getDatabase: {
      name: "GetDatabase",
      requestType: GetDatabaseRequest,
      requestStream: false,
      responseType: Database,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              47,
              18,
              45,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates a Cloud Spanner database. The returned
     * [long-running operation][google.longrunning.Operation] can be used to track
     * the progress of updating the database. If the named database does not
     * exist, returns `NOT_FOUND`.
     *
     * While the operation is pending:
     *
     *   * The database's
     *     [reconciling][google.spanner.admin.database.v1.Database.reconciling]
     *     field is set to true.
     *   * Cancelling the operation is best-effort. If the cancellation succeeds,
     *     the operation metadata's
     *     [cancel_time][google.spanner.admin.database.v1.UpdateDatabaseMetadata.cancel_time]
     *     is set, the updates are reverted, and the operation terminates with a
     *     `CANCELLED` status.
     *   * New UpdateDatabase requests will return a `FAILED_PRECONDITION` error
     *     until the pending operation is done (returns successfully or with
     *     error).
     *   * Reading the database via the API continues to give the pre-request
     *     values.
     *
     * Upon completion of the returned operation:
     *
     *   * The new values are in effect and readable via the API.
     *   * The database's
     *     [reconciling][google.spanner.admin.database.v1.Database.reconciling]
     *     field becomes false.
     *
     * The returned [long-running operation][google.longrunning.Operation] will
     * have a name of the format
     * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation_id>`
     * and can be used to track the database modification. The
     * [metadata][google.longrunning.Operation.metadata] field type is
     * [UpdateDatabaseMetadata][google.spanner.admin.database.v1.UpdateDatabaseMetadata].
     * The [response][google.longrunning.Operation.response] field type is
     * [Database][google.spanner.admin.database.v1.Database], if successful.
     */
    updateDatabase: {
      name: "UpdateDatabase",
      requestType: UpdateDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              34,
              10,
              8,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              22,
              85,
              112,
              100,
              97,
              116,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              20,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              66,
              58,
              8,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              50,
              54,
              47,
              118,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates the schema of a Cloud Spanner database by
     * creating/altering/dropping tables, columns, indexes, etc. The returned
     * [long-running operation][google.longrunning.Operation] will have a name of
     * the format `<database_name>/operations/<operation_id>` and can be used to
     * track execution of the schema change(s). The
     * [metadata][google.longrunning.Operation.metadata] field type is
     * [UpdateDatabaseDdlMetadata][google.spanner.admin.database.v1.UpdateDatabaseDdlMetadata].
     * The operation has no response.
     */
    updateDatabaseDdl: {
      name: "UpdateDatabaseDdl",
      requestType: UpdateDatabaseDdlRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              83,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              58,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              85,
              112,
              100,
              97,
              116,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              68,
              100,
              108,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([19, 100, 97, 116, 97, 98, 97, 115, 101, 44, 115, 116, 97, 116, 101, 109, 101, 110, 116, 115]),
          ],
          578365826: [
            Buffer.from([
              58,
              58,
              1,
              42,
              50,
              53,
              47,
              118,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              100,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Drops (aka deletes) a Cloud Spanner database.
     * Completed backups for the database will be retained according to their
     * `expire_time`.
     * Note: Cloud Spanner might continue to accept requests for a few seconds
     * after the database has been deleted.
     */
    dropDatabase: {
      name: "DropDatabase",
      requestType: DropDatabaseRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 97, 116, 97, 98, 97, 115, 101])],
          578365826: [
            Buffer.from([
              51,
              42,
              49,
              47,
              118,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Returns the schema of a Cloud Spanner database as a list of formatted
     * DDL statements. This method does not show pending schema updates, those may
     * be queried using the [Operations][google.longrunning.Operations] API.
     */
    getDatabaseDdl: {
      name: "GetDatabaseDdl",
      requestType: GetDatabaseDdlRequest,
      requestStream: false,
      responseType: GetDatabaseDdlResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 100, 97, 116, 97, 98, 97, 115, 101])],
          578365826: [
            Buffer.from([
              55,
              18,
              53,
              47,
              118,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              100,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Sets the access control policy on a database or backup resource.
     * Replaces any existing policy.
     *
     * Authorization requires `spanner.databases.setIamPolicy`
     * permission on [resource][google.iam.v1.SetIamPolicyRequest.resource].
     * For backups, authorization requires `spanner.backups.setIamPolicy`
     * permission on [resource][google.iam.v1.SetIamPolicyRequest.resource].
     */
    setIamPolicy: {
      name: "SetIamPolicy",
      requestType: SetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 114, 101, 115, 111, 117, 114, 99, 101, 44, 112, 111, 108, 105, 99, 121])],
          578365826: [
            Buffer.from([
              221,
              1,
              58,
              1,
              42,
              90,
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              90,
              85,
              58,
              1,
              42,
              34,
              80,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the access control policy for a database or backup resource.
     * Returns an empty policy if a database or backup exists but does not have a
     * policy set.
     *
     * Authorization requires `spanner.databases.getIamPolicy` permission on
     * [resource][google.iam.v1.GetIamPolicyRequest.resource].
     * For backups, authorization requires `spanner.backups.getIamPolicy`
     * permission on [resource][google.iam.v1.GetIamPolicyRequest.resource].
     */
    getIamPolicy: {
      name: "GetIamPolicy",
      requestType: GetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 114, 101, 115, 111, 117, 114, 99, 101])],
          578365826: [
            Buffer.from([
              221,
              1,
              58,
              1,
              42,
              90,
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              90,
              85,
              58,
              1,
              42,
              34,
              80,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Returns permissions that the caller has on the specified database or backup
     * resource.
     *
     * Attempting this RPC on a non-existent Cloud Spanner database will
     * result in a NOT_FOUND error if the user has
     * `spanner.databases.list` permission on the containing Cloud
     * Spanner instance. Otherwise returns an empty set of permissions.
     * Calling this method on a backup that does not exist will
     * result in a NOT_FOUND error if the user has
     * `spanner.backups.list` permission on the containing instance.
     */
    testIamPermissions: {
      name: "TestIamPermissions",
      requestType: TestIamPermissionsRequest,
      requestStream: false,
      responseType: TestIamPermissionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              44,
              112,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              202,
              2,
              58,
              1,
              42,
              90,
              71,
              58,
              1,
              42,
              34,
              66,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
              90,
              91,
              58,
              1,
              42,
              34,
              86,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
              90,
              89,
              58,
              1,
              42,
              34,
              84,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              82,
              111,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
              34,
              68,
              47,
              118,
              49,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Starts creating a new Cloud Spanner Backup.
     * The returned backup [long-running operation][google.longrunning.Operation]
     * will have a name of the format
     * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation_id>`
     * and can be used to track creation of the backup. The
     * [metadata][google.longrunning.Operation.metadata] field type is
     * [CreateBackupMetadata][google.spanner.admin.database.v1.CreateBackupMetadata].
     * The [response][google.longrunning.Operation.response] field type is
     * [Backup][google.spanner.admin.database.v1.Backup], if successful.
     * Cancelling the returned operation will stop the creation and delete the
     * backup. There can be only one pending backup creation per database. Backup
     * creation of different databases can run concurrently.
     */
    createBackup: {
      name: "CreateBackup",
      requestType: CreateBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              96,
              10,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              66,
              97,
              99,
              107,
              117,
              112,
              18,
              53,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              67,
              114,
              101,
              97,
              116,
              101,
              66,
              97,
              99,
              107,
              117,
              112,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              53,
              58,
              6,
              98,
              97,
              99,
              107,
              117,
              112,
              34,
              43,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Starts copying a Cloud Spanner Backup.
     * The returned backup [long-running operation][google.longrunning.Operation]
     * will have a name of the format
     * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation_id>`
     * and can be used to track copying of the backup. The operation is associated
     * with the destination backup.
     * The [metadata][google.longrunning.Operation.metadata] field type is
     * [CopyBackupMetadata][google.spanner.admin.database.v1.CopyBackupMetadata].
     * The [response][google.longrunning.Operation.response] field type is
     * [Backup][google.spanner.admin.database.v1.Backup], if successful.
     * Cancelling the returned operation will stop the copying and delete the
     * destination backup. Concurrent CopyBackup requests can run on the same
     * source backup.
     */
    copyBackup: {
      name: "CopyBackup",
      requestType: CopyBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              94,
              10,
              39,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              66,
              97,
              99,
              107,
              117,
              112,
              18,
              51,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              67,
              111,
              112,
              121,
              66,
              97,
              99,
              107,
              117,
              112,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              42,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              105,
              100,
              44,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              98,
              97,
              99,
              107,
              117,
              112,
              44,
              101,
              120,
              112,
              105,
              114,
              101,
              95,
              116,
              105,
              109,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              53,
              58,
              1,
              42,
              34,
              48,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              58,
              99,
              111,
              112,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Gets metadata on a pending or completed
     * [Backup][google.spanner.admin.database.v1.Backup].
     */
    getBackup: {
      name: "GetBackup",
      requestType: GetBackupRequest,
      requestStream: false,
      responseType: Backup,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              45,
              18,
              43,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates a pending or completed
     * [Backup][google.spanner.admin.database.v1.Backup].
     */
    updateBackup: {
      name: "UpdateBackup",
      requestType: UpdateBackupRequest,
      requestStream: false,
      responseType: Backup,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([18, 98, 97, 99, 107, 117, 112, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365826: [
            Buffer.from([
              60,
              58,
              6,
              98,
              97,
              99,
              107,
              117,
              112,
              50,
              50,
              47,
              118,
              49,
              47,
              123,
              98,
              97,
              99,
              107,
              117,
              112,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a pending or completed
     * [Backup][google.spanner.admin.database.v1.Backup].
     */
    deleteBackup: {
      name: "DeleteBackup",
      requestType: DeleteBackupRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              45,
              42,
              43,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists completed and pending backups.
     * Backups returned are ordered by `create_time` in descending order,
     * starting from the most recent `create_time`.
     */
    listBackups: {
      name: "ListBackups",
      requestType: ListBackupsRequest,
      requestStream: false,
      responseType: ListBackupsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              45,
              18,
              43,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Create a new database by restoring from a completed backup. The new
     * database must be in the same project and in an instance with the same
     * instance configuration as the instance containing
     * the backup. The returned database [long-running
     * operation][google.longrunning.Operation] has a name of the format
     * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation_id>`,
     * and can be used to track the progress of the operation, and to cancel it.
     * The [metadata][google.longrunning.Operation.metadata] field type is
     * [RestoreDatabaseMetadata][google.spanner.admin.database.v1.RestoreDatabaseMetadata].
     * The [response][google.longrunning.Operation.response] type
     * is [Database][google.spanner.admin.database.v1.Database], if
     * successful. Cancelling the returned operation will stop the restore and
     * delete the database.
     * There can be only one database being restored into an instance at a time.
     * Once the restore operation completes, a new restore operation can be
     * initiated, without waiting for the optimize operation associated with the
     * first restore to complete.
     */
    restoreDatabase: {
      name: "RestoreDatabase",
      requestType: RestoreDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              101,
              10,
              41,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              56,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              115,
              112,
              97,
              110,
              110,
              101,
              114,
              46,
              97,
              100,
              109,
              105,
              110,
              46,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              118,
              49,
              46,
              82,
              101,
              115,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              25,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
            ]),
          ],
          578365826: [
            Buffer.from([
              58,
              58,
              1,
              42,
              34,
              53,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              58,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Lists database [longrunning-operations][google.longrunning.Operation].
     * A database operation has a name of the form
     * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation>`.
     * The long-running operation
     * [metadata][google.longrunning.Operation.metadata] field type
     * `metadata.type_url` describes the type of the metadata. Operations returned
     * include those that have completed/failed/canceled within the last 7 days,
     * and pending operations.
     */
    listDatabaseOperations: {
      name: "ListDatabaseOperations",
      requestType: ListDatabaseOperationsRequest,
      requestStream: false,
      responseType: ListDatabaseOperationsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Lists the backup [long-running operations][google.longrunning.Operation] in
     * the given instance. A backup operation has a name of the form
     * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation>`.
     * The long-running operation
     * [metadata][google.longrunning.Operation.metadata] field type
     * `metadata.type_url` describes the type of the metadata. Operations returned
     * include those that have completed/failed/canceled within the last 7 days,
     * and pending operations. Operations returned are ordered by
     * `operation.metadata.value.progress.start_time` in descending order starting
     * from the most recently started operation.
     */
    listBackupOperations: {
      name: "ListBackupOperations",
      requestType: ListBackupOperationsRequest,
      requestStream: false,
      responseType: ListBackupOperationsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              54,
              18,
              52,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists Cloud Spanner database roles. */
    listDatabaseRoles: {
      name: "ListDatabaseRoles",
      requestType: ListDatabaseRolesRequest,
      requestStream: false,
      responseType: ListDatabaseRolesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              63,
              18,
              61,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              82,
              111,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Creates a new backup schedule. */
    createBackupSchedule: {
      name: "CreateBackupSchedule",
      requestType: CreateBackupScheduleRequest,
      requestStream: false,
      responseType: BackupSchedule,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              41,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              82,
              58,
              15,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              34,
              63,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets backup schedule for the input schedule name. */
    getBackupSchedule: {
      name: "GetBackupSchedule",
      requestType: GetBackupScheduleRequest,
      requestStream: false,
      responseType: BackupSchedule,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              65,
              18,
              63,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates a backup schedule. */
    updateBackupSchedule: {
      name: "UpdateBackupSchedule",
      requestType: UpdateBackupScheduleRequest,
      requestStream: false,
      responseType: BackupSchedule,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              27,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              98,
              58,
              15,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              50,
              79,
              47,
              118,
              49,
              47,
              123,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a backup schedule. */
    deleteBackupSchedule: {
      name: "DeleteBackupSchedule",
      requestType: DeleteBackupScheduleRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              65,
              42,
              63,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists all the backup schedules for the database. */
    listBackupSchedules: {
      name: "ListBackupSchedules",
      requestType: ListBackupSchedulesRequest,
      requestStream: false,
      responseType: ListBackupSchedulesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              65,
              18,
              63,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface DatabaseAdminServiceImplementation<CallContextExt = {}> {
  /** Lists Cloud Spanner databases. */
  listDatabases(
    request: ListDatabasesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDatabasesResponse>>;
  /**
   * Creates a new Cloud Spanner database and starts to prepare it for serving.
   * The returned [long-running operation][google.longrunning.Operation] will
   * have a name of the format `<database_name>/operations/<operation_id>` and
   * can be used to track preparation of the database. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [CreateDatabaseMetadata][google.spanner.admin.database.v1.CreateDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Database][google.spanner.admin.database.v1.Database], if successful.
   */
  createDatabase(
    request: CreateDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets the state of a Cloud Spanner database. */
  getDatabase(request: GetDatabaseRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Database>>;
  /**
   * Updates a Cloud Spanner database. The returned
   * [long-running operation][google.longrunning.Operation] can be used to track
   * the progress of updating the database. If the named database does not
   * exist, returns `NOT_FOUND`.
   *
   * While the operation is pending:
   *
   *   * The database's
   *     [reconciling][google.spanner.admin.database.v1.Database.reconciling]
   *     field is set to true.
   *   * Cancelling the operation is best-effort. If the cancellation succeeds,
   *     the operation metadata's
   *     [cancel_time][google.spanner.admin.database.v1.UpdateDatabaseMetadata.cancel_time]
   *     is set, the updates are reverted, and the operation terminates with a
   *     `CANCELLED` status.
   *   * New UpdateDatabase requests will return a `FAILED_PRECONDITION` error
   *     until the pending operation is done (returns successfully or with
   *     error).
   *   * Reading the database via the API continues to give the pre-request
   *     values.
   *
   * Upon completion of the returned operation:
   *
   *   * The new values are in effect and readable via the API.
   *   * The database's
   *     [reconciling][google.spanner.admin.database.v1.Database.reconciling]
   *     field becomes false.
   *
   * The returned [long-running operation][google.longrunning.Operation] will
   * have a name of the format
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation_id>`
   * and can be used to track the database modification. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [UpdateDatabaseMetadata][google.spanner.admin.database.v1.UpdateDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Database][google.spanner.admin.database.v1.Database], if successful.
   */
  updateDatabase(
    request: UpdateDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Updates the schema of a Cloud Spanner database by
   * creating/altering/dropping tables, columns, indexes, etc. The returned
   * [long-running operation][google.longrunning.Operation] will have a name of
   * the format `<database_name>/operations/<operation_id>` and can be used to
   * track execution of the schema change(s). The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [UpdateDatabaseDdlMetadata][google.spanner.admin.database.v1.UpdateDatabaseDdlMetadata].
   * The operation has no response.
   */
  updateDatabaseDdl(
    request: UpdateDatabaseDdlRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Drops (aka deletes) a Cloud Spanner database.
   * Completed backups for the database will be retained according to their
   * `expire_time`.
   * Note: Cloud Spanner might continue to accept requests for a few seconds
   * after the database has been deleted.
   */
  dropDatabase(request: DropDatabaseRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Returns the schema of a Cloud Spanner database as a list of formatted
   * DDL statements. This method does not show pending schema updates, those may
   * be queried using the [Operations][google.longrunning.Operations] API.
   */
  getDatabaseDdl(
    request: GetDatabaseDdlRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GetDatabaseDdlResponse>>;
  /**
   * Sets the access control policy on a database or backup resource.
   * Replaces any existing policy.
   *
   * Authorization requires `spanner.databases.setIamPolicy`
   * permission on [resource][google.iam.v1.SetIamPolicyRequest.resource].
   * For backups, authorization requires `spanner.backups.setIamPolicy`
   * permission on [resource][google.iam.v1.SetIamPolicyRequest.resource].
   */
  setIamPolicy(request: SetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Gets the access control policy for a database or backup resource.
   * Returns an empty policy if a database or backup exists but does not have a
   * policy set.
   *
   * Authorization requires `spanner.databases.getIamPolicy` permission on
   * [resource][google.iam.v1.GetIamPolicyRequest.resource].
   * For backups, authorization requires `spanner.backups.getIamPolicy`
   * permission on [resource][google.iam.v1.GetIamPolicyRequest.resource].
   */
  getIamPolicy(request: GetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Returns permissions that the caller has on the specified database or backup
   * resource.
   *
   * Attempting this RPC on a non-existent Cloud Spanner database will
   * result in a NOT_FOUND error if the user has
   * `spanner.databases.list` permission on the containing Cloud
   * Spanner instance. Otherwise returns an empty set of permissions.
   * Calling this method on a backup that does not exist will
   * result in a NOT_FOUND error if the user has
   * `spanner.backups.list` permission on the containing instance.
   */
  testIamPermissions(
    request: TestIamPermissionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TestIamPermissionsResponse>>;
  /**
   * Starts creating a new Cloud Spanner Backup.
   * The returned backup [long-running operation][google.longrunning.Operation]
   * will have a name of the format
   * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation_id>`
   * and can be used to track creation of the backup. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [CreateBackupMetadata][google.spanner.admin.database.v1.CreateBackupMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Backup][google.spanner.admin.database.v1.Backup], if successful.
   * Cancelling the returned operation will stop the creation and delete the
   * backup. There can be only one pending backup creation per database. Backup
   * creation of different databases can run concurrently.
   */
  createBackup(request: CreateBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Starts copying a Cloud Spanner Backup.
   * The returned backup [long-running operation][google.longrunning.Operation]
   * will have a name of the format
   * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation_id>`
   * and can be used to track copying of the backup. The operation is associated
   * with the destination backup.
   * The [metadata][google.longrunning.Operation.metadata] field type is
   * [CopyBackupMetadata][google.spanner.admin.database.v1.CopyBackupMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Backup][google.spanner.admin.database.v1.Backup], if successful.
   * Cancelling the returned operation will stop the copying and delete the
   * destination backup. Concurrent CopyBackup requests can run on the same
   * source backup.
   */
  copyBackup(request: CopyBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Gets metadata on a pending or completed
   * [Backup][google.spanner.admin.database.v1.Backup].
   */
  getBackup(request: GetBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Backup>>;
  /**
   * Updates a pending or completed
   * [Backup][google.spanner.admin.database.v1.Backup].
   */
  updateBackup(request: UpdateBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Backup>>;
  /**
   * Deletes a pending or completed
   * [Backup][google.spanner.admin.database.v1.Backup].
   */
  deleteBackup(request: DeleteBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Lists completed and pending backups.
   * Backups returned are ordered by `create_time` in descending order,
   * starting from the most recent `create_time`.
   */
  listBackups(
    request: ListBackupsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupsResponse>>;
  /**
   * Create a new database by restoring from a completed backup. The new
   * database must be in the same project and in an instance with the same
   * instance configuration as the instance containing
   * the backup. The returned database [long-running
   * operation][google.longrunning.Operation] has a name of the format
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation_id>`,
   * and can be used to track the progress of the operation, and to cancel it.
   * The [metadata][google.longrunning.Operation.metadata] field type is
   * [RestoreDatabaseMetadata][google.spanner.admin.database.v1.RestoreDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] type
   * is [Database][google.spanner.admin.database.v1.Database], if
   * successful. Cancelling the returned operation will stop the restore and
   * delete the database.
   * There can be only one database being restored into an instance at a time.
   * Once the restore operation completes, a new restore operation can be
   * initiated, without waiting for the optimize operation associated with the
   * first restore to complete.
   */
  restoreDatabase(
    request: RestoreDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Lists database [longrunning-operations][google.longrunning.Operation].
   * A database operation has a name of the form
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation>`.
   * The long-running operation
   * [metadata][google.longrunning.Operation.metadata] field type
   * `metadata.type_url` describes the type of the metadata. Operations returned
   * include those that have completed/failed/canceled within the last 7 days,
   * and pending operations.
   */
  listDatabaseOperations(
    request: ListDatabaseOperationsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDatabaseOperationsResponse>>;
  /**
   * Lists the backup [long-running operations][google.longrunning.Operation] in
   * the given instance. A backup operation has a name of the form
   * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation>`.
   * The long-running operation
   * [metadata][google.longrunning.Operation.metadata] field type
   * `metadata.type_url` describes the type of the metadata. Operations returned
   * include those that have completed/failed/canceled within the last 7 days,
   * and pending operations. Operations returned are ordered by
   * `operation.metadata.value.progress.start_time` in descending order starting
   * from the most recently started operation.
   */
  listBackupOperations(
    request: ListBackupOperationsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupOperationsResponse>>;
  /** Lists Cloud Spanner database roles. */
  listDatabaseRoles(
    request: ListDatabaseRolesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDatabaseRolesResponse>>;
  /** Creates a new backup schedule. */
  createBackupSchedule(
    request: CreateBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BackupSchedule>>;
  /** Gets backup schedule for the input schedule name. */
  getBackupSchedule(
    request: GetBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BackupSchedule>>;
  /** Updates a backup schedule. */
  updateBackupSchedule(
    request: UpdateBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BackupSchedule>>;
  /** Deletes a backup schedule. */
  deleteBackupSchedule(
    request: DeleteBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Lists all the backup schedules for the database. */
  listBackupSchedules(
    request: ListBackupSchedulesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupSchedulesResponse>>;
}

export interface DatabaseAdminClient<CallOptionsExt = {}> {
  /** Lists Cloud Spanner databases. */
  listDatabases(
    request: DeepPartial<ListDatabasesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDatabasesResponse>;
  /**
   * Creates a new Cloud Spanner database and starts to prepare it for serving.
   * The returned [long-running operation][google.longrunning.Operation] will
   * have a name of the format `<database_name>/operations/<operation_id>` and
   * can be used to track preparation of the database. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [CreateDatabaseMetadata][google.spanner.admin.database.v1.CreateDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Database][google.spanner.admin.database.v1.Database], if successful.
   */
  createDatabase(
    request: DeepPartial<CreateDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets the state of a Cloud Spanner database. */
  getDatabase(request: DeepPartial<GetDatabaseRequest>, options?: CallOptions & CallOptionsExt): Promise<Database>;
  /**
   * Updates a Cloud Spanner database. The returned
   * [long-running operation][google.longrunning.Operation] can be used to track
   * the progress of updating the database. If the named database does not
   * exist, returns `NOT_FOUND`.
   *
   * While the operation is pending:
   *
   *   * The database's
   *     [reconciling][google.spanner.admin.database.v1.Database.reconciling]
   *     field is set to true.
   *   * Cancelling the operation is best-effort. If the cancellation succeeds,
   *     the operation metadata's
   *     [cancel_time][google.spanner.admin.database.v1.UpdateDatabaseMetadata.cancel_time]
   *     is set, the updates are reverted, and the operation terminates with a
   *     `CANCELLED` status.
   *   * New UpdateDatabase requests will return a `FAILED_PRECONDITION` error
   *     until the pending operation is done (returns successfully or with
   *     error).
   *   * Reading the database via the API continues to give the pre-request
   *     values.
   *
   * Upon completion of the returned operation:
   *
   *   * The new values are in effect and readable via the API.
   *   * The database's
   *     [reconciling][google.spanner.admin.database.v1.Database.reconciling]
   *     field becomes false.
   *
   * The returned [long-running operation][google.longrunning.Operation] will
   * have a name of the format
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation_id>`
   * and can be used to track the database modification. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [UpdateDatabaseMetadata][google.spanner.admin.database.v1.UpdateDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Database][google.spanner.admin.database.v1.Database], if successful.
   */
  updateDatabase(
    request: DeepPartial<UpdateDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Updates the schema of a Cloud Spanner database by
   * creating/altering/dropping tables, columns, indexes, etc. The returned
   * [long-running operation][google.longrunning.Operation] will have a name of
   * the format `<database_name>/operations/<operation_id>` and can be used to
   * track execution of the schema change(s). The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [UpdateDatabaseDdlMetadata][google.spanner.admin.database.v1.UpdateDatabaseDdlMetadata].
   * The operation has no response.
   */
  updateDatabaseDdl(
    request: DeepPartial<UpdateDatabaseDdlRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Drops (aka deletes) a Cloud Spanner database.
   * Completed backups for the database will be retained according to their
   * `expire_time`.
   * Note: Cloud Spanner might continue to accept requests for a few seconds
   * after the database has been deleted.
   */
  dropDatabase(request: DeepPartial<DropDatabaseRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Returns the schema of a Cloud Spanner database as a list of formatted
   * DDL statements. This method does not show pending schema updates, those may
   * be queried using the [Operations][google.longrunning.Operations] API.
   */
  getDatabaseDdl(
    request: DeepPartial<GetDatabaseDdlRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GetDatabaseDdlResponse>;
  /**
   * Sets the access control policy on a database or backup resource.
   * Replaces any existing policy.
   *
   * Authorization requires `spanner.databases.setIamPolicy`
   * permission on [resource][google.iam.v1.SetIamPolicyRequest.resource].
   * For backups, authorization requires `spanner.backups.setIamPolicy`
   * permission on [resource][google.iam.v1.SetIamPolicyRequest.resource].
   */
  setIamPolicy(request: DeepPartial<SetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Gets the access control policy for a database or backup resource.
   * Returns an empty policy if a database or backup exists but does not have a
   * policy set.
   *
   * Authorization requires `spanner.databases.getIamPolicy` permission on
   * [resource][google.iam.v1.GetIamPolicyRequest.resource].
   * For backups, authorization requires `spanner.backups.getIamPolicy`
   * permission on [resource][google.iam.v1.GetIamPolicyRequest.resource].
   */
  getIamPolicy(request: DeepPartial<GetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Returns permissions that the caller has on the specified database or backup
   * resource.
   *
   * Attempting this RPC on a non-existent Cloud Spanner database will
   * result in a NOT_FOUND error if the user has
   * `spanner.databases.list` permission on the containing Cloud
   * Spanner instance. Otherwise returns an empty set of permissions.
   * Calling this method on a backup that does not exist will
   * result in a NOT_FOUND error if the user has
   * `spanner.backups.list` permission on the containing instance.
   */
  testIamPermissions(
    request: DeepPartial<TestIamPermissionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TestIamPermissionsResponse>;
  /**
   * Starts creating a new Cloud Spanner Backup.
   * The returned backup [long-running operation][google.longrunning.Operation]
   * will have a name of the format
   * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation_id>`
   * and can be used to track creation of the backup. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [CreateBackupMetadata][google.spanner.admin.database.v1.CreateBackupMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Backup][google.spanner.admin.database.v1.Backup], if successful.
   * Cancelling the returned operation will stop the creation and delete the
   * backup. There can be only one pending backup creation per database. Backup
   * creation of different databases can run concurrently.
   */
  createBackup(request: DeepPartial<CreateBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Starts copying a Cloud Spanner Backup.
   * The returned backup [long-running operation][google.longrunning.Operation]
   * will have a name of the format
   * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation_id>`
   * and can be used to track copying of the backup. The operation is associated
   * with the destination backup.
   * The [metadata][google.longrunning.Operation.metadata] field type is
   * [CopyBackupMetadata][google.spanner.admin.database.v1.CopyBackupMetadata].
   * The [response][google.longrunning.Operation.response] field type is
   * [Backup][google.spanner.admin.database.v1.Backup], if successful.
   * Cancelling the returned operation will stop the copying and delete the
   * destination backup. Concurrent CopyBackup requests can run on the same
   * source backup.
   */
  copyBackup(request: DeepPartial<CopyBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Gets metadata on a pending or completed
   * [Backup][google.spanner.admin.database.v1.Backup].
   */
  getBackup(request: DeepPartial<GetBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Backup>;
  /**
   * Updates a pending or completed
   * [Backup][google.spanner.admin.database.v1.Backup].
   */
  updateBackup(request: DeepPartial<UpdateBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Backup>;
  /**
   * Deletes a pending or completed
   * [Backup][google.spanner.admin.database.v1.Backup].
   */
  deleteBackup(request: DeepPartial<DeleteBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Lists completed and pending backups.
   * Backups returned are ordered by `create_time` in descending order,
   * starting from the most recent `create_time`.
   */
  listBackups(
    request: DeepPartial<ListBackupsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupsResponse>;
  /**
   * Create a new database by restoring from a completed backup. The new
   * database must be in the same project and in an instance with the same
   * instance configuration as the instance containing
   * the backup. The returned database [long-running
   * operation][google.longrunning.Operation] has a name of the format
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation_id>`,
   * and can be used to track the progress of the operation, and to cancel it.
   * The [metadata][google.longrunning.Operation.metadata] field type is
   * [RestoreDatabaseMetadata][google.spanner.admin.database.v1.RestoreDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] type
   * is [Database][google.spanner.admin.database.v1.Database], if
   * successful. Cancelling the returned operation will stop the restore and
   * delete the database.
   * There can be only one database being restored into an instance at a time.
   * Once the restore operation completes, a new restore operation can be
   * initiated, without waiting for the optimize operation associated with the
   * first restore to complete.
   */
  restoreDatabase(
    request: DeepPartial<RestoreDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Lists database [longrunning-operations][google.longrunning.Operation].
   * A database operation has a name of the form
   * `projects/<project>/instances/<instance>/databases/<database>/operations/<operation>`.
   * The long-running operation
   * [metadata][google.longrunning.Operation.metadata] field type
   * `metadata.type_url` describes the type of the metadata. Operations returned
   * include those that have completed/failed/canceled within the last 7 days,
   * and pending operations.
   */
  listDatabaseOperations(
    request: DeepPartial<ListDatabaseOperationsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDatabaseOperationsResponse>;
  /**
   * Lists the backup [long-running operations][google.longrunning.Operation] in
   * the given instance. A backup operation has a name of the form
   * `projects/<project>/instances/<instance>/backups/<backup>/operations/<operation>`.
   * The long-running operation
   * [metadata][google.longrunning.Operation.metadata] field type
   * `metadata.type_url` describes the type of the metadata. Operations returned
   * include those that have completed/failed/canceled within the last 7 days,
   * and pending operations. Operations returned are ordered by
   * `operation.metadata.value.progress.start_time` in descending order starting
   * from the most recently started operation.
   */
  listBackupOperations(
    request: DeepPartial<ListBackupOperationsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupOperationsResponse>;
  /** Lists Cloud Spanner database roles. */
  listDatabaseRoles(
    request: DeepPartial<ListDatabaseRolesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDatabaseRolesResponse>;
  /** Creates a new backup schedule. */
  createBackupSchedule(
    request: DeepPartial<CreateBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BackupSchedule>;
  /** Gets backup schedule for the input schedule name. */
  getBackupSchedule(
    request: DeepPartial<GetBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BackupSchedule>;
  /** Updates a backup schedule. */
  updateBackupSchedule(
    request: DeepPartial<UpdateBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BackupSchedule>;
  /** Deletes a backup schedule. */
  deleteBackupSchedule(
    request: DeepPartial<DeleteBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Lists all the backup schedules for the database. */
  listBackupSchedules(
    request: DeepPartial<ListBackupSchedulesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupSchedulesResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
