// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/bigtable/v2/bigtable.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Duration } from "../../protobuf/duration.js";
import { Timestamp } from "../../protobuf/timestamp.js";
import { BytesValue, StringValue } from "../../protobuf/wrappers.js";
import { Status } from "../../rpc/status.js";
import {
  Mutation,
  PartialResultSet,
  ProtoFormat,
  ReadModifyWriteRule,
  ResultSetMetadata,
  Row,
  RowFilter,
  RowSet,
  StreamContinuationToken,
  StreamContinuationTokens,
  StreamPartition,
  Value,
} from "./data.js";
import { RequestStats } from "./request_stats.js";

export const protobufPackage = "google.bigtable.v2";

/** Request message for Bigtable.ReadRows. */
export interface ReadRowsRequest {
  /**
   * Optional. The unique name of the table from which to read.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   */
  tableName: string;
  /**
   * Optional. The unique name of the AuthorizedView from which to read.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>`.
   */
  authorizedViewName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
  /**
   * The row keys and/or ranges to read sequentially. If not specified, reads
   * from all rows.
   */
  rows:
    | RowSet
    | undefined;
  /**
   * The filter to apply to the contents of the specified row(s). If unset,
   * reads the entirety of each row.
   */
  filter:
    | RowFilter
    | undefined;
  /**
   * The read will stop after committing to N rows' worth of results. The
   * default (zero) is to return all results.
   */
  rowsLimit: Long;
  /** The view into RequestStats, as described above. */
  requestStatsView: ReadRowsRequest_RequestStatsView;
  /**
   * Experimental API - Please note that this API is currently experimental
   * and can change in the future.
   *
   * Return rows in lexiographical descending order of the row keys. The row
   * contents will not be affected by this flag.
   *
   * Example result set:
   *
   *     [
   *       {key: "k2", "f:col1": "v1", "f:col2": "v1"},
   *       {key: "k1", "f:col1": "v2", "f:col2": "v2"}
   *     ]
   */
  reversed: boolean;
}

/**
 * The desired view into RequestStats that should be returned in the response.
 *
 * See also: RequestStats message.
 */
export enum ReadRowsRequest_RequestStatsView {
  /** REQUEST_STATS_VIEW_UNSPECIFIED - The default / unset value. The API will default to the NONE option below. */
  REQUEST_STATS_VIEW_UNSPECIFIED = 0,
  /**
   * REQUEST_STATS_NONE - Do not include any RequestStats in the response. This will leave the
   * RequestStats embedded message unset in the response.
   */
  REQUEST_STATS_NONE = 1,
  /**
   * REQUEST_STATS_FULL - Include the full set of available RequestStats in the response,
   * applicable to this read.
   */
  REQUEST_STATS_FULL = 2,
  UNRECOGNIZED = -1,
}

export function readRowsRequest_RequestStatsViewFromJSON(object: any): ReadRowsRequest_RequestStatsView {
  switch (object) {
    case 0:
    case "REQUEST_STATS_VIEW_UNSPECIFIED":
      return ReadRowsRequest_RequestStatsView.REQUEST_STATS_VIEW_UNSPECIFIED;
    case 1:
    case "REQUEST_STATS_NONE":
      return ReadRowsRequest_RequestStatsView.REQUEST_STATS_NONE;
    case 2:
    case "REQUEST_STATS_FULL":
      return ReadRowsRequest_RequestStatsView.REQUEST_STATS_FULL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ReadRowsRequest_RequestStatsView.UNRECOGNIZED;
  }
}

export function readRowsRequest_RequestStatsViewToJSON(object: ReadRowsRequest_RequestStatsView): string {
  switch (object) {
    case ReadRowsRequest_RequestStatsView.REQUEST_STATS_VIEW_UNSPECIFIED:
      return "REQUEST_STATS_VIEW_UNSPECIFIED";
    case ReadRowsRequest_RequestStatsView.REQUEST_STATS_NONE:
      return "REQUEST_STATS_NONE";
    case ReadRowsRequest_RequestStatsView.REQUEST_STATS_FULL:
      return "REQUEST_STATS_FULL";
    case ReadRowsRequest_RequestStatsView.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Response message for Bigtable.ReadRows. */
export interface ReadRowsResponse {
  /** A collection of a row's contents as part of the read request. */
  chunks: ReadRowsResponse_CellChunk[];
  /**
   * Optionally the server might return the row key of the last row it
   * has scanned.  The client can use this to construct a more
   * efficient retry request if needed: any row keys or portions of
   * ranges less than this row key can be dropped from the request.
   * This is primarily useful for cases where the server has read a
   * lot of data that was filtered out since the last committed row
   * key, allowing the client to skip that work on a retry.
   */
  lastScannedRowKey: Buffer;
  /**
   * If requested, provide enhanced query performance statistics. The semantics
   * dictate:
   *   * request_stats is empty on every (streamed) response, except
   *   * request_stats has non-empty information after all chunks have been
   *     streamed, where the ReadRowsResponse message only contains
   *     request_stats.
   *       * For example, if a read request would have returned an empty
   *         response instead a single ReadRowsResponse is streamed with empty
   *         chunks and request_stats filled.
   *
   * Visually, response messages will stream as follows:
   *    ... -> {chunks: [...]} -> {chunks: [], request_stats: {...}}
   *   \______________________/  \________________________________/
   *       Primary response         Trailer of RequestStats info
   *
   * Or if the read did not return any values:
   *   {chunks: [], request_stats: {...}}
   *   \________________________________/
   *      Trailer of RequestStats info
   */
  requestStats: RequestStats | undefined;
}

/**
 * Specifies a piece of a row's contents returned as part of the read
 * response stream.
 */
export interface ReadRowsResponse_CellChunk {
  /**
   * The row key for this chunk of data.  If the row key is empty,
   * this CellChunk is a continuation of the same row as the previous
   * CellChunk in the response stream, even if that CellChunk was in a
   * previous ReadRowsResponse message.
   */
  rowKey: Buffer;
  /**
   * The column family name for this chunk of data.  If this message
   * is not present this CellChunk is a continuation of the same column
   * family as the previous CellChunk.  The empty string can occur as a
   * column family name in a response so clients must check
   * explicitly for the presence of this message, not just for
   * `family_name.value` being non-empty.
   */
  familyName:
    | string
    | undefined;
  /**
   * The column qualifier for this chunk of data.  If this message
   * is not present, this CellChunk is a continuation of the same column
   * as the previous CellChunk.  Column qualifiers may be empty so
   * clients must check for the presence of this message, not just
   * for `qualifier.value` being non-empty.
   */
  qualifier:
    | Buffer
    | undefined;
  /**
   * The cell's stored timestamp, which also uniquely identifies it
   * within its column.  Values are always expressed in
   * microseconds, but individual tables may set a coarser
   * granularity to further restrict the allowed values. For
   * example, a table which specifies millisecond granularity will
   * only allow values of `timestamp_micros` which are multiples of
   * 1000.  Timestamps are only set in the first CellChunk per cell
   * (for cells split into multiple chunks).
   */
  timestampMicros: Long;
  /**
   * Labels applied to the cell by a
   * [RowFilter][google.bigtable.v2.RowFilter].  Labels are only set
   * on the first CellChunk per cell.
   */
  labels: string[];
  /**
   * The value stored in the cell.  Cell values can be split across
   * multiple CellChunks.  In that case only the value field will be
   * set in CellChunks after the first: the timestamp and labels
   * will only be present in the first CellChunk, even if the first
   * CellChunk came in a previous ReadRowsResponse.
   */
  value: Buffer;
  /**
   * If this CellChunk is part of a chunked cell value and this is
   * not the final chunk of that cell, value_size will be set to the
   * total length of the cell value.  The client can use this size
   * to pre-allocate memory to hold the full cell value.
   */
  valueSize: number;
  /**
   * Indicates that the client should drop all previous chunks for
   * `row_key`, as it will be re-read from the beginning.
   */
  resetRow?:
    | boolean
    | undefined;
  /**
   * Indicates that the client can safely process all previous chunks for
   * `row_key`, as its data has been fully read.
   */
  commitRow?: boolean | undefined;
}

/** Request message for Bigtable.SampleRowKeys. */
export interface SampleRowKeysRequest {
  /**
   * Optional. The unique name of the table from which to sample row keys.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   */
  tableName: string;
  /**
   * Optional. The unique name of the AuthorizedView from which to sample row
   * keys.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>`.
   */
  authorizedViewName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
}

/** Response message for Bigtable.SampleRowKeys. */
export interface SampleRowKeysResponse {
  /**
   * Sorted streamed sequence of sample row keys in the table. The table might
   * have contents before the first row key in the list and after the last one,
   * but a key containing the empty string indicates "end of table" and will be
   * the last response given, if present.
   * Note that row keys in this list may not have ever been written to or read
   * from, and users should therefore not make any assumptions about the row key
   * structure that are specific to their use case.
   */
  rowKey: Buffer;
  /**
   * Approximate total storage space used by all rows in the table which precede
   * `row_key`. Buffering the contents of all rows between two subsequent
   * samples would require space roughly equal to the difference in their
   * `offset_bytes` fields.
   */
  offsetBytes: Long;
}

/** Request message for Bigtable.MutateRow. */
export interface MutateRowRequest {
  /**
   * Optional. The unique name of the table to which the mutation should be
   * applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   */
  tableName: string;
  /**
   * Optional. The unique name of the AuthorizedView to which the mutation
   * should be applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>`.
   */
  authorizedViewName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
  /** Required. The key of the row to which the mutation should be applied. */
  rowKey: Buffer;
  /**
   * Required. Changes to be atomically applied to the specified row. Entries
   * are applied in order, meaning that earlier mutations can be masked by later
   * ones. Must contain at least one entry and at most 100000.
   */
  mutations: Mutation[];
}

/** Response message for Bigtable.MutateRow. */
export interface MutateRowResponse {
}

/** Request message for BigtableService.MutateRows. */
export interface MutateRowsRequest {
  /**
   * Optional. The unique name of the table to which the mutations should be
   * applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   */
  tableName: string;
  /**
   * Optional. The unique name of the AuthorizedView to which the mutations
   * should be applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>`.
   */
  authorizedViewName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
  /**
   * Required. The row keys and corresponding mutations to be applied in bulk.
   * Each entry is applied as an atomic mutation, but the entries may be
   * applied in arbitrary order (even between entries for the same row).
   * At least one entry must be specified, and in total the entries can
   * contain at most 100000 mutations.
   */
  entries: MutateRowsRequest_Entry[];
}

/** A mutation for a given row. */
export interface MutateRowsRequest_Entry {
  /** The key of the row to which the `mutations` should be applied. */
  rowKey: Buffer;
  /**
   * Required. Changes to be atomically applied to the specified row.
   * Mutations are applied in order, meaning that earlier mutations can be
   * masked by later ones. You must specify at least one mutation.
   */
  mutations: Mutation[];
}

/** Response message for BigtableService.MutateRows. */
export interface MutateRowsResponse {
  /** One or more results for Entries from the batch request. */
  entries: MutateRowsResponse_Entry[];
  /**
   * Information about how client should limit the rate (QPS). Primirily used by
   * supported official Cloud Bigtable clients. If unset, the rate limit info is
   * not provided by the server.
   */
  rateLimitInfo?: RateLimitInfo | undefined;
}

/** The result of applying a passed mutation in the original request. */
export interface MutateRowsResponse_Entry {
  /**
   * The index into the original request's `entries` list of the Entry
   * for which a result is being reported.
   */
  index: Long;
  /**
   * The result of the request Entry identified by `index`.
   * Depending on how requests are batched during execution, it is possible
   * for one Entry to fail due to an error with another Entry. In the event
   * that this occurs, the same error will be reported for both entries.
   */
  status: Status | undefined;
}

/** Information about how client should adjust the load to Bigtable. */
export interface RateLimitInfo {
  /**
   * Time that clients should wait before adjusting the target rate again.
   * If clients adjust rate too frequently, the impact of the previous
   * adjustment may not have been taken into account and may
   * over-throttle or under-throttle. If clients adjust rate too slowly, they
   * will not be responsive to load changes on server side, and may
   * over-throttle or under-throttle.
   */
  period:
    | Duration
    | undefined;
  /**
   * If it has been at least one `period` since the last load adjustment, the
   * client should multiply the current load by this value to get the new target
   * load. For example, if the current load is 100 and `factor` is 0.8, the new
   * target load should be 80. After adjusting, the client should ignore
   * `factor` until another `period` has passed.
   *
   * The client can measure its load using any unit that's comparable over time
   * For example, QPS can be used as long as each request involves a similar
   * amount of work.
   */
  factor: number;
}

/** Request message for Bigtable.CheckAndMutateRow. */
export interface CheckAndMutateRowRequest {
  /**
   * Optional. The unique name of the table to which the conditional mutation
   * should be applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   */
  tableName: string;
  /**
   * Optional. The unique name of the AuthorizedView to which the conditional
   * mutation should be applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>`.
   */
  authorizedViewName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
  /**
   * Required. The key of the row to which the conditional mutation should be
   * applied.
   */
  rowKey: Buffer;
  /**
   * The filter to be applied to the contents of the specified row. Depending
   * on whether or not any results are yielded, either `true_mutations` or
   * `false_mutations` will be executed. If unset, checks that the row contains
   * any values at all.
   */
  predicateFilter:
    | RowFilter
    | undefined;
  /**
   * Changes to be atomically applied to the specified row if `predicate_filter`
   * yields at least one cell when applied to `row_key`. Entries are applied in
   * order, meaning that earlier mutations can be masked by later ones.
   * Must contain at least one entry if `false_mutations` is empty, and at most
   * 100000.
   */
  trueMutations: Mutation[];
  /**
   * Changes to be atomically applied to the specified row if `predicate_filter`
   * does not yield any cells when applied to `row_key`. Entries are applied in
   * order, meaning that earlier mutations can be masked by later ones.
   * Must contain at least one entry if `true_mutations` is empty, and at most
   * 100000.
   */
  falseMutations: Mutation[];
}

/** Response message for Bigtable.CheckAndMutateRow. */
export interface CheckAndMutateRowResponse {
  /**
   * Whether or not the request's `predicate_filter` yielded any results for
   * the specified row.
   */
  predicateMatched: boolean;
}

/** Request message for client connection keep-alive and warming. */
export interface PingAndWarmRequest {
  /**
   * Required. The unique name of the instance to check permissions for as well
   * as respond. Values are of the form
   * `projects/<project>/instances/<instance>`.
   */
  name: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
}

/** Response message for Bigtable.PingAndWarm connection keepalive and warming. */
export interface PingAndWarmResponse {
}

/** Request message for Bigtable.ReadModifyWriteRow. */
export interface ReadModifyWriteRowRequest {
  /**
   * Optional. The unique name of the table to which the read/modify/write rules
   * should be applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   */
  tableName: string;
  /**
   * Optional. The unique name of the AuthorizedView to which the
   * read/modify/write rules should be applied.
   *
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>`.
   */
  authorizedViewName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   */
  appProfileId: string;
  /**
   * Required. The key of the row to which the read/modify/write rules should be
   * applied.
   */
  rowKey: Buffer;
  /**
   * Required. Rules specifying how the specified row's contents are to be
   * transformed into writes. Entries are applied in order, meaning that earlier
   * rules will affect the results of later ones.
   */
  rules: ReadModifyWriteRule[];
}

/** Response message for Bigtable.ReadModifyWriteRow. */
export interface ReadModifyWriteRowResponse {
  /** A Row containing the new contents of all cells modified by the request. */
  row: Row | undefined;
}

/**
 * NOTE: This API is intended to be used by Apache Beam BigtableIO.
 * Request message for Bigtable.GenerateInitialChangeStreamPartitions.
 */
export interface GenerateInitialChangeStreamPartitionsRequest {
  /**
   * Required. The unique name of the table from which to get change stream
   * partitions. Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   * Change streaming must be enabled on the table.
   */
  tableName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   * Single cluster routing must be configured on the profile.
   */
  appProfileId: string;
}

/**
 * NOTE: This API is intended to be used by Apache Beam BigtableIO.
 * Response message for Bigtable.GenerateInitialChangeStreamPartitions.
 */
export interface GenerateInitialChangeStreamPartitionsResponse {
  /** A partition of the change stream. */
  partition: StreamPartition | undefined;
}

/**
 * NOTE: This API is intended to be used by Apache Beam BigtableIO.
 * Request message for Bigtable.ReadChangeStream.
 */
export interface ReadChangeStreamRequest {
  /**
   * Required. The unique name of the table from which to read a change stream.
   * Values are of the form
   * `projects/<project>/instances/<instance>/tables/<table>`.
   * Change streaming must be enabled on the table.
   */
  tableName: string;
  /**
   * This value specifies routing for replication. If not specified, the
   * "default" application profile will be used.
   * Single cluster routing must be configured on the profile.
   */
  appProfileId: string;
  /** The partition to read changes from. */
  partition:
    | StreamPartition
    | undefined;
  /**
   * Start reading the stream at the specified timestamp. This timestamp must
   * be within the change stream retention period, less than or equal to the
   * current time, and after change stream creation, whichever is greater.
   * This value is inclusive and will be truncated to microsecond granularity.
   */
  startTime?:
    | Date
    | undefined;
  /**
   * Tokens that describe how to resume reading a stream where reading
   * previously left off. If specified, changes will be read starting at the
   * the position. Tokens are delivered on the stream as part of `Heartbeat`
   * and `CloseStream` messages.
   *
   * If a single token is provided, the token’s partition must exactly match
   * the request’s partition. If multiple tokens are provided, as in the case
   * of a partition merge, the union of the token partitions must exactly
   * cover the request’s partition. Otherwise, INVALID_ARGUMENT will be
   * returned.
   */
  continuationTokens?:
    | StreamContinuationTokens
    | undefined;
  /**
   * If specified, OK will be returned when the stream advances beyond
   * this time. Otherwise, changes will be continuously delivered on the stream.
   * This value is inclusive and will be truncated to microsecond granularity.
   */
  endTime:
    | Date
    | undefined;
  /**
   * If specified, the duration between `Heartbeat` messages on the stream.
   * Otherwise, defaults to 5 seconds.
   */
  heartbeatDuration: Duration | undefined;
}

/**
 * NOTE: This API is intended to be used by Apache Beam BigtableIO.
 * Response message for Bigtable.ReadChangeStream.
 */
export interface ReadChangeStreamResponse {
  /** A mutation to the partition. */
  dataChange?:
    | ReadChangeStreamResponse_DataChange
    | undefined;
  /** A periodic heartbeat message. */
  heartbeat?:
    | ReadChangeStreamResponse_Heartbeat
    | undefined;
  /** An indication that the stream should be closed. */
  closeStream?: ReadChangeStreamResponse_CloseStream | undefined;
}

/** A partial or complete mutation. */
export interface ReadChangeStreamResponse_MutationChunk {
  /**
   * If set, then the mutation is a `SetCell` with a chunked value across
   * multiple messages.
   */
  chunkInfo:
    | ReadChangeStreamResponse_MutationChunk_ChunkInfo
    | undefined;
  /**
   * If this is a continuation of a chunked message (`chunked_value_offset` >
   * 0), ignore all fields except the `SetCell`'s value and merge it with
   * the previous message by concatenating the value fields.
   */
  mutation: Mutation | undefined;
}

/**
 * Information about the chunking of this mutation.
 * Only `SetCell` mutations can be chunked, and all chunks for a `SetCell`
 * will be delivered contiguously with no other mutation types interleaved.
 */
export interface ReadChangeStreamResponse_MutationChunk_ChunkInfo {
  /** The total value size of all the chunks that make up the `SetCell`. */
  chunkedValueSize: number;
  /**
   * The byte offset of this chunk into the total value size of the
   * mutation.
   */
  chunkedValueOffset: number;
  /** When true, this is the last chunk of a chunked `SetCell`. */
  lastChunk: boolean;
}

/**
 * A message corresponding to one or more mutations to the partition
 * being streamed. A single logical `DataChange` message may also be split
 * across a sequence of multiple individual messages. Messages other than
 * the first in a sequence will only have the `type` and `chunks` fields
 * populated, with the final message in the sequence also containing `done`
 * set to true.
 */
export interface ReadChangeStreamResponse_DataChange {
  /** The type of the mutation. */
  type: ReadChangeStreamResponse_DataChange_Type;
  /**
   * The cluster where the mutation was applied.
   * Not set when `type` is `GARBAGE_COLLECTION`.
   */
  sourceClusterId: string;
  /**
   * The row key for all mutations that are part of this `DataChange`.
   * If the `DataChange` is chunked across multiple messages, then this field
   * will only be set for the first message.
   */
  rowKey: Buffer;
  /** The timestamp at which the mutation was applied on the Bigtable server. */
  commitTimestamp:
    | Date
    | undefined;
  /**
   * A value that lets stream consumers reconstruct Bigtable's
   * conflict resolution semantics.
   * https://cloud.google.com/bigtable/docs/writes#conflict-resolution
   * In the event that the same row key, column family, column qualifier,
   * timestamp are modified on different clusters at the same
   * `commit_timestamp`, the mutation with the larger `tiebreaker` will be the
   * one chosen for the eventually consistent state of the system.
   */
  tiebreaker: number;
  /**
   * The mutations associated with this change to the partition.
   * May contain complete mutations or chunks of a multi-message chunked
   * `DataChange` record.
   */
  chunks: ReadChangeStreamResponse_MutationChunk[];
  /**
   * When true, indicates that the entire `DataChange` has been read
   * and the client can safely process the message.
   */
  done: boolean;
  /**
   * An encoded position for this stream's partition to restart reading from.
   * This token is for the StreamPartition from the request.
   */
  token: string;
  /**
   * An estimate of the commit timestamp that is usually lower than or equal
   * to any timestamp for a record that will be delivered in the future on the
   * stream. It is possible that, under particular circumstances that a future
   * record has a timestamp is is lower than a previously seen timestamp. For
   * an example usage see
   * https://beam.apache.org/documentation/basics/#watermarks
   */
  estimatedLowWatermark: Date | undefined;
}

/** The type of mutation. */
export enum ReadChangeStreamResponse_DataChange_Type {
  /** TYPE_UNSPECIFIED - The type is unspecified. */
  TYPE_UNSPECIFIED = 0,
  /** USER - A user-initiated mutation. */
  USER = 1,
  /**
   * GARBAGE_COLLECTION - A system-initiated mutation as part of garbage collection.
   * https://cloud.google.com/bigtable/docs/garbage-collection
   */
  GARBAGE_COLLECTION = 2,
  /** CONTINUATION - This is a continuation of a multi-message change. */
  CONTINUATION = 3,
  UNRECOGNIZED = -1,
}

export function readChangeStreamResponse_DataChange_TypeFromJSON(
  object: any,
): ReadChangeStreamResponse_DataChange_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return ReadChangeStreamResponse_DataChange_Type.TYPE_UNSPECIFIED;
    case 1:
    case "USER":
      return ReadChangeStreamResponse_DataChange_Type.USER;
    case 2:
    case "GARBAGE_COLLECTION":
      return ReadChangeStreamResponse_DataChange_Type.GARBAGE_COLLECTION;
    case 3:
    case "CONTINUATION":
      return ReadChangeStreamResponse_DataChange_Type.CONTINUATION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ReadChangeStreamResponse_DataChange_Type.UNRECOGNIZED;
  }
}

export function readChangeStreamResponse_DataChange_TypeToJSON(
  object: ReadChangeStreamResponse_DataChange_Type,
): string {
  switch (object) {
    case ReadChangeStreamResponse_DataChange_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case ReadChangeStreamResponse_DataChange_Type.USER:
      return "USER";
    case ReadChangeStreamResponse_DataChange_Type.GARBAGE_COLLECTION:
      return "GARBAGE_COLLECTION";
    case ReadChangeStreamResponse_DataChange_Type.CONTINUATION:
      return "CONTINUATION";
    case ReadChangeStreamResponse_DataChange_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A periodic message with information that can be used to checkpoint
 * the state of a stream.
 */
export interface ReadChangeStreamResponse_Heartbeat {
  /**
   * A token that can be provided to a subsequent `ReadChangeStream` call
   * to pick up reading at the current stream position.
   */
  continuationToken:
    | StreamContinuationToken
    | undefined;
  /**
   * An estimate of the commit timestamp that is usually lower than or equal
   * to any timestamp for a record that will be delivered in the future on the
   * stream. It is possible that, under particular circumstances that a future
   * record has a timestamp is is lower than a previously seen timestamp. For
   * an example usage see
   * https://beam.apache.org/documentation/basics/#watermarks
   */
  estimatedLowWatermark: Date | undefined;
}

/**
 * A message indicating that the client should stop reading from the stream.
 * If status is OK and `continuation_tokens` & `new_partitions` are empty, the
 * stream has finished (for example if there was an `end_time` specified).
 * If `continuation_tokens` & `new_partitions` are present, then a change in
 * partitioning requires the client to open a new stream for each token to
 * resume reading. Example:
 *                                  [B,      D) ends
 *                                       |
 *                                       v
 *               new_partitions:  [A,  C) [C,  E)
 * continuation_tokens.partitions:  [B,C) [C,D)
 *                                  ^---^ ^---^
 *                                  ^     ^
 *                                  |     |
 *                                  |     StreamContinuationToken 2
 *                                  |
 *                                  StreamContinuationToken 1
 * To read the new partition [A,C), supply the continuation tokens whose
 * ranges cover the new partition, for example ContinuationToken[A,B) &
 * ContinuationToken[B,C).
 */
export interface ReadChangeStreamResponse_CloseStream {
  /** The status of the stream. */
  status:
    | Status
    | undefined;
  /**
   * If non-empty, contains the information needed to resume reading their
   * associated partitions.
   */
  continuationTokens: StreamContinuationToken[];
  /**
   * If non-empty, contains the new partitions to start reading from, which
   * are related to but not necessarily identical to the partitions for the
   * above `continuation_tokens`.
   */
  newPartitions: StreamPartition[];
}

/** Request message for Bigtable.ExecuteQuery */
export interface ExecuteQueryRequest {
  /**
   * Required. The unique name of the instance against which the query should be
   * executed.
   * Values are of the form `projects/<project>/instances/<instance>`
   */
  instanceName: string;
  /**
   * Optional. This value specifies routing for replication. If not specified,
   * the `default` application profile will be used.
   */
  appProfileId: string;
  /** Required. The query string. */
  query: string;
  /**
   * Protocol buffer format as described by ProtoSchema and ProtoRows
   * messages.
   */
  protoFormat?:
    | ProtoFormat
    | undefined;
  /**
   * Optional. If this request is resuming a previously interrupted query
   * execution, `resume_token` should be copied from the last
   * PartialResultSet yielded before the interruption. Doing this
   * enables the query execution to resume where the last one left
   * off.
   * The rest of the request parameters must exactly match the
   * request that yielded this token. Otherwise the request will fail.
   */
  resumeToken: Buffer;
  /**
   * Required. params contains string type keys and Bigtable type values that
   * bind to placeholders in the query string. In query string, a parameter
   * placeholder consists of the
   * `@` character followed by the parameter name (for example, `@firstName`) in
   * the query string.
   *
   * For example, if
   * `params["firstName"] = bytes_value: "foo" type {bytes_type {}}`
   *  then `@firstName` will be replaced with googlesql bytes value "foo" in the
   *  query string during query evaluation.
   *
   * In case of Value.kind is not set, it will be set to corresponding null
   * value in googlesql.
   *  `params["firstName"] =  type {string_type {}}`
   *  then `@firstName` will be replaced with googlesql null string.
   *
   * Value.type should always be set and no inference of type will be made from
   * Value.kind. If Value.type is not set, we will return INVALID_ARGUMENT
   * error.
   */
  params: { [key: string]: Value };
}

export interface ExecuteQueryRequest_ParamsEntry {
  key: string;
  value: Value | undefined;
}

/** Response message for Bigtable.ExecuteQuery */
export interface ExecuteQueryResponse {
  /**
   * Structure of rows in this response stream. The first (and only the first)
   * response streamed from the server will be of this type.
   */
  metadata?:
    | ResultSetMetadata
    | undefined;
  /**
   * A partial result set with row data potentially including additional
   * instructions on how recent past and future partial responses should be
   * interpreted.
   */
  results?: PartialResultSet | undefined;
}

function createBaseReadRowsRequest(): ReadRowsRequest {
  return {
    tableName: "",
    authorizedViewName: "",
    appProfileId: "",
    rows: undefined,
    filter: undefined,
    rowsLimit: Long.ZERO,
    requestStatsView: 0,
    reversed: false,
  };
}

export const ReadRowsRequest: MessageFns<ReadRowsRequest> = {
  encode(message: ReadRowsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.authorizedViewName !== "") {
      writer.uint32(74).string(message.authorizedViewName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(42).string(message.appProfileId);
    }
    if (message.rows !== undefined) {
      RowSet.encode(message.rows, writer.uint32(18).fork()).join();
    }
    if (message.filter !== undefined) {
      RowFilter.encode(message.filter, writer.uint32(26).fork()).join();
    }
    if (!message.rowsLimit.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.rowsLimit.toString());
    }
    if (message.requestStatsView !== 0) {
      writer.uint32(48).int32(message.requestStatsView);
    }
    if (message.reversed !== false) {
      writer.uint32(56).bool(message.reversed);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadRowsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadRowsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.authorizedViewName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rows = RowSet.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.filter = RowFilter.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.rowsLimit = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.requestStatsView = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.reversed = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadRowsRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      authorizedViewName: isSet(object.authorizedViewName) ? globalThis.String(object.authorizedViewName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      rows: isSet(object.rows) ? RowSet.fromJSON(object.rows) : undefined,
      filter: isSet(object.filter) ? RowFilter.fromJSON(object.filter) : undefined,
      rowsLimit: isSet(object.rowsLimit) ? Long.fromValue(object.rowsLimit) : Long.ZERO,
      requestStatsView: isSet(object.requestStatsView)
        ? readRowsRequest_RequestStatsViewFromJSON(object.requestStatsView)
        : 0,
      reversed: isSet(object.reversed) ? globalThis.Boolean(object.reversed) : false,
    };
  },

  toJSON(message: ReadRowsRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.authorizedViewName !== "") {
      obj.authorizedViewName = message.authorizedViewName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.rows !== undefined) {
      obj.rows = RowSet.toJSON(message.rows);
    }
    if (message.filter !== undefined) {
      obj.filter = RowFilter.toJSON(message.filter);
    }
    if (!message.rowsLimit.equals(Long.ZERO)) {
      obj.rowsLimit = (message.rowsLimit || Long.ZERO).toString();
    }
    if (message.requestStatsView !== 0) {
      obj.requestStatsView = readRowsRequest_RequestStatsViewToJSON(message.requestStatsView);
    }
    if (message.reversed !== false) {
      obj.reversed = message.reversed;
    }
    return obj;
  },

  create(base?: DeepPartial<ReadRowsRequest>): ReadRowsRequest {
    return ReadRowsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadRowsRequest>): ReadRowsRequest {
    const message = createBaseReadRowsRequest();
    message.tableName = object.tableName ?? "";
    message.authorizedViewName = object.authorizedViewName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.rows = (object.rows !== undefined && object.rows !== null) ? RowSet.fromPartial(object.rows) : undefined;
    message.filter = (object.filter !== undefined && object.filter !== null)
      ? RowFilter.fromPartial(object.filter)
      : undefined;
    message.rowsLimit = (object.rowsLimit !== undefined && object.rowsLimit !== null)
      ? Long.fromValue(object.rowsLimit)
      : Long.ZERO;
    message.requestStatsView = object.requestStatsView ?? 0;
    message.reversed = object.reversed ?? false;
    return message;
  },
};

function createBaseReadRowsResponse(): ReadRowsResponse {
  return { chunks: [], lastScannedRowKey: Buffer.alloc(0), requestStats: undefined };
}

export const ReadRowsResponse: MessageFns<ReadRowsResponse> = {
  encode(message: ReadRowsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.chunks) {
      ReadRowsResponse_CellChunk.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.lastScannedRowKey.length !== 0) {
      writer.uint32(18).bytes(message.lastScannedRowKey);
    }
    if (message.requestStats !== undefined) {
      RequestStats.encode(message.requestStats, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadRowsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadRowsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.chunks.push(ReadRowsResponse_CellChunk.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.lastScannedRowKey = Buffer.from(reader.bytes());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.requestStats = RequestStats.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadRowsResponse {
    return {
      chunks: globalThis.Array.isArray(object?.chunks)
        ? object.chunks.map((e: any) => ReadRowsResponse_CellChunk.fromJSON(e))
        : [],
      lastScannedRowKey: isSet(object.lastScannedRowKey)
        ? Buffer.from(bytesFromBase64(object.lastScannedRowKey))
        : Buffer.alloc(0),
      requestStats: isSet(object.requestStats) ? RequestStats.fromJSON(object.requestStats) : undefined,
    };
  },

  toJSON(message: ReadRowsResponse): unknown {
    const obj: any = {};
    if (message.chunks?.length) {
      obj.chunks = message.chunks.map((e) => ReadRowsResponse_CellChunk.toJSON(e));
    }
    if (message.lastScannedRowKey.length !== 0) {
      obj.lastScannedRowKey = base64FromBytes(message.lastScannedRowKey);
    }
    if (message.requestStats !== undefined) {
      obj.requestStats = RequestStats.toJSON(message.requestStats);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadRowsResponse>): ReadRowsResponse {
    return ReadRowsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadRowsResponse>): ReadRowsResponse {
    const message = createBaseReadRowsResponse();
    message.chunks = object.chunks?.map((e) => ReadRowsResponse_CellChunk.fromPartial(e)) || [];
    message.lastScannedRowKey = object.lastScannedRowKey ?? Buffer.alloc(0);
    message.requestStats = (object.requestStats !== undefined && object.requestStats !== null)
      ? RequestStats.fromPartial(object.requestStats)
      : undefined;
    return message;
  },
};

function createBaseReadRowsResponse_CellChunk(): ReadRowsResponse_CellChunk {
  return {
    rowKey: Buffer.alloc(0),
    familyName: undefined,
    qualifier: undefined,
    timestampMicros: Long.ZERO,
    labels: [],
    value: Buffer.alloc(0),
    valueSize: 0,
    resetRow: undefined,
    commitRow: undefined,
  };
}

export const ReadRowsResponse_CellChunk: MessageFns<ReadRowsResponse_CellChunk> = {
  encode(message: ReadRowsResponse_CellChunk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rowKey.length !== 0) {
      writer.uint32(10).bytes(message.rowKey);
    }
    if (message.familyName !== undefined) {
      StringValue.encode({ value: message.familyName! }, writer.uint32(18).fork()).join();
    }
    if (message.qualifier !== undefined) {
      BytesValue.encode({ value: message.qualifier! }, writer.uint32(26).fork()).join();
    }
    if (!message.timestampMicros.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.timestampMicros.toString());
    }
    for (const v of message.labels) {
      writer.uint32(42).string(v!);
    }
    if (message.value.length !== 0) {
      writer.uint32(50).bytes(message.value);
    }
    if (message.valueSize !== 0) {
      writer.uint32(56).int32(message.valueSize);
    }
    if (message.resetRow !== undefined) {
      writer.uint32(64).bool(message.resetRow);
    }
    if (message.commitRow !== undefined) {
      writer.uint32(72).bool(message.commitRow);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadRowsResponse_CellChunk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadRowsResponse_CellChunk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.familyName = StringValue.decode(reader, reader.uint32()).value;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.qualifier = BytesValue.decode(reader, reader.uint32()).value;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.timestampMicros = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.labels.push(reader.string());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.value = Buffer.from(reader.bytes());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.valueSize = reader.int32();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.resetRow = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.commitRow = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadRowsResponse_CellChunk {
    return {
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      familyName: isSet(object.familyName) ? String(object.familyName) : undefined,
      qualifier: isSet(object.qualifier) ? new Buffer(object.qualifier) : undefined,
      timestampMicros: isSet(object.timestampMicros) ? Long.fromValue(object.timestampMicros) : Long.ZERO,
      labels: globalThis.Array.isArray(object?.labels) ? object.labels.map((e: any) => globalThis.String(e)) : [],
      value: isSet(object.value) ? Buffer.from(bytesFromBase64(object.value)) : Buffer.alloc(0),
      valueSize: isSet(object.valueSize) ? globalThis.Number(object.valueSize) : 0,
      resetRow: isSet(object.resetRow) ? globalThis.Boolean(object.resetRow) : undefined,
      commitRow: isSet(object.commitRow) ? globalThis.Boolean(object.commitRow) : undefined,
    };
  },

  toJSON(message: ReadRowsResponse_CellChunk): unknown {
    const obj: any = {};
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (message.familyName !== undefined) {
      obj.familyName = message.familyName;
    }
    if (message.qualifier !== undefined) {
      obj.qualifier = message.qualifier;
    }
    if (!message.timestampMicros.equals(Long.ZERO)) {
      obj.timestampMicros = (message.timestampMicros || Long.ZERO).toString();
    }
    if (message.labels?.length) {
      obj.labels = message.labels;
    }
    if (message.value.length !== 0) {
      obj.value = base64FromBytes(message.value);
    }
    if (message.valueSize !== 0) {
      obj.valueSize = Math.round(message.valueSize);
    }
    if (message.resetRow !== undefined) {
      obj.resetRow = message.resetRow;
    }
    if (message.commitRow !== undefined) {
      obj.commitRow = message.commitRow;
    }
    return obj;
  },

  create(base?: DeepPartial<ReadRowsResponse_CellChunk>): ReadRowsResponse_CellChunk {
    return ReadRowsResponse_CellChunk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadRowsResponse_CellChunk>): ReadRowsResponse_CellChunk {
    const message = createBaseReadRowsResponse_CellChunk();
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.familyName = object.familyName ?? undefined;
    message.qualifier = object.qualifier ?? undefined;
    message.timestampMicros = (object.timestampMicros !== undefined && object.timestampMicros !== null)
      ? Long.fromValue(object.timestampMicros)
      : Long.ZERO;
    message.labels = object.labels?.map((e) => e) || [];
    message.value = object.value ?? Buffer.alloc(0);
    message.valueSize = object.valueSize ?? 0;
    message.resetRow = object.resetRow ?? undefined;
    message.commitRow = object.commitRow ?? undefined;
    return message;
  },
};

function createBaseSampleRowKeysRequest(): SampleRowKeysRequest {
  return { tableName: "", authorizedViewName: "", appProfileId: "" };
}

export const SampleRowKeysRequest: MessageFns<SampleRowKeysRequest> = {
  encode(message: SampleRowKeysRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.authorizedViewName !== "") {
      writer.uint32(34).string(message.authorizedViewName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(18).string(message.appProfileId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SampleRowKeysRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSampleRowKeysRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.authorizedViewName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SampleRowKeysRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      authorizedViewName: isSet(object.authorizedViewName) ? globalThis.String(object.authorizedViewName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
    };
  },

  toJSON(message: SampleRowKeysRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.authorizedViewName !== "") {
      obj.authorizedViewName = message.authorizedViewName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    return obj;
  },

  create(base?: DeepPartial<SampleRowKeysRequest>): SampleRowKeysRequest {
    return SampleRowKeysRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SampleRowKeysRequest>): SampleRowKeysRequest {
    const message = createBaseSampleRowKeysRequest();
    message.tableName = object.tableName ?? "";
    message.authorizedViewName = object.authorizedViewName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    return message;
  },
};

function createBaseSampleRowKeysResponse(): SampleRowKeysResponse {
  return { rowKey: Buffer.alloc(0), offsetBytes: Long.ZERO };
}

export const SampleRowKeysResponse: MessageFns<SampleRowKeysResponse> = {
  encode(message: SampleRowKeysResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rowKey.length !== 0) {
      writer.uint32(10).bytes(message.rowKey);
    }
    if (!message.offsetBytes.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.offsetBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SampleRowKeysResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSampleRowKeysResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.offsetBytes = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SampleRowKeysResponse {
    return {
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      offsetBytes: isSet(object.offsetBytes) ? Long.fromValue(object.offsetBytes) : Long.ZERO,
    };
  },

  toJSON(message: SampleRowKeysResponse): unknown {
    const obj: any = {};
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (!message.offsetBytes.equals(Long.ZERO)) {
      obj.offsetBytes = (message.offsetBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<SampleRowKeysResponse>): SampleRowKeysResponse {
    return SampleRowKeysResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SampleRowKeysResponse>): SampleRowKeysResponse {
    const message = createBaseSampleRowKeysResponse();
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.offsetBytes = (object.offsetBytes !== undefined && object.offsetBytes !== null)
      ? Long.fromValue(object.offsetBytes)
      : Long.ZERO;
    return message;
  },
};

function createBaseMutateRowRequest(): MutateRowRequest {
  return { tableName: "", authorizedViewName: "", appProfileId: "", rowKey: Buffer.alloc(0), mutations: [] };
}

export const MutateRowRequest: MessageFns<MutateRowRequest> = {
  encode(message: MutateRowRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.authorizedViewName !== "") {
      writer.uint32(50).string(message.authorizedViewName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(34).string(message.appProfileId);
    }
    if (message.rowKey.length !== 0) {
      writer.uint32(18).bytes(message.rowKey);
    }
    for (const v of message.mutations) {
      Mutation.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutateRowRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutateRowRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.authorizedViewName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mutations.push(Mutation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutateRowRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      authorizedViewName: isSet(object.authorizedViewName) ? globalThis.String(object.authorizedViewName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      mutations: globalThis.Array.isArray(object?.mutations)
        ? object.mutations.map((e: any) => Mutation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MutateRowRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.authorizedViewName !== "") {
      obj.authorizedViewName = message.authorizedViewName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (message.mutations?.length) {
      obj.mutations = message.mutations.map((e) => Mutation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MutateRowRequest>): MutateRowRequest {
    return MutateRowRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MutateRowRequest>): MutateRowRequest {
    const message = createBaseMutateRowRequest();
    message.tableName = object.tableName ?? "";
    message.authorizedViewName = object.authorizedViewName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.mutations = object.mutations?.map((e) => Mutation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMutateRowResponse(): MutateRowResponse {
  return {};
}

export const MutateRowResponse: MessageFns<MutateRowResponse> = {
  encode(_: MutateRowResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutateRowResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutateRowResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): MutateRowResponse {
    return {};
  },

  toJSON(_: MutateRowResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<MutateRowResponse>): MutateRowResponse {
    return MutateRowResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<MutateRowResponse>): MutateRowResponse {
    const message = createBaseMutateRowResponse();
    return message;
  },
};

function createBaseMutateRowsRequest(): MutateRowsRequest {
  return { tableName: "", authorizedViewName: "", appProfileId: "", entries: [] };
}

export const MutateRowsRequest: MessageFns<MutateRowsRequest> = {
  encode(message: MutateRowsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.authorizedViewName !== "") {
      writer.uint32(42).string(message.authorizedViewName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(26).string(message.appProfileId);
    }
    for (const v of message.entries) {
      MutateRowsRequest_Entry.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutateRowsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutateRowsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.authorizedViewName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entries.push(MutateRowsRequest_Entry.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutateRowsRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      authorizedViewName: isSet(object.authorizedViewName) ? globalThis.String(object.authorizedViewName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      entries: globalThis.Array.isArray(object?.entries)
        ? object.entries.map((e: any) => MutateRowsRequest_Entry.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MutateRowsRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.authorizedViewName !== "") {
      obj.authorizedViewName = message.authorizedViewName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.entries?.length) {
      obj.entries = message.entries.map((e) => MutateRowsRequest_Entry.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MutateRowsRequest>): MutateRowsRequest {
    return MutateRowsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MutateRowsRequest>): MutateRowsRequest {
    const message = createBaseMutateRowsRequest();
    message.tableName = object.tableName ?? "";
    message.authorizedViewName = object.authorizedViewName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.entries = object.entries?.map((e) => MutateRowsRequest_Entry.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMutateRowsRequest_Entry(): MutateRowsRequest_Entry {
  return { rowKey: Buffer.alloc(0), mutations: [] };
}

export const MutateRowsRequest_Entry: MessageFns<MutateRowsRequest_Entry> = {
  encode(message: MutateRowsRequest_Entry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rowKey.length !== 0) {
      writer.uint32(10).bytes(message.rowKey);
    }
    for (const v of message.mutations) {
      Mutation.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutateRowsRequest_Entry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutateRowsRequest_Entry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mutations.push(Mutation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutateRowsRequest_Entry {
    return {
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      mutations: globalThis.Array.isArray(object?.mutations)
        ? object.mutations.map((e: any) => Mutation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MutateRowsRequest_Entry): unknown {
    const obj: any = {};
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (message.mutations?.length) {
      obj.mutations = message.mutations.map((e) => Mutation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MutateRowsRequest_Entry>): MutateRowsRequest_Entry {
    return MutateRowsRequest_Entry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MutateRowsRequest_Entry>): MutateRowsRequest_Entry {
    const message = createBaseMutateRowsRequest_Entry();
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.mutations = object.mutations?.map((e) => Mutation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMutateRowsResponse(): MutateRowsResponse {
  return { entries: [], rateLimitInfo: undefined };
}

export const MutateRowsResponse: MessageFns<MutateRowsResponse> = {
  encode(message: MutateRowsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entries) {
      MutateRowsResponse_Entry.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.rateLimitInfo !== undefined) {
      RateLimitInfo.encode(message.rateLimitInfo, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutateRowsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutateRowsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entries.push(MutateRowsResponse_Entry.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.rateLimitInfo = RateLimitInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutateRowsResponse {
    return {
      entries: globalThis.Array.isArray(object?.entries)
        ? object.entries.map((e: any) => MutateRowsResponse_Entry.fromJSON(e))
        : [],
      rateLimitInfo: isSet(object.rateLimitInfo) ? RateLimitInfo.fromJSON(object.rateLimitInfo) : undefined,
    };
  },

  toJSON(message: MutateRowsResponse): unknown {
    const obj: any = {};
    if (message.entries?.length) {
      obj.entries = message.entries.map((e) => MutateRowsResponse_Entry.toJSON(e));
    }
    if (message.rateLimitInfo !== undefined) {
      obj.rateLimitInfo = RateLimitInfo.toJSON(message.rateLimitInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<MutateRowsResponse>): MutateRowsResponse {
    return MutateRowsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MutateRowsResponse>): MutateRowsResponse {
    const message = createBaseMutateRowsResponse();
    message.entries = object.entries?.map((e) => MutateRowsResponse_Entry.fromPartial(e)) || [];
    message.rateLimitInfo = (object.rateLimitInfo !== undefined && object.rateLimitInfo !== null)
      ? RateLimitInfo.fromPartial(object.rateLimitInfo)
      : undefined;
    return message;
  },
};

function createBaseMutateRowsResponse_Entry(): MutateRowsResponse_Entry {
  return { index: Long.ZERO, status: undefined };
}

export const MutateRowsResponse_Entry: MessageFns<MutateRowsResponse_Entry> = {
  encode(message: MutateRowsResponse_Entry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.index.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.index.toString());
    }
    if (message.status !== undefined) {
      Status.encode(message.status, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutateRowsResponse_Entry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutateRowsResponse_Entry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.index = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.status = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutateRowsResponse_Entry {
    return {
      index: isSet(object.index) ? Long.fromValue(object.index) : Long.ZERO,
      status: isSet(object.status) ? Status.fromJSON(object.status) : undefined,
    };
  },

  toJSON(message: MutateRowsResponse_Entry): unknown {
    const obj: any = {};
    if (!message.index.equals(Long.ZERO)) {
      obj.index = (message.index || Long.ZERO).toString();
    }
    if (message.status !== undefined) {
      obj.status = Status.toJSON(message.status);
    }
    return obj;
  },

  create(base?: DeepPartial<MutateRowsResponse_Entry>): MutateRowsResponse_Entry {
    return MutateRowsResponse_Entry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MutateRowsResponse_Entry>): MutateRowsResponse_Entry {
    const message = createBaseMutateRowsResponse_Entry();
    message.index = (object.index !== undefined && object.index !== null) ? Long.fromValue(object.index) : Long.ZERO;
    message.status = (object.status !== undefined && object.status !== null)
      ? Status.fromPartial(object.status)
      : undefined;
    return message;
  },
};

function createBaseRateLimitInfo(): RateLimitInfo {
  return { period: undefined, factor: 0 };
}

export const RateLimitInfo: MessageFns<RateLimitInfo> = {
  encode(message: RateLimitInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.period !== undefined) {
      Duration.encode(message.period, writer.uint32(10).fork()).join();
    }
    if (message.factor !== 0) {
      writer.uint32(17).double(message.factor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RateLimitInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRateLimitInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.period = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 17) {
            break;
          }

          message.factor = reader.double();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RateLimitInfo {
    return {
      period: isSet(object.period) ? Duration.fromJSON(object.period) : undefined,
      factor: isSet(object.factor) ? globalThis.Number(object.factor) : 0,
    };
  },

  toJSON(message: RateLimitInfo): unknown {
    const obj: any = {};
    if (message.period !== undefined) {
      obj.period = Duration.toJSON(message.period);
    }
    if (message.factor !== 0) {
      obj.factor = message.factor;
    }
    return obj;
  },

  create(base?: DeepPartial<RateLimitInfo>): RateLimitInfo {
    return RateLimitInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RateLimitInfo>): RateLimitInfo {
    const message = createBaseRateLimitInfo();
    message.period = (object.period !== undefined && object.period !== null)
      ? Duration.fromPartial(object.period)
      : undefined;
    message.factor = object.factor ?? 0;
    return message;
  },
};

function createBaseCheckAndMutateRowRequest(): CheckAndMutateRowRequest {
  return {
    tableName: "",
    authorizedViewName: "",
    appProfileId: "",
    rowKey: Buffer.alloc(0),
    predicateFilter: undefined,
    trueMutations: [],
    falseMutations: [],
  };
}

export const CheckAndMutateRowRequest: MessageFns<CheckAndMutateRowRequest> = {
  encode(message: CheckAndMutateRowRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.authorizedViewName !== "") {
      writer.uint32(74).string(message.authorizedViewName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(58).string(message.appProfileId);
    }
    if (message.rowKey.length !== 0) {
      writer.uint32(18).bytes(message.rowKey);
    }
    if (message.predicateFilter !== undefined) {
      RowFilter.encode(message.predicateFilter, writer.uint32(50).fork()).join();
    }
    for (const v of message.trueMutations) {
      Mutation.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.falseMutations) {
      Mutation.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CheckAndMutateRowRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCheckAndMutateRowRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.authorizedViewName = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.predicateFilter = RowFilter.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.trueMutations.push(Mutation.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.falseMutations.push(Mutation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CheckAndMutateRowRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      authorizedViewName: isSet(object.authorizedViewName) ? globalThis.String(object.authorizedViewName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      predicateFilter: isSet(object.predicateFilter) ? RowFilter.fromJSON(object.predicateFilter) : undefined,
      trueMutations: globalThis.Array.isArray(object?.trueMutations)
        ? object.trueMutations.map((e: any) => Mutation.fromJSON(e))
        : [],
      falseMutations: globalThis.Array.isArray(object?.falseMutations)
        ? object.falseMutations.map((e: any) => Mutation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CheckAndMutateRowRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.authorizedViewName !== "") {
      obj.authorizedViewName = message.authorizedViewName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (message.predicateFilter !== undefined) {
      obj.predicateFilter = RowFilter.toJSON(message.predicateFilter);
    }
    if (message.trueMutations?.length) {
      obj.trueMutations = message.trueMutations.map((e) => Mutation.toJSON(e));
    }
    if (message.falseMutations?.length) {
      obj.falseMutations = message.falseMutations.map((e) => Mutation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CheckAndMutateRowRequest>): CheckAndMutateRowRequest {
    return CheckAndMutateRowRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CheckAndMutateRowRequest>): CheckAndMutateRowRequest {
    const message = createBaseCheckAndMutateRowRequest();
    message.tableName = object.tableName ?? "";
    message.authorizedViewName = object.authorizedViewName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.predicateFilter = (object.predicateFilter !== undefined && object.predicateFilter !== null)
      ? RowFilter.fromPartial(object.predicateFilter)
      : undefined;
    message.trueMutations = object.trueMutations?.map((e) => Mutation.fromPartial(e)) || [];
    message.falseMutations = object.falseMutations?.map((e) => Mutation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCheckAndMutateRowResponse(): CheckAndMutateRowResponse {
  return { predicateMatched: false };
}

export const CheckAndMutateRowResponse: MessageFns<CheckAndMutateRowResponse> = {
  encode(message: CheckAndMutateRowResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.predicateMatched !== false) {
      writer.uint32(8).bool(message.predicateMatched);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CheckAndMutateRowResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCheckAndMutateRowResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.predicateMatched = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CheckAndMutateRowResponse {
    return { predicateMatched: isSet(object.predicateMatched) ? globalThis.Boolean(object.predicateMatched) : false };
  },

  toJSON(message: CheckAndMutateRowResponse): unknown {
    const obj: any = {};
    if (message.predicateMatched !== false) {
      obj.predicateMatched = message.predicateMatched;
    }
    return obj;
  },

  create(base?: DeepPartial<CheckAndMutateRowResponse>): CheckAndMutateRowResponse {
    return CheckAndMutateRowResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CheckAndMutateRowResponse>): CheckAndMutateRowResponse {
    const message = createBaseCheckAndMutateRowResponse();
    message.predicateMatched = object.predicateMatched ?? false;
    return message;
  },
};

function createBasePingAndWarmRequest(): PingAndWarmRequest {
  return { name: "", appProfileId: "" };
}

export const PingAndWarmRequest: MessageFns<PingAndWarmRequest> = {
  encode(message: PingAndWarmRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.appProfileId !== "") {
      writer.uint32(18).string(message.appProfileId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PingAndWarmRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePingAndWarmRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PingAndWarmRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
    };
  },

  toJSON(message: PingAndWarmRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    return obj;
  },

  create(base?: DeepPartial<PingAndWarmRequest>): PingAndWarmRequest {
    return PingAndWarmRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PingAndWarmRequest>): PingAndWarmRequest {
    const message = createBasePingAndWarmRequest();
    message.name = object.name ?? "";
    message.appProfileId = object.appProfileId ?? "";
    return message;
  },
};

function createBasePingAndWarmResponse(): PingAndWarmResponse {
  return {};
}

export const PingAndWarmResponse: MessageFns<PingAndWarmResponse> = {
  encode(_: PingAndWarmResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PingAndWarmResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePingAndWarmResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): PingAndWarmResponse {
    return {};
  },

  toJSON(_: PingAndWarmResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<PingAndWarmResponse>): PingAndWarmResponse {
    return PingAndWarmResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<PingAndWarmResponse>): PingAndWarmResponse {
    const message = createBasePingAndWarmResponse();
    return message;
  },
};

function createBaseReadModifyWriteRowRequest(): ReadModifyWriteRowRequest {
  return { tableName: "", authorizedViewName: "", appProfileId: "", rowKey: Buffer.alloc(0), rules: [] };
}

export const ReadModifyWriteRowRequest: MessageFns<ReadModifyWriteRowRequest> = {
  encode(message: ReadModifyWriteRowRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.authorizedViewName !== "") {
      writer.uint32(50).string(message.authorizedViewName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(34).string(message.appProfileId);
    }
    if (message.rowKey.length !== 0) {
      writer.uint32(18).bytes(message.rowKey);
    }
    for (const v of message.rules) {
      ReadModifyWriteRule.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadModifyWriteRowRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadModifyWriteRowRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.authorizedViewName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.rules.push(ReadModifyWriteRule.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadModifyWriteRowRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      authorizedViewName: isSet(object.authorizedViewName) ? globalThis.String(object.authorizedViewName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      rules: globalThis.Array.isArray(object?.rules)
        ? object.rules.map((e: any) => ReadModifyWriteRule.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ReadModifyWriteRowRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.authorizedViewName !== "") {
      obj.authorizedViewName = message.authorizedViewName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => ReadModifyWriteRule.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ReadModifyWriteRowRequest>): ReadModifyWriteRowRequest {
    return ReadModifyWriteRowRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadModifyWriteRowRequest>): ReadModifyWriteRowRequest {
    const message = createBaseReadModifyWriteRowRequest();
    message.tableName = object.tableName ?? "";
    message.authorizedViewName = object.authorizedViewName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.rules = object.rules?.map((e) => ReadModifyWriteRule.fromPartial(e)) || [];
    return message;
  },
};

function createBaseReadModifyWriteRowResponse(): ReadModifyWriteRowResponse {
  return { row: undefined };
}

export const ReadModifyWriteRowResponse: MessageFns<ReadModifyWriteRowResponse> = {
  encode(message: ReadModifyWriteRowResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.row !== undefined) {
      Row.encode(message.row, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadModifyWriteRowResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadModifyWriteRowResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.row = Row.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadModifyWriteRowResponse {
    return { row: isSet(object.row) ? Row.fromJSON(object.row) : undefined };
  },

  toJSON(message: ReadModifyWriteRowResponse): unknown {
    const obj: any = {};
    if (message.row !== undefined) {
      obj.row = Row.toJSON(message.row);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadModifyWriteRowResponse>): ReadModifyWriteRowResponse {
    return ReadModifyWriteRowResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadModifyWriteRowResponse>): ReadModifyWriteRowResponse {
    const message = createBaseReadModifyWriteRowResponse();
    message.row = (object.row !== undefined && object.row !== null) ? Row.fromPartial(object.row) : undefined;
    return message;
  },
};

function createBaseGenerateInitialChangeStreamPartitionsRequest(): GenerateInitialChangeStreamPartitionsRequest {
  return { tableName: "", appProfileId: "" };
}

export const GenerateInitialChangeStreamPartitionsRequest: MessageFns<GenerateInitialChangeStreamPartitionsRequest> = {
  encode(
    message: GenerateInitialChangeStreamPartitionsRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(18).string(message.appProfileId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateInitialChangeStreamPartitionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateInitialChangeStreamPartitionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateInitialChangeStreamPartitionsRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
    };
  },

  toJSON(message: GenerateInitialChangeStreamPartitionsRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    return obj;
  },

  create(
    base?: DeepPartial<GenerateInitialChangeStreamPartitionsRequest>,
  ): GenerateInitialChangeStreamPartitionsRequest {
    return GenerateInitialChangeStreamPartitionsRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<GenerateInitialChangeStreamPartitionsRequest>,
  ): GenerateInitialChangeStreamPartitionsRequest {
    const message = createBaseGenerateInitialChangeStreamPartitionsRequest();
    message.tableName = object.tableName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    return message;
  },
};

function createBaseGenerateInitialChangeStreamPartitionsResponse(): GenerateInitialChangeStreamPartitionsResponse {
  return { partition: undefined };
}

export const GenerateInitialChangeStreamPartitionsResponse: MessageFns<GenerateInitialChangeStreamPartitionsResponse> =
  {
    encode(
      message: GenerateInitialChangeStreamPartitionsResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.partition !== undefined) {
        StreamPartition.encode(message.partition, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): GenerateInitialChangeStreamPartitionsResponse {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGenerateInitialChangeStreamPartitionsResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.partition = StreamPartition.decode(reader, reader.uint32());
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GenerateInitialChangeStreamPartitionsResponse {
      return { partition: isSet(object.partition) ? StreamPartition.fromJSON(object.partition) : undefined };
    },

    toJSON(message: GenerateInitialChangeStreamPartitionsResponse): unknown {
      const obj: any = {};
      if (message.partition !== undefined) {
        obj.partition = StreamPartition.toJSON(message.partition);
      }
      return obj;
    },

    create(
      base?: DeepPartial<GenerateInitialChangeStreamPartitionsResponse>,
    ): GenerateInitialChangeStreamPartitionsResponse {
      return GenerateInitialChangeStreamPartitionsResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GenerateInitialChangeStreamPartitionsResponse>,
    ): GenerateInitialChangeStreamPartitionsResponse {
      const message = createBaseGenerateInitialChangeStreamPartitionsResponse();
      message.partition = (object.partition !== undefined && object.partition !== null)
        ? StreamPartition.fromPartial(object.partition)
        : undefined;
      return message;
    },
  };

function createBaseReadChangeStreamRequest(): ReadChangeStreamRequest {
  return {
    tableName: "",
    appProfileId: "",
    partition: undefined,
    startTime: undefined,
    continuationTokens: undefined,
    endTime: undefined,
    heartbeatDuration: undefined,
  };
}

export const ReadChangeStreamRequest: MessageFns<ReadChangeStreamRequest> = {
  encode(message: ReadChangeStreamRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableName !== "") {
      writer.uint32(10).string(message.tableName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(18).string(message.appProfileId);
    }
    if (message.partition !== undefined) {
      StreamPartition.encode(message.partition, writer.uint32(26).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(34).fork()).join();
    }
    if (message.continuationTokens !== undefined) {
      StreamContinuationTokens.encode(message.continuationTokens, writer.uint32(50).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(42).fork()).join();
    }
    if (message.heartbeatDuration !== undefined) {
      Duration.encode(message.heartbeatDuration, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tableName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.partition = StreamPartition.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.continuationTokens = StreamContinuationTokens.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.heartbeatDuration = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamRequest {
    return {
      tableName: isSet(object.tableName) ? globalThis.String(object.tableName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      partition: isSet(object.partition) ? StreamPartition.fromJSON(object.partition) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      continuationTokens: isSet(object.continuationTokens)
        ? StreamContinuationTokens.fromJSON(object.continuationTokens)
        : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      heartbeatDuration: isSet(object.heartbeatDuration) ? Duration.fromJSON(object.heartbeatDuration) : undefined,
    };
  },

  toJSON(message: ReadChangeStreamRequest): unknown {
    const obj: any = {};
    if (message.tableName !== "") {
      obj.tableName = message.tableName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.partition !== undefined) {
      obj.partition = StreamPartition.toJSON(message.partition);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.continuationTokens !== undefined) {
      obj.continuationTokens = StreamContinuationTokens.toJSON(message.continuationTokens);
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.heartbeatDuration !== undefined) {
      obj.heartbeatDuration = Duration.toJSON(message.heartbeatDuration);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadChangeStreamRequest>): ReadChangeStreamRequest {
    return ReadChangeStreamRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadChangeStreamRequest>): ReadChangeStreamRequest {
    const message = createBaseReadChangeStreamRequest();
    message.tableName = object.tableName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.partition = (object.partition !== undefined && object.partition !== null)
      ? StreamPartition.fromPartial(object.partition)
      : undefined;
    message.startTime = object.startTime ?? undefined;
    message.continuationTokens = (object.continuationTokens !== undefined && object.continuationTokens !== null)
      ? StreamContinuationTokens.fromPartial(object.continuationTokens)
      : undefined;
    message.endTime = object.endTime ?? undefined;
    message.heartbeatDuration = (object.heartbeatDuration !== undefined && object.heartbeatDuration !== null)
      ? Duration.fromPartial(object.heartbeatDuration)
      : undefined;
    return message;
  },
};

function createBaseReadChangeStreamResponse(): ReadChangeStreamResponse {
  return { dataChange: undefined, heartbeat: undefined, closeStream: undefined };
}

export const ReadChangeStreamResponse: MessageFns<ReadChangeStreamResponse> = {
  encode(message: ReadChangeStreamResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataChange !== undefined) {
      ReadChangeStreamResponse_DataChange.encode(message.dataChange, writer.uint32(10).fork()).join();
    }
    if (message.heartbeat !== undefined) {
      ReadChangeStreamResponse_Heartbeat.encode(message.heartbeat, writer.uint32(18).fork()).join();
    }
    if (message.closeStream !== undefined) {
      ReadChangeStreamResponse_CloseStream.encode(message.closeStream, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataChange = ReadChangeStreamResponse_DataChange.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.heartbeat = ReadChangeStreamResponse_Heartbeat.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.closeStream = ReadChangeStreamResponse_CloseStream.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamResponse {
    return {
      dataChange: isSet(object.dataChange)
        ? ReadChangeStreamResponse_DataChange.fromJSON(object.dataChange)
        : undefined,
      heartbeat: isSet(object.heartbeat) ? ReadChangeStreamResponse_Heartbeat.fromJSON(object.heartbeat) : undefined,
      closeStream: isSet(object.closeStream)
        ? ReadChangeStreamResponse_CloseStream.fromJSON(object.closeStream)
        : undefined,
    };
  },

  toJSON(message: ReadChangeStreamResponse): unknown {
    const obj: any = {};
    if (message.dataChange !== undefined) {
      obj.dataChange = ReadChangeStreamResponse_DataChange.toJSON(message.dataChange);
    }
    if (message.heartbeat !== undefined) {
      obj.heartbeat = ReadChangeStreamResponse_Heartbeat.toJSON(message.heartbeat);
    }
    if (message.closeStream !== undefined) {
      obj.closeStream = ReadChangeStreamResponse_CloseStream.toJSON(message.closeStream);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadChangeStreamResponse>): ReadChangeStreamResponse {
    return ReadChangeStreamResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadChangeStreamResponse>): ReadChangeStreamResponse {
    const message = createBaseReadChangeStreamResponse();
    message.dataChange = (object.dataChange !== undefined && object.dataChange !== null)
      ? ReadChangeStreamResponse_DataChange.fromPartial(object.dataChange)
      : undefined;
    message.heartbeat = (object.heartbeat !== undefined && object.heartbeat !== null)
      ? ReadChangeStreamResponse_Heartbeat.fromPartial(object.heartbeat)
      : undefined;
    message.closeStream = (object.closeStream !== undefined && object.closeStream !== null)
      ? ReadChangeStreamResponse_CloseStream.fromPartial(object.closeStream)
      : undefined;
    return message;
  },
};

function createBaseReadChangeStreamResponse_MutationChunk(): ReadChangeStreamResponse_MutationChunk {
  return { chunkInfo: undefined, mutation: undefined };
}

export const ReadChangeStreamResponse_MutationChunk: MessageFns<ReadChangeStreamResponse_MutationChunk> = {
  encode(message: ReadChangeStreamResponse_MutationChunk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.chunkInfo !== undefined) {
      ReadChangeStreamResponse_MutationChunk_ChunkInfo.encode(message.chunkInfo, writer.uint32(10).fork()).join();
    }
    if (message.mutation !== undefined) {
      Mutation.encode(message.mutation, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamResponse_MutationChunk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamResponse_MutationChunk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.chunkInfo = ReadChangeStreamResponse_MutationChunk_ChunkInfo.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mutation = Mutation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamResponse_MutationChunk {
    return {
      chunkInfo: isSet(object.chunkInfo)
        ? ReadChangeStreamResponse_MutationChunk_ChunkInfo.fromJSON(object.chunkInfo)
        : undefined,
      mutation: isSet(object.mutation) ? Mutation.fromJSON(object.mutation) : undefined,
    };
  },

  toJSON(message: ReadChangeStreamResponse_MutationChunk): unknown {
    const obj: any = {};
    if (message.chunkInfo !== undefined) {
      obj.chunkInfo = ReadChangeStreamResponse_MutationChunk_ChunkInfo.toJSON(message.chunkInfo);
    }
    if (message.mutation !== undefined) {
      obj.mutation = Mutation.toJSON(message.mutation);
    }
    return obj;
  },

  create(base?: DeepPartial<ReadChangeStreamResponse_MutationChunk>): ReadChangeStreamResponse_MutationChunk {
    return ReadChangeStreamResponse_MutationChunk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadChangeStreamResponse_MutationChunk>): ReadChangeStreamResponse_MutationChunk {
    const message = createBaseReadChangeStreamResponse_MutationChunk();
    message.chunkInfo = (object.chunkInfo !== undefined && object.chunkInfo !== null)
      ? ReadChangeStreamResponse_MutationChunk_ChunkInfo.fromPartial(object.chunkInfo)
      : undefined;
    message.mutation = (object.mutation !== undefined && object.mutation !== null)
      ? Mutation.fromPartial(object.mutation)
      : undefined;
    return message;
  },
};

function createBaseReadChangeStreamResponse_MutationChunk_ChunkInfo(): ReadChangeStreamResponse_MutationChunk_ChunkInfo {
  return { chunkedValueSize: 0, chunkedValueOffset: 0, lastChunk: false };
}

export const ReadChangeStreamResponse_MutationChunk_ChunkInfo: MessageFns<
  ReadChangeStreamResponse_MutationChunk_ChunkInfo
> = {
  encode(
    message: ReadChangeStreamResponse_MutationChunk_ChunkInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.chunkedValueSize !== 0) {
      writer.uint32(8).int32(message.chunkedValueSize);
    }
    if (message.chunkedValueOffset !== 0) {
      writer.uint32(16).int32(message.chunkedValueOffset);
    }
    if (message.lastChunk !== false) {
      writer.uint32(24).bool(message.lastChunk);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamResponse_MutationChunk_ChunkInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamResponse_MutationChunk_ChunkInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.chunkedValueSize = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.chunkedValueOffset = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.lastChunk = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamResponse_MutationChunk_ChunkInfo {
    return {
      chunkedValueSize: isSet(object.chunkedValueSize) ? globalThis.Number(object.chunkedValueSize) : 0,
      chunkedValueOffset: isSet(object.chunkedValueOffset) ? globalThis.Number(object.chunkedValueOffset) : 0,
      lastChunk: isSet(object.lastChunk) ? globalThis.Boolean(object.lastChunk) : false,
    };
  },

  toJSON(message: ReadChangeStreamResponse_MutationChunk_ChunkInfo): unknown {
    const obj: any = {};
    if (message.chunkedValueSize !== 0) {
      obj.chunkedValueSize = Math.round(message.chunkedValueSize);
    }
    if (message.chunkedValueOffset !== 0) {
      obj.chunkedValueOffset = Math.round(message.chunkedValueOffset);
    }
    if (message.lastChunk !== false) {
      obj.lastChunk = message.lastChunk;
    }
    return obj;
  },

  create(
    base?: DeepPartial<ReadChangeStreamResponse_MutationChunk_ChunkInfo>,
  ): ReadChangeStreamResponse_MutationChunk_ChunkInfo {
    return ReadChangeStreamResponse_MutationChunk_ChunkInfo.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ReadChangeStreamResponse_MutationChunk_ChunkInfo>,
  ): ReadChangeStreamResponse_MutationChunk_ChunkInfo {
    const message = createBaseReadChangeStreamResponse_MutationChunk_ChunkInfo();
    message.chunkedValueSize = object.chunkedValueSize ?? 0;
    message.chunkedValueOffset = object.chunkedValueOffset ?? 0;
    message.lastChunk = object.lastChunk ?? false;
    return message;
  },
};

function createBaseReadChangeStreamResponse_DataChange(): ReadChangeStreamResponse_DataChange {
  return {
    type: 0,
    sourceClusterId: "",
    rowKey: Buffer.alloc(0),
    commitTimestamp: undefined,
    tiebreaker: 0,
    chunks: [],
    done: false,
    token: "",
    estimatedLowWatermark: undefined,
  };
}

export const ReadChangeStreamResponse_DataChange: MessageFns<ReadChangeStreamResponse_DataChange> = {
  encode(message: ReadChangeStreamResponse_DataChange, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.sourceClusterId !== "") {
      writer.uint32(18).string(message.sourceClusterId);
    }
    if (message.rowKey.length !== 0) {
      writer.uint32(26).bytes(message.rowKey);
    }
    if (message.commitTimestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.commitTimestamp), writer.uint32(34).fork()).join();
    }
    if (message.tiebreaker !== 0) {
      writer.uint32(40).int32(message.tiebreaker);
    }
    for (const v of message.chunks) {
      ReadChangeStreamResponse_MutationChunk.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.done !== false) {
      writer.uint32(64).bool(message.done);
    }
    if (message.token !== "") {
      writer.uint32(74).string(message.token);
    }
    if (message.estimatedLowWatermark !== undefined) {
      Timestamp.encode(toTimestamp(message.estimatedLowWatermark), writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamResponse_DataChange {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamResponse_DataChange();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceClusterId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.rowKey = Buffer.from(reader.bytes());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.commitTimestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.tiebreaker = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.chunks.push(ReadChangeStreamResponse_MutationChunk.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.done = reader.bool();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.token = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.estimatedLowWatermark = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamResponse_DataChange {
    return {
      type: isSet(object.type) ? readChangeStreamResponse_DataChange_TypeFromJSON(object.type) : 0,
      sourceClusterId: isSet(object.sourceClusterId) ? globalThis.String(object.sourceClusterId) : "",
      rowKey: isSet(object.rowKey) ? Buffer.from(bytesFromBase64(object.rowKey)) : Buffer.alloc(0),
      commitTimestamp: isSet(object.commitTimestamp) ? fromJsonTimestamp(object.commitTimestamp) : undefined,
      tiebreaker: isSet(object.tiebreaker) ? globalThis.Number(object.tiebreaker) : 0,
      chunks: globalThis.Array.isArray(object?.chunks)
        ? object.chunks.map((e: any) => ReadChangeStreamResponse_MutationChunk.fromJSON(e))
        : [],
      done: isSet(object.done) ? globalThis.Boolean(object.done) : false,
      token: isSet(object.token) ? globalThis.String(object.token) : "",
      estimatedLowWatermark: isSet(object.estimatedLowWatermark)
        ? fromJsonTimestamp(object.estimatedLowWatermark)
        : undefined,
    };
  },

  toJSON(message: ReadChangeStreamResponse_DataChange): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = readChangeStreamResponse_DataChange_TypeToJSON(message.type);
    }
    if (message.sourceClusterId !== "") {
      obj.sourceClusterId = message.sourceClusterId;
    }
    if (message.rowKey.length !== 0) {
      obj.rowKey = base64FromBytes(message.rowKey);
    }
    if (message.commitTimestamp !== undefined) {
      obj.commitTimestamp = message.commitTimestamp.toISOString();
    }
    if (message.tiebreaker !== 0) {
      obj.tiebreaker = Math.round(message.tiebreaker);
    }
    if (message.chunks?.length) {
      obj.chunks = message.chunks.map((e) => ReadChangeStreamResponse_MutationChunk.toJSON(e));
    }
    if (message.done !== false) {
      obj.done = message.done;
    }
    if (message.token !== "") {
      obj.token = message.token;
    }
    if (message.estimatedLowWatermark !== undefined) {
      obj.estimatedLowWatermark = message.estimatedLowWatermark.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ReadChangeStreamResponse_DataChange>): ReadChangeStreamResponse_DataChange {
    return ReadChangeStreamResponse_DataChange.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadChangeStreamResponse_DataChange>): ReadChangeStreamResponse_DataChange {
    const message = createBaseReadChangeStreamResponse_DataChange();
    message.type = object.type ?? 0;
    message.sourceClusterId = object.sourceClusterId ?? "";
    message.rowKey = object.rowKey ?? Buffer.alloc(0);
    message.commitTimestamp = object.commitTimestamp ?? undefined;
    message.tiebreaker = object.tiebreaker ?? 0;
    message.chunks = object.chunks?.map((e) => ReadChangeStreamResponse_MutationChunk.fromPartial(e)) || [];
    message.done = object.done ?? false;
    message.token = object.token ?? "";
    message.estimatedLowWatermark = object.estimatedLowWatermark ?? undefined;
    return message;
  },
};

function createBaseReadChangeStreamResponse_Heartbeat(): ReadChangeStreamResponse_Heartbeat {
  return { continuationToken: undefined, estimatedLowWatermark: undefined };
}

export const ReadChangeStreamResponse_Heartbeat: MessageFns<ReadChangeStreamResponse_Heartbeat> = {
  encode(message: ReadChangeStreamResponse_Heartbeat, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.continuationToken !== undefined) {
      StreamContinuationToken.encode(message.continuationToken, writer.uint32(10).fork()).join();
    }
    if (message.estimatedLowWatermark !== undefined) {
      Timestamp.encode(toTimestamp(message.estimatedLowWatermark), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamResponse_Heartbeat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamResponse_Heartbeat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.continuationToken = StreamContinuationToken.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.estimatedLowWatermark = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamResponse_Heartbeat {
    return {
      continuationToken: isSet(object.continuationToken)
        ? StreamContinuationToken.fromJSON(object.continuationToken)
        : undefined,
      estimatedLowWatermark: isSet(object.estimatedLowWatermark)
        ? fromJsonTimestamp(object.estimatedLowWatermark)
        : undefined,
    };
  },

  toJSON(message: ReadChangeStreamResponse_Heartbeat): unknown {
    const obj: any = {};
    if (message.continuationToken !== undefined) {
      obj.continuationToken = StreamContinuationToken.toJSON(message.continuationToken);
    }
    if (message.estimatedLowWatermark !== undefined) {
      obj.estimatedLowWatermark = message.estimatedLowWatermark.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ReadChangeStreamResponse_Heartbeat>): ReadChangeStreamResponse_Heartbeat {
    return ReadChangeStreamResponse_Heartbeat.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadChangeStreamResponse_Heartbeat>): ReadChangeStreamResponse_Heartbeat {
    const message = createBaseReadChangeStreamResponse_Heartbeat();
    message.continuationToken = (object.continuationToken !== undefined && object.continuationToken !== null)
      ? StreamContinuationToken.fromPartial(object.continuationToken)
      : undefined;
    message.estimatedLowWatermark = object.estimatedLowWatermark ?? undefined;
    return message;
  },
};

function createBaseReadChangeStreamResponse_CloseStream(): ReadChangeStreamResponse_CloseStream {
  return { status: undefined, continuationTokens: [], newPartitions: [] };
}

export const ReadChangeStreamResponse_CloseStream: MessageFns<ReadChangeStreamResponse_CloseStream> = {
  encode(message: ReadChangeStreamResponse_CloseStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== undefined) {
      Status.encode(message.status, writer.uint32(10).fork()).join();
    }
    for (const v of message.continuationTokens) {
      StreamContinuationToken.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.newPartitions) {
      StreamPartition.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReadChangeStreamResponse_CloseStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReadChangeStreamResponse_CloseStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.status = Status.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.continuationTokens.push(StreamContinuationToken.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.newPartitions.push(StreamPartition.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReadChangeStreamResponse_CloseStream {
    return {
      status: isSet(object.status) ? Status.fromJSON(object.status) : undefined,
      continuationTokens: globalThis.Array.isArray(object?.continuationTokens)
        ? object.continuationTokens.map((e: any) => StreamContinuationToken.fromJSON(e))
        : [],
      newPartitions: globalThis.Array.isArray(object?.newPartitions)
        ? object.newPartitions.map((e: any) => StreamPartition.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ReadChangeStreamResponse_CloseStream): unknown {
    const obj: any = {};
    if (message.status !== undefined) {
      obj.status = Status.toJSON(message.status);
    }
    if (message.continuationTokens?.length) {
      obj.continuationTokens = message.continuationTokens.map((e) => StreamContinuationToken.toJSON(e));
    }
    if (message.newPartitions?.length) {
      obj.newPartitions = message.newPartitions.map((e) => StreamPartition.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ReadChangeStreamResponse_CloseStream>): ReadChangeStreamResponse_CloseStream {
    return ReadChangeStreamResponse_CloseStream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReadChangeStreamResponse_CloseStream>): ReadChangeStreamResponse_CloseStream {
    const message = createBaseReadChangeStreamResponse_CloseStream();
    message.status = (object.status !== undefined && object.status !== null)
      ? Status.fromPartial(object.status)
      : undefined;
    message.continuationTokens = object.continuationTokens?.map((e) => StreamContinuationToken.fromPartial(e)) || [];
    message.newPartitions = object.newPartitions?.map((e) => StreamPartition.fromPartial(e)) || [];
    return message;
  },
};

function createBaseExecuteQueryRequest(): ExecuteQueryRequest {
  return {
    instanceName: "",
    appProfileId: "",
    query: "",
    protoFormat: undefined,
    resumeToken: Buffer.alloc(0),
    params: {},
  };
}

export const ExecuteQueryRequest: MessageFns<ExecuteQueryRequest> = {
  encode(message: ExecuteQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instanceName !== "") {
      writer.uint32(10).string(message.instanceName);
    }
    if (message.appProfileId !== "") {
      writer.uint32(18).string(message.appProfileId);
    }
    if (message.query !== "") {
      writer.uint32(26).string(message.query);
    }
    if (message.protoFormat !== undefined) {
      ProtoFormat.encode(message.protoFormat, writer.uint32(34).fork()).join();
    }
    if (message.resumeToken.length !== 0) {
      writer.uint32(66).bytes(message.resumeToken);
    }
    Object.entries(message.params).forEach(([key, value]) => {
      ExecuteQueryRequest_ParamsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecuteQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecuteQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.instanceName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.appProfileId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.query = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.protoFormat = ProtoFormat.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.resumeToken = Buffer.from(reader.bytes());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          const entry7 = ExecuteQueryRequest_ParamsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.params[entry7.key] = entry7.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecuteQueryRequest {
    return {
      instanceName: isSet(object.instanceName) ? globalThis.String(object.instanceName) : "",
      appProfileId: isSet(object.appProfileId) ? globalThis.String(object.appProfileId) : "",
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      protoFormat: isSet(object.protoFormat) ? ProtoFormat.fromJSON(object.protoFormat) : undefined,
      resumeToken: isSet(object.resumeToken) ? Buffer.from(bytesFromBase64(object.resumeToken)) : Buffer.alloc(0),
      params: isObject(object.params)
        ? Object.entries(object.params).reduce<{ [key: string]: Value }>((acc, [key, value]) => {
          acc[key] = Value.fromJSON(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: ExecuteQueryRequest): unknown {
    const obj: any = {};
    if (message.instanceName !== "") {
      obj.instanceName = message.instanceName;
    }
    if (message.appProfileId !== "") {
      obj.appProfileId = message.appProfileId;
    }
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.protoFormat !== undefined) {
      obj.protoFormat = ProtoFormat.toJSON(message.protoFormat);
    }
    if (message.resumeToken.length !== 0) {
      obj.resumeToken = base64FromBytes(message.resumeToken);
    }
    if (message.params) {
      const entries = Object.entries(message.params);
      if (entries.length > 0) {
        obj.params = {};
        entries.forEach(([k, v]) => {
          obj.params[k] = Value.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<ExecuteQueryRequest>): ExecuteQueryRequest {
    return ExecuteQueryRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecuteQueryRequest>): ExecuteQueryRequest {
    const message = createBaseExecuteQueryRequest();
    message.instanceName = object.instanceName ?? "";
    message.appProfileId = object.appProfileId ?? "";
    message.query = object.query ?? "";
    message.protoFormat = (object.protoFormat !== undefined && object.protoFormat !== null)
      ? ProtoFormat.fromPartial(object.protoFormat)
      : undefined;
    message.resumeToken = object.resumeToken ?? Buffer.alloc(0);
    message.params = Object.entries(object.params ?? {}).reduce<{ [key: string]: Value }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = Value.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseExecuteQueryRequest_ParamsEntry(): ExecuteQueryRequest_ParamsEntry {
  return { key: "", value: undefined };
}

export const ExecuteQueryRequest_ParamsEntry: MessageFns<ExecuteQueryRequest_ParamsEntry> = {
  encode(message: ExecuteQueryRequest_ParamsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecuteQueryRequest_ParamsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecuteQueryRequest_ParamsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecuteQueryRequest_ParamsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: ExecuteQueryRequest_ParamsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<ExecuteQueryRequest_ParamsEntry>): ExecuteQueryRequest_ParamsEntry {
    return ExecuteQueryRequest_ParamsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecuteQueryRequest_ParamsEntry>): ExecuteQueryRequest_ParamsEntry {
    const message = createBaseExecuteQueryRequest_ParamsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    return message;
  },
};

function createBaseExecuteQueryResponse(): ExecuteQueryResponse {
  return { metadata: undefined, results: undefined };
}

export const ExecuteQueryResponse: MessageFns<ExecuteQueryResponse> = {
  encode(message: ExecuteQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.metadata !== undefined) {
      ResultSetMetadata.encode(message.metadata, writer.uint32(10).fork()).join();
    }
    if (message.results !== undefined) {
      PartialResultSet.encode(message.results, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecuteQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecuteQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metadata = ResultSetMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.results = PartialResultSet.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecuteQueryResponse {
    return {
      metadata: isSet(object.metadata) ? ResultSetMetadata.fromJSON(object.metadata) : undefined,
      results: isSet(object.results) ? PartialResultSet.fromJSON(object.results) : undefined,
    };
  },

  toJSON(message: ExecuteQueryResponse): unknown {
    const obj: any = {};
    if (message.metadata !== undefined) {
      obj.metadata = ResultSetMetadata.toJSON(message.metadata);
    }
    if (message.results !== undefined) {
      obj.results = PartialResultSet.toJSON(message.results);
    }
    return obj;
  },

  create(base?: DeepPartial<ExecuteQueryResponse>): ExecuteQueryResponse {
    return ExecuteQueryResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecuteQueryResponse>): ExecuteQueryResponse {
    const message = createBaseExecuteQueryResponse();
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? ResultSetMetadata.fromPartial(object.metadata)
      : undefined;
    message.results = (object.results !== undefined && object.results !== null)
      ? PartialResultSet.fromPartial(object.results)
      : undefined;
    return message;
  },
};

/** Service for reading from and writing to existing Bigtable tables. */
export type BigtableDefinition = typeof BigtableDefinition;
export const BigtableDefinition = {
  name: "Bigtable",
  fullName: "google.bigtable.v2.Bigtable",
  methods: {
    /**
     * Streams back the contents of all requested rows in key order, optionally
     * applying the same Reader filter to each. Depending on their size,
     * rows and cells may be broken up across multiple responses, but
     * atomicity of each row will still be preserved. See the
     * ReadRowsResponse documentation for details.
     */
    readRows: {
      name: "ReadRows",
      requestType: ReadRowsRequest,
      requestStream: false,
      responseType: ReadRowsResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([10, 116, 97, 98, 108, 101, 95, 110, 97, 109, 101]),
            Buffer.from([
              25,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              154,
              1,
              58,
              1,
              42,
              90,
              90,
              58,
              1,
              42,
              34,
              85,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              82,
              111,
              119,
              115,
              34,
              57,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              82,
              111,
              119,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              176,
              1,
              18,
              58,
              10,
              10,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
              18,
              96,
              10,
              20,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              18,
              72,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Returns a sample of row keys in the table. The returned row keys will
     * delimit contiguous sections of the table of approximately equal size,
     * which can be used to break up the data for distributed tasks like
     * mapreduces.
     */
    sampleRowKeys: {
      name: "SampleRowKeys",
      requestType: SampleRowKeysRequest,
      requestStream: false,
      responseType: SampleRowKeysResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([10, 116, 97, 98, 108, 101, 95, 110, 97, 109, 101]),
            Buffer.from([
              25,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              158,
              1,
              90,
              92,
              18,
              90,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
              58,
              115,
              97,
              109,
              112,
              108,
              101,
              82,
              111,
              119,
              75,
              101,
              121,
              115,
              18,
              62,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              115,
              97,
              109,
              112,
              108,
              101,
              82,
              111,
              119,
              75,
              101,
              121,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              176,
              1,
              18,
              58,
              10,
              10,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
              18,
              96,
              10,
              20,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              18,
              72,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Mutates a row atomically. Cells already present in the row are left
     * unchanged unless explicitly changed by `mutation`.
     */
    mutateRow: {
      name: "MutateRow",
      requestType: MutateRowRequest,
      requestStream: false,
      responseType: MutateRowResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              28,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              114,
              111,
              119,
              95,
              107,
              101,
              121,
              44,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
            Buffer.from([
              43,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              114,
              111,
              119,
              95,
              107,
              101,
              121,
              44,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              156,
              1,
              58,
              1,
              42,
              90,
              91,
              58,
              1,
              42,
              34,
              86,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
              58,
              109,
              117,
              116,
              97,
              116,
              101,
              82,
              111,
              119,
              34,
              58,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              117,
              116,
              97,
              116,
              101,
              82,
              111,
              119,
            ]),
          ],
          578365834: [
            Buffer.from([
              176,
              1,
              18,
              58,
              10,
              10,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
              18,
              96,
              10,
              20,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              18,
              72,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Mutates multiple rows in a batch. Each individual row is mutated
     * atomically as in MutateRow, but the entire batch is not executed
     * atomically.
     */
    mutateRows: {
      name: "MutateRows",
      requestType: MutateRowsRequest,
      requestStream: false,
      responseType: MutateRowsResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 116, 97, 98, 108, 101, 95, 110, 97, 109, 101, 44, 101, 110, 116, 114, 105, 101, 115]),
            Buffer.from([
              33,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              101,
              110,
              116,
              114,
              105,
              101,
              115,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              158,
              1,
              58,
              1,
              42,
              90,
              92,
              58,
              1,
              42,
              34,
              87,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
              58,
              109,
              117,
              116,
              97,
              116,
              101,
              82,
              111,
              119,
              115,
              34,
              59,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              117,
              116,
              97,
              116,
              101,
              82,
              111,
              119,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              176,
              1,
              18,
              58,
              10,
              10,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
              18,
              96,
              10,
              20,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              18,
              72,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Mutates a row atomically based on the output of a predicate Reader filter. */
    checkAndMutateRow: {
      name: "CheckAndMutateRow",
      requestType: CheckAndMutateRowRequest,
      requestStream: false,
      responseType: CheckAndMutateRowResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              66,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              114,
              111,
              119,
              95,
              107,
              101,
              121,
              44,
              112,
              114,
              101,
              100,
              105,
              99,
              97,
              116,
              101,
              95,
              102,
              105,
              108,
              116,
              101,
              114,
              44,
              116,
              114,
              117,
              101,
              95,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
              44,
              102,
              97,
              108,
              115,
              101,
              95,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
            ]),
            Buffer.from([
              81,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              114,
              111,
              119,
              95,
              107,
              101,
              121,
              44,
              112,
              114,
              101,
              100,
              105,
              99,
              97,
              116,
              101,
              95,
              102,
              105,
              108,
              116,
              101,
              114,
              44,
              116,
              114,
              117,
              101,
              95,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
              44,
              102,
              97,
              108,
              115,
              101,
              95,
              109,
              117,
              116,
              97,
              116,
              105,
              111,
              110,
              115,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              172,
              1,
              58,
              1,
              42,
              90,
              99,
              58,
              1,
              42,
              34,
              94,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
              58,
              99,
              104,
              101,
              99,
              107,
              65,
              110,
              100,
              77,
              117,
              116,
              97,
              116,
              101,
              82,
              111,
              119,
              34,
              66,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              99,
              104,
              101,
              99,
              107,
              65,
              110,
              100,
              77,
              117,
              116,
              97,
              116,
              101,
              82,
              111,
              119,
            ]),
          ],
          578365834: [
            Buffer.from([
              176,
              1,
              18,
              58,
              10,
              10,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
              18,
              96,
              10,
              20,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              18,
              72,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Warm up associated instance metadata for this connection.
     * This call is not required but may be useful for connection keep-alive.
     */
    pingAndWarm: {
      name: "PingAndWarm",
      requestType: PingAndWarmRequest,
      requestStream: false,
      responseType: PingAndWarmResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([4, 110, 97, 109, 101]),
            Buffer.from([19, 110, 97, 109, 101, 44, 97, 112, 112, 95, 112, 114, 111, 102, 105, 108, 101, 95, 105, 100]),
          ],
          578365826: [
            Buffer.from([
              43,
              58,
              1,
              42,
              34,
              38,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              112,
              105,
              110,
              103,
            ]),
          ],
          578365834: [
            Buffer.from([
              57,
              18,
              37,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              29,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
    /**
     * Modifies a row atomically on the server. The method reads the latest
     * existing timestamp and value from the specified columns and writes a new
     * entry based on pre-defined read/modify/write rules. The new value for the
     * timestamp is the greater of the existing timestamp or the current server
     * time. The method returns the new contents of all modified cells.
     */
    readModifyWriteRow: {
      name: "ReadModifyWriteRow",
      requestType: ReadModifyWriteRowRequest,
      requestStream: false,
      responseType: ReadModifyWriteRowResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              24,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              114,
              111,
              119,
              95,
              107,
              101,
              121,
              44,
              114,
              117,
              108,
              101,
              115,
            ]),
            Buffer.from([
              39,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              114,
              111,
              119,
              95,
              107,
              101,
              121,
              44,
              114,
              117,
              108,
              101,
              115,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              174,
              1,
              58,
              1,
              42,
              90,
              100,
              58,
              1,
              42,
              34,
              95,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              77,
              111,
              100,
              105,
              102,
              121,
              87,
              114,
              105,
              116,
              101,
              82,
              111,
              119,
              34,
              67,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              77,
              111,
              100,
              105,
              102,
              121,
              87,
              114,
              105,
              116,
              101,
              82,
              111,
              119,
            ]),
          ],
          578365834: [
            Buffer.from([
              176,
              1,
              18,
              58,
              10,
              10,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
              18,
              96,
              10,
              20,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              18,
              72,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * NOTE: This API is intended to be used by Apache Beam BigtableIO.
     * Returns the current list of partitions that make up the table's
     * change stream. The union of partitions will cover the entire keyspace.
     * Partitions can be read with `ReadChangeStream`.
     */
    generateInitialChangeStreamPartitions: {
      name: "GenerateInitialChangeStreamPartitions",
      requestType: GenerateInitialChangeStreamPartitionsRequest,
      requestStream: false,
      responseType: GenerateInitialChangeStreamPartitionsResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([10, 116, 97, 98, 108, 101, 95, 110, 97, 109, 101]),
            Buffer.from([
              25,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              91,
              58,
              1,
              42,
              34,
              86,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              101,
              73,
              110,
              105,
              116,
              105,
              97,
              108,
              67,
              104,
              97,
              110,
              103,
              101,
              83,
              116,
              114,
              101,
              97,
              109,
              80,
              97,
              114,
              116,
              105,
              116,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * NOTE: This API is intended to be used by Apache Beam BigtableIO.
     * Reads changes from a table's change stream. Changes will
     * reflect both user-initiated mutations and mutations that are caused by
     * garbage collection.
     */
    readChangeStream: {
      name: "ReadChangeStream",
      requestType: ReadChangeStreamRequest,
      requestStream: false,
      responseType: ReadChangeStreamResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([10, 116, 97, 98, 108, 101, 95, 110, 97, 109, 101]),
            Buffer.from([
              25,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              70,
              58,
              1,
              42,
              34,
              65,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              97,
              100,
              67,
              104,
              97,
              110,
              103,
              101,
              83,
              116,
              114,
              101,
              97,
              109,
            ]),
          ],
        },
      },
    },
    /** Executes a BTQL query against a particular Cloud Bigtable instance. */
    executeQuery: {
      name: "ExecuteQuery",
      requestType: ExecuteQueryRequest,
      requestStream: false,
      responseType: ExecuteQueryResponse,
      responseStream: true,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([19, 105, 110, 115, 116, 97, 110, 99, 101, 95, 110, 97, 109, 101, 44, 113, 117, 101, 114, 121]),
            Buffer.from([
              34,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              95,
              110,
              97,
              109,
              101,
              44,
              113,
              117,
              101,
              114,
              121,
              44,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              60,
              58,
              1,
              42,
              34,
              55,
              47,
              118,
              50,
              47,
              123,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              101,
              99,
              117,
              116,
              101,
              81,
              117,
              101,
              114,
              121,
            ]),
          ],
          578365834: [
            Buffer.from([
              66,
              18,
              46,
              10,
              13,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              29,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              18,
              16,
              10,
              14,
              97,
              112,
              112,
              95,
              112,
              114,
              111,
              102,
              105,
              108,
              101,
              95,
              105,
              100,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface BigtableServiceImplementation<CallContextExt = {}> {
  /**
   * Streams back the contents of all requested rows in key order, optionally
   * applying the same Reader filter to each. Depending on their size,
   * rows and cells may be broken up across multiple responses, but
   * atomicity of each row will still be preserved. See the
   * ReadRowsResponse documentation for details.
   */
  readRows(
    request: ReadRowsRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<ReadRowsResponse>>;
  /**
   * Returns a sample of row keys in the table. The returned row keys will
   * delimit contiguous sections of the table of approximately equal size,
   * which can be used to break up the data for distributed tasks like
   * mapreduces.
   */
  sampleRowKeys(
    request: SampleRowKeysRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<SampleRowKeysResponse>>;
  /**
   * Mutates a row atomically. Cells already present in the row are left
   * unchanged unless explicitly changed by `mutation`.
   */
  mutateRow(request: MutateRowRequest, context: CallContext & CallContextExt): Promise<DeepPartial<MutateRowResponse>>;
  /**
   * Mutates multiple rows in a batch. Each individual row is mutated
   * atomically as in MutateRow, but the entire batch is not executed
   * atomically.
   */
  mutateRows(
    request: MutateRowsRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<MutateRowsResponse>>;
  /** Mutates a row atomically based on the output of a predicate Reader filter. */
  checkAndMutateRow(
    request: CheckAndMutateRowRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CheckAndMutateRowResponse>>;
  /**
   * Warm up associated instance metadata for this connection.
   * This call is not required but may be useful for connection keep-alive.
   */
  pingAndWarm(
    request: PingAndWarmRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<PingAndWarmResponse>>;
  /**
   * Modifies a row atomically on the server. The method reads the latest
   * existing timestamp and value from the specified columns and writes a new
   * entry based on pre-defined read/modify/write rules. The new value for the
   * timestamp is the greater of the existing timestamp or the current server
   * time. The method returns the new contents of all modified cells.
   */
  readModifyWriteRow(
    request: ReadModifyWriteRowRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReadModifyWriteRowResponse>>;
  /**
   * NOTE: This API is intended to be used by Apache Beam BigtableIO.
   * Returns the current list of partitions that make up the table's
   * change stream. The union of partitions will cover the entire keyspace.
   * Partitions can be read with `ReadChangeStream`.
   */
  generateInitialChangeStreamPartitions(
    request: GenerateInitialChangeStreamPartitionsRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<GenerateInitialChangeStreamPartitionsResponse>>;
  /**
   * NOTE: This API is intended to be used by Apache Beam BigtableIO.
   * Reads changes from a table's change stream. Changes will
   * reflect both user-initiated mutations and mutations that are caused by
   * garbage collection.
   */
  readChangeStream(
    request: ReadChangeStreamRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<ReadChangeStreamResponse>>;
  /** Executes a BTQL query against a particular Cloud Bigtable instance. */
  executeQuery(
    request: ExecuteQueryRequest,
    context: CallContext & CallContextExt,
  ): ServerStreamingMethodResult<DeepPartial<ExecuteQueryResponse>>;
}

export interface BigtableClient<CallOptionsExt = {}> {
  /**
   * Streams back the contents of all requested rows in key order, optionally
   * applying the same Reader filter to each. Depending on their size,
   * rows and cells may be broken up across multiple responses, but
   * atomicity of each row will still be preserved. See the
   * ReadRowsResponse documentation for details.
   */
  readRows(
    request: DeepPartial<ReadRowsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<ReadRowsResponse>;
  /**
   * Returns a sample of row keys in the table. The returned row keys will
   * delimit contiguous sections of the table of approximately equal size,
   * which can be used to break up the data for distributed tasks like
   * mapreduces.
   */
  sampleRowKeys(
    request: DeepPartial<SampleRowKeysRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<SampleRowKeysResponse>;
  /**
   * Mutates a row atomically. Cells already present in the row are left
   * unchanged unless explicitly changed by `mutation`.
   */
  mutateRow(request: DeepPartial<MutateRowRequest>, options?: CallOptions & CallOptionsExt): Promise<MutateRowResponse>;
  /**
   * Mutates multiple rows in a batch. Each individual row is mutated
   * atomically as in MutateRow, but the entire batch is not executed
   * atomically.
   */
  mutateRows(
    request: DeepPartial<MutateRowsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<MutateRowsResponse>;
  /** Mutates a row atomically based on the output of a predicate Reader filter. */
  checkAndMutateRow(
    request: DeepPartial<CheckAndMutateRowRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CheckAndMutateRowResponse>;
  /**
   * Warm up associated instance metadata for this connection.
   * This call is not required but may be useful for connection keep-alive.
   */
  pingAndWarm(
    request: DeepPartial<PingAndWarmRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<PingAndWarmResponse>;
  /**
   * Modifies a row atomically on the server. The method reads the latest
   * existing timestamp and value from the specified columns and writes a new
   * entry based on pre-defined read/modify/write rules. The new value for the
   * timestamp is the greater of the existing timestamp or the current server
   * time. The method returns the new contents of all modified cells.
   */
  readModifyWriteRow(
    request: DeepPartial<ReadModifyWriteRowRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReadModifyWriteRowResponse>;
  /**
   * NOTE: This API is intended to be used by Apache Beam BigtableIO.
   * Returns the current list of partitions that make up the table's
   * change stream. The union of partitions will cover the entire keyspace.
   * Partitions can be read with `ReadChangeStream`.
   */
  generateInitialChangeStreamPartitions(
    request: DeepPartial<GenerateInitialChangeStreamPartitionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<GenerateInitialChangeStreamPartitionsResponse>;
  /**
   * NOTE: This API is intended to be used by Apache Beam BigtableIO.
   * Reads changes from a table's change stream. Changes will
   * reflect both user-initiated mutations and mutations that are caused by
   * garbage collection.
   */
  readChangeStream(
    request: DeepPartial<ReadChangeStreamRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<ReadChangeStreamResponse>;
  /** Executes a BTQL query against a particular Cloud Bigtable instance. */
  executeQuery(
    request: DeepPartial<ExecuteQueryRequest>,
    options?: CallOptions & CallOptionsExt,
  ): AsyncIterable<ExecuteQueryResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export type ServerStreamingMethodResult<Response> = { [Symbol.asyncIterator](): AsyncIterator<Response, void> };

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
