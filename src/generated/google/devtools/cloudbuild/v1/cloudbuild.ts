// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/devtools/cloudbuild/v1/cloudbuild.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { HttpBody } from "../../../api/httpbody.js";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.devtools.cloudbuild.v1";

/** Specifies a build to retry. */
export interface RetryBuildRequest {
  /**
   * The name of the `Build` to retry.
   * Format: `projects/{project}/locations/{location}/builds/{build}`
   */
  name: string;
  /** Required. ID of the project. */
  projectId: string;
  /** Required. Build ID of the original build. */
  id: string;
}

/** Specifies a build trigger to run and the source to use. */
export interface RunBuildTriggerRequest {
  /**
   * The name of the `Trigger` to run.
   * Format: `projects/{project}/locations/{location}/triggers/{trigger}`
   */
  name: string;
  /** Required. ID of the project. */
  projectId: string;
  /** Required. ID of the trigger. */
  triggerId: string;
  /**
   * Source to build against this trigger.
   * Branch and tag names cannot consist of regular expressions.
   */
  source: RepoSource | undefined;
}

/** Location of the source in an archive file in Cloud Storage. */
export interface StorageSource {
  /**
   * Cloud Storage bucket containing the source (see
   * [Bucket Name
   * Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).
   */
  bucket: string;
  /**
   * Cloud Storage object containing the source.
   *
   * This object must be a zipped (`.zip`) or gzipped archive file (`.tar.gz`)
   * containing source to build.
   */
  object: string;
  /**
   * Cloud Storage generation for the object. If the generation is
   * omitted, the latest generation will be used.
   */
  generation: Long;
  /** Option to specify the tool to fetch the source file for the build. */
  sourceFetcher: StorageSource_SourceFetcher;
}

/** Specifies the tool to fetch the source file for the build. */
export enum StorageSource_SourceFetcher {
  /** SOURCE_FETCHER_UNSPECIFIED - Unspecified. Defaults to GSUTIL. */
  SOURCE_FETCHER_UNSPECIFIED = 0,
  /** GSUTIL - Use the "gsutil" tool to download the source file. */
  GSUTIL = 1,
  /** GCS_FETCHER - Use the Cloud Storage Fetcher tool to download the source file. */
  GCS_FETCHER = 2,
  UNRECOGNIZED = -1,
}

export function storageSource_SourceFetcherFromJSON(object: any): StorageSource_SourceFetcher {
  switch (object) {
    case 0:
    case "SOURCE_FETCHER_UNSPECIFIED":
      return StorageSource_SourceFetcher.SOURCE_FETCHER_UNSPECIFIED;
    case 1:
    case "GSUTIL":
      return StorageSource_SourceFetcher.GSUTIL;
    case 2:
    case "GCS_FETCHER":
      return StorageSource_SourceFetcher.GCS_FETCHER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StorageSource_SourceFetcher.UNRECOGNIZED;
  }
}

export function storageSource_SourceFetcherToJSON(object: StorageSource_SourceFetcher): string {
  switch (object) {
    case StorageSource_SourceFetcher.SOURCE_FETCHER_UNSPECIFIED:
      return "SOURCE_FETCHER_UNSPECIFIED";
    case StorageSource_SourceFetcher.GSUTIL:
      return "GSUTIL";
    case StorageSource_SourceFetcher.GCS_FETCHER:
      return "GCS_FETCHER";
    case StorageSource_SourceFetcher.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Location of the source in any accessible Git repository. */
export interface GitSource {
  /**
   * Location of the Git repo to build.
   *
   * This will be used as a `git remote`, see
   * https://git-scm.com/docs/git-remote.
   */
  url: string;
  /**
   * Directory, relative to the source root, in which to run the build.
   *
   * This must be a relative path. If a step's `dir` is specified and is an
   * absolute path, this value is ignored for that step's execution.
   */
  dir: string;
  /**
   * The revision to fetch from the Git repository such as a branch, a tag, a
   * commit SHA, or any Git ref.
   *
   * Cloud Build uses `git fetch` to fetch the revision from the Git
   * repository; therefore make sure that the string you provide for `revision`
   * is parsable  by the command. For information on string values accepted by
   * `git fetch`, see
   * https://git-scm.com/docs/gitrevisions#_specifying_revisions. For
   * information on `git fetch`, see https://git-scm.com/docs/git-fetch.
   */
  revision: string;
}

/** Location of the source in a Google Cloud Source Repository. */
export interface RepoSource {
  /**
   * ID of the project that owns the Cloud Source Repository. If omitted, the
   * project ID requesting the build is assumed.
   */
  projectId: string;
  /** Name of the Cloud Source Repository. */
  repoName: string;
  /**
   * Regex matching branches to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  branchName?:
    | string
    | undefined;
  /**
   * Regex matching tags to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  tagName?:
    | string
    | undefined;
  /** Explicit commit SHA to build. */
  commitSha?:
    | string
    | undefined;
  /**
   * Directory, relative to the source root, in which to run the build.
   *
   * This must be a relative path. If a step's `dir` is specified and is an
   * absolute path, this value is ignored for that step's execution.
   */
  dir: string;
  /**
   * Only trigger a build if the revision regex does NOT match the revision
   * regex.
   */
  invertRegex: boolean;
  /**
   * Substitutions to use in a triggered build.
   * Should only be used with RunBuildTrigger
   */
  substitutions: { [key: string]: string };
}

export interface RepoSource_SubstitutionsEntry {
  key: string;
  value: string;
}

/**
 * Location of the source manifest in Cloud Storage.
 * This feature is in Preview; see description
 * [here](https://github.com/GoogleCloudPlatform/cloud-builders/tree/master/gcs-fetcher).
 */
export interface StorageSourceManifest {
  /**
   * Cloud Storage bucket containing the source manifest (see [Bucket
   * Name
   * Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).
   */
  bucket: string;
  /**
   * Cloud Storage object containing the source manifest.
   *
   * This object must be a JSON file.
   */
  object: string;
  /**
   * Cloud Storage generation for the object. If the generation is
   * omitted, the latest generation will be used.
   */
  generation: Long;
}

/** Location of the source in a supported storage service. */
export interface Source {
  /** If provided, get the source from this location in Cloud Storage. */
  storageSource?:
    | StorageSource
    | undefined;
  /**
   * If provided, get the source from this location in a Cloud Source
   * Repository.
   */
  repoSource?:
    | RepoSource
    | undefined;
  /** If provided, get the source from this Git repository. */
  gitSource?:
    | GitSource
    | undefined;
  /**
   * If provided, get the source from this manifest in Cloud Storage.
   * This feature is in Preview; see description
   * [here](https://github.com/GoogleCloudPlatform/cloud-builders/tree/master/gcs-fetcher).
   */
  storageSourceManifest?: StorageSourceManifest | undefined;
}

/** An image built by the pipeline. */
export interface BuiltImage {
  /**
   * Name used to push the container image to Google Container Registry, as
   * presented to `docker push`.
   */
  name: string;
  /** Docker Registry 2.0 digest. */
  digest: string;
  /** Output only. Stores timing information for pushing the specified image. */
  pushTiming: TimeSpan | undefined;
}

/** Artifact uploaded using the PythonPackage directive. */
export interface UploadedPythonPackage {
  /** URI of the uploaded artifact. */
  uri: string;
  /** Hash types and values of the Python Artifact. */
  fileHashes:
    | FileHashes
    | undefined;
  /** Output only. Stores timing information for pushing the specified artifact. */
  pushTiming: TimeSpan | undefined;
}

/** A Maven artifact uploaded using the MavenArtifact directive. */
export interface UploadedMavenArtifact {
  /** URI of the uploaded artifact. */
  uri: string;
  /** Hash types and values of the Maven Artifact. */
  fileHashes:
    | FileHashes
    | undefined;
  /** Output only. Stores timing information for pushing the specified artifact. */
  pushTiming: TimeSpan | undefined;
}

/**
 * An npm package uploaded to Artifact Registry using the NpmPackage
 * directive.
 */
export interface UploadedNpmPackage {
  /** URI of the uploaded npm package. */
  uri: string;
  /** Hash types and values of the npm package. */
  fileHashes:
    | FileHashes
    | undefined;
  /** Output only. Stores timing information for pushing the specified artifact. */
  pushTiming: TimeSpan | undefined;
}

/** A step in the build pipeline. */
export interface BuildStep {
  /**
   * Required. The name of the container image that will run this particular
   * build step.
   *
   * If the image is available in the host's Docker daemon's cache, it
   * will be run directly. If not, the host will attempt to pull the image
   * first, using the builder service account's credentials if necessary.
   *
   * The Docker daemon's cache will already have the latest versions of all of
   * the officially supported build steps
   * ([https://github.com/GoogleCloudPlatform/cloud-builders](https://github.com/GoogleCloudPlatform/cloud-builders)).
   * The Docker daemon will also have cached many of the layers for some popular
   * images, like "ubuntu", "debian", but they will be refreshed at the time you
   * attempt to use them.
   *
   * If you built an image in a previous build step, it will be stored in the
   * host's Docker daemon's cache and is available to use as the name for a
   * later build step.
   */
  name: string;
  /**
   * A list of environment variable definitions to be used when running a step.
   *
   * The elements are of the form "KEY=VALUE" for the environment variable "KEY"
   * being given the value "VALUE".
   */
  env: string[];
  /**
   * A list of arguments that will be presented to the step when it is started.
   *
   * If the image used to run the step's container has an entrypoint, the `args`
   * are used as arguments to that entrypoint. If the image does not define
   * an entrypoint, the first element in args is used as the entrypoint,
   * and the remainder will be used as arguments.
   */
  args: string[];
  /**
   * Working directory to use when running this step's container.
   *
   * If this value is a relative path, it is relative to the build's working
   * directory. If this value is absolute, it may be outside the build's working
   * directory, in which case the contents of the path may not be persisted
   * across build step executions, unless a `volume` for that path is specified.
   *
   * If the build specifies a `RepoSource` with `dir` and a step with a `dir`,
   * which specifies an absolute path, the `RepoSource` `dir` is ignored for
   * the step's execution.
   */
  dir: string;
  /**
   * Unique identifier for this build step, used in `wait_for` to
   * reference this build step as a dependency.
   */
  id: string;
  /**
   * The ID(s) of the step(s) that this build step depends on.
   * This build step will not start until all the build steps in `wait_for`
   * have completed successfully. If `wait_for` is empty, this build step will
   * start when all previous build steps in the `Build.Steps` list have
   * completed successfully.
   */
  waitFor: string[];
  /**
   * Entrypoint to be used instead of the build step image's default entrypoint.
   * If unset, the image's default entrypoint is used.
   */
  entrypoint: string;
  /**
   * A list of environment variables which are encrypted using a Cloud Key
   * Management Service crypto key. These values must be specified in the
   * build's `Secret`.
   */
  secretEnv: string[];
  /**
   * List of volumes to mount into the build step.
   *
   * Each volume is created as an empty volume prior to execution of the
   * build step. Upon completion of the build, volumes and their contents are
   * discarded.
   *
   * Using a named volume in only one step is not valid as it is indicative
   * of a build request with an incorrect configuration.
   */
  volumes: Volume[];
  /** Output only. Stores timing information for executing this build step. */
  timing:
    | TimeSpan
    | undefined;
  /**
   * Output only. Stores timing information for pulling this build step's
   * builder image only.
   */
  pullTiming:
    | TimeSpan
    | undefined;
  /**
   * Time limit for executing this build step. If not defined, the step has no
   * time limit and will be allowed to continue to run until either it completes
   * or the build itself times out.
   */
  timeout:
    | Duration
    | undefined;
  /**
   * Output only. Status of the build step. At this time, build step status is
   * only updated on build completion; step status is not updated in real-time
   * as the build progresses.
   */
  status: Build_Status;
  /**
   * Allow this build step to fail without failing the entire build.
   *
   * If false, the entire build will fail if this step fails. Otherwise, the
   * build will succeed, but this step will still have a failure status.
   * Error information will be reported in the failure_detail field.
   */
  allowFailure: boolean;
  /** Output only. Return code from running the step. */
  exitCode: number;
  /**
   * Allow this build step to fail without failing the entire build if and
   * only if the exit code is one of the specified codes. If allow_failure
   * is also specified, this field will take precedence.
   */
  allowExitCodes: number[];
  /**
   * A shell script to be executed in the step.
   *
   * When script is provided, the user cannot specify the entrypoint or args.
   */
  script: string;
  /**
   * Option to include built-in and custom substitutions as env variables
   * for this build step. This option will override the global option
   * in BuildOption.
   */
  automapSubstitutions?: boolean | undefined;
}

/**
 * Volume describes a Docker container volume which is mounted into build steps
 * in order to persist files across build step execution.
 */
export interface Volume {
  /**
   * Name of the volume to mount.
   *
   * Volume names must be unique per build step and must be valid names for
   * Docker volumes. Each named volume must be used by at least two build steps.
   */
  name: string;
  /**
   * Path at which to mount the volume.
   *
   * Paths must be absolute and cannot conflict with other volume paths on the
   * same build step or with certain reserved volume paths.
   */
  path: string;
}

/** Artifacts created by the build pipeline. */
export interface Results {
  /** Container images that were built as a part of the build. */
  images: BuiltImage[];
  /**
   * List of build step digests, in the order corresponding to build step
   * indices.
   */
  buildStepImages: string[];
  /**
   * Path to the artifact manifest for non-container artifacts uploaded to Cloud
   * Storage. Only populated when artifacts are uploaded to Cloud Storage.
   */
  artifactManifest: string;
  /**
   * Number of non-container artifacts uploaded to Cloud Storage. Only populated
   * when artifacts are uploaded to Cloud Storage.
   */
  numArtifacts: Long;
  /**
   * List of build step outputs, produced by builder images, in the order
   * corresponding to build step indices.
   *
   * [Cloud Builders](https://cloud.google.com/cloud-build/docs/cloud-builders)
   * can produce this output by writing to `$BUILDER_OUTPUT/output`.
   * Only the first 4KB of data is stored.
   */
  buildStepOutputs: Buffer[];
  /** Time to push all non-container artifacts to Cloud Storage. */
  artifactTiming:
    | TimeSpan
    | undefined;
  /** Python artifacts uploaded to Artifact Registry at the end of the build. */
  pythonPackages: UploadedPythonPackage[];
  /** Maven artifacts uploaded to Artifact Registry at the end of the build. */
  mavenArtifacts: UploadedMavenArtifact[];
  /** Npm packages uploaded to Artifact Registry at the end of the build. */
  npmPackages: UploadedNpmPackage[];
}

/**
 * An artifact that was uploaded during a build. This
 * is a single record in the artifact manifest JSON file.
 */
export interface ArtifactResult {
  /**
   * The path of an artifact in a Cloud Storage bucket, with the
   * generation number. For example,
   * `gs://mybucket/path/to/output.jar#generation`.
   */
  location: string;
  /** The file hash of the artifact. */
  fileHash: FileHashes[];
}

/**
 * A build resource in the Cloud Build API.
 *
 * At a high level, a `Build` describes where to find source code, how to build
 * it (for example, the builder image to run on the source), and where to store
 * the built artifacts.
 *
 * Fields can include the following variables, which will be expanded when the
 * build is created:
 *
 * - $PROJECT_ID: the project ID of the build.
 * - $PROJECT_NUMBER: the project number of the build.
 * - $LOCATION: the location/region of the build.
 * - $BUILD_ID: the autogenerated ID of the build.
 * - $REPO_NAME: the source repository name specified by RepoSource.
 * - $BRANCH_NAME: the branch name specified by RepoSource.
 * - $TAG_NAME: the tag name specified by RepoSource.
 * - $REVISION_ID or $COMMIT_SHA: the commit SHA specified by RepoSource or
 *   resolved from the specified branch or tag.
 * - $SHORT_SHA: first 7 characters of $REVISION_ID or $COMMIT_SHA.
 */
export interface Build {
  /**
   * Output only. The 'Build' name with format:
   * `projects/{project}/locations/{location}/builds/{build}`, where {build}
   * is a unique identifier generated by the service.
   */
  name: string;
  /** Output only. Unique identifier of the build. */
  id: string;
  /** Output only. ID of the project. */
  projectId: string;
  /** Output only. Status of the build. */
  status: Build_Status;
  /** Output only. Customer-readable message about the current status. */
  statusDetail: string;
  /** The location of the source files to build. */
  source:
    | Source
    | undefined;
  /** Required. The operations to be performed on the workspace. */
  steps: BuildStep[];
  /** Output only. Results of the build. */
  results:
    | Results
    | undefined;
  /** Output only. Time at which the request to create the build was received. */
  createTime:
    | Date
    | undefined;
  /** Output only. Time at which execution of the build was started. */
  startTime:
    | Date
    | undefined;
  /**
   * Output only. Time at which execution of the build was finished.
   *
   * The difference between finish_time and start_time is the duration of the
   * build's execution.
   */
  finishTime:
    | Date
    | undefined;
  /**
   * Amount of time that this build should be allowed to run, to second
   * granularity. If this amount of time elapses, work on the build will cease
   * and the build status will be `TIMEOUT`.
   *
   * `timeout` starts ticking from `startTime`.
   *
   * Default time is 60 minutes.
   */
  timeout:
    | Duration
    | undefined;
  /**
   * A list of images to be pushed upon the successful completion of all build
   * steps.
   *
   * The images are pushed using the builder service account's credentials.
   *
   * The digests of the pushed images will be stored in the `Build` resource's
   * results field.
   *
   * If any of the images fail to be pushed, the build status is marked
   * `FAILURE`.
   */
  images: string[];
  /**
   * TTL in queue for this build. If provided and the build is enqueued longer
   * than this value, the build will expire and the build status will be
   * `EXPIRED`.
   *
   * The TTL starts ticking from create_time.
   */
  queueTtl:
    | Duration
    | undefined;
  /**
   * Artifacts produced by the build that should be uploaded upon
   * successful completion of all build steps.
   */
  artifacts:
    | Artifacts
    | undefined;
  /**
   * Cloud Storage bucket where logs should be written (see
   * [Bucket Name
   * Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).
   * Logs file names will be of the format `${logs_bucket}/log-${build_id}.txt`.
   */
  logsBucket: string;
  /** Output only. A permanent fixed identifier for source. */
  sourceProvenance:
    | SourceProvenance
    | undefined;
  /**
   * Output only. The ID of the `BuildTrigger` that triggered this build, if it
   * was triggered automatically.
   */
  buildTriggerId: string;
  /** Special options for this build. */
  options:
    | BuildOptions
    | undefined;
  /** Output only. URL to logs for this build in Google Cloud Console. */
  logUrl: string;
  /** Substitutions data for `Build` resource. */
  substitutions: { [key: string]: string };
  /** Tags for annotation of a `Build`. These are not docker tags. */
  tags: string[];
  /**
   * Secrets to decrypt using Cloud Key Management Service.
   * Note: Secret Manager is the recommended technique
   * for managing sensitive data with Cloud Build. Use `available_secrets` to
   * configure builds to access secrets from Secret Manager. For instructions,
   * see: https://cloud.google.com/cloud-build/docs/securing-builds/use-secrets
   */
  secrets: Secret[];
  /**
   * Output only. Stores timing information for phases of the build. Valid keys
   * are:
   *
   * * BUILD: time to execute all build steps.
   * * PUSH: time to push all artifacts including docker images and non docker
   * artifacts.
   * * FETCHSOURCE: time to fetch source.
   * * SETUPBUILD: time to set up build.
   *
   * If the build does not specify source or images,
   * these keys will not be included.
   */
  timing: { [key: string]: TimeSpan };
  /**
   * Output only. Describes this build's approval configuration, status,
   * and result.
   */
  approval:
    | BuildApproval
    | undefined;
  /**
   * IAM service account whose credentials will be used at build runtime.
   * Must be of the format `projects/{PROJECT_ID}/serviceAccounts/{ACCOUNT}`.
   * ACCOUNT can be email address or uniqueId of the service account.
   */
  serviceAccount: string;
  /** Secrets and secret environment variables. */
  availableSecrets:
    | Secrets
    | undefined;
  /**
   * Output only. Non-fatal problems encountered during the execution of the
   * build.
   */
  warnings: Build_Warning[];
  /** Output only. Contains information about the build when status=FAILURE. */
  failureInfo: Build_FailureInfo | undefined;
}

/** Possible status of a build or build step. */
export enum Build_Status {
  /** STATUS_UNKNOWN - Status of the build is unknown. */
  STATUS_UNKNOWN = 0,
  /**
   * PENDING - Build has been created and is pending execution and queuing. It has not
   * been queued.
   */
  PENDING = 10,
  /** QUEUED - Build or step is queued; work has not yet begun. */
  QUEUED = 1,
  /** WORKING - Build or step is being executed. */
  WORKING = 2,
  /** SUCCESS - Build or step finished successfully. */
  SUCCESS = 3,
  /** FAILURE - Build or step failed to complete successfully. */
  FAILURE = 4,
  /** INTERNAL_ERROR - Build or step failed due to an internal cause. */
  INTERNAL_ERROR = 5,
  /** TIMEOUT - Build or step took longer than was allowed. */
  TIMEOUT = 6,
  /** CANCELLED - Build or step was canceled by a user. */
  CANCELLED = 7,
  /** EXPIRED - Build was enqueued for longer than the value of `queue_ttl`. */
  EXPIRED = 9,
  UNRECOGNIZED = -1,
}

export function build_StatusFromJSON(object: any): Build_Status {
  switch (object) {
    case 0:
    case "STATUS_UNKNOWN":
      return Build_Status.STATUS_UNKNOWN;
    case 10:
    case "PENDING":
      return Build_Status.PENDING;
    case 1:
    case "QUEUED":
      return Build_Status.QUEUED;
    case 2:
    case "WORKING":
      return Build_Status.WORKING;
    case 3:
    case "SUCCESS":
      return Build_Status.SUCCESS;
    case 4:
    case "FAILURE":
      return Build_Status.FAILURE;
    case 5:
    case "INTERNAL_ERROR":
      return Build_Status.INTERNAL_ERROR;
    case 6:
    case "TIMEOUT":
      return Build_Status.TIMEOUT;
    case 7:
    case "CANCELLED":
      return Build_Status.CANCELLED;
    case 9:
    case "EXPIRED":
      return Build_Status.EXPIRED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Build_Status.UNRECOGNIZED;
  }
}

export function build_StatusToJSON(object: Build_Status): string {
  switch (object) {
    case Build_Status.STATUS_UNKNOWN:
      return "STATUS_UNKNOWN";
    case Build_Status.PENDING:
      return "PENDING";
    case Build_Status.QUEUED:
      return "QUEUED";
    case Build_Status.WORKING:
      return "WORKING";
    case Build_Status.SUCCESS:
      return "SUCCESS";
    case Build_Status.FAILURE:
      return "FAILURE";
    case Build_Status.INTERNAL_ERROR:
      return "INTERNAL_ERROR";
    case Build_Status.TIMEOUT:
      return "TIMEOUT";
    case Build_Status.CANCELLED:
      return "CANCELLED";
    case Build_Status.EXPIRED:
      return "EXPIRED";
    case Build_Status.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A non-fatal problem encountered during the execution of the build. */
export interface Build_Warning {
  /** Explanation of the warning generated. */
  text: string;
  /** The priority for this warning. */
  priority: Build_Warning_Priority;
}

/** The relative importance of this warning. */
export enum Build_Warning_Priority {
  /** PRIORITY_UNSPECIFIED - Should not be used. */
  PRIORITY_UNSPECIFIED = 0,
  /** INFO - e.g. deprecation warnings and alternative feature highlights. */
  INFO = 1,
  /** WARNING - e.g. automated detection of possible issues with the build. */
  WARNING = 2,
  /** ALERT - e.g. alerts that a feature used in the build is pending removal */
  ALERT = 3,
  UNRECOGNIZED = -1,
}

export function build_Warning_PriorityFromJSON(object: any): Build_Warning_Priority {
  switch (object) {
    case 0:
    case "PRIORITY_UNSPECIFIED":
      return Build_Warning_Priority.PRIORITY_UNSPECIFIED;
    case 1:
    case "INFO":
      return Build_Warning_Priority.INFO;
    case 2:
    case "WARNING":
      return Build_Warning_Priority.WARNING;
    case 3:
    case "ALERT":
      return Build_Warning_Priority.ALERT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Build_Warning_Priority.UNRECOGNIZED;
  }
}

export function build_Warning_PriorityToJSON(object: Build_Warning_Priority): string {
  switch (object) {
    case Build_Warning_Priority.PRIORITY_UNSPECIFIED:
      return "PRIORITY_UNSPECIFIED";
    case Build_Warning_Priority.INFO:
      return "INFO";
    case Build_Warning_Priority.WARNING:
      return "WARNING";
    case Build_Warning_Priority.ALERT:
      return "ALERT";
    case Build_Warning_Priority.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A fatal problem encountered during the execution of the build. */
export interface Build_FailureInfo {
  /** The name of the failure. */
  type: Build_FailureInfo_FailureType;
  /** Explains the failure issue in more detail using hard-coded text. */
  detail: string;
}

/**
 * The name of a fatal problem encountered during the execution of the
 * build.
 */
export enum Build_FailureInfo_FailureType {
  /** FAILURE_TYPE_UNSPECIFIED - Type unspecified */
  FAILURE_TYPE_UNSPECIFIED = 0,
  /** PUSH_FAILED - Unable to push the image to the repository. */
  PUSH_FAILED = 1,
  /** PUSH_IMAGE_NOT_FOUND - Final image not found. */
  PUSH_IMAGE_NOT_FOUND = 2,
  /** PUSH_NOT_AUTHORIZED - Unauthorized push of the final image. */
  PUSH_NOT_AUTHORIZED = 3,
  /** LOGGING_FAILURE - Backend logging failures. Should retry. */
  LOGGING_FAILURE = 4,
  /** USER_BUILD_STEP - A build step has failed. */
  USER_BUILD_STEP = 5,
  /** FETCH_SOURCE_FAILED - The source fetching has failed. */
  FETCH_SOURCE_FAILED = 6,
  UNRECOGNIZED = -1,
}

export function build_FailureInfo_FailureTypeFromJSON(object: any): Build_FailureInfo_FailureType {
  switch (object) {
    case 0:
    case "FAILURE_TYPE_UNSPECIFIED":
      return Build_FailureInfo_FailureType.FAILURE_TYPE_UNSPECIFIED;
    case 1:
    case "PUSH_FAILED":
      return Build_FailureInfo_FailureType.PUSH_FAILED;
    case 2:
    case "PUSH_IMAGE_NOT_FOUND":
      return Build_FailureInfo_FailureType.PUSH_IMAGE_NOT_FOUND;
    case 3:
    case "PUSH_NOT_AUTHORIZED":
      return Build_FailureInfo_FailureType.PUSH_NOT_AUTHORIZED;
    case 4:
    case "LOGGING_FAILURE":
      return Build_FailureInfo_FailureType.LOGGING_FAILURE;
    case 5:
    case "USER_BUILD_STEP":
      return Build_FailureInfo_FailureType.USER_BUILD_STEP;
    case 6:
    case "FETCH_SOURCE_FAILED":
      return Build_FailureInfo_FailureType.FETCH_SOURCE_FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Build_FailureInfo_FailureType.UNRECOGNIZED;
  }
}

export function build_FailureInfo_FailureTypeToJSON(object: Build_FailureInfo_FailureType): string {
  switch (object) {
    case Build_FailureInfo_FailureType.FAILURE_TYPE_UNSPECIFIED:
      return "FAILURE_TYPE_UNSPECIFIED";
    case Build_FailureInfo_FailureType.PUSH_FAILED:
      return "PUSH_FAILED";
    case Build_FailureInfo_FailureType.PUSH_IMAGE_NOT_FOUND:
      return "PUSH_IMAGE_NOT_FOUND";
    case Build_FailureInfo_FailureType.PUSH_NOT_AUTHORIZED:
      return "PUSH_NOT_AUTHORIZED";
    case Build_FailureInfo_FailureType.LOGGING_FAILURE:
      return "LOGGING_FAILURE";
    case Build_FailureInfo_FailureType.USER_BUILD_STEP:
      return "USER_BUILD_STEP";
    case Build_FailureInfo_FailureType.FETCH_SOURCE_FAILED:
      return "FETCH_SOURCE_FAILED";
    case Build_FailureInfo_FailureType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Build_SubstitutionsEntry {
  key: string;
  value: string;
}

export interface Build_TimingEntry {
  key: string;
  value: TimeSpan | undefined;
}

/**
 * Artifacts produced by a build that should be uploaded upon
 * successful completion of all build steps.
 */
export interface Artifacts {
  /**
   * A list of images to be pushed upon the successful completion of all build
   * steps.
   *
   * The images will be pushed using the builder service account's credentials.
   *
   * The digests of the pushed images will be stored in the Build resource's
   * results field.
   *
   * If any of the images fail to be pushed, the build is marked FAILURE.
   */
  images: string[];
  /**
   * A list of objects to be uploaded to Cloud Storage upon successful
   * completion of all build steps.
   *
   * Files in the workspace matching specified paths globs will be uploaded to
   * the specified Cloud Storage location using the builder service account's
   * credentials.
   *
   * The location and generation of the uploaded objects will be stored in the
   * Build resource's results field.
   *
   * If any objects fail to be pushed, the build is marked FAILURE.
   */
  objects:
    | Artifacts_ArtifactObjects
    | undefined;
  /**
   * A list of Maven artifacts to be uploaded to Artifact Registry upon
   * successful completion of all build steps.
   *
   * Artifacts in the workspace matching specified paths globs will be uploaded
   * to the specified Artifact Registry repository using the builder service
   * account's credentials.
   *
   * If any artifacts fail to be pushed, the build is marked FAILURE.
   */
  mavenArtifacts: Artifacts_MavenArtifact[];
  /**
   * A list of Python packages to be uploaded to Artifact Registry upon
   * successful completion of all build steps.
   *
   * The build service account credentials will be used to perform the upload.
   *
   * If any objects fail to be pushed, the build is marked FAILURE.
   */
  pythonPackages: Artifacts_PythonPackage[];
  /**
   * A list of npm packages to be uploaded to Artifact Registry upon
   * successful completion of all build steps.
   *
   * Npm packages in the specified paths will be uploaded
   * to the specified Artifact Registry repository using the builder service
   * account's credentials.
   *
   * If any packages fail to be pushed, the build is marked FAILURE.
   */
  npmPackages: Artifacts_NpmPackage[];
}

/**
 * Files in the workspace to upload to Cloud Storage upon successful
 * completion of all build steps.
 */
export interface Artifacts_ArtifactObjects {
  /**
   * Cloud Storage bucket and optional object path, in the form
   * "gs://bucket/path/to/somewhere/". (see [Bucket Name
   * Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).
   *
   * Files in the workspace matching any path pattern will be uploaded to
   * Cloud Storage with this location as a prefix.
   */
  location: string;
  /** Path globs used to match files in the build's workspace. */
  paths: string[];
  /** Output only. Stores timing information for pushing all artifact objects. */
  timing: TimeSpan | undefined;
}

/**
 * A Maven artifact to upload to Artifact Registry upon successful completion
 * of all build steps.
 */
export interface Artifacts_MavenArtifact {
  /**
   * Artifact Registry repository, in the form
   * "https://$REGION-maven.pkg.dev/$PROJECT/$REPOSITORY"
   *
   * Artifact in the workspace specified by path will be uploaded to
   * Artifact Registry with this location as a prefix.
   */
  repository: string;
  /**
   * Path to an artifact in the build's workspace to be uploaded to
   * Artifact Registry.
   * This can be either an absolute path,
   * e.g. /workspace/my-app/target/my-app-1.0.SNAPSHOT.jar
   * or a relative path from /workspace,
   * e.g. my-app/target/my-app-1.0.SNAPSHOT.jar.
   */
  path: string;
  /**
   * Maven `artifactId` value used when uploading the artifact to Artifact
   * Registry.
   */
  artifactId: string;
  /**
   * Maven `groupId` value used when uploading the artifact to Artifact
   * Registry.
   */
  groupId: string;
  /**
   * Maven `version` value used when uploading the artifact to Artifact
   * Registry.
   */
  version: string;
}

/**
 * Python package to upload to Artifact Registry upon successful completion
 * of all build steps. A package can encapsulate multiple objects to be
 * uploaded to a single repository.
 */
export interface Artifacts_PythonPackage {
  /**
   * Artifact Registry repository, in the form
   * "https://$REGION-python.pkg.dev/$PROJECT/$REPOSITORY"
   *
   * Files in the workspace matching any path pattern will be uploaded to
   * Artifact Registry with this location as a prefix.
   */
  repository: string;
  /**
   * Path globs used to match files in the build's workspace. For Python/
   * Twine, this is usually `dist/*`, and sometimes additionally an `.asc`
   * file.
   */
  paths: string[];
}

/**
 * Npm package to upload to Artifact Registry upon successful completion
 * of all build steps.
 */
export interface Artifacts_NpmPackage {
  /**
   * Artifact Registry repository, in the form
   * "https://$REGION-npm.pkg.dev/$PROJECT/$REPOSITORY"
   *
   * Npm package in the workspace specified by path will be zipped and
   * uploaded to Artifact Registry with this location as a prefix.
   */
  repository: string;
  /**
   * Path to the package.json.
   * e.g. workspace/path/to/package
   */
  packagePath: string;
}

/** Start and end times for a build execution phase. */
export interface TimeSpan {
  /** Start of time span. */
  startTime:
    | Date
    | undefined;
  /** End of time span. */
  endTime: Date | undefined;
}

/** Metadata for build operations. */
export interface BuildOperationMetadata {
  /** The build that the operation is tracking. */
  build: Build | undefined;
}

/**
 * Provenance of the source. Ways to find the original source, or verify that
 * some source was used for this build.
 */
export interface SourceProvenance {
  /**
   * A copy of the build's `source.storage_source`, if exists, with any
   * generations resolved.
   */
  resolvedStorageSource:
    | StorageSource
    | undefined;
  /**
   * A copy of the build's `source.repo_source`, if exists, with any
   * revisions resolved.
   */
  resolvedRepoSource:
    | RepoSource
    | undefined;
  /**
   * A copy of the build's `source.storage_source_manifest`, if exists, with any
   * revisions resolved.
   * This feature is in Preview.
   */
  resolvedStorageSourceManifest:
    | StorageSourceManifest
    | undefined;
  /**
   * Output only. Hash(es) of the build source, which can be used to verify that
   * the original source integrity was maintained in the build. Note that
   * `FileHashes` will only be populated if `BuildOptions` has requested a
   * `SourceProvenanceHash`.
   *
   * The keys to this map are file paths used as build source and the values
   * contain the hash values for those files.
   *
   * If the build source came in a single package such as a gzipped tarfile
   * (`.tar.gz`), the `FileHash` will be for the single path to that file.
   */
  fileHashes: { [key: string]: FileHashes };
}

export interface SourceProvenance_FileHashesEntry {
  key: string;
  value: FileHashes | undefined;
}

/**
 * Container message for hashes of byte content of files, used in
 * SourceProvenance messages to verify integrity of source input to the build.
 */
export interface FileHashes {
  /** Collection of file hashes. */
  fileHash: Hash[];
}

/** Container message for hash values. */
export interface Hash {
  /** The type of hash that was performed. */
  type: Hash_HashType;
  /** The hash value. */
  value: Buffer;
}

/** Specifies the hash algorithm, if any. */
export enum Hash_HashType {
  /** NONE - No hash requested. */
  NONE = 0,
  /** SHA256 - Use a sha256 hash. */
  SHA256 = 1,
  /** MD5 - Use a md5 hash. */
  MD5 = 2,
  /** SHA512 - Use a sha512 hash. */
  SHA512 = 4,
  UNRECOGNIZED = -1,
}

export function hash_HashTypeFromJSON(object: any): Hash_HashType {
  switch (object) {
    case 0:
    case "NONE":
      return Hash_HashType.NONE;
    case 1:
    case "SHA256":
      return Hash_HashType.SHA256;
    case 2:
    case "MD5":
      return Hash_HashType.MD5;
    case 4:
    case "SHA512":
      return Hash_HashType.SHA512;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Hash_HashType.UNRECOGNIZED;
  }
}

export function hash_HashTypeToJSON(object: Hash_HashType): string {
  switch (object) {
    case Hash_HashType.NONE:
      return "NONE";
    case Hash_HashType.SHA256:
      return "SHA256";
    case Hash_HashType.MD5:
      return "MD5";
    case Hash_HashType.SHA512:
      return "SHA512";
    case Hash_HashType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Secrets and secret environment variables. */
export interface Secrets {
  /** Secrets in Secret Manager and associated secret environment variable. */
  secretManager: SecretManagerSecret[];
  /**
   * Secrets encrypted with KMS key and the associated secret environment
   * variable.
   */
  inline: InlineSecret[];
}

/**
 * Pairs a set of secret environment variables mapped to encrypted
 * values with the Cloud KMS key to use to decrypt the value.
 */
export interface InlineSecret {
  /**
   * Resource name of Cloud KMS crypto key to decrypt the encrypted value.
   * In format: projects/* /locations/* /keyRings/* /cryptoKeys/*
   */
  kmsKeyName: string;
  /**
   * Map of environment variable name to its encrypted value.
   *
   * Secret environment variables must be unique across all of a build's
   * secrets, and must be used by at least one build step. Values can be at most
   * 64 KB in size. There can be at most 100 secret values across all of a
   * build's secrets.
   */
  envMap: { [key: string]: Buffer };
}

export interface InlineSecret_EnvMapEntry {
  key: string;
  value: Buffer;
}

/** Pairs a secret environment variable with a SecretVersion in Secret Manager. */
export interface SecretManagerSecret {
  /**
   * Resource name of the SecretVersion. In format:
   * projects/* /secrets/* /versions/*
   */
  versionName: string;
  /**
   * Environment variable name to associate with the secret.
   * Secret environment variables must be unique across all of a build's
   * secrets, and must be used by at least one build step.
   */
  env: string;
}

/**
 * Pairs a set of secret environment variables containing encrypted
 * values with the Cloud KMS key to use to decrypt the value.
 * Note: Use `kmsKeyName` with  `available_secrets` instead of using
 * `kmsKeyName` with `secret`. For instructions see:
 * https://cloud.google.com/cloud-build/docs/securing-builds/use-encrypted-credentials.
 */
export interface Secret {
  /** Cloud KMS key name to use to decrypt these envs. */
  kmsKeyName: string;
  /**
   * Map of environment variable name to its encrypted value.
   *
   * Secret environment variables must be unique across all of a build's
   * secrets, and must be used by at least one build step. Values can be at most
   * 64 KB in size. There can be at most 100 secret values across all of a
   * build's secrets.
   */
  secretEnv: { [key: string]: Buffer };
}

export interface Secret_SecretEnvEntry {
  key: string;
  value: Buffer;
}

/** Request to create a new build. */
export interface CreateBuildRequest {
  /**
   * The parent resource where this build will be created.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. ID of the project. */
  projectId: string;
  /** Required. Build resource to create. */
  build: Build | undefined;
}

/** Request to get a build. */
export interface GetBuildRequest {
  /**
   * The name of the `Build` to retrieve.
   * Format: `projects/{project}/locations/{location}/builds/{build}`
   */
  name: string;
  /** Required. ID of the project. */
  projectId: string;
  /** Required. ID of the build. */
  id: string;
}

/** Request to list builds. */
export interface ListBuildsRequest {
  /**
   * The parent of the collection of `Builds`.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. ID of the project. */
  projectId: string;
  /** Number of results to return in the list. */
  pageSize: number;
  /**
   * The page token for the next page of Builds.
   *
   * If unspecified, the first page of results is returned.
   *
   * If the token is rejected for any reason, INVALID_ARGUMENT will be thrown.
   * In this case, the token should be discarded, and pagination should be
   * restarted from the first page of results.
   *
   * See https://google.aip.dev/158 for more.
   */
  pageToken: string;
  /** The raw filter text to constrain the results. */
  filter: string;
}

/** Response including listed builds. */
export interface ListBuildsResponse {
  /** Builds will be sorted by `create_time`, descending. */
  builds: Build[];
  /**
   * Token to receive the next page of results.
   * This will be absent if the end of the response list has been reached.
   */
  nextPageToken: string;
}

/** Request to cancel an ongoing build. */
export interface CancelBuildRequest {
  /**
   * The name of the `Build` to cancel.
   * Format: `projects/{project}/locations/{location}/builds/{build}`
   */
  name: string;
  /** Required. ID of the project. */
  projectId: string;
  /** Required. ID of the build. */
  id: string;
}

/** Request to approve or reject a pending build. */
export interface ApproveBuildRequest {
  /**
   * Required. Name of the target build.
   * For example: "projects/{$project_id}/builds/{$build_id}"
   */
  name: string;
  /** Approval decision and metadata. */
  approvalResult: ApprovalResult | undefined;
}

/**
 * BuildApproval describes a build's approval configuration, state, and
 * result.
 */
export interface BuildApproval {
  /** Output only. The state of this build's approval. */
  state: BuildApproval_State;
  /** Output only. Configuration for manual approval of this build. */
  config:
    | ApprovalConfig
    | undefined;
  /** Output only. Result of manual approval for this Build. */
  result: ApprovalResult | undefined;
}

/** Specifies the current state of a build's approval. */
export enum BuildApproval_State {
  /** STATE_UNSPECIFIED - Default enum type. This should not be used. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - Build approval is pending. */
  PENDING = 1,
  /** APPROVED - Build approval has been approved. */
  APPROVED = 2,
  /** REJECTED - Build approval has been rejected. */
  REJECTED = 3,
  /** CANCELLED - Build was cancelled while it was still pending approval. */
  CANCELLED = 5,
  UNRECOGNIZED = -1,
}

export function buildApproval_StateFromJSON(object: any): BuildApproval_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return BuildApproval_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return BuildApproval_State.PENDING;
    case 2:
    case "APPROVED":
      return BuildApproval_State.APPROVED;
    case 3:
    case "REJECTED":
      return BuildApproval_State.REJECTED;
    case 5:
    case "CANCELLED":
      return BuildApproval_State.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildApproval_State.UNRECOGNIZED;
  }
}

export function buildApproval_StateToJSON(object: BuildApproval_State): string {
  switch (object) {
    case BuildApproval_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case BuildApproval_State.PENDING:
      return "PENDING";
    case BuildApproval_State.APPROVED:
      return "APPROVED";
    case BuildApproval_State.REJECTED:
      return "REJECTED";
    case BuildApproval_State.CANCELLED:
      return "CANCELLED";
    case BuildApproval_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** ApprovalConfig describes configuration for manual approval of a build. */
export interface ApprovalConfig {
  /**
   * Whether or not approval is needed. If this is set on a build, it will
   * become pending when created, and will need to be explicitly approved
   * to start.
   */
  approvalRequired: boolean;
}

/**
 * ApprovalResult describes the decision and associated metadata of a manual
 * approval of a build.
 */
export interface ApprovalResult {
  /**
   * Output only. Email of the user that called the ApproveBuild API to
   * approve or reject a build at the time that the API was called.
   */
  approverAccount: string;
  /** Output only. The time when the approval decision was made. */
  approvalTime:
    | Date
    | undefined;
  /** Required. The decision of this manual approval. */
  decision: ApprovalResult_Decision;
  /** Optional. An optional comment for this manual approval result. */
  comment: string;
  /**
   * Optional. An optional URL tied to this manual approval result. This field
   * is essentially the same as comment, except that it will be rendered by the
   * UI differently. An example use case is a link to an external job that
   * approved this Build.
   */
  url: string;
}

/**
 * Specifies whether or not this manual approval result is to approve
 * or reject a build.
 */
export enum ApprovalResult_Decision {
  /** DECISION_UNSPECIFIED - Default enum type. This should not be used. */
  DECISION_UNSPECIFIED = 0,
  /** APPROVED - Build is approved. */
  APPROVED = 1,
  /** REJECTED - Build is rejected. */
  REJECTED = 2,
  UNRECOGNIZED = -1,
}

export function approvalResult_DecisionFromJSON(object: any): ApprovalResult_Decision {
  switch (object) {
    case 0:
    case "DECISION_UNSPECIFIED":
      return ApprovalResult_Decision.DECISION_UNSPECIFIED;
    case 1:
    case "APPROVED":
      return ApprovalResult_Decision.APPROVED;
    case 2:
    case "REJECTED":
      return ApprovalResult_Decision.REJECTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ApprovalResult_Decision.UNRECOGNIZED;
  }
}

export function approvalResult_DecisionToJSON(object: ApprovalResult_Decision): string {
  switch (object) {
    case ApprovalResult_Decision.DECISION_UNSPECIFIED:
      return "DECISION_UNSPECIFIED";
    case ApprovalResult_Decision.APPROVED:
      return "APPROVED";
    case ApprovalResult_Decision.REJECTED:
      return "REJECTED";
    case ApprovalResult_Decision.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** GitRepoSource describes a repo and ref of a code repository. */
export interface GitRepoSource {
  /**
   * The URI of the repo (e.g. https://github.com/user/repo.git).
   * Either `uri` or `repository` can be specified and is required.
   */
  uri: string;
  /**
   * The connected repository resource name, in the format
   * `projects/* /locations/* /connections/* /repositories/*`. Either `uri` or
   * `repository` can be specified and is required.
   */
  repository?:
    | string
    | undefined;
  /** The branch or tag to use. Must start with "refs/" (required). */
  ref: string;
  /** See RepoType below. */
  repoType: GitFileSource_RepoType;
  /**
   * The full resource name of the github enterprise config.
   * Format:
   * `projects/{project}/locations/{location}/githubEnterpriseConfigs/{id}`.
   * `projects/{project}/githubEnterpriseConfigs/{id}`.
   */
  githubEnterpriseConfig?: string | undefined;
}

/** GitFileSource describes a file within a (possibly remote) code repository. */
export interface GitFileSource {
  /** The path of the file, with the repo root as the root of the path. */
  path: string;
  /**
   * The URI of the repo.
   * Either uri or repository can be specified.
   * If unspecified, the repo from which the trigger invocation originated is
   * assumed to be the repo from which to read the specified path.
   */
  uri: string;
  /**
   * The fully qualified resource name of the Repos API repository.
   * Either URI or repository can be specified.
   * If unspecified, the repo from which the trigger invocation originated is
   * assumed to be the repo from which to read the specified path.
   */
  repository?:
    | string
    | undefined;
  /** See RepoType above. */
  repoType: GitFileSource_RepoType;
  /**
   * The branch, tag, arbitrary ref, or SHA version of the repo to use when
   * resolving the filename (optional).
   * This field respects the same syntax/resolution as described here:
   * https://git-scm.com/docs/gitrevisions
   * If unspecified, the revision from which the trigger invocation originated
   * is assumed to be the revision from which to read the specified path.
   */
  revision: string;
  /**
   * The full resource name of the github enterprise config.
   * Format:
   * `projects/{project}/locations/{location}/githubEnterpriseConfigs/{id}`.
   * `projects/{project}/githubEnterpriseConfigs/{id}`.
   */
  githubEnterpriseConfig?: string | undefined;
}

/**
 * The type of the repo, since it may not be explicit from the `repo` field
 * (e.g from a URL).
 */
export enum GitFileSource_RepoType {
  /**
   * UNKNOWN - The default, unknown repo type. Don't use it, instead use one of
   * the other repo types.
   */
  UNKNOWN = 0,
  /** CLOUD_SOURCE_REPOSITORIES - A Google Cloud Source Repositories-hosted repo. */
  CLOUD_SOURCE_REPOSITORIES = 1,
  /**
   * GITHUB - A GitHub-hosted repo not necessarily on "github.com" (i.e. GitHub
   * Enterprise).
   */
  GITHUB = 2,
  /** BITBUCKET_SERVER - A Bitbucket Server-hosted repo. */
  BITBUCKET_SERVER = 3,
  /** GITLAB - A GitLab-hosted repo. */
  GITLAB = 4,
  UNRECOGNIZED = -1,
}

export function gitFileSource_RepoTypeFromJSON(object: any): GitFileSource_RepoType {
  switch (object) {
    case 0:
    case "UNKNOWN":
      return GitFileSource_RepoType.UNKNOWN;
    case 1:
    case "CLOUD_SOURCE_REPOSITORIES":
      return GitFileSource_RepoType.CLOUD_SOURCE_REPOSITORIES;
    case 2:
    case "GITHUB":
      return GitFileSource_RepoType.GITHUB;
    case 3:
    case "BITBUCKET_SERVER":
      return GitFileSource_RepoType.BITBUCKET_SERVER;
    case 4:
    case "GITLAB":
      return GitFileSource_RepoType.GITLAB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return GitFileSource_RepoType.UNRECOGNIZED;
  }
}

export function gitFileSource_RepoTypeToJSON(object: GitFileSource_RepoType): string {
  switch (object) {
    case GitFileSource_RepoType.UNKNOWN:
      return "UNKNOWN";
    case GitFileSource_RepoType.CLOUD_SOURCE_REPOSITORIES:
      return "CLOUD_SOURCE_REPOSITORIES";
    case GitFileSource_RepoType.GITHUB:
      return "GITHUB";
    case GitFileSource_RepoType.BITBUCKET_SERVER:
      return "BITBUCKET_SERVER";
    case GitFileSource_RepoType.GITLAB:
      return "GITLAB";
    case GitFileSource_RepoType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Configuration for an automated build in response to source repository
 * changes.
 */
export interface BuildTrigger {
  /**
   * The `Trigger` name with format:
   * `projects/{project}/locations/{location}/triggers/{trigger}`, where
   * {trigger} is a unique identifier generated by the service.
   */
  resourceName: string;
  /** Output only. Unique identifier of the trigger. */
  id: string;
  /** Human-readable description of this trigger. */
  description: string;
  /**
   * User-assigned name of the trigger. Must be unique within the project.
   * Trigger names must meet the following requirements:
   *
   * + They must contain only alphanumeric characters and dashes.
   * + They can be 1-64 characters long.
   * + They must begin and end with an alphanumeric character.
   */
  name: string;
  /** Tags for annotation of a `BuildTrigger` */
  tags: string[];
  /**
   * Template describing the types of source changes to trigger a build.
   *
   * Branch and tag names in trigger templates are interpreted as regular
   * expressions. Any branch or tag change that matches that regular expression
   * will trigger a build.
   *
   * Mutually exclusive with `github`.
   */
  triggerTemplate:
    | RepoSource
    | undefined;
  /**
   * GitHubEventsConfig describes the configuration of a trigger that creates
   * a build whenever a GitHub event is received.
   *
   * Mutually exclusive with `trigger_template`.
   */
  github:
    | GitHubEventsConfig
    | undefined;
  /**
   * PubsubConfig describes the configuration of a trigger that
   * creates a build whenever a Pub/Sub message is published.
   */
  pubsubConfig:
    | PubsubConfig
    | undefined;
  /**
   * WebhookConfig describes the configuration of a trigger that
   * creates a build whenever a webhook is sent to a trigger's webhook URL.
   */
  webhookConfig:
    | WebhookConfig
    | undefined;
  /**
   * Autodetect build configuration.  The following precedence is used (case
   * insensitive):
   *
   * 1. cloudbuild.yaml
   * 2. cloudbuild.yml
   * 3. cloudbuild.json
   * 4. Dockerfile
   *
   * Currently only available for GitHub App Triggers.
   */
  autodetect?:
    | boolean
    | undefined;
  /** Contents of the build template. */
  build?:
    | Build
    | undefined;
  /**
   * Path, from the source root, to the build configuration file
   * (i.e. cloudbuild.yaml).
   */
  filename?:
    | string
    | undefined;
  /** The file source describing the local or remote Build template. */
  gitFileSource?:
    | GitFileSource
    | undefined;
  /** Output only. Time when the trigger was created. */
  createTime:
    | Date
    | undefined;
  /** If true, the trigger will never automatically execute a build. */
  disabled: boolean;
  /**
   * Substitutions for Build resource. The keys must match the following
   * regular expression: `^_[A-Z0-9_]+$`.
   */
  substitutions: { [key: string]: string };
  /**
   * ignored_files and included_files are file glob matches using
   * https://golang.org/pkg/path/filepath/#Match extended with support for "**".
   *
   * If ignored_files and changed files are both empty, then they are
   * not used to determine whether or not to trigger a build.
   *
   * If ignored_files is not empty, then we ignore any files that match
   * any of the ignored_file globs. If the change has no files that are
   * outside of the ignored_files globs, then we do not trigger a build.
   */
  ignoredFiles: string[];
  /**
   * If any of the files altered in the commit pass the ignored_files
   * filter and included_files is empty, then as far as this filter is
   * concerned, we should trigger the build.
   *
   * If any of the files altered in the commit pass the ignored_files
   * filter and included_files is not empty, then we make sure that at
   * least one of those files matches a included_files glob. If not,
   * then we do not trigger a build.
   */
  includedFiles: string[];
  /** Optional. A Common Expression Language string. */
  filter: string;
  /**
   * The repo and ref of the repository from which to build. This field
   * is used only for those triggers that do not respond to SCM events.
   * Triggers that respond to such events build source at whatever commit
   * caused the event.
   * This field is currently only used by Webhook, Pub/Sub, Manual, and Cron
   * triggers.
   */
  sourceToBuild:
    | GitRepoSource
    | undefined;
  /**
   * The service account used for all user-controlled operations including
   * UpdateBuildTrigger, RunBuildTrigger, CreateBuild, and CancelBuild.
   * If no service account is set, then the standard Cloud Build service account
   * ([PROJECT_NUM]@system.gserviceaccount.com) will be used instead.
   * Format: `projects/{PROJECT_ID}/serviceAccounts/{ACCOUNT_ID_OR_EMAIL}`
   */
  serviceAccount: string;
  /**
   * The configuration of a trigger that creates a build whenever an event from
   * Repo API is received.
   */
  repositoryEventConfig: RepositoryEventConfig | undefined;
}

export interface BuildTrigger_SubstitutionsEntry {
  key: string;
  value: string;
}

/**
 * The configuration of a trigger that creates a build whenever an event from
 * Repo API is received.
 */
export interface RepositoryEventConfig {
  /** The resource name of the Repo API resource. */
  repository: string;
  /** Output only. The type of the SCM vendor the repository points to. */
  repositoryType: RepositoryEventConfig_RepositoryType;
  /** Filter to match changes in pull requests. */
  pullRequest?:
    | PullRequestFilter
    | undefined;
  /** Filter to match changes in refs like branches, tags. */
  push?: PushFilter | undefined;
}

/** All possible SCM repo types from Repo API. */
export enum RepositoryEventConfig_RepositoryType {
  /** REPOSITORY_TYPE_UNSPECIFIED - If unspecified, RepositoryType defaults to GITHUB. */
  REPOSITORY_TYPE_UNSPECIFIED = 0,
  /** GITHUB - The SCM repo is GITHUB. */
  GITHUB = 1,
  /** GITHUB_ENTERPRISE - The SCM repo is GITHUB Enterprise. */
  GITHUB_ENTERPRISE = 2,
  /** GITLAB_ENTERPRISE - The SCM repo is GITLAB Enterprise. */
  GITLAB_ENTERPRISE = 3,
  UNRECOGNIZED = -1,
}

export function repositoryEventConfig_RepositoryTypeFromJSON(object: any): RepositoryEventConfig_RepositoryType {
  switch (object) {
    case 0:
    case "REPOSITORY_TYPE_UNSPECIFIED":
      return RepositoryEventConfig_RepositoryType.REPOSITORY_TYPE_UNSPECIFIED;
    case 1:
    case "GITHUB":
      return RepositoryEventConfig_RepositoryType.GITHUB;
    case 2:
    case "GITHUB_ENTERPRISE":
      return RepositoryEventConfig_RepositoryType.GITHUB_ENTERPRISE;
    case 3:
    case "GITLAB_ENTERPRISE":
      return RepositoryEventConfig_RepositoryType.GITLAB_ENTERPRISE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RepositoryEventConfig_RepositoryType.UNRECOGNIZED;
  }
}

export function repositoryEventConfig_RepositoryTypeToJSON(object: RepositoryEventConfig_RepositoryType): string {
  switch (object) {
    case RepositoryEventConfig_RepositoryType.REPOSITORY_TYPE_UNSPECIFIED:
      return "REPOSITORY_TYPE_UNSPECIFIED";
    case RepositoryEventConfig_RepositoryType.GITHUB:
      return "GITHUB";
    case RepositoryEventConfig_RepositoryType.GITHUB_ENTERPRISE:
      return "GITHUB_ENTERPRISE";
    case RepositoryEventConfig_RepositoryType.GITLAB_ENTERPRISE:
      return "GITLAB_ENTERPRISE";
    case RepositoryEventConfig_RepositoryType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * GitHubEventsConfig describes the configuration of a trigger that creates a
 * build whenever a GitHub event is received.
 */
export interface GitHubEventsConfig {
  /**
   * The installationID that emits the GitHub event.
   *
   * @deprecated
   */
  installationId: Long;
  /**
   * Owner of the repository. For example: The owner for
   * https://github.com/googlecloudplatform/cloud-builders is
   * "googlecloudplatform".
   */
  owner: string;
  /**
   * Name of the repository. For example: The name for
   * https://github.com/googlecloudplatform/cloud-builders is "cloud-builders".
   */
  name: string;
  /** filter to match changes in pull requests. */
  pullRequest?:
    | PullRequestFilter
    | undefined;
  /** filter to match changes in refs like branches, tags. */
  push?: PushFilter | undefined;
}

/**
 * PubsubConfig describes the configuration of a trigger that
 * creates a build whenever a Pub/Sub message is published.
 */
export interface PubsubConfig {
  /**
   * Output only. Name of the subscription. Format is
   * `projects/{project}/subscriptions/{subscription}`.
   */
  subscription: string;
  /**
   * The name of the topic from which this subscription is receiving messages.
   * Format is `projects/{project}/topics/{topic}`.
   */
  topic: string;
  /** Service account that will make the push request. */
  serviceAccountEmail: string;
  /**
   * Potential issues with the underlying Pub/Sub subscription configuration.
   * Only populated on get requests.
   */
  state: PubsubConfig_State;
}

/**
 * Enumerates potential issues with the underlying Pub/Sub subscription
 * configuration.
 */
export enum PubsubConfig_State {
  /** STATE_UNSPECIFIED - The subscription configuration has not been checked. */
  STATE_UNSPECIFIED = 0,
  /** OK - The Pub/Sub subscription is properly configured. */
  OK = 1,
  /** SUBSCRIPTION_DELETED - The subscription has been deleted. */
  SUBSCRIPTION_DELETED = 2,
  /** TOPIC_DELETED - The topic has been deleted. */
  TOPIC_DELETED = 3,
  /** SUBSCRIPTION_MISCONFIGURED - Some of the subscription's field are misconfigured. */
  SUBSCRIPTION_MISCONFIGURED = 4,
  UNRECOGNIZED = -1,
}

export function pubsubConfig_StateFromJSON(object: any): PubsubConfig_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return PubsubConfig_State.STATE_UNSPECIFIED;
    case 1:
    case "OK":
      return PubsubConfig_State.OK;
    case 2:
    case "SUBSCRIPTION_DELETED":
      return PubsubConfig_State.SUBSCRIPTION_DELETED;
    case 3:
    case "TOPIC_DELETED":
      return PubsubConfig_State.TOPIC_DELETED;
    case 4:
    case "SUBSCRIPTION_MISCONFIGURED":
      return PubsubConfig_State.SUBSCRIPTION_MISCONFIGURED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PubsubConfig_State.UNRECOGNIZED;
  }
}

export function pubsubConfig_StateToJSON(object: PubsubConfig_State): string {
  switch (object) {
    case PubsubConfig_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case PubsubConfig_State.OK:
      return "OK";
    case PubsubConfig_State.SUBSCRIPTION_DELETED:
      return "SUBSCRIPTION_DELETED";
    case PubsubConfig_State.TOPIC_DELETED:
      return "TOPIC_DELETED";
    case PubsubConfig_State.SUBSCRIPTION_MISCONFIGURED:
      return "SUBSCRIPTION_MISCONFIGURED";
    case PubsubConfig_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * WebhookConfig describes the configuration of a trigger that
 * creates a build whenever a webhook is sent to a trigger's webhook URL.
 */
export interface WebhookConfig {
  /** Required. Resource name for the secret required as a URL parameter. */
  secret?:
    | string
    | undefined;
  /**
   * Potential issues with the underlying Pub/Sub subscription configuration.
   * Only populated on get requests.
   */
  state: WebhookConfig_State;
}

/**
 * Enumerates potential issues with the Secret Manager secret provided by the
 * user.
 */
export enum WebhookConfig_State {
  /** STATE_UNSPECIFIED - The webhook auth configuration not been checked. */
  STATE_UNSPECIFIED = 0,
  /** OK - The auth configuration is properly setup. */
  OK = 1,
  /** SECRET_DELETED - The secret provided in auth_method has been deleted. */
  SECRET_DELETED = 2,
  UNRECOGNIZED = -1,
}

export function webhookConfig_StateFromJSON(object: any): WebhookConfig_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return WebhookConfig_State.STATE_UNSPECIFIED;
    case 1:
    case "OK":
      return WebhookConfig_State.OK;
    case 2:
    case "SECRET_DELETED":
      return WebhookConfig_State.SECRET_DELETED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WebhookConfig_State.UNRECOGNIZED;
  }
}

export function webhookConfig_StateToJSON(object: WebhookConfig_State): string {
  switch (object) {
    case WebhookConfig_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case WebhookConfig_State.OK:
      return "OK";
    case WebhookConfig_State.SECRET_DELETED:
      return "SECRET_DELETED";
    case WebhookConfig_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * PullRequestFilter contains filter properties for matching GitHub Pull
 * Requests.
 */
export interface PullRequestFilter {
  /**
   * Regex of branches to match.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  branch?:
    | string
    | undefined;
  /**
   * Configure builds to run whether a repository owner or collaborator need to
   * comment `/gcbrun`.
   */
  commentControl: PullRequestFilter_CommentControl;
  /** If true, branches that do NOT match the git_ref will trigger a build. */
  invertRegex: boolean;
}

/** Controls behavior of Pull Request comments. */
export enum PullRequestFilter_CommentControl {
  /** COMMENTS_DISABLED - Do not require comments on Pull Requests before builds are triggered. */
  COMMENTS_DISABLED = 0,
  /**
   * COMMENTS_ENABLED - Enforce that repository owners or collaborators must comment on Pull
   * Requests before builds are triggered.
   */
  COMMENTS_ENABLED = 1,
  /**
   * COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY - Enforce that repository owners or collaborators must comment on external
   * contributors' Pull Requests before builds are triggered.
   */
  COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY = 2,
  UNRECOGNIZED = -1,
}

export function pullRequestFilter_CommentControlFromJSON(object: any): PullRequestFilter_CommentControl {
  switch (object) {
    case 0:
    case "COMMENTS_DISABLED":
      return PullRequestFilter_CommentControl.COMMENTS_DISABLED;
    case 1:
    case "COMMENTS_ENABLED":
      return PullRequestFilter_CommentControl.COMMENTS_ENABLED;
    case 2:
    case "COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY":
      return PullRequestFilter_CommentControl.COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PullRequestFilter_CommentControl.UNRECOGNIZED;
  }
}

export function pullRequestFilter_CommentControlToJSON(object: PullRequestFilter_CommentControl): string {
  switch (object) {
    case PullRequestFilter_CommentControl.COMMENTS_DISABLED:
      return "COMMENTS_DISABLED";
    case PullRequestFilter_CommentControl.COMMENTS_ENABLED:
      return "COMMENTS_ENABLED";
    case PullRequestFilter_CommentControl.COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY:
      return "COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY";
    case PullRequestFilter_CommentControl.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Push contains filter properties for matching GitHub git pushes. */
export interface PushFilter {
  /**
   * Regexes matching branches to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  branch?:
    | string
    | undefined;
  /**
   * Regexes matching tags to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  tag?:
    | string
    | undefined;
  /**
   * When true, only trigger a build if the revision regex does NOT match the
   * git_ref regex.
   */
  invertRegex: boolean;
}

/** Request to create a new `BuildTrigger`. */
export interface CreateBuildTriggerRequest {
  /**
   * The parent resource where this trigger will be created.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. ID of the project for which to configure automatic builds. */
  projectId: string;
  /** Required. `BuildTrigger` to create. */
  trigger: BuildTrigger | undefined;
}

/** Returns the `BuildTrigger` with the specified ID. */
export interface GetBuildTriggerRequest {
  /**
   * The name of the `Trigger` to retrieve.
   * Format: `projects/{project}/locations/{location}/triggers/{trigger}`
   */
  name: string;
  /** Required. ID of the project that owns the trigger. */
  projectId: string;
  /** Required. Identifier (`id` or `name`) of the `BuildTrigger` to get. */
  triggerId: string;
}

/** Request to list existing `BuildTriggers`. */
export interface ListBuildTriggersRequest {
  /**
   * The parent of the collection of `Triggers`.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. ID of the project for which to list BuildTriggers. */
  projectId: string;
  /** Number of results to return in the list. */
  pageSize: number;
  /** Token to provide to skip to a particular spot in the list. */
  pageToken: string;
}

/** Response containing existing `BuildTriggers`. */
export interface ListBuildTriggersResponse {
  /** `BuildTriggers` for the project, sorted by `create_time` descending. */
  triggers: BuildTrigger[];
  /** Token to receive the next page of results. */
  nextPageToken: string;
}

/** Request to delete a `BuildTrigger`. */
export interface DeleteBuildTriggerRequest {
  /**
   * The name of the `Trigger` to delete.
   * Format: `projects/{project}/locations/{location}/triggers/{trigger}`
   */
  name: string;
  /** Required. ID of the project that owns the trigger. */
  projectId: string;
  /** Required. ID of the `BuildTrigger` to delete. */
  triggerId: string;
}

/** Request to update an existing `BuildTrigger`. */
export interface UpdateBuildTriggerRequest {
  /** Required. ID of the project that owns the trigger. */
  projectId: string;
  /** Required. ID of the `BuildTrigger` to update. */
  triggerId: string;
  /** Required. `BuildTrigger` to update. */
  trigger:
    | BuildTrigger
    | undefined;
  /**
   * Update mask for the resource. If this is set,
   * the server will only update the fields specified in the field mask.
   * Otherwise, a full update of the mutable resource fields will be performed.
   */
  updateMask: string[] | undefined;
}

/** Optional arguments to enable specific features of builds. */
export interface BuildOptions {
  /** Requested hash for SourceProvenance. */
  sourceProvenanceHash: Hash_HashType[];
  /** Requested verifiability options. */
  requestedVerifyOption: BuildOptions_VerifyOption;
  /** Compute Engine machine type on which to run the build. */
  machineType: BuildOptions_MachineType;
  /**
   * Requested disk size for the VM that runs the build. Note that this is *NOT*
   * "disk free"; some of the space will be used by the operating system and
   * build utilities. Also note that this is the minimum disk size that will be
   * allocated for the build -- the build may run with a larger disk than
   * requested. At present, the maximum disk size is 2000GB; builds that request
   * more than the maximum are rejected with an error.
   */
  diskSizeGb: Long;
  /**
   * Option to specify behavior when there is an error in the substitution
   * checks.
   *
   * NOTE: this is always set to ALLOW_LOOSE for triggered builds and cannot
   * be overridden in the build configuration file.
   */
  substitutionOption: BuildOptions_SubstitutionOption;
  /**
   * Option to specify whether or not to apply bash style string
   * operations to the substitutions.
   *
   * NOTE: this is always enabled for triggered builds and cannot be
   * overridden in the build configuration file.
   */
  dynamicSubstitutions: boolean;
  /**
   * Option to include built-in and custom substitutions as env variables
   * for all build steps.
   */
  automapSubstitutions: boolean;
  /**
   * Option to define build log streaming behavior to Cloud
   * Storage.
   */
  logStreamingOption: BuildOptions_LogStreamingOption;
  /**
   * This field deprecated; please use `pool.name` instead.
   *
   * @deprecated
   */
  workerPool: string;
  /**
   * Optional. Specification for execution on a `WorkerPool`.
   *
   * See [running builds in a private
   * pool](https://cloud.google.com/build/docs/private-pools/run-builds-in-private-pool)
   * for more information.
   */
  pool:
    | BuildOptions_PoolOption
    | undefined;
  /**
   * Option to specify the logging mode, which determines if and where build
   * logs are stored.
   */
  logging: BuildOptions_LoggingMode;
  /**
   * A list of global environment variable definitions that will exist for all
   * build steps in this build. If a variable is defined in both globally and in
   * a build step, the variable will use the build step value.
   *
   * The elements are of the form "KEY=VALUE" for the environment variable "KEY"
   * being given the value "VALUE".
   */
  env: string[];
  /**
   * A list of global environment variables, which are encrypted using a Cloud
   * Key Management Service crypto key. These values must be specified in the
   * build's `Secret`. These variables will be available to all build steps
   * in this build.
   */
  secretEnv: string[];
  /**
   * Global list of volumes to mount for ALL build steps
   *
   * Each volume is created as an empty volume prior to starting the build
   * process. Upon completion of the build, volumes and their contents are
   * discarded. Global volume names and paths cannot conflict with the volumes
   * defined a build step.
   *
   * Using a global volume in a build with only one step is not valid as
   * it is indicative of a build request with an incorrect configuration.
   */
  volumes: Volume[];
  /** Optional. Option to specify how default logs buckets are setup. */
  defaultLogsBucketBehavior: BuildOptions_DefaultLogsBucketBehavior;
}

/**
 * Specifies the manner in which the build should be verified, if at all.
 *
 * If a verified build is requested, and any part of the process to generate
 * and upload provenance fails, the build will also fail.
 *
 * If the build does not request verification then that process may occur, but
 * is not guaranteed to. If it does occur and fails, the build will not fail.
 *
 * For more information, see [Viewing Build
 * Provenance](https://cloud.google.com/build/docs/securing-builds/view-build-provenance).
 */
export enum BuildOptions_VerifyOption {
  /** NOT_VERIFIED - Not a verifiable build (the default). */
  NOT_VERIFIED = 0,
  /** VERIFIED - Build must be verified. */
  VERIFIED = 1,
  UNRECOGNIZED = -1,
}

export function buildOptions_VerifyOptionFromJSON(object: any): BuildOptions_VerifyOption {
  switch (object) {
    case 0:
    case "NOT_VERIFIED":
      return BuildOptions_VerifyOption.NOT_VERIFIED;
    case 1:
    case "VERIFIED":
      return BuildOptions_VerifyOption.VERIFIED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildOptions_VerifyOption.UNRECOGNIZED;
  }
}

export function buildOptions_VerifyOptionToJSON(object: BuildOptions_VerifyOption): string {
  switch (object) {
    case BuildOptions_VerifyOption.NOT_VERIFIED:
      return "NOT_VERIFIED";
    case BuildOptions_VerifyOption.VERIFIED:
      return "VERIFIED";
    case BuildOptions_VerifyOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Supported Compute Engine machine types.
 * For more information, see [Machine
 * types](https://cloud.google.com/compute/docs/machine-types).
 */
export enum BuildOptions_MachineType {
  /** UNSPECIFIED - Standard machine type. */
  UNSPECIFIED = 0,
  /** N1_HIGHCPU_8 - Highcpu machine with 8 CPUs. */
  N1_HIGHCPU_8 = 1,
  /** N1_HIGHCPU_32 - Highcpu machine with 32 CPUs. */
  N1_HIGHCPU_32 = 2,
  /** E2_HIGHCPU_8 - Highcpu e2 machine with 8 CPUs. */
  E2_HIGHCPU_8 = 5,
  /** E2_HIGHCPU_32 - Highcpu e2 machine with 32 CPUs. */
  E2_HIGHCPU_32 = 6,
  /** E2_MEDIUM - E2 machine with 1 CPU. */
  E2_MEDIUM = 7,
  UNRECOGNIZED = -1,
}

export function buildOptions_MachineTypeFromJSON(object: any): BuildOptions_MachineType {
  switch (object) {
    case 0:
    case "UNSPECIFIED":
      return BuildOptions_MachineType.UNSPECIFIED;
    case 1:
    case "N1_HIGHCPU_8":
      return BuildOptions_MachineType.N1_HIGHCPU_8;
    case 2:
    case "N1_HIGHCPU_32":
      return BuildOptions_MachineType.N1_HIGHCPU_32;
    case 5:
    case "E2_HIGHCPU_8":
      return BuildOptions_MachineType.E2_HIGHCPU_8;
    case 6:
    case "E2_HIGHCPU_32":
      return BuildOptions_MachineType.E2_HIGHCPU_32;
    case 7:
    case "E2_MEDIUM":
      return BuildOptions_MachineType.E2_MEDIUM;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildOptions_MachineType.UNRECOGNIZED;
  }
}

export function buildOptions_MachineTypeToJSON(object: BuildOptions_MachineType): string {
  switch (object) {
    case BuildOptions_MachineType.UNSPECIFIED:
      return "UNSPECIFIED";
    case BuildOptions_MachineType.N1_HIGHCPU_8:
      return "N1_HIGHCPU_8";
    case BuildOptions_MachineType.N1_HIGHCPU_32:
      return "N1_HIGHCPU_32";
    case BuildOptions_MachineType.E2_HIGHCPU_8:
      return "E2_HIGHCPU_8";
    case BuildOptions_MachineType.E2_HIGHCPU_32:
      return "E2_HIGHCPU_32";
    case BuildOptions_MachineType.E2_MEDIUM:
      return "E2_MEDIUM";
    case BuildOptions_MachineType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Specifies the behavior when there is an error in the substitution checks. */
export enum BuildOptions_SubstitutionOption {
  /**
   * MUST_MATCH - Fails the build if error in substitutions checks, like missing
   * a substitution in the template or in the map.
   */
  MUST_MATCH = 0,
  /** ALLOW_LOOSE - Do not fail the build if error in substitutions checks. */
  ALLOW_LOOSE = 1,
  UNRECOGNIZED = -1,
}

export function buildOptions_SubstitutionOptionFromJSON(object: any): BuildOptions_SubstitutionOption {
  switch (object) {
    case 0:
    case "MUST_MATCH":
      return BuildOptions_SubstitutionOption.MUST_MATCH;
    case 1:
    case "ALLOW_LOOSE":
      return BuildOptions_SubstitutionOption.ALLOW_LOOSE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildOptions_SubstitutionOption.UNRECOGNIZED;
  }
}

export function buildOptions_SubstitutionOptionToJSON(object: BuildOptions_SubstitutionOption): string {
  switch (object) {
    case BuildOptions_SubstitutionOption.MUST_MATCH:
      return "MUST_MATCH";
    case BuildOptions_SubstitutionOption.ALLOW_LOOSE:
      return "ALLOW_LOOSE";
    case BuildOptions_SubstitutionOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Specifies the behavior when writing build logs to Cloud Storage. */
export enum BuildOptions_LogStreamingOption {
  /** STREAM_DEFAULT - Service may automatically determine build log streaming behavior. */
  STREAM_DEFAULT = 0,
  /** STREAM_ON - Build logs should be streamed to Cloud Storage. */
  STREAM_ON = 1,
  /**
   * STREAM_OFF - Build logs should not be streamed to Cloud Storage; they will be
   * written when the build is completed.
   */
  STREAM_OFF = 2,
  UNRECOGNIZED = -1,
}

export function buildOptions_LogStreamingOptionFromJSON(object: any): BuildOptions_LogStreamingOption {
  switch (object) {
    case 0:
    case "STREAM_DEFAULT":
      return BuildOptions_LogStreamingOption.STREAM_DEFAULT;
    case 1:
    case "STREAM_ON":
      return BuildOptions_LogStreamingOption.STREAM_ON;
    case 2:
    case "STREAM_OFF":
      return BuildOptions_LogStreamingOption.STREAM_OFF;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildOptions_LogStreamingOption.UNRECOGNIZED;
  }
}

export function buildOptions_LogStreamingOptionToJSON(object: BuildOptions_LogStreamingOption): string {
  switch (object) {
    case BuildOptions_LogStreamingOption.STREAM_DEFAULT:
      return "STREAM_DEFAULT";
    case BuildOptions_LogStreamingOption.STREAM_ON:
      return "STREAM_ON";
    case BuildOptions_LogStreamingOption.STREAM_OFF:
      return "STREAM_OFF";
    case BuildOptions_LogStreamingOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Specifies the logging mode. */
export enum BuildOptions_LoggingMode {
  /**
   * LOGGING_UNSPECIFIED - The service determines the logging mode. The default is `LEGACY`. Do not
   * rely on the default logging behavior as it may change in the future.
   */
  LOGGING_UNSPECIFIED = 0,
  /** LEGACY - Build logs are stored in Cloud Logging and Cloud Storage. */
  LEGACY = 1,
  /** GCS_ONLY - Build logs are stored in Cloud Storage. */
  GCS_ONLY = 2,
  /**
   * STACKDRIVER_ONLY - This option is the same as CLOUD_LOGGING_ONLY.
   *
   * @deprecated
   */
  STACKDRIVER_ONLY = 3,
  /**
   * CLOUD_LOGGING_ONLY - Build logs are stored in Cloud Logging. Selecting this option will not
   * allow [logs
   * streaming](https://cloud.google.com/sdk/gcloud/reference/builds/log).
   */
  CLOUD_LOGGING_ONLY = 5,
  /** NONE - Turn off all logging. No build logs will be captured. */
  NONE = 4,
  UNRECOGNIZED = -1,
}

export function buildOptions_LoggingModeFromJSON(object: any): BuildOptions_LoggingMode {
  switch (object) {
    case 0:
    case "LOGGING_UNSPECIFIED":
      return BuildOptions_LoggingMode.LOGGING_UNSPECIFIED;
    case 1:
    case "LEGACY":
      return BuildOptions_LoggingMode.LEGACY;
    case 2:
    case "GCS_ONLY":
      return BuildOptions_LoggingMode.GCS_ONLY;
    case 3:
    case "STACKDRIVER_ONLY":
      return BuildOptions_LoggingMode.STACKDRIVER_ONLY;
    case 5:
    case "CLOUD_LOGGING_ONLY":
      return BuildOptions_LoggingMode.CLOUD_LOGGING_ONLY;
    case 4:
    case "NONE":
      return BuildOptions_LoggingMode.NONE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildOptions_LoggingMode.UNRECOGNIZED;
  }
}

export function buildOptions_LoggingModeToJSON(object: BuildOptions_LoggingMode): string {
  switch (object) {
    case BuildOptions_LoggingMode.LOGGING_UNSPECIFIED:
      return "LOGGING_UNSPECIFIED";
    case BuildOptions_LoggingMode.LEGACY:
      return "LEGACY";
    case BuildOptions_LoggingMode.GCS_ONLY:
      return "GCS_ONLY";
    case BuildOptions_LoggingMode.STACKDRIVER_ONLY:
      return "STACKDRIVER_ONLY";
    case BuildOptions_LoggingMode.CLOUD_LOGGING_ONLY:
      return "CLOUD_LOGGING_ONLY";
    case BuildOptions_LoggingMode.NONE:
      return "NONE";
    case BuildOptions_LoggingMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Default Cloud Storage log bucket behavior options. */
export enum BuildOptions_DefaultLogsBucketBehavior {
  /** DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED - Unspecified. */
  DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED = 0,
  /**
   * REGIONAL_USER_OWNED_BUCKET - Bucket is located in user-owned project in the same region as the
   * build. The builder service account must have access to create and write
   * to Cloud Storage buckets in the build project.
   */
  REGIONAL_USER_OWNED_BUCKET = 1,
  /** LEGACY_BUCKET - Bucket is located in a Google-owned project and is not regionalized. */
  LEGACY_BUCKET = 2,
  UNRECOGNIZED = -1,
}

export function buildOptions_DefaultLogsBucketBehaviorFromJSON(object: any): BuildOptions_DefaultLogsBucketBehavior {
  switch (object) {
    case 0:
    case "DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED":
      return BuildOptions_DefaultLogsBucketBehavior.DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED;
    case 1:
    case "REGIONAL_USER_OWNED_BUCKET":
      return BuildOptions_DefaultLogsBucketBehavior.REGIONAL_USER_OWNED_BUCKET;
    case 2:
    case "LEGACY_BUCKET":
      return BuildOptions_DefaultLogsBucketBehavior.LEGACY_BUCKET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildOptions_DefaultLogsBucketBehavior.UNRECOGNIZED;
  }
}

export function buildOptions_DefaultLogsBucketBehaviorToJSON(object: BuildOptions_DefaultLogsBucketBehavior): string {
  switch (object) {
    case BuildOptions_DefaultLogsBucketBehavior.DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED:
      return "DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED";
    case BuildOptions_DefaultLogsBucketBehavior.REGIONAL_USER_OWNED_BUCKET:
      return "REGIONAL_USER_OWNED_BUCKET";
    case BuildOptions_DefaultLogsBucketBehavior.LEGACY_BUCKET:
      return "LEGACY_BUCKET";
    case BuildOptions_DefaultLogsBucketBehavior.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Details about how a build should be executed on a `WorkerPool`.
 *
 * See [running builds in a private
 * pool](https://cloud.google.com/build/docs/private-pools/run-builds-in-private-pool)
 * for more information.
 */
export interface BuildOptions_PoolOption {
  /**
   * The `WorkerPool` resource to execute the build on.
   * You must have `cloudbuild.workerpools.use` on the project hosting the
   * WorkerPool.
   *
   * Format projects/{project}/locations/{location}/workerPools/{workerPoolId}
   */
  name: string;
}

/**
 * ReceiveTriggerWebhookRequest [Experimental] is the request object accepted by
 * the ReceiveTriggerWebhook method.
 */
export interface ReceiveTriggerWebhookRequest {
  /**
   * The name of the `ReceiveTriggerWebhook` to retrieve.
   * Format: `projects/{project}/locations/{location}/triggers/{trigger}`
   */
  name: string;
  /** HTTP request body. */
  body:
    | HttpBody
    | undefined;
  /** Project in which the specified trigger lives */
  projectId: string;
  /** Name of the trigger to run the payload against */
  trigger: string;
  /** Secret token used for authorization if an OAuth token isn't provided. */
  secret: string;
}

/**
 * ReceiveTriggerWebhookResponse [Experimental] is the response object for the
 * ReceiveTriggerWebhook method.
 */
export interface ReceiveTriggerWebhookResponse {
}

export interface GitHubEnterpriseConfig {
  /**
   * Optional. The full resource name for the GitHubEnterpriseConfig
   * For example:
   * "projects/{$project_id}/locations/{$location_id}/githubEnterpriseConfigs/{$config_id}"
   */
  name: string;
  /** The URL of the github enterprise host the configuration is for. */
  hostUrl: string;
  /**
   * Required. The GitHub app id of the Cloud Build app on the GitHub Enterprise
   * server.
   */
  appId: Long;
  /** Output only. Time when the installation was associated with the project. */
  createTime:
    | Date
    | undefined;
  /**
   * The key that should be attached to webhook calls to the ReceiveWebhook
   * endpoint.
   */
  webhookKey: string;
  /**
   * Optional. The network to be used when reaching out to the GitHub
   * Enterprise server. The VPC network must be enabled for private
   * service connection. This should be set if the GitHub Enterprise server is
   * hosted on-premises and not reachable by public internet.
   * If this field is left empty, no network peering will occur and calls to
   * the GitHub Enterprise server will be made over the public internet.
   * Must be in the format
   * `projects/{project}/global/networks/{network}`, where {project}
   * is a project number or id and {network} is the name of a
   * VPC network in the project.
   */
  peeredNetwork: string;
  /** Names of secrets in Secret Manager. */
  secrets:
    | GitHubEnterpriseSecrets
    | undefined;
  /** Name to display for this config. */
  displayName: string;
  /** Optional. SSL certificate to use for requests to GitHub Enterprise. */
  sslCa: string;
}

/**
 * GitHubEnterpriseSecrets represents the names of all necessary secrets in
 * Secret Manager for a GitHub Enterprise server.
 * Format is: projects/<project number>/secrets/<secret name>.
 */
export interface GitHubEnterpriseSecrets {
  /** The resource name for the private key secret version. */
  privateKeyVersionName: string;
  /** The resource name for the webhook secret secret version in Secret Manager. */
  webhookSecretVersionName: string;
  /** The resource name for the OAuth secret secret version in Secret Manager. */
  oauthSecretVersionName: string;
  /** The resource name for the OAuth client ID secret version in Secret Manager. */
  oauthClientIdVersionName: string;
}

/**
 * Configuration for a `WorkerPool`.
 *
 * Cloud Build owns and maintains a pool of workers for general use and have no
 * access to a project's private network. By default, builds submitted to
 * Cloud Build will use a worker from this pool.
 *
 * If your build needs access to resources on a private network,
 * create and use a `WorkerPool` to run your builds. Private `WorkerPool`s give
 * your builds access to any single VPC network that you
 * administer, including any on-prem resources connected to that VPC
 * network. For an overview of private pools, see
 * [Private pools
 * overview](https://cloud.google.com/build/docs/private-pools/private-pools-overview).
 */
export interface WorkerPool {
  /**
   * Output only. The resource name of the `WorkerPool`, with format
   * `projects/{project}/locations/{location}/workerPools/{worker_pool}`.
   * The value of `{worker_pool}` is provided by `worker_pool_id` in
   * `CreateWorkerPool` request and the value of `{location}` is determined by
   * the endpoint accessed.
   */
  name: string;
  /**
   * A user-specified, human-readable name for the `WorkerPool`. If provided,
   * this value must be 1-63 characters.
   */
  displayName: string;
  /** Output only. A unique identifier for the `WorkerPool`. */
  uid: string;
  /**
   * User specified annotations. See https://google.aip.dev/128#annotations
   * for more details such as format and size limitations.
   */
  annotations: { [key: string]: string };
  /**
   * Output only. Time at which the request to create the `WorkerPool` was
   * received.
   */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Time at which the request to update the `WorkerPool` was
   * received.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * Output only. Time at which the request to delete the `WorkerPool` was
   * received.
   */
  deleteTime:
    | Date
    | undefined;
  /** Output only. `WorkerPool` state. */
  state: WorkerPool_State;
  /** Legacy Private Pool configuration. */
  privatePoolV1Config?:
    | PrivatePoolV1Config
    | undefined;
  /**
   * Output only. Checksum computed by the server. May be sent on update and
   * delete requests to ensure that the client has an up-to-date value before
   * proceeding.
   */
  etag: string;
}

/** State of the `WorkerPool`. */
export enum WorkerPool_State {
  /** STATE_UNSPECIFIED - State of the `WorkerPool` is unknown. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - `WorkerPool` is being created. */
  CREATING = 1,
  /** RUNNING - `WorkerPool` is running. */
  RUNNING = 2,
  /** DELETING - `WorkerPool` is being deleted: cancelling builds and draining workers. */
  DELETING = 3,
  /** DELETED - `WorkerPool` is deleted. */
  DELETED = 4,
  /** UPDATING - `WorkerPool` is being updated; new builds cannot be run. */
  UPDATING = 5,
  UNRECOGNIZED = -1,
}

export function workerPool_StateFromJSON(object: any): WorkerPool_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return WorkerPool_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return WorkerPool_State.CREATING;
    case 2:
    case "RUNNING":
      return WorkerPool_State.RUNNING;
    case 3:
    case "DELETING":
      return WorkerPool_State.DELETING;
    case 4:
    case "DELETED":
      return WorkerPool_State.DELETED;
    case 5:
    case "UPDATING":
      return WorkerPool_State.UPDATING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return WorkerPool_State.UNRECOGNIZED;
  }
}

export function workerPool_StateToJSON(object: WorkerPool_State): string {
  switch (object) {
    case WorkerPool_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case WorkerPool_State.CREATING:
      return "CREATING";
    case WorkerPool_State.RUNNING:
      return "RUNNING";
    case WorkerPool_State.DELETING:
      return "DELETING";
    case WorkerPool_State.DELETED:
      return "DELETED";
    case WorkerPool_State.UPDATING:
      return "UPDATING";
    case WorkerPool_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface WorkerPool_AnnotationsEntry {
  key: string;
  value: string;
}

/** Configuration for a V1 `PrivatePool`. */
export interface PrivatePoolV1Config {
  /** Machine configuration for the workers in the pool. */
  workerConfig:
    | PrivatePoolV1Config_WorkerConfig
    | undefined;
  /** Network configuration for the pool. */
  networkConfig: PrivatePoolV1Config_NetworkConfig | undefined;
}

/**
 * Defines the configuration to be used for creating workers in
 * the pool.
 */
export interface PrivatePoolV1Config_WorkerConfig {
  /**
   * Machine type of a worker, such as `e2-medium`.
   * See [Worker pool config
   * file](https://cloud.google.com/build/docs/private-pools/worker-pool-config-file-schema).
   * If left blank, Cloud Build will use a sensible default.
   */
  machineType: string;
  /**
   * Size of the disk attached to the worker, in GB.
   * See [Worker pool config
   * file](https://cloud.google.com/build/docs/private-pools/worker-pool-config-file-schema).
   * Specify a value of up to 2000. If `0` is specified, Cloud Build will use
   * a standard disk size.
   */
  diskSizeGb: Long;
}

/** Defines the network configuration for the pool. */
export interface PrivatePoolV1Config_NetworkConfig {
  /**
   * Required. Immutable. The network definition that the workers are peered
   * to. If this section is left empty, the workers will be peered to
   * `WorkerPool.project_id` on the service producer network. Must be in the
   * format `projects/{project}/global/networks/{network}`, where `{project}`
   * is a project number, such as `12345`, and `{network}` is the name of a
   * VPC network in the project. See
   * [Understanding network configuration
   * options](https://cloud.google.com/build/docs/private-pools/set-up-private-pool-environment)
   */
  peeredNetwork: string;
  /** Option to configure network egress for the workers. */
  egressOption: PrivatePoolV1Config_NetworkConfig_EgressOption;
  /**
   * Immutable. Subnet IP range within the peered network. This is specified
   * in CIDR notation with a slash and the subnet prefix size. You can
   * optionally specify an IP address before the subnet prefix value. e.g.
   * `192.168.0.0/29` would specify an IP range starting at 192.168.0.0 with a
   * prefix size of 29 bits.
   * `/16` would specify a prefix size of 16 bits, with an automatically
   * determined IP within the peered VPC.
   * If unspecified, a value of `/24` will be used.
   */
  peeredNetworkIpRange: string;
}

/** Defines the egress option for the pool. */
export enum PrivatePoolV1Config_NetworkConfig_EgressOption {
  /** EGRESS_OPTION_UNSPECIFIED - If set, defaults to PUBLIC_EGRESS. */
  EGRESS_OPTION_UNSPECIFIED = 0,
  /**
   * NO_PUBLIC_EGRESS - If set, workers are created without any public address, which prevents
   * network egress to public IPs unless a network proxy is configured.
   */
  NO_PUBLIC_EGRESS = 1,
  /**
   * PUBLIC_EGRESS - If set, workers are created with a public address which allows for
   * public internet egress.
   */
  PUBLIC_EGRESS = 2,
  UNRECOGNIZED = -1,
}

export function privatePoolV1Config_NetworkConfig_EgressOptionFromJSON(
  object: any,
): PrivatePoolV1Config_NetworkConfig_EgressOption {
  switch (object) {
    case 0:
    case "EGRESS_OPTION_UNSPECIFIED":
      return PrivatePoolV1Config_NetworkConfig_EgressOption.EGRESS_OPTION_UNSPECIFIED;
    case 1:
    case "NO_PUBLIC_EGRESS":
      return PrivatePoolV1Config_NetworkConfig_EgressOption.NO_PUBLIC_EGRESS;
    case 2:
    case "PUBLIC_EGRESS":
      return PrivatePoolV1Config_NetworkConfig_EgressOption.PUBLIC_EGRESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PrivatePoolV1Config_NetworkConfig_EgressOption.UNRECOGNIZED;
  }
}

export function privatePoolV1Config_NetworkConfig_EgressOptionToJSON(
  object: PrivatePoolV1Config_NetworkConfig_EgressOption,
): string {
  switch (object) {
    case PrivatePoolV1Config_NetworkConfig_EgressOption.EGRESS_OPTION_UNSPECIFIED:
      return "EGRESS_OPTION_UNSPECIFIED";
    case PrivatePoolV1Config_NetworkConfig_EgressOption.NO_PUBLIC_EGRESS:
      return "NO_PUBLIC_EGRESS";
    case PrivatePoolV1Config_NetworkConfig_EgressOption.PUBLIC_EGRESS:
      return "PUBLIC_EGRESS";
    case PrivatePoolV1Config_NetworkConfig_EgressOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Request to create a new `WorkerPool`. */
export interface CreateWorkerPoolRequest {
  /**
   * Required. The parent resource where this worker pool will be created.
   * Format: `projects/{project}/locations/{location}`.
   */
  parent: string;
  /** Required. `WorkerPool` resource to create. */
  workerPool:
    | WorkerPool
    | undefined;
  /**
   * Required. Immutable. The ID to use for the `WorkerPool`, which will become
   * the final component of the resource name.
   *
   * This value should be 1-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   */
  workerPoolId: string;
  /**
   * If set, validate the request and preview the response, but do not actually
   * post it.
   */
  validateOnly: boolean;
}

/** Request to get a `WorkerPool` with the specified name. */
export interface GetWorkerPoolRequest {
  /**
   * Required. The name of the `WorkerPool` to retrieve.
   * Format: `projects/{project}/locations/{location}/workerPools/{workerPool}`.
   */
  name: string;
}

/** Request to delete a `WorkerPool`. */
export interface DeleteWorkerPoolRequest {
  /**
   * Required. The name of the `WorkerPool` to delete.
   * Format:
   * `projects/{project}/locations/{location}/workerPools/{workerPool}`.
   */
  name: string;
  /**
   * Optional. If provided, it must match the server's etag on the workerpool
   * for the request to be processed.
   */
  etag: string;
  /**
   * If set to true, and the `WorkerPool` is not found, the request will succeed
   * but no action will be taken on the server.
   */
  allowMissing: boolean;
  /**
   * If set, validate the request and preview the response, but do not actually
   * post it.
   */
  validateOnly: boolean;
}

/** Request to update a `WorkerPool`. */
export interface UpdateWorkerPoolRequest {
  /**
   * Required. The `WorkerPool` to update.
   *
   * The `name` field is used to identify the `WorkerPool` to update.
   * Format: `projects/{project}/locations/{location}/workerPools/{workerPool}`.
   */
  workerPool:
    | WorkerPool
    | undefined;
  /** A mask specifying which fields in `worker_pool` to update. */
  updateMask:
    | string[]
    | undefined;
  /**
   * If set, validate the request and preview the response, but do not actually
   * post it.
   */
  validateOnly: boolean;
}

/** Request to list `WorkerPool`s. */
export interface ListWorkerPoolsRequest {
  /**
   * Required. The parent of the collection of `WorkerPools`.
   * Format: `projects/{project}/locations/{location}`.
   */
  parent: string;
  /**
   * The maximum number of `WorkerPool`s to return. The service may return
   * fewer than this value. If omitted, the server will use a sensible default.
   */
  pageSize: number;
  /**
   * A page token, received from a previous `ListWorkerPools` call. Provide this
   * to retrieve the subsequent page.
   */
  pageToken: string;
}

/** Response containing existing `WorkerPools`. */
export interface ListWorkerPoolsResponse {
  /** `WorkerPools` for the specified project. */
  workerPools: WorkerPool[];
  /**
   * Continuation token used to page through large result sets. Provide this
   * value in a subsequent ListWorkerPoolsRequest to return the next page of
   * results.
   */
  nextPageToken: string;
}

/** Metadata for the `CreateWorkerPool` operation. */
export interface CreateWorkerPoolOperationMetadata {
  /**
   * The resource name of the `WorkerPool` to create.
   * Format:
   * `projects/{project}/locations/{location}/workerPools/{worker_pool}`.
   */
  workerPool: string;
  /** Time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Time the operation was completed. */
  completeTime: Date | undefined;
}

/** Metadata for the `UpdateWorkerPool` operation. */
export interface UpdateWorkerPoolOperationMetadata {
  /**
   * The resource name of the `WorkerPool` being updated.
   * Format:
   * `projects/{project}/locations/{location}/workerPools/{worker_pool}`.
   */
  workerPool: string;
  /** Time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Time the operation was completed. */
  completeTime: Date | undefined;
}

/** Metadata for the `DeleteWorkerPool` operation. */
export interface DeleteWorkerPoolOperationMetadata {
  /**
   * The resource name of the `WorkerPool` being deleted.
   * Format:
   * `projects/{project}/locations/{location}/workerPools/{worker_pool}`.
   */
  workerPool: string;
  /** Time the operation was created. */
  createTime:
    | Date
    | undefined;
  /** Time the operation was completed. */
  completeTime: Date | undefined;
}

function createBaseRetryBuildRequest(): RetryBuildRequest {
  return { name: "", projectId: "", id: "" };
}

export const RetryBuildRequest: MessageFns<RetryBuildRequest> = {
  encode(message: RetryBuildRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RetryBuildRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRetryBuildRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RetryBuildRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
    };
  },

  toJSON(message: RetryBuildRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    return obj;
  },

  create(base?: DeepPartial<RetryBuildRequest>): RetryBuildRequest {
    return RetryBuildRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RetryBuildRequest>): RetryBuildRequest {
    const message = createBaseRetryBuildRequest();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.id = object.id ?? "";
    return message;
  },
};

function createBaseRunBuildTriggerRequest(): RunBuildTriggerRequest {
  return { name: "", projectId: "", triggerId: "", source: undefined };
}

export const RunBuildTriggerRequest: MessageFns<RunBuildTriggerRequest> = {
  encode(message: RunBuildTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(34).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.triggerId !== "") {
      writer.uint32(18).string(message.triggerId);
    }
    if (message.source !== undefined) {
      RepoSource.encode(message.source, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RunBuildTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunBuildTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.triggerId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.source = RepoSource.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RunBuildTriggerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      triggerId: isSet(object.triggerId) ? globalThis.String(object.triggerId) : "",
      source: isSet(object.source) ? RepoSource.fromJSON(object.source) : undefined,
    };
  },

  toJSON(message: RunBuildTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.triggerId !== "") {
      obj.triggerId = message.triggerId;
    }
    if (message.source !== undefined) {
      obj.source = RepoSource.toJSON(message.source);
    }
    return obj;
  },

  create(base?: DeepPartial<RunBuildTriggerRequest>): RunBuildTriggerRequest {
    return RunBuildTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RunBuildTriggerRequest>): RunBuildTriggerRequest {
    const message = createBaseRunBuildTriggerRequest();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.triggerId = object.triggerId ?? "";
    message.source = (object.source !== undefined && object.source !== null)
      ? RepoSource.fromPartial(object.source)
      : undefined;
    return message;
  },
};

function createBaseStorageSource(): StorageSource {
  return { bucket: "", object: "", generation: Long.ZERO, sourceFetcher: 0 };
}

export const StorageSource: MessageFns<StorageSource> = {
  encode(message: StorageSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    if (message.sourceFetcher !== 0) {
      writer.uint32(40).int32(message.sourceFetcher);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.sourceFetcher = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageSource {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
      sourceFetcher: isSet(object.sourceFetcher) ? storageSource_SourceFetcherFromJSON(object.sourceFetcher) : 0,
    };
  },

  toJSON(message: StorageSource): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    if (message.sourceFetcher !== 0) {
      obj.sourceFetcher = storageSource_SourceFetcherToJSON(message.sourceFetcher);
    }
    return obj;
  },

  create(base?: DeepPartial<StorageSource>): StorageSource {
    return StorageSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageSource>): StorageSource {
    const message = createBaseStorageSource();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    message.sourceFetcher = object.sourceFetcher ?? 0;
    return message;
  },
};

function createBaseGitSource(): GitSource {
  return { url: "", dir: "", revision: "" };
}

export const GitSource: MessageFns<GitSource> = {
  encode(message: GitSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.url !== "") {
      writer.uint32(10).string(message.url);
    }
    if (message.dir !== "") {
      writer.uint32(42).string(message.dir);
    }
    if (message.revision !== "") {
      writer.uint32(50).string(message.revision);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GitSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGitSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.url = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.dir = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.revision = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GitSource {
    return {
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      dir: isSet(object.dir) ? globalThis.String(object.dir) : "",
      revision: isSet(object.revision) ? globalThis.String(object.revision) : "",
    };
  },

  toJSON(message: GitSource): unknown {
    const obj: any = {};
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.dir !== "") {
      obj.dir = message.dir;
    }
    if (message.revision !== "") {
      obj.revision = message.revision;
    }
    return obj;
  },

  create(base?: DeepPartial<GitSource>): GitSource {
    return GitSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GitSource>): GitSource {
    const message = createBaseGitSource();
    message.url = object.url ?? "";
    message.dir = object.dir ?? "";
    message.revision = object.revision ?? "";
    return message;
  },
};

function createBaseRepoSource(): RepoSource {
  return {
    projectId: "",
    repoName: "",
    branchName: undefined,
    tagName: undefined,
    commitSha: undefined,
    dir: "",
    invertRegex: false,
    substitutions: {},
  };
}

export const RepoSource: MessageFns<RepoSource> = {
  encode(message: RepoSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.repoName !== "") {
      writer.uint32(18).string(message.repoName);
    }
    if (message.branchName !== undefined) {
      writer.uint32(26).string(message.branchName);
    }
    if (message.tagName !== undefined) {
      writer.uint32(34).string(message.tagName);
    }
    if (message.commitSha !== undefined) {
      writer.uint32(42).string(message.commitSha);
    }
    if (message.dir !== "") {
      writer.uint32(58).string(message.dir);
    }
    if (message.invertRegex !== false) {
      writer.uint32(64).bool(message.invertRegex);
    }
    Object.entries(message.substitutions).forEach(([key, value]) => {
      RepoSource_SubstitutionsEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepoSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepoSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.repoName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.branchName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.tagName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.dir = reader.string();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.invertRegex = reader.bool();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          const entry9 = RepoSource_SubstitutionsEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.substitutions[entry9.key] = entry9.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepoSource {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      repoName: isSet(object.repoName) ? globalThis.String(object.repoName) : "",
      branchName: isSet(object.branchName) ? globalThis.String(object.branchName) : undefined,
      tagName: isSet(object.tagName) ? globalThis.String(object.tagName) : undefined,
      commitSha: isSet(object.commitSha) ? globalThis.String(object.commitSha) : undefined,
      dir: isSet(object.dir) ? globalThis.String(object.dir) : "",
      invertRegex: isSet(object.invertRegex) ? globalThis.Boolean(object.invertRegex) : false,
      substitutions: isObject(object.substitutions)
        ? Object.entries(object.substitutions).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: RepoSource): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.repoName !== "") {
      obj.repoName = message.repoName;
    }
    if (message.branchName !== undefined) {
      obj.branchName = message.branchName;
    }
    if (message.tagName !== undefined) {
      obj.tagName = message.tagName;
    }
    if (message.commitSha !== undefined) {
      obj.commitSha = message.commitSha;
    }
    if (message.dir !== "") {
      obj.dir = message.dir;
    }
    if (message.invertRegex !== false) {
      obj.invertRegex = message.invertRegex;
    }
    if (message.substitutions) {
      const entries = Object.entries(message.substitutions);
      if (entries.length > 0) {
        obj.substitutions = {};
        entries.forEach(([k, v]) => {
          obj.substitutions[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<RepoSource>): RepoSource {
    return RepoSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RepoSource>): RepoSource {
    const message = createBaseRepoSource();
    message.projectId = object.projectId ?? "";
    message.repoName = object.repoName ?? "";
    message.branchName = object.branchName ?? undefined;
    message.tagName = object.tagName ?? undefined;
    message.commitSha = object.commitSha ?? undefined;
    message.dir = object.dir ?? "";
    message.invertRegex = object.invertRegex ?? false;
    message.substitutions = Object.entries(object.substitutions ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseRepoSource_SubstitutionsEntry(): RepoSource_SubstitutionsEntry {
  return { key: "", value: "" };
}

export const RepoSource_SubstitutionsEntry: MessageFns<RepoSource_SubstitutionsEntry> = {
  encode(message: RepoSource_SubstitutionsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepoSource_SubstitutionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepoSource_SubstitutionsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepoSource_SubstitutionsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: RepoSource_SubstitutionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<RepoSource_SubstitutionsEntry>): RepoSource_SubstitutionsEntry {
    return RepoSource_SubstitutionsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RepoSource_SubstitutionsEntry>): RepoSource_SubstitutionsEntry {
    const message = createBaseRepoSource_SubstitutionsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseStorageSourceManifest(): StorageSourceManifest {
  return { bucket: "", object: "", generation: Long.ZERO };
}

export const StorageSourceManifest: MessageFns<StorageSourceManifest> = {
  encode(message: StorageSourceManifest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageSourceManifest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageSourceManifest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageSourceManifest {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
    };
  },

  toJSON(message: StorageSourceManifest): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<StorageSourceManifest>): StorageSourceManifest {
    return StorageSourceManifest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StorageSourceManifest>): StorageSourceManifest {
    const message = createBaseStorageSourceManifest();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    return message;
  },
};

function createBaseSource(): Source {
  return { storageSource: undefined, repoSource: undefined, gitSource: undefined, storageSourceManifest: undefined };
}

export const Source: MessageFns<Source> = {
  encode(message: Source, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.storageSource !== undefined) {
      StorageSource.encode(message.storageSource, writer.uint32(18).fork()).join();
    }
    if (message.repoSource !== undefined) {
      RepoSource.encode(message.repoSource, writer.uint32(26).fork()).join();
    }
    if (message.gitSource !== undefined) {
      GitSource.encode(message.gitSource, writer.uint32(42).fork()).join();
    }
    if (message.storageSourceManifest !== undefined) {
      StorageSourceManifest.encode(message.storageSourceManifest, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Source {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.storageSource = StorageSource.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.repoSource = RepoSource.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.gitSource = GitSource.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.storageSourceManifest = StorageSourceManifest.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Source {
    return {
      storageSource: isSet(object.storageSource) ? StorageSource.fromJSON(object.storageSource) : undefined,
      repoSource: isSet(object.repoSource) ? RepoSource.fromJSON(object.repoSource) : undefined,
      gitSource: isSet(object.gitSource) ? GitSource.fromJSON(object.gitSource) : undefined,
      storageSourceManifest: isSet(object.storageSourceManifest)
        ? StorageSourceManifest.fromJSON(object.storageSourceManifest)
        : undefined,
    };
  },

  toJSON(message: Source): unknown {
    const obj: any = {};
    if (message.storageSource !== undefined) {
      obj.storageSource = StorageSource.toJSON(message.storageSource);
    }
    if (message.repoSource !== undefined) {
      obj.repoSource = RepoSource.toJSON(message.repoSource);
    }
    if (message.gitSource !== undefined) {
      obj.gitSource = GitSource.toJSON(message.gitSource);
    }
    if (message.storageSourceManifest !== undefined) {
      obj.storageSourceManifest = StorageSourceManifest.toJSON(message.storageSourceManifest);
    }
    return obj;
  },

  create(base?: DeepPartial<Source>): Source {
    return Source.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Source>): Source {
    const message = createBaseSource();
    message.storageSource = (object.storageSource !== undefined && object.storageSource !== null)
      ? StorageSource.fromPartial(object.storageSource)
      : undefined;
    message.repoSource = (object.repoSource !== undefined && object.repoSource !== null)
      ? RepoSource.fromPartial(object.repoSource)
      : undefined;
    message.gitSource = (object.gitSource !== undefined && object.gitSource !== null)
      ? GitSource.fromPartial(object.gitSource)
      : undefined;
    message.storageSourceManifest =
      (object.storageSourceManifest !== undefined && object.storageSourceManifest !== null)
        ? StorageSourceManifest.fromPartial(object.storageSourceManifest)
        : undefined;
    return message;
  },
};

function createBaseBuiltImage(): BuiltImage {
  return { name: "", digest: "", pushTiming: undefined };
}

export const BuiltImage: MessageFns<BuiltImage> = {
  encode(message: BuiltImage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.digest !== "") {
      writer.uint32(26).string(message.digest);
    }
    if (message.pushTiming !== undefined) {
      TimeSpan.encode(message.pushTiming, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuiltImage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuiltImage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.digest = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pushTiming = TimeSpan.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuiltImage {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      digest: isSet(object.digest) ? globalThis.String(object.digest) : "",
      pushTiming: isSet(object.pushTiming) ? TimeSpan.fromJSON(object.pushTiming) : undefined,
    };
  },

  toJSON(message: BuiltImage): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.digest !== "") {
      obj.digest = message.digest;
    }
    if (message.pushTiming !== undefined) {
      obj.pushTiming = TimeSpan.toJSON(message.pushTiming);
    }
    return obj;
  },

  create(base?: DeepPartial<BuiltImage>): BuiltImage {
    return BuiltImage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuiltImage>): BuiltImage {
    const message = createBaseBuiltImage();
    message.name = object.name ?? "";
    message.digest = object.digest ?? "";
    message.pushTiming = (object.pushTiming !== undefined && object.pushTiming !== null)
      ? TimeSpan.fromPartial(object.pushTiming)
      : undefined;
    return message;
  },
};

function createBaseUploadedPythonPackage(): UploadedPythonPackage {
  return { uri: "", fileHashes: undefined, pushTiming: undefined };
}

export const UploadedPythonPackage: MessageFns<UploadedPythonPackage> = {
  encode(message: UploadedPythonPackage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.fileHashes !== undefined) {
      FileHashes.encode(message.fileHashes, writer.uint32(18).fork()).join();
    }
    if (message.pushTiming !== undefined) {
      TimeSpan.encode(message.pushTiming, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadedPythonPackage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadedPythonPackage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fileHashes = FileHashes.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pushTiming = TimeSpan.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadedPythonPackage {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      fileHashes: isSet(object.fileHashes) ? FileHashes.fromJSON(object.fileHashes) : undefined,
      pushTiming: isSet(object.pushTiming) ? TimeSpan.fromJSON(object.pushTiming) : undefined,
    };
  },

  toJSON(message: UploadedPythonPackage): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.fileHashes !== undefined) {
      obj.fileHashes = FileHashes.toJSON(message.fileHashes);
    }
    if (message.pushTiming !== undefined) {
      obj.pushTiming = TimeSpan.toJSON(message.pushTiming);
    }
    return obj;
  },

  create(base?: DeepPartial<UploadedPythonPackage>): UploadedPythonPackage {
    return UploadedPythonPackage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadedPythonPackage>): UploadedPythonPackage {
    const message = createBaseUploadedPythonPackage();
    message.uri = object.uri ?? "";
    message.fileHashes = (object.fileHashes !== undefined && object.fileHashes !== null)
      ? FileHashes.fromPartial(object.fileHashes)
      : undefined;
    message.pushTiming = (object.pushTiming !== undefined && object.pushTiming !== null)
      ? TimeSpan.fromPartial(object.pushTiming)
      : undefined;
    return message;
  },
};

function createBaseUploadedMavenArtifact(): UploadedMavenArtifact {
  return { uri: "", fileHashes: undefined, pushTiming: undefined };
}

export const UploadedMavenArtifact: MessageFns<UploadedMavenArtifact> = {
  encode(message: UploadedMavenArtifact, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.fileHashes !== undefined) {
      FileHashes.encode(message.fileHashes, writer.uint32(18).fork()).join();
    }
    if (message.pushTiming !== undefined) {
      TimeSpan.encode(message.pushTiming, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadedMavenArtifact {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadedMavenArtifact();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fileHashes = FileHashes.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pushTiming = TimeSpan.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadedMavenArtifact {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      fileHashes: isSet(object.fileHashes) ? FileHashes.fromJSON(object.fileHashes) : undefined,
      pushTiming: isSet(object.pushTiming) ? TimeSpan.fromJSON(object.pushTiming) : undefined,
    };
  },

  toJSON(message: UploadedMavenArtifact): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.fileHashes !== undefined) {
      obj.fileHashes = FileHashes.toJSON(message.fileHashes);
    }
    if (message.pushTiming !== undefined) {
      obj.pushTiming = TimeSpan.toJSON(message.pushTiming);
    }
    return obj;
  },

  create(base?: DeepPartial<UploadedMavenArtifact>): UploadedMavenArtifact {
    return UploadedMavenArtifact.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadedMavenArtifact>): UploadedMavenArtifact {
    const message = createBaseUploadedMavenArtifact();
    message.uri = object.uri ?? "";
    message.fileHashes = (object.fileHashes !== undefined && object.fileHashes !== null)
      ? FileHashes.fromPartial(object.fileHashes)
      : undefined;
    message.pushTiming = (object.pushTiming !== undefined && object.pushTiming !== null)
      ? TimeSpan.fromPartial(object.pushTiming)
      : undefined;
    return message;
  },
};

function createBaseUploadedNpmPackage(): UploadedNpmPackage {
  return { uri: "", fileHashes: undefined, pushTiming: undefined };
}

export const UploadedNpmPackage: MessageFns<UploadedNpmPackage> = {
  encode(message: UploadedNpmPackage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.fileHashes !== undefined) {
      FileHashes.encode(message.fileHashes, writer.uint32(18).fork()).join();
    }
    if (message.pushTiming !== undefined) {
      TimeSpan.encode(message.pushTiming, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadedNpmPackage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadedNpmPackage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fileHashes = FileHashes.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pushTiming = TimeSpan.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadedNpmPackage {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      fileHashes: isSet(object.fileHashes) ? FileHashes.fromJSON(object.fileHashes) : undefined,
      pushTiming: isSet(object.pushTiming) ? TimeSpan.fromJSON(object.pushTiming) : undefined,
    };
  },

  toJSON(message: UploadedNpmPackage): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.fileHashes !== undefined) {
      obj.fileHashes = FileHashes.toJSON(message.fileHashes);
    }
    if (message.pushTiming !== undefined) {
      obj.pushTiming = TimeSpan.toJSON(message.pushTiming);
    }
    return obj;
  },

  create(base?: DeepPartial<UploadedNpmPackage>): UploadedNpmPackage {
    return UploadedNpmPackage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UploadedNpmPackage>): UploadedNpmPackage {
    const message = createBaseUploadedNpmPackage();
    message.uri = object.uri ?? "";
    message.fileHashes = (object.fileHashes !== undefined && object.fileHashes !== null)
      ? FileHashes.fromPartial(object.fileHashes)
      : undefined;
    message.pushTiming = (object.pushTiming !== undefined && object.pushTiming !== null)
      ? TimeSpan.fromPartial(object.pushTiming)
      : undefined;
    return message;
  },
};

function createBaseBuildStep(): BuildStep {
  return {
    name: "",
    env: [],
    args: [],
    dir: "",
    id: "",
    waitFor: [],
    entrypoint: "",
    secretEnv: [],
    volumes: [],
    timing: undefined,
    pullTiming: undefined,
    timeout: undefined,
    status: 0,
    allowFailure: false,
    exitCode: 0,
    allowExitCodes: [],
    script: "",
    automapSubstitutions: undefined,
  };
}

export const BuildStep: MessageFns<BuildStep> = {
  encode(message: BuildStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.env) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.args) {
      writer.uint32(26).string(v!);
    }
    if (message.dir !== "") {
      writer.uint32(34).string(message.dir);
    }
    if (message.id !== "") {
      writer.uint32(42).string(message.id);
    }
    for (const v of message.waitFor) {
      writer.uint32(50).string(v!);
    }
    if (message.entrypoint !== "") {
      writer.uint32(58).string(message.entrypoint);
    }
    for (const v of message.secretEnv) {
      writer.uint32(66).string(v!);
    }
    for (const v of message.volumes) {
      Volume.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.timing !== undefined) {
      TimeSpan.encode(message.timing, writer.uint32(82).fork()).join();
    }
    if (message.pullTiming !== undefined) {
      TimeSpan.encode(message.pullTiming, writer.uint32(106).fork()).join();
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(90).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(96).int32(message.status);
    }
    if (message.allowFailure !== false) {
      writer.uint32(112).bool(message.allowFailure);
    }
    if (message.exitCode !== 0) {
      writer.uint32(128).int32(message.exitCode);
    }
    writer.uint32(146).fork();
    for (const v of message.allowExitCodes) {
      writer.int32(v);
    }
    writer.join();
    if (message.script !== "") {
      writer.uint32(154).string(message.script);
    }
    if (message.automapSubstitutions !== undefined) {
      writer.uint32(160).bool(message.automapSubstitutions);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.env.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.args.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.dir = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.id = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.waitFor.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.entrypoint = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.secretEnv.push(reader.string());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.volumes.push(Volume.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.timing = TimeSpan.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.pullTiming = TimeSpan.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 14:
          if (tag !== 112) {
            break;
          }

          message.allowFailure = reader.bool();
          continue;
        case 16:
          if (tag !== 128) {
            break;
          }

          message.exitCode = reader.int32();
          continue;
        case 18:
          if (tag === 144) {
            message.allowExitCodes.push(reader.int32());

            continue;
          }

          if (tag === 146) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.allowExitCodes.push(reader.int32());
            }

            continue;
          }

          break;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.script = reader.string();
          continue;
        case 20:
          if (tag !== 160) {
            break;
          }

          message.automapSubstitutions = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildStep {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      env: globalThis.Array.isArray(object?.env) ? object.env.map((e: any) => globalThis.String(e)) : [],
      args: globalThis.Array.isArray(object?.args) ? object.args.map((e: any) => globalThis.String(e)) : [],
      dir: isSet(object.dir) ? globalThis.String(object.dir) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      waitFor: globalThis.Array.isArray(object?.waitFor) ? object.waitFor.map((e: any) => globalThis.String(e)) : [],
      entrypoint: isSet(object.entrypoint) ? globalThis.String(object.entrypoint) : "",
      secretEnv: globalThis.Array.isArray(object?.secretEnv)
        ? object.secretEnv.map((e: any) => globalThis.String(e))
        : [],
      volumes: globalThis.Array.isArray(object?.volumes) ? object.volumes.map((e: any) => Volume.fromJSON(e)) : [],
      timing: isSet(object.timing) ? TimeSpan.fromJSON(object.timing) : undefined,
      pullTiming: isSet(object.pullTiming) ? TimeSpan.fromJSON(object.pullTiming) : undefined,
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      status: isSet(object.status) ? build_StatusFromJSON(object.status) : 0,
      allowFailure: isSet(object.allowFailure) ? globalThis.Boolean(object.allowFailure) : false,
      exitCode: isSet(object.exitCode) ? globalThis.Number(object.exitCode) : 0,
      allowExitCodes: globalThis.Array.isArray(object?.allowExitCodes)
        ? object.allowExitCodes.map((e: any) => globalThis.Number(e))
        : [],
      script: isSet(object.script) ? globalThis.String(object.script) : "",
      automapSubstitutions: isSet(object.automapSubstitutions)
        ? globalThis.Boolean(object.automapSubstitutions)
        : undefined,
    };
  },

  toJSON(message: BuildStep): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.env?.length) {
      obj.env = message.env;
    }
    if (message.args?.length) {
      obj.args = message.args;
    }
    if (message.dir !== "") {
      obj.dir = message.dir;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.waitFor?.length) {
      obj.waitFor = message.waitFor;
    }
    if (message.entrypoint !== "") {
      obj.entrypoint = message.entrypoint;
    }
    if (message.secretEnv?.length) {
      obj.secretEnv = message.secretEnv;
    }
    if (message.volumes?.length) {
      obj.volumes = message.volumes.map((e) => Volume.toJSON(e));
    }
    if (message.timing !== undefined) {
      obj.timing = TimeSpan.toJSON(message.timing);
    }
    if (message.pullTiming !== undefined) {
      obj.pullTiming = TimeSpan.toJSON(message.pullTiming);
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.status !== 0) {
      obj.status = build_StatusToJSON(message.status);
    }
    if (message.allowFailure !== false) {
      obj.allowFailure = message.allowFailure;
    }
    if (message.exitCode !== 0) {
      obj.exitCode = Math.round(message.exitCode);
    }
    if (message.allowExitCodes?.length) {
      obj.allowExitCodes = message.allowExitCodes.map((e) => Math.round(e));
    }
    if (message.script !== "") {
      obj.script = message.script;
    }
    if (message.automapSubstitutions !== undefined) {
      obj.automapSubstitutions = message.automapSubstitutions;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildStep>): BuildStep {
    return BuildStep.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildStep>): BuildStep {
    const message = createBaseBuildStep();
    message.name = object.name ?? "";
    message.env = object.env?.map((e) => e) || [];
    message.args = object.args?.map((e) => e) || [];
    message.dir = object.dir ?? "";
    message.id = object.id ?? "";
    message.waitFor = object.waitFor?.map((e) => e) || [];
    message.entrypoint = object.entrypoint ?? "";
    message.secretEnv = object.secretEnv?.map((e) => e) || [];
    message.volumes = object.volumes?.map((e) => Volume.fromPartial(e)) || [];
    message.timing = (object.timing !== undefined && object.timing !== null)
      ? TimeSpan.fromPartial(object.timing)
      : undefined;
    message.pullTiming = (object.pullTiming !== undefined && object.pullTiming !== null)
      ? TimeSpan.fromPartial(object.pullTiming)
      : undefined;
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.status = object.status ?? 0;
    message.allowFailure = object.allowFailure ?? false;
    message.exitCode = object.exitCode ?? 0;
    message.allowExitCodes = object.allowExitCodes?.map((e) => e) || [];
    message.script = object.script ?? "";
    message.automapSubstitutions = object.automapSubstitutions ?? undefined;
    return message;
  },
};

function createBaseVolume(): Volume {
  return { name: "", path: "" };
}

export const Volume: MessageFns<Volume> = {
  encode(message: Volume, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Volume {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVolume();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Volume {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: Volume): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<Volume>): Volume {
    return Volume.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Volume>): Volume {
    const message = createBaseVolume();
    message.name = object.name ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseResults(): Results {
  return {
    images: [],
    buildStepImages: [],
    artifactManifest: "",
    numArtifacts: Long.ZERO,
    buildStepOutputs: [],
    artifactTiming: undefined,
    pythonPackages: [],
    mavenArtifacts: [],
    npmPackages: [],
  };
}

export const Results: MessageFns<Results> = {
  encode(message: Results, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.images) {
      BuiltImage.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.buildStepImages) {
      writer.uint32(26).string(v!);
    }
    if (message.artifactManifest !== "") {
      writer.uint32(34).string(message.artifactManifest);
    }
    if (!message.numArtifacts.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.numArtifacts.toString());
    }
    for (const v of message.buildStepOutputs) {
      writer.uint32(50).bytes(v!);
    }
    if (message.artifactTiming !== undefined) {
      TimeSpan.encode(message.artifactTiming, writer.uint32(58).fork()).join();
    }
    for (const v of message.pythonPackages) {
      UploadedPythonPackage.encode(v!, writer.uint32(66).fork()).join();
    }
    for (const v of message.mavenArtifacts) {
      UploadedMavenArtifact.encode(v!, writer.uint32(74).fork()).join();
    }
    for (const v of message.npmPackages) {
      UploadedNpmPackage.encode(v!, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Results {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResults();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.images.push(BuiltImage.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.buildStepImages.push(reader.string());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.artifactManifest = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.numArtifacts = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.buildStepOutputs.push(Buffer.from(reader.bytes()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.artifactTiming = TimeSpan.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.pythonPackages.push(UploadedPythonPackage.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.mavenArtifacts.push(UploadedMavenArtifact.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.npmPackages.push(UploadedNpmPackage.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Results {
    return {
      images: globalThis.Array.isArray(object?.images) ? object.images.map((e: any) => BuiltImage.fromJSON(e)) : [],
      buildStepImages: globalThis.Array.isArray(object?.buildStepImages)
        ? object.buildStepImages.map((e: any) => globalThis.String(e))
        : [],
      artifactManifest: isSet(object.artifactManifest) ? globalThis.String(object.artifactManifest) : "",
      numArtifacts: isSet(object.numArtifacts) ? Long.fromValue(object.numArtifacts) : Long.ZERO,
      buildStepOutputs: globalThis.Array.isArray(object?.buildStepOutputs)
        ? object.buildStepOutputs.map((e: any) => Buffer.from(bytesFromBase64(e)))
        : [],
      artifactTiming: isSet(object.artifactTiming) ? TimeSpan.fromJSON(object.artifactTiming) : undefined,
      pythonPackages: globalThis.Array.isArray(object?.pythonPackages)
        ? object.pythonPackages.map((e: any) => UploadedPythonPackage.fromJSON(e))
        : [],
      mavenArtifacts: globalThis.Array.isArray(object?.mavenArtifacts)
        ? object.mavenArtifacts.map((e: any) => UploadedMavenArtifact.fromJSON(e))
        : [],
      npmPackages: globalThis.Array.isArray(object?.npmPackages)
        ? object.npmPackages.map((e: any) => UploadedNpmPackage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Results): unknown {
    const obj: any = {};
    if (message.images?.length) {
      obj.images = message.images.map((e) => BuiltImage.toJSON(e));
    }
    if (message.buildStepImages?.length) {
      obj.buildStepImages = message.buildStepImages;
    }
    if (message.artifactManifest !== "") {
      obj.artifactManifest = message.artifactManifest;
    }
    if (!message.numArtifacts.equals(Long.ZERO)) {
      obj.numArtifacts = (message.numArtifacts || Long.ZERO).toString();
    }
    if (message.buildStepOutputs?.length) {
      obj.buildStepOutputs = message.buildStepOutputs.map((e) => base64FromBytes(e));
    }
    if (message.artifactTiming !== undefined) {
      obj.artifactTiming = TimeSpan.toJSON(message.artifactTiming);
    }
    if (message.pythonPackages?.length) {
      obj.pythonPackages = message.pythonPackages.map((e) => UploadedPythonPackage.toJSON(e));
    }
    if (message.mavenArtifacts?.length) {
      obj.mavenArtifacts = message.mavenArtifacts.map((e) => UploadedMavenArtifact.toJSON(e));
    }
    if (message.npmPackages?.length) {
      obj.npmPackages = message.npmPackages.map((e) => UploadedNpmPackage.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Results>): Results {
    return Results.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Results>): Results {
    const message = createBaseResults();
    message.images = object.images?.map((e) => BuiltImage.fromPartial(e)) || [];
    message.buildStepImages = object.buildStepImages?.map((e) => e) || [];
    message.artifactManifest = object.artifactManifest ?? "";
    message.numArtifacts = (object.numArtifacts !== undefined && object.numArtifacts !== null)
      ? Long.fromValue(object.numArtifacts)
      : Long.ZERO;
    message.buildStepOutputs = object.buildStepOutputs?.map((e) => e) || [];
    message.artifactTiming = (object.artifactTiming !== undefined && object.artifactTiming !== null)
      ? TimeSpan.fromPartial(object.artifactTiming)
      : undefined;
    message.pythonPackages = object.pythonPackages?.map((e) => UploadedPythonPackage.fromPartial(e)) || [];
    message.mavenArtifacts = object.mavenArtifacts?.map((e) => UploadedMavenArtifact.fromPartial(e)) || [];
    message.npmPackages = object.npmPackages?.map((e) => UploadedNpmPackage.fromPartial(e)) || [];
    return message;
  },
};

function createBaseArtifactResult(): ArtifactResult {
  return { location: "", fileHash: [] };
}

export const ArtifactResult: MessageFns<ArtifactResult> = {
  encode(message: ArtifactResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== "") {
      writer.uint32(10).string(message.location);
    }
    for (const v of message.fileHash) {
      FileHashes.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ArtifactResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArtifactResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.fileHash.push(FileHashes.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ArtifactResult {
    return {
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      fileHash: globalThis.Array.isArray(object?.fileHash)
        ? object.fileHash.map((e: any) => FileHashes.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ArtifactResult): unknown {
    const obj: any = {};
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.fileHash?.length) {
      obj.fileHash = message.fileHash.map((e) => FileHashes.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ArtifactResult>): ArtifactResult {
    return ArtifactResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ArtifactResult>): ArtifactResult {
    const message = createBaseArtifactResult();
    message.location = object.location ?? "";
    message.fileHash = object.fileHash?.map((e) => FileHashes.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBuild(): Build {
  return {
    name: "",
    id: "",
    projectId: "",
    status: 0,
    statusDetail: "",
    source: undefined,
    steps: [],
    results: undefined,
    createTime: undefined,
    startTime: undefined,
    finishTime: undefined,
    timeout: undefined,
    images: [],
    queueTtl: undefined,
    artifacts: undefined,
    logsBucket: "",
    sourceProvenance: undefined,
    buildTriggerId: "",
    options: undefined,
    logUrl: "",
    substitutions: {},
    tags: [],
    secrets: [],
    timing: {},
    approval: undefined,
    serviceAccount: "",
    availableSecrets: undefined,
    warnings: [],
    failureInfo: undefined,
  };
}

export const Build: MessageFns<Build> = {
  encode(message: Build, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(362).string(message.name);
    }
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.projectId !== "") {
      writer.uint32(130).string(message.projectId);
    }
    if (message.status !== 0) {
      writer.uint32(16).int32(message.status);
    }
    if (message.statusDetail !== "") {
      writer.uint32(194).string(message.statusDetail);
    }
    if (message.source !== undefined) {
      Source.encode(message.source, writer.uint32(26).fork()).join();
    }
    for (const v of message.steps) {
      BuildStep.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.results !== undefined) {
      Results.encode(message.results, writer.uint32(82).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(58).fork()).join();
    }
    if (message.finishTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finishTime), writer.uint32(66).fork()).join();
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(98).fork()).join();
    }
    for (const v of message.images) {
      writer.uint32(106).string(v!);
    }
    if (message.queueTtl !== undefined) {
      Duration.encode(message.queueTtl, writer.uint32(322).fork()).join();
    }
    if (message.artifacts !== undefined) {
      Artifacts.encode(message.artifacts, writer.uint32(298).fork()).join();
    }
    if (message.logsBucket !== "") {
      writer.uint32(154).string(message.logsBucket);
    }
    if (message.sourceProvenance !== undefined) {
      SourceProvenance.encode(message.sourceProvenance, writer.uint32(170).fork()).join();
    }
    if (message.buildTriggerId !== "") {
      writer.uint32(178).string(message.buildTriggerId);
    }
    if (message.options !== undefined) {
      BuildOptions.encode(message.options, writer.uint32(186).fork()).join();
    }
    if (message.logUrl !== "") {
      writer.uint32(202).string(message.logUrl);
    }
    Object.entries(message.substitutions).forEach(([key, value]) => {
      Build_SubstitutionsEntry.encode({ key: key as any, value }, writer.uint32(234).fork()).join();
    });
    for (const v of message.tags) {
      writer.uint32(250).string(v!);
    }
    for (const v of message.secrets) {
      Secret.encode(v!, writer.uint32(258).fork()).join();
    }
    Object.entries(message.timing).forEach(([key, value]) => {
      Build_TimingEntry.encode({ key: key as any, value }, writer.uint32(266).fork()).join();
    });
    if (message.approval !== undefined) {
      BuildApproval.encode(message.approval, writer.uint32(354).fork()).join();
    }
    if (message.serviceAccount !== "") {
      writer.uint32(338).string(message.serviceAccount);
    }
    if (message.availableSecrets !== undefined) {
      Secrets.encode(message.availableSecrets, writer.uint32(378).fork()).join();
    }
    for (const v of message.warnings) {
      Build_Warning.encode(v!, writer.uint32(394).fork()).join();
    }
    if (message.failureInfo !== undefined) {
      Build_FailureInfo.encode(message.failureInfo, writer.uint32(410).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Build {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuild();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 45:
          if (tag !== 362) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.statusDetail = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.source = Source.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.steps.push(BuildStep.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.results = Results.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.finishTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.images.push(reader.string());
          continue;
        case 40:
          if (tag !== 322) {
            break;
          }

          message.queueTtl = Duration.decode(reader, reader.uint32());
          continue;
        case 37:
          if (tag !== 298) {
            break;
          }

          message.artifacts = Artifacts.decode(reader, reader.uint32());
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.logsBucket = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.sourceProvenance = SourceProvenance.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 178) {
            break;
          }

          message.buildTriggerId = reader.string();
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.options = BuildOptions.decode(reader, reader.uint32());
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.logUrl = reader.string();
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          const entry29 = Build_SubstitutionsEntry.decode(reader, reader.uint32());
          if (entry29.value !== undefined) {
            message.substitutions[entry29.key] = entry29.value;
          }
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.tags.push(reader.string());
          continue;
        case 32:
          if (tag !== 258) {
            break;
          }

          message.secrets.push(Secret.decode(reader, reader.uint32()));
          continue;
        case 33:
          if (tag !== 266) {
            break;
          }

          const entry33 = Build_TimingEntry.decode(reader, reader.uint32());
          if (entry33.value !== undefined) {
            message.timing[entry33.key] = entry33.value;
          }
          continue;
        case 44:
          if (tag !== 354) {
            break;
          }

          message.approval = BuildApproval.decode(reader, reader.uint32());
          continue;
        case 42:
          if (tag !== 338) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        case 47:
          if (tag !== 378) {
            break;
          }

          message.availableSecrets = Secrets.decode(reader, reader.uint32());
          continue;
        case 49:
          if (tag !== 394) {
            break;
          }

          message.warnings.push(Build_Warning.decode(reader, reader.uint32()));
          continue;
        case 51:
          if (tag !== 410) {
            break;
          }

          message.failureInfo = Build_FailureInfo.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Build {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      status: isSet(object.status) ? build_StatusFromJSON(object.status) : 0,
      statusDetail: isSet(object.statusDetail) ? globalThis.String(object.statusDetail) : "",
      source: isSet(object.source) ? Source.fromJSON(object.source) : undefined,
      steps: globalThis.Array.isArray(object?.steps) ? object.steps.map((e: any) => BuildStep.fromJSON(e)) : [],
      results: isSet(object.results) ? Results.fromJSON(object.results) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      finishTime: isSet(object.finishTime) ? fromJsonTimestamp(object.finishTime) : undefined,
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      images: globalThis.Array.isArray(object?.images) ? object.images.map((e: any) => globalThis.String(e)) : [],
      queueTtl: isSet(object.queueTtl) ? Duration.fromJSON(object.queueTtl) : undefined,
      artifacts: isSet(object.artifacts) ? Artifacts.fromJSON(object.artifacts) : undefined,
      logsBucket: isSet(object.logsBucket) ? globalThis.String(object.logsBucket) : "",
      sourceProvenance: isSet(object.sourceProvenance) ? SourceProvenance.fromJSON(object.sourceProvenance) : undefined,
      buildTriggerId: isSet(object.buildTriggerId) ? globalThis.String(object.buildTriggerId) : "",
      options: isSet(object.options) ? BuildOptions.fromJSON(object.options) : undefined,
      logUrl: isSet(object.logUrl) ? globalThis.String(object.logUrl) : "",
      substitutions: isObject(object.substitutions)
        ? Object.entries(object.substitutions).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => globalThis.String(e)) : [],
      secrets: globalThis.Array.isArray(object?.secrets) ? object.secrets.map((e: any) => Secret.fromJSON(e)) : [],
      timing: isObject(object.timing)
        ? Object.entries(object.timing).reduce<{ [key: string]: TimeSpan }>((acc, [key, value]) => {
          acc[key] = TimeSpan.fromJSON(value);
          return acc;
        }, {})
        : {},
      approval: isSet(object.approval) ? BuildApproval.fromJSON(object.approval) : undefined,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      availableSecrets: isSet(object.availableSecrets) ? Secrets.fromJSON(object.availableSecrets) : undefined,
      warnings: globalThis.Array.isArray(object?.warnings)
        ? object.warnings.map((e: any) => Build_Warning.fromJSON(e))
        : [],
      failureInfo: isSet(object.failureInfo) ? Build_FailureInfo.fromJSON(object.failureInfo) : undefined,
    };
  },

  toJSON(message: Build): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.status !== 0) {
      obj.status = build_StatusToJSON(message.status);
    }
    if (message.statusDetail !== "") {
      obj.statusDetail = message.statusDetail;
    }
    if (message.source !== undefined) {
      obj.source = Source.toJSON(message.source);
    }
    if (message.steps?.length) {
      obj.steps = message.steps.map((e) => BuildStep.toJSON(e));
    }
    if (message.results !== undefined) {
      obj.results = Results.toJSON(message.results);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.finishTime !== undefined) {
      obj.finishTime = message.finishTime.toISOString();
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.images?.length) {
      obj.images = message.images;
    }
    if (message.queueTtl !== undefined) {
      obj.queueTtl = Duration.toJSON(message.queueTtl);
    }
    if (message.artifacts !== undefined) {
      obj.artifacts = Artifacts.toJSON(message.artifacts);
    }
    if (message.logsBucket !== "") {
      obj.logsBucket = message.logsBucket;
    }
    if (message.sourceProvenance !== undefined) {
      obj.sourceProvenance = SourceProvenance.toJSON(message.sourceProvenance);
    }
    if (message.buildTriggerId !== "") {
      obj.buildTriggerId = message.buildTriggerId;
    }
    if (message.options !== undefined) {
      obj.options = BuildOptions.toJSON(message.options);
    }
    if (message.logUrl !== "") {
      obj.logUrl = message.logUrl;
    }
    if (message.substitutions) {
      const entries = Object.entries(message.substitutions);
      if (entries.length > 0) {
        obj.substitutions = {};
        entries.forEach(([k, v]) => {
          obj.substitutions[k] = v;
        });
      }
    }
    if (message.tags?.length) {
      obj.tags = message.tags;
    }
    if (message.secrets?.length) {
      obj.secrets = message.secrets.map((e) => Secret.toJSON(e));
    }
    if (message.timing) {
      const entries = Object.entries(message.timing);
      if (entries.length > 0) {
        obj.timing = {};
        entries.forEach(([k, v]) => {
          obj.timing[k] = TimeSpan.toJSON(v);
        });
      }
    }
    if (message.approval !== undefined) {
      obj.approval = BuildApproval.toJSON(message.approval);
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.availableSecrets !== undefined) {
      obj.availableSecrets = Secrets.toJSON(message.availableSecrets);
    }
    if (message.warnings?.length) {
      obj.warnings = message.warnings.map((e) => Build_Warning.toJSON(e));
    }
    if (message.failureInfo !== undefined) {
      obj.failureInfo = Build_FailureInfo.toJSON(message.failureInfo);
    }
    return obj;
  },

  create(base?: DeepPartial<Build>): Build {
    return Build.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Build>): Build {
    const message = createBaseBuild();
    message.name = object.name ?? "";
    message.id = object.id ?? "";
    message.projectId = object.projectId ?? "";
    message.status = object.status ?? 0;
    message.statusDetail = object.statusDetail ?? "";
    message.source = (object.source !== undefined && object.source !== null)
      ? Source.fromPartial(object.source)
      : undefined;
    message.steps = object.steps?.map((e) => BuildStep.fromPartial(e)) || [];
    message.results = (object.results !== undefined && object.results !== null)
      ? Results.fromPartial(object.results)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.finishTime = object.finishTime ?? undefined;
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.images = object.images?.map((e) => e) || [];
    message.queueTtl = (object.queueTtl !== undefined && object.queueTtl !== null)
      ? Duration.fromPartial(object.queueTtl)
      : undefined;
    message.artifacts = (object.artifacts !== undefined && object.artifacts !== null)
      ? Artifacts.fromPartial(object.artifacts)
      : undefined;
    message.logsBucket = object.logsBucket ?? "";
    message.sourceProvenance = (object.sourceProvenance !== undefined && object.sourceProvenance !== null)
      ? SourceProvenance.fromPartial(object.sourceProvenance)
      : undefined;
    message.buildTriggerId = object.buildTriggerId ?? "";
    message.options = (object.options !== undefined && object.options !== null)
      ? BuildOptions.fromPartial(object.options)
      : undefined;
    message.logUrl = object.logUrl ?? "";
    message.substitutions = Object.entries(object.substitutions ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.tags = object.tags?.map((e) => e) || [];
    message.secrets = object.secrets?.map((e) => Secret.fromPartial(e)) || [];
    message.timing = Object.entries(object.timing ?? {}).reduce<{ [key: string]: TimeSpan }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = TimeSpan.fromPartial(value);
      }
      return acc;
    }, {});
    message.approval = (object.approval !== undefined && object.approval !== null)
      ? BuildApproval.fromPartial(object.approval)
      : undefined;
    message.serviceAccount = object.serviceAccount ?? "";
    message.availableSecrets = (object.availableSecrets !== undefined && object.availableSecrets !== null)
      ? Secrets.fromPartial(object.availableSecrets)
      : undefined;
    message.warnings = object.warnings?.map((e) => Build_Warning.fromPartial(e)) || [];
    message.failureInfo = (object.failureInfo !== undefined && object.failureInfo !== null)
      ? Build_FailureInfo.fromPartial(object.failureInfo)
      : undefined;
    return message;
  },
};

function createBaseBuild_Warning(): Build_Warning {
  return { text: "", priority: 0 };
}

export const Build_Warning: MessageFns<Build_Warning> = {
  encode(message: Build_Warning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    if (message.priority !== 0) {
      writer.uint32(16).int32(message.priority);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Build_Warning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuild_Warning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.priority = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Build_Warning {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : "",
      priority: isSet(object.priority) ? build_Warning_PriorityFromJSON(object.priority) : 0,
    };
  },

  toJSON(message: Build_Warning): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    if (message.priority !== 0) {
      obj.priority = build_Warning_PriorityToJSON(message.priority);
    }
    return obj;
  },

  create(base?: DeepPartial<Build_Warning>): Build_Warning {
    return Build_Warning.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Build_Warning>): Build_Warning {
    const message = createBaseBuild_Warning();
    message.text = object.text ?? "";
    message.priority = object.priority ?? 0;
    return message;
  },
};

function createBaseBuild_FailureInfo(): Build_FailureInfo {
  return { type: 0, detail: "" };
}

export const Build_FailureInfo: MessageFns<Build_FailureInfo> = {
  encode(message: Build_FailureInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.detail !== "") {
      writer.uint32(18).string(message.detail);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Build_FailureInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuild_FailureInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.detail = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Build_FailureInfo {
    return {
      type: isSet(object.type) ? build_FailureInfo_FailureTypeFromJSON(object.type) : 0,
      detail: isSet(object.detail) ? globalThis.String(object.detail) : "",
    };
  },

  toJSON(message: Build_FailureInfo): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = build_FailureInfo_FailureTypeToJSON(message.type);
    }
    if (message.detail !== "") {
      obj.detail = message.detail;
    }
    return obj;
  },

  create(base?: DeepPartial<Build_FailureInfo>): Build_FailureInfo {
    return Build_FailureInfo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Build_FailureInfo>): Build_FailureInfo {
    const message = createBaseBuild_FailureInfo();
    message.type = object.type ?? 0;
    message.detail = object.detail ?? "";
    return message;
  },
};

function createBaseBuild_SubstitutionsEntry(): Build_SubstitutionsEntry {
  return { key: "", value: "" };
}

export const Build_SubstitutionsEntry: MessageFns<Build_SubstitutionsEntry> = {
  encode(message: Build_SubstitutionsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Build_SubstitutionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuild_SubstitutionsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Build_SubstitutionsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Build_SubstitutionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Build_SubstitutionsEntry>): Build_SubstitutionsEntry {
    return Build_SubstitutionsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Build_SubstitutionsEntry>): Build_SubstitutionsEntry {
    const message = createBaseBuild_SubstitutionsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBuild_TimingEntry(): Build_TimingEntry {
  return { key: "", value: undefined };
}

export const Build_TimingEntry: MessageFns<Build_TimingEntry> = {
  encode(message: Build_TimingEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      TimeSpan.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Build_TimingEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuild_TimingEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = TimeSpan.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Build_TimingEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? TimeSpan.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: Build_TimingEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = TimeSpan.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<Build_TimingEntry>): Build_TimingEntry {
    return Build_TimingEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Build_TimingEntry>): Build_TimingEntry {
    const message = createBaseBuild_TimingEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? TimeSpan.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseArtifacts(): Artifacts {
  return { images: [], objects: undefined, mavenArtifacts: [], pythonPackages: [], npmPackages: [] };
}

export const Artifacts: MessageFns<Artifacts> = {
  encode(message: Artifacts, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.images) {
      writer.uint32(10).string(v!);
    }
    if (message.objects !== undefined) {
      Artifacts_ArtifactObjects.encode(message.objects, writer.uint32(18).fork()).join();
    }
    for (const v of message.mavenArtifacts) {
      Artifacts_MavenArtifact.encode(v!, writer.uint32(26).fork()).join();
    }
    for (const v of message.pythonPackages) {
      Artifacts_PythonPackage.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.npmPackages) {
      Artifacts_NpmPackage.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Artifacts {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArtifacts();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.images.push(reader.string());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.objects = Artifacts_ArtifactObjects.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.mavenArtifacts.push(Artifacts_MavenArtifact.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pythonPackages.push(Artifacts_PythonPackage.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.npmPackages.push(Artifacts_NpmPackage.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Artifacts {
    return {
      images: globalThis.Array.isArray(object?.images) ? object.images.map((e: any) => globalThis.String(e)) : [],
      objects: isSet(object.objects) ? Artifacts_ArtifactObjects.fromJSON(object.objects) : undefined,
      mavenArtifacts: globalThis.Array.isArray(object?.mavenArtifacts)
        ? object.mavenArtifacts.map((e: any) => Artifacts_MavenArtifact.fromJSON(e))
        : [],
      pythonPackages: globalThis.Array.isArray(object?.pythonPackages)
        ? object.pythonPackages.map((e: any) => Artifacts_PythonPackage.fromJSON(e))
        : [],
      npmPackages: globalThis.Array.isArray(object?.npmPackages)
        ? object.npmPackages.map((e: any) => Artifacts_NpmPackage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Artifacts): unknown {
    const obj: any = {};
    if (message.images?.length) {
      obj.images = message.images;
    }
    if (message.objects !== undefined) {
      obj.objects = Artifacts_ArtifactObjects.toJSON(message.objects);
    }
    if (message.mavenArtifacts?.length) {
      obj.mavenArtifacts = message.mavenArtifacts.map((e) => Artifacts_MavenArtifact.toJSON(e));
    }
    if (message.pythonPackages?.length) {
      obj.pythonPackages = message.pythonPackages.map((e) => Artifacts_PythonPackage.toJSON(e));
    }
    if (message.npmPackages?.length) {
      obj.npmPackages = message.npmPackages.map((e) => Artifacts_NpmPackage.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Artifacts>): Artifacts {
    return Artifacts.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Artifacts>): Artifacts {
    const message = createBaseArtifacts();
    message.images = object.images?.map((e) => e) || [];
    message.objects = (object.objects !== undefined && object.objects !== null)
      ? Artifacts_ArtifactObjects.fromPartial(object.objects)
      : undefined;
    message.mavenArtifacts = object.mavenArtifacts?.map((e) => Artifacts_MavenArtifact.fromPartial(e)) || [];
    message.pythonPackages = object.pythonPackages?.map((e) => Artifacts_PythonPackage.fromPartial(e)) || [];
    message.npmPackages = object.npmPackages?.map((e) => Artifacts_NpmPackage.fromPartial(e)) || [];
    return message;
  },
};

function createBaseArtifacts_ArtifactObjects(): Artifacts_ArtifactObjects {
  return { location: "", paths: [], timing: undefined };
}

export const Artifacts_ArtifactObjects: MessageFns<Artifacts_ArtifactObjects> = {
  encode(message: Artifacts_ArtifactObjects, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== "") {
      writer.uint32(10).string(message.location);
    }
    for (const v of message.paths) {
      writer.uint32(18).string(v!);
    }
    if (message.timing !== undefined) {
      TimeSpan.encode(message.timing, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Artifacts_ArtifactObjects {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArtifacts_ArtifactObjects();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.paths.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timing = TimeSpan.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Artifacts_ArtifactObjects {
    return {
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      paths: globalThis.Array.isArray(object?.paths) ? object.paths.map((e: any) => globalThis.String(e)) : [],
      timing: isSet(object.timing) ? TimeSpan.fromJSON(object.timing) : undefined,
    };
  },

  toJSON(message: Artifacts_ArtifactObjects): unknown {
    const obj: any = {};
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.paths?.length) {
      obj.paths = message.paths;
    }
    if (message.timing !== undefined) {
      obj.timing = TimeSpan.toJSON(message.timing);
    }
    return obj;
  },

  create(base?: DeepPartial<Artifacts_ArtifactObjects>): Artifacts_ArtifactObjects {
    return Artifacts_ArtifactObjects.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Artifacts_ArtifactObjects>): Artifacts_ArtifactObjects {
    const message = createBaseArtifacts_ArtifactObjects();
    message.location = object.location ?? "";
    message.paths = object.paths?.map((e) => e) || [];
    message.timing = (object.timing !== undefined && object.timing !== null)
      ? TimeSpan.fromPartial(object.timing)
      : undefined;
    return message;
  },
};

function createBaseArtifacts_MavenArtifact(): Artifacts_MavenArtifact {
  return { repository: "", path: "", artifactId: "", groupId: "", version: "" };
}

export const Artifacts_MavenArtifact: MessageFns<Artifacts_MavenArtifact> = {
  encode(message: Artifacts_MavenArtifact, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.repository !== "") {
      writer.uint32(10).string(message.repository);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.artifactId !== "") {
      writer.uint32(26).string(message.artifactId);
    }
    if (message.groupId !== "") {
      writer.uint32(34).string(message.groupId);
    }
    if (message.version !== "") {
      writer.uint32(42).string(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Artifacts_MavenArtifact {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArtifacts_MavenArtifact();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.artifactId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.groupId = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.version = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Artifacts_MavenArtifact {
    return {
      repository: isSet(object.repository) ? globalThis.String(object.repository) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      artifactId: isSet(object.artifactId) ? globalThis.String(object.artifactId) : "",
      groupId: isSet(object.groupId) ? globalThis.String(object.groupId) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
    };
  },

  toJSON(message: Artifacts_MavenArtifact): unknown {
    const obj: any = {};
    if (message.repository !== "") {
      obj.repository = message.repository;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.artifactId !== "") {
      obj.artifactId = message.artifactId;
    }
    if (message.groupId !== "") {
      obj.groupId = message.groupId;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    return obj;
  },

  create(base?: DeepPartial<Artifacts_MavenArtifact>): Artifacts_MavenArtifact {
    return Artifacts_MavenArtifact.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Artifacts_MavenArtifact>): Artifacts_MavenArtifact {
    const message = createBaseArtifacts_MavenArtifact();
    message.repository = object.repository ?? "";
    message.path = object.path ?? "";
    message.artifactId = object.artifactId ?? "";
    message.groupId = object.groupId ?? "";
    message.version = object.version ?? "";
    return message;
  },
};

function createBaseArtifacts_PythonPackage(): Artifacts_PythonPackage {
  return { repository: "", paths: [] };
}

export const Artifacts_PythonPackage: MessageFns<Artifacts_PythonPackage> = {
  encode(message: Artifacts_PythonPackage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.repository !== "") {
      writer.uint32(10).string(message.repository);
    }
    for (const v of message.paths) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Artifacts_PythonPackage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArtifacts_PythonPackage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.paths.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Artifacts_PythonPackage {
    return {
      repository: isSet(object.repository) ? globalThis.String(object.repository) : "",
      paths: globalThis.Array.isArray(object?.paths) ? object.paths.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: Artifacts_PythonPackage): unknown {
    const obj: any = {};
    if (message.repository !== "") {
      obj.repository = message.repository;
    }
    if (message.paths?.length) {
      obj.paths = message.paths;
    }
    return obj;
  },

  create(base?: DeepPartial<Artifacts_PythonPackage>): Artifacts_PythonPackage {
    return Artifacts_PythonPackage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Artifacts_PythonPackage>): Artifacts_PythonPackage {
    const message = createBaseArtifacts_PythonPackage();
    message.repository = object.repository ?? "";
    message.paths = object.paths?.map((e) => e) || [];
    return message;
  },
};

function createBaseArtifacts_NpmPackage(): Artifacts_NpmPackage {
  return { repository: "", packagePath: "" };
}

export const Artifacts_NpmPackage: MessageFns<Artifacts_NpmPackage> = {
  encode(message: Artifacts_NpmPackage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.repository !== "") {
      writer.uint32(10).string(message.repository);
    }
    if (message.packagePath !== "") {
      writer.uint32(18).string(message.packagePath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Artifacts_NpmPackage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseArtifacts_NpmPackage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.packagePath = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Artifacts_NpmPackage {
    return {
      repository: isSet(object.repository) ? globalThis.String(object.repository) : "",
      packagePath: isSet(object.packagePath) ? globalThis.String(object.packagePath) : "",
    };
  },

  toJSON(message: Artifacts_NpmPackage): unknown {
    const obj: any = {};
    if (message.repository !== "") {
      obj.repository = message.repository;
    }
    if (message.packagePath !== "") {
      obj.packagePath = message.packagePath;
    }
    return obj;
  },

  create(base?: DeepPartial<Artifacts_NpmPackage>): Artifacts_NpmPackage {
    return Artifacts_NpmPackage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Artifacts_NpmPackage>): Artifacts_NpmPackage {
    const message = createBaseArtifacts_NpmPackage();
    message.repository = object.repository ?? "";
    message.packagePath = object.packagePath ?? "";
    return message;
  },
};

function createBaseTimeSpan(): TimeSpan {
  return { startTime: undefined, endTime: undefined };
}

export const TimeSpan: MessageFns<TimeSpan> = {
  encode(message: TimeSpan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TimeSpan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTimeSpan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TimeSpan {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: TimeSpan): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<TimeSpan>): TimeSpan {
    return TimeSpan.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TimeSpan>): TimeSpan {
    const message = createBaseTimeSpan();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseBuildOperationMetadata(): BuildOperationMetadata {
  return { build: undefined };
}

export const BuildOperationMetadata: MessageFns<BuildOperationMetadata> = {
  encode(message: BuildOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.build !== undefined) {
      Build.encode(message.build, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.build = Build.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildOperationMetadata {
    return { build: isSet(object.build) ? Build.fromJSON(object.build) : undefined };
  },

  toJSON(message: BuildOperationMetadata): unknown {
    const obj: any = {};
    if (message.build !== undefined) {
      obj.build = Build.toJSON(message.build);
    }
    return obj;
  },

  create(base?: DeepPartial<BuildOperationMetadata>): BuildOperationMetadata {
    return BuildOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildOperationMetadata>): BuildOperationMetadata {
    const message = createBaseBuildOperationMetadata();
    message.build = (object.build !== undefined && object.build !== null) ? Build.fromPartial(object.build) : undefined;
    return message;
  },
};

function createBaseSourceProvenance(): SourceProvenance {
  return {
    resolvedStorageSource: undefined,
    resolvedRepoSource: undefined,
    resolvedStorageSourceManifest: undefined,
    fileHashes: {},
  };
}

export const SourceProvenance: MessageFns<SourceProvenance> = {
  encode(message: SourceProvenance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resolvedStorageSource !== undefined) {
      StorageSource.encode(message.resolvedStorageSource, writer.uint32(26).fork()).join();
    }
    if (message.resolvedRepoSource !== undefined) {
      RepoSource.encode(message.resolvedRepoSource, writer.uint32(50).fork()).join();
    }
    if (message.resolvedStorageSourceManifest !== undefined) {
      StorageSourceManifest.encode(message.resolvedStorageSourceManifest, writer.uint32(74).fork()).join();
    }
    Object.entries(message.fileHashes).forEach(([key, value]) => {
      SourceProvenance_FileHashesEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceProvenance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceProvenance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.resolvedStorageSource = StorageSource.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.resolvedRepoSource = RepoSource.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.resolvedStorageSourceManifest = StorageSourceManifest.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = SourceProvenance_FileHashesEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.fileHashes[entry4.key] = entry4.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceProvenance {
    return {
      resolvedStorageSource: isSet(object.resolvedStorageSource)
        ? StorageSource.fromJSON(object.resolvedStorageSource)
        : undefined,
      resolvedRepoSource: isSet(object.resolvedRepoSource) ? RepoSource.fromJSON(object.resolvedRepoSource) : undefined,
      resolvedStorageSourceManifest: isSet(object.resolvedStorageSourceManifest)
        ? StorageSourceManifest.fromJSON(object.resolvedStorageSourceManifest)
        : undefined,
      fileHashes: isObject(object.fileHashes)
        ? Object.entries(object.fileHashes).reduce<{ [key: string]: FileHashes }>((acc, [key, value]) => {
          acc[key] = FileHashes.fromJSON(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: SourceProvenance): unknown {
    const obj: any = {};
    if (message.resolvedStorageSource !== undefined) {
      obj.resolvedStorageSource = StorageSource.toJSON(message.resolvedStorageSource);
    }
    if (message.resolvedRepoSource !== undefined) {
      obj.resolvedRepoSource = RepoSource.toJSON(message.resolvedRepoSource);
    }
    if (message.resolvedStorageSourceManifest !== undefined) {
      obj.resolvedStorageSourceManifest = StorageSourceManifest.toJSON(message.resolvedStorageSourceManifest);
    }
    if (message.fileHashes) {
      const entries = Object.entries(message.fileHashes);
      if (entries.length > 0) {
        obj.fileHashes = {};
        entries.forEach(([k, v]) => {
          obj.fileHashes[k] = FileHashes.toJSON(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<SourceProvenance>): SourceProvenance {
    return SourceProvenance.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceProvenance>): SourceProvenance {
    const message = createBaseSourceProvenance();
    message.resolvedStorageSource =
      (object.resolvedStorageSource !== undefined && object.resolvedStorageSource !== null)
        ? StorageSource.fromPartial(object.resolvedStorageSource)
        : undefined;
    message.resolvedRepoSource = (object.resolvedRepoSource !== undefined && object.resolvedRepoSource !== null)
      ? RepoSource.fromPartial(object.resolvedRepoSource)
      : undefined;
    message.resolvedStorageSourceManifest =
      (object.resolvedStorageSourceManifest !== undefined && object.resolvedStorageSourceManifest !== null)
        ? StorageSourceManifest.fromPartial(object.resolvedStorageSourceManifest)
        : undefined;
    message.fileHashes = Object.entries(object.fileHashes ?? {}).reduce<{ [key: string]: FileHashes }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = FileHashes.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseSourceProvenance_FileHashesEntry(): SourceProvenance_FileHashesEntry {
  return { key: "", value: undefined };
}

export const SourceProvenance_FileHashesEntry: MessageFns<SourceProvenance_FileHashesEntry> = {
  encode(message: SourceProvenance_FileHashesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      FileHashes.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceProvenance_FileHashesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceProvenance_FileHashesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = FileHashes.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceProvenance_FileHashesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? FileHashes.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: SourceProvenance_FileHashesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = FileHashes.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<SourceProvenance_FileHashesEntry>): SourceProvenance_FileHashesEntry {
    return SourceProvenance_FileHashesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceProvenance_FileHashesEntry>): SourceProvenance_FileHashesEntry {
    const message = createBaseSourceProvenance_FileHashesEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? FileHashes.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseFileHashes(): FileHashes {
  return { fileHash: [] };
}

export const FileHashes: MessageFns<FileHashes> = {
  encode(message: FileHashes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fileHash) {
      Hash.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FileHashes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFileHashes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fileHash.push(Hash.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FileHashes {
    return {
      fileHash: globalThis.Array.isArray(object?.fileHash) ? object.fileHash.map((e: any) => Hash.fromJSON(e)) : [],
    };
  },

  toJSON(message: FileHashes): unknown {
    const obj: any = {};
    if (message.fileHash?.length) {
      obj.fileHash = message.fileHash.map((e) => Hash.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<FileHashes>): FileHashes {
    return FileHashes.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FileHashes>): FileHashes {
    const message = createBaseFileHashes();
    message.fileHash = object.fileHash?.map((e) => Hash.fromPartial(e)) || [];
    return message;
  },
};

function createBaseHash(): Hash {
  return { type: 0, value: Buffer.alloc(0) };
}

export const Hash: MessageFns<Hash> = {
  encode(message: Hash, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.value.length !== 0) {
      writer.uint32(18).bytes(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Hash {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHash();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Hash {
    return {
      type: isSet(object.type) ? hash_HashTypeFromJSON(object.type) : 0,
      value: isSet(object.value) ? Buffer.from(bytesFromBase64(object.value)) : Buffer.alloc(0),
    };
  },

  toJSON(message: Hash): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = hash_HashTypeToJSON(message.type);
    }
    if (message.value.length !== 0) {
      obj.value = base64FromBytes(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<Hash>): Hash {
    return Hash.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Hash>): Hash {
    const message = createBaseHash();
    message.type = object.type ?? 0;
    message.value = object.value ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseSecrets(): Secrets {
  return { secretManager: [], inline: [] };
}

export const Secrets: MessageFns<Secrets> = {
  encode(message: Secrets, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.secretManager) {
      SecretManagerSecret.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.inline) {
      InlineSecret.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Secrets {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecrets();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.secretManager.push(SecretManagerSecret.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.inline.push(InlineSecret.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Secrets {
    return {
      secretManager: globalThis.Array.isArray(object?.secretManager)
        ? object.secretManager.map((e: any) => SecretManagerSecret.fromJSON(e))
        : [],
      inline: globalThis.Array.isArray(object?.inline) ? object.inline.map((e: any) => InlineSecret.fromJSON(e)) : [],
    };
  },

  toJSON(message: Secrets): unknown {
    const obj: any = {};
    if (message.secretManager?.length) {
      obj.secretManager = message.secretManager.map((e) => SecretManagerSecret.toJSON(e));
    }
    if (message.inline?.length) {
      obj.inline = message.inline.map((e) => InlineSecret.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Secrets>): Secrets {
    return Secrets.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Secrets>): Secrets {
    const message = createBaseSecrets();
    message.secretManager = object.secretManager?.map((e) => SecretManagerSecret.fromPartial(e)) || [];
    message.inline = object.inline?.map((e) => InlineSecret.fromPartial(e)) || [];
    return message;
  },
};

function createBaseInlineSecret(): InlineSecret {
  return { kmsKeyName: "", envMap: {} };
}

export const InlineSecret: MessageFns<InlineSecret> = {
  encode(message: InlineSecret, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKeyName !== "") {
      writer.uint32(10).string(message.kmsKeyName);
    }
    Object.entries(message.envMap).forEach(([key, value]) => {
      InlineSecret_EnvMapEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InlineSecret {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInlineSecret();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = InlineSecret_EnvMapEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.envMap[entry2.key] = entry2.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InlineSecret {
    return {
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      envMap: isObject(object.envMap)
        ? Object.entries(object.envMap).reduce<{ [key: string]: Buffer }>((acc, [key, value]) => {
          acc[key] = Buffer.from(bytesFromBase64(value as string));
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: InlineSecret): unknown {
    const obj: any = {};
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.envMap) {
      const entries = Object.entries(message.envMap);
      if (entries.length > 0) {
        obj.envMap = {};
        entries.forEach(([k, v]) => {
          obj.envMap[k] = base64FromBytes(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<InlineSecret>): InlineSecret {
    return InlineSecret.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InlineSecret>): InlineSecret {
    const message = createBaseInlineSecret();
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.envMap = Object.entries(object.envMap ?? {}).reduce<{ [key: string]: Buffer }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = value;
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseInlineSecret_EnvMapEntry(): InlineSecret_EnvMapEntry {
  return { key: "", value: Buffer.alloc(0) };
}

export const InlineSecret_EnvMapEntry: MessageFns<InlineSecret_EnvMapEntry> = {
  encode(message: InlineSecret_EnvMapEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value.length !== 0) {
      writer.uint32(18).bytes(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InlineSecret_EnvMapEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInlineSecret_EnvMapEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InlineSecret_EnvMapEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Buffer.from(bytesFromBase64(object.value)) : Buffer.alloc(0),
    };
  },

  toJSON(message: InlineSecret_EnvMapEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value.length !== 0) {
      obj.value = base64FromBytes(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<InlineSecret_EnvMapEntry>): InlineSecret_EnvMapEntry {
    return InlineSecret_EnvMapEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<InlineSecret_EnvMapEntry>): InlineSecret_EnvMapEntry {
    const message = createBaseInlineSecret_EnvMapEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseSecretManagerSecret(): SecretManagerSecret {
  return { versionName: "", env: "" };
}

export const SecretManagerSecret: MessageFns<SecretManagerSecret> = {
  encode(message: SecretManagerSecret, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.versionName !== "") {
      writer.uint32(10).string(message.versionName);
    }
    if (message.env !== "") {
      writer.uint32(18).string(message.env);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretManagerSecret {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretManagerSecret();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.versionName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.env = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretManagerSecret {
    return {
      versionName: isSet(object.versionName) ? globalThis.String(object.versionName) : "",
      env: isSet(object.env) ? globalThis.String(object.env) : "",
    };
  },

  toJSON(message: SecretManagerSecret): unknown {
    const obj: any = {};
    if (message.versionName !== "") {
      obj.versionName = message.versionName;
    }
    if (message.env !== "") {
      obj.env = message.env;
    }
    return obj;
  },

  create(base?: DeepPartial<SecretManagerSecret>): SecretManagerSecret {
    return SecretManagerSecret.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SecretManagerSecret>): SecretManagerSecret {
    const message = createBaseSecretManagerSecret();
    message.versionName = object.versionName ?? "";
    message.env = object.env ?? "";
    return message;
  },
};

function createBaseSecret(): Secret {
  return { kmsKeyName: "", secretEnv: {} };
}

export const Secret: MessageFns<Secret> = {
  encode(message: Secret, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKeyName !== "") {
      writer.uint32(10).string(message.kmsKeyName);
    }
    Object.entries(message.secretEnv).forEach(([key, value]) => {
      Secret_SecretEnvEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Secret {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecret();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = Secret_SecretEnvEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.secretEnv[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Secret {
    return {
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
      secretEnv: isObject(object.secretEnv)
        ? Object.entries(object.secretEnv).reduce<{ [key: string]: Buffer }>((acc, [key, value]) => {
          acc[key] = Buffer.from(bytesFromBase64(value as string));
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Secret): unknown {
    const obj: any = {};
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    if (message.secretEnv) {
      const entries = Object.entries(message.secretEnv);
      if (entries.length > 0) {
        obj.secretEnv = {};
        entries.forEach(([k, v]) => {
          obj.secretEnv[k] = base64FromBytes(v);
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<Secret>): Secret {
    return Secret.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Secret>): Secret {
    const message = createBaseSecret();
    message.kmsKeyName = object.kmsKeyName ?? "";
    message.secretEnv = Object.entries(object.secretEnv ?? {}).reduce<{ [key: string]: Buffer }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = value;
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseSecret_SecretEnvEntry(): Secret_SecretEnvEntry {
  return { key: "", value: Buffer.alloc(0) };
}

export const Secret_SecretEnvEntry: MessageFns<Secret_SecretEnvEntry> = {
  encode(message: Secret_SecretEnvEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value.length !== 0) {
      writer.uint32(18).bytes(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Secret_SecretEnvEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecret_SecretEnvEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Secret_SecretEnvEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Buffer.from(bytesFromBase64(object.value)) : Buffer.alloc(0),
    };
  },

  toJSON(message: Secret_SecretEnvEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value.length !== 0) {
      obj.value = base64FromBytes(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<Secret_SecretEnvEntry>): Secret_SecretEnvEntry {
    return Secret_SecretEnvEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Secret_SecretEnvEntry>): Secret_SecretEnvEntry {
    const message = createBaseSecret_SecretEnvEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCreateBuildRequest(): CreateBuildRequest {
  return { parent: "", projectId: "", build: undefined };
}

export const CreateBuildRequest: MessageFns<CreateBuildRequest> = {
  encode(message: CreateBuildRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.build !== undefined) {
      Build.encode(message.build, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBuildRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBuildRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.build = Build.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBuildRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      build: isSet(object.build) ? Build.fromJSON(object.build) : undefined,
    };
  },

  toJSON(message: CreateBuildRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.build !== undefined) {
      obj.build = Build.toJSON(message.build);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBuildRequest>): CreateBuildRequest {
    return CreateBuildRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBuildRequest>): CreateBuildRequest {
    const message = createBaseCreateBuildRequest();
    message.parent = object.parent ?? "";
    message.projectId = object.projectId ?? "";
    message.build = (object.build !== undefined && object.build !== null) ? Build.fromPartial(object.build) : undefined;
    return message;
  },
};

function createBaseGetBuildRequest(): GetBuildRequest {
  return { name: "", projectId: "", id: "" };
}

export const GetBuildRequest: MessageFns<GetBuildRequest> = {
  encode(message: GetBuildRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(34).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBuildRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBuildRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBuildRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
    };
  },

  toJSON(message: GetBuildRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBuildRequest>): GetBuildRequest {
    return GetBuildRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBuildRequest>): GetBuildRequest {
    const message = createBaseGetBuildRequest();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.id = object.id ?? "";
    return message;
  },
};

function createBaseListBuildsRequest(): ListBuildsRequest {
  return { parent: "", projectId: "", pageSize: 0, pageToken: "", filter: "" };
}

export const ListBuildsRequest: MessageFns<ListBuildsRequest> = {
  encode(message: ListBuildsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(74).string(message.parent);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.filter !== "") {
      writer.uint32(66).string(message.filter);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBuildsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBuildsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 9:
          if (tag !== 74) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.filter = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBuildsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
    };
  },

  toJSON(message: ListBuildsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBuildsRequest>): ListBuildsRequest {
    return ListBuildsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBuildsRequest>): ListBuildsRequest {
    const message = createBaseListBuildsRequest();
    message.parent = object.parent ?? "";
    message.projectId = object.projectId ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.filter = object.filter ?? "";
    return message;
  },
};

function createBaseListBuildsResponse(): ListBuildsResponse {
  return { builds: [], nextPageToken: "" };
}

export const ListBuildsResponse: MessageFns<ListBuildsResponse> = {
  encode(message: ListBuildsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.builds) {
      Build.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBuildsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBuildsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.builds.push(Build.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBuildsResponse {
    return {
      builds: globalThis.Array.isArray(object?.builds) ? object.builds.map((e: any) => Build.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListBuildsResponse): unknown {
    const obj: any = {};
    if (message.builds?.length) {
      obj.builds = message.builds.map((e) => Build.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBuildsResponse>): ListBuildsResponse {
    return ListBuildsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBuildsResponse>): ListBuildsResponse {
    const message = createBaseListBuildsResponse();
    message.builds = object.builds?.map((e) => Build.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCancelBuildRequest(): CancelBuildRequest {
  return { name: "", projectId: "", id: "" };
}

export const CancelBuildRequest: MessageFns<CancelBuildRequest> = {
  encode(message: CancelBuildRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(34).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.id !== "") {
      writer.uint32(18).string(message.id);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelBuildRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelBuildRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.id = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelBuildRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
    };
  },

  toJSON(message: CancelBuildRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelBuildRequest>): CancelBuildRequest {
    return CancelBuildRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelBuildRequest>): CancelBuildRequest {
    const message = createBaseCancelBuildRequest();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.id = object.id ?? "";
    return message;
  },
};

function createBaseApproveBuildRequest(): ApproveBuildRequest {
  return { name: "", approvalResult: undefined };
}

export const ApproveBuildRequest: MessageFns<ApproveBuildRequest> = {
  encode(message: ApproveBuildRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.approvalResult !== undefined) {
      ApprovalResult.encode(message.approvalResult, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ApproveBuildRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseApproveBuildRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.approvalResult = ApprovalResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ApproveBuildRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      approvalResult: isSet(object.approvalResult) ? ApprovalResult.fromJSON(object.approvalResult) : undefined,
    };
  },

  toJSON(message: ApproveBuildRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.approvalResult !== undefined) {
      obj.approvalResult = ApprovalResult.toJSON(message.approvalResult);
    }
    return obj;
  },

  create(base?: DeepPartial<ApproveBuildRequest>): ApproveBuildRequest {
    return ApproveBuildRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ApproveBuildRequest>): ApproveBuildRequest {
    const message = createBaseApproveBuildRequest();
    message.name = object.name ?? "";
    message.approvalResult = (object.approvalResult !== undefined && object.approvalResult !== null)
      ? ApprovalResult.fromPartial(object.approvalResult)
      : undefined;
    return message;
  },
};

function createBaseBuildApproval(): BuildApproval {
  return { state: 0, config: undefined, result: undefined };
}

export const BuildApproval: MessageFns<BuildApproval> = {
  encode(message: BuildApproval, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.config !== undefined) {
      ApprovalConfig.encode(message.config, writer.uint32(18).fork()).join();
    }
    if (message.result !== undefined) {
      ApprovalResult.encode(message.result, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildApproval {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildApproval();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.config = ApprovalConfig.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.result = ApprovalResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildApproval {
    return {
      state: isSet(object.state) ? buildApproval_StateFromJSON(object.state) : 0,
      config: isSet(object.config) ? ApprovalConfig.fromJSON(object.config) : undefined,
      result: isSet(object.result) ? ApprovalResult.fromJSON(object.result) : undefined,
    };
  },

  toJSON(message: BuildApproval): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = buildApproval_StateToJSON(message.state);
    }
    if (message.config !== undefined) {
      obj.config = ApprovalConfig.toJSON(message.config);
    }
    if (message.result !== undefined) {
      obj.result = ApprovalResult.toJSON(message.result);
    }
    return obj;
  },

  create(base?: DeepPartial<BuildApproval>): BuildApproval {
    return BuildApproval.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildApproval>): BuildApproval {
    const message = createBaseBuildApproval();
    message.state = object.state ?? 0;
    message.config = (object.config !== undefined && object.config !== null)
      ? ApprovalConfig.fromPartial(object.config)
      : undefined;
    message.result = (object.result !== undefined && object.result !== null)
      ? ApprovalResult.fromPartial(object.result)
      : undefined;
    return message;
  },
};

function createBaseApprovalConfig(): ApprovalConfig {
  return { approvalRequired: false };
}

export const ApprovalConfig: MessageFns<ApprovalConfig> = {
  encode(message: ApprovalConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.approvalRequired !== false) {
      writer.uint32(8).bool(message.approvalRequired);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ApprovalConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseApprovalConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.approvalRequired = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ApprovalConfig {
    return { approvalRequired: isSet(object.approvalRequired) ? globalThis.Boolean(object.approvalRequired) : false };
  },

  toJSON(message: ApprovalConfig): unknown {
    const obj: any = {};
    if (message.approvalRequired !== false) {
      obj.approvalRequired = message.approvalRequired;
    }
    return obj;
  },

  create(base?: DeepPartial<ApprovalConfig>): ApprovalConfig {
    return ApprovalConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ApprovalConfig>): ApprovalConfig {
    const message = createBaseApprovalConfig();
    message.approvalRequired = object.approvalRequired ?? false;
    return message;
  },
};

function createBaseApprovalResult(): ApprovalResult {
  return { approverAccount: "", approvalTime: undefined, decision: 0, comment: "", url: "" };
}

export const ApprovalResult: MessageFns<ApprovalResult> = {
  encode(message: ApprovalResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.approverAccount !== "") {
      writer.uint32(18).string(message.approverAccount);
    }
    if (message.approvalTime !== undefined) {
      Timestamp.encode(toTimestamp(message.approvalTime), writer.uint32(26).fork()).join();
    }
    if (message.decision !== 0) {
      writer.uint32(32).int32(message.decision);
    }
    if (message.comment !== "") {
      writer.uint32(42).string(message.comment);
    }
    if (message.url !== "") {
      writer.uint32(50).string(message.url);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ApprovalResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseApprovalResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.approverAccount = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.approvalTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.decision = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.comment = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.url = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ApprovalResult {
    return {
      approverAccount: isSet(object.approverAccount) ? globalThis.String(object.approverAccount) : "",
      approvalTime: isSet(object.approvalTime) ? fromJsonTimestamp(object.approvalTime) : undefined,
      decision: isSet(object.decision) ? approvalResult_DecisionFromJSON(object.decision) : 0,
      comment: isSet(object.comment) ? globalThis.String(object.comment) : "",
      url: isSet(object.url) ? globalThis.String(object.url) : "",
    };
  },

  toJSON(message: ApprovalResult): unknown {
    const obj: any = {};
    if (message.approverAccount !== "") {
      obj.approverAccount = message.approverAccount;
    }
    if (message.approvalTime !== undefined) {
      obj.approvalTime = message.approvalTime.toISOString();
    }
    if (message.decision !== 0) {
      obj.decision = approvalResult_DecisionToJSON(message.decision);
    }
    if (message.comment !== "") {
      obj.comment = message.comment;
    }
    if (message.url !== "") {
      obj.url = message.url;
    }
    return obj;
  },

  create(base?: DeepPartial<ApprovalResult>): ApprovalResult {
    return ApprovalResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ApprovalResult>): ApprovalResult {
    const message = createBaseApprovalResult();
    message.approverAccount = object.approverAccount ?? "";
    message.approvalTime = object.approvalTime ?? undefined;
    message.decision = object.decision ?? 0;
    message.comment = object.comment ?? "";
    message.url = object.url ?? "";
    return message;
  },
};

function createBaseGitRepoSource(): GitRepoSource {
  return { uri: "", repository: undefined, ref: "", repoType: 0, githubEnterpriseConfig: undefined };
}

export const GitRepoSource: MessageFns<GitRepoSource> = {
  encode(message: GitRepoSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.uri !== "") {
      writer.uint32(10).string(message.uri);
    }
    if (message.repository !== undefined) {
      writer.uint32(50).string(message.repository);
    }
    if (message.ref !== "") {
      writer.uint32(18).string(message.ref);
    }
    if (message.repoType !== 0) {
      writer.uint32(24).int32(message.repoType);
    }
    if (message.githubEnterpriseConfig !== undefined) {
      writer.uint32(34).string(message.githubEnterpriseConfig);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GitRepoSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGitRepoSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.ref = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.repoType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.githubEnterpriseConfig = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GitRepoSource {
    return {
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      repository: isSet(object.repository) ? globalThis.String(object.repository) : undefined,
      ref: isSet(object.ref) ? globalThis.String(object.ref) : "",
      repoType: isSet(object.repoType) ? gitFileSource_RepoTypeFromJSON(object.repoType) : 0,
      githubEnterpriseConfig: isSet(object.githubEnterpriseConfig)
        ? globalThis.String(object.githubEnterpriseConfig)
        : undefined,
    };
  },

  toJSON(message: GitRepoSource): unknown {
    const obj: any = {};
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.repository !== undefined) {
      obj.repository = message.repository;
    }
    if (message.ref !== "") {
      obj.ref = message.ref;
    }
    if (message.repoType !== 0) {
      obj.repoType = gitFileSource_RepoTypeToJSON(message.repoType);
    }
    if (message.githubEnterpriseConfig !== undefined) {
      obj.githubEnterpriseConfig = message.githubEnterpriseConfig;
    }
    return obj;
  },

  create(base?: DeepPartial<GitRepoSource>): GitRepoSource {
    return GitRepoSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GitRepoSource>): GitRepoSource {
    const message = createBaseGitRepoSource();
    message.uri = object.uri ?? "";
    message.repository = object.repository ?? undefined;
    message.ref = object.ref ?? "";
    message.repoType = object.repoType ?? 0;
    message.githubEnterpriseConfig = object.githubEnterpriseConfig ?? undefined;
    return message;
  },
};

function createBaseGitFileSource(): GitFileSource {
  return { path: "", uri: "", repository: undefined, repoType: 0, revision: "", githubEnterpriseConfig: undefined };
}

export const GitFileSource: MessageFns<GitFileSource> = {
  encode(message: GitFileSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    if (message.uri !== "") {
      writer.uint32(18).string(message.uri);
    }
    if (message.repository !== undefined) {
      writer.uint32(58).string(message.repository);
    }
    if (message.repoType !== 0) {
      writer.uint32(24).int32(message.repoType);
    }
    if (message.revision !== "") {
      writer.uint32(34).string(message.revision);
    }
    if (message.githubEnterpriseConfig !== undefined) {
      writer.uint32(42).string(message.githubEnterpriseConfig);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GitFileSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGitFileSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.uri = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.repoType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.revision = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.githubEnterpriseConfig = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GitFileSource {
    return {
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      repository: isSet(object.repository) ? globalThis.String(object.repository) : undefined,
      repoType: isSet(object.repoType) ? gitFileSource_RepoTypeFromJSON(object.repoType) : 0,
      revision: isSet(object.revision) ? globalThis.String(object.revision) : "",
      githubEnterpriseConfig: isSet(object.githubEnterpriseConfig)
        ? globalThis.String(object.githubEnterpriseConfig)
        : undefined,
    };
  },

  toJSON(message: GitFileSource): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.repository !== undefined) {
      obj.repository = message.repository;
    }
    if (message.repoType !== 0) {
      obj.repoType = gitFileSource_RepoTypeToJSON(message.repoType);
    }
    if (message.revision !== "") {
      obj.revision = message.revision;
    }
    if (message.githubEnterpriseConfig !== undefined) {
      obj.githubEnterpriseConfig = message.githubEnterpriseConfig;
    }
    return obj;
  },

  create(base?: DeepPartial<GitFileSource>): GitFileSource {
    return GitFileSource.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GitFileSource>): GitFileSource {
    const message = createBaseGitFileSource();
    message.path = object.path ?? "";
    message.uri = object.uri ?? "";
    message.repository = object.repository ?? undefined;
    message.repoType = object.repoType ?? 0;
    message.revision = object.revision ?? "";
    message.githubEnterpriseConfig = object.githubEnterpriseConfig ?? undefined;
    return message;
  },
};

function createBaseBuildTrigger(): BuildTrigger {
  return {
    resourceName: "",
    id: "",
    description: "",
    name: "",
    tags: [],
    triggerTemplate: undefined,
    github: undefined,
    pubsubConfig: undefined,
    webhookConfig: undefined,
    autodetect: undefined,
    build: undefined,
    filename: undefined,
    gitFileSource: undefined,
    createTime: undefined,
    disabled: false,
    substitutions: {},
    ignoredFiles: [],
    includedFiles: [],
    filter: "",
    sourceToBuild: undefined,
    serviceAccount: "",
    repositoryEventConfig: undefined,
  };
}

export const BuildTrigger: MessageFns<BuildTrigger> = {
  encode(message: BuildTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resourceName !== "") {
      writer.uint32(274).string(message.resourceName);
    }
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.description !== "") {
      writer.uint32(82).string(message.description);
    }
    if (message.name !== "") {
      writer.uint32(170).string(message.name);
    }
    for (const v of message.tags) {
      writer.uint32(154).string(v!);
    }
    if (message.triggerTemplate !== undefined) {
      RepoSource.encode(message.triggerTemplate, writer.uint32(58).fork()).join();
    }
    if (message.github !== undefined) {
      GitHubEventsConfig.encode(message.github, writer.uint32(106).fork()).join();
    }
    if (message.pubsubConfig !== undefined) {
      PubsubConfig.encode(message.pubsubConfig, writer.uint32(234).fork()).join();
    }
    if (message.webhookConfig !== undefined) {
      WebhookConfig.encode(message.webhookConfig, writer.uint32(250).fork()).join();
    }
    if (message.autodetect !== undefined) {
      writer.uint32(144).bool(message.autodetect);
    }
    if (message.build !== undefined) {
      Build.encode(message.build, writer.uint32(34).fork()).join();
    }
    if (message.filename !== undefined) {
      writer.uint32(66).string(message.filename);
    }
    if (message.gitFileSource !== undefined) {
      GitFileSource.encode(message.gitFileSource, writer.uint32(194).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(42).fork()).join();
    }
    if (message.disabled !== false) {
      writer.uint32(72).bool(message.disabled);
    }
    Object.entries(message.substitutions).forEach(([key, value]) => {
      BuildTrigger_SubstitutionsEntry.encode({ key: key as any, value }, writer.uint32(90).fork()).join();
    });
    for (const v of message.ignoredFiles) {
      writer.uint32(122).string(v!);
    }
    for (const v of message.includedFiles) {
      writer.uint32(130).string(v!);
    }
    if (message.filter !== "") {
      writer.uint32(242).string(message.filter);
    }
    if (message.sourceToBuild !== undefined) {
      GitRepoSource.encode(message.sourceToBuild, writer.uint32(210).fork()).join();
    }
    if (message.serviceAccount !== "") {
      writer.uint32(266).string(message.serviceAccount);
    }
    if (message.repositoryEventConfig !== undefined) {
      RepositoryEventConfig.encode(message.repositoryEventConfig, writer.uint32(314).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 34:
          if (tag !== 274) {
            break;
          }

          message.resourceName = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.description = reader.string();
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.name = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.tags.push(reader.string());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.triggerTemplate = RepoSource.decode(reader, reader.uint32());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.github = GitHubEventsConfig.decode(reader, reader.uint32());
          continue;
        case 29:
          if (tag !== 234) {
            break;
          }

          message.pubsubConfig = PubsubConfig.decode(reader, reader.uint32());
          continue;
        case 31:
          if (tag !== 250) {
            break;
          }

          message.webhookConfig = WebhookConfig.decode(reader, reader.uint32());
          continue;
        case 18:
          if (tag !== 144) {
            break;
          }

          message.autodetect = reader.bool();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.build = Build.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.filename = reader.string();
          continue;
        case 24:
          if (tag !== 194) {
            break;
          }

          message.gitFileSource = GitFileSource.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.disabled = reader.bool();
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          const entry11 = BuildTrigger_SubstitutionsEntry.decode(reader, reader.uint32());
          if (entry11.value !== undefined) {
            message.substitutions[entry11.key] = entry11.value;
          }
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.ignoredFiles.push(reader.string());
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.includedFiles.push(reader.string());
          continue;
        case 30:
          if (tag !== 242) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 26:
          if (tag !== 210) {
            break;
          }

          message.sourceToBuild = GitRepoSource.decode(reader, reader.uint32());
          continue;
        case 33:
          if (tag !== 266) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        case 39:
          if (tag !== 314) {
            break;
          }

          message.repositoryEventConfig = RepositoryEventConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildTrigger {
    return {
      resourceName: isSet(object.resourceName) ? globalThis.String(object.resourceName) : "",
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => globalThis.String(e)) : [],
      triggerTemplate: isSet(object.triggerTemplate) ? RepoSource.fromJSON(object.triggerTemplate) : undefined,
      github: isSet(object.github) ? GitHubEventsConfig.fromJSON(object.github) : undefined,
      pubsubConfig: isSet(object.pubsubConfig) ? PubsubConfig.fromJSON(object.pubsubConfig) : undefined,
      webhookConfig: isSet(object.webhookConfig) ? WebhookConfig.fromJSON(object.webhookConfig) : undefined,
      autodetect: isSet(object.autodetect) ? globalThis.Boolean(object.autodetect) : undefined,
      build: isSet(object.build) ? Build.fromJSON(object.build) : undefined,
      filename: isSet(object.filename) ? globalThis.String(object.filename) : undefined,
      gitFileSource: isSet(object.gitFileSource) ? GitFileSource.fromJSON(object.gitFileSource) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      disabled: isSet(object.disabled) ? globalThis.Boolean(object.disabled) : false,
      substitutions: isObject(object.substitutions)
        ? Object.entries(object.substitutions).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      ignoredFiles: globalThis.Array.isArray(object?.ignoredFiles)
        ? object.ignoredFiles.map((e: any) => globalThis.String(e))
        : [],
      includedFiles: globalThis.Array.isArray(object?.includedFiles)
        ? object.includedFiles.map((e: any) => globalThis.String(e))
        : [],
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      sourceToBuild: isSet(object.sourceToBuild) ? GitRepoSource.fromJSON(object.sourceToBuild) : undefined,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      repositoryEventConfig: isSet(object.repositoryEventConfig)
        ? RepositoryEventConfig.fromJSON(object.repositoryEventConfig)
        : undefined,
    };
  },

  toJSON(message: BuildTrigger): unknown {
    const obj: any = {};
    if (message.resourceName !== "") {
      obj.resourceName = message.resourceName;
    }
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.tags?.length) {
      obj.tags = message.tags;
    }
    if (message.triggerTemplate !== undefined) {
      obj.triggerTemplate = RepoSource.toJSON(message.triggerTemplate);
    }
    if (message.github !== undefined) {
      obj.github = GitHubEventsConfig.toJSON(message.github);
    }
    if (message.pubsubConfig !== undefined) {
      obj.pubsubConfig = PubsubConfig.toJSON(message.pubsubConfig);
    }
    if (message.webhookConfig !== undefined) {
      obj.webhookConfig = WebhookConfig.toJSON(message.webhookConfig);
    }
    if (message.autodetect !== undefined) {
      obj.autodetect = message.autodetect;
    }
    if (message.build !== undefined) {
      obj.build = Build.toJSON(message.build);
    }
    if (message.filename !== undefined) {
      obj.filename = message.filename;
    }
    if (message.gitFileSource !== undefined) {
      obj.gitFileSource = GitFileSource.toJSON(message.gitFileSource);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.disabled !== false) {
      obj.disabled = message.disabled;
    }
    if (message.substitutions) {
      const entries = Object.entries(message.substitutions);
      if (entries.length > 0) {
        obj.substitutions = {};
        entries.forEach(([k, v]) => {
          obj.substitutions[k] = v;
        });
      }
    }
    if (message.ignoredFiles?.length) {
      obj.ignoredFiles = message.ignoredFiles;
    }
    if (message.includedFiles?.length) {
      obj.includedFiles = message.includedFiles;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.sourceToBuild !== undefined) {
      obj.sourceToBuild = GitRepoSource.toJSON(message.sourceToBuild);
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.repositoryEventConfig !== undefined) {
      obj.repositoryEventConfig = RepositoryEventConfig.toJSON(message.repositoryEventConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<BuildTrigger>): BuildTrigger {
    return BuildTrigger.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildTrigger>): BuildTrigger {
    const message = createBaseBuildTrigger();
    message.resourceName = object.resourceName ?? "";
    message.id = object.id ?? "";
    message.description = object.description ?? "";
    message.name = object.name ?? "";
    message.tags = object.tags?.map((e) => e) || [];
    message.triggerTemplate = (object.triggerTemplate !== undefined && object.triggerTemplate !== null)
      ? RepoSource.fromPartial(object.triggerTemplate)
      : undefined;
    message.github = (object.github !== undefined && object.github !== null)
      ? GitHubEventsConfig.fromPartial(object.github)
      : undefined;
    message.pubsubConfig = (object.pubsubConfig !== undefined && object.pubsubConfig !== null)
      ? PubsubConfig.fromPartial(object.pubsubConfig)
      : undefined;
    message.webhookConfig = (object.webhookConfig !== undefined && object.webhookConfig !== null)
      ? WebhookConfig.fromPartial(object.webhookConfig)
      : undefined;
    message.autodetect = object.autodetect ?? undefined;
    message.build = (object.build !== undefined && object.build !== null) ? Build.fromPartial(object.build) : undefined;
    message.filename = object.filename ?? undefined;
    message.gitFileSource = (object.gitFileSource !== undefined && object.gitFileSource !== null)
      ? GitFileSource.fromPartial(object.gitFileSource)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.disabled = object.disabled ?? false;
    message.substitutions = Object.entries(object.substitutions ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.ignoredFiles = object.ignoredFiles?.map((e) => e) || [];
    message.includedFiles = object.includedFiles?.map((e) => e) || [];
    message.filter = object.filter ?? "";
    message.sourceToBuild = (object.sourceToBuild !== undefined && object.sourceToBuild !== null)
      ? GitRepoSource.fromPartial(object.sourceToBuild)
      : undefined;
    message.serviceAccount = object.serviceAccount ?? "";
    message.repositoryEventConfig =
      (object.repositoryEventConfig !== undefined && object.repositoryEventConfig !== null)
        ? RepositoryEventConfig.fromPartial(object.repositoryEventConfig)
        : undefined;
    return message;
  },
};

function createBaseBuildTrigger_SubstitutionsEntry(): BuildTrigger_SubstitutionsEntry {
  return { key: "", value: "" };
}

export const BuildTrigger_SubstitutionsEntry: MessageFns<BuildTrigger_SubstitutionsEntry> = {
  encode(message: BuildTrigger_SubstitutionsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildTrigger_SubstitutionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildTrigger_SubstitutionsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildTrigger_SubstitutionsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: BuildTrigger_SubstitutionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildTrigger_SubstitutionsEntry>): BuildTrigger_SubstitutionsEntry {
    return BuildTrigger_SubstitutionsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildTrigger_SubstitutionsEntry>): BuildTrigger_SubstitutionsEntry {
    const message = createBaseBuildTrigger_SubstitutionsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRepositoryEventConfig(): RepositoryEventConfig {
  return { repository: "", repositoryType: 0, pullRequest: undefined, push: undefined };
}

export const RepositoryEventConfig: MessageFns<RepositoryEventConfig> = {
  encode(message: RepositoryEventConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.repository !== "") {
      writer.uint32(10).string(message.repository);
    }
    if (message.repositoryType !== 0) {
      writer.uint32(16).int32(message.repositoryType);
    }
    if (message.pullRequest !== undefined) {
      PullRequestFilter.encode(message.pullRequest, writer.uint32(26).fork()).join();
    }
    if (message.push !== undefined) {
      PushFilter.encode(message.push, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepositoryEventConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepositoryEventConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.repository = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.repositoryType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pullRequest = PullRequestFilter.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.push = PushFilter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepositoryEventConfig {
    return {
      repository: isSet(object.repository) ? globalThis.String(object.repository) : "",
      repositoryType: isSet(object.repositoryType)
        ? repositoryEventConfig_RepositoryTypeFromJSON(object.repositoryType)
        : 0,
      pullRequest: isSet(object.pullRequest) ? PullRequestFilter.fromJSON(object.pullRequest) : undefined,
      push: isSet(object.push) ? PushFilter.fromJSON(object.push) : undefined,
    };
  },

  toJSON(message: RepositoryEventConfig): unknown {
    const obj: any = {};
    if (message.repository !== "") {
      obj.repository = message.repository;
    }
    if (message.repositoryType !== 0) {
      obj.repositoryType = repositoryEventConfig_RepositoryTypeToJSON(message.repositoryType);
    }
    if (message.pullRequest !== undefined) {
      obj.pullRequest = PullRequestFilter.toJSON(message.pullRequest);
    }
    if (message.push !== undefined) {
      obj.push = PushFilter.toJSON(message.push);
    }
    return obj;
  },

  create(base?: DeepPartial<RepositoryEventConfig>): RepositoryEventConfig {
    return RepositoryEventConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RepositoryEventConfig>): RepositoryEventConfig {
    const message = createBaseRepositoryEventConfig();
    message.repository = object.repository ?? "";
    message.repositoryType = object.repositoryType ?? 0;
    message.pullRequest = (object.pullRequest !== undefined && object.pullRequest !== null)
      ? PullRequestFilter.fromPartial(object.pullRequest)
      : undefined;
    message.push = (object.push !== undefined && object.push !== null)
      ? PushFilter.fromPartial(object.push)
      : undefined;
    return message;
  },
};

function createBaseGitHubEventsConfig(): GitHubEventsConfig {
  return { installationId: Long.ZERO, owner: "", name: "", pullRequest: undefined, push: undefined };
}

export const GitHubEventsConfig: MessageFns<GitHubEventsConfig> = {
  encode(message: GitHubEventsConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.installationId.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.installationId.toString());
    }
    if (message.owner !== "") {
      writer.uint32(50).string(message.owner);
    }
    if (message.name !== "") {
      writer.uint32(58).string(message.name);
    }
    if (message.pullRequest !== undefined) {
      PullRequestFilter.encode(message.pullRequest, writer.uint32(34).fork()).join();
    }
    if (message.push !== undefined) {
      PushFilter.encode(message.push, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GitHubEventsConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGitHubEventsConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.installationId = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.owner = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.name = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pullRequest = PullRequestFilter.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.push = PushFilter.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GitHubEventsConfig {
    return {
      installationId: isSet(object.installationId) ? Long.fromValue(object.installationId) : Long.ZERO,
      owner: isSet(object.owner) ? globalThis.String(object.owner) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      pullRequest: isSet(object.pullRequest) ? PullRequestFilter.fromJSON(object.pullRequest) : undefined,
      push: isSet(object.push) ? PushFilter.fromJSON(object.push) : undefined,
    };
  },

  toJSON(message: GitHubEventsConfig): unknown {
    const obj: any = {};
    if (!message.installationId.equals(Long.ZERO)) {
      obj.installationId = (message.installationId || Long.ZERO).toString();
    }
    if (message.owner !== "") {
      obj.owner = message.owner;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.pullRequest !== undefined) {
      obj.pullRequest = PullRequestFilter.toJSON(message.pullRequest);
    }
    if (message.push !== undefined) {
      obj.push = PushFilter.toJSON(message.push);
    }
    return obj;
  },

  create(base?: DeepPartial<GitHubEventsConfig>): GitHubEventsConfig {
    return GitHubEventsConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GitHubEventsConfig>): GitHubEventsConfig {
    const message = createBaseGitHubEventsConfig();
    message.installationId = (object.installationId !== undefined && object.installationId !== null)
      ? Long.fromValue(object.installationId)
      : Long.ZERO;
    message.owner = object.owner ?? "";
    message.name = object.name ?? "";
    message.pullRequest = (object.pullRequest !== undefined && object.pullRequest !== null)
      ? PullRequestFilter.fromPartial(object.pullRequest)
      : undefined;
    message.push = (object.push !== undefined && object.push !== null)
      ? PushFilter.fromPartial(object.push)
      : undefined;
    return message;
  },
};

function createBasePubsubConfig(): PubsubConfig {
  return { subscription: "", topic: "", serviceAccountEmail: "", state: 0 };
}

export const PubsubConfig: MessageFns<PubsubConfig> = {
  encode(message: PubsubConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subscription !== "") {
      writer.uint32(10).string(message.subscription);
    }
    if (message.topic !== "") {
      writer.uint32(18).string(message.topic);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(26).string(message.serviceAccountEmail);
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PubsubConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePubsubConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PubsubConfig {
    return {
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      state: isSet(object.state) ? pubsubConfig_StateFromJSON(object.state) : 0,
    };
  },

  toJSON(message: PubsubConfig): unknown {
    const obj: any = {};
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.state !== 0) {
      obj.state = pubsubConfig_StateToJSON(message.state);
    }
    return obj;
  },

  create(base?: DeepPartial<PubsubConfig>): PubsubConfig {
    return PubsubConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PubsubConfig>): PubsubConfig {
    const message = createBasePubsubConfig();
    message.subscription = object.subscription ?? "";
    message.topic = object.topic ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.state = object.state ?? 0;
    return message;
  },
};

function createBaseWebhookConfig(): WebhookConfig {
  return { secret: undefined, state: 0 };
}

export const WebhookConfig: MessageFns<WebhookConfig> = {
  encode(message: WebhookConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.secret !== undefined) {
      writer.uint32(26).string(message.secret);
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WebhookConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWebhookConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WebhookConfig {
    return {
      secret: isSet(object.secret) ? globalThis.String(object.secret) : undefined,
      state: isSet(object.state) ? webhookConfig_StateFromJSON(object.state) : 0,
    };
  },

  toJSON(message: WebhookConfig): unknown {
    const obj: any = {};
    if (message.secret !== undefined) {
      obj.secret = message.secret;
    }
    if (message.state !== 0) {
      obj.state = webhookConfig_StateToJSON(message.state);
    }
    return obj;
  },

  create(base?: DeepPartial<WebhookConfig>): WebhookConfig {
    return WebhookConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WebhookConfig>): WebhookConfig {
    const message = createBaseWebhookConfig();
    message.secret = object.secret ?? undefined;
    message.state = object.state ?? 0;
    return message;
  },
};

function createBasePullRequestFilter(): PullRequestFilter {
  return { branch: undefined, commentControl: 0, invertRegex: false };
}

export const PullRequestFilter: MessageFns<PullRequestFilter> = {
  encode(message: PullRequestFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.branch !== undefined) {
      writer.uint32(18).string(message.branch);
    }
    if (message.commentControl !== 0) {
      writer.uint32(40).int32(message.commentControl);
    }
    if (message.invertRegex !== false) {
      writer.uint32(48).bool(message.invertRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PullRequestFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePullRequestFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.branch = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.commentControl = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.invertRegex = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PullRequestFilter {
    return {
      branch: isSet(object.branch) ? globalThis.String(object.branch) : undefined,
      commentControl: isSet(object.commentControl)
        ? pullRequestFilter_CommentControlFromJSON(object.commentControl)
        : 0,
      invertRegex: isSet(object.invertRegex) ? globalThis.Boolean(object.invertRegex) : false,
    };
  },

  toJSON(message: PullRequestFilter): unknown {
    const obj: any = {};
    if (message.branch !== undefined) {
      obj.branch = message.branch;
    }
    if (message.commentControl !== 0) {
      obj.commentControl = pullRequestFilter_CommentControlToJSON(message.commentControl);
    }
    if (message.invertRegex !== false) {
      obj.invertRegex = message.invertRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<PullRequestFilter>): PullRequestFilter {
    return PullRequestFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PullRequestFilter>): PullRequestFilter {
    const message = createBasePullRequestFilter();
    message.branch = object.branch ?? undefined;
    message.commentControl = object.commentControl ?? 0;
    message.invertRegex = object.invertRegex ?? false;
    return message;
  },
};

function createBasePushFilter(): PushFilter {
  return { branch: undefined, tag: undefined, invertRegex: false };
}

export const PushFilter: MessageFns<PushFilter> = {
  encode(message: PushFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.branch !== undefined) {
      writer.uint32(18).string(message.branch);
    }
    if (message.tag !== undefined) {
      writer.uint32(26).string(message.tag);
    }
    if (message.invertRegex !== false) {
      writer.uint32(32).bool(message.invertRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PushFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePushFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.branch = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.tag = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.invertRegex = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PushFilter {
    return {
      branch: isSet(object.branch) ? globalThis.String(object.branch) : undefined,
      tag: isSet(object.tag) ? globalThis.String(object.tag) : undefined,
      invertRegex: isSet(object.invertRegex) ? globalThis.Boolean(object.invertRegex) : false,
    };
  },

  toJSON(message: PushFilter): unknown {
    const obj: any = {};
    if (message.branch !== undefined) {
      obj.branch = message.branch;
    }
    if (message.tag !== undefined) {
      obj.tag = message.tag;
    }
    if (message.invertRegex !== false) {
      obj.invertRegex = message.invertRegex;
    }
    return obj;
  },

  create(base?: DeepPartial<PushFilter>): PushFilter {
    return PushFilter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PushFilter>): PushFilter {
    const message = createBasePushFilter();
    message.branch = object.branch ?? undefined;
    message.tag = object.tag ?? undefined;
    message.invertRegex = object.invertRegex ?? false;
    return message;
  },
};

function createBaseCreateBuildTriggerRequest(): CreateBuildTriggerRequest {
  return { parent: "", projectId: "", trigger: undefined };
}

export const CreateBuildTriggerRequest: MessageFns<CreateBuildTriggerRequest> = {
  encode(message: CreateBuildTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(26).string(message.parent);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.trigger !== undefined) {
      BuildTrigger.encode(message.trigger, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBuildTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBuildTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.trigger = BuildTrigger.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBuildTriggerRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      trigger: isSet(object.trigger) ? BuildTrigger.fromJSON(object.trigger) : undefined,
    };
  },

  toJSON(message: CreateBuildTriggerRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.trigger !== undefined) {
      obj.trigger = BuildTrigger.toJSON(message.trigger);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBuildTriggerRequest>): CreateBuildTriggerRequest {
    return CreateBuildTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBuildTriggerRequest>): CreateBuildTriggerRequest {
    const message = createBaseCreateBuildTriggerRequest();
    message.parent = object.parent ?? "";
    message.projectId = object.projectId ?? "";
    message.trigger = (object.trigger !== undefined && object.trigger !== null)
      ? BuildTrigger.fromPartial(object.trigger)
      : undefined;
    return message;
  },
};

function createBaseGetBuildTriggerRequest(): GetBuildTriggerRequest {
  return { name: "", projectId: "", triggerId: "" };
}

export const GetBuildTriggerRequest: MessageFns<GetBuildTriggerRequest> = {
  encode(message: GetBuildTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.triggerId !== "") {
      writer.uint32(18).string(message.triggerId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBuildTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBuildTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.triggerId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBuildTriggerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      triggerId: isSet(object.triggerId) ? globalThis.String(object.triggerId) : "",
    };
  },

  toJSON(message: GetBuildTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.triggerId !== "") {
      obj.triggerId = message.triggerId;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBuildTriggerRequest>): GetBuildTriggerRequest {
    return GetBuildTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBuildTriggerRequest>): GetBuildTriggerRequest {
    const message = createBaseGetBuildTriggerRequest();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.triggerId = object.triggerId ?? "";
    return message;
  },
};

function createBaseListBuildTriggersRequest(): ListBuildTriggersRequest {
  return { parent: "", projectId: "", pageSize: 0, pageToken: "" };
}

export const ListBuildTriggersRequest: MessageFns<ListBuildTriggersRequest> = {
  encode(message: ListBuildTriggersRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(34).string(message.parent);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBuildTriggersRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBuildTriggersRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBuildTriggersRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListBuildTriggersRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBuildTriggersRequest>): ListBuildTriggersRequest {
    return ListBuildTriggersRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBuildTriggersRequest>): ListBuildTriggersRequest {
    const message = createBaseListBuildTriggersRequest();
    message.parent = object.parent ?? "";
    message.projectId = object.projectId ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListBuildTriggersResponse(): ListBuildTriggersResponse {
  return { triggers: [], nextPageToken: "" };
}

export const ListBuildTriggersResponse: MessageFns<ListBuildTriggersResponse> = {
  encode(message: ListBuildTriggersResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.triggers) {
      BuildTrigger.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBuildTriggersResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBuildTriggersResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.triggers.push(BuildTrigger.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBuildTriggersResponse {
    return {
      triggers: globalThis.Array.isArray(object?.triggers)
        ? object.triggers.map((e: any) => BuildTrigger.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListBuildTriggersResponse): unknown {
    const obj: any = {};
    if (message.triggers?.length) {
      obj.triggers = message.triggers.map((e) => BuildTrigger.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBuildTriggersResponse>): ListBuildTriggersResponse {
    return ListBuildTriggersResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBuildTriggersResponse>): ListBuildTriggersResponse {
    const message = createBaseListBuildTriggersResponse();
    message.triggers = object.triggers?.map((e) => BuildTrigger.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteBuildTriggerRequest(): DeleteBuildTriggerRequest {
  return { name: "", projectId: "", triggerId: "" };
}

export const DeleteBuildTriggerRequest: MessageFns<DeleteBuildTriggerRequest> = {
  encode(message: DeleteBuildTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.triggerId !== "") {
      writer.uint32(18).string(message.triggerId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBuildTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBuildTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.triggerId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBuildTriggerRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      triggerId: isSet(object.triggerId) ? globalThis.String(object.triggerId) : "",
    };
  },

  toJSON(message: DeleteBuildTriggerRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.triggerId !== "") {
      obj.triggerId = message.triggerId;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBuildTriggerRequest>): DeleteBuildTriggerRequest {
    return DeleteBuildTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBuildTriggerRequest>): DeleteBuildTriggerRequest {
    const message = createBaseDeleteBuildTriggerRequest();
    message.name = object.name ?? "";
    message.projectId = object.projectId ?? "";
    message.triggerId = object.triggerId ?? "";
    return message;
  },
};

function createBaseUpdateBuildTriggerRequest(): UpdateBuildTriggerRequest {
  return { projectId: "", triggerId: "", trigger: undefined, updateMask: undefined };
}

export const UpdateBuildTriggerRequest: MessageFns<UpdateBuildTriggerRequest> = {
  encode(message: UpdateBuildTriggerRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.triggerId !== "") {
      writer.uint32(18).string(message.triggerId);
    }
    if (message.trigger !== undefined) {
      BuildTrigger.encode(message.trigger, writer.uint32(26).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateBuildTriggerRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateBuildTriggerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.triggerId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.trigger = BuildTrigger.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateBuildTriggerRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      triggerId: isSet(object.triggerId) ? globalThis.String(object.triggerId) : "",
      trigger: isSet(object.trigger) ? BuildTrigger.fromJSON(object.trigger) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateBuildTriggerRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.triggerId !== "") {
      obj.triggerId = message.triggerId;
    }
    if (message.trigger !== undefined) {
      obj.trigger = BuildTrigger.toJSON(message.trigger);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateBuildTriggerRequest>): UpdateBuildTriggerRequest {
    return UpdateBuildTriggerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateBuildTriggerRequest>): UpdateBuildTriggerRequest {
    const message = createBaseUpdateBuildTriggerRequest();
    message.projectId = object.projectId ?? "";
    message.triggerId = object.triggerId ?? "";
    message.trigger = (object.trigger !== undefined && object.trigger !== null)
      ? BuildTrigger.fromPartial(object.trigger)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseBuildOptions(): BuildOptions {
  return {
    sourceProvenanceHash: [],
    requestedVerifyOption: 0,
    machineType: 0,
    diskSizeGb: Long.ZERO,
    substitutionOption: 0,
    dynamicSubstitutions: false,
    automapSubstitutions: false,
    logStreamingOption: 0,
    workerPool: "",
    pool: undefined,
    logging: 0,
    env: [],
    secretEnv: [],
    volumes: [],
    defaultLogsBucketBehavior: 0,
  };
}

export const BuildOptions: MessageFns<BuildOptions> = {
  encode(message: BuildOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.sourceProvenanceHash) {
      writer.int32(v);
    }
    writer.join();
    if (message.requestedVerifyOption !== 0) {
      writer.uint32(16).int32(message.requestedVerifyOption);
    }
    if (message.machineType !== 0) {
      writer.uint32(24).int32(message.machineType);
    }
    if (!message.diskSizeGb.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.diskSizeGb.toString());
    }
    if (message.substitutionOption !== 0) {
      writer.uint32(32).int32(message.substitutionOption);
    }
    if (message.dynamicSubstitutions !== false) {
      writer.uint32(136).bool(message.dynamicSubstitutions);
    }
    if (message.automapSubstitutions !== false) {
      writer.uint32(176).bool(message.automapSubstitutions);
    }
    if (message.logStreamingOption !== 0) {
      writer.uint32(40).int32(message.logStreamingOption);
    }
    if (message.workerPool !== "") {
      writer.uint32(58).string(message.workerPool);
    }
    if (message.pool !== undefined) {
      BuildOptions_PoolOption.encode(message.pool, writer.uint32(154).fork()).join();
    }
    if (message.logging !== 0) {
      writer.uint32(88).int32(message.logging);
    }
    for (const v of message.env) {
      writer.uint32(98).string(v!);
    }
    for (const v of message.secretEnv) {
      writer.uint32(106).string(v!);
    }
    for (const v of message.volumes) {
      Volume.encode(v!, writer.uint32(114).fork()).join();
    }
    if (message.defaultLogsBucketBehavior !== 0) {
      writer.uint32(168).int32(message.defaultLogsBucketBehavior);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.sourceProvenanceHash.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.sourceProvenanceHash.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.requestedVerifyOption = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.machineType = reader.int32() as any;
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.diskSizeGb = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.substitutionOption = reader.int32() as any;
          continue;
        case 17:
          if (tag !== 136) {
            break;
          }

          message.dynamicSubstitutions = reader.bool();
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.automapSubstitutions = reader.bool();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.logStreamingOption = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.pool = BuildOptions_PoolOption.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.logging = reader.int32() as any;
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.env.push(reader.string());
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.secretEnv.push(reader.string());
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.volumes.push(Volume.decode(reader, reader.uint32()));
          continue;
        case 21:
          if (tag !== 168) {
            break;
          }

          message.defaultLogsBucketBehavior = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildOptions {
    return {
      sourceProvenanceHash: globalThis.Array.isArray(object?.sourceProvenanceHash)
        ? object.sourceProvenanceHash.map((e: any) => hash_HashTypeFromJSON(e))
        : [],
      requestedVerifyOption: isSet(object.requestedVerifyOption)
        ? buildOptions_VerifyOptionFromJSON(object.requestedVerifyOption)
        : 0,
      machineType: isSet(object.machineType) ? buildOptions_MachineTypeFromJSON(object.machineType) : 0,
      diskSizeGb: isSet(object.diskSizeGb) ? Long.fromValue(object.diskSizeGb) : Long.ZERO,
      substitutionOption: isSet(object.substitutionOption)
        ? buildOptions_SubstitutionOptionFromJSON(object.substitutionOption)
        : 0,
      dynamicSubstitutions: isSet(object.dynamicSubstitutions)
        ? globalThis.Boolean(object.dynamicSubstitutions)
        : false,
      automapSubstitutions: isSet(object.automapSubstitutions)
        ? globalThis.Boolean(object.automapSubstitutions)
        : false,
      logStreamingOption: isSet(object.logStreamingOption)
        ? buildOptions_LogStreamingOptionFromJSON(object.logStreamingOption)
        : 0,
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      pool: isSet(object.pool) ? BuildOptions_PoolOption.fromJSON(object.pool) : undefined,
      logging: isSet(object.logging) ? buildOptions_LoggingModeFromJSON(object.logging) : 0,
      env: globalThis.Array.isArray(object?.env) ? object.env.map((e: any) => globalThis.String(e)) : [],
      secretEnv: globalThis.Array.isArray(object?.secretEnv)
        ? object.secretEnv.map((e: any) => globalThis.String(e))
        : [],
      volumes: globalThis.Array.isArray(object?.volumes) ? object.volumes.map((e: any) => Volume.fromJSON(e)) : [],
      defaultLogsBucketBehavior: isSet(object.defaultLogsBucketBehavior)
        ? buildOptions_DefaultLogsBucketBehaviorFromJSON(object.defaultLogsBucketBehavior)
        : 0,
    };
  },

  toJSON(message: BuildOptions): unknown {
    const obj: any = {};
    if (message.sourceProvenanceHash?.length) {
      obj.sourceProvenanceHash = message.sourceProvenanceHash.map((e) => hash_HashTypeToJSON(e));
    }
    if (message.requestedVerifyOption !== 0) {
      obj.requestedVerifyOption = buildOptions_VerifyOptionToJSON(message.requestedVerifyOption);
    }
    if (message.machineType !== 0) {
      obj.machineType = buildOptions_MachineTypeToJSON(message.machineType);
    }
    if (!message.diskSizeGb.equals(Long.ZERO)) {
      obj.diskSizeGb = (message.diskSizeGb || Long.ZERO).toString();
    }
    if (message.substitutionOption !== 0) {
      obj.substitutionOption = buildOptions_SubstitutionOptionToJSON(message.substitutionOption);
    }
    if (message.dynamicSubstitutions !== false) {
      obj.dynamicSubstitutions = message.dynamicSubstitutions;
    }
    if (message.automapSubstitutions !== false) {
      obj.automapSubstitutions = message.automapSubstitutions;
    }
    if (message.logStreamingOption !== 0) {
      obj.logStreamingOption = buildOptions_LogStreamingOptionToJSON(message.logStreamingOption);
    }
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.pool !== undefined) {
      obj.pool = BuildOptions_PoolOption.toJSON(message.pool);
    }
    if (message.logging !== 0) {
      obj.logging = buildOptions_LoggingModeToJSON(message.logging);
    }
    if (message.env?.length) {
      obj.env = message.env;
    }
    if (message.secretEnv?.length) {
      obj.secretEnv = message.secretEnv;
    }
    if (message.volumes?.length) {
      obj.volumes = message.volumes.map((e) => Volume.toJSON(e));
    }
    if (message.defaultLogsBucketBehavior !== 0) {
      obj.defaultLogsBucketBehavior = buildOptions_DefaultLogsBucketBehaviorToJSON(message.defaultLogsBucketBehavior);
    }
    return obj;
  },

  create(base?: DeepPartial<BuildOptions>): BuildOptions {
    return BuildOptions.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildOptions>): BuildOptions {
    const message = createBaseBuildOptions();
    message.sourceProvenanceHash = object.sourceProvenanceHash?.map((e) => e) || [];
    message.requestedVerifyOption = object.requestedVerifyOption ?? 0;
    message.machineType = object.machineType ?? 0;
    message.diskSizeGb = (object.diskSizeGb !== undefined && object.diskSizeGb !== null)
      ? Long.fromValue(object.diskSizeGb)
      : Long.ZERO;
    message.substitutionOption = object.substitutionOption ?? 0;
    message.dynamicSubstitutions = object.dynamicSubstitutions ?? false;
    message.automapSubstitutions = object.automapSubstitutions ?? false;
    message.logStreamingOption = object.logStreamingOption ?? 0;
    message.workerPool = object.workerPool ?? "";
    message.pool = (object.pool !== undefined && object.pool !== null)
      ? BuildOptions_PoolOption.fromPartial(object.pool)
      : undefined;
    message.logging = object.logging ?? 0;
    message.env = object.env?.map((e) => e) || [];
    message.secretEnv = object.secretEnv?.map((e) => e) || [];
    message.volumes = object.volumes?.map((e) => Volume.fromPartial(e)) || [];
    message.defaultLogsBucketBehavior = object.defaultLogsBucketBehavior ?? 0;
    return message;
  },
};

function createBaseBuildOptions_PoolOption(): BuildOptions_PoolOption {
  return { name: "" };
}

export const BuildOptions_PoolOption: MessageFns<BuildOptions_PoolOption> = {
  encode(message: BuildOptions_PoolOption, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildOptions_PoolOption {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildOptions_PoolOption();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildOptions_PoolOption {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: BuildOptions_PoolOption): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildOptions_PoolOption>): BuildOptions_PoolOption {
    return BuildOptions_PoolOption.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildOptions_PoolOption>): BuildOptions_PoolOption {
    const message = createBaseBuildOptions_PoolOption();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseReceiveTriggerWebhookRequest(): ReceiveTriggerWebhookRequest {
  return { name: "", body: undefined, projectId: "", trigger: "", secret: "" };
}

export const ReceiveTriggerWebhookRequest: MessageFns<ReceiveTriggerWebhookRequest> = {
  encode(message: ReceiveTriggerWebhookRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(42).string(message.name);
    }
    if (message.body !== undefined) {
      HttpBody.encode(message.body, writer.uint32(10).fork()).join();
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.trigger !== "") {
      writer.uint32(26).string(message.trigger);
    }
    if (message.secret !== "") {
      writer.uint32(34).string(message.secret);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReceiveTriggerWebhookRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReceiveTriggerWebhookRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.name = reader.string();
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.body = HttpBody.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.trigger = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.secret = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReceiveTriggerWebhookRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      body: isSet(object.body) ? HttpBody.fromJSON(object.body) : undefined,
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      trigger: isSet(object.trigger) ? globalThis.String(object.trigger) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
    };
  },

  toJSON(message: ReceiveTriggerWebhookRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.body !== undefined) {
      obj.body = HttpBody.toJSON(message.body);
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.trigger !== "") {
      obj.trigger = message.trigger;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    return obj;
  },

  create(base?: DeepPartial<ReceiveTriggerWebhookRequest>): ReceiveTriggerWebhookRequest {
    return ReceiveTriggerWebhookRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ReceiveTriggerWebhookRequest>): ReceiveTriggerWebhookRequest {
    const message = createBaseReceiveTriggerWebhookRequest();
    message.name = object.name ?? "";
    message.body = (object.body !== undefined && object.body !== null) ? HttpBody.fromPartial(object.body) : undefined;
    message.projectId = object.projectId ?? "";
    message.trigger = object.trigger ?? "";
    message.secret = object.secret ?? "";
    return message;
  },
};

function createBaseReceiveTriggerWebhookResponse(): ReceiveTriggerWebhookResponse {
  return {};
}

export const ReceiveTriggerWebhookResponse: MessageFns<ReceiveTriggerWebhookResponse> = {
  encode(_: ReceiveTriggerWebhookResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReceiveTriggerWebhookResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReceiveTriggerWebhookResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ReceiveTriggerWebhookResponse {
    return {};
  },

  toJSON(_: ReceiveTriggerWebhookResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ReceiveTriggerWebhookResponse>): ReceiveTriggerWebhookResponse {
    return ReceiveTriggerWebhookResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ReceiveTriggerWebhookResponse>): ReceiveTriggerWebhookResponse {
    const message = createBaseReceiveTriggerWebhookResponse();
    return message;
  },
};

function createBaseGitHubEnterpriseConfig(): GitHubEnterpriseConfig {
  return {
    name: "",
    hostUrl: "",
    appId: Long.ZERO,
    createTime: undefined,
    webhookKey: "",
    peeredNetwork: "",
    secrets: undefined,
    displayName: "",
    sslCa: "",
  };
}

export const GitHubEnterpriseConfig: MessageFns<GitHubEnterpriseConfig> = {
  encode(message: GitHubEnterpriseConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(58).string(message.name);
    }
    if (message.hostUrl !== "") {
      writer.uint32(26).string(message.hostUrl);
    }
    if (!message.appId.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.appId.toString());
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.webhookKey !== "") {
      writer.uint32(66).string(message.webhookKey);
    }
    if (message.peeredNetwork !== "") {
      writer.uint32(74).string(message.peeredNetwork);
    }
    if (message.secrets !== undefined) {
      GitHubEnterpriseSecrets.encode(message.secrets, writer.uint32(82).fork()).join();
    }
    if (message.displayName !== "") {
      writer.uint32(90).string(message.displayName);
    }
    if (message.sslCa !== "") {
      writer.uint32(98).string(message.sslCa);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GitHubEnterpriseConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGitHubEnterpriseConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 7:
          if (tag !== 58) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.hostUrl = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.appId = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.webhookKey = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.peeredNetwork = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.secrets = GitHubEnterpriseSecrets.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.sslCa = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GitHubEnterpriseConfig {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      hostUrl: isSet(object.hostUrl) ? globalThis.String(object.hostUrl) : "",
      appId: isSet(object.appId) ? Long.fromValue(object.appId) : Long.ZERO,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      webhookKey: isSet(object.webhookKey) ? globalThis.String(object.webhookKey) : "",
      peeredNetwork: isSet(object.peeredNetwork) ? globalThis.String(object.peeredNetwork) : "",
      secrets: isSet(object.secrets) ? GitHubEnterpriseSecrets.fromJSON(object.secrets) : undefined,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      sslCa: isSet(object.sslCa) ? globalThis.String(object.sslCa) : "",
    };
  },

  toJSON(message: GitHubEnterpriseConfig): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.hostUrl !== "") {
      obj.hostUrl = message.hostUrl;
    }
    if (!message.appId.equals(Long.ZERO)) {
      obj.appId = (message.appId || Long.ZERO).toString();
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.webhookKey !== "") {
      obj.webhookKey = message.webhookKey;
    }
    if (message.peeredNetwork !== "") {
      obj.peeredNetwork = message.peeredNetwork;
    }
    if (message.secrets !== undefined) {
      obj.secrets = GitHubEnterpriseSecrets.toJSON(message.secrets);
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.sslCa !== "") {
      obj.sslCa = message.sslCa;
    }
    return obj;
  },

  create(base?: DeepPartial<GitHubEnterpriseConfig>): GitHubEnterpriseConfig {
    return GitHubEnterpriseConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GitHubEnterpriseConfig>): GitHubEnterpriseConfig {
    const message = createBaseGitHubEnterpriseConfig();
    message.name = object.name ?? "";
    message.hostUrl = object.hostUrl ?? "";
    message.appId = (object.appId !== undefined && object.appId !== null) ? Long.fromValue(object.appId) : Long.ZERO;
    message.createTime = object.createTime ?? undefined;
    message.webhookKey = object.webhookKey ?? "";
    message.peeredNetwork = object.peeredNetwork ?? "";
    message.secrets = (object.secrets !== undefined && object.secrets !== null)
      ? GitHubEnterpriseSecrets.fromPartial(object.secrets)
      : undefined;
    message.displayName = object.displayName ?? "";
    message.sslCa = object.sslCa ?? "";
    return message;
  },
};

function createBaseGitHubEnterpriseSecrets(): GitHubEnterpriseSecrets {
  return {
    privateKeyVersionName: "",
    webhookSecretVersionName: "",
    oauthSecretVersionName: "",
    oauthClientIdVersionName: "",
  };
}

export const GitHubEnterpriseSecrets: MessageFns<GitHubEnterpriseSecrets> = {
  encode(message: GitHubEnterpriseSecrets, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.privateKeyVersionName !== "") {
      writer.uint32(42).string(message.privateKeyVersionName);
    }
    if (message.webhookSecretVersionName !== "") {
      writer.uint32(50).string(message.webhookSecretVersionName);
    }
    if (message.oauthSecretVersionName !== "") {
      writer.uint32(58).string(message.oauthSecretVersionName);
    }
    if (message.oauthClientIdVersionName !== "") {
      writer.uint32(66).string(message.oauthClientIdVersionName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GitHubEnterpriseSecrets {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGitHubEnterpriseSecrets();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.privateKeyVersionName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.webhookSecretVersionName = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.oauthSecretVersionName = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.oauthClientIdVersionName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GitHubEnterpriseSecrets {
    return {
      privateKeyVersionName: isSet(object.privateKeyVersionName) ? globalThis.String(object.privateKeyVersionName) : "",
      webhookSecretVersionName: isSet(object.webhookSecretVersionName)
        ? globalThis.String(object.webhookSecretVersionName)
        : "",
      oauthSecretVersionName: isSet(object.oauthSecretVersionName)
        ? globalThis.String(object.oauthSecretVersionName)
        : "",
      oauthClientIdVersionName: isSet(object.oauthClientIdVersionName)
        ? globalThis.String(object.oauthClientIdVersionName)
        : "",
    };
  },

  toJSON(message: GitHubEnterpriseSecrets): unknown {
    const obj: any = {};
    if (message.privateKeyVersionName !== "") {
      obj.privateKeyVersionName = message.privateKeyVersionName;
    }
    if (message.webhookSecretVersionName !== "") {
      obj.webhookSecretVersionName = message.webhookSecretVersionName;
    }
    if (message.oauthSecretVersionName !== "") {
      obj.oauthSecretVersionName = message.oauthSecretVersionName;
    }
    if (message.oauthClientIdVersionName !== "") {
      obj.oauthClientIdVersionName = message.oauthClientIdVersionName;
    }
    return obj;
  },

  create(base?: DeepPartial<GitHubEnterpriseSecrets>): GitHubEnterpriseSecrets {
    return GitHubEnterpriseSecrets.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GitHubEnterpriseSecrets>): GitHubEnterpriseSecrets {
    const message = createBaseGitHubEnterpriseSecrets();
    message.privateKeyVersionName = object.privateKeyVersionName ?? "";
    message.webhookSecretVersionName = object.webhookSecretVersionName ?? "";
    message.oauthSecretVersionName = object.oauthSecretVersionName ?? "";
    message.oauthClientIdVersionName = object.oauthClientIdVersionName ?? "";
    return message;
  },
};

function createBaseWorkerPool(): WorkerPool {
  return {
    name: "",
    displayName: "",
    uid: "",
    annotations: {},
    createTime: undefined,
    updateTime: undefined,
    deleteTime: undefined,
    state: 0,
    privatePoolV1Config: undefined,
    etag: "",
  };
}

export const WorkerPool: MessageFns<WorkerPool> = {
  encode(message: WorkerPool, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      WorkerPool_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(42).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(50).fork()).join();
    }
    if (message.deleteTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deleteTime), writer.uint32(58).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.privatePoolV1Config !== undefined) {
      PrivatePoolV1Config.encode(message.privatePoolV1Config, writer.uint32(98).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(90).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkerPool {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerPool();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = WorkerPool_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.annotations[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.deleteTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.privatePoolV1Config = PrivatePoolV1Config.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkerPool {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      deleteTime: isSet(object.deleteTime) ? fromJsonTimestamp(object.deleteTime) : undefined,
      state: isSet(object.state) ? workerPool_StateFromJSON(object.state) : 0,
      privatePoolV1Config: isSet(object.privatePoolV1Config)
        ? PrivatePoolV1Config.fromJSON(object.privatePoolV1Config)
        : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: WorkerPool): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.deleteTime !== undefined) {
      obj.deleteTime = message.deleteTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = workerPool_StateToJSON(message.state);
    }
    if (message.privatePoolV1Config !== undefined) {
      obj.privatePoolV1Config = PrivatePoolV1Config.toJSON(message.privatePoolV1Config);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkerPool>): WorkerPool {
    return WorkerPool.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerPool>): WorkerPool {
    const message = createBaseWorkerPool();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.deleteTime = object.deleteTime ?? undefined;
    message.state = object.state ?? 0;
    message.privatePoolV1Config = (object.privatePoolV1Config !== undefined && object.privatePoolV1Config !== null)
      ? PrivatePoolV1Config.fromPartial(object.privatePoolV1Config)
      : undefined;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseWorkerPool_AnnotationsEntry(): WorkerPool_AnnotationsEntry {
  return { key: "", value: "" };
}

export const WorkerPool_AnnotationsEntry: MessageFns<WorkerPool_AnnotationsEntry> = {
  encode(message: WorkerPool_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkerPool_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkerPool_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkerPool_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: WorkerPool_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkerPool_AnnotationsEntry>): WorkerPool_AnnotationsEntry {
    return WorkerPool_AnnotationsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkerPool_AnnotationsEntry>): WorkerPool_AnnotationsEntry {
    const message = createBaseWorkerPool_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePrivatePoolV1Config(): PrivatePoolV1Config {
  return { workerConfig: undefined, networkConfig: undefined };
}

export const PrivatePoolV1Config: MessageFns<PrivatePoolV1Config> = {
  encode(message: PrivatePoolV1Config, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerConfig !== undefined) {
      PrivatePoolV1Config_WorkerConfig.encode(message.workerConfig, writer.uint32(10).fork()).join();
    }
    if (message.networkConfig !== undefined) {
      PrivatePoolV1Config_NetworkConfig.encode(message.networkConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivatePoolV1Config {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivatePoolV1Config();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerConfig = PrivatePoolV1Config_WorkerConfig.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.networkConfig = PrivatePoolV1Config_NetworkConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivatePoolV1Config {
    return {
      workerConfig: isSet(object.workerConfig)
        ? PrivatePoolV1Config_WorkerConfig.fromJSON(object.workerConfig)
        : undefined,
      networkConfig: isSet(object.networkConfig)
        ? PrivatePoolV1Config_NetworkConfig.fromJSON(object.networkConfig)
        : undefined,
    };
  },

  toJSON(message: PrivatePoolV1Config): unknown {
    const obj: any = {};
    if (message.workerConfig !== undefined) {
      obj.workerConfig = PrivatePoolV1Config_WorkerConfig.toJSON(message.workerConfig);
    }
    if (message.networkConfig !== undefined) {
      obj.networkConfig = PrivatePoolV1Config_NetworkConfig.toJSON(message.networkConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivatePoolV1Config>): PrivatePoolV1Config {
    return PrivatePoolV1Config.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivatePoolV1Config>): PrivatePoolV1Config {
    const message = createBasePrivatePoolV1Config();
    message.workerConfig = (object.workerConfig !== undefined && object.workerConfig !== null)
      ? PrivatePoolV1Config_WorkerConfig.fromPartial(object.workerConfig)
      : undefined;
    message.networkConfig = (object.networkConfig !== undefined && object.networkConfig !== null)
      ? PrivatePoolV1Config_NetworkConfig.fromPartial(object.networkConfig)
      : undefined;
    return message;
  },
};

function createBasePrivatePoolV1Config_WorkerConfig(): PrivatePoolV1Config_WorkerConfig {
  return { machineType: "", diskSizeGb: Long.ZERO };
}

export const PrivatePoolV1Config_WorkerConfig: MessageFns<PrivatePoolV1Config_WorkerConfig> = {
  encode(message: PrivatePoolV1Config_WorkerConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.machineType !== "") {
      writer.uint32(10).string(message.machineType);
    }
    if (!message.diskSizeGb.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.diskSizeGb.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivatePoolV1Config_WorkerConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivatePoolV1Config_WorkerConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.machineType = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.diskSizeGb = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivatePoolV1Config_WorkerConfig {
    return {
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
      diskSizeGb: isSet(object.diskSizeGb) ? Long.fromValue(object.diskSizeGb) : Long.ZERO,
    };
  },

  toJSON(message: PrivatePoolV1Config_WorkerConfig): unknown {
    const obj: any = {};
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    if (!message.diskSizeGb.equals(Long.ZERO)) {
      obj.diskSizeGb = (message.diskSizeGb || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<PrivatePoolV1Config_WorkerConfig>): PrivatePoolV1Config_WorkerConfig {
    return PrivatePoolV1Config_WorkerConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivatePoolV1Config_WorkerConfig>): PrivatePoolV1Config_WorkerConfig {
    const message = createBasePrivatePoolV1Config_WorkerConfig();
    message.machineType = object.machineType ?? "";
    message.diskSizeGb = (object.diskSizeGb !== undefined && object.diskSizeGb !== null)
      ? Long.fromValue(object.diskSizeGb)
      : Long.ZERO;
    return message;
  },
};

function createBasePrivatePoolV1Config_NetworkConfig(): PrivatePoolV1Config_NetworkConfig {
  return { peeredNetwork: "", egressOption: 0, peeredNetworkIpRange: "" };
}

export const PrivatePoolV1Config_NetworkConfig: MessageFns<PrivatePoolV1Config_NetworkConfig> = {
  encode(message: PrivatePoolV1Config_NetworkConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.peeredNetwork !== "") {
      writer.uint32(10).string(message.peeredNetwork);
    }
    if (message.egressOption !== 0) {
      writer.uint32(16).int32(message.egressOption);
    }
    if (message.peeredNetworkIpRange !== "") {
      writer.uint32(26).string(message.peeredNetworkIpRange);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivatePoolV1Config_NetworkConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivatePoolV1Config_NetworkConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.peeredNetwork = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.egressOption = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.peeredNetworkIpRange = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivatePoolV1Config_NetworkConfig {
    return {
      peeredNetwork: isSet(object.peeredNetwork) ? globalThis.String(object.peeredNetwork) : "",
      egressOption: isSet(object.egressOption)
        ? privatePoolV1Config_NetworkConfig_EgressOptionFromJSON(object.egressOption)
        : 0,
      peeredNetworkIpRange: isSet(object.peeredNetworkIpRange) ? globalThis.String(object.peeredNetworkIpRange) : "",
    };
  },

  toJSON(message: PrivatePoolV1Config_NetworkConfig): unknown {
    const obj: any = {};
    if (message.peeredNetwork !== "") {
      obj.peeredNetwork = message.peeredNetwork;
    }
    if (message.egressOption !== 0) {
      obj.egressOption = privatePoolV1Config_NetworkConfig_EgressOptionToJSON(message.egressOption);
    }
    if (message.peeredNetworkIpRange !== "") {
      obj.peeredNetworkIpRange = message.peeredNetworkIpRange;
    }
    return obj;
  },

  create(base?: DeepPartial<PrivatePoolV1Config_NetworkConfig>): PrivatePoolV1Config_NetworkConfig {
    return PrivatePoolV1Config_NetworkConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivatePoolV1Config_NetworkConfig>): PrivatePoolV1Config_NetworkConfig {
    const message = createBasePrivatePoolV1Config_NetworkConfig();
    message.peeredNetwork = object.peeredNetwork ?? "";
    message.egressOption = object.egressOption ?? 0;
    message.peeredNetworkIpRange = object.peeredNetworkIpRange ?? "";
    return message;
  },
};

function createBaseCreateWorkerPoolRequest(): CreateWorkerPoolRequest {
  return { parent: "", workerPool: undefined, workerPoolId: "", validateOnly: false };
}

export const CreateWorkerPoolRequest: MessageFns<CreateWorkerPoolRequest> = {
  encode(message: CreateWorkerPoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.workerPool !== undefined) {
      WorkerPool.encode(message.workerPool, writer.uint32(18).fork()).join();
    }
    if (message.workerPoolId !== "") {
      writer.uint32(26).string(message.workerPoolId);
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateWorkerPoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateWorkerPoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.workerPool = WorkerPool.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.workerPoolId = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateWorkerPoolRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      workerPool: isSet(object.workerPool) ? WorkerPool.fromJSON(object.workerPool) : undefined,
      workerPoolId: isSet(object.workerPoolId) ? globalThis.String(object.workerPoolId) : "",
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: CreateWorkerPoolRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.workerPool !== undefined) {
      obj.workerPool = WorkerPool.toJSON(message.workerPool);
    }
    if (message.workerPoolId !== "") {
      obj.workerPoolId = message.workerPoolId;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateWorkerPoolRequest>): CreateWorkerPoolRequest {
    return CreateWorkerPoolRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateWorkerPoolRequest>): CreateWorkerPoolRequest {
    const message = createBaseCreateWorkerPoolRequest();
    message.parent = object.parent ?? "";
    message.workerPool = (object.workerPool !== undefined && object.workerPool !== null)
      ? WorkerPool.fromPartial(object.workerPool)
      : undefined;
    message.workerPoolId = object.workerPoolId ?? "";
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseGetWorkerPoolRequest(): GetWorkerPoolRequest {
  return { name: "" };
}

export const GetWorkerPoolRequest: MessageFns<GetWorkerPoolRequest> = {
  encode(message: GetWorkerPoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetWorkerPoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetWorkerPoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetWorkerPoolRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetWorkerPoolRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetWorkerPoolRequest>): GetWorkerPoolRequest {
    return GetWorkerPoolRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetWorkerPoolRequest>): GetWorkerPoolRequest {
    const message = createBaseGetWorkerPoolRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDeleteWorkerPoolRequest(): DeleteWorkerPoolRequest {
  return { name: "", etag: "", allowMissing: false, validateOnly: false };
}

export const DeleteWorkerPoolRequest: MessageFns<DeleteWorkerPoolRequest> = {
  encode(message: DeleteWorkerPoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.etag !== "") {
      writer.uint32(18).string(message.etag);
    }
    if (message.allowMissing !== false) {
      writer.uint32(24).bool(message.allowMissing);
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteWorkerPoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteWorkerPoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.etag = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.allowMissing = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteWorkerPoolRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      allowMissing: isSet(object.allowMissing) ? globalThis.Boolean(object.allowMissing) : false,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: DeleteWorkerPoolRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.allowMissing !== false) {
      obj.allowMissing = message.allowMissing;
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteWorkerPoolRequest>): DeleteWorkerPoolRequest {
    return DeleteWorkerPoolRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteWorkerPoolRequest>): DeleteWorkerPoolRequest {
    const message = createBaseDeleteWorkerPoolRequest();
    message.name = object.name ?? "";
    message.etag = object.etag ?? "";
    message.allowMissing = object.allowMissing ?? false;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseUpdateWorkerPoolRequest(): UpdateWorkerPoolRequest {
  return { workerPool: undefined, updateMask: undefined, validateOnly: false };
}

export const UpdateWorkerPoolRequest: MessageFns<UpdateWorkerPoolRequest> = {
  encode(message: UpdateWorkerPoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerPool !== undefined) {
      WorkerPool.encode(message.workerPool, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    if (message.validateOnly !== false) {
      writer.uint32(32).bool(message.validateOnly);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateWorkerPoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateWorkerPoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerPool = WorkerPool.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.validateOnly = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateWorkerPoolRequest {
    return {
      workerPool: isSet(object.workerPool) ? WorkerPool.fromJSON(object.workerPool) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      validateOnly: isSet(object.validateOnly) ? globalThis.Boolean(object.validateOnly) : false,
    };
  },

  toJSON(message: UpdateWorkerPoolRequest): unknown {
    const obj: any = {};
    if (message.workerPool !== undefined) {
      obj.workerPool = WorkerPool.toJSON(message.workerPool);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.validateOnly !== false) {
      obj.validateOnly = message.validateOnly;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateWorkerPoolRequest>): UpdateWorkerPoolRequest {
    return UpdateWorkerPoolRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateWorkerPoolRequest>): UpdateWorkerPoolRequest {
    const message = createBaseUpdateWorkerPoolRequest();
    message.workerPool = (object.workerPool !== undefined && object.workerPool !== null)
      ? WorkerPool.fromPartial(object.workerPool)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    message.validateOnly = object.validateOnly ?? false;
    return message;
  },
};

function createBaseListWorkerPoolsRequest(): ListWorkerPoolsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListWorkerPoolsRequest: MessageFns<ListWorkerPoolsRequest> = {
  encode(message: ListWorkerPoolsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkerPoolsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkerPoolsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkerPoolsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListWorkerPoolsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkerPoolsRequest>): ListWorkerPoolsRequest {
    return ListWorkerPoolsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkerPoolsRequest>): ListWorkerPoolsRequest {
    const message = createBaseListWorkerPoolsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListWorkerPoolsResponse(): ListWorkerPoolsResponse {
  return { workerPools: [], nextPageToken: "" };
}

export const ListWorkerPoolsResponse: MessageFns<ListWorkerPoolsResponse> = {
  encode(message: ListWorkerPoolsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workerPools) {
      WorkerPool.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListWorkerPoolsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListWorkerPoolsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerPools.push(WorkerPool.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListWorkerPoolsResponse {
    return {
      workerPools: globalThis.Array.isArray(object?.workerPools)
        ? object.workerPools.map((e: any) => WorkerPool.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListWorkerPoolsResponse): unknown {
    const obj: any = {};
    if (message.workerPools?.length) {
      obj.workerPools = message.workerPools.map((e) => WorkerPool.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListWorkerPoolsResponse>): ListWorkerPoolsResponse {
    return ListWorkerPoolsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListWorkerPoolsResponse>): ListWorkerPoolsResponse {
    const message = createBaseListWorkerPoolsResponse();
    message.workerPools = object.workerPools?.map((e) => WorkerPool.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCreateWorkerPoolOperationMetadata(): CreateWorkerPoolOperationMetadata {
  return { workerPool: "", createTime: undefined, completeTime: undefined };
}

export const CreateWorkerPoolOperationMetadata: MessageFns<CreateWorkerPoolOperationMetadata> = {
  encode(message: CreateWorkerPoolOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerPool !== "") {
      writer.uint32(10).string(message.workerPool);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.completeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.completeTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateWorkerPoolOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateWorkerPoolOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.completeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateWorkerPoolOperationMetadata {
    return {
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      completeTime: isSet(object.completeTime) ? fromJsonTimestamp(object.completeTime) : undefined,
    };
  },

  toJSON(message: CreateWorkerPoolOperationMetadata): unknown {
    const obj: any = {};
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.completeTime !== undefined) {
      obj.completeTime = message.completeTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CreateWorkerPoolOperationMetadata>): CreateWorkerPoolOperationMetadata {
    return CreateWorkerPoolOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateWorkerPoolOperationMetadata>): CreateWorkerPoolOperationMetadata {
    const message = createBaseCreateWorkerPoolOperationMetadata();
    message.workerPool = object.workerPool ?? "";
    message.createTime = object.createTime ?? undefined;
    message.completeTime = object.completeTime ?? undefined;
    return message;
  },
};

function createBaseUpdateWorkerPoolOperationMetadata(): UpdateWorkerPoolOperationMetadata {
  return { workerPool: "", createTime: undefined, completeTime: undefined };
}

export const UpdateWorkerPoolOperationMetadata: MessageFns<UpdateWorkerPoolOperationMetadata> = {
  encode(message: UpdateWorkerPoolOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerPool !== "") {
      writer.uint32(10).string(message.workerPool);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.completeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.completeTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateWorkerPoolOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateWorkerPoolOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.completeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateWorkerPoolOperationMetadata {
    return {
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      completeTime: isSet(object.completeTime) ? fromJsonTimestamp(object.completeTime) : undefined,
    };
  },

  toJSON(message: UpdateWorkerPoolOperationMetadata): unknown {
    const obj: any = {};
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.completeTime !== undefined) {
      obj.completeTime = message.completeTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateWorkerPoolOperationMetadata>): UpdateWorkerPoolOperationMetadata {
    return UpdateWorkerPoolOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateWorkerPoolOperationMetadata>): UpdateWorkerPoolOperationMetadata {
    const message = createBaseUpdateWorkerPoolOperationMetadata();
    message.workerPool = object.workerPool ?? "";
    message.createTime = object.createTime ?? undefined;
    message.completeTime = object.completeTime ?? undefined;
    return message;
  },
};

function createBaseDeleteWorkerPoolOperationMetadata(): DeleteWorkerPoolOperationMetadata {
  return { workerPool: "", createTime: undefined, completeTime: undefined };
}

export const DeleteWorkerPoolOperationMetadata: MessageFns<DeleteWorkerPoolOperationMetadata> = {
  encode(message: DeleteWorkerPoolOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerPool !== "") {
      writer.uint32(10).string(message.workerPool);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.completeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.completeTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteWorkerPoolOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteWorkerPoolOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.completeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteWorkerPoolOperationMetadata {
    return {
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      completeTime: isSet(object.completeTime) ? fromJsonTimestamp(object.completeTime) : undefined,
    };
  },

  toJSON(message: DeleteWorkerPoolOperationMetadata): unknown {
    const obj: any = {};
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.completeTime !== undefined) {
      obj.completeTime = message.completeTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteWorkerPoolOperationMetadata>): DeleteWorkerPoolOperationMetadata {
    return DeleteWorkerPoolOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteWorkerPoolOperationMetadata>): DeleteWorkerPoolOperationMetadata {
    const message = createBaseDeleteWorkerPoolOperationMetadata();
    message.workerPool = object.workerPool ?? "";
    message.createTime = object.createTime ?? undefined;
    message.completeTime = object.completeTime ?? undefined;
    return message;
  },
};

/**
 * Creates and manages builds on Google Cloud Platform.
 *
 * The main concept used by this API is a `Build`, which describes the location
 * of the source to build, how to build the source, and where to store the
 * built artifacts, if any.
 *
 * A user can list previously-requested builds or get builds by their ID to
 * determine the status of the build.
 */
export type CloudBuildDefinition = typeof CloudBuildDefinition;
export const CloudBuildDefinition = {
  name: "CloudBuild",
  fullName: "google.devtools.cloudbuild.v1.CloudBuild",
  methods: {
    /**
     * Starts a build with the specified configuration.
     *
     * This method returns a long-running `Operation`, which includes the build
     * ID. Pass the build ID to `GetBuild` to determine the build status (such as
     * `SUCCESS` or `FAILURE`).
     */
    createBuild: {
      name: "CreateBuild",
      requestType: CreateBuildRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              5,
              66,
              117,
              105,
              108,
              100,
              18,
              22,
              66,
              117,
              105,
              108,
              100,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([16, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 98, 117, 105, 108, 100])],
          578365826: [
            Buffer.from([
              94,
              58,
              5,
              98,
              117,
              105,
              108,
              100,
              90,
              51,
              58,
              5,
              98,
              117,
              105,
              108,
              100,
              34,
              42,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              34,
              32,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              45,
              18,
              43,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Returns information about a previously requested build.
     *
     * The `Build` that is returned includes its status (such as `SUCCESS`,
     * `FAILURE`, or `WORKING`), and timing information.
     */
    getBuild: {
      name: "GetBuild",
      requestType: GetBuildRequest,
      requestStream: false,
      responseType: Build,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([13, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 105, 100])],
          578365826: [
            Buffer.from([
              85,
              90,
              44,
              18,
              42,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
              125,
              18,
              37,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              123,
              105,
              100,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              52,
              18,
              50,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              42,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Lists previously requested builds.
     *
     * Previously requested builds may still be in-progress, or may have finished
     * successfully or unsuccessfully.
     */
    listBuilds: {
      name: "ListBuilds",
      requestType: ListBuildsRequest,
      requestStream: false,
      responseType: ListBuildsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([17, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 102, 105, 108, 116, 101, 114])],
          578365826: [
            Buffer.from([
              80,
              90,
              44,
              18,
              42,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              18,
              32,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              45,
              18,
              43,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Cancels a build in progress. */
    cancelBuild: {
      name: "CancelBuild",
      requestType: CancelBuildRequest,
      requestStream: false,
      responseType: Build,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([13, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 105, 100])],
          578365826: [
            Buffer.from([
              105,
              58,
              1,
              42,
              90,
              54,
              58,
              1,
              42,
              34,
              49,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
              34,
              44,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              123,
              105,
              100,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
          578365834: [
            Buffer.from([
              52,
              18,
              50,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              42,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new build based on the specified build.
     *
     * This method creates a new build using the original build request, which may
     * or may not result in an identical build.
     *
     * For triggered builds:
     *
     * * Triggered builds resolve to a precise revision; therefore a retry of a
     * triggered build will result in a build that uses the same revision.
     *
     * For non-triggered builds that specify `RepoSource`:
     *
     * * If the original build built from the tip of a branch, the retried build
     * will build from the tip of that branch, which may not be the same revision
     * as the original build.
     * * If the original build specified a commit sha or revision ID, the retried
     * build will use the identical source.
     *
     * For builds that specify `StorageSource`:
     *
     * * If the original build pulled source from Cloud Storage without
     * specifying the generation of the object, the new build will use the current
     * object, which may be different from the original build source.
     * * If the original build pulled source from Cloud Storage and specified the
     * generation of the object, the new build will attempt to use the same
     * object, which may or may not be available depending on the bucket's
     * lifecycle management settings.
     */
    retryBuild: {
      name: "RetryBuild",
      requestType: RetryBuildRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              5,
              66,
              117,
              105,
              108,
              100,
              18,
              22,
              66,
              117,
              105,
              108,
              100,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([13, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 105, 100])],
          578365826: [
            Buffer.from([
              103,
              58,
              1,
              42,
              90,
              53,
              58,
              1,
              42,
              34,
              48,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
              125,
              58,
              114,
              101,
              116,
              114,
              121,
              34,
              43,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              123,
              105,
              100,
              125,
              58,
              114,
              101,
              116,
              114,
              121,
            ]),
          ],
          578365834: [
            Buffer.from([
              52,
              18,
              50,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              42,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Approves or rejects a pending build.
     *
     * If approved, the returned LRO will be analogous to the LRO returned from
     * a CreateBuild call.
     *
     * If rejected, the returned LRO will be immediately done.
     */
    approveBuild: {
      name: "ApproveBuild",
      requestType: ApproveBuildRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              5,
              66,
              117,
              105,
              108,
              100,
              18,
              22,
              66,
              117,
              105,
              108,
              100,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              20,
              110,
              97,
              109,
              101,
              44,
              97,
              112,
              112,
              114,
              111,
              118,
              97,
              108,
              95,
              114,
              101,
              115,
              117,
              108,
              116,
            ]),
          ],
          578365826: [
            Buffer.from([
              100,
              58,
              1,
              42,
              90,
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
              125,
              58,
              97,
              112,
              112,
              114,
              111,
              118,
              101,
              34,
              38,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
              125,
              58,
              97,
              112,
              112,
              114,
              111,
              118,
              101,
            ]),
          ],
          578365834: [
            Buffer.from([
              52,
              18,
              50,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              42,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              98,
              117,
              105,
              108,
              100,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new `BuildTrigger`.
     *
     * This API is experimental.
     */
    createBuildTrigger: {
      name: "CreateBuildTrigger",
      requestType: CreateBuildTriggerRequest,
      requestStream: false,
      responseType: BuildTrigger,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100, 44, 116, 114, 105, 103, 103, 101, 114]),
          ],
          578365826: [
            Buffer.from([
              102,
              58,
              7,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              90,
              55,
              58,
              7,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              34,
              44,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              34,
              34,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              45,
              18,
              43,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Returns information about a `BuildTrigger`.
     *
     * This API is experimental.
     */
    getBuildTrigger: {
      name: "GetBuildTrigger",
      requestType: GetBuildTriggerRequest,
      requestStream: false,
      responseType: BuildTrigger,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              21,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              97,
              90,
              46,
              18,
              44,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              18,
              47,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              123,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              54,
              18,
              52,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              44,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Lists existing `BuildTrigger`s.
     *
     * This API is experimental.
     */
    listBuildTriggers: {
      name: "ListBuildTriggers",
      requestType: ListBuildTriggersRequest,
      requestStream: false,
      responseType: ListBuildTriggersResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([10, 112, 114, 111, 106, 101, 99, 116, 95, 105, 100])],
          578365826: [
            Buffer.from([
              84,
              90,
              46,
              18,
              44,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              18,
              34,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              45,
              18,
              43,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a `BuildTrigger` by its project ID and trigger ID.
     *
     * This API is experimental.
     */
    deleteBuildTrigger: {
      name: "DeleteBuildTrigger",
      requestType: DeleteBuildTriggerRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              21,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              97,
              90,
              46,
              42,
              44,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              42,
              47,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              123,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              54,
              18,
              52,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              44,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Updates a `BuildTrigger` by its project ID and trigger ID.
     *
     * This API is experimental.
     */
    updateBuildTrigger: {
      name: "UpdateBuildTrigger",
      requestType: UpdateBuildTriggerRequest,
      requestStream: false,
      responseType: BuildTrigger,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              29,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
              44,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
            ]),
          ],
          578365826: [
            Buffer.from([
              132,
              1,
              58,
              7,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              90,
              72,
              58,
              7,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              50,
              61,
              47,
              118,
              49,
              47,
              123,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              46,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              50,
              47,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              123,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              71,
              18,
              69,
              10,
              21,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              46,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              110,
              97,
              109,
              101,
              18,
              44,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * Runs a `BuildTrigger` at a particular source revision.
     *
     * To run a regional or global trigger, use the POST request
     * that includes the location endpoint in the path (ex.
     * v1/projects/{projectId}/locations/{region}/triggers/{triggerId}:run). The
     * POST request that does not include the location endpoint in the path can
     * only be used when running global triggers.
     */
    runBuildTrigger: {
      name: "RunBuildTrigger",
      requestType: RunBuildTriggerRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              5,
              66,
              117,
              105,
              108,
              100,
              18,
              22,
              66,
              117,
              105,
              108,
              100,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              28,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              44,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
              44,
              115,
              111,
              117,
              114,
              99,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              116,
              58,
              6,
              115,
              111,
              117,
              114,
              99,
              101,
              90,
              53,
              58,
              1,
              42,
              34,
              48,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              114,
              117,
              110,
              34,
              51,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              123,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              95,
              105,
              100,
              125,
              58,
              114,
              117,
              110,
            ]),
          ],
          578365834: [
            Buffer.from([
              54,
              18,
              52,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              44,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /**
     * ReceiveTriggerWebhook [Experimental] is called when the API receives a
     * webhook request targeted at a specific trigger.
     */
    receiveTriggerWebhook: {
      name: "ReceiveTriggerWebhook",
      requestType: ReceiveTriggerWebhookRequest,
      requestStream: false,
      responseType: ReceiveTriggerWebhookResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              122,
              58,
              4,
              98,
              111,
              100,
              121,
              90,
              60,
              58,
              4,
              98,
              111,
              100,
              121,
              34,
              52,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              42,
              125,
              58,
              119,
              101,
              98,
              104,
              111,
              111,
              107,
              34,
              52,
              47,
              118,
              49,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              115,
              47,
              123,
              116,
              114,
              105,
              103,
              103,
              101,
              114,
              125,
              58,
              119,
              101,
              98,
              104,
              111,
              111,
              107,
            ]),
          ],
        },
      },
    },
    /** Creates a `WorkerPool`. */
    createWorkerPool: {
      name: "CreateWorkerPool",
      requestType: CreateWorkerPoolRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              47,
              10,
              10,
              87,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              18,
              33,
              67,
              114,
              101,
              97,
              116,
              101,
              87,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              33,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              44,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              62,
              58,
              11,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              34,
              47,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              45,
              18,
              43,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Returns details of a `WorkerPool`. */
    getWorkerPool: {
      name: "GetWorkerPool",
      requestType: GetWorkerPoolRequest,
      requestStream: false,
      responseType: WorkerPool,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              57,
              18,
              55,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /** Deletes a `WorkerPool`. */
    deleteWorkerPool: {
      name: "DeleteWorkerPool",
      requestType: DeleteWorkerPoolRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              58,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              33,
              68,
              101,
              108,
              101,
              116,
              101,
              87,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              49,
              42,
              47,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              57,
              18,
              55,
              10,
              4,
              110,
              97,
              109,
              101,
              18,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /** Updates a `WorkerPool`. */
    updateWorkerPool: {
      name: "UpdateWorkerPool",
      requestType: UpdateWorkerPoolRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              47,
              10,
              10,
              87,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              18,
              33,
              85,
              112,
              100,
              97,
              116,
              101,
              87,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              23,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              74,
              58,
              11,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              50,
              59,
              47,
              118,
              49,
              47,
              123,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
          578365834: [
            Buffer.from([
              69,
              18,
              67,
              10,
              16,
              119,
              111,
              114,
              107,
              101,
              114,
              95,
              112,
              111,
              111,
              108,
              46,
              110,
              97,
              109,
              101,
              18,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
              47,
              42,
            ]),
          ],
        },
      },
    },
    /** Lists `WorkerPool`s. */
    listWorkerPools: {
      name: "ListWorkerPools",
      requestType: ListWorkerPoolsRequest,
      requestStream: false,
      responseType: ListWorkerPoolsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              49,
              18,
              47,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              119,
              111,
              114,
              107,
              101,
              114,
              80,
              111,
              111,
              108,
              115,
            ]),
          ],
          578365834: [
            Buffer.from([
              45,
              18,
              43,
              10,
              6,
              112,
              97,
              114,
              101,
              110,
              116,
              18,
              33,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface CloudBuildServiceImplementation<CallContextExt = {}> {
  /**
   * Starts a build with the specified configuration.
   *
   * This method returns a long-running `Operation`, which includes the build
   * ID. Pass the build ID to `GetBuild` to determine the build status (such as
   * `SUCCESS` or `FAILURE`).
   */
  createBuild(request: CreateBuildRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Returns information about a previously requested build.
   *
   * The `Build` that is returned includes its status (such as `SUCCESS`,
   * `FAILURE`, or `WORKING`), and timing information.
   */
  getBuild(request: GetBuildRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Build>>;
  /**
   * Lists previously requested builds.
   *
   * Previously requested builds may still be in-progress, or may have finished
   * successfully or unsuccessfully.
   */
  listBuilds(
    request: ListBuildsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBuildsResponse>>;
  /** Cancels a build in progress. */
  cancelBuild(request: CancelBuildRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Build>>;
  /**
   * Creates a new build based on the specified build.
   *
   * This method creates a new build using the original build request, which may
   * or may not result in an identical build.
   *
   * For triggered builds:
   *
   * * Triggered builds resolve to a precise revision; therefore a retry of a
   * triggered build will result in a build that uses the same revision.
   *
   * For non-triggered builds that specify `RepoSource`:
   *
   * * If the original build built from the tip of a branch, the retried build
   * will build from the tip of that branch, which may not be the same revision
   * as the original build.
   * * If the original build specified a commit sha or revision ID, the retried
   * build will use the identical source.
   *
   * For builds that specify `StorageSource`:
   *
   * * If the original build pulled source from Cloud Storage without
   * specifying the generation of the object, the new build will use the current
   * object, which may be different from the original build source.
   * * If the original build pulled source from Cloud Storage and specified the
   * generation of the object, the new build will attempt to use the same
   * object, which may or may not be available depending on the bucket's
   * lifecycle management settings.
   */
  retryBuild(request: RetryBuildRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Approves or rejects a pending build.
   *
   * If approved, the returned LRO will be analogous to the LRO returned from
   * a CreateBuild call.
   *
   * If rejected, the returned LRO will be immediately done.
   */
  approveBuild(request: ApproveBuildRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Creates a new `BuildTrigger`.
   *
   * This API is experimental.
   */
  createBuildTrigger(
    request: CreateBuildTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BuildTrigger>>;
  /**
   * Returns information about a `BuildTrigger`.
   *
   * This API is experimental.
   */
  getBuildTrigger(
    request: GetBuildTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BuildTrigger>>;
  /**
   * Lists existing `BuildTrigger`s.
   *
   * This API is experimental.
   */
  listBuildTriggers(
    request: ListBuildTriggersRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBuildTriggersResponse>>;
  /**
   * Deletes a `BuildTrigger` by its project ID and trigger ID.
   *
   * This API is experimental.
   */
  deleteBuildTrigger(
    request: DeleteBuildTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Updates a `BuildTrigger` by its project ID and trigger ID.
   *
   * This API is experimental.
   */
  updateBuildTrigger(
    request: UpdateBuildTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BuildTrigger>>;
  /**
   * Runs a `BuildTrigger` at a particular source revision.
   *
   * To run a regional or global trigger, use the POST request
   * that includes the location endpoint in the path (ex.
   * v1/projects/{projectId}/locations/{region}/triggers/{triggerId}:run). The
   * POST request that does not include the location endpoint in the path can
   * only be used when running global triggers.
   */
  runBuildTrigger(
    request: RunBuildTriggerRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * ReceiveTriggerWebhook [Experimental] is called when the API receives a
   * webhook request targeted at a specific trigger.
   */
  receiveTriggerWebhook(
    request: ReceiveTriggerWebhookRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ReceiveTriggerWebhookResponse>>;
  /** Creates a `WorkerPool`. */
  createWorkerPool(
    request: CreateWorkerPoolRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Returns details of a `WorkerPool`. */
  getWorkerPool(request: GetWorkerPoolRequest, context: CallContext & CallContextExt): Promise<DeepPartial<WorkerPool>>;
  /** Deletes a `WorkerPool`. */
  deleteWorkerPool(
    request: DeleteWorkerPoolRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Updates a `WorkerPool`. */
  updateWorkerPool(
    request: UpdateWorkerPoolRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists `WorkerPool`s. */
  listWorkerPools(
    request: ListWorkerPoolsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListWorkerPoolsResponse>>;
}

export interface CloudBuildClient<CallOptionsExt = {}> {
  /**
   * Starts a build with the specified configuration.
   *
   * This method returns a long-running `Operation`, which includes the build
   * ID. Pass the build ID to `GetBuild` to determine the build status (such as
   * `SUCCESS` or `FAILURE`).
   */
  createBuild(request: DeepPartial<CreateBuildRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Returns information about a previously requested build.
   *
   * The `Build` that is returned includes its status (such as `SUCCESS`,
   * `FAILURE`, or `WORKING`), and timing information.
   */
  getBuild(request: DeepPartial<GetBuildRequest>, options?: CallOptions & CallOptionsExt): Promise<Build>;
  /**
   * Lists previously requested builds.
   *
   * Previously requested builds may still be in-progress, or may have finished
   * successfully or unsuccessfully.
   */
  listBuilds(
    request: DeepPartial<ListBuildsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBuildsResponse>;
  /** Cancels a build in progress. */
  cancelBuild(request: DeepPartial<CancelBuildRequest>, options?: CallOptions & CallOptionsExt): Promise<Build>;
  /**
   * Creates a new build based on the specified build.
   *
   * This method creates a new build using the original build request, which may
   * or may not result in an identical build.
   *
   * For triggered builds:
   *
   * * Triggered builds resolve to a precise revision; therefore a retry of a
   * triggered build will result in a build that uses the same revision.
   *
   * For non-triggered builds that specify `RepoSource`:
   *
   * * If the original build built from the tip of a branch, the retried build
   * will build from the tip of that branch, which may not be the same revision
   * as the original build.
   * * If the original build specified a commit sha or revision ID, the retried
   * build will use the identical source.
   *
   * For builds that specify `StorageSource`:
   *
   * * If the original build pulled source from Cloud Storage without
   * specifying the generation of the object, the new build will use the current
   * object, which may be different from the original build source.
   * * If the original build pulled source from Cloud Storage and specified the
   * generation of the object, the new build will attempt to use the same
   * object, which may or may not be available depending on the bucket's
   * lifecycle management settings.
   */
  retryBuild(request: DeepPartial<RetryBuildRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Approves or rejects a pending build.
   *
   * If approved, the returned LRO will be analogous to the LRO returned from
   * a CreateBuild call.
   *
   * If rejected, the returned LRO will be immediately done.
   */
  approveBuild(request: DeepPartial<ApproveBuildRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Creates a new `BuildTrigger`.
   *
   * This API is experimental.
   */
  createBuildTrigger(
    request: DeepPartial<CreateBuildTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BuildTrigger>;
  /**
   * Returns information about a `BuildTrigger`.
   *
   * This API is experimental.
   */
  getBuildTrigger(
    request: DeepPartial<GetBuildTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BuildTrigger>;
  /**
   * Lists existing `BuildTrigger`s.
   *
   * This API is experimental.
   */
  listBuildTriggers(
    request: DeepPartial<ListBuildTriggersRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBuildTriggersResponse>;
  /**
   * Deletes a `BuildTrigger` by its project ID and trigger ID.
   *
   * This API is experimental.
   */
  deleteBuildTrigger(
    request: DeepPartial<DeleteBuildTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Updates a `BuildTrigger` by its project ID and trigger ID.
   *
   * This API is experimental.
   */
  updateBuildTrigger(
    request: DeepPartial<UpdateBuildTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BuildTrigger>;
  /**
   * Runs a `BuildTrigger` at a particular source revision.
   *
   * To run a regional or global trigger, use the POST request
   * that includes the location endpoint in the path (ex.
   * v1/projects/{projectId}/locations/{region}/triggers/{triggerId}:run). The
   * POST request that does not include the location endpoint in the path can
   * only be used when running global triggers.
   */
  runBuildTrigger(
    request: DeepPartial<RunBuildTriggerRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * ReceiveTriggerWebhook [Experimental] is called when the API receives a
   * webhook request targeted at a specific trigger.
   */
  receiveTriggerWebhook(
    request: DeepPartial<ReceiveTriggerWebhookRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ReceiveTriggerWebhookResponse>;
  /** Creates a `WorkerPool`. */
  createWorkerPool(
    request: DeepPartial<CreateWorkerPoolRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Returns details of a `WorkerPool`. */
  getWorkerPool(
    request: DeepPartial<GetWorkerPoolRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<WorkerPool>;
  /** Deletes a `WorkerPool`. */
  deleteWorkerPool(
    request: DeepPartial<DeleteWorkerPoolRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Updates a `WorkerPool`. */
  updateWorkerPool(
    request: DeepPartial<UpdateWorkerPoolRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists `WorkerPool`s. */
  listWorkerPools(
    request: DeepPartial<ListWorkerPoolsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListWorkerPoolsResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
