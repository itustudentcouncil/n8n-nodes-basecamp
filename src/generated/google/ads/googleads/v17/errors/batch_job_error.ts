// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/ads/googleads/v17/errors/batch_job_error.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.ads.googleads.v17.errors";

/** Container for enum describing possible batch job errors. */
export interface BatchJobErrorEnum {
}

/** Enum describing possible request errors. */
export enum BatchJobErrorEnum_BatchJobError {
  /** UNSPECIFIED - Enum unspecified. */
  UNSPECIFIED = 0,
  /** UNKNOWN - The received error code is not known in this version. */
  UNKNOWN = 1,
  /**
   * CANNOT_MODIFY_JOB_AFTER_JOB_STARTS_RUNNING - The batch job cannot add more operations or run after it has started
   * running.
   */
  CANNOT_MODIFY_JOB_AFTER_JOB_STARTS_RUNNING = 2,
  /** EMPTY_OPERATIONS - The operations for an AddBatchJobOperations request were empty. */
  EMPTY_OPERATIONS = 3,
  /** INVALID_SEQUENCE_TOKEN - The sequence token for an AddBatchJobOperations request was invalid. */
  INVALID_SEQUENCE_TOKEN = 4,
  /** RESULTS_NOT_READY - Batch job results can only be retrieved once the job is finished. */
  RESULTS_NOT_READY = 5,
  /** INVALID_PAGE_SIZE - The page size for ListBatchJobResults was invalid. */
  INVALID_PAGE_SIZE = 6,
  /** CAN_ONLY_REMOVE_PENDING_JOB - The batch job cannot be removed because it has started running. */
  CAN_ONLY_REMOVE_PENDING_JOB = 7,
  /**
   * CANNOT_LIST_RESULTS - The batch job cannot be listed due to unexpected errors such as duplicate
   * checkpoints.
   */
  CANNOT_LIST_RESULTS = 8,
  /**
   * ASSET_GROUP_AND_ASSET_GROUP_ASSET_TRANSACTION_FAILURE - The request contains interdependent AssetGroup and AssetGroupAsset
   * operations that are treated atomically as a single transaction, and one
   * or more of the operations in that transaction failed, which caused the
   * entire transaction, and therefore this mutate operation, to fail. The
   * operations that caused the transaction to fail can be found in the
   * consecutive AssetGroup or AssetGroupAsset results with the same asset
   * group id. The mutate operation will be successful once the remaining
   * errors in the transaction are fixed.
   */
  ASSET_GROUP_AND_ASSET_GROUP_ASSET_TRANSACTION_FAILURE = 9,
  /**
   * ASSET_GROUP_LISTING_GROUP_FILTER_TRANSACTION_FAILURE - The request contains interdependent AssetGroupListingGroupFilter
   * operations that are treated atomically as a single transaction, and one
   * or more of the operations in that transaction failed, which caused the
   * entire transaction, and therefore this mutate operation, to fail. The
   * operations that caused the transaction to fail can be found in the
   * consecutive AssetGroupListingGroupFilter results with the same asset
   * group id. The mutate operation will be successful once the remaining
   * errors in the transaction are fixed.
   */
  ASSET_GROUP_LISTING_GROUP_FILTER_TRANSACTION_FAILURE = 10,
  /**
   * REQUEST_TOO_LARGE - The AddBatchJobOperationsRequest is too large. Split the request into
   * smaller requests. The maximum allowed request size is 10484504 bytes.
   */
  REQUEST_TOO_LARGE = 11,
  UNRECOGNIZED = -1,
}

export function batchJobErrorEnum_BatchJobErrorFromJSON(object: any): BatchJobErrorEnum_BatchJobError {
  switch (object) {
    case 0:
    case "UNSPECIFIED":
      return BatchJobErrorEnum_BatchJobError.UNSPECIFIED;
    case 1:
    case "UNKNOWN":
      return BatchJobErrorEnum_BatchJobError.UNKNOWN;
    case 2:
    case "CANNOT_MODIFY_JOB_AFTER_JOB_STARTS_RUNNING":
      return BatchJobErrorEnum_BatchJobError.CANNOT_MODIFY_JOB_AFTER_JOB_STARTS_RUNNING;
    case 3:
    case "EMPTY_OPERATIONS":
      return BatchJobErrorEnum_BatchJobError.EMPTY_OPERATIONS;
    case 4:
    case "INVALID_SEQUENCE_TOKEN":
      return BatchJobErrorEnum_BatchJobError.INVALID_SEQUENCE_TOKEN;
    case 5:
    case "RESULTS_NOT_READY":
      return BatchJobErrorEnum_BatchJobError.RESULTS_NOT_READY;
    case 6:
    case "INVALID_PAGE_SIZE":
      return BatchJobErrorEnum_BatchJobError.INVALID_PAGE_SIZE;
    case 7:
    case "CAN_ONLY_REMOVE_PENDING_JOB":
      return BatchJobErrorEnum_BatchJobError.CAN_ONLY_REMOVE_PENDING_JOB;
    case 8:
    case "CANNOT_LIST_RESULTS":
      return BatchJobErrorEnum_BatchJobError.CANNOT_LIST_RESULTS;
    case 9:
    case "ASSET_GROUP_AND_ASSET_GROUP_ASSET_TRANSACTION_FAILURE":
      return BatchJobErrorEnum_BatchJobError.ASSET_GROUP_AND_ASSET_GROUP_ASSET_TRANSACTION_FAILURE;
    case 10:
    case "ASSET_GROUP_LISTING_GROUP_FILTER_TRANSACTION_FAILURE":
      return BatchJobErrorEnum_BatchJobError.ASSET_GROUP_LISTING_GROUP_FILTER_TRANSACTION_FAILURE;
    case 11:
    case "REQUEST_TOO_LARGE":
      return BatchJobErrorEnum_BatchJobError.REQUEST_TOO_LARGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BatchJobErrorEnum_BatchJobError.UNRECOGNIZED;
  }
}

export function batchJobErrorEnum_BatchJobErrorToJSON(object: BatchJobErrorEnum_BatchJobError): string {
  switch (object) {
    case BatchJobErrorEnum_BatchJobError.UNSPECIFIED:
      return "UNSPECIFIED";
    case BatchJobErrorEnum_BatchJobError.UNKNOWN:
      return "UNKNOWN";
    case BatchJobErrorEnum_BatchJobError.CANNOT_MODIFY_JOB_AFTER_JOB_STARTS_RUNNING:
      return "CANNOT_MODIFY_JOB_AFTER_JOB_STARTS_RUNNING";
    case BatchJobErrorEnum_BatchJobError.EMPTY_OPERATIONS:
      return "EMPTY_OPERATIONS";
    case BatchJobErrorEnum_BatchJobError.INVALID_SEQUENCE_TOKEN:
      return "INVALID_SEQUENCE_TOKEN";
    case BatchJobErrorEnum_BatchJobError.RESULTS_NOT_READY:
      return "RESULTS_NOT_READY";
    case BatchJobErrorEnum_BatchJobError.INVALID_PAGE_SIZE:
      return "INVALID_PAGE_SIZE";
    case BatchJobErrorEnum_BatchJobError.CAN_ONLY_REMOVE_PENDING_JOB:
      return "CAN_ONLY_REMOVE_PENDING_JOB";
    case BatchJobErrorEnum_BatchJobError.CANNOT_LIST_RESULTS:
      return "CANNOT_LIST_RESULTS";
    case BatchJobErrorEnum_BatchJobError.ASSET_GROUP_AND_ASSET_GROUP_ASSET_TRANSACTION_FAILURE:
      return "ASSET_GROUP_AND_ASSET_GROUP_ASSET_TRANSACTION_FAILURE";
    case BatchJobErrorEnum_BatchJobError.ASSET_GROUP_LISTING_GROUP_FILTER_TRANSACTION_FAILURE:
      return "ASSET_GROUP_LISTING_GROUP_FILTER_TRANSACTION_FAILURE";
    case BatchJobErrorEnum_BatchJobError.REQUEST_TOO_LARGE:
      return "REQUEST_TOO_LARGE";
    case BatchJobErrorEnum_BatchJobError.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseBatchJobErrorEnum(): BatchJobErrorEnum {
  return {};
}

export const BatchJobErrorEnum: MessageFns<BatchJobErrorEnum> = {
  encode(_: BatchJobErrorEnum, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchJobErrorEnum {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchJobErrorEnum();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): BatchJobErrorEnum {
    return {};
  },

  toJSON(_: BatchJobErrorEnum): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<BatchJobErrorEnum>): BatchJobErrorEnum {
    return BatchJobErrorEnum.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<BatchJobErrorEnum>): BatchJobErrorEnum {
    const message = createBaseBatchJobErrorEnum();
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
