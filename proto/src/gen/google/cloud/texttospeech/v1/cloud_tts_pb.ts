// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/texttospeech/v1/cloud_tts.proto (package google.cloud.texttospeech.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/texttospeech/v1/cloud_tts.proto.
 */
export const file_google_cloud_texttospeech_v1_cloud_tts: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource]);

/**
 * The top-level message sent by the client for the `ListVoices` method.
 *
 * @generated from message google.cloud.texttospeech.v1.ListVoicesRequest
 */
export type ListVoicesRequest = Message<"google.cloud.texttospeech.v1.ListVoicesRequest"> & {
  /**
   * Optional. Recommended.
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
   * If not specified, the API will return all supported voices.
   * If specified, the ListVoices call will only return voices that can be used
   * to synthesize this language_code. For example, if you specify `"en-NZ"`,
   * all `"en-NZ"` voices will be returned. If you specify `"no"`, both
   * `"no-\*"` (Norwegian) and `"nb-\*"` (Norwegian Bokmal) voices will be
   * returned.
   *
   * @generated from field: string language_code = 1;
   */
  languageCode: string;
};

/**
 * Describes the message google.cloud.texttospeech.v1.ListVoicesRequest.
 * Use `create(ListVoicesRequestSchema)` to create a new message.
 */
export const ListVoicesRequestSchema: GenMessage<ListVoicesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 0);

/**
 * The message returned to the client by the `ListVoices` method.
 *
 * @generated from message google.cloud.texttospeech.v1.ListVoicesResponse
 */
export type ListVoicesResponse = Message<"google.cloud.texttospeech.v1.ListVoicesResponse"> & {
  /**
   * The list of voices.
   *
   * @generated from field: repeated google.cloud.texttospeech.v1.Voice voices = 1;
   */
  voices: Voice[];
};

/**
 * Describes the message google.cloud.texttospeech.v1.ListVoicesResponse.
 * Use `create(ListVoicesResponseSchema)` to create a new message.
 */
export const ListVoicesResponseSchema: GenMessage<ListVoicesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 1);

/**
 * Description of a voice supported by the TTS service.
 *
 * @generated from message google.cloud.texttospeech.v1.Voice
 */
export type Voice = Message<"google.cloud.texttospeech.v1.Voice"> & {
  /**
   * The languages that this voice supports, expressed as
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tags (e.g.
   * "en-US", "es-419", "cmn-tw").
   *
   * @generated from field: repeated string language_codes = 1;
   */
  languageCodes: string[];

  /**
   * The name of this voice.  Each distinct voice has a unique name.
   *
   * @generated from field: string name = 2;
   */
  name: string;

  /**
   * The gender of this voice.
   *
   * @generated from field: google.cloud.texttospeech.v1.SsmlVoiceGender ssml_gender = 3;
   */
  ssmlGender: SsmlVoiceGender;

  /**
   * The natural sample rate (in hertz) for this voice.
   *
   * @generated from field: int32 natural_sample_rate_hertz = 4;
   */
  naturalSampleRateHertz: number;
};

/**
 * Describes the message google.cloud.texttospeech.v1.Voice.
 * Use `create(VoiceSchema)` to create a new message.
 */
export const VoiceSchema: GenMessage<Voice> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 2);

/**
 * The top-level message sent by the client for the `SynthesizeSpeech` method.
 *
 * @generated from message google.cloud.texttospeech.v1.SynthesizeSpeechRequest
 */
export type SynthesizeSpeechRequest = Message<"google.cloud.texttospeech.v1.SynthesizeSpeechRequest"> & {
  /**
   * Required. The Synthesizer requires either plain text or SSML as input.
   *
   * @generated from field: google.cloud.texttospeech.v1.SynthesisInput input = 1;
   */
  input?: SynthesisInput;

  /**
   * Required. The desired voice of the synthesized audio.
   *
   * @generated from field: google.cloud.texttospeech.v1.VoiceSelectionParams voice = 2;
   */
  voice?: VoiceSelectionParams;

  /**
   * Required. The configuration of the synthesized audio.
   *
   * @generated from field: google.cloud.texttospeech.v1.AudioConfig audio_config = 3;
   */
  audioConfig?: AudioConfig;
};

/**
 * Describes the message google.cloud.texttospeech.v1.SynthesizeSpeechRequest.
 * Use `create(SynthesizeSpeechRequestSchema)` to create a new message.
 */
export const SynthesizeSpeechRequestSchema: GenMessage<SynthesizeSpeechRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 3);

/**
 * Contains text input to be synthesized. Either `text` or `ssml` must be
 * supplied. Supplying both or neither returns
 * [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. The
 * input size is limited to 5000 bytes.
 *
 * @generated from message google.cloud.texttospeech.v1.SynthesisInput
 */
export type SynthesisInput = Message<"google.cloud.texttospeech.v1.SynthesisInput"> & {
  /**
   * The input source, which is either plain text or SSML.
   *
   * @generated from oneof google.cloud.texttospeech.v1.SynthesisInput.input_source
   */
  inputSource: {
    /**
     * The raw text to be synthesized.
     *
     * @generated from field: string text = 1;
     */
    value: string;
    case: "text";
  } | {
    /**
     * The SSML document to be synthesized. The SSML document must be valid
     * and well-formed. Otherwise the RPC will fail and return
     * [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. For
     * more information, see
     * [SSML](https://cloud.google.com/text-to-speech/docs/ssml).
     *
     * @generated from field: string ssml = 2;
     */
    value: string;
    case: "ssml";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.texttospeech.v1.SynthesisInput.
 * Use `create(SynthesisInputSchema)` to create a new message.
 */
export const SynthesisInputSchema: GenMessage<SynthesisInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 4);

/**
 * Description of which voice to use for a synthesis request.
 *
 * @generated from message google.cloud.texttospeech.v1.VoiceSelectionParams
 */
export type VoiceSelectionParams = Message<"google.cloud.texttospeech.v1.VoiceSelectionParams"> & {
  /**
   * Required. The language (and potentially also the region) of the voice
   * expressed as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag, e.g. "en-US". This should not include a script tag (e.g. use
   * "cmn-cn" rather than "cmn-Hant-cn"), because the script will be inferred
   * from the input provided in the SynthesisInput.  The TTS service
   * will use this parameter to help choose an appropriate voice.  Note that
   * the TTS service may choose a voice with a slightly different language code
   * than the one selected; it may substitute a different region
   * (e.g. using en-US rather than en-CA if there isn't a Canadian voice
   * available), or even a different language, e.g. using "nb" (Norwegian
   * Bokmal) instead of "no" (Norwegian)".
   *
   * @generated from field: string language_code = 1;
   */
  languageCode: string;

  /**
   * The name of the voice. If both the name and the gender are not set,
   * the service will choose a voice based on the other parameters such as
   * language_code.
   *
   * @generated from field: string name = 2;
   */
  name: string;

  /**
   * The preferred gender of the voice. If not set, the service will
   * choose a voice based on the other parameters such as language_code and
   * name. Note that this is only a preference, not requirement; if a
   * voice of the appropriate gender is not available, the synthesizer should
   * substitute a voice with a different gender rather than failing the request.
   *
   * @generated from field: google.cloud.texttospeech.v1.SsmlVoiceGender ssml_gender = 3;
   */
  ssmlGender: SsmlVoiceGender;

  /**
   * The configuration for a custom voice. If [CustomVoiceParams.model] is set,
   * the service will choose the custom voice matching the specified
   * configuration.
   *
   * @generated from field: google.cloud.texttospeech.v1.CustomVoiceParams custom_voice = 4;
   */
  customVoice?: CustomVoiceParams;
};

/**
 * Describes the message google.cloud.texttospeech.v1.VoiceSelectionParams.
 * Use `create(VoiceSelectionParamsSchema)` to create a new message.
 */
export const VoiceSelectionParamsSchema: GenMessage<VoiceSelectionParams> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 5);

/**
 * Description of audio data to be synthesized.
 *
 * @generated from message google.cloud.texttospeech.v1.AudioConfig
 */
export type AudioConfig = Message<"google.cloud.texttospeech.v1.AudioConfig"> & {
  /**
   * Required. The format of the audio byte stream.
   *
   * @generated from field: google.cloud.texttospeech.v1.AudioEncoding audio_encoding = 1;
   */
  audioEncoding: AudioEncoding;

  /**
   * Optional. Input only. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is
   * the normal native speed supported by the specific voice. 2.0 is twice as
   * fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
   * speed. Any other values < 0.25 or > 4.0 will return an error.
   *
   * @generated from field: double speaking_rate = 2;
   */
  speakingRate: number;

  /**
   * Optional. Input only. Speaking pitch, in the range [-20.0, 20.0]. 20 means
   * increase 20 semitones from the original pitch. -20 means decrease 20
   * semitones from the original pitch.
   *
   * @generated from field: double pitch = 3;
   */
  pitch: number;

  /**
   * Optional. Input only. Volume gain (in dB) of the normal native volume
   * supported by the specific voice, in the range [-96.0, 16.0]. If unset, or
   * set to a value of 0.0 (dB), will play at normal native signal amplitude. A
   * value of -6.0 (dB) will play at approximately half the amplitude of the
   * normal native signal amplitude. A value of +6.0 (dB) will play at
   * approximately twice the amplitude of the normal native signal amplitude.
   * Strongly recommend not to exceed +10 (dB) as there's usually no effective
   * increase in loudness for any value greater than that.
   *
   * @generated from field: double volume_gain_db = 4;
   */
  volumeGainDb: number;

  /**
   * Optional. The synthesis sample rate (in hertz) for this audio. When this is
   * specified in SynthesizeSpeechRequest, if this is different from the voice's
   * natural sample rate, then the synthesizer will honor this request by
   * converting to the desired sample rate (which might result in worse audio
   * quality), unless the specified sample rate is not supported for the
   * encoding chosen, in which case it will fail the request and return
   * [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
   *
   * @generated from field: int32 sample_rate_hertz = 5;
   */
  sampleRateHertz: number;

  /**
   * Optional. Input only. An identifier which selects 'audio effects' profiles
   * that are applied on (post synthesized) text to speech. Effects are applied
   * on top of each other in the order they are given. See
   * [audio
   * profiles](https://cloud.google.com/text-to-speech/docs/audio-profiles) for
   * current supported profile ids.
   *
   * @generated from field: repeated string effects_profile_id = 6;
   */
  effectsProfileId: string[];
};

/**
 * Describes the message google.cloud.texttospeech.v1.AudioConfig.
 * Use `create(AudioConfigSchema)` to create a new message.
 */
export const AudioConfigSchema: GenMessage<AudioConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 6);

/**
 * Description of the custom voice to be synthesized.
 *
 * @generated from message google.cloud.texttospeech.v1.CustomVoiceParams
 */
export type CustomVoiceParams = Message<"google.cloud.texttospeech.v1.CustomVoiceParams"> & {
  /**
   * Required. The name of the AutoML model that synthesizes the custom voice.
   *
   * @generated from field: string model = 1;
   */
  model: string;

  /**
   * Optional. Deprecated. The usage of the synthesized audio to be reported.
   *
   * @generated from field: google.cloud.texttospeech.v1.CustomVoiceParams.ReportedUsage reported_usage = 3 [deprecated = true];
   * @deprecated
   */
  reportedUsage: CustomVoiceParams_ReportedUsage;
};

/**
 * Describes the message google.cloud.texttospeech.v1.CustomVoiceParams.
 * Use `create(CustomVoiceParamsSchema)` to create a new message.
 */
export const CustomVoiceParamsSchema: GenMessage<CustomVoiceParams> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 7);

/**
 * Deprecated. The usage of the synthesized audio. Usage does not affect
 * billing.
 *
 * @generated from enum google.cloud.texttospeech.v1.CustomVoiceParams.ReportedUsage
 */
export enum CustomVoiceParams_ReportedUsage {
  /**
   * Request with reported usage unspecified will be rejected.
   *
   * @generated from enum value: REPORTED_USAGE_UNSPECIFIED = 0;
   */
  REPORTED_USAGE_UNSPECIFIED = 0,

  /**
   * For scenarios where the synthesized audio is not downloadable and can
   * only be used once. For example, real-time request in IVR system.
   *
   * @generated from enum value: REALTIME = 1;
   */
  REALTIME = 1,

  /**
   * For scenarios where the synthesized audio is downloadable and can be
   * reused. For example, the synthesized audio is downloaded, stored in
   * customer service system and played repeatedly.
   *
   * @generated from enum value: OFFLINE = 2;
   */
  OFFLINE = 2,
}

/**
 * Describes the enum google.cloud.texttospeech.v1.CustomVoiceParams.ReportedUsage.
 */
export const CustomVoiceParams_ReportedUsageSchema: GenEnum<CustomVoiceParams_ReportedUsage> = /*@__PURE__*/
  enumDesc(file_google_cloud_texttospeech_v1_cloud_tts, 7, 0);

/**
 * The message returned to the client by the `SynthesizeSpeech` method.
 *
 * @generated from message google.cloud.texttospeech.v1.SynthesizeSpeechResponse
 */
export type SynthesizeSpeechResponse = Message<"google.cloud.texttospeech.v1.SynthesizeSpeechResponse"> & {
  /**
   * The audio data bytes encoded as specified in the request, including the
   * header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS).
   * For LINEAR16 audio, we include the WAV header. Note: as
   * with all bytes fields, protobuffers use a pure binary representation,
   * whereas JSON representations use base64.
   *
   * @generated from field: bytes audio_content = 1;
   */
  audioContent: Uint8Array;
};

/**
 * Describes the message google.cloud.texttospeech.v1.SynthesizeSpeechResponse.
 * Use `create(SynthesizeSpeechResponseSchema)` to create a new message.
 */
export const SynthesizeSpeechResponseSchema: GenMessage<SynthesizeSpeechResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 8);

/**
 * Provides configuration information for the StreamingSynthesize request.
 *
 * @generated from message google.cloud.texttospeech.v1.StreamingSynthesizeConfig
 */
export type StreamingSynthesizeConfig = Message<"google.cloud.texttospeech.v1.StreamingSynthesizeConfig"> & {
  /**
   * Required. The desired voice of the synthesized audio.
   *
   * @generated from field: google.cloud.texttospeech.v1.VoiceSelectionParams voice = 1;
   */
  voice?: VoiceSelectionParams;
};

/**
 * Describes the message google.cloud.texttospeech.v1.StreamingSynthesizeConfig.
 * Use `create(StreamingSynthesizeConfigSchema)` to create a new message.
 */
export const StreamingSynthesizeConfigSchema: GenMessage<StreamingSynthesizeConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 9);

/**
 * Input to be synthesized.
 *
 * @generated from message google.cloud.texttospeech.v1.StreamingSynthesisInput
 */
export type StreamingSynthesisInput = Message<"google.cloud.texttospeech.v1.StreamingSynthesisInput"> & {
  /**
   * @generated from oneof google.cloud.texttospeech.v1.StreamingSynthesisInput.input_source
   */
  inputSource: {
    /**
     * The raw text to be synthesized. It is recommended that each input
     * contains complete, terminating sentences, as this will likely result in
     * better prosody in the output audio. That being said, users are free to
     * input text however they please.
     *
     * @generated from field: string text = 1;
     */
    value: string;
    case: "text";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.texttospeech.v1.StreamingSynthesisInput.
 * Use `create(StreamingSynthesisInputSchema)` to create a new message.
 */
export const StreamingSynthesisInputSchema: GenMessage<StreamingSynthesisInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 10);

/**
 * Request message for the `StreamingSynthesize` method. Multiple
 * `StreamingSynthesizeRequest` messages are sent in one call.
 * The first message must contain a `streaming_config` that
 * fully specifies the request configuration and must not contain `input`. All
 * subsequent messages must only have `input` set.
 *
 * @generated from message google.cloud.texttospeech.v1.StreamingSynthesizeRequest
 */
export type StreamingSynthesizeRequest = Message<"google.cloud.texttospeech.v1.StreamingSynthesizeRequest"> & {
  /**
   * The request to be sent, either a StreamingSynthesizeConfig or
   * StreamingSynthesisInput.
   *
   * @generated from oneof google.cloud.texttospeech.v1.StreamingSynthesizeRequest.streaming_request
   */
  streamingRequest: {
    /**
     * StreamingSynthesizeConfig to be used in this streaming attempt. Only
     * specified in the first message sent in a `StreamingSynthesize` call.
     *
     * @generated from field: google.cloud.texttospeech.v1.StreamingSynthesizeConfig streaming_config = 1;
     */
    value: StreamingSynthesizeConfig;
    case: "streamingConfig";
  } | {
    /**
     * Input to synthesize. Specified in all messages but the first in a
     * `StreamingSynthesize` call.
     *
     * @generated from field: google.cloud.texttospeech.v1.StreamingSynthesisInput input = 2;
     */
    value: StreamingSynthesisInput;
    case: "input";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.texttospeech.v1.StreamingSynthesizeRequest.
 * Use `create(StreamingSynthesizeRequestSchema)` to create a new message.
 */
export const StreamingSynthesizeRequestSchema: GenMessage<StreamingSynthesizeRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 11);

/**
 * `StreamingSynthesizeResponse` is the only message returned to the
 * client by `StreamingSynthesize` method. A series of zero or more
 * `StreamingSynthesizeResponse` messages are streamed back to the client.
 *
 * @generated from message google.cloud.texttospeech.v1.StreamingSynthesizeResponse
 */
export type StreamingSynthesizeResponse = Message<"google.cloud.texttospeech.v1.StreamingSynthesizeResponse"> & {
  /**
   * The audio data bytes encoded as specified in the request. This is
   * headerless LINEAR16 audio with a sample rate of 24000.
   *
   * @generated from field: bytes audio_content = 1;
   */
  audioContent: Uint8Array;
};

/**
 * Describes the message google.cloud.texttospeech.v1.StreamingSynthesizeResponse.
 * Use `create(StreamingSynthesizeResponseSchema)` to create a new message.
 */
export const StreamingSynthesizeResponseSchema: GenMessage<StreamingSynthesizeResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_texttospeech_v1_cloud_tts, 12);

/**
 * Gender of the voice as described in
 * [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
 *
 * @generated from enum google.cloud.texttospeech.v1.SsmlVoiceGender
 */
export enum SsmlVoiceGender {
  /**
   * An unspecified gender.
   * In VoiceSelectionParams, this means that the client doesn't care which
   * gender the selected voice will have. In the Voice field of
   * ListVoicesResponse, this may mean that the voice doesn't fit any of the
   * other categories in this enum, or that the gender of the voice isn't known.
   *
   * @generated from enum value: SSML_VOICE_GENDER_UNSPECIFIED = 0;
   */
  SSML_VOICE_GENDER_UNSPECIFIED = 0,

  /**
   * A male voice.
   *
   * @generated from enum value: MALE = 1;
   */
  MALE = 1,

  /**
   * A female voice.
   *
   * @generated from enum value: FEMALE = 2;
   */
  FEMALE = 2,

  /**
   * A gender-neutral voice. This voice is not yet supported.
   *
   * @generated from enum value: NEUTRAL = 3;
   */
  NEUTRAL = 3,
}

/**
 * Describes the enum google.cloud.texttospeech.v1.SsmlVoiceGender.
 */
export const SsmlVoiceGenderSchema: GenEnum<SsmlVoiceGender> = /*@__PURE__*/
  enumDesc(file_google_cloud_texttospeech_v1_cloud_tts, 0);

/**
 * Configuration to set up audio encoder. The encoding determines the output
 * audio format that we'd like.
 *
 * @generated from enum google.cloud.texttospeech.v1.AudioEncoding
 */
export enum AudioEncoding {
  /**
   * Not specified. Will return result
   * [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
   *
   * @generated from enum value: AUDIO_ENCODING_UNSPECIFIED = 0;
   */
  AUDIO_ENCODING_UNSPECIFIED = 0,

  /**
   * Uncompressed 16-bit signed little-endian samples (Linear PCM).
   * Audio content returned as LINEAR16 also contains a WAV header.
   *
   * @generated from enum value: LINEAR16 = 1;
   */
  LINEAR16 = 1,

  /**
   * MP3 audio at 32kbps.
   *
   * @generated from enum value: MP3 = 2;
   */
  MP3 = 2,

  /**
   * Opus encoded audio wrapped in an ogg container. The result will be a
   * file which can be played natively on Android, and in browsers (at least
   * Chrome and Firefox). The quality of the encoding is considerably higher
   * than MP3 while using approximately the same bitrate.
   *
   * @generated from enum value: OGG_OPUS = 3;
   */
  OGG_OPUS = 3,

  /**
   * 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
   * Audio content returned as MULAW also contains a WAV header.
   *
   * @generated from enum value: MULAW = 5;
   */
  MULAW = 5,

  /**
   * 8-bit samples that compand 14-bit audio samples using G.711 PCMU/A-law.
   * Audio content returned as ALAW also contains a WAV header.
   *
   * @generated from enum value: ALAW = 6;
   */
  ALAW = 6,
}

/**
 * Describes the enum google.cloud.texttospeech.v1.AudioEncoding.
 */
export const AudioEncodingSchema: GenEnum<AudioEncoding> = /*@__PURE__*/
  enumDesc(file_google_cloud_texttospeech_v1_cloud_tts, 1);

/**
 * Service that implements Google Cloud Text-to-Speech API.
 *
 * @generated from service google.cloud.texttospeech.v1.TextToSpeech
 */
export const TextToSpeech: GenService<{
  /**
   * Returns a list of Voice supported for synthesis.
   *
   * @generated from rpc google.cloud.texttospeech.v1.TextToSpeech.ListVoices
   */
  listVoices: {
    methodKind: "unary";
    input: typeof ListVoicesRequestSchema;
    output: typeof ListVoicesResponseSchema;
  },
  /**
   * Synthesizes speech synchronously: receive results after all text input
   * has been processed.
   *
   * @generated from rpc google.cloud.texttospeech.v1.TextToSpeech.SynthesizeSpeech
   */
  synthesizeSpeech: {
    methodKind: "unary";
    input: typeof SynthesizeSpeechRequestSchema;
    output: typeof SynthesizeSpeechResponseSchema;
  },
  /**
   * Performs bidirectional streaming speech synthesis: receive audio while
   * sending text.
   *
   * @generated from rpc google.cloud.texttospeech.v1.TextToSpeech.StreamingSynthesize
   */
  streamingSynthesize: {
    methodKind: "bidi_streaming";
    input: typeof StreamingSynthesizeRequestSchema;
    output: typeof StreamingSynthesizeResponseSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_texttospeech_v1_cloud_tts, 0);

