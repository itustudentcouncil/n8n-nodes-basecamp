// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/dialogflow/v2/participant.proto (package google.cloud.dialogflow.v2, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { InputAudioConfig, OutputAudioConfig, TelephonyDtmfEvents } from "./audio_config_pb";
import { file_google_cloud_dialogflow_v2_audio_config } from "./audio_config_pb";
import type { CloudConversationDebuggingInfo, DetectIntentResponse, EventInput, QueryParameters, QueryResult, SentimentAnalysisResult, StreamingRecognitionResult, TextInput } from "./session_pb";
import { file_google_cloud_dialogflow_v2_session } from "./session_pb";
import type { FieldMask, Timestamp, Value } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_field_mask, file_google_protobuf_struct, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../rpc/status_pb";
import type { JsonObject, Message as Message$1 } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/dialogflow/v2/participant.proto.
 */
export const file_google_cloud_dialogflow_v2_participant: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_cloud_dialogflow_v2_audio_config, file_google_cloud_dialogflow_v2_session, file_google_protobuf_field_mask, file_google_protobuf_struct, file_google_protobuf_timestamp, file_google_rpc_status]);

/**
 * Represents a conversation participant (human agent, virtual agent, end-user).
 *
 * @generated from message google.cloud.dialogflow.v2.Participant
 */
export type Participant = Message$1<"google.cloud.dialogflow.v2.Participant"> & {
  /**
   * Optional. The unique identifier of this participant.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Immutable. The role this participant plays in the conversation. This field
   * must be set during participant creation and is then immutable.
   *
   * @generated from field: google.cloud.dialogflow.v2.Participant.Role role = 2;
   */
  role: Participant_Role;

  /**
   * Optional. Label applied to streams representing this participant in SIPREC
   * XML metadata and SDP. This is used to assign transcriptions from that
   * media stream to this participant. This field can be updated.
   *
   * @generated from field: string sip_recording_media_label = 6;
   */
  sipRecordingMediaLabel: string;

  /**
   * Optional. Obfuscated user id that should be associated with the created
   * participant.
   *
   * You can specify a user id as follows:
   *
   * 1. If you set this field in
   *    [CreateParticipantRequest][google.cloud.dialogflow.v2.CreateParticipantRequest.participant]
   *    or
   *    [UpdateParticipantRequest][google.cloud.dialogflow.v2.UpdateParticipantRequest.participant],
   *    Dialogflow adds the obfuscated user id with the participant.
   *
   * 2. If you set this field in
   *    [AnalyzeContent][google.cloud.dialogflow.v2.AnalyzeContentRequest.obfuscated_external_user_id]
   *    or
   *    [StreamingAnalyzeContent][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.obfuscated_external_user_id],
   *    Dialogflow will update
   *    [Participant.obfuscated_external_user_id][google.cloud.dialogflow.v2.Participant.obfuscated_external_user_id].
   *
   * Dialogflow returns an error if you try to add a user id for a
   * non-[END_USER][google.cloud.dialogflow.v2.Participant.Role.END_USER]
   * participant.
   *
   * Dialogflow uses this user id for billing and measurement purposes. For
   * example, Dialogflow determines whether a user in one conversation returned
   * in a later conversation.
   *
   * Note:
   *
   * * Please never pass raw user ids to Dialogflow. Always obfuscate your user
   *   id first.
   * * Dialogflow only accepts a UTF-8 encoded string, e.g., a hex digest of a
   *   hash function like SHA-512.
   * * The length of the user id must be <= 256 characters.
   *
   * @generated from field: string obfuscated_external_user_id = 7;
   */
  obfuscatedExternalUserId: string;

  /**
   * Optional. Key-value filters on the metadata of documents returned by
   * article suggestion. If specified, article suggestion only returns suggested
   * documents that match all filters in their
   * [Document.metadata][google.cloud.dialogflow.v2.Document.metadata]. Multiple
   * values for a metadata key should be concatenated by comma. For example,
   * filters to match all documents that have 'US' or 'CA' in their market
   * metadata values and 'agent' in their user metadata values will be
   * ```
   * documents_metadata_filters {
   *   key: "market"
   *   value: "US,CA"
   * }
   * documents_metadata_filters {
   *   key: "user"
   *   value: "agent"
   * }
   * ```
   *
   * @generated from field: map<string, string> documents_metadata_filters = 8;
   */
  documentsMetadataFilters: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dialogflow.v2.Participant.
 * Use `create(ParticipantSchema)` to create a new message.
 */
export const ParticipantSchema: GenMessage<Participant> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 0);

/**
 * Enumeration of the roles a participant can play in a conversation.
 *
 * @generated from enum google.cloud.dialogflow.v2.Participant.Role
 */
export enum Participant_Role {
  /**
   * Participant role not set.
   *
   * @generated from enum value: ROLE_UNSPECIFIED = 0;
   */
  ROLE_UNSPECIFIED = 0,

  /**
   * Participant is a human agent.
   *
   * @generated from enum value: HUMAN_AGENT = 1;
   */
  HUMAN_AGENT = 1,

  /**
   * Participant is an automated agent, such as a Dialogflow agent.
   *
   * @generated from enum value: AUTOMATED_AGENT = 2;
   */
  AUTOMATED_AGENT = 2,

  /**
   * Participant is an end user that has called or chatted with
   * Dialogflow services.
   *
   * @generated from enum value: END_USER = 3;
   */
  END_USER = 3,
}

/**
 * Describes the enum google.cloud.dialogflow.v2.Participant.Role.
 */
export const Participant_RoleSchema: GenEnum<Participant_Role> = /*@__PURE__*/
  enumDesc(file_google_cloud_dialogflow_v2_participant, 0, 0);

/**
 * Represents a message posted into a conversation.
 *
 * @generated from message google.cloud.dialogflow.v2.Message
 */
export type Message = Message$1<"google.cloud.dialogflow.v2.Message"> & {
  /**
   * Optional. The unique identifier of the message.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The message content.
   *
   * @generated from field: string content = 2;
   */
  content: string;

  /**
   * Optional. The message language.
   * This should be a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag. Example: "en-US".
   *
   * @generated from field: string language_code = 3;
   */
  languageCode: string;

  /**
   * Output only. The participant that sends this message.
   *
   * @generated from field: string participant = 4;
   */
  participant: string;

  /**
   * Output only. The role of the participant.
   *
   * @generated from field: google.cloud.dialogflow.v2.Participant.Role participant_role = 5;
   */
  participantRole: Participant_Role;

  /**
   * Output only. The time when the message was created in Contact Center AI.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 6;
   */
  createTime?: Timestamp;

  /**
   * Optional. The time when the message was sent.
   *
   * @generated from field: google.protobuf.Timestamp send_time = 9;
   */
  sendTime?: Timestamp;

  /**
   * Output only. The annotation for the message.
   *
   * @generated from field: google.cloud.dialogflow.v2.MessageAnnotation message_annotation = 7;
   */
  messageAnnotation?: MessageAnnotation;

  /**
   * Output only. The sentiment analysis result for the message.
   *
   * @generated from field: google.cloud.dialogflow.v2.SentimentAnalysisResult sentiment_analysis = 8;
   */
  sentimentAnalysis?: SentimentAnalysisResult;
};

/**
 * Describes the message google.cloud.dialogflow.v2.Message.
 * Use `create(MessageSchema)` to create a new message.
 */
export const MessageSchema: GenMessage<Message> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 1);

/**
 * The request message for
 * [Participants.CreateParticipant][google.cloud.dialogflow.v2.Participants.CreateParticipant].
 *
 * @generated from message google.cloud.dialogflow.v2.CreateParticipantRequest
 */
export type CreateParticipantRequest = Message$1<"google.cloud.dialogflow.v2.CreateParticipantRequest"> & {
  /**
   * Required. Resource identifier of the conversation adding the participant.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>`.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. The participant to create.
   *
   * @generated from field: google.cloud.dialogflow.v2.Participant participant = 2;
   */
  participant?: Participant;
};

/**
 * Describes the message google.cloud.dialogflow.v2.CreateParticipantRequest.
 * Use `create(CreateParticipantRequestSchema)` to create a new message.
 */
export const CreateParticipantRequestSchema: GenMessage<CreateParticipantRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 2);

/**
 * The request message for
 * [Participants.GetParticipant][google.cloud.dialogflow.v2.Participants.GetParticipant].
 *
 * @generated from message google.cloud.dialogflow.v2.GetParticipantRequest
 */
export type GetParticipantRequest = Message$1<"google.cloud.dialogflow.v2.GetParticipantRequest"> & {
  /**
   * Required. The name of the participant. Format:
   * `projects/<Project ID>/locations/<Location ID>/conversations/<Conversation
   * ID>/participants/<Participant ID>`.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.GetParticipantRequest.
 * Use `create(GetParticipantRequestSchema)` to create a new message.
 */
export const GetParticipantRequestSchema: GenMessage<GetParticipantRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 3);

/**
 * The request message for
 * [Participants.ListParticipants][google.cloud.dialogflow.v2.Participants.ListParticipants].
 *
 * @generated from message google.cloud.dialogflow.v2.ListParticipantsRequest
 */
export type ListParticipantsRequest = Message$1<"google.cloud.dialogflow.v2.ListParticipantsRequest"> & {
  /**
   * Required. The conversation to list all participants from.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>`.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Optional. The maximum number of items to return in a single page. By
   * default 100 and at most 1000.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * Optional. The next_page_token value returned from a previous list request.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.ListParticipantsRequest.
 * Use `create(ListParticipantsRequestSchema)` to create a new message.
 */
export const ListParticipantsRequestSchema: GenMessage<ListParticipantsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 4);

/**
 * The response message for
 * [Participants.ListParticipants][google.cloud.dialogflow.v2.Participants.ListParticipants].
 *
 * @generated from message google.cloud.dialogflow.v2.ListParticipantsResponse
 */
export type ListParticipantsResponse = Message$1<"google.cloud.dialogflow.v2.ListParticipantsResponse"> & {
  /**
   * The list of participants. There is a maximum number of items
   * returned based on the page_size field in the request.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.Participant participants = 1;
   */
  participants: Participant[];

  /**
   * Token to retrieve the next page of results or empty if there are no
   * more results in the list.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.ListParticipantsResponse.
 * Use `create(ListParticipantsResponseSchema)` to create a new message.
 */
export const ListParticipantsResponseSchema: GenMessage<ListParticipantsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 5);

/**
 * The request message for
 * [Participants.UpdateParticipant][google.cloud.dialogflow.v2.Participants.UpdateParticipant].
 *
 * @generated from message google.cloud.dialogflow.v2.UpdateParticipantRequest
 */
export type UpdateParticipantRequest = Message$1<"google.cloud.dialogflow.v2.UpdateParticipantRequest"> & {
  /**
   * Required. The participant to update.
   *
   * @generated from field: google.cloud.dialogflow.v2.Participant participant = 1;
   */
  participant?: Participant;

  /**
   * Required. The mask to specify which fields to update.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 2;
   */
  updateMask?: FieldMask;
};

/**
 * Describes the message google.cloud.dialogflow.v2.UpdateParticipantRequest.
 * Use `create(UpdateParticipantRequestSchema)` to create a new message.
 */
export const UpdateParticipantRequestSchema: GenMessage<UpdateParticipantRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 6);

/**
 * The request message for
 * [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent].
 *
 * @generated from message google.cloud.dialogflow.v2.AnalyzeContentRequest
 */
export type AnalyzeContentRequest = Message$1<"google.cloud.dialogflow.v2.AnalyzeContentRequest"> & {
  /**
   * Required. The name of the participant this text comes from.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string participant = 1;
   */
  participant: string;

  /**
   * Required. The input content.
   *
   * @generated from oneof google.cloud.dialogflow.v2.AnalyzeContentRequest.input
   */
  input: {
    /**
     * The natural language text to be processed.
     *
     * @generated from field: google.cloud.dialogflow.v2.TextInput text_input = 6;
     */
    value: TextInput;
    case: "textInput";
  } | {
    /**
     * An input event to send to Dialogflow.
     *
     * @generated from field: google.cloud.dialogflow.v2.EventInput event_input = 8;
     */
    value: EventInput;
    case: "eventInput";
  } | {
    /**
     * An input representing the selection of a suggestion.
     *
     * @generated from field: google.cloud.dialogflow.v2.SuggestionInput suggestion_input = 12;
     */
    value: SuggestionInput;
    case: "suggestionInput";
  } | { case: undefined; value?: undefined };

  /**
   * Speech synthesis configuration.
   * The speech synthesis settings for a virtual agent that may be configured
   * for the associated conversation profile are not used when calling
   * AnalyzeContent. If this configuration is not supplied, speech synthesis
   * is disabled.
   *
   * @generated from field: google.cloud.dialogflow.v2.OutputAudioConfig reply_audio_config = 5;
   */
  replyAudioConfig?: OutputAudioConfig;

  /**
   * Parameters for a Dialogflow virtual-agent query.
   *
   * @generated from field: google.cloud.dialogflow.v2.QueryParameters query_params = 9;
   */
  queryParams?: QueryParameters;

  /**
   * Parameters for a human assist query.
   *
   * @generated from field: google.cloud.dialogflow.v2.AssistQueryParameters assist_query_params = 14;
   */
  assistQueryParams?: AssistQueryParameters;

  /**
   * Additional parameters to be put into Dialogflow CX session parameters. To
   * remove a parameter from the session, clients should explicitly set the
   * parameter value to null.
   *
   * Note: this field should only be used if you are connecting to a Dialogflow
   * CX agent.
   *
   * @generated from field: google.protobuf.Struct cx_parameters = 18;
   */
  cxParameters?: JsonObject;

  /**
   * A unique identifier for this request. Restricted to 36 ASCII characters.
   * A random UUID is recommended.
   * This request is only idempotent if a `request_id` is provided.
   *
   * @generated from field: string request_id = 11;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.AnalyzeContentRequest.
 * Use `create(AnalyzeContentRequestSchema)` to create a new message.
 */
export const AnalyzeContentRequestSchema: GenMessage<AnalyzeContentRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 7);

/**
 * The message in the response that indicates the parameters of DTMF.
 *
 * @generated from message google.cloud.dialogflow.v2.DtmfParameters
 */
export type DtmfParameters = Message$1<"google.cloud.dialogflow.v2.DtmfParameters"> & {
  /**
   * Indicates whether DTMF input can be handled in the next request.
   *
   * @generated from field: bool accepts_dtmf_input = 1;
   */
  acceptsDtmfInput: boolean;
};

/**
 * Describes the message google.cloud.dialogflow.v2.DtmfParameters.
 * Use `create(DtmfParametersSchema)` to create a new message.
 */
export const DtmfParametersSchema: GenMessage<DtmfParameters> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 8);

/**
 * The response message for
 * [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent].
 *
 * @generated from message google.cloud.dialogflow.v2.AnalyzeContentResponse
 */
export type AnalyzeContentResponse = Message$1<"google.cloud.dialogflow.v2.AnalyzeContentResponse"> & {
  /**
   * The output text content.
   * This field is set if the automated agent responded with text to show to
   * the user.
   *
   * @generated from field: string reply_text = 1;
   */
  replyText: string;

  /**
   * The audio data bytes encoded as specified in the request.
   * This field is set if:
   *
   *  - `reply_audio_config` was specified in the request, or
   *  - The automated agent responded with audio to play to the user. In such
   *    case, `reply_audio.config` contains settings used to synthesize the
   *    speech.
   *
   * In some scenarios, multiple output audio fields may be present in the
   * response structure. In these cases, only the top-most-level audio output
   * has content.
   *
   * @generated from field: google.cloud.dialogflow.v2.OutputAudio reply_audio = 2;
   */
  replyAudio?: OutputAudio;

  /**
   * Only set if a Dialogflow automated agent has responded.
   * Note that: [AutomatedAgentReply.detect_intent_response.output_audio][]
   * and [AutomatedAgentReply.detect_intent_response.output_audio_config][]
   * are always empty, use
   * [reply_audio][google.cloud.dialogflow.v2.AnalyzeContentResponse.reply_audio]
   * instead.
   *
   * @generated from field: google.cloud.dialogflow.v2.AutomatedAgentReply automated_agent_reply = 3;
   */
  automatedAgentReply?: AutomatedAgentReply;

  /**
   * Message analyzed by CCAI.
   *
   * @generated from field: google.cloud.dialogflow.v2.Message message = 5;
   */
  message?: Message;

  /**
   * The suggestions for most recent human agent. The order is the same as
   * [HumanAgentAssistantConfig.SuggestionConfig.feature_configs][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.SuggestionConfig.feature_configs]
   * of
   * [HumanAgentAssistantConfig.human_agent_suggestion_config][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.human_agent_suggestion_config].
   *
   * Note that any failure of Agent Assist features will not lead to the overall
   * failure of an AnalyzeContent API call. Instead, the features will
   * fail silently with the error field set in the corresponding
   * SuggestionResult.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.SuggestionResult human_agent_suggestion_results = 6;
   */
  humanAgentSuggestionResults: SuggestionResult[];

  /**
   * The suggestions for end user. The order is the same as
   * [HumanAgentAssistantConfig.SuggestionConfig.feature_configs][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.SuggestionConfig.feature_configs]
   * of
   * [HumanAgentAssistantConfig.end_user_suggestion_config][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.end_user_suggestion_config].
   *
   * Same as human_agent_suggestion_results, any failure of Agent Assist
   * features will not lead to the overall failure of an AnalyzeContent API
   * call. Instead, the features will fail silently with the error field set in
   * the corresponding SuggestionResult.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.SuggestionResult end_user_suggestion_results = 7;
   */
  endUserSuggestionResults: SuggestionResult[];

  /**
   * Indicates the parameters of DTMF.
   *
   * @generated from field: google.cloud.dialogflow.v2.DtmfParameters dtmf_parameters = 9;
   */
  dtmfParameters?: DtmfParameters;
};

/**
 * Describes the message google.cloud.dialogflow.v2.AnalyzeContentResponse.
 * Use `create(AnalyzeContentResponseSchema)` to create a new message.
 */
export const AnalyzeContentResponseSchema: GenMessage<AnalyzeContentResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 9);

/**
 * The top-level message sent by the client to the
 * [Participants.StreamingAnalyzeContent][google.cloud.dialogflow.v2.Participants.StreamingAnalyzeContent]
 * method.
 *
 * Multiple request messages should be sent in order:
 *
 * 1.  The first message must contain
 *     [participant][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.participant],
 *     [config][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.config]
 *     and optionally
 *     [query_params][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.query_params].
 *     If you want to receive an audio response, it should also contain
 *     [reply_audio_config][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.reply_audio_config].
 *     The message must not contain
 *     [input][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.input].
 *
 * 2.  If
 * [config][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.config] in
 * the first message
 *     was set to
 *     [audio_config][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.audio_config],
 *     all subsequent messages must contain
 *     [input_audio][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.input_audio]
 *     to continue with Speech recognition. However, note that:
 *
 *     * Dialogflow will bill you for the audio so far.
 *     * Dialogflow discards all Speech recognition results in favor of the
 *       text input.
 *
 *  3. If
 *  [StreamingAnalyzeContentRequest.config][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.config]
 *  in the first message was set
 *    to
 *    [StreamingAnalyzeContentRequest.text_config][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.text_config],
 *    then the second message must contain only
 *    [input_text][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.input_text].
 *    Moreover, you must not send more than two messages.
 *
 *  After you sent all input, you must half-close or abort the request stream.
 *
 * @generated from message google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest
 */
export type StreamingAnalyzeContentRequest = Message$1<"google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest"> & {
  /**
   * Required. The name of the participant this text comes from.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string participant = 1;
   */
  participant: string;

  /**
   * The input config.
   *
   * @generated from oneof google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.config
   */
  config: {
    /**
     * Instructs the speech recognizer how to process the speech audio.
     *
     * @generated from field: google.cloud.dialogflow.v2.InputAudioConfig audio_config = 2;
     */
    value: InputAudioConfig;
    case: "audioConfig";
  } | {
    /**
     * The natural language text to be processed.
     *
     * @generated from field: google.cloud.dialogflow.v2.InputTextConfig text_config = 3;
     */
    value: InputTextConfig;
    case: "textConfig";
  } | { case: undefined; value?: undefined };

  /**
   * Speech synthesis configuration.
   * The speech synthesis settings for a virtual agent that may be configured
   * for the associated conversation profile are not used when calling
   * StreamingAnalyzeContent. If this configuration is not supplied, speech
   * synthesis is disabled.
   *
   * @generated from field: google.cloud.dialogflow.v2.OutputAudioConfig reply_audio_config = 4;
   */
  replyAudioConfig?: OutputAudioConfig;

  /**
   * The input.
   *
   * @generated from oneof google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.input
   */
  input: {
    /**
     * The input audio content to be recognized. Must be sent if `audio_config`
     * is set in the first message. The complete audio over all streaming
     * messages must not exceed 1 minute.
     *
     * @generated from field: bytes input_audio = 5;
     */
    value: Uint8Array;
    case: "inputAudio";
  } | {
    /**
     * The UTF-8 encoded natural language text to be processed. Must be sent if
     * `text_config` is set in the first message. Text length must not exceed
     * 256 bytes for virtual agent interactions. The `input_text` field can be
     * only sent once, and would cancel the speech recognition if any ongoing.
     *
     * @generated from field: string input_text = 6;
     */
    value: string;
    case: "inputText";
  } | {
    /**
     * The DTMF digits used to invoke intent and fill in parameter value.
     *
     * This input is ignored if the previous response indicated that DTMF input
     * is not accepted.
     *
     * @generated from field: google.cloud.dialogflow.v2.TelephonyDtmfEvents input_dtmf = 9;
     */
    value: TelephonyDtmfEvents;
    case: "inputDtmf";
  } | { case: undefined; value?: undefined };

  /**
   * Parameters for a Dialogflow virtual-agent query.
   *
   * @generated from field: google.cloud.dialogflow.v2.QueryParameters query_params = 7;
   */
  queryParams?: QueryParameters;

  /**
   * Parameters for a human assist query.
   *
   * @generated from field: google.cloud.dialogflow.v2.AssistQueryParameters assist_query_params = 8;
   */
  assistQueryParams?: AssistQueryParameters;

  /**
   * Additional parameters to be put into Dialogflow CX session parameters. To
   * remove a parameter from the session, clients should explicitly set the
   * parameter value to null.
   *
   * Note: this field should only be used if you are connecting to a Dialogflow
   * CX agent.
   *
   * @generated from field: google.protobuf.Struct cx_parameters = 13;
   */
  cxParameters?: JsonObject;

  /**
   * Optional. Enable full bidirectional streaming. You can keep streaming the
   * audio until timeout, and there's no need to half close the stream to get
   * the response.
   *
   * Restrictions:
   *
   * - Timeout: 3 mins.
   * - Audio Encoding: only supports
   * [AudioEncoding.AUDIO_ENCODING_LINEAR_16][google.cloud.dialogflow.v2.AudioEncoding.AUDIO_ENCODING_LINEAR_16]
   * and
   * [AudioEncoding.AUDIO_ENCODING_MULAW][google.cloud.dialogflow.v2.AudioEncoding.AUDIO_ENCODING_MULAW]
   * - Lifecycle: conversation should be in `Assist Stage`, go to
   *   [Conversation.CreateConversation][] for more information.
   *
   * InvalidArgument Error will be returned if the one of restriction checks
   * failed.
   *
   * You can find more details in
   * https://cloud.google.com/agent-assist/docs/extended-streaming
   *
   * @generated from field: bool enable_extended_streaming = 11;
   */
  enableExtendedStreaming: boolean;

  /**
   * Enable partial virtual agent responses. If this flag is not enabled,
   * response stream still contains only one final response even if some
   * `Fulfillment`s in Dialogflow virtual agent have been configured to return
   * partial responses.
   *
   * @generated from field: bool enable_partial_automated_agent_reply = 12;
   */
  enablePartialAutomatedAgentReply: boolean;

  /**
   * If true, `StreamingAnalyzeContentResponse.debugging_info` will get
   * populated.
   *
   * @generated from field: bool enable_debugging_info = 19;
   */
  enableDebuggingInfo: boolean;
};

/**
 * Describes the message google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest.
 * Use `create(StreamingAnalyzeContentRequestSchema)` to create a new message.
 */
export const StreamingAnalyzeContentRequestSchema: GenMessage<StreamingAnalyzeContentRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 10);

/**
 * The top-level message returned from the `StreamingAnalyzeContent` method.
 *
 * Multiple response messages can be returned in order:
 *
 * 1.  If the input was set to streaming audio, the first one or more messages
 *     contain `recognition_result`. Each `recognition_result` represents a more
 *     complete transcript of what the user said. The last `recognition_result`
 *     has `is_final` set to `true`.
 *
 * 2.  In virtual agent stage: if `enable_partial_automated_agent_reply` is
 *     true, the following N (currently 1 <= N <= 4) messages
 *     contain `automated_agent_reply` and optionally `reply_audio`
 *     returned by the virtual agent. The first (N-1)
 *     `automated_agent_reply`s will have `automated_agent_reply_type` set to
 *     `PARTIAL`. The last `automated_agent_reply` has
 *     `automated_agent_reply_type` set to `FINAL`.
 *     If `enable_partial_automated_agent_reply` is not enabled, response stream
 *     only contains the final reply.
 *
 *     In human assist stage: the following N (N >= 1) messages contain
 *     `human_agent_suggestion_results`, `end_user_suggestion_results` or
 *     `message`.
 *
 * @generated from message google.cloud.dialogflow.v2.StreamingAnalyzeContentResponse
 */
export type StreamingAnalyzeContentResponse = Message$1<"google.cloud.dialogflow.v2.StreamingAnalyzeContentResponse"> & {
  /**
   * The result of speech recognition.
   *
   * @generated from field: google.cloud.dialogflow.v2.StreamingRecognitionResult recognition_result = 1;
   */
  recognitionResult?: StreamingRecognitionResult;

  /**
   * The output text content.
   * This field is set if an automated agent responded with a text for the user.
   *
   * @generated from field: string reply_text = 2;
   */
  replyText: string;

  /**
   * The audio data bytes encoded as specified in the request.
   * This field is set if:
   *
   *  - The `reply_audio_config` field is specified in the request.
   *  - The automated agent, which this output comes from, responded with audio.
   *    In such case, the `reply_audio.config` field contains settings used to
   *    synthesize the speech.
   *
   * In some scenarios, multiple output audio fields may be present in the
   * response structure. In these cases, only the top-most-level audio output
   * has content.
   *
   * @generated from field: google.cloud.dialogflow.v2.OutputAudio reply_audio = 3;
   */
  replyAudio?: OutputAudio;

  /**
   * Only set if a Dialogflow automated agent has responded.
   * Note that: [AutomatedAgentReply.detect_intent_response.output_audio][]
   * and [AutomatedAgentReply.detect_intent_response.output_audio_config][]
   * are always empty, use
   * [reply_audio][google.cloud.dialogflow.v2.StreamingAnalyzeContentResponse.reply_audio]
   * instead.
   *
   * @generated from field: google.cloud.dialogflow.v2.AutomatedAgentReply automated_agent_reply = 4;
   */
  automatedAgentReply?: AutomatedAgentReply;

  /**
   * Message analyzed by CCAI.
   *
   * @generated from field: google.cloud.dialogflow.v2.Message message = 6;
   */
  message?: Message;

  /**
   * The suggestions for most recent human agent. The order is the same as
   * [HumanAgentAssistantConfig.SuggestionConfig.feature_configs][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.SuggestionConfig.feature_configs]
   * of
   * [HumanAgentAssistantConfig.human_agent_suggestion_config][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.human_agent_suggestion_config].
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.SuggestionResult human_agent_suggestion_results = 7;
   */
  humanAgentSuggestionResults: SuggestionResult[];

  /**
   * The suggestions for end user. The order is the same as
   * [HumanAgentAssistantConfig.SuggestionConfig.feature_configs][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.SuggestionConfig.feature_configs]
   * of
   * [HumanAgentAssistantConfig.end_user_suggestion_config][google.cloud.dialogflow.v2.HumanAgentAssistantConfig.end_user_suggestion_config].
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.SuggestionResult end_user_suggestion_results = 8;
   */
  endUserSuggestionResults: SuggestionResult[];

  /**
   * Indicates the parameters of DTMF.
   *
   * @generated from field: google.cloud.dialogflow.v2.DtmfParameters dtmf_parameters = 10;
   */
  dtmfParameters?: DtmfParameters;

  /**
   * Debugging info that would get populated when
   * `StreamingAnalyzeContentRequest.enable_debugging_info` is set to true.
   *
   * @generated from field: google.cloud.dialogflow.v2.CloudConversationDebuggingInfo debugging_info = 11;
   */
  debuggingInfo?: CloudConversationDebuggingInfo;
};

/**
 * Describes the message google.cloud.dialogflow.v2.StreamingAnalyzeContentResponse.
 * Use `create(StreamingAnalyzeContentResponseSchema)` to create a new message.
 */
export const StreamingAnalyzeContentResponseSchema: GenMessage<StreamingAnalyzeContentResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 11);

/**
 * The request message for
 * [Participants.SuggestArticles][google.cloud.dialogflow.v2.Participants.SuggestArticles].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestArticlesRequest
 */
export type SuggestArticlesRequest = Message$1<"google.cloud.dialogflow.v2.SuggestArticlesRequest"> & {
  /**
   * Required. The name of the participant to fetch suggestion for.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Optional. The name of the latest conversation message to compile suggestion
   * for. If empty, it will be the latest message of the conversation.
   *
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Optional. Max number of messages prior to and including
   * [latest_message][google.cloud.dialogflow.v2.SuggestArticlesRequest.latest_message]
   * to use as context when compiling the suggestion. By default 20 and at
   * most 50.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;

  /**
   * Parameters for a human assist query.
   *
   * @generated from field: google.cloud.dialogflow.v2.AssistQueryParameters assist_query_params = 4;
   */
  assistQueryParams?: AssistQueryParameters;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestArticlesRequest.
 * Use `create(SuggestArticlesRequestSchema)` to create a new message.
 */
export const SuggestArticlesRequestSchema: GenMessage<SuggestArticlesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 12);

/**
 * The response message for
 * [Participants.SuggestArticles][google.cloud.dialogflow.v2.Participants.SuggestArticles].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestArticlesResponse
 */
export type SuggestArticlesResponse = Message$1<"google.cloud.dialogflow.v2.SuggestArticlesResponse"> & {
  /**
   * Articles ordered by score in descending order.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.ArticleAnswer article_answers = 1;
   */
  articleAnswers: ArticleAnswer[];

  /**
   * The name of the latest conversation message used to compile
   * suggestion for.
   *
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Number of messages prior to and including
   * [latest_message][google.cloud.dialogflow.v2.SuggestArticlesResponse.latest_message]
   * to compile the suggestion. It may be smaller than the
   * [SuggestArticlesRequest.context_size][google.cloud.dialogflow.v2.SuggestArticlesRequest.context_size]
   * field in the request if there aren't that many messages in the
   * conversation.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestArticlesResponse.
 * Use `create(SuggestArticlesResponseSchema)` to create a new message.
 */
export const SuggestArticlesResponseSchema: GenMessage<SuggestArticlesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 13);

/**
 * The request message for
 * [Participants.SuggestFaqAnswers][google.cloud.dialogflow.v2.Participants.SuggestFaqAnswers].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestFaqAnswersRequest
 */
export type SuggestFaqAnswersRequest = Message$1<"google.cloud.dialogflow.v2.SuggestFaqAnswersRequest"> & {
  /**
   * Required. The name of the participant to fetch suggestion for.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Optional. The name of the latest conversation message to compile suggestion
   * for. If empty, it will be the latest message of the conversation.
   *
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Optional. Max number of messages prior to and including
   * [latest_message] to use as context when compiling the
   * suggestion. By default 20 and at most 50.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;

  /**
   * Parameters for a human assist query.
   *
   * @generated from field: google.cloud.dialogflow.v2.AssistQueryParameters assist_query_params = 4;
   */
  assistQueryParams?: AssistQueryParameters;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestFaqAnswersRequest.
 * Use `create(SuggestFaqAnswersRequestSchema)` to create a new message.
 */
export const SuggestFaqAnswersRequestSchema: GenMessage<SuggestFaqAnswersRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 14);

/**
 * The request message for
 * [Participants.SuggestFaqAnswers][google.cloud.dialogflow.v2.Participants.SuggestFaqAnswers].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestFaqAnswersResponse
 */
export type SuggestFaqAnswersResponse = Message$1<"google.cloud.dialogflow.v2.SuggestFaqAnswersResponse"> & {
  /**
   * Answers extracted from FAQ documents.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.FaqAnswer faq_answers = 1;
   */
  faqAnswers: FaqAnswer[];

  /**
   * The name of the latest conversation message used to compile
   * suggestion for.
   *
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Number of messages prior to and including
   * [latest_message][google.cloud.dialogflow.v2.SuggestFaqAnswersResponse.latest_message]
   * to compile the suggestion. It may be smaller than the
   * [SuggestFaqAnswersRequest.context_size][google.cloud.dialogflow.v2.SuggestFaqAnswersRequest.context_size]
   * field in the request if there aren't that many messages in the
   * conversation.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestFaqAnswersResponse.
 * Use `create(SuggestFaqAnswersResponseSchema)` to create a new message.
 */
export const SuggestFaqAnswersResponseSchema: GenMessage<SuggestFaqAnswersResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 15);

/**
 * The request message for
 * [Participants.SuggestSmartReplies][google.cloud.dialogflow.v2.Participants.SuggestSmartReplies].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestSmartRepliesRequest
 */
export type SuggestSmartRepliesRequest = Message$1<"google.cloud.dialogflow.v2.SuggestSmartRepliesRequest"> & {
  /**
   * Required. The name of the participant to fetch suggestion for.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The current natural language text segment to compile suggestion
   * for. This provides a way for user to get follow up smart reply suggestion
   * after a smart reply selection, without sending a text message.
   *
   * @generated from field: google.cloud.dialogflow.v2.TextInput current_text_input = 4;
   */
  currentTextInput?: TextInput;

  /**
   * The name of the latest conversation message to compile suggestion
   * for. If empty, it will be the latest message of the conversation.
   *
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Max number of messages prior to and including
   * [latest_message] to use as context when compiling the
   * suggestion. By default 20 and at most 50.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestSmartRepliesRequest.
 * Use `create(SuggestSmartRepliesRequestSchema)` to create a new message.
 */
export const SuggestSmartRepliesRequestSchema: GenMessage<SuggestSmartRepliesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 16);

/**
 * The response message for
 * [Participants.SuggestSmartReplies][google.cloud.dialogflow.v2.Participants.SuggestSmartReplies].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestSmartRepliesResponse
 */
export type SuggestSmartRepliesResponse = Message$1<"google.cloud.dialogflow.v2.SuggestSmartRepliesResponse"> & {
  /**
   * Output only. Multiple reply options provided by smart reply service. The
   * order is based on the rank of the model prediction.
   * The maximum number of the returned replies is set in SmartReplyConfig.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.SmartReplyAnswer smart_reply_answers = 1;
   */
  smartReplyAnswers: SmartReplyAnswer[];

  /**
   * The name of the latest conversation message used to compile
   * suggestion for.
   *
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Number of messages prior to and including
   * [latest_message][google.cloud.dialogflow.v2.SuggestSmartRepliesResponse.latest_message]
   * to compile the suggestion. It may be smaller than the
   * [SuggestSmartRepliesRequest.context_size][google.cloud.dialogflow.v2.SuggestSmartRepliesRequest.context_size]
   * field in the request if there aren't that many messages in the
   * conversation.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestSmartRepliesResponse.
 * Use `create(SuggestSmartRepliesResponseSchema)` to create a new message.
 */
export const SuggestSmartRepliesResponseSchema: GenMessage<SuggestSmartRepliesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 17);

/**
 * Represents the natural language speech audio to be played to the end user.
 *
 * @generated from message google.cloud.dialogflow.v2.OutputAudio
 */
export type OutputAudio = Message$1<"google.cloud.dialogflow.v2.OutputAudio"> & {
  /**
   * Instructs the speech synthesizer how to generate the speech
   * audio.
   *
   * @generated from field: google.cloud.dialogflow.v2.OutputAudioConfig config = 1;
   */
  config?: OutputAudioConfig;

  /**
   * The natural language speech audio.
   *
   * @generated from field: bytes audio = 2;
   */
  audio: Uint8Array;
};

/**
 * Describes the message google.cloud.dialogflow.v2.OutputAudio.
 * Use `create(OutputAudioSchema)` to create a new message.
 */
export const OutputAudioSchema: GenMessage<OutputAudio> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 18);

/**
 * Represents a response from an automated agent.
 *
 * @generated from message google.cloud.dialogflow.v2.AutomatedAgentReply
 */
export type AutomatedAgentReply = Message$1<"google.cloud.dialogflow.v2.AutomatedAgentReply"> & {
  /**
   * Response of the Dialogflow
   * [Sessions.DetectIntent][google.cloud.dialogflow.v2.Sessions.DetectIntent]
   * call.
   *
   * @generated from field: google.cloud.dialogflow.v2.DetectIntentResponse detect_intent_response = 1;
   */
  detectIntentResponse?: DetectIntentResponse;

  /**
   * AutomatedAgentReply type.
   *
   * @generated from field: google.cloud.dialogflow.v2.AutomatedAgentReply.AutomatedAgentReplyType automated_agent_reply_type = 7;
   */
  automatedAgentReplyType: AutomatedAgentReply_AutomatedAgentReplyType;

  /**
   * Indicates whether the partial automated agent reply is interruptible when a
   * later reply message arrives. e.g. if the agent specified some music as
   * partial response, it can be cancelled.
   *
   * @generated from field: bool allow_cancellation = 8;
   */
  allowCancellation: boolean;

  /**
   * The unique identifier of the current Dialogflow CX conversation page.
   * Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
   * ID>/flows/<Flow ID>/pages/<Page ID>`.
   *
   * @generated from field: string cx_current_page = 11;
   */
  cxCurrentPage: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.AutomatedAgentReply.
 * Use `create(AutomatedAgentReplySchema)` to create a new message.
 */
export const AutomatedAgentReplySchema: GenMessage<AutomatedAgentReply> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 19);

/**
 * Represents different automated agent reply types.
 *
 * @generated from enum google.cloud.dialogflow.v2.AutomatedAgentReply.AutomatedAgentReplyType
 */
export enum AutomatedAgentReply_AutomatedAgentReplyType {
  /**
   * Not specified. This should never happen.
   *
   * @generated from enum value: AUTOMATED_AGENT_REPLY_TYPE_UNSPECIFIED = 0;
   */
  AUTOMATED_AGENT_REPLY_TYPE_UNSPECIFIED = 0,

  /**
   * Partial reply. e.g. Aggregated responses in a `Fulfillment` that enables
   * `return_partial_response` can be returned as partial reply.
   * WARNING: partial reply is not eligible for barge-in.
   *
   * @generated from enum value: PARTIAL = 1;
   */
  PARTIAL = 1,

  /**
   * Final reply.
   *
   * @generated from enum value: FINAL = 2;
   */
  FINAL = 2,
}

/**
 * Describes the enum google.cloud.dialogflow.v2.AutomatedAgentReply.AutomatedAgentReplyType.
 */
export const AutomatedAgentReply_AutomatedAgentReplyTypeSchema: GenEnum<AutomatedAgentReply_AutomatedAgentReplyType> = /*@__PURE__*/
  enumDesc(file_google_cloud_dialogflow_v2_participant, 19, 0);

/**
 * Represents article answer.
 *
 * @generated from message google.cloud.dialogflow.v2.ArticleAnswer
 */
export type ArticleAnswer = Message$1<"google.cloud.dialogflow.v2.ArticleAnswer"> & {
  /**
   * The article title.
   *
   * @generated from field: string title = 1;
   */
  title: string;

  /**
   * The article URI.
   *
   * @generated from field: string uri = 2;
   */
  uri: string;

  /**
   * Article snippets.
   *
   * @generated from field: repeated string snippets = 3;
   */
  snippets: string[];

  /**
   * Article match confidence.
   * The system's confidence score that this article is a good match for this
   * conversation, as a value from 0.0 (completely uncertain) to 1.0
   * (completely certain).
   *
   * @generated from field: float confidence = 4;
   */
  confidence: number;

  /**
   * A map that contains metadata about the answer and the
   * document from which it originates.
   *
   * @generated from field: map<string, string> metadata = 5;
   */
  metadata: { [key: string]: string };

  /**
   * The name of answer record, in the format of
   * "projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
   * ID>"
   *
   * @generated from field: string answer_record = 6;
   */
  answerRecord: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.ArticleAnswer.
 * Use `create(ArticleAnswerSchema)` to create a new message.
 */
export const ArticleAnswerSchema: GenMessage<ArticleAnswer> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 20);

/**
 * Represents answer from "frequently asked questions".
 *
 * @generated from message google.cloud.dialogflow.v2.FaqAnswer
 */
export type FaqAnswer = Message$1<"google.cloud.dialogflow.v2.FaqAnswer"> & {
  /**
   * The piece of text from the `source` knowledge base document.
   *
   * @generated from field: string answer = 1;
   */
  answer: string;

  /**
   * The system's confidence score that this Knowledge answer is a good match
   * for this conversational query, range from 0.0 (completely uncertain)
   * to 1.0 (completely certain).
   *
   * @generated from field: float confidence = 2;
   */
  confidence: number;

  /**
   * The corresponding FAQ question.
   *
   * @generated from field: string question = 3;
   */
  question: string;

  /**
   * Indicates which Knowledge Document this answer was extracted
   * from.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/agent/knowledgeBases/<Knowledge Base ID>/documents/<Document ID>`.
   *
   * @generated from field: string source = 4;
   */
  source: string;

  /**
   * A map that contains metadata about the answer and the
   * document from which it originates.
   *
   * @generated from field: map<string, string> metadata = 5;
   */
  metadata: { [key: string]: string };

  /**
   * The name of answer record, in the format of
   * "projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
   * ID>"
   *
   * @generated from field: string answer_record = 6;
   */
  answerRecord: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.FaqAnswer.
 * Use `create(FaqAnswerSchema)` to create a new message.
 */
export const FaqAnswerSchema: GenMessage<FaqAnswer> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 21);

/**
 * Represents a smart reply answer.
 *
 * @generated from message google.cloud.dialogflow.v2.SmartReplyAnswer
 */
export type SmartReplyAnswer = Message$1<"google.cloud.dialogflow.v2.SmartReplyAnswer"> & {
  /**
   * The content of the reply.
   *
   * @generated from field: string reply = 1;
   */
  reply: string;

  /**
   * Smart reply confidence.
   * The system's confidence score that this reply is a good match for
   * this conversation, as a value from 0.0 (completely uncertain) to 1.0
   * (completely certain).
   *
   * @generated from field: float confidence = 2;
   */
  confidence: number;

  /**
   * The name of answer record, in the format of
   * "projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
   * ID>"
   *
   * @generated from field: string answer_record = 3;
   */
  answerRecord: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SmartReplyAnswer.
 * Use `create(SmartReplyAnswerSchema)` to create a new message.
 */
export const SmartReplyAnswerSchema: GenMessage<SmartReplyAnswer> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 22);

/**
 * Represents an intent suggestion.
 *
 * @generated from message google.cloud.dialogflow.v2.IntentSuggestion
 */
export type IntentSuggestion = Message$1<"google.cloud.dialogflow.v2.IntentSuggestion"> & {
  /**
   * The display name of the intent.
   *
   * @generated from field: string display_name = 1;
   */
  displayName: string;

  /**
   * The name of the intent.
   *
   * @generated from oneof google.cloud.dialogflow.v2.IntentSuggestion.intent
   */
  intent: {
    /**
     * The unique identifier of this
     * [intent][google.cloud.dialogflow.v2.Intent]. Format: `projects/<Project
     * ID>/locations/<Location ID>/agent/intents/<Intent ID>`.
     *
     * @generated from field: string intent_v2 = 2;
     */
    value: string;
    case: "intentV2";
  } | { case: undefined; value?: undefined };

  /**
   * Human readable description for better understanding an intent like its
   * scope, content, result etc. Maximum character limit: 140 characters.
   *
   * @generated from field: string description = 5;
   */
  description: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.IntentSuggestion.
 * Use `create(IntentSuggestionSchema)` to create a new message.
 */
export const IntentSuggestionSchema: GenMessage<IntentSuggestion> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 23);

/**
 * Represents a Dialogflow assist answer.
 *
 * @generated from message google.cloud.dialogflow.v2.DialogflowAssistAnswer
 */
export type DialogflowAssistAnswer = Message$1<"google.cloud.dialogflow.v2.DialogflowAssistAnswer"> & {
  /**
   * Result from DetectIntent for one matched intent.
   *
   * @generated from oneof google.cloud.dialogflow.v2.DialogflowAssistAnswer.result
   */
  result: {
    /**
     * Result from v2 agent.
     *
     * @generated from field: google.cloud.dialogflow.v2.QueryResult query_result = 1;
     */
    value: QueryResult;
    case: "queryResult";
  } | {
    /**
     * An intent suggestion generated from conversation.
     *
     * @generated from field: google.cloud.dialogflow.v2.IntentSuggestion intent_suggestion = 5;
     */
    value: IntentSuggestion;
    case: "intentSuggestion";
  } | { case: undefined; value?: undefined };

  /**
   * The name of answer record, in the format of
   * "projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
   * ID>"
   *
   * @generated from field: string answer_record = 2;
   */
  answerRecord: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.DialogflowAssistAnswer.
 * Use `create(DialogflowAssistAnswerSchema)` to create a new message.
 */
export const DialogflowAssistAnswerSchema: GenMessage<DialogflowAssistAnswer> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 24);

/**
 * One response of different type of suggestion response which is used in
 * the response of
 * [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent]
 * and
 * [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent],
 * as well as
 * [HumanAgentAssistantEvent][google.cloud.dialogflow.v2.HumanAgentAssistantEvent].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestionResult
 */
export type SuggestionResult = Message$1<"google.cloud.dialogflow.v2.SuggestionResult"> & {
  /**
   * Different type of suggestion response.
   *
   * @generated from oneof google.cloud.dialogflow.v2.SuggestionResult.suggestion_response
   */
  suggestionResponse: {
    /**
     * Error status if the request failed.
     *
     * @generated from field: google.rpc.Status error = 1;
     */
    value: Status;
    case: "error";
  } | {
    /**
     * SuggestArticlesResponse if request is for ARTICLE_SUGGESTION.
     *
     * @generated from field: google.cloud.dialogflow.v2.SuggestArticlesResponse suggest_articles_response = 2;
     */
    value: SuggestArticlesResponse;
    case: "suggestArticlesResponse";
  } | {
    /**
     * SuggestKnowledgeAssistResponse if request is for KNOWLEDGE_ASSIST.
     *
     * @generated from field: google.cloud.dialogflow.v2.SuggestKnowledgeAssistResponse suggest_knowledge_assist_response = 8;
     */
    value: SuggestKnowledgeAssistResponse;
    case: "suggestKnowledgeAssistResponse";
  } | {
    /**
     * SuggestFaqAnswersResponse if request is for FAQ_ANSWER.
     *
     * @generated from field: google.cloud.dialogflow.v2.SuggestFaqAnswersResponse suggest_faq_answers_response = 3;
     */
    value: SuggestFaqAnswersResponse;
    case: "suggestFaqAnswersResponse";
  } | {
    /**
     * SuggestSmartRepliesResponse if request is for SMART_REPLY.
     *
     * @generated from field: google.cloud.dialogflow.v2.SuggestSmartRepliesResponse suggest_smart_replies_response = 4;
     */
    value: SuggestSmartRepliesResponse;
    case: "suggestSmartRepliesResponse";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestionResult.
 * Use `create(SuggestionResultSchema)` to create a new message.
 */
export const SuggestionResultSchema: GenMessage<SuggestionResult> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 25);

/**
 * Defines the language used in the input text.
 *
 * @generated from message google.cloud.dialogflow.v2.InputTextConfig
 */
export type InputTextConfig = Message$1<"google.cloud.dialogflow.v2.InputTextConfig"> & {
  /**
   * Required. The language of this conversational query. See [Language
   * Support](https://cloud.google.com/dialogflow/docs/reference/language)
   * for a list of the currently supported language codes.
   *
   * @generated from field: string language_code = 1;
   */
  languageCode: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.InputTextConfig.
 * Use `create(InputTextConfigSchema)` to create a new message.
 */
export const InputTextConfigSchema: GenMessage<InputTextConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 26);

/**
 * Represents a part of a message possibly annotated with an entity. The part
 * can be an entity or purely a part of the message between two entities or
 * message start/end.
 *
 * @generated from message google.cloud.dialogflow.v2.AnnotatedMessagePart
 */
export type AnnotatedMessagePart = Message$1<"google.cloud.dialogflow.v2.AnnotatedMessagePart"> & {
  /**
   * A part of a message possibly annotated with an entity.
   *
   * @generated from field: string text = 1;
   */
  text: string;

  /**
   * The [Dialogflow system entity
   * type](https://cloud.google.com/dialogflow/docs/reference/system-entities)
   * of this message part. If this is empty, Dialogflow could not annotate the
   * phrase part with a system entity.
   *
   * @generated from field: string entity_type = 2;
   */
  entityType: string;

  /**
   * The [Dialogflow system entity formatted value
   * ](https://cloud.google.com/dialogflow/docs/reference/system-entities) of
   * this message part. For example for a system entity of type
   * `@sys.unit-currency`, this may contain:
   * <pre>
   * {
   *   "amount": 5,
   *   "currency": "USD"
   * }
   * </pre>
   *
   * @generated from field: google.protobuf.Value formatted_value = 3;
   */
  formattedValue?: Value;
};

/**
 * Describes the message google.cloud.dialogflow.v2.AnnotatedMessagePart.
 * Use `create(AnnotatedMessagePartSchema)` to create a new message.
 */
export const AnnotatedMessagePartSchema: GenMessage<AnnotatedMessagePart> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 27);

/**
 * Represents the result of annotation for the message.
 *
 * @generated from message google.cloud.dialogflow.v2.MessageAnnotation
 */
export type MessageAnnotation = Message$1<"google.cloud.dialogflow.v2.MessageAnnotation"> & {
  /**
   * The collection of annotated message parts ordered by their
   * position in the message. You can recover the annotated message by
   * concatenating [AnnotatedMessagePart.text].
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.AnnotatedMessagePart parts = 1;
   */
  parts: AnnotatedMessagePart[];

  /**
   * Indicates whether the text message contains entities.
   *
   * @generated from field: bool contain_entities = 2;
   */
  containEntities: boolean;
};

/**
 * Describes the message google.cloud.dialogflow.v2.MessageAnnotation.
 * Use `create(MessageAnnotationSchema)` to create a new message.
 */
export const MessageAnnotationSchema: GenMessage<MessageAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 28);

/**
 * Represents the selection of a suggestion.
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestionInput
 */
export type SuggestionInput = Message$1<"google.cloud.dialogflow.v2.SuggestionInput"> & {
  /**
   * Required. The ID of a suggestion selected by the human agent.
   * The suggestion(s) were generated in a previous call to
   * request Dialogflow assist.
   * The format is:
   * `projects/<Project ID>/locations/<Location ID>/answerRecords/<Answer Record
   * ID>` where <Answer Record ID> is an alphanumeric string.
   *
   * @generated from field: string answer_record = 1;
   */
  answerRecord: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestionInput.
 * Use `create(SuggestionInputSchema)` to create a new message.
 */
export const SuggestionInputSchema: GenMessage<SuggestionInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 29);

/**
 * Represents the parameters of human assist query.
 *
 * @generated from message google.cloud.dialogflow.v2.AssistQueryParameters
 */
export type AssistQueryParameters = Message$1<"google.cloud.dialogflow.v2.AssistQueryParameters"> & {
  /**
   * Key-value filters on the metadata of documents returned by article
   * suggestion. If specified, article suggestion only returns suggested
   * documents that match all filters in their
   * [Document.metadata][google.cloud.dialogflow.v2.Document.metadata]. Multiple
   * values for a metadata key should be concatenated by comma. For example,
   * filters to match all documents that have 'US' or 'CA' in their market
   * metadata values and 'agent' in their user metadata values will be
   * ```
   * documents_metadata_filters {
   *   key: "market"
   *   value: "US,CA"
   * }
   * documents_metadata_filters {
   *   key: "user"
   *   value: "agent"
   * }
   * ```
   *
   * @generated from field: map<string, string> documents_metadata_filters = 1;
   */
  documentsMetadataFilters: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dialogflow.v2.AssistQueryParameters.
 * Use `create(AssistQueryParametersSchema)` to create a new message.
 */
export const AssistQueryParametersSchema: GenMessage<AssistQueryParameters> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 30);

/**
 * The request message for
 * [Participants.SuggestKnowledgeAssist][google.cloud.dialogflow.v2.Participants.SuggestKnowledgeAssist].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestKnowledgeAssistRequest
 */
export type SuggestKnowledgeAssistRequest = Message$1<"google.cloud.dialogflow.v2.SuggestKnowledgeAssistRequest"> & {
  /**
   * Required. The name of the participant to fetch suggestions for.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/participants/<Participant ID>`.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Optional. The name of the latest conversation message to compile
   * suggestions for. If empty, it will be the latest message of the
   * conversation. Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Optional. Max number of messages prior to and including
   * [latest_message][google.cloud.dialogflow.v2.SuggestKnowledgeAssistRequest.latest_message]
   * to use as context when compiling the suggestion. The context size is by
   * default 100 and at most 100.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;

  /**
   * Optional. The previously suggested query for the given conversation. This
   * helps identify whether the next suggestion we generate is resonably
   * different from the previous one. This is useful to avoid similar
   * suggestions within the conversation.
   *
   * @generated from field: string previous_suggested_query = 4;
   */
  previousSuggestedQuery: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestKnowledgeAssistRequest.
 * Use `create(SuggestKnowledgeAssistRequestSchema)` to create a new message.
 */
export const SuggestKnowledgeAssistRequestSchema: GenMessage<SuggestKnowledgeAssistRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 31);

/**
 * The response message for
 * [Participants.SuggestKnowledgeAssist][google.cloud.dialogflow.v2.Participants.SuggestKnowledgeAssist].
 *
 * @generated from message google.cloud.dialogflow.v2.SuggestKnowledgeAssistResponse
 */
export type SuggestKnowledgeAssistResponse = Message$1<"google.cloud.dialogflow.v2.SuggestKnowledgeAssistResponse"> & {
  /**
   * Output only. Knowledge Assist suggestion.
   *
   * @generated from field: google.cloud.dialogflow.v2.KnowledgeAssistAnswer knowledge_assist_answer = 1;
   */
  knowledgeAssistAnswer?: KnowledgeAssistAnswer;

  /**
   * The name of the latest conversation message used to compile suggestion for.
   * Format: `projects/<Project ID>/locations/<Location
   * ID>/conversations/<Conversation ID>/messages/<Message ID>`.
   *
   * @generated from field: string latest_message = 2;
   */
  latestMessage: string;

  /**
   * Number of messages prior to and including
   * [latest_message][google.cloud.dialogflow.v2.SuggestKnowledgeAssistResponse.latest_message]
   * to compile the suggestion. It may be smaller than the
   * [SuggestKnowledgeAssistRequest.context_size][google.cloud.dialogflow.v2.SuggestKnowledgeAssistRequest.context_size]
   * field in the request if there are fewer messages in the conversation.
   *
   * @generated from field: int32 context_size = 3;
   */
  contextSize: number;
};

/**
 * Describes the message google.cloud.dialogflow.v2.SuggestKnowledgeAssistResponse.
 * Use `create(SuggestKnowledgeAssistResponseSchema)` to create a new message.
 */
export const SuggestKnowledgeAssistResponseSchema: GenMessage<SuggestKnowledgeAssistResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 32);

/**
 * Represents a Knowledge Assist answer.
 *
 * @generated from message google.cloud.dialogflow.v2.KnowledgeAssistAnswer
 */
export type KnowledgeAssistAnswer = Message$1<"google.cloud.dialogflow.v2.KnowledgeAssistAnswer"> & {
  /**
   * The query suggested based on the context. Suggestion is made only if it
   * is different from the previous suggestion.
   *
   * @generated from field: google.cloud.dialogflow.v2.KnowledgeAssistAnswer.SuggestedQuery suggested_query = 1;
   */
  suggestedQuery?: KnowledgeAssistAnswer_SuggestedQuery;

  /**
   * The answer generated for the suggested query. Whether or not an answer is
   * generated depends on how confident we are about the generated query.
   *
   * @generated from field: google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer suggested_query_answer = 2;
   */
  suggestedQueryAnswer?: KnowledgeAssistAnswer_KnowledgeAnswer;

  /**
   * The name of the answer record.
   * Format: `projects/<Project ID>/locations/<location ID>/answer
   * Records/<Answer Record ID>`.
   *
   * @generated from field: string answer_record = 3;
   */
  answerRecord: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.
 * Use `create(KnowledgeAssistAnswerSchema)` to create a new message.
 */
export const KnowledgeAssistAnswerSchema: GenMessage<KnowledgeAssistAnswer> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 33);

/**
 * Represents a suggested query.
 *
 * @generated from message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.SuggestedQuery
 */
export type KnowledgeAssistAnswer_SuggestedQuery = Message$1<"google.cloud.dialogflow.v2.KnowledgeAssistAnswer.SuggestedQuery"> & {
  /**
   * Suggested query text.
   *
   * @generated from field: string query_text = 1;
   */
  queryText: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.SuggestedQuery.
 * Use `create(KnowledgeAssistAnswer_SuggestedQuerySchema)` to create a new message.
 */
export const KnowledgeAssistAnswer_SuggestedQuerySchema: GenMessage<KnowledgeAssistAnswer_SuggestedQuery> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 33, 0);

/**
 * Represents an answer from Knowledge. Currently supports FAQ and Generative
 * answers.
 *
 * @generated from message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer
 */
export type KnowledgeAssistAnswer_KnowledgeAnswer = Message$1<"google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer"> & {
  /**
   * The piece of text from the `source` that answers this suggested query.
   *
   * @generated from field: string answer_text = 1;
   */
  answerText: string;

  /**
   * Source of result.
   *
   * @generated from oneof google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.source
   */
  source: {
    /**
     * Populated if the prediction came from FAQ.
     *
     * @generated from field: google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.FaqSource faq_source = 3;
     */
    value: KnowledgeAssistAnswer_KnowledgeAnswer_FaqSource;
    case: "faqSource";
  } | {
    /**
     * Populated if the prediction was Generative.
     *
     * @generated from field: google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource generative_source = 4;
     */
    value: KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource;
    case: "generativeSource";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.
 * Use `create(KnowledgeAssistAnswer_KnowledgeAnswerSchema)` to create a new message.
 */
export const KnowledgeAssistAnswer_KnowledgeAnswerSchema: GenMessage<KnowledgeAssistAnswer_KnowledgeAnswer> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 33, 1);

/**
 * Details about source of FAQ answer.
 *
 * @generated from message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.FaqSource
 */
export type KnowledgeAssistAnswer_KnowledgeAnswer_FaqSource = Message$1<"google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.FaqSource"> & {
  /**
   * The corresponding FAQ question.
   *
   * @generated from field: string question = 2;
   */
  question: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.FaqSource.
 * Use `create(KnowledgeAssistAnswer_KnowledgeAnswer_FaqSourceSchema)` to create a new message.
 */
export const KnowledgeAssistAnswer_KnowledgeAnswer_FaqSourceSchema: GenMessage<KnowledgeAssistAnswer_KnowledgeAnswer_FaqSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 33, 1, 0);

/**
 * Details about source of Generative answer.
 *
 * @generated from message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource
 */
export type KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource = Message$1<"google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource"> & {
  /**
   * All snippets used for this Generative Prediction, with their source URI
   * and data.
   *
   * @generated from field: repeated google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource.Snippet snippets = 1;
   */
  snippets: KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource_Snippet[];
};

/**
 * Describes the message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource.
 * Use `create(KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSourceSchema)` to create a new message.
 */
export const KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSourceSchema: GenMessage<KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 33, 1, 1);

/**
 * Snippet Source for a Generative Prediction.
 *
 * @generated from message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource.Snippet
 */
export type KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource_Snippet = Message$1<"google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource.Snippet"> & {
  /**
   * URI the data is sourced from.
   *
   * @generated from field: string uri = 2;
   */
  uri: string;

  /**
   * Text taken from that URI.
   *
   * @generated from field: string text = 3;
   */
  text: string;

  /**
   * Title of the document.
   *
   * @generated from field: string title = 4;
   */
  title: string;
};

/**
 * Describes the message google.cloud.dialogflow.v2.KnowledgeAssistAnswer.KnowledgeAnswer.GenerativeSource.Snippet.
 * Use `create(KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource_SnippetSchema)` to create a new message.
 */
export const KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource_SnippetSchema: GenMessage<KnowledgeAssistAnswer_KnowledgeAnswer_GenerativeSource_Snippet> = /*@__PURE__*/
  messageDesc(file_google_cloud_dialogflow_v2_participant, 33, 1, 1, 0);

/**
 * Service for managing [Participants][google.cloud.dialogflow.v2.Participant].
 *
 * @generated from service google.cloud.dialogflow.v2.Participants
 */
export const Participants: GenService<{
  /**
   * Creates a new participant in a conversation.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.CreateParticipant
   */
  createParticipant: {
    methodKind: "unary";
    input: typeof CreateParticipantRequestSchema;
    output: typeof ParticipantSchema;
  },
  /**
   * Retrieves a conversation participant.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.GetParticipant
   */
  getParticipant: {
    methodKind: "unary";
    input: typeof GetParticipantRequestSchema;
    output: typeof ParticipantSchema;
  },
  /**
   * Returns the list of all participants in the specified conversation.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.ListParticipants
   */
  listParticipants: {
    methodKind: "unary";
    input: typeof ListParticipantsRequestSchema;
    output: typeof ListParticipantsResponseSchema;
  },
  /**
   * Updates the specified participant.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.UpdateParticipant
   */
  updateParticipant: {
    methodKind: "unary";
    input: typeof UpdateParticipantRequestSchema;
    output: typeof ParticipantSchema;
  },
  /**
   * Adds a text (chat, for example), or audio (phone recording, for example)
   * message from a participant into the conversation.
   *
   * Note: Always use agent versions for production traffic
   * sent to virtual agents. See [Versions and
   * environments](https://cloud.google.com/dialogflow/es/docs/agents-versions).
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.AnalyzeContent
   */
  analyzeContent: {
    methodKind: "unary";
    input: typeof AnalyzeContentRequestSchema;
    output: typeof AnalyzeContentResponseSchema;
  },
  /**
   * Adds a text (chat, for example), or audio (phone recording, for example)
   * message from a participant into the conversation.
   * Note: This method is only available through the gRPC API (not REST).
   *
   * The top-level message sent to the client by the server is
   * `StreamingAnalyzeContentResponse`. Multiple response messages can be
   * returned in order. The first one or more messages contain the
   * `recognition_result` field. Each result represents a more complete
   * transcript of what the user said. The next message contains the
   * `reply_text` field and potentially the `reply_audio` field. The message can
   * also contain the `automated_agent_reply` field.
   *
   * Note: Always use agent versions for production traffic
   * sent to virtual agents. See [Versions and
   * environments](https://cloud.google.com/dialogflow/es/docs/agents-versions).
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.StreamingAnalyzeContent
   */
  streamingAnalyzeContent: {
    methodKind: "bidi_streaming";
    input: typeof StreamingAnalyzeContentRequestSchema;
    output: typeof StreamingAnalyzeContentResponseSchema;
  },
  /**
   * Gets suggested articles for a participant based on specific historical
   * messages.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.SuggestArticles
   */
  suggestArticles: {
    methodKind: "unary";
    input: typeof SuggestArticlesRequestSchema;
    output: typeof SuggestArticlesResponseSchema;
  },
  /**
   * Gets suggested faq answers for a participant based on specific historical
   * messages.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.SuggestFaqAnswers
   */
  suggestFaqAnswers: {
    methodKind: "unary";
    input: typeof SuggestFaqAnswersRequestSchema;
    output: typeof SuggestFaqAnswersResponseSchema;
  },
  /**
   * Gets smart replies for a participant based on specific historical
   * messages.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.SuggestSmartReplies
   */
  suggestSmartReplies: {
    methodKind: "unary";
    input: typeof SuggestSmartRepliesRequestSchema;
    output: typeof SuggestSmartRepliesResponseSchema;
  },
  /**
   * Gets knowledge assist suggestions based on historical messages.
   *
   * @generated from rpc google.cloud.dialogflow.v2.Participants.SuggestKnowledgeAssist
   */
  suggestKnowledgeAssist: {
    methodKind: "unary";
    input: typeof SuggestKnowledgeAssistRequestSchema;
    output: typeof SuggestKnowledgeAssistResponseSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_dialogflow_v2_participant, 0);

