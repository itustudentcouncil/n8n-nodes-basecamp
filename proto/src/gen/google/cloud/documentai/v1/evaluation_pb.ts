// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/documentai/v1/evaluation.proto (package google.cloud.documentai.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/documentai/v1/evaluation.proto.
 */
export const file_google_cloud_documentai_v1_evaluation: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_resource, file_google_protobuf_timestamp]);

/**
 * Gives a short summary of an evaluation, and links to the evaluation itself.
 *
 * @generated from message google.cloud.documentai.v1.EvaluationReference
 */
export type EvaluationReference = Message<"google.cloud.documentai.v1.EvaluationReference"> & {
  /**
   * The resource name of the Long Running Operation for the evaluation.
   *
   * @generated from field: string operation = 1;
   */
  operation: string;

  /**
   * The resource name of the evaluation.
   *
   * @generated from field: string evaluation = 2;
   */
  evaluation: string;

  /**
   * An aggregate of the statistics for the evaluation with fuzzy matching on.
   *
   * @generated from field: google.cloud.documentai.v1.Evaluation.Metrics aggregate_metrics = 4;
   */
  aggregateMetrics?: Evaluation_Metrics;

  /**
   * An aggregate of the statistics for the evaluation with fuzzy matching off.
   *
   * @generated from field: google.cloud.documentai.v1.Evaluation.Metrics aggregate_metrics_exact = 5;
   */
  aggregateMetricsExact?: Evaluation_Metrics;
};

/**
 * Describes the message google.cloud.documentai.v1.EvaluationReference.
 * Use `create(EvaluationReferenceSchema)` to create a new message.
 */
export const EvaluationReferenceSchema: GenMessage<EvaluationReference> = /*@__PURE__*/
  messageDesc(file_google_cloud_documentai_v1_evaluation, 0);

/**
 * An evaluation of a ProcessorVersion's performance.
 *
 * @generated from message google.cloud.documentai.v1.Evaluation
 */
export type Evaluation = Message<"google.cloud.documentai.v1.Evaluation"> & {
  /**
   * The resource name of the evaluation.
   * Format:
   * `projects/{project}/locations/{location}/processors/{processor}/processorVersions/{processor_version}/evaluations/{evaluation}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The time that the evaluation was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Counters for the documents used in the evaluation.
   *
   * @generated from field: google.cloud.documentai.v1.Evaluation.Counters document_counters = 5;
   */
  documentCounters?: Evaluation_Counters;

  /**
   * Metrics for all the entities in aggregate.
   *
   * @generated from field: google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics all_entities_metrics = 3;
   */
  allEntitiesMetrics?: Evaluation_MultiConfidenceMetrics;

  /**
   * Metrics across confidence levels, for different entities.
   *
   * @generated from field: map<string, google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics> entity_metrics = 4;
   */
  entityMetrics: { [key: string]: Evaluation_MultiConfidenceMetrics };

  /**
   * The KMS key name used for encryption.
   *
   * @generated from field: string kms_key_name = 6;
   */
  kmsKeyName: string;

  /**
   * The KMS key version with which data is encrypted.
   *
   * @generated from field: string kms_key_version_name = 7;
   */
  kmsKeyVersionName: string;
};

/**
 * Describes the message google.cloud.documentai.v1.Evaluation.
 * Use `create(EvaluationSchema)` to create a new message.
 */
export const EvaluationSchema: GenMessage<Evaluation> = /*@__PURE__*/
  messageDesc(file_google_cloud_documentai_v1_evaluation, 1);

/**
 * Evaluation counters for the documents that were used.
 *
 * @generated from message google.cloud.documentai.v1.Evaluation.Counters
 */
export type Evaluation_Counters = Message<"google.cloud.documentai.v1.Evaluation.Counters"> & {
  /**
   * How many documents were sent for evaluation.
   *
   * @generated from field: int32 input_documents_count = 1;
   */
  inputDocumentsCount: number;

  /**
   * How many documents were not included in the evaluation as they didn't
   * pass validation.
   *
   * @generated from field: int32 invalid_documents_count = 2;
   */
  invalidDocumentsCount: number;

  /**
   * How many documents were not included in the evaluation as Document AI
   * failed to process them.
   *
   * @generated from field: int32 failed_documents_count = 3;
   */
  failedDocumentsCount: number;

  /**
   * How many documents were used in the evaluation.
   *
   * @generated from field: int32 evaluated_documents_count = 4;
   */
  evaluatedDocumentsCount: number;
};

/**
 * Describes the message google.cloud.documentai.v1.Evaluation.Counters.
 * Use `create(Evaluation_CountersSchema)` to create a new message.
 */
export const Evaluation_CountersSchema: GenMessage<Evaluation_Counters> = /*@__PURE__*/
  messageDesc(file_google_cloud_documentai_v1_evaluation, 1, 0);

/**
 * Evaluation metrics, either in aggregate or about a specific entity.
 *
 * @generated from message google.cloud.documentai.v1.Evaluation.Metrics
 */
export type Evaluation_Metrics = Message<"google.cloud.documentai.v1.Evaluation.Metrics"> & {
  /**
   * The calculated precision.
   *
   * @generated from field: float precision = 1;
   */
  precision: number;

  /**
   * The calculated recall.
   *
   * @generated from field: float recall = 2;
   */
  recall: number;

  /**
   * The calculated f1 score.
   *
   * @generated from field: float f1_score = 3;
   */
  f1Score: number;

  /**
   * The amount of occurrences in predicted documents.
   *
   * @generated from field: int32 predicted_occurrences_count = 4;
   */
  predictedOccurrencesCount: number;

  /**
   * The amount of occurrences in ground truth documents.
   *
   * @generated from field: int32 ground_truth_occurrences_count = 5;
   */
  groundTruthOccurrencesCount: number;

  /**
   * The amount of documents with a predicted occurrence.
   *
   * @generated from field: int32 predicted_document_count = 10;
   */
  predictedDocumentCount: number;

  /**
   * The amount of documents with a ground truth occurrence.
   *
   * @generated from field: int32 ground_truth_document_count = 11;
   */
  groundTruthDocumentCount: number;

  /**
   * The amount of true positives.
   *
   * @generated from field: int32 true_positives_count = 6;
   */
  truePositivesCount: number;

  /**
   * The amount of false positives.
   *
   * @generated from field: int32 false_positives_count = 7;
   */
  falsePositivesCount: number;

  /**
   * The amount of false negatives.
   *
   * @generated from field: int32 false_negatives_count = 8;
   */
  falseNegativesCount: number;

  /**
   * The amount of documents that had an occurrence of this label.
   *
   * @generated from field: int32 total_documents_count = 9;
   */
  totalDocumentsCount: number;
};

/**
 * Describes the message google.cloud.documentai.v1.Evaluation.Metrics.
 * Use `create(Evaluation_MetricsSchema)` to create a new message.
 */
export const Evaluation_MetricsSchema: GenMessage<Evaluation_Metrics> = /*@__PURE__*/
  messageDesc(file_google_cloud_documentai_v1_evaluation, 1, 1);

/**
 * Evaluations metrics, at a specific confidence level.
 *
 * @generated from message google.cloud.documentai.v1.Evaluation.ConfidenceLevelMetrics
 */
export type Evaluation_ConfidenceLevelMetrics = Message<"google.cloud.documentai.v1.Evaluation.ConfidenceLevelMetrics"> & {
  /**
   * The confidence level.
   *
   * @generated from field: float confidence_level = 1;
   */
  confidenceLevel: number;

  /**
   * The metrics at the specific confidence level.
   *
   * @generated from field: google.cloud.documentai.v1.Evaluation.Metrics metrics = 2;
   */
  metrics?: Evaluation_Metrics;
};

/**
 * Describes the message google.cloud.documentai.v1.Evaluation.ConfidenceLevelMetrics.
 * Use `create(Evaluation_ConfidenceLevelMetricsSchema)` to create a new message.
 */
export const Evaluation_ConfidenceLevelMetricsSchema: GenMessage<Evaluation_ConfidenceLevelMetrics> = /*@__PURE__*/
  messageDesc(file_google_cloud_documentai_v1_evaluation, 1, 2);

/**
 * Metrics across multiple confidence levels.
 *
 * @generated from message google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics
 */
export type Evaluation_MultiConfidenceMetrics = Message<"google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics"> & {
  /**
   * Metrics across confidence levels with fuzzy matching enabled.
   *
   * @generated from field: repeated google.cloud.documentai.v1.Evaluation.ConfidenceLevelMetrics confidence_level_metrics = 1;
   */
  confidenceLevelMetrics: Evaluation_ConfidenceLevelMetrics[];

  /**
   * Metrics across confidence levels with only exact matching.
   *
   * @generated from field: repeated google.cloud.documentai.v1.Evaluation.ConfidenceLevelMetrics confidence_level_metrics_exact = 4;
   */
  confidenceLevelMetricsExact: Evaluation_ConfidenceLevelMetrics[];

  /**
   * The calculated area under the precision recall curve (AUPRC), computed by
   * integrating over all confidence thresholds.
   *
   * @generated from field: float auprc = 2;
   */
  auprc: number;

  /**
   * The Estimated Calibration Error (ECE) of the confidence of the predicted
   * entities.
   *
   * @generated from field: float estimated_calibration_error = 3;
   */
  estimatedCalibrationError: number;

  /**
   * The AUPRC for metrics with fuzzy matching disabled, i.e., exact matching
   * only.
   *
   * @generated from field: float auprc_exact = 5;
   */
  auprcExact: number;

  /**
   * The ECE for the predicted entities with fuzzy matching disabled, i.e.,
   * exact matching only.
   *
   * @generated from field: float estimated_calibration_error_exact = 6;
   */
  estimatedCalibrationErrorExact: number;

  /**
   * The metrics type for the label.
   *
   * @generated from field: google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics.MetricsType metrics_type = 7;
   */
  metricsType: Evaluation_MultiConfidenceMetrics_MetricsType;
};

/**
 * Describes the message google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics.
 * Use `create(Evaluation_MultiConfidenceMetricsSchema)` to create a new message.
 */
export const Evaluation_MultiConfidenceMetricsSchema: GenMessage<Evaluation_MultiConfidenceMetrics> = /*@__PURE__*/
  messageDesc(file_google_cloud_documentai_v1_evaluation, 1, 3);

/**
 * A type that determines how metrics should be interpreted.
 *
 * @generated from enum google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics.MetricsType
 */
export enum Evaluation_MultiConfidenceMetrics_MetricsType {
  /**
   * The metrics type is unspecified. By default, metrics without a
   * particular specification are for leaf entity types (i.e., top-level
   * entity types without child types, or child types which are not
   * parent types themselves).
   *
   * @generated from enum value: METRICS_TYPE_UNSPECIFIED = 0;
   */
  METRICS_TYPE_UNSPECIFIED = 0,

  /**
   * Indicates whether metrics for this particular label type represent an
   * aggregate of metrics for other types instead of being based on actual
   * TP/FP/FN values for the label type. Metrics for parent (i.e., non-leaf)
   * entity types are an aggregate of metrics for their children.
   *
   * @generated from enum value: AGGREGATE = 1;
   */
  AGGREGATE = 1,
}

/**
 * Describes the enum google.cloud.documentai.v1.Evaluation.MultiConfidenceMetrics.MetricsType.
 */
export const Evaluation_MultiConfidenceMetrics_MetricsTypeSchema: GenEnum<Evaluation_MultiConfidenceMetrics_MetricsType> = /*@__PURE__*/
  enumDesc(file_google_cloud_documentai_v1_evaluation, 1, 3, 0);

