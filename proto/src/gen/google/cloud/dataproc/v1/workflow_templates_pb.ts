// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/dataproc/v1/workflow_templates.proto (package google.cloud.dataproc.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { ClusterConfig } from "./clusters_pb";
import { file_google_cloud_dataproc_v1_clusters } from "./clusters_pb";
import type { FlinkJob, HadoopJob, HiveJob, JobScheduling, PigJob, PrestoJob, PySparkJob, SparkJob, SparkRJob, SparkSqlJob, TrinoJob } from "./jobs_pb";
import { file_google_cloud_dataproc_v1_jobs } from "./jobs_pb";
import type { OperationSchema } from "../../../longrunning/operations_pb";
import { file_google_longrunning_operations } from "../../../longrunning/operations_pb";
import type { Duration, EmptySchema, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_empty, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/dataproc/v1/workflow_templates.proto.
 */
export const file_google_cloud_dataproc_v1_workflow_templates: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_cloud_dataproc_v1_clusters, file_google_cloud_dataproc_v1_jobs, file_google_longrunning_operations, file_google_protobuf_duration, file_google_protobuf_empty, file_google_protobuf_timestamp]);

/**
 * A Dataproc workflow template resource.
 *
 * @generated from message google.cloud.dataproc.v1.WorkflowTemplate
 */
export type WorkflowTemplate = Message<"google.cloud.dataproc.v1.WorkflowTemplate"> & {
  /**
   * @generated from field: string id = 2;
   */
  id: string;

  /**
   * Output only. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. Used to perform a consistent read-modify-write.
   *
   * This field should be left blank for a `CreateWorkflowTemplate` request. It
   * is required for an `UpdateWorkflowTemplate` request, and must match the
   * current server version. A typical update template flow would fetch the
   * current template with a `GetWorkflowTemplate` request, which will return
   * the current template with the `version` field filled in with the
   * current server version. The user updates other fields in the template,
   * then returns it as part of the `UpdateWorkflowTemplate` request.
   *
   * @generated from field: int32 version = 3;
   */
  version: number;

  /**
   * Output only. The time template was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 4;
   */
  createTime?: Timestamp;

  /**
   * Output only. The time template was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 5;
   */
  updateTime?: Timestamp;

  /**
   * Optional. The labels to associate with this template. These labels
   * will be propagated to all jobs and clusters created by the workflow
   * instance.
   *
   * Label **keys** must contain 1 to 63 characters, and must conform to
   * [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).
   *
   * Label **values** may be empty, but, if present, must contain 1 to 63
   * characters, and must conform to
   * [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).
   *
   * No more than 32 labels can be associated with a template.
   *
   * @generated from field: map<string, string> labels = 6;
   */
  labels: { [key: string]: string };

  /**
   * Required. WorkflowTemplate scheduling information.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowTemplatePlacement placement = 7;
   */
  placement?: WorkflowTemplatePlacement;

  /**
   * Required. The Directed Acyclic Graph of Jobs to submit.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.OrderedJob jobs = 8;
   */
  jobs: OrderedJob[];

  /**
   * Optional. Template parameters whose values are substituted into the
   * template. Values for parameters must be provided when the template is
   * instantiated.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.TemplateParameter parameters = 9;
   */
  parameters: TemplateParameter[];

  /**
   * Optional. Timeout duration for the DAG of jobs, expressed in seconds (see
   * [JSON representation of
   * duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
   * The timeout duration must be from 10 minutes ("600s") to 24 hours
   * ("86400s"). The timer begins when the first job is submitted. If the
   * workflow is running at the end of the timeout period, any remaining jobs
   * are cancelled, the workflow is ended, and if the workflow was running on a
   * [managed
   * cluster](/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
   * the cluster is deleted.
   *
   * @generated from field: google.protobuf.Duration dag_timeout = 10;
   */
  dagTimeout?: Duration;

  /**
   * Optional. Encryption settings for encrypting workflow template job
   * arguments.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowTemplate.EncryptionConfig encryption_config = 11;
   */
  encryptionConfig?: WorkflowTemplate_EncryptionConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.WorkflowTemplate.
 * Use `create(WorkflowTemplateSchema)` to create a new message.
 */
export const WorkflowTemplateSchema: GenMessage<WorkflowTemplate> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 0);

/**
 * Encryption settings for encrypting workflow template job arguments.
 *
 * @generated from message google.cloud.dataproc.v1.WorkflowTemplate.EncryptionConfig
 */
export type WorkflowTemplate_EncryptionConfig = Message<"google.cloud.dataproc.v1.WorkflowTemplate.EncryptionConfig"> & {
  /**
   * Optional. The Cloud KMS key name to use for encrypting
   * workflow template job arguments.
   *
   * When this this key is provided, the following workflow template
   * [job arguments]
   * (https://cloud.google.com/dataproc/docs/concepts/workflows/use-workflows#adding_jobs_to_a_template),
   * if present, are
   * [CMEK
   * encrypted](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_workflow_template_data):
   *
   * * [FlinkJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/FlinkJob)
   * * [HadoopJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/HadoopJob)
   * * [SparkJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkJob)
   * * [SparkRJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkRJob)
   * * [PySparkJob
   * args](https://cloud.google.com/dataproc/docs/reference/rest/v1/PySparkJob)
   * * [SparkSqlJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkSqlJob)
   *   scriptVariables and queryList.queries
   * * [HiveJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/HiveJob)
   *   scriptVariables and queryList.queries
   * * [PigJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PigJob)
   *   scriptVariables and queryList.queries
   * * [PrestoJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PrestoJob)
   *   scriptVariables and queryList.queries
   *
   * @generated from field: string kms_key = 1;
   */
  kmsKey: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.WorkflowTemplate.EncryptionConfig.
 * Use `create(WorkflowTemplate_EncryptionConfigSchema)` to create a new message.
 */
export const WorkflowTemplate_EncryptionConfigSchema: GenMessage<WorkflowTemplate_EncryptionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 0, 0);

/**
 * Specifies workflow execution target.
 *
 * Either `managed_cluster` or `cluster_selector` is required.
 *
 * @generated from message google.cloud.dataproc.v1.WorkflowTemplatePlacement
 */
export type WorkflowTemplatePlacement = Message<"google.cloud.dataproc.v1.WorkflowTemplatePlacement"> & {
  /**
   * Required. Specifies where workflow executes; either on a managed
   * cluster or an existing cluster chosen by labels.
   *
   * @generated from oneof google.cloud.dataproc.v1.WorkflowTemplatePlacement.placement
   */
  placement: {
    /**
     * A cluster that is managed by the workflow.
     *
     * @generated from field: google.cloud.dataproc.v1.ManagedCluster managed_cluster = 1;
     */
    value: ManagedCluster;
    case: "managedCluster";
  } | {
    /**
     * Optional. A selector that chooses target cluster for jobs based
     * on metadata.
     *
     * The selector is evaluated at the time each job is submitted.
     *
     * @generated from field: google.cloud.dataproc.v1.ClusterSelector cluster_selector = 2;
     */
    value: ClusterSelector;
    case: "clusterSelector";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dataproc.v1.WorkflowTemplatePlacement.
 * Use `create(WorkflowTemplatePlacementSchema)` to create a new message.
 */
export const WorkflowTemplatePlacementSchema: GenMessage<WorkflowTemplatePlacement> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 1);

/**
 * Cluster that is managed by the workflow.
 *
 * @generated from message google.cloud.dataproc.v1.ManagedCluster
 */
export type ManagedCluster = Message<"google.cloud.dataproc.v1.ManagedCluster"> & {
  /**
   * Required. The cluster name prefix. A unique cluster name will be formed by
   * appending a random suffix.
   *
   * The name must contain only lower-case letters (a-z), numbers (0-9),
   * and hyphens (-). Must begin with a letter. Cannot begin or end with
   * hyphen. Must consist of between 2 and 35 characters.
   *
   * @generated from field: string cluster_name = 2;
   */
  clusterName: string;

  /**
   * Required. The cluster configuration.
   *
   * @generated from field: google.cloud.dataproc.v1.ClusterConfig config = 3;
   */
  config?: ClusterConfig;

  /**
   * Optional. The labels to associate with this cluster.
   *
   * Label keys must be between 1 and 63 characters long, and must conform to
   * the following PCRE regular expression:
   * [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}
   *
   * Label values must be between 1 and 63 characters long, and must conform to
   * the following PCRE regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}
   *
   * No more than 32 labels can be associated with a given cluster.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dataproc.v1.ManagedCluster.
 * Use `create(ManagedClusterSchema)` to create a new message.
 */
export const ManagedClusterSchema: GenMessage<ManagedCluster> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 2);

/**
 * A selector that chooses target cluster for jobs based on metadata.
 *
 * @generated from message google.cloud.dataproc.v1.ClusterSelector
 */
export type ClusterSelector = Message<"google.cloud.dataproc.v1.ClusterSelector"> & {
  /**
   * Optional. The zone where workflow process executes. This parameter does not
   * affect the selection of the cluster.
   *
   * If unspecified, the zone of the first cluster matching the selector
   * is used.
   *
   * @generated from field: string zone = 1;
   */
  zone: string;

  /**
   * Required. The cluster labels. Cluster must have all labels
   * to match.
   *
   * @generated from field: map<string, string> cluster_labels = 2;
   */
  clusterLabels: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dataproc.v1.ClusterSelector.
 * Use `create(ClusterSelectorSchema)` to create a new message.
 */
export const ClusterSelectorSchema: GenMessage<ClusterSelector> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 3);

/**
 * A job executed by the workflow.
 *
 * @generated from message google.cloud.dataproc.v1.OrderedJob
 */
export type OrderedJob = Message<"google.cloud.dataproc.v1.OrderedJob"> & {
  /**
   * Required. The step id. The id must be unique among all jobs
   * within the template.
   *
   * The step id is used as prefix for job id, as job
   * `goog-dataproc-workflow-step-id` label, and in
   * [prerequisiteStepIds][google.cloud.dataproc.v1.OrderedJob.prerequisite_step_ids]
   * field from other steps.
   *
   * The id must contain only letters (a-z, A-Z), numbers (0-9),
   * underscores (_), and hyphens (-). Cannot begin or end with underscore
   * or hyphen. Must consist of between 3 and 50 characters.
   *
   * @generated from field: string step_id = 1;
   */
  stepId: string;

  /**
   * Required. The job definition.
   *
   * @generated from oneof google.cloud.dataproc.v1.OrderedJob.job_type
   */
  jobType: {
    /**
     * Optional. Job is a Hadoop job.
     *
     * @generated from field: google.cloud.dataproc.v1.HadoopJob hadoop_job = 2;
     */
    value: HadoopJob;
    case: "hadoopJob";
  } | {
    /**
     * Optional. Job is a Spark job.
     *
     * @generated from field: google.cloud.dataproc.v1.SparkJob spark_job = 3;
     */
    value: SparkJob;
    case: "sparkJob";
  } | {
    /**
     * Optional. Job is a PySpark job.
     *
     * @generated from field: google.cloud.dataproc.v1.PySparkJob pyspark_job = 4;
     */
    value: PySparkJob;
    case: "pysparkJob";
  } | {
    /**
     * Optional. Job is a Hive job.
     *
     * @generated from field: google.cloud.dataproc.v1.HiveJob hive_job = 5;
     */
    value: HiveJob;
    case: "hiveJob";
  } | {
    /**
     * Optional. Job is a Pig job.
     *
     * @generated from field: google.cloud.dataproc.v1.PigJob pig_job = 6;
     */
    value: PigJob;
    case: "pigJob";
  } | {
    /**
     * Optional. Job is a SparkR job.
     *
     * @generated from field: google.cloud.dataproc.v1.SparkRJob spark_r_job = 11;
     */
    value: SparkRJob;
    case: "sparkRJob";
  } | {
    /**
     * Optional. Job is a SparkSql job.
     *
     * @generated from field: google.cloud.dataproc.v1.SparkSqlJob spark_sql_job = 7;
     */
    value: SparkSqlJob;
    case: "sparkSqlJob";
  } | {
    /**
     * Optional. Job is a Presto job.
     *
     * @generated from field: google.cloud.dataproc.v1.PrestoJob presto_job = 12;
     */
    value: PrestoJob;
    case: "prestoJob";
  } | {
    /**
     * Optional. Job is a Trino job.
     *
     * @generated from field: google.cloud.dataproc.v1.TrinoJob trino_job = 13;
     */
    value: TrinoJob;
    case: "trinoJob";
  } | {
    /**
     * Optional. Job is a Flink job.
     *
     * @generated from field: google.cloud.dataproc.v1.FlinkJob flink_job = 14;
     */
    value: FlinkJob;
    case: "flinkJob";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. The labels to associate with this job.
   *
   * Label keys must be between 1 and 63 characters long, and must conform to
   * the following regular expression:
   * [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}
   *
   * Label values must be between 1 and 63 characters long, and must conform to
   * the following regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}
   *
   * No more than 32 labels can be associated with a given job.
   *
   * @generated from field: map<string, string> labels = 8;
   */
  labels: { [key: string]: string };

  /**
   * Optional. Job scheduling configuration.
   *
   * @generated from field: google.cloud.dataproc.v1.JobScheduling scheduling = 9;
   */
  scheduling?: JobScheduling;

  /**
   * Optional. The optional list of prerequisite job step_ids.
   * If not specified, the job will start at the beginning of workflow.
   *
   * @generated from field: repeated string prerequisite_step_ids = 10;
   */
  prerequisiteStepIds: string[];
};

/**
 * Describes the message google.cloud.dataproc.v1.OrderedJob.
 * Use `create(OrderedJobSchema)` to create a new message.
 */
export const OrderedJobSchema: GenMessage<OrderedJob> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 4);

/**
 * A configurable parameter that replaces one or more fields in the template.
 * Parameterizable fields:
 * - Labels
 * - File uris
 * - Job properties
 * - Job arguments
 * - Script variables
 * - Main class (in HadoopJob and SparkJob)
 * - Zone (in ClusterSelector)
 *
 * @generated from message google.cloud.dataproc.v1.TemplateParameter
 */
export type TemplateParameter = Message<"google.cloud.dataproc.v1.TemplateParameter"> & {
  /**
   * Required. Parameter name.
   * The parameter name is used as the key, and paired with the
   * parameter value, which are passed to the template when the template
   * is instantiated.
   * The name must contain only capital letters (A-Z), numbers (0-9), and
   * underscores (_), and must not start with a number. The maximum length is
   * 40 characters.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. Paths to all fields that the parameter replaces.
   * A field is allowed to appear in at most one parameter's list of field
   * paths.
   *
   * A field path is similar in syntax to a
   * [google.protobuf.FieldMask][google.protobuf.FieldMask]. For example, a
   * field path that references the zone field of a workflow template's cluster
   * selector would be specified as `placement.clusterSelector.zone`.
   *
   * Also, field paths can reference fields using the following syntax:
   *
   * * Values in maps can be referenced by key:
   *     * labels['key']
   *     * placement.clusterSelector.clusterLabels['key']
   *     * placement.managedCluster.labels['key']
   *     * placement.clusterSelector.clusterLabels['key']
   *     * jobs['step-id'].labels['key']
   *
   * * Jobs in the jobs list can be referenced by step-id:
   *     * jobs['step-id'].hadoopJob.mainJarFileUri
   *     * jobs['step-id'].hiveJob.queryFileUri
   *     * jobs['step-id'].pySparkJob.mainPythonFileUri
   *     * jobs['step-id'].hadoopJob.jarFileUris[0]
   *     * jobs['step-id'].hadoopJob.archiveUris[0]
   *     * jobs['step-id'].hadoopJob.fileUris[0]
   *     * jobs['step-id'].pySparkJob.pythonFileUris[0]
   *
   * * Items in repeated fields can be referenced by a zero-based index:
   *     * jobs['step-id'].sparkJob.args[0]
   *
   * * Other examples:
   *     * jobs['step-id'].hadoopJob.properties['key']
   *     * jobs['step-id'].hadoopJob.args[0]
   *     * jobs['step-id'].hiveJob.scriptVariables['key']
   *     * jobs['step-id'].hadoopJob.mainJarFileUri
   *     * placement.clusterSelector.zone
   *
   * It may not be possible to parameterize maps and repeated fields in their
   * entirety since only individual map values and individual items in repeated
   * fields can be referenced. For example, the following field paths are
   * invalid:
   *
   * - placement.clusterSelector.clusterLabels
   * - jobs['step-id'].sparkJob.args
   *
   * @generated from field: repeated string fields = 2;
   */
  fields: string[];

  /**
   * Optional. Brief description of the parameter.
   * Must not exceed 1024 characters.
   *
   * @generated from field: string description = 3;
   */
  description: string;

  /**
   * Optional. Validation rules to be applied to this parameter's value.
   *
   * @generated from field: google.cloud.dataproc.v1.ParameterValidation validation = 4;
   */
  validation?: ParameterValidation;
};

/**
 * Describes the message google.cloud.dataproc.v1.TemplateParameter.
 * Use `create(TemplateParameterSchema)` to create a new message.
 */
export const TemplateParameterSchema: GenMessage<TemplateParameter> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 5);

/**
 * Configuration for parameter validation.
 *
 * @generated from message google.cloud.dataproc.v1.ParameterValidation
 */
export type ParameterValidation = Message<"google.cloud.dataproc.v1.ParameterValidation"> & {
  /**
   * Required. The type of validation to be performed.
   *
   * @generated from oneof google.cloud.dataproc.v1.ParameterValidation.validation_type
   */
  validationType: {
    /**
     * Validation based on regular expressions.
     *
     * @generated from field: google.cloud.dataproc.v1.RegexValidation regex = 1;
     */
    value: RegexValidation;
    case: "regex";
  } | {
    /**
     * Validation based on a list of allowed values.
     *
     * @generated from field: google.cloud.dataproc.v1.ValueValidation values = 2;
     */
    value: ValueValidation;
    case: "values";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dataproc.v1.ParameterValidation.
 * Use `create(ParameterValidationSchema)` to create a new message.
 */
export const ParameterValidationSchema: GenMessage<ParameterValidation> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 6);

/**
 * Validation based on regular expressions.
 *
 * @generated from message google.cloud.dataproc.v1.RegexValidation
 */
export type RegexValidation = Message<"google.cloud.dataproc.v1.RegexValidation"> & {
  /**
   * Required. RE2 regular expressions used to validate the parameter's value.
   * The value must match the regex in its entirety (substring
   * matches are not sufficient).
   *
   * @generated from field: repeated string regexes = 1;
   */
  regexes: string[];
};

/**
 * Describes the message google.cloud.dataproc.v1.RegexValidation.
 * Use `create(RegexValidationSchema)` to create a new message.
 */
export const RegexValidationSchema: GenMessage<RegexValidation> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 7);

/**
 * Validation based on a list of allowed values.
 *
 * @generated from message google.cloud.dataproc.v1.ValueValidation
 */
export type ValueValidation = Message<"google.cloud.dataproc.v1.ValueValidation"> & {
  /**
   * Required. List of allowed values for the parameter.
   *
   * @generated from field: repeated string values = 1;
   */
  values: string[];
};

/**
 * Describes the message google.cloud.dataproc.v1.ValueValidation.
 * Use `create(ValueValidationSchema)` to create a new message.
 */
export const ValueValidationSchema: GenMessage<ValueValidation> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 8);

/**
 * A Dataproc workflow template resource.
 *
 * @generated from message google.cloud.dataproc.v1.WorkflowMetadata
 */
export type WorkflowMetadata = Message<"google.cloud.dataproc.v1.WorkflowMetadata"> & {
  /**
   * Output only. The resource name of the workflow template as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   *
   * @generated from field: string template = 1;
   */
  template: string;

  /**
   * Output only. The version of template at the time of
   * workflow instantiation.
   *
   * @generated from field: int32 version = 2;
   */
  version: number;

  /**
   * Output only. The create cluster operation metadata.
   *
   * @generated from field: google.cloud.dataproc.v1.ClusterOperation create_cluster = 3;
   */
  createCluster?: ClusterOperation;

  /**
   * Output only. The workflow graph.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowGraph graph = 4;
   */
  graph?: WorkflowGraph;

  /**
   * Output only. The delete cluster operation metadata.
   *
   * @generated from field: google.cloud.dataproc.v1.ClusterOperation delete_cluster = 5;
   */
  deleteCluster?: ClusterOperation;

  /**
   * Output only. The workflow state.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowMetadata.State state = 6;
   */
  state: WorkflowMetadata_State;

  /**
   * Output only. The name of the target cluster.
   *
   * @generated from field: string cluster_name = 7;
   */
  clusterName: string;

  /**
   * Map from parameter names to values that were used for those parameters.
   *
   * @generated from field: map<string, string> parameters = 8;
   */
  parameters: { [key: string]: string };

  /**
   * Output only. Workflow start time.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 9;
   */
  startTime?: Timestamp;

  /**
   * Output only. Workflow end time.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 10;
   */
  endTime?: Timestamp;

  /**
   * Output only. The UUID of target cluster.
   *
   * @generated from field: string cluster_uuid = 11;
   */
  clusterUuid: string;

  /**
   * Output only. The timeout duration for the DAG of jobs, expressed in seconds
   * (see [JSON representation of
   * duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
   *
   * @generated from field: google.protobuf.Duration dag_timeout = 12;
   */
  dagTimeout?: Duration;

  /**
   * Output only. DAG start time, only set for workflows with
   * [dag_timeout][google.cloud.dataproc.v1.WorkflowMetadata.dag_timeout] when
   * DAG begins.
   *
   * @generated from field: google.protobuf.Timestamp dag_start_time = 13;
   */
  dagStartTime?: Timestamp;

  /**
   * Output only. DAG end time, only set for workflows with
   * [dag_timeout][google.cloud.dataproc.v1.WorkflowMetadata.dag_timeout] when
   * DAG ends.
   *
   * @generated from field: google.protobuf.Timestamp dag_end_time = 14;
   */
  dagEndTime?: Timestamp;
};

/**
 * Describes the message google.cloud.dataproc.v1.WorkflowMetadata.
 * Use `create(WorkflowMetadataSchema)` to create a new message.
 */
export const WorkflowMetadataSchema: GenMessage<WorkflowMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 9);

/**
 * The operation state.
 *
 * @generated from enum google.cloud.dataproc.v1.WorkflowMetadata.State
 */
export enum WorkflowMetadata_State {
  /**
   * Unused.
   *
   * @generated from enum value: UNKNOWN = 0;
   */
  UNKNOWN = 0,

  /**
   * The operation has been created.
   *
   * @generated from enum value: PENDING = 1;
   */
  PENDING = 1,

  /**
   * The operation is running.
   *
   * @generated from enum value: RUNNING = 2;
   */
  RUNNING = 2,

  /**
   * The operation is done; either cancelled or completed.
   *
   * @generated from enum value: DONE = 3;
   */
  DONE = 3,
}

/**
 * Describes the enum google.cloud.dataproc.v1.WorkflowMetadata.State.
 */
export const WorkflowMetadata_StateSchema: GenEnum<WorkflowMetadata_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataproc_v1_workflow_templates, 9, 0);

/**
 * The cluster operation triggered by a workflow.
 *
 * @generated from message google.cloud.dataproc.v1.ClusterOperation
 */
export type ClusterOperation = Message<"google.cloud.dataproc.v1.ClusterOperation"> & {
  /**
   * Output only. The id of the cluster operation.
   *
   * @generated from field: string operation_id = 1;
   */
  operationId: string;

  /**
   * Output only. Error, if operation failed.
   *
   * @generated from field: string error = 2;
   */
  error: string;

  /**
   * Output only. Indicates the operation is done.
   *
   * @generated from field: bool done = 3;
   */
  done: boolean;
};

/**
 * Describes the message google.cloud.dataproc.v1.ClusterOperation.
 * Use `create(ClusterOperationSchema)` to create a new message.
 */
export const ClusterOperationSchema: GenMessage<ClusterOperation> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 10);

/**
 * The workflow graph.
 *
 * @generated from message google.cloud.dataproc.v1.WorkflowGraph
 */
export type WorkflowGraph = Message<"google.cloud.dataproc.v1.WorkflowGraph"> & {
  /**
   * Output only. The workflow nodes.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.WorkflowNode nodes = 1;
   */
  nodes: WorkflowNode[];
};

/**
 * Describes the message google.cloud.dataproc.v1.WorkflowGraph.
 * Use `create(WorkflowGraphSchema)` to create a new message.
 */
export const WorkflowGraphSchema: GenMessage<WorkflowGraph> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 11);

/**
 * The workflow node.
 *
 * @generated from message google.cloud.dataproc.v1.WorkflowNode
 */
export type WorkflowNode = Message<"google.cloud.dataproc.v1.WorkflowNode"> & {
  /**
   * Output only. The name of the node.
   *
   * @generated from field: string step_id = 1;
   */
  stepId: string;

  /**
   * Output only. Node's prerequisite nodes.
   *
   * @generated from field: repeated string prerequisite_step_ids = 2;
   */
  prerequisiteStepIds: string[];

  /**
   * Output only. The job id; populated after the node enters RUNNING state.
   *
   * @generated from field: string job_id = 3;
   */
  jobId: string;

  /**
   * Output only. The node state.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowNode.NodeState state = 5;
   */
  state: WorkflowNode_NodeState;

  /**
   * Output only. The error detail.
   *
   * @generated from field: string error = 6;
   */
  error: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.WorkflowNode.
 * Use `create(WorkflowNodeSchema)` to create a new message.
 */
export const WorkflowNodeSchema: GenMessage<WorkflowNode> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 12);

/**
 * The workflow node state.
 *
 * @generated from enum google.cloud.dataproc.v1.WorkflowNode.NodeState
 */
export enum WorkflowNode_NodeState {
  /**
   * State is unspecified.
   *
   * @generated from enum value: NODE_STATE_UNSPECIFIED = 0;
   */
  NODE_STATE_UNSPECIFIED = 0,

  /**
   * The node is awaiting prerequisite node to finish.
   *
   * @generated from enum value: BLOCKED = 1;
   */
  BLOCKED = 1,

  /**
   * The node is runnable but not running.
   *
   * @generated from enum value: RUNNABLE = 2;
   */
  RUNNABLE = 2,

  /**
   * The node is running.
   *
   * @generated from enum value: RUNNING = 3;
   */
  RUNNING = 3,

  /**
   * The node completed successfully.
   *
   * @generated from enum value: COMPLETED = 4;
   */
  COMPLETED = 4,

  /**
   * The node failed. A node can be marked FAILED because
   * its ancestor or peer failed.
   *
   * @generated from enum value: FAILED = 5;
   */
  FAILED = 5,
}

/**
 * Describes the enum google.cloud.dataproc.v1.WorkflowNode.NodeState.
 */
export const WorkflowNode_NodeStateSchema: GenEnum<WorkflowNode_NodeState> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataproc_v1_workflow_templates, 12, 0);

/**
 * A request to create a workflow template.
 *
 * @generated from message google.cloud.dataproc.v1.CreateWorkflowTemplateRequest
 */
export type CreateWorkflowTemplateRequest = Message<"google.cloud.dataproc.v1.CreateWorkflowTemplateRequest"> & {
  /**
   * Required. The resource name of the region or location, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.create`, the resource name of the
   *   region has the following format:
   *   `projects/{project_id}/regions/{region}`
   *
   * * For `projects.locations.workflowTemplates.create`, the resource name of
   *   the location has the following format:
   *   `projects/{project_id}/locations/{location}`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. The Dataproc workflow template to create.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowTemplate template = 2;
   */
  template?: WorkflowTemplate;
};

/**
 * Describes the message google.cloud.dataproc.v1.CreateWorkflowTemplateRequest.
 * Use `create(CreateWorkflowTemplateRequestSchema)` to create a new message.
 */
export const CreateWorkflowTemplateRequestSchema: GenMessage<CreateWorkflowTemplateRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 13);

/**
 * A request to fetch a workflow template.
 *
 * @generated from message google.cloud.dataproc.v1.GetWorkflowTemplateRequest
 */
export type GetWorkflowTemplateRequest = Message<"google.cloud.dataproc.v1.GetWorkflowTemplateRequest"> & {
  /**
   * Required. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.get`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates.get`, the resource name of the
   *   template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. The version of workflow template to retrieve. Only previously
   * instantiated versions can be retrieved.
   *
   * If unspecified, retrieves the current version.
   *
   * @generated from field: int32 version = 2;
   */
  version: number;
};

/**
 * Describes the message google.cloud.dataproc.v1.GetWorkflowTemplateRequest.
 * Use `create(GetWorkflowTemplateRequestSchema)` to create a new message.
 */
export const GetWorkflowTemplateRequestSchema: GenMessage<GetWorkflowTemplateRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 14);

/**
 * A request to instantiate a workflow template.
 *
 * @generated from message google.cloud.dataproc.v1.InstantiateWorkflowTemplateRequest
 */
export type InstantiateWorkflowTemplateRequest = Message<"google.cloud.dataproc.v1.InstantiateWorkflowTemplateRequest"> & {
  /**
   * Required. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.instantiate`, the resource name
   * of the template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates.instantiate`, the resource name
   *   of the template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. The version of workflow template to instantiate. If specified,
   * the workflow will be instantiated only if the current version of
   * the workflow template has the supplied version.
   *
   * This option cannot be used to instantiate a previous version of
   * workflow template.
   *
   * @generated from field: int32 version = 2;
   */
  version: number;

  /**
   * Optional. A tag that prevents multiple concurrent workflow
   * instances with the same tag from running. This mitigates risk of
   * concurrent instances started due to retries.
   *
   * It is recommended to always set this value to a
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier).
   *
   * The tag must contain only letters (a-z, A-Z), numbers (0-9),
   * underscores (_), and hyphens (-). The maximum length is 40 characters.
   *
   * @generated from field: string request_id = 5;
   */
  requestId: string;

  /**
   * Optional. Map from parameter names to values that should be used for those
   * parameters. Values may not exceed 1000 characters.
   *
   * @generated from field: map<string, string> parameters = 6;
   */
  parameters: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dataproc.v1.InstantiateWorkflowTemplateRequest.
 * Use `create(InstantiateWorkflowTemplateRequestSchema)` to create a new message.
 */
export const InstantiateWorkflowTemplateRequestSchema: GenMessage<InstantiateWorkflowTemplateRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 15);

/**
 * A request to instantiate an inline workflow template.
 *
 * @generated from message google.cloud.dataproc.v1.InstantiateInlineWorkflowTemplateRequest
 */
export type InstantiateInlineWorkflowTemplateRequest = Message<"google.cloud.dataproc.v1.InstantiateInlineWorkflowTemplateRequest"> & {
  /**
   * Required. The resource name of the region or location, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates,instantiateinline`, the resource
   *   name of the region has the following format:
   *   `projects/{project_id}/regions/{region}`
   *
   * * For `projects.locations.workflowTemplates.instantiateinline`, the
   *   resource name of the location has the following format:
   *   `projects/{project_id}/locations/{location}`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. The workflow template to instantiate.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowTemplate template = 2;
   */
  template?: WorkflowTemplate;

  /**
   * Optional. A tag that prevents multiple concurrent workflow
   * instances with the same tag from running. This mitigates risk of
   * concurrent instances started due to retries.
   *
   * It is recommended to always set this value to a
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier).
   *
   * The tag must contain only letters (a-z, A-Z), numbers (0-9),
   * underscores (_), and hyphens (-). The maximum length is 40 characters.
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.InstantiateInlineWorkflowTemplateRequest.
 * Use `create(InstantiateInlineWorkflowTemplateRequestSchema)` to create a new message.
 */
export const InstantiateInlineWorkflowTemplateRequestSchema: GenMessage<InstantiateInlineWorkflowTemplateRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 16);

/**
 * A request to update a workflow template.
 *
 * @generated from message google.cloud.dataproc.v1.UpdateWorkflowTemplateRequest
 */
export type UpdateWorkflowTemplateRequest = Message<"google.cloud.dataproc.v1.UpdateWorkflowTemplateRequest"> & {
  /**
   * Required. The updated workflow template.
   *
   * The `template.version` field must match the current version.
   *
   * @generated from field: google.cloud.dataproc.v1.WorkflowTemplate template = 1;
   */
  template?: WorkflowTemplate;
};

/**
 * Describes the message google.cloud.dataproc.v1.UpdateWorkflowTemplateRequest.
 * Use `create(UpdateWorkflowTemplateRequestSchema)` to create a new message.
 */
export const UpdateWorkflowTemplateRequestSchema: GenMessage<UpdateWorkflowTemplateRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 17);

/**
 * A request to list workflow templates in a project.
 *
 * @generated from message google.cloud.dataproc.v1.ListWorkflowTemplatesRequest
 */
export type ListWorkflowTemplatesRequest = Message<"google.cloud.dataproc.v1.ListWorkflowTemplatesRequest"> & {
  /**
   * Required. The resource name of the region or location, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates,list`, the resource
   *   name of the region has the following format:
   *   `projects/{project_id}/regions/{region}`
   *
   * * For `projects.locations.workflowTemplates.list`, the
   *   resource name of the location has the following format:
   *   `projects/{project_id}/locations/{location}`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Optional. The maximum number of results to return in each response.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * Optional. The page token, returned by a previous call, to request the
   * next page of results.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.ListWorkflowTemplatesRequest.
 * Use `create(ListWorkflowTemplatesRequestSchema)` to create a new message.
 */
export const ListWorkflowTemplatesRequestSchema: GenMessage<ListWorkflowTemplatesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 18);

/**
 * A response to a request to list workflow templates in a project.
 *
 * @generated from message google.cloud.dataproc.v1.ListWorkflowTemplatesResponse
 */
export type ListWorkflowTemplatesResponse = Message<"google.cloud.dataproc.v1.ListWorkflowTemplatesResponse"> & {
  /**
   * Output only. WorkflowTemplates list.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.WorkflowTemplate templates = 1;
   */
  templates: WorkflowTemplate[];

  /**
   * Output only. This token is included in the response if there are more
   * results to fetch. To fetch additional results, provide this value as the
   * page_token in a subsequent <code>ListWorkflowTemplatesRequest</code>.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Output only. List of workflow templates that could not be included in the
   * response. Attempting to get one of these resources may indicate why it was
   * not included in the list response.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.dataproc.v1.ListWorkflowTemplatesResponse.
 * Use `create(ListWorkflowTemplatesResponseSchema)` to create a new message.
 */
export const ListWorkflowTemplatesResponseSchema: GenMessage<ListWorkflowTemplatesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 19);

/**
 * A request to delete a workflow template.
 *
 * Currently started workflows will remain running.
 *
 * @generated from message google.cloud.dataproc.v1.DeleteWorkflowTemplateRequest
 */
export type DeleteWorkflowTemplateRequest = Message<"google.cloud.dataproc.v1.DeleteWorkflowTemplateRequest"> & {
  /**
   * Required. The resource name of the workflow template, as described
   * in https://cloud.google.com/apis/design/resource_names.
   *
   * * For `projects.regions.workflowTemplates.delete`, the resource name
   * of the template has the following format:
   *   `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`
   *
   * * For `projects.locations.workflowTemplates.instantiate`, the resource name
   *   of the template has the following format:
   *   `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. The version of workflow template to delete. If specified,
   * will only delete the template if the current server version matches
   * specified version.
   *
   * @generated from field: int32 version = 2;
   */
  version: number;
};

/**
 * Describes the message google.cloud.dataproc.v1.DeleteWorkflowTemplateRequest.
 * Use `create(DeleteWorkflowTemplateRequestSchema)` to create a new message.
 */
export const DeleteWorkflowTemplateRequestSchema: GenMessage<DeleteWorkflowTemplateRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_workflow_templates, 20);

/**
 * The API interface for managing Workflow Templates in the
 * Dataproc API.
 *
 * @generated from service google.cloud.dataproc.v1.WorkflowTemplateService
 */
export const WorkflowTemplateService: GenService<{
  /**
   * Creates new workflow template.
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.CreateWorkflowTemplate
   */
  createWorkflowTemplate: {
    methodKind: "unary";
    input: typeof CreateWorkflowTemplateRequestSchema;
    output: typeof WorkflowTemplateSchema;
  },
  /**
   * Retrieves the latest workflow template.
   *
   * Can retrieve previously instantiated template by specifying optional
   * version parameter.
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.GetWorkflowTemplate
   */
  getWorkflowTemplate: {
    methodKind: "unary";
    input: typeof GetWorkflowTemplateRequestSchema;
    output: typeof WorkflowTemplateSchema;
  },
  /**
   * Instantiates a template and begins execution.
   *
   * The returned Operation can be used to track execution of
   * workflow by polling
   * [operations.get][google.longrunning.Operations.GetOperation].
   * The Operation will complete when entire workflow is finished.
   *
   * The running workflow can be aborted via
   * [operations.cancel][google.longrunning.Operations.CancelOperation].
   * This will cause any inflight jobs to be cancelled and workflow-owned
   * clusters to be deleted.
   *
   * The [Operation.metadata][google.longrunning.Operation.metadata] will be
   * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
   * Also see [Using
   * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
   *
   * On successful completion,
   * [Operation.response][google.longrunning.Operation.response] will be
   * [Empty][google.protobuf.Empty].
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.InstantiateWorkflowTemplate
   */
  instantiateWorkflowTemplate: {
    methodKind: "unary";
    input: typeof InstantiateWorkflowTemplateRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Instantiates a template and begins execution.
   *
   * This method is equivalent to executing the sequence
   * [CreateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.CreateWorkflowTemplate],
   * [InstantiateWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.InstantiateWorkflowTemplate],
   * [DeleteWorkflowTemplate][google.cloud.dataproc.v1.WorkflowTemplateService.DeleteWorkflowTemplate].
   *
   * The returned Operation can be used to track execution of
   * workflow by polling
   * [operations.get][google.longrunning.Operations.GetOperation].
   * The Operation will complete when entire workflow is finished.
   *
   * The running workflow can be aborted via
   * [operations.cancel][google.longrunning.Operations.CancelOperation].
   * This will cause any inflight jobs to be cancelled and workflow-owned
   * clusters to be deleted.
   *
   * The [Operation.metadata][google.longrunning.Operation.metadata] will be
   * [WorkflowMetadata](https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#workflowmetadata).
   * Also see [Using
   * WorkflowMetadata](https://cloud.google.com/dataproc/docs/concepts/workflows/debugging#using_workflowmetadata).
   *
   * On successful completion,
   * [Operation.response][google.longrunning.Operation.response] will be
   * [Empty][google.protobuf.Empty].
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.InstantiateInlineWorkflowTemplate
   */
  instantiateInlineWorkflowTemplate: {
    methodKind: "unary";
    input: typeof InstantiateInlineWorkflowTemplateRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates (replaces) workflow template. The updated template
   * must contain version that matches the current server version.
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.UpdateWorkflowTemplate
   */
  updateWorkflowTemplate: {
    methodKind: "unary";
    input: typeof UpdateWorkflowTemplateRequestSchema;
    output: typeof WorkflowTemplateSchema;
  },
  /**
   * Lists workflows that match the specified filter in the request.
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.ListWorkflowTemplates
   */
  listWorkflowTemplates: {
    methodKind: "unary";
    input: typeof ListWorkflowTemplatesRequestSchema;
    output: typeof ListWorkflowTemplatesResponseSchema;
  },
  /**
   * Deletes a workflow template. It does not cancel in-progress workflows.
   *
   * @generated from rpc google.cloud.dataproc.v1.WorkflowTemplateService.DeleteWorkflowTemplate
   */
  deleteWorkflowTemplate: {
    methodKind: "unary";
    input: typeof DeleteWorkflowTemplateRequestSchema;
    output: typeof EmptySchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_dataproc_v1_workflow_templates, 0);

