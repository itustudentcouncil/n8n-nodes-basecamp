// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/dataproc/v1/shared.proto (package google.cloud.dataproc.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Duration, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/dataproc/v1/shared.proto.
 */
export const file_google_cloud_dataproc_v1_shared: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_protobuf_duration, file_google_protobuf_timestamp]);

/**
 * Runtime configuration for a workload.
 *
 * @generated from message google.cloud.dataproc.v1.RuntimeConfig
 */
export type RuntimeConfig = Message<"google.cloud.dataproc.v1.RuntimeConfig"> & {
  /**
   * Optional. Version of the batch runtime.
   *
   * @generated from field: string version = 1;
   */
  version: string;

  /**
   * Optional. Optional custom container image for the job runtime environment.
   * If not specified, a default container image will be used.
   *
   * @generated from field: string container_image = 2;
   */
  containerImage: string;

  /**
   * Optional. A mapping of property names to values, which are used to
   * configure workload execution.
   *
   * @generated from field: map<string, string> properties = 3;
   */
  properties: { [key: string]: string };

  /**
   * Optional. Dependency repository configuration.
   *
   * @generated from field: google.cloud.dataproc.v1.RepositoryConfig repository_config = 5;
   */
  repositoryConfig?: RepositoryConfig;

  /**
   * Optional. Autotuning configuration of the workload.
   *
   * @generated from field: google.cloud.dataproc.v1.AutotuningConfig autotuning_config = 6;
   */
  autotuningConfig?: AutotuningConfig;

  /**
   * Optional. Cohort identifier. Identifies families of the workloads having
   * the same shape, e.g. daily ETL jobs.
   *
   * @generated from field: string cohort = 7;
   */
  cohort: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.RuntimeConfig.
 * Use `create(RuntimeConfigSchema)` to create a new message.
 */
export const RuntimeConfigSchema: GenMessage<RuntimeConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 0);

/**
 * Environment configuration for a workload.
 *
 * @generated from message google.cloud.dataproc.v1.EnvironmentConfig
 */
export type EnvironmentConfig = Message<"google.cloud.dataproc.v1.EnvironmentConfig"> & {
  /**
   * Optional. Execution configuration for a workload.
   *
   * @generated from field: google.cloud.dataproc.v1.ExecutionConfig execution_config = 1;
   */
  executionConfig?: ExecutionConfig;

  /**
   * Optional. Peripherals configuration that workload has access to.
   *
   * @generated from field: google.cloud.dataproc.v1.PeripheralsConfig peripherals_config = 2;
   */
  peripheralsConfig?: PeripheralsConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.EnvironmentConfig.
 * Use `create(EnvironmentConfigSchema)` to create a new message.
 */
export const EnvironmentConfigSchema: GenMessage<EnvironmentConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 1);

/**
 * Execution configuration for a workload.
 *
 * @generated from message google.cloud.dataproc.v1.ExecutionConfig
 */
export type ExecutionConfig = Message<"google.cloud.dataproc.v1.ExecutionConfig"> & {
  /**
   * Optional. Service account that used to execute workload.
   *
   * @generated from field: string service_account = 2;
   */
  serviceAccount: string;

  /**
   * Network configuration for workload execution.
   *
   * @generated from oneof google.cloud.dataproc.v1.ExecutionConfig.network
   */
  network: {
    /**
     * Optional. Network URI to connect workload to.
     *
     * @generated from field: string network_uri = 4;
     */
    value: string;
    case: "networkUri";
  } | {
    /**
     * Optional. Subnetwork URI to connect workload to.
     *
     * @generated from field: string subnetwork_uri = 5;
     */
    value: string;
    case: "subnetworkUri";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. Tags used for network traffic control.
   *
   * @generated from field: repeated string network_tags = 6;
   */
  networkTags: string[];

  /**
   * Optional. The Cloud KMS key to use for encryption.
   *
   * @generated from field: string kms_key = 7;
   */
  kmsKey: string;

  /**
   * Optional. Applies to sessions only. The duration to keep the session alive
   * while it's idling. Exceeding this threshold causes the session to
   * terminate. This field cannot be set on a batch workload. Minimum value is
   * 10 minutes; maximum value is 14 days (see JSON representation of
   * [Duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
   * Defaults to 1 hour if not set.
   * If both `ttl` and `idle_ttl` are specified for an interactive session,
   * the conditions are treated as `OR` conditions: the workload will be
   * terminated when it has been idle for `idle_ttl` or when `ttl` has been
   * exceeded, whichever occurs first.
   *
   * @generated from field: google.protobuf.Duration idle_ttl = 8;
   */
  idleTtl?: Duration;

  /**
   * Optional. The duration after which the workload will be terminated,
   * specified as the JSON representation for
   * [Duration](https://protobuf.dev/programming-guides/proto3/#json).
   * When the workload exceeds this duration, it will be unconditionally
   * terminated without waiting for ongoing work to finish. If `ttl` is not
   * specified for a batch workload, the workload will be allowed to run until
   * it exits naturally (or run forever without exiting). If `ttl` is not
   * specified for an interactive session, it defaults to 24 hours. If `ttl` is
   * not specified for a batch that uses 2.1+ runtime version, it defaults to 4
   * hours. Minimum value is 10 minutes; maximum value is 14 days. If both `ttl`
   * and `idle_ttl` are specified (for an interactive session), the conditions
   * are treated as `OR` conditions: the workload will be terminated when it has
   * been idle for `idle_ttl` or when `ttl` has been exceeded, whichever occurs
   * first.
   *
   * @generated from field: google.protobuf.Duration ttl = 9;
   */
  ttl?: Duration;

  /**
   * Optional. A Cloud Storage bucket used to stage workload dependencies,
   * config files, and store workload output and other ephemeral data, such as
   * Spark history files. If you do not specify a staging bucket, Cloud Dataproc
   * will determine a Cloud Storage location according to the region where your
   * workload is running, and then create and manage project-level, per-location
   * staging and temporary buckets.
   * **This field requires a Cloud Storage bucket name, not a `gs://...` URI to
   * a Cloud Storage bucket.**
   *
   * @generated from field: string staging_bucket = 10;
   */
  stagingBucket: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.ExecutionConfig.
 * Use `create(ExecutionConfigSchema)` to create a new message.
 */
export const ExecutionConfigSchema: GenMessage<ExecutionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 2);

/**
 * Spark History Server configuration for the workload.
 *
 * @generated from message google.cloud.dataproc.v1.SparkHistoryServerConfig
 */
export type SparkHistoryServerConfig = Message<"google.cloud.dataproc.v1.SparkHistoryServerConfig"> & {
  /**
   * Optional. Resource name of an existing Dataproc Cluster to act as a Spark
   * History Server for the workload.
   *
   * Example:
   *
   * * `projects/[project_id]/regions/[region]/clusters/[cluster_name]`
   *
   * @generated from field: string dataproc_cluster = 1;
   */
  dataprocCluster: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.SparkHistoryServerConfig.
 * Use `create(SparkHistoryServerConfigSchema)` to create a new message.
 */
export const SparkHistoryServerConfigSchema: GenMessage<SparkHistoryServerConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 3);

/**
 * Auxiliary services configuration for a workload.
 *
 * @generated from message google.cloud.dataproc.v1.PeripheralsConfig
 */
export type PeripheralsConfig = Message<"google.cloud.dataproc.v1.PeripheralsConfig"> & {
  /**
   * Optional. Resource name of an existing Dataproc Metastore service.
   *
   * Example:
   *
   * * `projects/[project_id]/locations/[region]/services/[service_id]`
   *
   * @generated from field: string metastore_service = 1;
   */
  metastoreService: string;

  /**
   * Optional. The Spark History Server configuration for the workload.
   *
   * @generated from field: google.cloud.dataproc.v1.SparkHistoryServerConfig spark_history_server_config = 2;
   */
  sparkHistoryServerConfig?: SparkHistoryServerConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.PeripheralsConfig.
 * Use `create(PeripheralsConfigSchema)` to create a new message.
 */
export const PeripheralsConfigSchema: GenMessage<PeripheralsConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 4);

/**
 * Runtime information about workload execution.
 *
 * @generated from message google.cloud.dataproc.v1.RuntimeInfo
 */
export type RuntimeInfo = Message<"google.cloud.dataproc.v1.RuntimeInfo"> & {
  /**
   * Output only. Map of remote access endpoints (such as web interfaces and
   * APIs) to their URIs.
   *
   * @generated from field: map<string, string> endpoints = 1;
   */
  endpoints: { [key: string]: string };

  /**
   * Output only. A URI pointing to the location of the stdout and stderr of the
   * workload.
   *
   * @generated from field: string output_uri = 2;
   */
  outputUri: string;

  /**
   * Output only. A URI pointing to the location of the diagnostics tarball.
   *
   * @generated from field: string diagnostic_output_uri = 3;
   */
  diagnosticOutputUri: string;

  /**
   * Output only. Approximate workload resource usage, calculated when
   * the workload completes (see [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing)).
   *
   * **Note:** This metric calculation may change in the future, for
   * example, to capture cumulative workload resource
   * consumption during workload execution (see the
   * [Dataproc Serverless release notes]
   * (https://cloud.google.com/dataproc-serverless/docs/release-notes)
   * for announcements, changes, fixes
   * and other Dataproc developments).
   *
   * @generated from field: google.cloud.dataproc.v1.UsageMetrics approximate_usage = 6;
   */
  approximateUsage?: UsageMetrics;

  /**
   * Output only. Snapshot of current workload resource usage.
   *
   * @generated from field: google.cloud.dataproc.v1.UsageSnapshot current_usage = 7;
   */
  currentUsage?: UsageSnapshot;
};

/**
 * Describes the message google.cloud.dataproc.v1.RuntimeInfo.
 * Use `create(RuntimeInfoSchema)` to create a new message.
 */
export const RuntimeInfoSchema: GenMessage<RuntimeInfo> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 5);

/**
 * Usage metrics represent approximate total resources consumed by a workload.
 *
 * @generated from message google.cloud.dataproc.v1.UsageMetrics
 */
export type UsageMetrics = Message<"google.cloud.dataproc.v1.UsageMetrics"> & {
  /**
   * Optional. DCU (Dataproc Compute Units) usage in (`milliDCU` x `seconds`)
   * (see [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing)).
   *
   * @generated from field: int64 milli_dcu_seconds = 1;
   */
  milliDcuSeconds: bigint;

  /**
   * Optional. Shuffle storage usage in (`GB` x `seconds`) (see
   * [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing)).
   *
   * @generated from field: int64 shuffle_storage_gb_seconds = 2;
   */
  shuffleStorageGbSeconds: bigint;

  /**
   * Optional. Accelerator usage in (`milliAccelerator` x `seconds`) (see
   * [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing)).
   *
   * @generated from field: int64 milli_accelerator_seconds = 3;
   */
  milliAcceleratorSeconds: bigint;

  /**
   * Optional. Accelerator type being used, if any
   *
   * @generated from field: string accelerator_type = 4;
   */
  acceleratorType: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.UsageMetrics.
 * Use `create(UsageMetricsSchema)` to create a new message.
 */
export const UsageMetricsSchema: GenMessage<UsageMetrics> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 6);

/**
 * The usage snapshot represents the resources consumed by a workload at a
 * specified time.
 *
 * @generated from message google.cloud.dataproc.v1.UsageSnapshot
 */
export type UsageSnapshot = Message<"google.cloud.dataproc.v1.UsageSnapshot"> & {
  /**
   * Optional. Milli (one-thousandth) Dataproc Compute Units (DCUs) (see
   * [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing)).
   *
   * @generated from field: int64 milli_dcu = 1;
   */
  milliDcu: bigint;

  /**
   * Optional. Shuffle Storage in gigabytes (GB). (see [Dataproc Serverless
   * pricing] (https://cloud.google.com/dataproc-serverless/pricing))
   *
   * @generated from field: int64 shuffle_storage_gb = 2;
   */
  shuffleStorageGb: bigint;

  /**
   * Optional. Milli (one-thousandth) Dataproc Compute Units (DCUs) charged at
   * premium tier (see [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing)).
   *
   * @generated from field: int64 milli_dcu_premium = 4;
   */
  milliDcuPremium: bigint;

  /**
   * Optional. Shuffle Storage in gigabytes (GB) charged at premium tier. (see
   * [Dataproc Serverless pricing]
   * (https://cloud.google.com/dataproc-serverless/pricing))
   *
   * @generated from field: int64 shuffle_storage_gb_premium = 5;
   */
  shuffleStorageGbPremium: bigint;

  /**
   * Optional. Milli (one-thousandth) accelerator. (see [Dataproc
   * Serverless pricing] (https://cloud.google.com/dataproc-serverless/pricing))
   *
   * @generated from field: int64 milli_accelerator = 6;
   */
  milliAccelerator: bigint;

  /**
   * Optional. Accelerator type being used, if any
   *
   * @generated from field: string accelerator_type = 7;
   */
  acceleratorType: string;

  /**
   * Optional. The timestamp of the usage snapshot.
   *
   * @generated from field: google.protobuf.Timestamp snapshot_time = 3;
   */
  snapshotTime?: Timestamp;
};

/**
 * Describes the message google.cloud.dataproc.v1.UsageSnapshot.
 * Use `create(UsageSnapshotSchema)` to create a new message.
 */
export const UsageSnapshotSchema: GenMessage<UsageSnapshot> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 7);

/**
 * The cluster's GKE config.
 *
 * @generated from message google.cloud.dataproc.v1.GkeClusterConfig
 */
export type GkeClusterConfig = Message<"google.cloud.dataproc.v1.GkeClusterConfig"> & {
  /**
   * Optional. A target GKE cluster to deploy to. It must be in the same project
   * and region as the Dataproc cluster (the GKE cluster can be zonal or
   * regional). Format:
   * 'projects/{project}/locations/{location}/clusters/{cluster_id}'
   *
   * @generated from field: string gke_cluster_target = 2;
   */
  gkeClusterTarget: string;

  /**
   * Optional. GKE node pools where workloads will be scheduled. At least one
   * node pool must be assigned the `DEFAULT`
   * [GkeNodePoolTarget.Role][google.cloud.dataproc.v1.GkeNodePoolTarget.Role].
   * If a `GkeNodePoolTarget` is not specified, Dataproc constructs a `DEFAULT`
   * `GkeNodePoolTarget`. Each role can be given to only one
   * `GkeNodePoolTarget`. All node pools must have the same location settings.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.GkeNodePoolTarget node_pool_target = 3;
   */
  nodePoolTarget: GkeNodePoolTarget[];
};

/**
 * Describes the message google.cloud.dataproc.v1.GkeClusterConfig.
 * Use `create(GkeClusterConfigSchema)` to create a new message.
 */
export const GkeClusterConfigSchema: GenMessage<GkeClusterConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 8);

/**
 * The configuration for running the Dataproc cluster on Kubernetes.
 *
 * @generated from message google.cloud.dataproc.v1.KubernetesClusterConfig
 */
export type KubernetesClusterConfig = Message<"google.cloud.dataproc.v1.KubernetesClusterConfig"> & {
  /**
   * Optional. A namespace within the Kubernetes cluster to deploy into. If this
   * namespace does not exist, it is created. If it exists, Dataproc verifies
   * that another Dataproc VirtualCluster is not installed into it. If not
   * specified, the name of the Dataproc Cluster is used.
   *
   * @generated from field: string kubernetes_namespace = 1;
   */
  kubernetesNamespace: string;

  /**
   * @generated from oneof google.cloud.dataproc.v1.KubernetesClusterConfig.config
   */
  config: {
    /**
     * Required. The configuration for running the Dataproc cluster on GKE.
     *
     * @generated from field: google.cloud.dataproc.v1.GkeClusterConfig gke_cluster_config = 2;
     */
    value: GkeClusterConfig;
    case: "gkeClusterConfig";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. The software configuration for this Dataproc cluster running on
   * Kubernetes.
   *
   * @generated from field: google.cloud.dataproc.v1.KubernetesSoftwareConfig kubernetes_software_config = 3;
   */
  kubernetesSoftwareConfig?: KubernetesSoftwareConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.KubernetesClusterConfig.
 * Use `create(KubernetesClusterConfigSchema)` to create a new message.
 */
export const KubernetesClusterConfigSchema: GenMessage<KubernetesClusterConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 9);

/**
 * The software configuration for this Dataproc cluster running on Kubernetes.
 *
 * @generated from message google.cloud.dataproc.v1.KubernetesSoftwareConfig
 */
export type KubernetesSoftwareConfig = Message<"google.cloud.dataproc.v1.KubernetesSoftwareConfig"> & {
  /**
   * The components that should be installed in this Dataproc cluster. The key
   * must be a string from the KubernetesComponent enumeration. The value is
   * the version of the software to be installed.
   * At least one entry must be specified.
   *
   * @generated from field: map<string, string> component_version = 1;
   */
  componentVersion: { [key: string]: string };

  /**
   * The properties to set on daemon config files.
   *
   * Property keys are specified in `prefix:property` format, for example
   * `spark:spark.kubernetes.container.image`. The following are supported
   * prefixes and their mappings:
   *
   * * spark:  `spark-defaults.conf`
   *
   * For more information, see [Cluster
   * properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
   *
   * @generated from field: map<string, string> properties = 2;
   */
  properties: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dataproc.v1.KubernetesSoftwareConfig.
 * Use `create(KubernetesSoftwareConfigSchema)` to create a new message.
 */
export const KubernetesSoftwareConfigSchema: GenMessage<KubernetesSoftwareConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 10);

/**
 * GKE node pools that Dataproc workloads run on.
 *
 * @generated from message google.cloud.dataproc.v1.GkeNodePoolTarget
 */
export type GkeNodePoolTarget = Message<"google.cloud.dataproc.v1.GkeNodePoolTarget"> & {
  /**
   * Required. The target GKE node pool.
   * Format:
   * 'projects/{project}/locations/{location}/clusters/{cluster}/nodePools/{node_pool}'
   *
   * @generated from field: string node_pool = 1;
   */
  nodePool: string;

  /**
   * Required. The roles associated with the GKE node pool.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.GkeNodePoolTarget.Role roles = 2;
   */
  roles: GkeNodePoolTarget_Role[];

  /**
   * Input only. The configuration for the GKE node pool.
   *
   * If specified, Dataproc attempts to create a node pool with the
   * specified shape. If one with the same name already exists, it is
   * verified against all specified fields. If a field differs, the
   * virtual cluster creation will fail.
   *
   * If omitted, any node pool with the specified name is used. If a
   * node pool with the specified name does not exist, Dataproc create a
   * node pool with default values.
   *
   * This is an input only field. It will not be returned by the API.
   *
   * @generated from field: google.cloud.dataproc.v1.GkeNodePoolConfig node_pool_config = 3;
   */
  nodePoolConfig?: GkeNodePoolConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.GkeNodePoolTarget.
 * Use `create(GkeNodePoolTargetSchema)` to create a new message.
 */
export const GkeNodePoolTargetSchema: GenMessage<GkeNodePoolTarget> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 11);

/**
 * `Role` specifies the tasks that will run on the node pool. Roles can be
 * specific to workloads. Exactly one
 * [GkeNodePoolTarget][google.cloud.dataproc.v1.GkeNodePoolTarget] within the
 * virtual cluster must have the `DEFAULT` role, which is used to run all
 * workloads that are not associated with a node pool.
 *
 * @generated from enum google.cloud.dataproc.v1.GkeNodePoolTarget.Role
 */
export enum GkeNodePoolTarget_Role {
  /**
   * Role is unspecified.
   *
   * @generated from enum value: ROLE_UNSPECIFIED = 0;
   */
  ROLE_UNSPECIFIED = 0,

  /**
   * At least one node pool must have the `DEFAULT` role.
   * Work assigned to a role that is not associated with a node pool
   * is assigned to the node pool with the `DEFAULT` role. For example,
   * work assigned to the `CONTROLLER` role will be assigned to the node pool
   * with the `DEFAULT` role if no node pool has the `CONTROLLER` role.
   *
   * @generated from enum value: DEFAULT = 1;
   */
  DEFAULT = 1,

  /**
   * Run work associated with the Dataproc control plane (for example,
   * controllers and webhooks). Very low resource requirements.
   *
   * @generated from enum value: CONTROLLER = 2;
   */
  CONTROLLER = 2,

  /**
   * Run work associated with a Spark driver of a job.
   *
   * @generated from enum value: SPARK_DRIVER = 3;
   */
  SPARK_DRIVER = 3,

  /**
   * Run work associated with a Spark executor of a job.
   *
   * @generated from enum value: SPARK_EXECUTOR = 4;
   */
  SPARK_EXECUTOR = 4,
}

/**
 * Describes the enum google.cloud.dataproc.v1.GkeNodePoolTarget.Role.
 */
export const GkeNodePoolTarget_RoleSchema: GenEnum<GkeNodePoolTarget_Role> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataproc_v1_shared, 11, 0);

/**
 * The configuration of a GKE node pool used by a [Dataproc-on-GKE
 * cluster](https://cloud.google.com/dataproc/docs/concepts/jobs/dataproc-gke#create-a-dataproc-on-gke-cluster).
 *
 * @generated from message google.cloud.dataproc.v1.GkeNodePoolConfig
 */
export type GkeNodePoolConfig = Message<"google.cloud.dataproc.v1.GkeNodePoolConfig"> & {
  /**
   * Optional. The node pool configuration.
   *
   * @generated from field: google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodeConfig config = 2;
   */
  config?: GkeNodePoolConfig_GkeNodeConfig;

  /**
   * Optional. The list of Compute Engine
   * [zones](https://cloud.google.com/compute/docs/zones#available) where
   * node pool nodes associated with a Dataproc on GKE virtual cluster
   * will be located.
   *
   * **Note:** All node pools associated with a virtual cluster
   * must be located in the same region as the virtual cluster, and they must
   * be located in the same zone within that region.
   *
   * If a location is not specified during node pool creation, Dataproc on GKE
   * will choose the zone.
   *
   * @generated from field: repeated string locations = 13;
   */
  locations: string[];

  /**
   * Optional. The autoscaler configuration for this node pool. The autoscaler
   * is enabled only when a valid configuration is present.
   *
   * @generated from field: google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAutoscalingConfig autoscaling = 4;
   */
  autoscaling?: GkeNodePoolConfig_GkeNodePoolAutoscalingConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.GkeNodePoolConfig.
 * Use `create(GkeNodePoolConfigSchema)` to create a new message.
 */
export const GkeNodePoolConfigSchema: GenMessage<GkeNodePoolConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 12);

/**
 * Parameters that describe cluster nodes.
 *
 * @generated from message google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodeConfig
 */
export type GkeNodePoolConfig_GkeNodeConfig = Message<"google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodeConfig"> & {
  /**
   * Optional. The name of a Compute Engine [machine
   * type](https://cloud.google.com/compute/docs/machine-types).
   *
   * @generated from field: string machine_type = 1;
   */
  machineType: string;

  /**
   * Optional. The number of local SSD disks to attach to the node, which is
   * limited by the maximum number of disks allowable per zone (see [Adding
   * Local SSDs](https://cloud.google.com/compute/docs/disks/local-ssd)).
   *
   * @generated from field: int32 local_ssd_count = 7;
   */
  localSsdCount: number;

  /**
   * Optional. Whether the nodes are created as legacy [preemptible VM
   * instances] (https://cloud.google.com/compute/docs/instances/preemptible).
   * Also see
   * [Spot][google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodeConfig.spot]
   * VMs, preemptible VM instances without a maximum lifetime. Legacy and Spot
   * preemptible nodes cannot be used in a node pool with the `CONTROLLER`
   * [role]
   * (/dataproc/docs/reference/rest/v1/projects.regions.clusters#role)
   * or in the DEFAULT node pool if the CONTROLLER role is not assigned (the
   * DEFAULT node pool will assume the CONTROLLER role).
   *
   * @generated from field: bool preemptible = 10;
   */
  preemptible: boolean;

  /**
   * Optional. A list of [hardware
   * accelerators](https://cloud.google.com/compute/docs/gpus) to attach to
   * each node.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAcceleratorConfig accelerators = 11;
   */
  accelerators: GkeNodePoolConfig_GkeNodePoolAcceleratorConfig[];

  /**
   * Optional. [Minimum CPU
   * platform](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
   * to be used by this instance. The instance may be scheduled on the
   * specified or a newer CPU platform. Specify the friendly names of CPU
   * platforms, such as "Intel Haswell"` or Intel Sandy Bridge".
   *
   * @generated from field: string min_cpu_platform = 13;
   */
  minCpuPlatform: string;

  /**
   * Optional. The [Customer Managed Encryption Key (CMEK)]
   * (https://cloud.google.com/kubernetes-engine/docs/how-to/using-cmek)
   * used to encrypt the boot disk attached to each node in the node pool.
   * Specify the key using the following format:
   * <code>projects/<var>KEY_PROJECT_ID</var>/locations/<var>LOCATION</var>/keyRings/<var>RING_NAME</var>/cryptoKeys/<var>KEY_NAME</var></code>.
   *
   * @generated from field: string boot_disk_kms_key = 23;
   */
  bootDiskKmsKey: string;

  /**
   * Optional. Whether the nodes are created as [Spot VM instances]
   * (https://cloud.google.com/compute/docs/instances/spot).
   * Spot VMs are the latest update to legacy
   * [preemptible
   * VMs][google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodeConfig.preemptible].
   * Spot VMs do not have a maximum lifetime. Legacy and Spot preemptible
   * nodes cannot be used in a node pool with the `CONTROLLER`
   * [role](/dataproc/docs/reference/rest/v1/projects.regions.clusters#role)
   * or in the DEFAULT node pool if the CONTROLLER role is not assigned (the
   * DEFAULT node pool will assume the CONTROLLER role).
   *
   * @generated from field: bool spot = 32;
   */
  spot: boolean;
};

/**
 * Describes the message google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodeConfig.
 * Use `create(GkeNodePoolConfig_GkeNodeConfigSchema)` to create a new message.
 */
export const GkeNodePoolConfig_GkeNodeConfigSchema: GenMessage<GkeNodePoolConfig_GkeNodeConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 12, 0);

/**
 * A GkeNodeConfigAcceleratorConfig represents a Hardware Accelerator request
 * for a node pool.
 *
 * @generated from message google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAcceleratorConfig
 */
export type GkeNodePoolConfig_GkeNodePoolAcceleratorConfig = Message<"google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAcceleratorConfig"> & {
  /**
   * The number of accelerator cards exposed to an instance.
   *
   * @generated from field: int64 accelerator_count = 1;
   */
  acceleratorCount: bigint;

  /**
   * The accelerator type resource namename (see GPUs on Compute Engine).
   *
   * @generated from field: string accelerator_type = 2;
   */
  acceleratorType: string;

  /**
   * Size of partitions to create on the GPU. Valid values are described in
   * the NVIDIA [mig user
   * guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
   *
   * @generated from field: string gpu_partition_size = 3;
   */
  gpuPartitionSize: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAcceleratorConfig.
 * Use `create(GkeNodePoolConfig_GkeNodePoolAcceleratorConfigSchema)` to create a new message.
 */
export const GkeNodePoolConfig_GkeNodePoolAcceleratorConfigSchema: GenMessage<GkeNodePoolConfig_GkeNodePoolAcceleratorConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 12, 1);

/**
 * GkeNodePoolAutoscaling contains information the cluster autoscaler needs to
 * adjust the size of the node pool to the current cluster usage.
 *
 * @generated from message google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAutoscalingConfig
 */
export type GkeNodePoolConfig_GkeNodePoolAutoscalingConfig = Message<"google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAutoscalingConfig"> & {
  /**
   * The minimum number of nodes in the node pool. Must be >= 0 and <=
   * max_node_count.
   *
   * @generated from field: int32 min_node_count = 2;
   */
  minNodeCount: number;

  /**
   * The maximum number of nodes in the node pool. Must be >= min_node_count,
   * and must be > 0.
   * **Note:** Quota must be sufficient to scale up the cluster.
   *
   * @generated from field: int32 max_node_count = 3;
   */
  maxNodeCount: number;
};

/**
 * Describes the message google.cloud.dataproc.v1.GkeNodePoolConfig.GkeNodePoolAutoscalingConfig.
 * Use `create(GkeNodePoolConfig_GkeNodePoolAutoscalingConfigSchema)` to create a new message.
 */
export const GkeNodePoolConfig_GkeNodePoolAutoscalingConfigSchema: GenMessage<GkeNodePoolConfig_GkeNodePoolAutoscalingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 12, 2);

/**
 * Autotuning configuration of the workload.
 *
 * @generated from message google.cloud.dataproc.v1.AutotuningConfig
 */
export type AutotuningConfig = Message<"google.cloud.dataproc.v1.AutotuningConfig"> & {
  /**
   * Optional. Scenarios for which tunings are applied.
   *
   * @generated from field: repeated google.cloud.dataproc.v1.AutotuningConfig.Scenario scenarios = 2;
   */
  scenarios: AutotuningConfig_Scenario[];
};

/**
 * Describes the message google.cloud.dataproc.v1.AutotuningConfig.
 * Use `create(AutotuningConfigSchema)` to create a new message.
 */
export const AutotuningConfigSchema: GenMessage<AutotuningConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 13);

/**
 * Scenario represents a specific goal that autotuning will attempt to achieve
 * by modifying workloads.
 *
 * @generated from enum google.cloud.dataproc.v1.AutotuningConfig.Scenario
 */
export enum AutotuningConfig_Scenario {
  /**
   * Default value.
   *
   * @generated from enum value: SCENARIO_UNSPECIFIED = 0;
   */
  SCENARIO_UNSPECIFIED = 0,

  /**
   * Scaling recommendations such as initialExecutors.
   *
   * @generated from enum value: SCALING = 2;
   */
  SCALING = 2,

  /**
   * Adding hints for potential relation broadcasts.
   *
   * @generated from enum value: BROADCAST_HASH_JOIN = 3;
   */
  BROADCAST_HASH_JOIN = 3,

  /**
   * Memory management for workloads.
   *
   * @generated from enum value: MEMORY = 4;
   */
  MEMORY = 4,
}

/**
 * Describes the enum google.cloud.dataproc.v1.AutotuningConfig.Scenario.
 */
export const AutotuningConfig_ScenarioSchema: GenEnum<AutotuningConfig_Scenario> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataproc_v1_shared, 13, 0);

/**
 * Configuration for dependency repositories
 *
 * @generated from message google.cloud.dataproc.v1.RepositoryConfig
 */
export type RepositoryConfig = Message<"google.cloud.dataproc.v1.RepositoryConfig"> & {
  /**
   * Optional. Configuration for PyPi repository.
   *
   * @generated from field: google.cloud.dataproc.v1.PyPiRepositoryConfig pypi_repository_config = 1;
   */
  pypiRepositoryConfig?: PyPiRepositoryConfig;
};

/**
 * Describes the message google.cloud.dataproc.v1.RepositoryConfig.
 * Use `create(RepositoryConfigSchema)` to create a new message.
 */
export const RepositoryConfigSchema: GenMessage<RepositoryConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 14);

/**
 * Configuration for PyPi repository
 *
 * @generated from message google.cloud.dataproc.v1.PyPiRepositoryConfig
 */
export type PyPiRepositoryConfig = Message<"google.cloud.dataproc.v1.PyPiRepositoryConfig"> & {
  /**
   * Optional. PyPi repository address
   *
   * @generated from field: string pypi_repository = 1;
   */
  pypiRepository: string;
};

/**
 * Describes the message google.cloud.dataproc.v1.PyPiRepositoryConfig.
 * Use `create(PyPiRepositoryConfigSchema)` to create a new message.
 */
export const PyPiRepositoryConfigSchema: GenMessage<PyPiRepositoryConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataproc_v1_shared, 15);

/**
 * Cluster components that can be activated.
 *
 * @generated from enum google.cloud.dataproc.v1.Component
 */
export enum Component {
  /**
   * Unspecified component. Specifying this will cause Cluster creation to fail.
   *
   * @generated from enum value: COMPONENT_UNSPECIFIED = 0;
   */
  COMPONENT_UNSPECIFIED = 0,

  /**
   * The Anaconda component is no longer supported or applicable to
   * [supported Dataproc on Compute Engine image versions]
   * (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-version-clusters#supported-dataproc-image-versions).
   * It cannot be activated on clusters created with supported Dataproc on
   * Compute Engine image versions.
   *
   * @generated from enum value: ANACONDA = 5;
   */
  ANACONDA = 5,

  /**
   * Docker
   *
   * @generated from enum value: DOCKER = 13;
   */
  DOCKER = 13,

  /**
   * The Druid query engine. (alpha)
   *
   * @generated from enum value: DRUID = 9;
   */
  DRUID = 9,

  /**
   * Flink
   *
   * @generated from enum value: FLINK = 14;
   */
  FLINK = 14,

  /**
   * HBase. (beta)
   *
   * @generated from enum value: HBASE = 11;
   */
  HBASE = 11,

  /**
   * The Hive Web HCatalog (the REST service for accessing HCatalog).
   *
   * @generated from enum value: HIVE_WEBHCAT = 3;
   */
  HIVE_WEBHCAT = 3,

  /**
   * Hudi.
   *
   * @generated from enum value: HUDI = 18;
   */
  HUDI = 18,

  /**
   * The Jupyter Notebook.
   *
   * @generated from enum value: JUPYTER = 1;
   */
  JUPYTER = 1,

  /**
   * The Presto query engine.
   *
   * @generated from enum value: PRESTO = 6;
   */
  PRESTO = 6,

  /**
   * The Trino query engine.
   *
   * @generated from enum value: TRINO = 17;
   */
  TRINO = 17,

  /**
   * The Ranger service.
   *
   * @generated from enum value: RANGER = 12;
   */
  RANGER = 12,

  /**
   * The Solr service.
   *
   * @generated from enum value: SOLR = 10;
   */
  SOLR = 10,

  /**
   * The Zeppelin notebook.
   *
   * @generated from enum value: ZEPPELIN = 4;
   */
  ZEPPELIN = 4,

  /**
   * The Zookeeper service.
   *
   * @generated from enum value: ZOOKEEPER = 8;
   */
  ZOOKEEPER = 8,
}

/**
 * Describes the enum google.cloud.dataproc.v1.Component.
 */
export const ComponentSchema: GenEnum<Component> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataproc_v1_shared, 0);

/**
 * Actions in response to failure of a resource associated with a cluster.
 *
 * @generated from enum google.cloud.dataproc.v1.FailureAction
 */
export enum FailureAction {
  /**
   * When FailureAction is unspecified, failure action defaults to NO_ACTION.
   *
   * @generated from enum value: FAILURE_ACTION_UNSPECIFIED = 0;
   */
  FAILURE_ACTION_UNSPECIFIED = 0,

  /**
   * Take no action on failure to create a cluster resource. NO_ACTION is the
   * default.
   *
   * @generated from enum value: NO_ACTION = 1;
   */
  NO_ACTION = 1,

  /**
   * Delete the failed cluster resource.
   *
   * @generated from enum value: DELETE = 2;
   */
  DELETE = 2,
}

/**
 * Describes the enum google.cloud.dataproc.v1.FailureAction.
 */
export const FailureActionSchema: GenEnum<FailureAction> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataproc_v1_shared, 1);

