// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/automl/v1beta1/detection.proto (package google.cloud.automl.v1beta1, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { BoundingPoly } from "./geometry_pb";
import { file_google_cloud_automl_v1beta1_geometry } from "./geometry_pb";
import type { Duration } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/automl/v1beta1/detection.proto.
 */
export const file_google_cloud_automl_v1beta1_detection: GenFile = /*@__PURE__*/
  fileDesc("Citnb29nbGUvY2xvdWQvYXV0b21sL3YxYmV0YTEvZGV0ZWN0aW9uLnByb3RvEhtnb29nbGUuY2xvdWQuYXV0b21sLnYxYmV0YTEicAoeSW1hZ2VPYmplY3REZXRlY3Rpb25Bbm5vdGF0aW9uEj8KDGJvdW5kaW5nX2JveBgBIAEoCzIpLmdvb2dsZS5jbG91ZC5hdXRvbWwudjFiZXRhMS5Cb3VuZGluZ1BvbHkSDQoFc2NvcmUYAiABKAIitAEKHVZpZGVvT2JqZWN0VHJhY2tpbmdBbm5vdGF0aW9uEhMKC2luc3RhbmNlX2lkGAEgASgJEi4KC3RpbWVfb2Zmc2V0GAIgASgLMhkuZ29vZ2xlLnByb3RvYnVmLkR1cmF0aW9uEj8KDGJvdW5kaW5nX2JveBgDIAEoCzIpLmdvb2dsZS5jbG91ZC5hdXRvbWwudjFiZXRhMS5Cb3VuZGluZ1BvbHkSDQoFc2NvcmUYBCABKAIirgIKF0JvdW5kaW5nQm94TWV0cmljc0VudHJ5EhUKDWlvdV90aHJlc2hvbGQYASABKAISHgoWbWVhbl9hdmVyYWdlX3ByZWNpc2lvbhgCIAEoAhJvChpjb25maWRlbmNlX21ldHJpY3NfZW50cmllcxgDIAMoCzJLLmdvb2dsZS5jbG91ZC5hdXRvbWwudjFiZXRhMS5Cb3VuZGluZ0JveE1ldHJpY3NFbnRyeS5Db25maWRlbmNlTWV0cmljc0VudHJ5GmsKFkNvbmZpZGVuY2VNZXRyaWNzRW50cnkSHAoUY29uZmlkZW5jZV90aHJlc2hvbGQYASABKAISDgoGcmVjYWxsGAIgASgCEhEKCXByZWNpc2lvbhgDIAEoAhIQCghmMV9zY29yZRgEIAEoAiLWAQolSW1hZ2VPYmplY3REZXRlY3Rpb25FdmFsdWF0aW9uTWV0cmljcxIkChxldmFsdWF0ZWRfYm91bmRpbmdfYm94X2NvdW50GAEgASgFEloKHGJvdW5kaW5nX2JveF9tZXRyaWNzX2VudHJpZXMYAiADKAsyNC5nb29nbGUuY2xvdWQuYXV0b21sLnYxYmV0YTEuQm91bmRpbmdCb3hNZXRyaWNzRW50cnkSKwojYm91bmRpbmdfYm94X21lYW5fYXZlcmFnZV9wcmVjaXNpb24YAyABKAIi9AEKJFZpZGVvT2JqZWN0VHJhY2tpbmdFdmFsdWF0aW9uTWV0cmljcxIdChVldmFsdWF0ZWRfZnJhbWVfY291bnQYASABKAUSJAocZXZhbHVhdGVkX2JvdW5kaW5nX2JveF9jb3VudBgCIAEoBRJaChxib3VuZGluZ19ib3hfbWV0cmljc19lbnRyaWVzGAQgAygLMjQuZ29vZ2xlLmNsb3VkLmF1dG9tbC52MWJldGExLkJvdW5kaW5nQm94TWV0cmljc0VudHJ5EisKI2JvdW5kaW5nX2JveF9tZWFuX2F2ZXJhZ2VfcHJlY2lzaW9uGAYgASgCQpsBCh9jb20uZ29vZ2xlLmNsb3VkLmF1dG9tbC52MWJldGExUAFaN2Nsb3VkLmdvb2dsZS5jb20vZ28vYXV0b21sL2FwaXYxYmV0YTEvYXV0b21scGI7YXV0b21scGLKAhtHb29nbGVcQ2xvdWRcQXV0b01sXFYxYmV0YTHqAh5Hb29nbGU6OkNsb3VkOjpBdXRvTUw6OlYxYmV0YTFiBnByb3RvMw", [file_google_cloud_automl_v1beta1_geometry, file_google_protobuf_duration]);

/**
 * Annotation details for image object detection.
 *
 * @generated from message google.cloud.automl.v1beta1.ImageObjectDetectionAnnotation
 */
export type ImageObjectDetectionAnnotation = Message<"google.cloud.automl.v1beta1.ImageObjectDetectionAnnotation"> & {
  /**
   * Output only. The rectangle representing the object location.
   *
   * @generated from field: google.cloud.automl.v1beta1.BoundingPoly bounding_box = 1;
   */
  boundingBox?: BoundingPoly;

  /**
   * Output only. The confidence that this annotation is positive for the parent example,
   * value in [0, 1], higher means higher positivity confidence.
   *
   * @generated from field: float score = 2;
   */
  score: number;
};

/**
 * Describes the message google.cloud.automl.v1beta1.ImageObjectDetectionAnnotation.
 * Use `create(ImageObjectDetectionAnnotationSchema)` to create a new message.
 */
export const ImageObjectDetectionAnnotationSchema: GenMessage<ImageObjectDetectionAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_automl_v1beta1_detection, 0);

/**
 * Annotation details for video object tracking.
 *
 * @generated from message google.cloud.automl.v1beta1.VideoObjectTrackingAnnotation
 */
export type VideoObjectTrackingAnnotation = Message<"google.cloud.automl.v1beta1.VideoObjectTrackingAnnotation"> & {
  /**
   * Optional. The instance of the object, expressed as a positive integer. Used to tell
   * apart objects of the same type (i.e. AnnotationSpec) when multiple are
   * present on a single example.
   * NOTE: Instance ID prediction quality is not a part of model evaluation and
   * is done as best effort. Especially in cases when an entity goes
   * off-screen for a longer time (minutes), when it comes back it may be given
   * a new instance ID.
   *
   * @generated from field: string instance_id = 1;
   */
  instanceId: string;

  /**
   * Required. A time (frame) of a video to which this annotation pertains.
   * Represented as the duration since the video's start.
   *
   * @generated from field: google.protobuf.Duration time_offset = 2;
   */
  timeOffset?: Duration;

  /**
   * Required. The rectangle representing the object location on the frame (i.e.
   * at the time_offset of the video).
   *
   * @generated from field: google.cloud.automl.v1beta1.BoundingPoly bounding_box = 3;
   */
  boundingBox?: BoundingPoly;

  /**
   * Output only. The confidence that this annotation is positive for the video at
   * the time_offset, value in [0, 1], higher means higher positivity
   * confidence. For annotations created by the user the score is 1. When
   * user approves an annotation, the original float score is kept (and not
   * changed to 1).
   *
   * @generated from field: float score = 4;
   */
  score: number;
};

/**
 * Describes the message google.cloud.automl.v1beta1.VideoObjectTrackingAnnotation.
 * Use `create(VideoObjectTrackingAnnotationSchema)` to create a new message.
 */
export const VideoObjectTrackingAnnotationSchema: GenMessage<VideoObjectTrackingAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_automl_v1beta1_detection, 1);

/**
 * Bounding box matching model metrics for a single intersection-over-union
 * threshold and multiple label match confidence thresholds.
 *
 * @generated from message google.cloud.automl.v1beta1.BoundingBoxMetricsEntry
 */
export type BoundingBoxMetricsEntry = Message<"google.cloud.automl.v1beta1.BoundingBoxMetricsEntry"> & {
  /**
   * Output only. The intersection-over-union threshold value used to compute
   * this metrics entry.
   *
   * @generated from field: float iou_threshold = 1;
   */
  iouThreshold: number;

  /**
   * Output only. The mean average precision, most often close to au_prc.
   *
   * @generated from field: float mean_average_precision = 2;
   */
  meanAveragePrecision: number;

  /**
   * Output only. Metrics for each label-match confidence_threshold from
   * 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99. Precision-recall curve is
   * derived from them.
   *
   * @generated from field: repeated google.cloud.automl.v1beta1.BoundingBoxMetricsEntry.ConfidenceMetricsEntry confidence_metrics_entries = 3;
   */
  confidenceMetricsEntries: BoundingBoxMetricsEntry_ConfidenceMetricsEntry[];
};

/**
 * Describes the message google.cloud.automl.v1beta1.BoundingBoxMetricsEntry.
 * Use `create(BoundingBoxMetricsEntrySchema)` to create a new message.
 */
export const BoundingBoxMetricsEntrySchema: GenMessage<BoundingBoxMetricsEntry> = /*@__PURE__*/
  messageDesc(file_google_cloud_automl_v1beta1_detection, 2);

/**
 * Metrics for a single confidence threshold.
 *
 * @generated from message google.cloud.automl.v1beta1.BoundingBoxMetricsEntry.ConfidenceMetricsEntry
 */
export type BoundingBoxMetricsEntry_ConfidenceMetricsEntry = Message<"google.cloud.automl.v1beta1.BoundingBoxMetricsEntry.ConfidenceMetricsEntry"> & {
  /**
   * Output only. The confidence threshold value used to compute the metrics.
   *
   * @generated from field: float confidence_threshold = 1;
   */
  confidenceThreshold: number;

  /**
   * Output only. Recall under the given confidence threshold.
   *
   * @generated from field: float recall = 2;
   */
  recall: number;

  /**
   * Output only. Precision under the given confidence threshold.
   *
   * @generated from field: float precision = 3;
   */
  precision: number;

  /**
   * Output only. The harmonic mean of recall and precision.
   *
   * @generated from field: float f1_score = 4;
   */
  f1Score: number;
};

/**
 * Describes the message google.cloud.automl.v1beta1.BoundingBoxMetricsEntry.ConfidenceMetricsEntry.
 * Use `create(BoundingBoxMetricsEntry_ConfidenceMetricsEntrySchema)` to create a new message.
 */
export const BoundingBoxMetricsEntry_ConfidenceMetricsEntrySchema: GenMessage<BoundingBoxMetricsEntry_ConfidenceMetricsEntry> = /*@__PURE__*/
  messageDesc(file_google_cloud_automl_v1beta1_detection, 2, 0);

/**
 * Model evaluation metrics for image object detection problems.
 * Evaluates prediction quality of labeled bounding boxes.
 *
 * @generated from message google.cloud.automl.v1beta1.ImageObjectDetectionEvaluationMetrics
 */
export type ImageObjectDetectionEvaluationMetrics = Message<"google.cloud.automl.v1beta1.ImageObjectDetectionEvaluationMetrics"> & {
  /**
   * Output only. The total number of bounding boxes (i.e. summed over all
   * images) the ground truth used to create this evaluation had.
   *
   * @generated from field: int32 evaluated_bounding_box_count = 1;
   */
  evaluatedBoundingBoxCount: number;

  /**
   * Output only. The bounding boxes match metrics for each
   * Intersection-over-union threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * and each label confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * pair.
   *
   * @generated from field: repeated google.cloud.automl.v1beta1.BoundingBoxMetricsEntry bounding_box_metrics_entries = 2;
   */
  boundingBoxMetricsEntries: BoundingBoxMetricsEntry[];

  /**
   * Output only. The single metric for bounding boxes evaluation:
   * the mean_average_precision averaged over all bounding_box_metrics_entries.
   *
   * @generated from field: float bounding_box_mean_average_precision = 3;
   */
  boundingBoxMeanAveragePrecision: number;
};

/**
 * Describes the message google.cloud.automl.v1beta1.ImageObjectDetectionEvaluationMetrics.
 * Use `create(ImageObjectDetectionEvaluationMetricsSchema)` to create a new message.
 */
export const ImageObjectDetectionEvaluationMetricsSchema: GenMessage<ImageObjectDetectionEvaluationMetrics> = /*@__PURE__*/
  messageDesc(file_google_cloud_automl_v1beta1_detection, 3);

/**
 * Model evaluation metrics for video object tracking problems.
 * Evaluates prediction quality of both labeled bounding boxes and labeled
 * tracks (i.e. series of bounding boxes sharing same label and instance ID).
 *
 * @generated from message google.cloud.automl.v1beta1.VideoObjectTrackingEvaluationMetrics
 */
export type VideoObjectTrackingEvaluationMetrics = Message<"google.cloud.automl.v1beta1.VideoObjectTrackingEvaluationMetrics"> & {
  /**
   * Output only. The number of video frames used to create this evaluation.
   *
   * @generated from field: int32 evaluated_frame_count = 1;
   */
  evaluatedFrameCount: number;

  /**
   * Output only. The total number of bounding boxes (i.e. summed over all
   * frames) the ground truth used to create this evaluation had.
   *
   * @generated from field: int32 evaluated_bounding_box_count = 2;
   */
  evaluatedBoundingBoxCount: number;

  /**
   * Output only. The bounding boxes match metrics for each
   * Intersection-over-union threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * and each label confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99
   * pair.
   *
   * @generated from field: repeated google.cloud.automl.v1beta1.BoundingBoxMetricsEntry bounding_box_metrics_entries = 4;
   */
  boundingBoxMetricsEntries: BoundingBoxMetricsEntry[];

  /**
   * Output only. The single metric for bounding boxes evaluation:
   * the mean_average_precision averaged over all bounding_box_metrics_entries.
   *
   * @generated from field: float bounding_box_mean_average_precision = 6;
   */
  boundingBoxMeanAveragePrecision: number;
};

/**
 * Describes the message google.cloud.automl.v1beta1.VideoObjectTrackingEvaluationMetrics.
 * Use `create(VideoObjectTrackingEvaluationMetricsSchema)` to create a new message.
 */
export const VideoObjectTrackingEvaluationMetricsSchema: GenMessage<VideoObjectTrackingEvaluationMetrics> = /*@__PURE__*/
  messageDesc(file_google_cloud_automl_v1beta1_detection, 4);

