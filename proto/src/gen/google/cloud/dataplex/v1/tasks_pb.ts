// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/dataplex/v1/tasks.proto (package google.cloud.dataplex.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { State } from "./resources_pb";
import { file_google_cloud_dataplex_v1_resources } from "./resources_pb";
import type { Duration, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/dataplex/v1/tasks.proto.
 */
export const file_google_cloud_dataplex_v1_tasks: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_dataplex_v1_resources, file_google_protobuf_duration, file_google_protobuf_timestamp]);

/**
 * A task represents a user-visible job.
 *
 * @generated from message google.cloud.dataplex.v1.Task
 */
export type Task = Message<"google.cloud.dataplex.v1.Task"> & {
  /**
   * Output only. The relative resource name of the task, of the form:
   * projects/{project_number}/locations/{location_id}/lakes/{lake_id}/
   * tasks/{task_id}.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. System generated globally unique ID for the task. This ID will
   * be different if the task is deleted and re-created with the same name.
   *
   * @generated from field: string uid = 2;
   */
  uid: string;

  /**
   * Output only. The time when the task was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 3;
   */
  createTime?: Timestamp;

  /**
   * Output only. The time when the task was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 4;
   */
  updateTime?: Timestamp;

  /**
   * Optional. Description of the task.
   *
   * @generated from field: string description = 5;
   */
  description: string;

  /**
   * Optional. User friendly display name.
   *
   * @generated from field: string display_name = 6;
   */
  displayName: string;

  /**
   * Output only. Current state of the task.
   *
   * @generated from field: google.cloud.dataplex.v1.State state = 7;
   */
  state: State;

  /**
   * Optional. User-defined labels for the task.
   *
   * @generated from field: map<string, string> labels = 8;
   */
  labels: { [key: string]: string };

  /**
   * Required. Spec related to how often and when a task should be triggered.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.TriggerSpec trigger_spec = 100;
   */
  triggerSpec?: Task_TriggerSpec;

  /**
   * Required. Spec related to how a task is executed.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.ExecutionSpec execution_spec = 101;
   */
  executionSpec?: Task_ExecutionSpec;

  /**
   * Output only. Status of the latest task executions.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.ExecutionStatus execution_status = 201;
   */
  executionStatus?: Task_ExecutionStatus;

  /**
   * Task template specific user-specified config.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.config
   */
  config: {
    /**
     * Config related to running custom Spark tasks.
     *
     * @generated from field: google.cloud.dataplex.v1.Task.SparkTaskConfig spark = 300;
     */
    value: Task_SparkTaskConfig;
    case: "spark";
  } | {
    /**
     * Config related to running scheduled Notebooks.
     *
     * @generated from field: google.cloud.dataplex.v1.Task.NotebookTaskConfig notebook = 302;
     */
    value: Task_NotebookTaskConfig;
    case: "notebook";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.
 * Use `create(TaskSchema)` to create a new message.
 */
export const TaskSchema: GenMessage<Task> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0);

/**
 * Configuration for the underlying infrastructure used to run workloads.
 *
 * @generated from message google.cloud.dataplex.v1.Task.InfrastructureSpec
 */
export type Task_InfrastructureSpec = Message<"google.cloud.dataplex.v1.Task.InfrastructureSpec"> & {
  /**
   * Hardware config.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.InfrastructureSpec.resources
   */
  resources: {
    /**
     * Compute resources needed for a Task when using Dataproc Serverless.
     *
     * @generated from field: google.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResources batch = 52;
     */
    value: Task_InfrastructureSpec_BatchComputeResources;
    case: "batch";
  } | { case: undefined; value?: undefined };

  /**
   * Software config.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.InfrastructureSpec.runtime
   */
  runtime: {
    /**
     * Container Image Runtime Configuration.
     *
     * @generated from field: google.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime container_image = 101;
     */
    value: Task_InfrastructureSpec_ContainerImageRuntime;
    case: "containerImage";
  } | { case: undefined; value?: undefined };

  /**
   * Networking config.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.InfrastructureSpec.network
   */
  network: {
    /**
     * Vpc network.
     *
     * @generated from field: google.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork vpc_network = 150;
     */
    value: Task_InfrastructureSpec_VpcNetwork;
    case: "vpcNetwork";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.InfrastructureSpec.
 * Use `create(Task_InfrastructureSpecSchema)` to create a new message.
 */
export const Task_InfrastructureSpecSchema: GenMessage<Task_InfrastructureSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 0);

/**
 * Batch compute resources associated with the task.
 *
 * @generated from message google.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResources
 */
export type Task_InfrastructureSpec_BatchComputeResources = Message<"google.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResources"> & {
  /**
   * Optional. Total number of job executors.
   * Executor Count should be between 2 and 100. [Default=2]
   *
   * @generated from field: int32 executors_count = 1;
   */
  executorsCount: number;

  /**
   * Optional. Max configurable executors.
   * If max_executors_count > executors_count, then auto-scaling is enabled.
   * Max Executor Count should be between 2 and 1000. [Default=1000]
   *
   * @generated from field: int32 max_executors_count = 2;
   */
  maxExecutorsCount: number;
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResources.
 * Use `create(Task_InfrastructureSpec_BatchComputeResourcesSchema)` to create a new message.
 */
export const Task_InfrastructureSpec_BatchComputeResourcesSchema: GenMessage<Task_InfrastructureSpec_BatchComputeResources> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 0, 0);

/**
 * Container Image Runtime Configuration used with Batch execution.
 *
 * @generated from message google.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime
 */
export type Task_InfrastructureSpec_ContainerImageRuntime = Message<"google.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime"> & {
  /**
   * Optional. Container image to use.
   *
   * @generated from field: string image = 1;
   */
  image: string;

  /**
   * Optional. A list of Java JARS to add to the classpath.
   * Valid input includes Cloud Storage URIs to Jar binaries.
   * For example, gs://bucket-name/my/path/to/file.jar
   *
   * @generated from field: repeated string java_jars = 2;
   */
  javaJars: string[];

  /**
   * Optional. A list of python packages to be installed.
   * Valid formats include Cloud Storage URI to a PIP installable library.
   * For example, gs://bucket-name/my/path/to/lib.tar.gz
   *
   * @generated from field: repeated string python_packages = 3;
   */
  pythonPackages: string[];

  /**
   * Optional. Override to common configuration of open source components
   * installed on the Dataproc cluster. The properties to set on daemon
   * config files. Property keys are specified in `prefix:property` format,
   * for example `core:hadoop.tmp.dir`. For more information, see [Cluster
   * properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
   *
   * @generated from field: map<string, string> properties = 4;
   */
  properties: { [key: string]: string };
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime.
 * Use `create(Task_InfrastructureSpec_ContainerImageRuntimeSchema)` to create a new message.
 */
export const Task_InfrastructureSpec_ContainerImageRuntimeSchema: GenMessage<Task_InfrastructureSpec_ContainerImageRuntime> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 0, 1);

/**
 * Cloud VPC Network used to run the infrastructure.
 *
 * @generated from message google.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork
 */
export type Task_InfrastructureSpec_VpcNetwork = Message<"google.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork"> & {
  /**
   * The Cloud VPC network identifier.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork.network_name
   */
  networkName: {
    /**
     * Optional. The Cloud VPC network in which the job is run. By default,
     * the Cloud VPC network named Default within the project is used.
     *
     * @generated from field: string network = 1;
     */
    value: string;
    case: "network";
  } | {
    /**
     * Optional. The Cloud VPC sub-network in which the job is run.
     *
     * @generated from field: string sub_network = 2;
     */
    value: string;
    case: "subNetwork";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. List of network tags to apply to the job.
   *
   * @generated from field: repeated string network_tags = 3;
   */
  networkTags: string[];
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork.
 * Use `create(Task_InfrastructureSpec_VpcNetworkSchema)` to create a new message.
 */
export const Task_InfrastructureSpec_VpcNetworkSchema: GenMessage<Task_InfrastructureSpec_VpcNetwork> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 0, 2);

/**
 * Task scheduling and trigger settings.
 *
 * @generated from message google.cloud.dataplex.v1.Task.TriggerSpec
 */
export type Task_TriggerSpec = Message<"google.cloud.dataplex.v1.Task.TriggerSpec"> & {
  /**
   * Required. Immutable. Trigger type of the user-specified Task.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.TriggerSpec.Type type = 5;
   */
  type: Task_TriggerSpec_Type;

  /**
   * Optional. The first run of the task will be after this time.
   * If not specified, the task will run shortly after being submitted if
   * ON_DEMAND and based on the schedule if RECURRING.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 6;
   */
  startTime?: Timestamp;

  /**
   * Optional. Prevent the task from executing.
   * This does not cancel already running tasks. It is intended to temporarily
   * disable RECURRING tasks.
   *
   * @generated from field: bool disabled = 4;
   */
  disabled: boolean;

  /**
   * Optional. Number of retry attempts before aborting.
   * Set to zero to never attempt to retry a failed task.
   *
   * @generated from field: int32 max_retries = 7;
   */
  maxRetries: number;

  /**
   * Trigger only applies for RECURRING tasks.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.TriggerSpec.trigger
   */
  trigger: {
    /**
     * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
     * running tasks periodically. To explicitly set a timezone to the cron
     * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
     * "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid
     * string from IANA time zone database. For example,
     * `CRON_TZ=America/New_York 1 * * * *`, or `TZ=America/New_York 1 * * *
     * *`. This field is required for RECURRING tasks.
     *
     * @generated from field: string schedule = 100;
     */
    value: string;
    case: "schedule";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.TriggerSpec.
 * Use `create(Task_TriggerSpecSchema)` to create a new message.
 */
export const Task_TriggerSpecSchema: GenMessage<Task_TriggerSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 1);

/**
 * Determines how often and when the job will run.
 *
 * @generated from enum google.cloud.dataplex.v1.Task.TriggerSpec.Type
 */
export enum Task_TriggerSpec_Type {
  /**
   * Unspecified trigger type.
   *
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  TYPE_UNSPECIFIED = 0,

  /**
   * The task runs one-time shortly after Task Creation.
   *
   * @generated from enum value: ON_DEMAND = 1;
   */
  ON_DEMAND = 1,

  /**
   * The task is scheduled to run periodically.
   *
   * @generated from enum value: RECURRING = 2;
   */
  RECURRING = 2,
}

/**
 * Describes the enum google.cloud.dataplex.v1.Task.TriggerSpec.Type.
 */
export const Task_TriggerSpec_TypeSchema: GenEnum<Task_TriggerSpec_Type> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataplex_v1_tasks, 0, 1, 0);

/**
 * Execution related settings, like retry and service_account.
 *
 * @generated from message google.cloud.dataplex.v1.Task.ExecutionSpec
 */
export type Task_ExecutionSpec = Message<"google.cloud.dataplex.v1.Task.ExecutionSpec"> & {
  /**
   * Optional. The arguments to pass to the task.
   * The args can use placeholders of the format ${placeholder} as
   * part of key/value string. These will be interpolated before passing the
   * args to the driver. Currently supported placeholders:
   * - ${task_id}
   * - ${job_time}
   * To pass positional args, set the key as TASK_ARGS. The value should be a
   * comma-separated string of all the positional arguments. To use a
   * delimiter other than comma, refer to
   * https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of
   * other keys being present in the args, then TASK_ARGS will be passed as
   * the last argument.
   *
   * @generated from field: map<string, string> args = 4;
   */
  args: { [key: string]: string };

  /**
   * Required. Service account to use to execute a task.
   * If not provided, the default Compute service account for the project is
   * used.
   *
   * @generated from field: string service_account = 5;
   */
  serviceAccount: string;

  /**
   * Optional. The project in which jobs are run. By default, the project
   * containing the Lake is used. If a project is provided, the
   * [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account]
   * must belong to this project.
   *
   * @generated from field: string project = 7;
   */
  project: string;

  /**
   * Optional. The maximum duration after which the job execution is expired.
   *
   * @generated from field: google.protobuf.Duration max_job_execution_lifetime = 8;
   */
  maxJobExecutionLifetime?: Duration;

  /**
   * Optional. The Cloud KMS key to use for encryption, of the form:
   * `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`.
   *
   * @generated from field: string kms_key = 9;
   */
  kmsKey: string;
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.ExecutionSpec.
 * Use `create(Task_ExecutionSpecSchema)` to create a new message.
 */
export const Task_ExecutionSpecSchema: GenMessage<Task_ExecutionSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 2);

/**
 * User-specified config for running a Spark task.
 *
 * @generated from message google.cloud.dataplex.v1.Task.SparkTaskConfig
 */
export type Task_SparkTaskConfig = Message<"google.cloud.dataplex.v1.Task.SparkTaskConfig"> & {
  /**
   * Required. The specification of the main method to call to drive the
   * job. Specify either the jar file that contains the main class or the
   * main class name.
   *
   * @generated from oneof google.cloud.dataplex.v1.Task.SparkTaskConfig.driver
   */
  driver: {
    /**
     * The Cloud Storage URI of the jar file that contains the main class.
     * The execution args are passed in as a sequence of named process
     * arguments (`--key=value`).
     *
     * @generated from field: string main_jar_file_uri = 100;
     */
    value: string;
    case: "mainJarFileUri";
  } | {
    /**
     * The name of the driver's main class. The jar file that contains the
     * class must be in the default CLASSPATH or specified in
     * `jar_file_uris`.
     * The execution args are passed in as a sequence of named process
     * arguments (`--key=value`).
     *
     * @generated from field: string main_class = 101;
     */
    value: string;
    case: "mainClass";
  } | {
    /**
     * The Gcloud Storage URI of the main Python file to use as the driver.
     * Must be a .py file. The execution args are passed in as a sequence of
     * named process arguments (`--key=value`).
     *
     * @generated from field: string python_script_file = 102;
     */
    value: string;
    case: "pythonScriptFile";
  } | {
    /**
     * A reference to a query file. This can be the Cloud Storage URI of the
     * query file or it can the path to a SqlScript Content. The execution
     * args are used to declare a set of script variables
     * (`set key="value";`).
     *
     * @generated from field: string sql_script_file = 104;
     */
    value: string;
    case: "sqlScriptFile";
  } | {
    /**
     * The query text.
     * The execution args are used to declare a set of script variables
     * (`set key="value";`).
     *
     * @generated from field: string sql_script = 105;
     */
    value: string;
    case: "sqlScript";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. Cloud Storage URIs of files to be placed in the working
   * directory of each executor.
   *
   * @generated from field: repeated string file_uris = 3;
   */
  fileUris: string[];

  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working
   * directory of each executor. Supported file types: .jar, .tar, .tar.gz,
   * .tgz, and .zip.
   *
   * @generated from field: repeated string archive_uris = 4;
   */
  archiveUris: string[];

  /**
   * Optional. Infrastructure specification for the execution.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.InfrastructureSpec infrastructure_spec = 6;
   */
  infrastructureSpec?: Task_InfrastructureSpec;
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.SparkTaskConfig.
 * Use `create(Task_SparkTaskConfigSchema)` to create a new message.
 */
export const Task_SparkTaskConfigSchema: GenMessage<Task_SparkTaskConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 3);

/**
 * Config for running scheduled notebooks.
 *
 * @generated from message google.cloud.dataplex.v1.Task.NotebookTaskConfig
 */
export type Task_NotebookTaskConfig = Message<"google.cloud.dataplex.v1.Task.NotebookTaskConfig"> & {
  /**
   * Required. Path to input notebook. This can be the Cloud Storage URI of
   * the notebook file or the path to a Notebook Content. The execution args
   * are accessible as environment variables
   * (`TASK_key=value`).
   *
   * @generated from field: string notebook = 4;
   */
  notebook: string;

  /**
   * Optional. Infrastructure specification for the execution.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.InfrastructureSpec infrastructure_spec = 3;
   */
  infrastructureSpec?: Task_InfrastructureSpec;

  /**
   * Optional. Cloud Storage URIs of files to be placed in the working
   * directory of each executor.
   *
   * @generated from field: repeated string file_uris = 5;
   */
  fileUris: string[];

  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working
   * directory of each executor. Supported file types: .jar, .tar, .tar.gz,
   * .tgz, and .zip.
   *
   * @generated from field: repeated string archive_uris = 6;
   */
  archiveUris: string[];
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.NotebookTaskConfig.
 * Use `create(Task_NotebookTaskConfigSchema)` to create a new message.
 */
export const Task_NotebookTaskConfigSchema: GenMessage<Task_NotebookTaskConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 4);

/**
 * Status of the task execution (e.g. Jobs).
 *
 * @generated from message google.cloud.dataplex.v1.Task.ExecutionStatus
 */
export type Task_ExecutionStatus = Message<"google.cloud.dataplex.v1.Task.ExecutionStatus"> & {
  /**
   * Output only. Last update time of the status.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * Output only. latest job execution
   *
   * @generated from field: google.cloud.dataplex.v1.Job latest_job = 9;
   */
  latestJob?: Job;
};

/**
 * Describes the message google.cloud.dataplex.v1.Task.ExecutionStatus.
 * Use `create(Task_ExecutionStatusSchema)` to create a new message.
 */
export const Task_ExecutionStatusSchema: GenMessage<Task_ExecutionStatus> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 0, 5);

/**
 * A job represents an instance of a task.
 *
 * @generated from message google.cloud.dataplex.v1.Job
 */
export type Job = Message<"google.cloud.dataplex.v1.Job"> & {
  /**
   * Output only. The relative resource name of the job, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. System generated globally unique ID for the job.
   *
   * @generated from field: string uid = 2;
   */
  uid: string;

  /**
   * Output only. The time when the job was started.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 3;
   */
  startTime?: Timestamp;

  /**
   * Output only. The time when the job ended.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 4;
   */
  endTime?: Timestamp;

  /**
   * Output only. Execution state for the job.
   *
   * @generated from field: google.cloud.dataplex.v1.Job.State state = 5;
   */
  state: Job_State;

  /**
   * Output only. The number of times the job has been retried (excluding the
   * initial attempt).
   *
   * @generated from field: uint32 retry_count = 6;
   */
  retryCount: number;

  /**
   * Output only. The underlying service running a job.
   *
   * @generated from field: google.cloud.dataplex.v1.Job.Service service = 7;
   */
  service: Job_Service;

  /**
   * Output only. The full resource name for the job run under a particular
   * service.
   *
   * @generated from field: string service_job = 8;
   */
  serviceJob: string;

  /**
   * Output only. Additional information about the current state.
   *
   * @generated from field: string message = 9;
   */
  message: string;

  /**
   * Output only. User-defined labels for the task.
   *
   * @generated from field: map<string, string> labels = 10;
   */
  labels: { [key: string]: string };

  /**
   * Output only. Job execution trigger.
   *
   * @generated from field: google.cloud.dataplex.v1.Job.Trigger trigger = 11;
   */
  trigger: Job_Trigger;

  /**
   * Output only. Spec related to how a task is executed.
   *
   * @generated from field: google.cloud.dataplex.v1.Task.ExecutionSpec execution_spec = 100;
   */
  executionSpec?: Task_ExecutionSpec;
};

/**
 * Describes the message google.cloud.dataplex.v1.Job.
 * Use `create(JobSchema)` to create a new message.
 */
export const JobSchema: GenMessage<Job> = /*@__PURE__*/
  messageDesc(file_google_cloud_dataplex_v1_tasks, 1);

/**
 * @generated from enum google.cloud.dataplex.v1.Job.Service
 */
export enum Job_Service {
  /**
   * Service used to run the job is unspecified.
   *
   * @generated from enum value: SERVICE_UNSPECIFIED = 0;
   */
  SERVICE_UNSPECIFIED = 0,

  /**
   * Dataproc service is used to run this job.
   *
   * @generated from enum value: DATAPROC = 1;
   */
  DATAPROC = 1,
}

/**
 * Describes the enum google.cloud.dataplex.v1.Job.Service.
 */
export const Job_ServiceSchema: GenEnum<Job_Service> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataplex_v1_tasks, 1, 0);

/**
 * @generated from enum google.cloud.dataplex.v1.Job.State
 */
export enum Job_State {
  /**
   * The job state is unknown.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The job is running.
   *
   * @generated from enum value: RUNNING = 1;
   */
  RUNNING = 1,

  /**
   * The job is cancelling.
   *
   * @generated from enum value: CANCELLING = 2;
   */
  CANCELLING = 2,

  /**
   * The job cancellation was successful.
   *
   * @generated from enum value: CANCELLED = 3;
   */
  CANCELLED = 3,

  /**
   * The job completed successfully.
   *
   * @generated from enum value: SUCCEEDED = 4;
   */
  SUCCEEDED = 4,

  /**
   * The job is no longer running due to an error.
   *
   * @generated from enum value: FAILED = 5;
   */
  FAILED = 5,

  /**
   * The job was cancelled outside of Dataplex.
   *
   * @generated from enum value: ABORTED = 6;
   */
  ABORTED = 6,
}

/**
 * Describes the enum google.cloud.dataplex.v1.Job.State.
 */
export const Job_StateSchema: GenEnum<Job_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataplex_v1_tasks, 1, 1);

/**
 * Job execution trigger.
 *
 * @generated from enum google.cloud.dataplex.v1.Job.Trigger
 */
export enum Job_Trigger {
  /**
   * The trigger is unspecified.
   *
   * @generated from enum value: TRIGGER_UNSPECIFIED = 0;
   */
  TRIGGER_UNSPECIFIED = 0,

  /**
   * The job was triggered by Dataplex based on trigger spec from task
   * definition.
   *
   * @generated from enum value: TASK_CONFIG = 1;
   */
  TASK_CONFIG = 1,

  /**
   * The job was triggered by the explicit call of Task API.
   *
   * @generated from enum value: RUN_REQUEST = 2;
   */
  RUN_REQUEST = 2,
}

/**
 * Describes the enum google.cloud.dataplex.v1.Job.Trigger.
 */
export const Job_TriggerSchema: GenEnum<Job_Trigger> = /*@__PURE__*/
  enumDesc(file_google_cloud_dataplex_v1_tasks, 1, 2);

