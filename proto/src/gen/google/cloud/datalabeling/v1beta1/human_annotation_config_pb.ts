// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/datalabeling/v1beta1/human_annotation_config.proto (package google.cloud.datalabeling.v1beta1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import type { Duration } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/datalabeling/v1beta1/human_annotation_config.proto.
 */
export const file_google_cloud_datalabeling_v1beta1_human_annotation_config: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_protobuf_duration]);

/**
 * Configuration for how human labeling task should be done.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.HumanAnnotationConfig
 */
export type HumanAnnotationConfig = Message<"google.cloud.datalabeling.v1beta1.HumanAnnotationConfig"> & {
  /**
   * Required. Instruction resource name.
   *
   * @generated from field: string instruction = 1;
   */
  instruction: string;

  /**
   * Required. A human-readable name for AnnotatedDataset defined by
   * users. Maximum of 64 characters
   * .
   *
   * @generated from field: string annotated_dataset_display_name = 2;
   */
  annotatedDatasetDisplayName: string;

  /**
   * Optional. A human-readable description for AnnotatedDataset.
   * The description can be up to 10000 characters long.
   *
   * @generated from field: string annotated_dataset_description = 3;
   */
  annotatedDatasetDescription: string;

  /**
   * Optional. A human-readable label used to logically group labeling tasks.
   * This string must match the regular expression `[a-zA-Z\\d_-]{0,128}`.
   *
   * @generated from field: string label_group = 4;
   */
  labelGroup: string;

  /**
   * Optional. The Language of this question, as a
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt).
   * Default value is en-US.
   * Only need to set this when task is language related. For example, French
   * text classification.
   *
   * @generated from field: string language_code = 5;
   */
  languageCode: string;

  /**
   * Optional. Replication of questions. Each question will be sent to up to
   * this number of contributors to label. Aggregated answers will be returned.
   * Default is set to 1.
   * For image related labeling, valid values are 1, 3, 5.
   *
   * @generated from field: int32 replica_count = 6;
   */
  replicaCount: number;

  /**
   * Optional. Maximum duration for contributors to answer a question. Maximum
   * is 3600 seconds. Default is 3600 seconds.
   *
   * @generated from field: google.protobuf.Duration question_duration = 7;
   */
  questionDuration?: Duration;

  /**
   * Optional. If you want your own labeling contributors to manage and work on
   * this labeling request, you can set these contributors here. We will give
   * them access to the question types in crowdcompute. Note that these
   * emails must be registered in crowdcompute worker UI:
   * https://crowd-compute.appspot.com/
   *
   * @generated from field: repeated string contributor_emails = 9;
   */
  contributorEmails: string[];

  /**
   * Email of the user who started the labeling task and should be notified by
   * email. If empty no notification will be sent.
   *
   * @generated from field: string user_email_address = 10;
   */
  userEmailAddress: string;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.HumanAnnotationConfig.
 * Use `create(HumanAnnotationConfigSchema)` to create a new message.
 */
export const HumanAnnotationConfigSchema: GenMessage<HumanAnnotationConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 0);

/**
 * Config for image classification human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.ImageClassificationConfig
 */
export type ImageClassificationConfig = Message<"google.cloud.datalabeling.v1beta1.ImageClassificationConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;

  /**
   * Optional. If allow_multi_label is true, contributors are able to choose
   * multiple labels for one image.
   *
   * @generated from field: bool allow_multi_label = 2;
   */
  allowMultiLabel: boolean;

  /**
   * Optional. The type of how to aggregate answers.
   *
   * @generated from field: google.cloud.datalabeling.v1beta1.StringAggregationType answer_aggregation_type = 3;
   */
  answerAggregationType: StringAggregationType;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.ImageClassificationConfig.
 * Use `create(ImageClassificationConfigSchema)` to create a new message.
 */
export const ImageClassificationConfigSchema: GenMessage<ImageClassificationConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 1);

/**
 * Config for image bounding poly (and bounding box) human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.BoundingPolyConfig
 */
export type BoundingPolyConfig = Message<"google.cloud.datalabeling.v1beta1.BoundingPolyConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;

  /**
   * Optional. Instruction message showed on contributors UI.
   *
   * @generated from field: string instruction_message = 2;
   */
  instructionMessage: string;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.BoundingPolyConfig.
 * Use `create(BoundingPolyConfigSchema)` to create a new message.
 */
export const BoundingPolyConfigSchema: GenMessage<BoundingPolyConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 2);

/**
 * Config for image polyline human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.PolylineConfig
 */
export type PolylineConfig = Message<"google.cloud.datalabeling.v1beta1.PolylineConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;

  /**
   * Optional. Instruction message showed on contributors UI.
   *
   * @generated from field: string instruction_message = 2;
   */
  instructionMessage: string;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.PolylineConfig.
 * Use `create(PolylineConfigSchema)` to create a new message.
 */
export const PolylineConfigSchema: GenMessage<PolylineConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 3);

/**
 * Config for image segmentation
 *
 * @generated from message google.cloud.datalabeling.v1beta1.SegmentationConfig
 */
export type SegmentationConfig = Message<"google.cloud.datalabeling.v1beta1.SegmentationConfig"> & {
  /**
   * Required. Annotation spec set resource name. format:
   * projects/{project_id}/annotationSpecSets/{annotation_spec_set_id}
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;

  /**
   * Instruction message showed on labelers UI.
   *
   * @generated from field: string instruction_message = 2;
   */
  instructionMessage: string;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.SegmentationConfig.
 * Use `create(SegmentationConfigSchema)` to create a new message.
 */
export const SegmentationConfigSchema: GenMessage<SegmentationConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 4);

/**
 * Config for video classification human labeling task.
 * Currently two types of video classification are supported:
 * 1. Assign labels on the entire video.
 * 2. Split the video into multiple video clips based on camera shot, and
 * assign labels on each video clip.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.VideoClassificationConfig
 */
export type VideoClassificationConfig = Message<"google.cloud.datalabeling.v1beta1.VideoClassificationConfig"> & {
  /**
   * Required. The list of annotation spec set configs.
   * Since watching a video clip takes much longer time than an image, we
   * support label with multiple AnnotationSpecSet at the same time. Labels
   * in each AnnotationSpecSet will be shown in a group to contributors.
   * Contributors can select one or more (depending on whether to allow multi
   * label) from each group.
   *
   * @generated from field: repeated google.cloud.datalabeling.v1beta1.VideoClassificationConfig.AnnotationSpecSetConfig annotation_spec_set_configs = 1;
   */
  annotationSpecSetConfigs: VideoClassificationConfig_AnnotationSpecSetConfig[];

  /**
   * Optional. Option to apply shot detection on the video.
   *
   * @generated from field: bool apply_shot_detection = 2;
   */
  applyShotDetection: boolean;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.VideoClassificationConfig.
 * Use `create(VideoClassificationConfigSchema)` to create a new message.
 */
export const VideoClassificationConfigSchema: GenMessage<VideoClassificationConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 5);

/**
 * Annotation spec set with the setting of allowing multi labels or not.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.VideoClassificationConfig.AnnotationSpecSetConfig
 */
export type VideoClassificationConfig_AnnotationSpecSetConfig = Message<"google.cloud.datalabeling.v1beta1.VideoClassificationConfig.AnnotationSpecSetConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;

  /**
   * Optional. If allow_multi_label is true, contributors are able to
   * choose multiple labels from one annotation spec set.
   *
   * @generated from field: bool allow_multi_label = 2;
   */
  allowMultiLabel: boolean;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.VideoClassificationConfig.AnnotationSpecSetConfig.
 * Use `create(VideoClassificationConfig_AnnotationSpecSetConfigSchema)` to create a new message.
 */
export const VideoClassificationConfig_AnnotationSpecSetConfigSchema: GenMessage<VideoClassificationConfig_AnnotationSpecSetConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 5, 0);

/**
 * Config for video object detection human labeling task.
 * Object detection will be conducted on the images extracted from the video,
 * and those objects will be labeled with bounding boxes.
 * User need to specify the number of images to be extracted per second as the
 * extraction frame rate.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.ObjectDetectionConfig
 */
export type ObjectDetectionConfig = Message<"google.cloud.datalabeling.v1beta1.ObjectDetectionConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;

  /**
   * Required. Number of frames per second to be extracted from the video.
   *
   * @generated from field: double extraction_frame_rate = 3;
   */
  extractionFrameRate: number;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.ObjectDetectionConfig.
 * Use `create(ObjectDetectionConfigSchema)` to create a new message.
 */
export const ObjectDetectionConfigSchema: GenMessage<ObjectDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 6);

/**
 * Config for video object tracking human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.ObjectTrackingConfig
 */
export type ObjectTrackingConfig = Message<"google.cloud.datalabeling.v1beta1.ObjectTrackingConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.ObjectTrackingConfig.
 * Use `create(ObjectTrackingConfigSchema)` to create a new message.
 */
export const ObjectTrackingConfigSchema: GenMessage<ObjectTrackingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 7);

/**
 * Config for video event human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.EventConfig
 */
export type EventConfig = Message<"google.cloud.datalabeling.v1beta1.EventConfig"> & {
  /**
   * Required. The list of annotation spec set resource name. Similar to video
   * classification, we support selecting event from multiple AnnotationSpecSet
   * at the same time.
   *
   * @generated from field: repeated string annotation_spec_sets = 1;
   */
  annotationSpecSets: string[];
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.EventConfig.
 * Use `create(EventConfigSchema)` to create a new message.
 */
export const EventConfigSchema: GenMessage<EventConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 8);

/**
 * Config for text classification human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.TextClassificationConfig
 */
export type TextClassificationConfig = Message<"google.cloud.datalabeling.v1beta1.TextClassificationConfig"> & {
  /**
   * Optional. If allow_multi_label is true, contributors are able to choose
   * multiple labels for one text segment.
   *
   * @generated from field: bool allow_multi_label = 1;
   */
  allowMultiLabel: boolean;

  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 2;
   */
  annotationSpecSet: string;

  /**
   * Optional. Configs for sentiment selection.
   *
   * @generated from field: google.cloud.datalabeling.v1beta1.SentimentConfig sentiment_config = 3;
   */
  sentimentConfig?: SentimentConfig;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.TextClassificationConfig.
 * Use `create(TextClassificationConfigSchema)` to create a new message.
 */
export const TextClassificationConfigSchema: GenMessage<TextClassificationConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 9);

/**
 * Config for setting up sentiments.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.SentimentConfig
 */
export type SentimentConfig = Message<"google.cloud.datalabeling.v1beta1.SentimentConfig"> & {
  /**
   * If set to true, contributors will have the option to select sentiment of
   * the label they selected, to mark it as negative or positive label. Default
   * is false.
   *
   * @generated from field: bool enable_label_sentiment_selection = 1;
   */
  enableLabelSentimentSelection: boolean;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.SentimentConfig.
 * Use `create(SentimentConfigSchema)` to create a new message.
 */
export const SentimentConfigSchema: GenMessage<SentimentConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 10);

/**
 * Config for text entity extraction human labeling task.
 *
 * @generated from message google.cloud.datalabeling.v1beta1.TextEntityExtractionConfig
 */
export type TextEntityExtractionConfig = Message<"google.cloud.datalabeling.v1beta1.TextEntityExtractionConfig"> & {
  /**
   * Required. Annotation spec set resource name.
   *
   * @generated from field: string annotation_spec_set = 1;
   */
  annotationSpecSet: string;
};

/**
 * Describes the message google.cloud.datalabeling.v1beta1.TextEntityExtractionConfig.
 * Use `create(TextEntityExtractionConfigSchema)` to create a new message.
 */
export const TextEntityExtractionConfigSchema: GenMessage<TextEntityExtractionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 11);

/**
 * @generated from enum google.cloud.datalabeling.v1beta1.StringAggregationType
 */
export enum StringAggregationType {
  /**
   * @generated from enum value: STRING_AGGREGATION_TYPE_UNSPECIFIED = 0;
   */
  STRING_AGGREGATION_TYPE_UNSPECIFIED = 0,

  /**
   * Majority vote to aggregate answers.
   *
   * @generated from enum value: MAJORITY_VOTE = 1;
   */
  MAJORITY_VOTE = 1,

  /**
   * Unanimous answers will be adopted.
   *
   * @generated from enum value: UNANIMOUS_VOTE = 2;
   */
  UNANIMOUS_VOTE = 2,

  /**
   * Preserve all answers by crowd compute.
   *
   * @generated from enum value: NO_AGGREGATION = 3;
   */
  NO_AGGREGATION = 3,
}

/**
 * Describes the enum google.cloud.datalabeling.v1beta1.StringAggregationType.
 */
export const StringAggregationTypeSchema: GenEnum<StringAggregationType> = /*@__PURE__*/
  enumDesc(file_google_cloud_datalabeling_v1beta1_human_annotation_config, 0);

