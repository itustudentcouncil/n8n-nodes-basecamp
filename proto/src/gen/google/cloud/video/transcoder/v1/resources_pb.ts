// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/video/transcoder/v1/resources.proto (package google.cloud.video.transcoder.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../../api/resource_pb";
import type { Duration, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../../rpc/status_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/video/transcoder/v1/resources.proto.
 */
export const file_google_cloud_video_transcoder_v1_resources: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_protobuf_duration, file_google_protobuf_timestamp, file_google_rpc_status]);

/**
 * Transcoding job resource.
 *
 * @generated from message google.cloud.video.transcoder.v1.Job
 */
export type Job = Message<"google.cloud.video.transcoder.v1.Job"> & {
  /**
   * The resource name of the job.
   * Format: `projects/{project_number}/locations/{location}/jobs/{job}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Input only. Specify the `input_uri` to populate empty `uri` fields in each
   * element of `Job.config.inputs` or `JobTemplate.config.inputs` when using
   * template. URI of the media. Input files must be at least 5 seconds in
   * duration and stored in Cloud Storage (for example,
   * `gs://bucket/inputs/file.mp4`). See [Supported input and output
   * formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats).
   *
   * @generated from field: string input_uri = 2;
   */
  inputUri: string;

  /**
   * Input only. Specify the `output_uri` to populate an empty
   * `Job.config.output.uri` or `JobTemplate.config.output.uri` when using
   * template. URI for the output file(s). For example,
   * `gs://my-bucket/outputs/`. See [Supported input and output
   * formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats).
   *
   * @generated from field: string output_uri = 3;
   */
  outputUri: string;

  /**
   * Specify the `job_config` for the transcoding job. If you don't specify the
   * `job_config`, the API selects `templateId`; this template ID is set to
   * `preset/web-hd` by default. When you use a `template_id` to create a job,
   * the `Job.config` is populated by the `JobTemplate.config`.<br>
   *
   * @generated from oneof google.cloud.video.transcoder.v1.Job.job_config
   */
  jobConfig: {
    /**
     * Input only. Specify the `template_id` to use for populating `Job.config`.
     * The default is `preset/web-hd`, which is the only supported preset.
     *
     * User defined JobTemplate: `{job_template_id}`
     *
     * @generated from field: string template_id = 4;
     */
    value: string;
    case: "templateId";
  } | {
    /**
     * The configuration for this job.
     *
     * @generated from field: google.cloud.video.transcoder.v1.JobConfig config = 5;
     */
    value: JobConfig;
    case: "config";
  } | { case: undefined; value?: undefined };

  /**
   * Output only. The current state of the job.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Job.ProcessingState state = 8;
   */
  state: Job_ProcessingState;

  /**
   * Output only. The time the job was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 12;
   */
  createTime?: Timestamp;

  /**
   * Output only. The time the transcoding started.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 13;
   */
  startTime?: Timestamp;

  /**
   * Output only. The time the transcoding finished.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 14;
   */
  endTime?: Timestamp;

  /**
   * Job time to live value in days, which will be effective after job
   * completion. Job should be deleted automatically after the given TTL. Enter
   * a value between 1 and 90. The default is 30.
   *
   * @generated from field: int32 ttl_after_completion_days = 15;
   */
  ttlAfterCompletionDays: number;

  /**
   * The labels associated with this job. You can use these to organize and
   * group your jobs.
   *
   * @generated from field: map<string, string> labels = 16;
   */
  labels: { [key: string]: string };

  /**
   * Output only. An error object that describes the reason for the failure.
   * This property is always present when `state` is `FAILED`.
   *
   * @generated from field: google.rpc.Status error = 17;
   */
  error?: Status;

  /**
   * The processing mode of the job.
   * The default is `PROCESSING_MODE_INTERACTIVE`.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Job.ProcessingMode mode = 20;
   */
  mode: Job_ProcessingMode;

  /**
   * The processing priority of a batch job.
   * This field can only be set for batch mode jobs. The default value is 0.
   * This value cannot be negative. Higher values correspond to higher
   * priorities for the job.
   *
   * @generated from field: int32 batch_mode_priority = 21;
   */
  batchModePriority: number;

  /**
   * Optional. The optimization strategy of the job. The default is
   * `AUTODETECT`.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Job.OptimizationStrategy optimization = 22;
   */
  optimization: Job_OptimizationStrategy;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Job.
 * Use `create(JobSchema)` to create a new message.
 */
export const JobSchema: GenMessage<Job> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 0);

/**
 * The current state of the job.
 *
 * @generated from enum google.cloud.video.transcoder.v1.Job.ProcessingState
 */
export enum Job_ProcessingState {
  /**
   * The processing state is not specified.
   *
   * @generated from enum value: PROCESSING_STATE_UNSPECIFIED = 0;
   */
  PROCESSING_STATE_UNSPECIFIED = 0,

  /**
   * The job is enqueued and will be picked up for processing soon.
   *
   * @generated from enum value: PENDING = 1;
   */
  PENDING = 1,

  /**
   * The job is being processed.
   *
   * @generated from enum value: RUNNING = 2;
   */
  RUNNING = 2,

  /**
   * The job has been completed successfully.
   *
   * @generated from enum value: SUCCEEDED = 3;
   */
  SUCCEEDED = 3,

  /**
   * The job has failed. For additional information, see `failure_reason` and
   * `failure_details`
   *
   * @generated from enum value: FAILED = 4;
   */
  FAILED = 4,
}

/**
 * Describes the enum google.cloud.video.transcoder.v1.Job.ProcessingState.
 */
export const Job_ProcessingStateSchema: GenEnum<Job_ProcessingState> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_transcoder_v1_resources, 0, 0);

/**
 * The processing mode of the job.
 *
 * @generated from enum google.cloud.video.transcoder.v1.Job.ProcessingMode
 */
export enum Job_ProcessingMode {
  /**
   * The job processing mode is not specified.
   *
   * @generated from enum value: PROCESSING_MODE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * The job processing mode is interactive mode.
   * Interactive job will either be ran or rejected if quota does not allow
   * for it.
   *
   * @generated from enum value: PROCESSING_MODE_INTERACTIVE = 1;
   */
  INTERACTIVE = 1,

  /**
   * The job processing mode is batch mode.
   * Batch mode allows queuing of jobs.
   *
   * @generated from enum value: PROCESSING_MODE_BATCH = 2;
   */
  BATCH = 2,
}

/**
 * Describes the enum google.cloud.video.transcoder.v1.Job.ProcessingMode.
 */
export const Job_ProcessingModeSchema: GenEnum<Job_ProcessingMode> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_transcoder_v1_resources, 0, 1);

/**
 * The optimization strategy of the job. The default is `AUTODETECT`.
 *
 * @generated from enum google.cloud.video.transcoder.v1.Job.OptimizationStrategy
 */
export enum Job_OptimizationStrategy {
  /**
   * The optimization strategy is not specified.
   *
   * @generated from enum value: OPTIMIZATION_STRATEGY_UNSPECIFIED = 0;
   */
  OPTIMIZATION_STRATEGY_UNSPECIFIED = 0,

  /**
   * Prioritize job processing speed.
   *
   * @generated from enum value: AUTODETECT = 1;
   */
  AUTODETECT = 1,

  /**
   * Disable all optimizations.
   *
   * @generated from enum value: DISABLED = 2;
   */
  DISABLED = 2,
}

/**
 * Describes the enum google.cloud.video.transcoder.v1.Job.OptimizationStrategy.
 */
export const Job_OptimizationStrategySchema: GenEnum<Job_OptimizationStrategy> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_transcoder_v1_resources, 0, 2);

/**
 * Transcoding job template resource.
 *
 * @generated from message google.cloud.video.transcoder.v1.JobTemplate
 */
export type JobTemplate = Message<"google.cloud.video.transcoder.v1.JobTemplate"> & {
  /**
   * The resource name of the job template.
   * Format:
   * `projects/{project_number}/locations/{location}/jobTemplates/{job_template}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The configuration for this template.
   *
   * @generated from field: google.cloud.video.transcoder.v1.JobConfig config = 2;
   */
  config?: JobConfig;

  /**
   * The labels associated with this job template. You can use these to organize
   * and group your job templates.
   *
   * @generated from field: map<string, string> labels = 3;
   */
  labels: { [key: string]: string };
};

/**
 * Describes the message google.cloud.video.transcoder.v1.JobTemplate.
 * Use `create(JobTemplateSchema)` to create a new message.
 */
export const JobTemplateSchema: GenMessage<JobTemplate> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 1);

/**
 * Job configuration
 *
 * @generated from message google.cloud.video.transcoder.v1.JobConfig
 */
export type JobConfig = Message<"google.cloud.video.transcoder.v1.JobConfig"> & {
  /**
   * List of input assets stored in Cloud Storage.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.Input inputs = 1;
   */
  inputs: Input[];

  /**
   * List of `Edit atom`s. Defines the ultimate timeline of the resulting
   * file or manifest.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.EditAtom edit_list = 2;
   */
  editList: EditAtom[];

  /**
   * List of elementary streams.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.ElementaryStream elementary_streams = 3;
   */
  elementaryStreams: ElementaryStream[];

  /**
   * List of multiplexing settings for output streams.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.MuxStream mux_streams = 4;
   */
  muxStreams: MuxStream[];

  /**
   * List of output manifests.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.Manifest manifests = 5;
   */
  manifests: Manifest[];

  /**
   * Output configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Output output = 6;
   */
  output?: Output;

  /**
   * List of ad breaks. Specifies where to insert ad break tags in the output
   * manifests.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.AdBreak ad_breaks = 7;
   */
  adBreaks: AdBreak[];

  /**
   * Destination on Pub/Sub.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PubsubDestination pubsub_destination = 8;
   */
  pubsubDestination?: PubsubDestination;

  /**
   * List of output sprite sheets.
   * Spritesheets require at least one VideoStream in the Jobconfig.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.SpriteSheet sprite_sheets = 9;
   */
  spriteSheets: SpriteSheet[];

  /**
   * List of overlays on the output video, in descending Z-order.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.Overlay overlays = 10;
   */
  overlays: Overlay[];

  /**
   * List of encryption configurations for the content.
   * Each configuration has an ID. Specify this ID in the
   * [MuxStream.encryption_id][google.cloud.video.transcoder.v1.MuxStream.encryption_id]
   * field to indicate the configuration to use for that `MuxStream` output.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.Encryption encryptions = 11;
   */
  encryptions: Encryption[];
};

/**
 * Describes the message google.cloud.video.transcoder.v1.JobConfig.
 * Use `create(JobConfigSchema)` to create a new message.
 */
export const JobConfigSchema: GenMessage<JobConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 2);

/**
 * Input asset.
 *
 * @generated from message google.cloud.video.transcoder.v1.Input
 */
export type Input = Message<"google.cloud.video.transcoder.v1.Input"> & {
  /**
   * A unique key for this input. Must be specified when using advanced
   * mapping and edit lists.
   *
   * @generated from field: string key = 1;
   */
  key: string;

  /**
   * URI of the media. Input files must be at least 5 seconds in duration and
   * stored in Cloud Storage (for example, `gs://bucket/inputs/file.mp4`).
   * If empty, the value is populated from `Job.input_uri`. See
   * [Supported input and output
   * formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats).
   *
   * @generated from field: string uri = 2;
   */
  uri: string;

  /**
   * Preprocessing configurations.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig preprocessing_config = 3;
   */
  preprocessingConfig?: PreprocessingConfig;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Input.
 * Use `create(InputSchema)` to create a new message.
 */
export const InputSchema: GenMessage<Input> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 3);

/**
 * Location of output file(s) in a Cloud Storage bucket.
 *
 * @generated from message google.cloud.video.transcoder.v1.Output
 */
export type Output = Message<"google.cloud.video.transcoder.v1.Output"> & {
  /**
   * URI for the output file(s). For example, `gs://my-bucket/outputs/`.
   * If empty, the value is populated from `Job.output_uri`. See
   * [Supported input and output
   * formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats).
   *
   * @generated from field: string uri = 1;
   */
  uri: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Output.
 * Use `create(OutputSchema)` to create a new message.
 */
export const OutputSchema: GenMessage<Output> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 4);

/**
 * Edit atom.
 *
 * @generated from message google.cloud.video.transcoder.v1.EditAtom
 */
export type EditAtom = Message<"google.cloud.video.transcoder.v1.EditAtom"> & {
  /**
   * A unique key for this atom. Must be specified when using advanced
   * mapping.
   *
   * @generated from field: string key = 1;
   */
  key: string;

  /**
   * List of `Input.key`s identifying files that should be used in this atom.
   * The listed `inputs` must have the same timeline.
   *
   * @generated from field: repeated string inputs = 2;
   */
  inputs: string[];

  /**
   * End time in seconds for the atom, relative to the input file timeline.
   * When `end_time_offset` is not specified, the `inputs` are used until
   * the end of the atom.
   *
   * @generated from field: google.protobuf.Duration end_time_offset = 3;
   */
  endTimeOffset?: Duration;

  /**
   * Start time in seconds for the atom, relative to the input file timeline.
   * The default is `0s`.
   *
   * @generated from field: google.protobuf.Duration start_time_offset = 4;
   */
  startTimeOffset?: Duration;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.EditAtom.
 * Use `create(EditAtomSchema)` to create a new message.
 */
export const EditAtomSchema: GenMessage<EditAtom> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 5);

/**
 * Ad break.
 *
 * @generated from message google.cloud.video.transcoder.v1.AdBreak
 */
export type AdBreak = Message<"google.cloud.video.transcoder.v1.AdBreak"> & {
  /**
   * Start time in seconds for the ad break, relative to the output file
   * timeline. The default is `0s`.
   *
   * @generated from field: google.protobuf.Duration start_time_offset = 1;
   */
  startTimeOffset?: Duration;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.AdBreak.
 * Use `create(AdBreakSchema)` to create a new message.
 */
export const AdBreakSchema: GenMessage<AdBreak> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 6);

/**
 * Encoding of an input file such as an audio, video, or text track.
 * Elementary streams must be packaged before
 * mapping and sharing between different output formats.
 *
 * @generated from message google.cloud.video.transcoder.v1.ElementaryStream
 */
export type ElementaryStream = Message<"google.cloud.video.transcoder.v1.ElementaryStream"> & {
  /**
   * A unique key for this elementary stream.
   *
   * @generated from field: string key = 4;
   */
  key: string;

  /**
   * Encoding of an audio, video, or text track.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.ElementaryStream.elementary_stream
   */
  elementaryStream: {
    /**
     * Encoding of a video stream.
     *
     * @generated from field: google.cloud.video.transcoder.v1.VideoStream video_stream = 1;
     */
    value: VideoStream;
    case: "videoStream";
  } | {
    /**
     * Encoding of an audio stream.
     *
     * @generated from field: google.cloud.video.transcoder.v1.AudioStream audio_stream = 2;
     */
    value: AudioStream;
    case: "audioStream";
  } | {
    /**
     * Encoding of a text stream. For example, closed captions or subtitles.
     *
     * @generated from field: google.cloud.video.transcoder.v1.TextStream text_stream = 3;
     */
    value: TextStream;
    case: "textStream";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.transcoder.v1.ElementaryStream.
 * Use `create(ElementaryStreamSchema)` to create a new message.
 */
export const ElementaryStreamSchema: GenMessage<ElementaryStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 7);

/**
 * Multiplexing settings for output stream.
 *
 * @generated from message google.cloud.video.transcoder.v1.MuxStream
 */
export type MuxStream = Message<"google.cloud.video.transcoder.v1.MuxStream"> & {
  /**
   * A unique key for this multiplexed stream. HLS media manifests will be
   * named `MuxStream.key` with the `.m3u8` extension suffix.
   *
   * @generated from field: string key = 1;
   */
  key: string;

  /**
   * The name of the generated file. The default is `MuxStream.key` with the
   * extension suffix corresponding to the `MuxStream.container`.
   *
   * Individual segments also have an incremental 10-digit zero-padded suffix
   * starting from 0 before the extension, such as `mux_stream0000000123.ts`.
   *
   * @generated from field: string file_name = 2;
   */
  fileName: string;

  /**
   * The container format. The default is `mp4`
   *
   * Supported container formats:
   *
   * - `ts`
   * - `fmp4`- the corresponding file extension is `.m4s`
   * - `mp4`
   * - `vtt`
   *
   * See also:
   * [Supported input and output
   * formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats)
   *
   * @generated from field: string container = 3;
   */
  container: string;

  /**
   * List of `ElementaryStream.key`s multiplexed in this stream.
   *
   * @generated from field: repeated string elementary_streams = 4;
   */
  elementaryStreams: string[];

  /**
   * Segment settings for `ts`, `fmp4` and `vtt`.
   *
   * @generated from field: google.cloud.video.transcoder.v1.SegmentSettings segment_settings = 5;
   */
  segmentSettings?: SegmentSettings;

  /**
   * Identifier of the encryption configuration to use. If omitted, output will
   * be unencrypted.
   *
   * @generated from field: string encryption_id = 7;
   */
  encryptionId: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.MuxStream.
 * Use `create(MuxStreamSchema)` to create a new message.
 */
export const MuxStreamSchema: GenMessage<MuxStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 8);

/**
 * Manifest configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Manifest
 */
export type Manifest = Message<"google.cloud.video.transcoder.v1.Manifest"> & {
  /**
   * The name of the generated file. The default is `manifest` with the
   * extension suffix corresponding to the `Manifest.type`.
   *
   * @generated from field: string file_name = 1;
   */
  fileName: string;

  /**
   * Required. Type of the manifest.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Manifest.ManifestType type = 2;
   */
  type: Manifest_ManifestType;

  /**
   * Required. List of user given `MuxStream.key`s that should appear in this
   * manifest.
   *
   * When `Manifest.type` is `HLS`, a media manifest with name `MuxStream.key`
   * and `.m3u8` extension is generated for each element of the
   * `Manifest.mux_streams`.
   *
   * @generated from field: repeated string mux_streams = 3;
   */
  muxStreams: string[];

  /**
   * Specifies the manifest configuration.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.Manifest.manifest_config
   */
  manifestConfig: {
    /**
     * `DASH` manifest configuration.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Manifest.DashConfig dash = 4;
     */
    value: Manifest_DashConfig;
    case: "dash";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Manifest.
 * Use `create(ManifestSchema)` to create a new message.
 */
export const ManifestSchema: GenMessage<Manifest> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 9);

/**
 * `DASH` manifest configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Manifest.DashConfig
 */
export type Manifest_DashConfig = Message<"google.cloud.video.transcoder.v1.Manifest.DashConfig"> & {
  /**
   * The segment reference scheme for a `DASH` manifest. The default is
   * `SEGMENT_LIST`.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Manifest.DashConfig.SegmentReferenceScheme segment_reference_scheme = 1;
   */
  segmentReferenceScheme: Manifest_DashConfig_SegmentReferenceScheme;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Manifest.DashConfig.
 * Use `create(Manifest_DashConfigSchema)` to create a new message.
 */
export const Manifest_DashConfigSchema: GenMessage<Manifest_DashConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 9, 0);

/**
 * The segment reference scheme for a `DASH` manifest.
 *
 * @generated from enum google.cloud.video.transcoder.v1.Manifest.DashConfig.SegmentReferenceScheme
 */
export enum Manifest_DashConfig_SegmentReferenceScheme {
  /**
   * The segment reference scheme is not specified.
   *
   * @generated from enum value: SEGMENT_REFERENCE_SCHEME_UNSPECIFIED = 0;
   */
  SEGMENT_REFERENCE_SCHEME_UNSPECIFIED = 0,

  /**
   * Lists the URLs of media files for each segment.
   *
   * @generated from enum value: SEGMENT_LIST = 1;
   */
  SEGMENT_LIST = 1,

  /**
   * Lists each segment from a template with $Number$ variable.
   *
   * @generated from enum value: SEGMENT_TEMPLATE_NUMBER = 2;
   */
  SEGMENT_TEMPLATE_NUMBER = 2,
}

/**
 * Describes the enum google.cloud.video.transcoder.v1.Manifest.DashConfig.SegmentReferenceScheme.
 */
export const Manifest_DashConfig_SegmentReferenceSchemeSchema: GenEnum<Manifest_DashConfig_SegmentReferenceScheme> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_transcoder_v1_resources, 9, 0, 0);

/**
 * The manifest type, which corresponds to the adaptive streaming format used.
 *
 * @generated from enum google.cloud.video.transcoder.v1.Manifest.ManifestType
 */
export enum Manifest_ManifestType {
  /**
   * The manifest type is not specified.
   *
   * @generated from enum value: MANIFEST_TYPE_UNSPECIFIED = 0;
   */
  MANIFEST_TYPE_UNSPECIFIED = 0,

  /**
   * Create an HLS manifest. The corresponding file extension is `.m3u8`.
   *
   * @generated from enum value: HLS = 1;
   */
  HLS = 1,

  /**
   * Create an MPEG-DASH manifest. The corresponding file extension is `.mpd`.
   *
   * @generated from enum value: DASH = 2;
   */
  DASH = 2,
}

/**
 * Describes the enum google.cloud.video.transcoder.v1.Manifest.ManifestType.
 */
export const Manifest_ManifestTypeSchema: GenEnum<Manifest_ManifestType> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_transcoder_v1_resources, 9, 0);

/**
 * A Pub/Sub destination.
 *
 * @generated from message google.cloud.video.transcoder.v1.PubsubDestination
 */
export type PubsubDestination = Message<"google.cloud.video.transcoder.v1.PubsubDestination"> & {
  /**
   * The name of the Pub/Sub topic to publish job completion notification
   * to. For example: `projects/{project}/topics/{topic}`.
   *
   * @generated from field: string topic = 1;
   */
  topic: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PubsubDestination.
 * Use `create(PubsubDestinationSchema)` to create a new message.
 */
export const PubsubDestinationSchema: GenMessage<PubsubDestination> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 10);

/**
 * Sprite sheet configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.SpriteSheet
 */
export type SpriteSheet = Message<"google.cloud.video.transcoder.v1.SpriteSheet"> & {
  /**
   * Format type. The default is `jpeg`.
   *
   * Supported formats:
   *
   * - `jpeg`
   *
   * @generated from field: string format = 1;
   */
  format: string;

  /**
   * Required. File name prefix for the generated sprite sheets.
   *
   * Each sprite sheet has an incremental 10-digit zero-padded suffix starting
   * from 0 before the extension, such as `sprite_sheet0000000123.jpeg`.
   *
   * @generated from field: string file_prefix = 2;
   */
  filePrefix: string;

  /**
   * Required. The width of sprite in pixels. Must be an even integer. To
   * preserve the source aspect ratio, set the
   * [SpriteSheet.sprite_width_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_width_pixels]
   * field or the
   * [SpriteSheet.sprite_height_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_height_pixels]
   * field, but not both (the API will automatically calculate the missing
   * field).
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the width, in pixels, per the horizontal ASR. The API calculates
   * the height per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 sprite_width_pixels = 3;
   */
  spriteWidthPixels: number;

  /**
   * Required. The height of sprite in pixels. Must be an even integer. To
   * preserve the source aspect ratio, set the
   * [SpriteSheet.sprite_height_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_height_pixels]
   * field or the
   * [SpriteSheet.sprite_width_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_width_pixels]
   * field, but not both (the API will automatically calculate the missing
   * field).
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the height, in pixels, per the horizontal ASR. The API calculates
   * the width per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 sprite_height_pixels = 4;
   */
  spriteHeightPixels: number;

  /**
   * The maximum number of sprites per row in a sprite sheet. The default is 0,
   * which indicates no maximum limit.
   *
   * @generated from field: int32 column_count = 5;
   */
  columnCount: number;

  /**
   * The maximum number of rows per sprite sheet. When the sprite sheet is full,
   * a new sprite sheet is created. The default is 0, which indicates no maximum
   * limit.
   *
   * @generated from field: int32 row_count = 6;
   */
  rowCount: number;

  /**
   * Start time in seconds, relative to the output file timeline. Determines the
   * first sprite to pick. The default is `0s`.
   *
   * @generated from field: google.protobuf.Duration start_time_offset = 7;
   */
  startTimeOffset?: Duration;

  /**
   * End time in seconds, relative to the output file timeline. When
   * `end_time_offset` is not specified, the sprites are generated until the end
   * of the output file.
   *
   * @generated from field: google.protobuf.Duration end_time_offset = 8;
   */
  endTimeOffset?: Duration;

  /**
   * Specify either total number of sprites or interval to create sprites.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.SpriteSheet.extraction_strategy
   */
  extractionStrategy: {
    /**
     * Total number of sprites. Create the specified number of sprites
     * distributed evenly across the timeline of the output media. The default
     * is 100.
     *
     * @generated from field: int32 total_count = 9;
     */
    value: number;
    case: "totalCount";
  } | {
    /**
     * Starting from `0s`, create sprites at regular intervals. Specify the
     * interval value in seconds.
     *
     * @generated from field: google.protobuf.Duration interval = 10;
     */
    value: Duration;
    case: "interval";
  } | { case: undefined; value?: undefined };

  /**
   * The quality of the generated sprite sheet. Enter a value between 1
   * and 100, where 1 is the lowest quality and 100 is the highest quality.
   * The default is 100. A high quality value corresponds to a low image data
   * compression ratio.
   *
   * @generated from field: int32 quality = 11;
   */
  quality: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.SpriteSheet.
 * Use `create(SpriteSheetSchema)` to create a new message.
 */
export const SpriteSheetSchema: GenMessage<SpriteSheet> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 11);

/**
 * Overlay configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay
 */
export type Overlay = Message<"google.cloud.video.transcoder.v1.Overlay"> & {
  /**
   * Image overlay.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Overlay.Image image = 1;
   */
  image?: Overlay_Image;

  /**
   * List of Animations. The list should be chronological, without any time
   * overlap.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.Overlay.Animation animations = 2;
   */
  animations: Overlay_Animation[];
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.
 * Use `create(OverlaySchema)` to create a new message.
 */
export const OverlaySchema: GenMessage<Overlay> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12);

/**
 * 2D normalized coordinates. Default: `{0.0, 0.0}`
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate
 */
export type Overlay_NormalizedCoordinate = Message<"google.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate"> & {
  /**
   * Normalized x coordinate.
   *
   * @generated from field: double x = 1;
   */
  x: number;

  /**
   * Normalized y coordinate.
   *
   * @generated from field: double y = 2;
   */
  y: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate.
 * Use `create(Overlay_NormalizedCoordinateSchema)` to create a new message.
 */
export const Overlay_NormalizedCoordinateSchema: GenMessage<Overlay_NormalizedCoordinate> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12, 0);

/**
 * Overlaid image.
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay.Image
 */
export type Overlay_Image = Message<"google.cloud.video.transcoder.v1.Overlay.Image"> & {
  /**
   * Required. URI of the image in Cloud Storage. For example,
   * `gs://bucket/inputs/image.png`. Only PNG and JPEG images are supported.
   *
   * @generated from field: string uri = 1;
   */
  uri: string;

  /**
   * Normalized image resolution, based on output video resolution. Valid
   * values: `0.0`–`1.0`. To respect the original image aspect ratio, set
   * either `x` or `y` to `0.0`. To use the original image resolution, set
   * both `x` and `y` to `0.0`.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate resolution = 2;
   */
  resolution?: Overlay_NormalizedCoordinate;

  /**
   * Target image opacity. Valid values are from  `1.0` (solid, default) to
   * `0.0` (transparent), exclusive. Set this to a value greater than `0.0`.
   *
   * @generated from field: double alpha = 3;
   */
  alpha: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.Image.
 * Use `create(Overlay_ImageSchema)` to create a new message.
 */
export const Overlay_ImageSchema: GenMessage<Overlay_Image> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12, 1);

/**
 * Display static overlay object.
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay.AnimationStatic
 */
export type Overlay_AnimationStatic = Message<"google.cloud.video.transcoder.v1.Overlay.AnimationStatic"> & {
  /**
   * Normalized coordinates based on output video resolution. Valid
   * values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay
   * object. For example, use the x and y coordinates {0,0} to position the
   * top-left corner of the overlay animation in the top-left corner of the
   * output video.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate xy = 1;
   */
  xy?: Overlay_NormalizedCoordinate;

  /**
   * The time to start displaying the overlay object, in seconds. Default: 0
   *
   * @generated from field: google.protobuf.Duration start_time_offset = 2;
   */
  startTimeOffset?: Duration;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.AnimationStatic.
 * Use `create(Overlay_AnimationStaticSchema)` to create a new message.
 */
export const Overlay_AnimationStaticSchema: GenMessage<Overlay_AnimationStatic> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12, 2);

/**
 * Display overlay object with fade animation.
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay.AnimationFade
 */
export type Overlay_AnimationFade = Message<"google.cloud.video.transcoder.v1.Overlay.AnimationFade"> & {
  /**
   * Required. Type of fade animation: `FADE_IN` or `FADE_OUT`.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Overlay.FadeType fade_type = 1;
   */
  fadeType: Overlay_FadeType;

  /**
   * Normalized coordinates based on output video resolution. Valid
   * values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay
   * object. For example, use the x and y coordinates {0,0} to position the
   * top-left corner of the overlay animation in the top-left corner of the
   * output video.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate xy = 2;
   */
  xy?: Overlay_NormalizedCoordinate;

  /**
   * The time to start the fade animation, in seconds. Default: 0
   *
   * @generated from field: google.protobuf.Duration start_time_offset = 3;
   */
  startTimeOffset?: Duration;

  /**
   * The time to end the fade animation, in seconds. Default:
   * `start_time_offset` + 1s
   *
   * @generated from field: google.protobuf.Duration end_time_offset = 4;
   */
  endTimeOffset?: Duration;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.AnimationFade.
 * Use `create(Overlay_AnimationFadeSchema)` to create a new message.
 */
export const Overlay_AnimationFadeSchema: GenMessage<Overlay_AnimationFade> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12, 3);

/**
 * End previous overlay animation from the video. Without AnimationEnd, the
 * overlay object will keep the state of previous animation until the end of
 * the video.
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay.AnimationEnd
 */
export type Overlay_AnimationEnd = Message<"google.cloud.video.transcoder.v1.Overlay.AnimationEnd"> & {
  /**
   * The time to end overlay object, in seconds. Default: 0
   *
   * @generated from field: google.protobuf.Duration start_time_offset = 1;
   */
  startTimeOffset?: Duration;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.AnimationEnd.
 * Use `create(Overlay_AnimationEndSchema)` to create a new message.
 */
export const Overlay_AnimationEndSchema: GenMessage<Overlay_AnimationEnd> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12, 4);

/**
 * Animation types.
 *
 * @generated from message google.cloud.video.transcoder.v1.Overlay.Animation
 */
export type Overlay_Animation = Message<"google.cloud.video.transcoder.v1.Overlay.Animation"> & {
  /**
   * Animations can be static or fade, or they can end the previous animation.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.Overlay.Animation.animation_type
   */
  animationType: {
    /**
     * Display static overlay object.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Overlay.AnimationStatic animation_static = 1;
     */
    value: Overlay_AnimationStatic;
    case: "animationStatic";
  } | {
    /**
     * Display overlay object with fade animation.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Overlay.AnimationFade animation_fade = 2;
     */
    value: Overlay_AnimationFade;
    case: "animationFade";
  } | {
    /**
     * End previous animation.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Overlay.AnimationEnd animation_end = 3;
     */
    value: Overlay_AnimationEnd;
    case: "animationEnd";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Overlay.Animation.
 * Use `create(Overlay_AnimationSchema)` to create a new message.
 */
export const Overlay_AnimationSchema: GenMessage<Overlay_Animation> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 12, 5);

/**
 * Fade type for the overlay: `FADE_IN` or `FADE_OUT`.
 *
 * @generated from enum google.cloud.video.transcoder.v1.Overlay.FadeType
 */
export enum Overlay_FadeType {
  /**
   * The fade type is not specified.
   *
   * @generated from enum value: FADE_TYPE_UNSPECIFIED = 0;
   */
  FADE_TYPE_UNSPECIFIED = 0,

  /**
   * Fade the overlay object into view.
   *
   * @generated from enum value: FADE_IN = 1;
   */
  FADE_IN = 1,

  /**
   * Fade the overlay object out of view.
   *
   * @generated from enum value: FADE_OUT = 2;
   */
  FADE_OUT = 2,
}

/**
 * Describes the enum google.cloud.video.transcoder.v1.Overlay.FadeType.
 */
export const Overlay_FadeTypeSchema: GenEnum<Overlay_FadeType> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_transcoder_v1_resources, 12, 0);

/**
 * Preprocessing configurations.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig
 */
export type PreprocessingConfig = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig"> & {
  /**
   * Color preprocessing configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Color color = 1;
   */
  color?: PreprocessingConfig_Color;

  /**
   * Denoise preprocessing configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Denoise denoise = 2;
   */
  denoise?: PreprocessingConfig_Denoise;

  /**
   * Deblock preprocessing configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Deblock deblock = 3;
   */
  deblock?: PreprocessingConfig_Deblock;

  /**
   * Audio preprocessing configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Audio audio = 4;
   */
  audio?: PreprocessingConfig_Audio;

  /**
   * Specify the video cropping configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Crop crop = 5;
   */
  crop?: PreprocessingConfig_Crop;

  /**
   * Specify the video pad filter configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Pad pad = 6;
   */
  pad?: PreprocessingConfig_Pad;

  /**
   * Specify the video deinterlace configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace deinterlace = 7;
   */
  deinterlace?: PreprocessingConfig_Deinterlace;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.
 * Use `create(PreprocessingConfigSchema)` to create a new message.
 */
export const PreprocessingConfigSchema: GenMessage<PreprocessingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13);

/**
 * Color preprocessing configuration.
 *
 * **Note:** This configuration is not supported.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Color
 */
export type PreprocessingConfig_Color = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Color"> & {
  /**
   * Control color saturation of the video. Enter a value between -1 and 1,
   * where -1 is fully desaturated and 1 is maximum saturation. 0 is no
   * change. The default is 0.
   *
   * @generated from field: double saturation = 1;
   */
  saturation: number;

  /**
   * Control black and white contrast of the video. Enter a value between -1
   * and 1, where -1 is minimum contrast and 1 is maximum contrast. 0 is no
   * change. The default is 0.
   *
   * @generated from field: double contrast = 2;
   */
  contrast: number;

  /**
   * Control brightness of the video. Enter a value between -1 and 1, where -1
   * is minimum brightness and 1 is maximum brightness. 0 is no change. The
   * default is 0.
   *
   * @generated from field: double brightness = 3;
   */
  brightness: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Color.
 * Use `create(PreprocessingConfig_ColorSchema)` to create a new message.
 */
export const PreprocessingConfig_ColorSchema: GenMessage<PreprocessingConfig_Color> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 0);

/**
 * Denoise preprocessing configuration.
 *
 * **Note:** This configuration is not supported.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Denoise
 */
export type PreprocessingConfig_Denoise = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Denoise"> & {
  /**
   * Set strength of the denoise. Enter a value between 0 and 1. The higher
   * the value, the smoother the image. 0 is no denoising. The default is 0.
   *
   * @generated from field: double strength = 1;
   */
  strength: number;

  /**
   * Set the denoiser mode. The default is `standard`.
   *
   * Supported denoiser modes:
   *
   * - `standard`
   * - `grain`
   *
   * @generated from field: string tune = 2;
   */
  tune: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Denoise.
 * Use `create(PreprocessingConfig_DenoiseSchema)` to create a new message.
 */
export const PreprocessingConfig_DenoiseSchema: GenMessage<PreprocessingConfig_Denoise> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 1);

/**
 * Deblock preprocessing configuration.
 *
 * **Note:** This configuration is not supported.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Deblock
 */
export type PreprocessingConfig_Deblock = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Deblock"> & {
  /**
   * Set strength of the deblocker. Enter a value between 0 and 1. The higher
   * the value, the stronger the block removal. 0 is no deblocking. The
   * default is 0.
   *
   * @generated from field: double strength = 1;
   */
  strength: number;

  /**
   * Enable deblocker. The default is `false`.
   *
   * @generated from field: bool enabled = 2;
   */
  enabled: boolean;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Deblock.
 * Use `create(PreprocessingConfig_DeblockSchema)` to create a new message.
 */
export const PreprocessingConfig_DeblockSchema: GenMessage<PreprocessingConfig_Deblock> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 2);

/**
 * Audio preprocessing configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Audio
 */
export type PreprocessingConfig_Audio = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Audio"> & {
  /**
   * Specify audio loudness normalization in loudness units relative to full
   * scale (LUFS). Enter a value between -24 and 0 (the default), where:
   *
   * *   -24 is the Advanced Television Systems Committee (ATSC A/85) standard
   * *   -23 is the EU R128 broadcast standard
   * *   -19 is the prior standard for online mono audio
   * *   -18 is the ReplayGain standard
   * *   -16 is the prior standard for stereo audio
   * *   -14 is the new online audio standard recommended by Spotify, as well
   *     as Amazon Echo
   * *   0 disables normalization
   *
   * @generated from field: double lufs = 1;
   */
  lufs: number;

  /**
   * Enable boosting high frequency components. The default is `false`.
   *
   * **Note:** This field is not supported.
   *
   * @generated from field: bool high_boost = 2;
   */
  highBoost: boolean;

  /**
   * Enable boosting low frequency components. The default is `false`.
   *
   * **Note:** This field is not supported.
   *
   * @generated from field: bool low_boost = 3;
   */
  lowBoost: boolean;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Audio.
 * Use `create(PreprocessingConfig_AudioSchema)` to create a new message.
 */
export const PreprocessingConfig_AudioSchema: GenMessage<PreprocessingConfig_Audio> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 3);

/**
 * Video cropping configuration for the input video. The cropped input video
 * is scaled to match the output resolution.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Crop
 */
export type PreprocessingConfig_Crop = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Crop"> & {
  /**
   * The number of pixels to crop from the top. The default is 0.
   *
   * @generated from field: int32 top_pixels = 1;
   */
  topPixels: number;

  /**
   * The number of pixels to crop from the bottom. The default is 0.
   *
   * @generated from field: int32 bottom_pixels = 2;
   */
  bottomPixels: number;

  /**
   * The number of pixels to crop from the left. The default is 0.
   *
   * @generated from field: int32 left_pixels = 3;
   */
  leftPixels: number;

  /**
   * The number of pixels to crop from the right. The default is 0.
   *
   * @generated from field: int32 right_pixels = 4;
   */
  rightPixels: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Crop.
 * Use `create(PreprocessingConfig_CropSchema)` to create a new message.
 */
export const PreprocessingConfig_CropSchema: GenMessage<PreprocessingConfig_Crop> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 4);

/**
 * Pad filter configuration for the input video. The padded input video
 * is scaled after padding with black to match the output resolution.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Pad
 */
export type PreprocessingConfig_Pad = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Pad"> & {
  /**
   * The number of pixels to add to the top. The default is 0.
   *
   * @generated from field: int32 top_pixels = 1;
   */
  topPixels: number;

  /**
   * The number of pixels to add to the bottom. The default is 0.
   *
   * @generated from field: int32 bottom_pixels = 2;
   */
  bottomPixels: number;

  /**
   * The number of pixels to add to the left. The default is 0.
   *
   * @generated from field: int32 left_pixels = 3;
   */
  leftPixels: number;

  /**
   * The number of pixels to add to the right. The default is 0.
   *
   * @generated from field: int32 right_pixels = 4;
   */
  rightPixels: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Pad.
 * Use `create(PreprocessingConfig_PadSchema)` to create a new message.
 */
export const PreprocessingConfig_PadSchema: GenMessage<PreprocessingConfig_Pad> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 5);

/**
 * Deinterlace configuration for input video.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace
 */
export type PreprocessingConfig_Deinterlace = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace"> & {
  /**
   * Specify the video deinterlacing filter. The default is `yadif`.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.deinterlacing_filter
   */
  deinterlacingFilter: {
    /**
     * Specifies the Yet Another Deinterlacing Filter Configuration.
     *
     * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfig yadif = 1;
     */
    value: PreprocessingConfig_Deinterlace_YadifConfig;
    case: "yadif";
  } | {
    /**
     * Specifies the Bob Weaver Deinterlacing Filter Configuration.
     *
     * @generated from field: google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfig bwdif = 2;
     */
    value: PreprocessingConfig_Deinterlace_BwdifConfig;
    case: "bwdif";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.
 * Use `create(PreprocessingConfig_DeinterlaceSchema)` to create a new message.
 */
export const PreprocessingConfig_DeinterlaceSchema: GenMessage<PreprocessingConfig_Deinterlace> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 6);

/**
 * Yet Another Deinterlacing Filter Configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfig
 */
export type PreprocessingConfig_Deinterlace_YadifConfig = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfig"> & {
  /**
   * Specifies the deinterlacing mode to adopt.
   * The default is `send_frame`.
   * Supported values:
   *
   * - `send_frame`: Output one frame for each frame
   * - `send_field`: Output one frame for each field
   *
   * @generated from field: string mode = 1;
   */
  mode: string;

  /**
   * Disable spacial interlacing.
   * The default is `false`.
   *
   * @generated from field: bool disable_spatial_interlacing = 2;
   */
  disableSpatialInterlacing: boolean;

  /**
   * The picture field parity assumed for the input interlaced video.
   * The default is `auto`.
   * Supported values:
   *
   * - `tff`: Assume the top field is first
   * - `bff`: Assume the bottom field is first
   * - `auto`: Enable automatic detection of field parity
   *
   * @generated from field: string parity = 3;
   */
  parity: string;

  /**
   * Deinterlace all frames rather than just the frames identified as
   * interlaced. The default is `false`.
   *
   * @generated from field: bool deinterlace_all_frames = 4;
   */
  deinterlaceAllFrames: boolean;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfig.
 * Use `create(PreprocessingConfig_Deinterlace_YadifConfigSchema)` to create a new message.
 */
export const PreprocessingConfig_Deinterlace_YadifConfigSchema: GenMessage<PreprocessingConfig_Deinterlace_YadifConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 6, 0);

/**
 * Bob Weaver Deinterlacing Filter Configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfig
 */
export type PreprocessingConfig_Deinterlace_BwdifConfig = Message<"google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfig"> & {
  /**
   * Specifies the deinterlacing mode to adopt.
   * The default is `send_frame`.
   * Supported values:
   *
   * - `send_frame`: Output one frame for each frame
   * - `send_field`: Output one frame for each field
   *
   * @generated from field: string mode = 1;
   */
  mode: string;

  /**
   * The picture field parity assumed for the input interlaced video.
   * The default is `auto`.
   * Supported values:
   *
   * - `tff`: Assume the top field is first
   * - `bff`: Assume the bottom field is first
   * - `auto`: Enable automatic detection of field parity
   *
   * @generated from field: string parity = 2;
   */
  parity: string;

  /**
   * Deinterlace all frames rather than just the frames identified as
   * interlaced. The default is `false`.
   *
   * @generated from field: bool deinterlace_all_frames = 3;
   */
  deinterlaceAllFrames: boolean;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfig.
 * Use `create(PreprocessingConfig_Deinterlace_BwdifConfigSchema)` to create a new message.
 */
export const PreprocessingConfig_Deinterlace_BwdifConfigSchema: GenMessage<PreprocessingConfig_Deinterlace_BwdifConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 13, 6, 1);

/**
 * Video stream resource.
 *
 * @generated from message google.cloud.video.transcoder.v1.VideoStream
 */
export type VideoStream = Message<"google.cloud.video.transcoder.v1.VideoStream"> & {
  /**
   * Codec settings can be h264, h265, or vp9.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.VideoStream.codec_settings
   */
  codecSettings: {
    /**
     * H264 codec settings.
     *
     * @generated from field: google.cloud.video.transcoder.v1.VideoStream.H264CodecSettings h264 = 1;
     */
    value: VideoStream_H264CodecSettings;
    case: "h264";
  } | {
    /**
     * H265 codec settings.
     *
     * @generated from field: google.cloud.video.transcoder.v1.VideoStream.H265CodecSettings h265 = 2;
     */
    value: VideoStream_H265CodecSettings;
    case: "h265";
  } | {
    /**
     * VP9 codec settings.
     *
     * @generated from field: google.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings vp9 = 3;
     */
    value: VideoStream_Vp9CodecSettings;
    case: "vp9";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.transcoder.v1.VideoStream.
 * Use `create(VideoStreamSchema)` to create a new message.
 */
export const VideoStreamSchema: GenMessage<VideoStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 14);

/**
 * H264 codec settings.
 *
 * @generated from message google.cloud.video.transcoder.v1.VideoStream.H264CodecSettings
 */
export type VideoStream_H264CodecSettings = Message<"google.cloud.video.transcoder.v1.VideoStream.H264CodecSettings"> & {
  /**
   * The width of the video in pixels. Must be an even integer.
   * When not specified, the width is adjusted to match the specified height
   * and input aspect ratio. If both are omitted, the input width is used.
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the width, in pixels, per the horizontal ASR. The API calculates
   * the height per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 width_pixels = 1;
   */
  widthPixels: number;

  /**
   * The height of the video in pixels. Must be an even integer.
   * When not specified, the height is adjusted to match the specified width
   * and input aspect ratio. If both are omitted, the input height is used.
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the height, in pixels, per the horizontal ASR. The API calculates
   * the width per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 height_pixels = 2;
   */
  heightPixels: number;

  /**
   * Required. The target video frame rate in frames per second (FPS). Must be
   * less than or equal to 120. Will default to the input frame rate if larger
   * than the input frame rate. The API will generate an output FPS that is
   * divisible by the input FPS, and smaller or equal to the target FPS. See
   * [Calculating frame
   * rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
   * more information.
   *
   * @generated from field: double frame_rate = 3;
   */
  frameRate: number;

  /**
   * Required. The video bitrate in bits per second. The minimum value is
   * 1,000. The maximum value is 800,000,000.
   *
   * @generated from field: int32 bitrate_bps = 4;
   */
  bitrateBps: number;

  /**
   * Pixel format to use. The default is `yuv420p`.
   *
   * Supported pixel formats:
   *
   * - `yuv420p` pixel format
   * - `yuv422p` pixel format
   * - `yuv444p` pixel format
   * - `yuv420p10` 10-bit HDR pixel format
   * - `yuv422p10` 10-bit HDR pixel format
   * - `yuv444p10` 10-bit HDR pixel format
   * - `yuv420p12` 12-bit HDR pixel format
   * - `yuv422p12` 12-bit HDR pixel format
   * - `yuv444p12` 12-bit HDR pixel format
   *
   * @generated from field: string pixel_format = 5;
   */
  pixelFormat: string;

  /**
   * Specify the `rate_control_mode`. The default is `vbr`.
   *
   * Supported rate control modes:
   *
   * - `vbr` - variable bitrate
   * - `crf` - constant rate factor
   *
   * @generated from field: string rate_control_mode = 6;
   */
  rateControlMode: string;

  /**
   * Target CRF level. Must be between 10 and 36, where 10 is the highest
   * quality and 36 is the most efficient compression. The default is 21.
   *
   * @generated from field: int32 crf_level = 7;
   */
  crfLevel: number;

  /**
   * Specifies whether an open Group of Pictures (GOP) structure should be
   * allowed or not. The default is `false`.
   *
   * @generated from field: bool allow_open_gop = 8;
   */
  allowOpenGop: boolean;

  /**
   * GOP mode can be either by frame count or duration.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.VideoStream.H264CodecSettings.gop_mode
   */
  gopMode: {
    /**
     * Select the GOP size based on the specified frame count. Must be greater
     * than zero.
     *
     * @generated from field: int32 gop_frame_count = 9;
     */
    value: number;
    case: "gopFrameCount";
  } | {
    /**
     * Select the GOP size based on the specified duration. The default is
     * `3s`. Note that `gopDuration` must be less than or equal to
     * [`segmentDuration`](#SegmentSettings), and
     * [`segmentDuration`](#SegmentSettings) must be divisible by
     * `gopDuration`.
     *
     * @generated from field: google.protobuf.Duration gop_duration = 10;
     */
    value: Duration;
    case: "gopDuration";
  } | { case: undefined; value?: undefined };

  /**
   * Use two-pass encoding strategy to achieve better video quality.
   * `VideoStream.rate_control_mode` must be `vbr`. The default is `false`.
   *
   * @generated from field: bool enable_two_pass = 11;
   */
  enableTwoPass: boolean;

  /**
   * Size of the Video Buffering Verifier (VBV) buffer in bits. Must be
   * greater than zero. The default is equal to `VideoStream.bitrate_bps`.
   *
   * @generated from field: int32 vbv_size_bits = 12;
   */
  vbvSizeBits: number;

  /**
   * Initial fullness of the Video Buffering Verifier (VBV) buffer in bits.
   * Must be greater than zero. The default is equal to 90% of
   * `VideoStream.vbv_size_bits`.
   *
   * @generated from field: int32 vbv_fullness_bits = 13;
   */
  vbvFullnessBits: number;

  /**
   * The entropy coder to use. The default is `cabac`.
   *
   * Supported entropy coders:
   *
   * - `cavlc`
   * - `cabac`
   *
   * @generated from field: string entropy_coder = 14;
   */
  entropyCoder: string;

  /**
   * Allow B-pyramid for reference frame selection. This may not be supported
   * on all decoders. The default is `false`.
   *
   * @generated from field: bool b_pyramid = 15;
   */
  bPyramid: boolean;

  /**
   * The number of consecutive B-frames. Must be greater than or equal to
   * zero. Must be less than `VideoStream.gop_frame_count` if set. The default
   * is 0.
   *
   * @generated from field: int32 b_frame_count = 16;
   */
  bFrameCount: number;

  /**
   * Specify the intensity of the adaptive quantizer (AQ). Must be between 0
   * and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A
   * higher value equals a lower bitrate but smoother image. The default is 0.
   *
   * @generated from field: double aq_strength = 17;
   */
  aqStrength: number;

  /**
   * Enforces the specified codec profile. The following profiles are
   * supported:
   *
   * *   `baseline`
   * *   `main`
   * *   `high` (default)
   *
   * The available options are
   * [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `H264CodecSettings`
   * message.
   *
   * @generated from field: string profile = 18;
   */
  profile: string;

  /**
   * Enforces the specified codec tune. The available options are
   * [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `H264CodecSettings`
   * message.
   *
   * @generated from field: string tune = 19;
   */
  tune: string;

  /**
   * Enforces the specified codec preset. The default is `veryfast`. The
   * available options are
   * [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Preset).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `H264CodecSettings`
   * message.
   *
   * @generated from field: string preset = 20;
   */
  preset: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.VideoStream.H264CodecSettings.
 * Use `create(VideoStream_H264CodecSettingsSchema)` to create a new message.
 */
export const VideoStream_H264CodecSettingsSchema: GenMessage<VideoStream_H264CodecSettings> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 14, 0);

/**
 * H265 codec settings.
 *
 * @generated from message google.cloud.video.transcoder.v1.VideoStream.H265CodecSettings
 */
export type VideoStream_H265CodecSettings = Message<"google.cloud.video.transcoder.v1.VideoStream.H265CodecSettings"> & {
  /**
   * The width of the video in pixels. Must be an even integer.
   * When not specified, the width is adjusted to match the specified height
   * and input aspect ratio. If both are omitted, the input width is used.
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the width, in pixels, per the horizontal ASR. The API calculates
   * the height per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 width_pixels = 1;
   */
  widthPixels: number;

  /**
   * The height of the video in pixels. Must be an even integer.
   * When not specified, the height is adjusted to match the specified width
   * and input aspect ratio. If both are omitted, the input height is used.
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the height, in pixels, per the horizontal ASR. The API calculates
   * the width per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 height_pixels = 2;
   */
  heightPixels: number;

  /**
   * Required. The target video frame rate in frames per second (FPS). Must be
   * less than or equal to 120. Will default to the input frame rate if larger
   * than the input frame rate. The API will generate an output FPS that is
   * divisible by the input FPS, and smaller or equal to the target FPS. See
   * [Calculating frame
   * rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
   * more information.
   *
   * @generated from field: double frame_rate = 3;
   */
  frameRate: number;

  /**
   * Required. The video bitrate in bits per second. The minimum value is
   * 1,000. The maximum value is 800,000,000.
   *
   * @generated from field: int32 bitrate_bps = 4;
   */
  bitrateBps: number;

  /**
   * Pixel format to use. The default is `yuv420p`.
   *
   * Supported pixel formats:
   *
   * - `yuv420p` pixel format
   * - `yuv422p` pixel format
   * - `yuv444p` pixel format
   * - `yuv420p10` 10-bit HDR pixel format
   * - `yuv422p10` 10-bit HDR pixel format
   * - `yuv444p10` 10-bit HDR pixel format
   * - `yuv420p12` 12-bit HDR pixel format
   * - `yuv422p12` 12-bit HDR pixel format
   * - `yuv444p12` 12-bit HDR pixel format
   *
   * @generated from field: string pixel_format = 5;
   */
  pixelFormat: string;

  /**
   * Specify the `rate_control_mode`. The default is `vbr`.
   *
   * Supported rate control modes:
   *
   * - `vbr` - variable bitrate
   * - `crf` - constant rate factor
   *
   * @generated from field: string rate_control_mode = 6;
   */
  rateControlMode: string;

  /**
   * Target CRF level. Must be between 10 and 36, where 10 is the highest
   * quality and 36 is the most efficient compression. The default is 21.
   *
   * @generated from field: int32 crf_level = 7;
   */
  crfLevel: number;

  /**
   * Specifies whether an open Group of Pictures (GOP) structure should be
   * allowed or not. The default is `false`.
   *
   * @generated from field: bool allow_open_gop = 8;
   */
  allowOpenGop: boolean;

  /**
   * GOP mode can be either by frame count or duration.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.VideoStream.H265CodecSettings.gop_mode
   */
  gopMode: {
    /**
     * Select the GOP size based on the specified frame count. Must be greater
     * than zero.
     *
     * @generated from field: int32 gop_frame_count = 9;
     */
    value: number;
    case: "gopFrameCount";
  } | {
    /**
     * Select the GOP size based on the specified duration. The default is
     * `3s`. Note that `gopDuration` must be less than or equal to
     * [`segmentDuration`](#SegmentSettings), and
     * [`segmentDuration`](#SegmentSettings) must be divisible by
     * `gopDuration`.
     *
     * @generated from field: google.protobuf.Duration gop_duration = 10;
     */
    value: Duration;
    case: "gopDuration";
  } | { case: undefined; value?: undefined };

  /**
   * Use two-pass encoding strategy to achieve better video quality.
   * `VideoStream.rate_control_mode` must be `vbr`. The default is `false`.
   *
   * @generated from field: bool enable_two_pass = 11;
   */
  enableTwoPass: boolean;

  /**
   * Size of the Video Buffering Verifier (VBV) buffer in bits. Must be
   * greater than zero. The default is equal to `VideoStream.bitrate_bps`.
   *
   * @generated from field: int32 vbv_size_bits = 12;
   */
  vbvSizeBits: number;

  /**
   * Initial fullness of the Video Buffering Verifier (VBV) buffer in bits.
   * Must be greater than zero. The default is equal to 90% of
   * `VideoStream.vbv_size_bits`.
   *
   * @generated from field: int32 vbv_fullness_bits = 13;
   */
  vbvFullnessBits: number;

  /**
   * Allow B-pyramid for reference frame selection. This may not be supported
   * on all decoders. The default is `false`.
   *
   * @generated from field: bool b_pyramid = 14;
   */
  bPyramid: boolean;

  /**
   * The number of consecutive B-frames. Must be greater than or equal to
   * zero. Must be less than `VideoStream.gop_frame_count` if set. The default
   * is 0.
   *
   * @generated from field: int32 b_frame_count = 15;
   */
  bFrameCount: number;

  /**
   * Specify the intensity of the adaptive quantizer (AQ). Must be between 0
   * and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A
   * higher value equals a lower bitrate but smoother image. The default is 0.
   *
   * @generated from field: double aq_strength = 16;
   */
  aqStrength: number;

  /**
   * Enforces the specified codec profile. The following profiles are
   * supported:
   *
   * *   8-bit profiles
   *     *   `main` (default)
   *     *   `main-intra`
   *     *   `mainstillpicture`
   * *   10-bit profiles
   *     *   `main10` (default)
   *     *   `main10-intra`
   *     *   `main422-10`
   *     *   `main422-10-intra`
   *     *   `main444-10`
   *     *   `main444-10-intra`
   * *   12-bit profiles
   *     *   `main12` (default)
   *     *   `main12-intra`
   *     *   `main422-12`
   *     *   `main422-12-intra`
   *     *   `main444-12`
   *     *   `main444-12-intra`
   *
   * The available options are
   * [FFmpeg-compatible](https://x265.readthedocs.io/).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `H265CodecSettings`
   * message.
   *
   * @generated from field: string profile = 17;
   */
  profile: string;

  /**
   * Enforces the specified codec tune. The available options are
   * [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `H265CodecSettings`
   * message.
   *
   * @generated from field: string tune = 18;
   */
  tune: string;

  /**
   * Enforces the specified codec preset. The default is `veryfast`. The
   * available options are
   * [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `H265CodecSettings`
   * message.
   *
   * @generated from field: string preset = 19;
   */
  preset: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.VideoStream.H265CodecSettings.
 * Use `create(VideoStream_H265CodecSettingsSchema)` to create a new message.
 */
export const VideoStream_H265CodecSettingsSchema: GenMessage<VideoStream_H265CodecSettings> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 14, 1);

/**
 * VP9 codec settings.
 *
 * @generated from message google.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings
 */
export type VideoStream_Vp9CodecSettings = Message<"google.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings"> & {
  /**
   * The width of the video in pixels. Must be an even integer.
   * When not specified, the width is adjusted to match the specified height
   * and input aspect ratio. If both are omitted, the input width is used.
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the width, in pixels, per the horizontal ASR. The API calculates
   * the height per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 width_pixels = 1;
   */
  widthPixels: number;

  /**
   * The height of the video in pixels. Must be an even integer.
   * When not specified, the height is adjusted to match the specified width
   * and input aspect ratio. If both are omitted, the input height is used.
   *
   * For portrait videos that contain horizontal ASR and rotation metadata,
   * provide the height, in pixels, per the horizontal ASR. The API calculates
   * the width per the horizontal ASR. The API detects any rotation metadata
   * and swaps the requested height and width for the output.
   *
   * @generated from field: int32 height_pixels = 2;
   */
  heightPixels: number;

  /**
   * Required. The target video frame rate in frames per second (FPS). Must be
   * less than or equal to 120. Will default to the input frame rate if larger
   * than the input frame rate. The API will generate an output FPS that is
   * divisible by the input FPS, and smaller or equal to the target FPS. See
   * [Calculating frame
   * rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
   * more information.
   *
   * @generated from field: double frame_rate = 3;
   */
  frameRate: number;

  /**
   * Required. The video bitrate in bits per second. The minimum value is
   * 1,000. The maximum value is 480,000,000.
   *
   * @generated from field: int32 bitrate_bps = 4;
   */
  bitrateBps: number;

  /**
   * Pixel format to use. The default is `yuv420p`.
   *
   * Supported pixel formats:
   *
   * - `yuv420p` pixel format
   * - `yuv422p` pixel format
   * - `yuv444p` pixel format
   * - `yuv420p10` 10-bit HDR pixel format
   * - `yuv422p10` 10-bit HDR pixel format
   * - `yuv444p10` 10-bit HDR pixel format
   * - `yuv420p12` 12-bit HDR pixel format
   * - `yuv422p12` 12-bit HDR pixel format
   * - `yuv444p12` 12-bit HDR pixel format
   *
   * @generated from field: string pixel_format = 5;
   */
  pixelFormat: string;

  /**
   * Specify the `rate_control_mode`. The default is `vbr`.
   *
   * Supported rate control modes:
   *
   * - `vbr` - variable bitrate
   *
   * @generated from field: string rate_control_mode = 6;
   */
  rateControlMode: string;

  /**
   * Target CRF level. Must be between 10 and 36, where 10 is the highest
   * quality and 36 is the most efficient compression. The default is 21.
   *
   * **Note:** This field is not supported.
   *
   * @generated from field: int32 crf_level = 7;
   */
  crfLevel: number;

  /**
   * GOP mode can be either by frame count or duration.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings.gop_mode
   */
  gopMode: {
    /**
     * Select the GOP size based on the specified frame count. Must be greater
     * than zero.
     *
     * @generated from field: int32 gop_frame_count = 8;
     */
    value: number;
    case: "gopFrameCount";
  } | {
    /**
     * Select the GOP size based on the specified duration. The default is
     * `3s`. Note that `gopDuration` must be less than or equal to
     * [`segmentDuration`](#SegmentSettings), and
     * [`segmentDuration`](#SegmentSettings) must be divisible by
     * `gopDuration`.
     *
     * @generated from field: google.protobuf.Duration gop_duration = 9;
     */
    value: Duration;
    case: "gopDuration";
  } | { case: undefined; value?: undefined };

  /**
   * Enforces the specified codec profile. The following profiles are
   * supported:
   *
   * *   `profile0` (default)
   * *   `profile1`
   * *   `profile2`
   * *   `profile3`
   *
   * The available options are
   * [WebM-compatible](https://www.webmproject.org/vp9/profiles/).
   * Note that certain values for this field may cause the
   * transcoder to override other fields you set in the `Vp9CodecSettings`
   * message.
   *
   * @generated from field: string profile = 10;
   */
  profile: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings.
 * Use `create(VideoStream_Vp9CodecSettingsSchema)` to create a new message.
 */
export const VideoStream_Vp9CodecSettingsSchema: GenMessage<VideoStream_Vp9CodecSettings> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 14, 2);

/**
 * Audio stream resource.
 *
 * @generated from message google.cloud.video.transcoder.v1.AudioStream
 */
export type AudioStream = Message<"google.cloud.video.transcoder.v1.AudioStream"> & {
  /**
   * The codec for this audio stream. The default is `aac`.
   *
   * Supported audio codecs:
   *
   * - `aac`
   * - `aac-he`
   * - `aac-he-v2`
   * - `mp3`
   * - `ac3`
   * - `eac3`
   *
   * @generated from field: string codec = 1;
   */
  codec: string;

  /**
   * Required. Audio bitrate in bits per second. Must be between 1 and
   * 10,000,000.
   *
   * @generated from field: int32 bitrate_bps = 2;
   */
  bitrateBps: number;

  /**
   * Number of audio channels. Must be between 1 and 6. The default is 2.
   *
   * @generated from field: int32 channel_count = 3;
   */
  channelCount: number;

  /**
   * A list of channel names specifying layout of the audio channels.
   * This only affects the metadata embedded in the container headers, if
   * supported by the specified format. The default is `["fl", "fr"]`.
   *
   * Supported channel names:
   *
   * - `fl` - Front left channel
   * - `fr` - Front right channel
   * - `sl` - Side left channel
   * - `sr` - Side right channel
   * - `fc` - Front center channel
   * - `lfe` - Low frequency
   *
   * @generated from field: repeated string channel_layout = 4;
   */
  channelLayout: string[];

  /**
   * The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.AudioStream.AudioMapping mapping = 5;
   */
  mapping: AudioStream_AudioMapping[];

  /**
   * The audio sample rate in Hertz. The default is 48000 Hertz.
   *
   * @generated from field: int32 sample_rate_hertz = 6;
   */
  sampleRateHertz: number;

  /**
   * The BCP-47 language code, such as `en-US` or `sr-Latn`. For more
   * information, see
   * https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. Not
   * supported in MP4 files.
   *
   * @generated from field: string language_code = 7;
   */
  languageCode: string;

  /**
   * The name for this particular audio stream that
   * will be added to the HLS/DASH manifest. Not supported in MP4 files.
   *
   * @generated from field: string display_name = 8;
   */
  displayName: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.AudioStream.
 * Use `create(AudioStreamSchema)` to create a new message.
 */
export const AudioStreamSchema: GenMessage<AudioStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 15);

/**
 * The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`.
 *
 * @generated from message google.cloud.video.transcoder.v1.AudioStream.AudioMapping
 */
export type AudioStream_AudioMapping = Message<"google.cloud.video.transcoder.v1.AudioStream.AudioMapping"> & {
  /**
   * Required. The `EditAtom.key` that references the atom with audio inputs
   * in the `Job.edit_list`.
   *
   * @generated from field: string atom_key = 1;
   */
  atomKey: string;

  /**
   * Required. The `Input.key` that identifies the input file.
   *
   * @generated from field: string input_key = 2;
   */
  inputKey: string;

  /**
   * Required. The zero-based index of the track in the input file.
   *
   * @generated from field: int32 input_track = 3;
   */
  inputTrack: number;

  /**
   * Required. The zero-based index of the channel in the input audio stream.
   *
   * @generated from field: int32 input_channel = 4;
   */
  inputChannel: number;

  /**
   * Required. The zero-based index of the channel in the output audio stream.
   *
   * @generated from field: int32 output_channel = 5;
   */
  outputChannel: number;

  /**
   * Audio volume control in dB. Negative values decrease volume,
   * positive values increase. The default is 0.
   *
   * @generated from field: double gain_db = 6;
   */
  gainDb: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.AudioStream.AudioMapping.
 * Use `create(AudioStream_AudioMappingSchema)` to create a new message.
 */
export const AudioStream_AudioMappingSchema: GenMessage<AudioStream_AudioMapping> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 15, 0);

/**
 * Encoding of a text stream. For example, closed captions or subtitles.
 *
 * @generated from message google.cloud.video.transcoder.v1.TextStream
 */
export type TextStream = Message<"google.cloud.video.transcoder.v1.TextStream"> & {
  /**
   * The codec for this text stream. The default is `webvtt`.
   *
   * Supported text codecs:
   *
   * - `srt`
   * - `ttml`
   * - `cea608`
   * - `cea708`
   * - `webvtt`
   *
   * @generated from field: string codec = 1;
   */
  codec: string;

  /**
   * The BCP-47 language code, such as `en-US` or `sr-Latn`. For more
   * information, see
   * https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. Not
   * supported in MP4 files.
   *
   * @generated from field: string language_code = 2;
   */
  languageCode: string;

  /**
   * The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`.
   *
   * @generated from field: repeated google.cloud.video.transcoder.v1.TextStream.TextMapping mapping = 3;
   */
  mapping: TextStream_TextMapping[];

  /**
   * The name for this particular text stream that
   * will be added to the HLS/DASH manifest. Not supported in MP4 files.
   *
   * @generated from field: string display_name = 4;
   */
  displayName: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.TextStream.
 * Use `create(TextStreamSchema)` to create a new message.
 */
export const TextStreamSchema: GenMessage<TextStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 16);

/**
 * The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`.
 *
 * @generated from message google.cloud.video.transcoder.v1.TextStream.TextMapping
 */
export type TextStream_TextMapping = Message<"google.cloud.video.transcoder.v1.TextStream.TextMapping"> & {
  /**
   * Required. The `EditAtom.key` that references atom with text inputs in the
   * `Job.edit_list`.
   *
   * @generated from field: string atom_key = 1;
   */
  atomKey: string;

  /**
   * Required. The `Input.key` that identifies the input file.
   *
   * @generated from field: string input_key = 2;
   */
  inputKey: string;

  /**
   * Required. The zero-based index of the track in the input file.
   *
   * @generated from field: int32 input_track = 3;
   */
  inputTrack: number;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.TextStream.TextMapping.
 * Use `create(TextStream_TextMappingSchema)` to create a new message.
 */
export const TextStream_TextMappingSchema: GenMessage<TextStream_TextMapping> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 16, 0);

/**
 * Segment settings for `ts`, `fmp4` and `vtt`.
 *
 * @generated from message google.cloud.video.transcoder.v1.SegmentSettings
 */
export type SegmentSettings = Message<"google.cloud.video.transcoder.v1.SegmentSettings"> & {
  /**
   * Duration of the segments in seconds. The default is `6.0s`. Note that
   * `segmentDuration` must be greater than or equal to
   * [`gopDuration`](#videostream), and `segmentDuration` must be divisible by
   * [`gopDuration`](#videostream).
   *
   * @generated from field: google.protobuf.Duration segment_duration = 1;
   */
  segmentDuration?: Duration;

  /**
   * Required. Create an individual segment file. The default is `false`.
   *
   * @generated from field: bool individual_segments = 3;
   */
  individualSegments: boolean;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.SegmentSettings.
 * Use `create(SegmentSettingsSchema)` to create a new message.
 */
export const SegmentSettingsSchema: GenMessage<SegmentSettings> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 17);

/**
 * Encryption settings.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption
 */
export type Encryption = Message<"google.cloud.video.transcoder.v1.Encryption"> & {
  /**
   * Required. Identifier for this set of encryption options.
   *
   * @generated from field: string id = 6;
   */
  id: string;

  /**
   * Encryption mode can be either `aes` or `cenc`.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.Encryption.encryption_mode
   */
  encryptionMode: {
    /**
     * Configuration for AES-128 encryption.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Encryption.Aes128Encryption aes_128 = 3;
     */
    value: Encryption_Aes128Encryption;
    case: "aes128";
  } | {
    /**
     * Configuration for SAMPLE-AES encryption.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Encryption.SampleAesEncryption sample_aes = 4;
     */
    value: Encryption_SampleAesEncryption;
    case: "sampleAes";
  } | {
    /**
     * Configuration for MPEG Common Encryption (MPEG-CENC).
     *
     * @generated from field: google.cloud.video.transcoder.v1.Encryption.MpegCommonEncryption mpeg_cenc = 5;
     */
    value: Encryption_MpegCommonEncryption;
    case: "mpegCenc";
  } | { case: undefined; value?: undefined };

  /**
   * Defines where content keys are stored.
   *
   * @generated from oneof google.cloud.video.transcoder.v1.Encryption.secret_source
   */
  secretSource: {
    /**
     * Keys are stored in Google Secret Manager.
     *
     * @generated from field: google.cloud.video.transcoder.v1.Encryption.SecretManagerSource secret_manager_key_source = 7;
     */
    value: Encryption_SecretManagerSource;
    case: "secretManagerKeySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. DRM system(s) to use; at least one must be specified. If a
   * DRM system is omitted, it is considered disabled.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Encryption.DrmSystems drm_systems = 8;
   */
  drmSystems?: Encryption_DrmSystems;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.
 * Use `create(EncryptionSchema)` to create a new message.
 */
export const EncryptionSchema: GenMessage<Encryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18);

/**
 * Configuration for AES-128 encryption.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.Aes128Encryption
 */
export type Encryption_Aes128Encryption = Message<"google.cloud.video.transcoder.v1.Encryption.Aes128Encryption"> & {
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.Aes128Encryption.
 * Use `create(Encryption_Aes128EncryptionSchema)` to create a new message.
 */
export const Encryption_Aes128EncryptionSchema: GenMessage<Encryption_Aes128Encryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 0);

/**
 * Configuration for SAMPLE-AES encryption.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.SampleAesEncryption
 */
export type Encryption_SampleAesEncryption = Message<"google.cloud.video.transcoder.v1.Encryption.SampleAesEncryption"> & {
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.SampleAesEncryption.
 * Use `create(Encryption_SampleAesEncryptionSchema)` to create a new message.
 */
export const Encryption_SampleAesEncryptionSchema: GenMessage<Encryption_SampleAesEncryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 1);

/**
 * Configuration for MPEG Common Encryption (MPEG-CENC).
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.MpegCommonEncryption
 */
export type Encryption_MpegCommonEncryption = Message<"google.cloud.video.transcoder.v1.Encryption.MpegCommonEncryption"> & {
  /**
   * Required. Specify the encryption scheme.
   *
   * Supported encryption schemes:
   *
   * - `cenc`
   * - `cbcs`
   *
   * @generated from field: string scheme = 2;
   */
  scheme: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.MpegCommonEncryption.
 * Use `create(Encryption_MpegCommonEncryptionSchema)` to create a new message.
 */
export const Encryption_MpegCommonEncryptionSchema: GenMessage<Encryption_MpegCommonEncryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 2);

/**
 * Configuration for secrets stored in Google Secret Manager.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.SecretManagerSource
 */
export type Encryption_SecretManagerSource = Message<"google.cloud.video.transcoder.v1.Encryption.SecretManagerSource"> & {
  /**
   * Required. The name of the Secret Version containing the encryption key in
   * the following format:
   * `projects/{project}/secrets/{secret_id}/versions/{version_number}`
   *
   * Note that only numbered versions are supported. Aliases like "latest" are
   * not supported.
   *
   * @generated from field: string secret_version = 1;
   */
  secretVersion: string;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.SecretManagerSource.
 * Use `create(Encryption_SecretManagerSourceSchema)` to create a new message.
 */
export const Encryption_SecretManagerSourceSchema: GenMessage<Encryption_SecretManagerSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 3);

/**
 * Widevine configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.Widevine
 */
export type Encryption_Widevine = Message<"google.cloud.video.transcoder.v1.Encryption.Widevine"> & {
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.Widevine.
 * Use `create(Encryption_WidevineSchema)` to create a new message.
 */
export const Encryption_WidevineSchema: GenMessage<Encryption_Widevine> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 4);

/**
 * Fairplay configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.Fairplay
 */
export type Encryption_Fairplay = Message<"google.cloud.video.transcoder.v1.Encryption.Fairplay"> & {
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.Fairplay.
 * Use `create(Encryption_FairplaySchema)` to create a new message.
 */
export const Encryption_FairplaySchema: GenMessage<Encryption_Fairplay> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 5);

/**
 * Playready configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.Playready
 */
export type Encryption_Playready = Message<"google.cloud.video.transcoder.v1.Encryption.Playready"> & {
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.Playready.
 * Use `create(Encryption_PlayreadySchema)` to create a new message.
 */
export const Encryption_PlayreadySchema: GenMessage<Encryption_Playready> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 6);

/**
 * Clearkey configuration.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.Clearkey
 */
export type Encryption_Clearkey = Message<"google.cloud.video.transcoder.v1.Encryption.Clearkey"> & {
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.Clearkey.
 * Use `create(Encryption_ClearkeySchema)` to create a new message.
 */
export const Encryption_ClearkeySchema: GenMessage<Encryption_Clearkey> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 7);

/**
 * Defines configuration for DRM systems in use.
 *
 * @generated from message google.cloud.video.transcoder.v1.Encryption.DrmSystems
 */
export type Encryption_DrmSystems = Message<"google.cloud.video.transcoder.v1.Encryption.DrmSystems"> & {
  /**
   * Widevine configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Encryption.Widevine widevine = 1;
   */
  widevine?: Encryption_Widevine;

  /**
   * Fairplay configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Encryption.Fairplay fairplay = 2;
   */
  fairplay?: Encryption_Fairplay;

  /**
   * Playready configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Encryption.Playready playready = 3;
   */
  playready?: Encryption_Playready;

  /**
   * Clearkey configuration.
   *
   * @generated from field: google.cloud.video.transcoder.v1.Encryption.Clearkey clearkey = 4;
   */
  clearkey?: Encryption_Clearkey;
};

/**
 * Describes the message google.cloud.video.transcoder.v1.Encryption.DrmSystems.
 * Use `create(Encryption_DrmSystemsSchema)` to create a new message.
 */
export const Encryption_DrmSystemsSchema: GenMessage<Encryption_DrmSystems> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_transcoder_v1_resources, 18, 8);

