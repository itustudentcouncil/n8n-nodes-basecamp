// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/video/livestream/v1/resources.proto (package google.cloud.video.livestream.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../../api/resource_pb";
import type { ElementaryStream, Manifest, MuxStream, PreprocessingConfig, SpriteSheet, TimecodeConfig } from "./outputs_pb";
import { file_google_cloud_video_livestream_v1_outputs } from "./outputs_pb";
import type { Duration, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../../rpc/status_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/video/livestream/v1/resources.proto.
 */
export const file_google_cloud_video_livestream_v1_resources: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_video_livestream_v1_outputs, file_google_protobuf_duration, file_google_protobuf_timestamp, file_google_rpc_status]);

/**
 * Input resource represents the endpoint from which the channel ingests
 * the input stream.
 *
 * @generated from message google.cloud.video.livestream.v1.Input
 */
export type Input = Message<"google.cloud.video.livestream.v1.Input"> & {
  /**
   * The resource name of the input, in the form of:
   * `projects/{project}/locations/{location}/inputs/{inputId}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. The update time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * User-defined key/value metadata.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Source type.
   *
   * @generated from field: google.cloud.video.livestream.v1.Input.Type type = 5;
   */
  type: Input_Type;

  /**
   * Tier defines the maximum input specification that is accepted by the
   * video pipeline. The billing is charged based on the tier specified here.
   * See [Pricing](https://cloud.google.com/livestream/pricing) for more detail.
   * The default is `HD`.
   *
   * @generated from field: google.cloud.video.livestream.v1.Input.Tier tier = 14;
   */
  tier: Input_Tier;

  /**
   * Output only. URI to push the input stream to.
   * Its format depends on the input
   * [type][google.cloud.video.livestream.v1.Input.type], for example:
   *
   * *  `RTMP_PUSH`: `rtmp://1.2.3.4/live/{STREAM-ID}`
   * *  `SRT_PUSH`: `srt://1.2.3.4:4201?streamid={STREAM-ID}`
   *
   * @generated from field: string uri = 6;
   */
  uri: string;

  /**
   * Preprocessing configurations.
   *
   * @generated from field: google.cloud.video.livestream.v1.PreprocessingConfig preprocessing_config = 9;
   */
  preprocessingConfig?: PreprocessingConfig;

  /**
   * Security rule for access control.
   *
   * @generated from field: google.cloud.video.livestream.v1.Input.SecurityRule security_rules = 12;
   */
  securityRules?: Input_SecurityRule;

  /**
   * Output only. The information for the input stream. This field will be
   * present only when this input receives the input stream.
   *
   * @generated from field: google.cloud.video.livestream.v1.InputStreamProperty input_stream_property = 15;
   */
  inputStreamProperty?: InputStreamProperty;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Input.
 * Use `create(InputSchema)` to create a new message.
 */
export const InputSchema: GenMessage<Input> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 0);

/**
 * Security rules for access control. Each field represents one security rule.
 * Only when the source of the input stream satisfies all the fields, this
 * input stream can be accepted.
 *
 * @generated from message google.cloud.video.livestream.v1.Input.SecurityRule
 */
export type Input_SecurityRule = Message<"google.cloud.video.livestream.v1.Input.SecurityRule"> & {
  /**
   * At least one ip range must match unless none specified. The IP range is
   * defined by CIDR block: for example, `192.0.1.0/24` for a range and
   * `192.0.1.0/32` for a single IP address.
   *
   * @generated from field: repeated string ip_ranges = 1;
   */
  ipRanges: string[];
};

/**
 * Describes the message google.cloud.video.livestream.v1.Input.SecurityRule.
 * Use `create(Input_SecurityRuleSchema)` to create a new message.
 */
export const Input_SecurityRuleSchema: GenMessage<Input_SecurityRule> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 0, 0);

/**
 * The type of the input.
 *
 * @generated from enum google.cloud.video.livestream.v1.Input.Type
 */
export enum Input_Type {
  /**
   * Input type is not specified.
   *
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  TYPE_UNSPECIFIED = 0,

  /**
   * Input will take an rtmp input stream.
   *
   * @generated from enum value: RTMP_PUSH = 1;
   */
  RTMP_PUSH = 1,

  /**
   * Input will take an srt (Secure Reliable Transport) input stream.
   *
   * @generated from enum value: SRT_PUSH = 2;
   */
  SRT_PUSH = 2,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.Input.Type.
 */
export const Input_TypeSchema: GenEnum<Input_Type> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 0, 0);

/**
 * Tier of the input specification.
 *
 * @generated from enum google.cloud.video.livestream.v1.Input.Tier
 */
export enum Input_Tier {
  /**
   * Tier is not specified.
   *
   * @generated from enum value: TIER_UNSPECIFIED = 0;
   */
  TIER_UNSPECIFIED = 0,

  /**
   * Resolution < 1280x720. Bitrate <= 6 Mbps. FPS <= 60.
   *
   * @generated from enum value: SD = 1;
   */
  SD = 1,

  /**
   * Resolution <= 1920x1080. Bitrate <= 25 Mbps. FPS <= 60.
   *
   * @generated from enum value: HD = 2;
   */
  HD = 2,

  /**
   * Resolution <= 4096x2160. Not supported yet.
   *
   * @generated from enum value: UHD = 3;
   */
  UHD = 3,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.Input.Tier.
 */
export const Input_TierSchema: GenEnum<Input_Tier> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 0, 1);

/**
 * Channel resource represents the processor that does a user-defined
 * "streaming" operation, which includes getting an input stream through an
 * input, transcoding it to multiple renditions, and publishing output live
 * streams in certain formats (for example, HLS or DASH) to the specified
 * location.
 *
 * @generated from message google.cloud.video.livestream.v1.Channel
 */
export type Channel = Message<"google.cloud.video.livestream.v1.Channel"> & {
  /**
   * The resource name of the channel, in the form of:
   * `projects/{project}/locations/{location}/channels/{channelId}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. The update time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * User-defined key/value metadata.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * A list of input attachments that this channel uses.
   * One channel can have multiple inputs as the input sources. Only one
   * input can be selected as the input source at one time.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.InputAttachment input_attachments = 16;
   */
  inputAttachments: InputAttachment[];

  /**
   * Output only. The
   * [InputAttachment.key][google.cloud.video.livestream.v1.InputAttachment.key]
   * that serves as the current input source. The first input in the
   * [input_attachments][google.cloud.video.livestream.v1.Channel.input_attachments]
   * is the initial input source.
   *
   * @generated from field: string active_input = 6;
   */
  activeInput: string;

  /**
   * Required. Information about the output (that is, the Cloud Storage bucket
   * to store the generated live stream).
   *
   * @generated from field: google.cloud.video.livestream.v1.Channel.Output output = 9;
   */
  output?: Channel_Output;

  /**
   * List of elementary streams.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.ElementaryStream elementary_streams = 10;
   */
  elementaryStreams: ElementaryStream[];

  /**
   * List of multiplexing settings for output streams.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.MuxStream mux_streams = 11;
   */
  muxStreams: MuxStream[];

  /**
   * List of output manifests.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.Manifest manifests = 12;
   */
  manifests: Manifest[];

  /**
   * List of output sprite sheets.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.SpriteSheet sprite_sheets = 13;
   */
  spriteSheets: SpriteSheet[];

  /**
   * Output only. State of the streaming operation.
   *
   * @generated from field: google.cloud.video.livestream.v1.Channel.StreamingState streaming_state = 14;
   */
  streamingState: Channel_StreamingState;

  /**
   * Output only. A description of the reason for the streaming error. This
   * property is always present when
   * [streaming_state][google.cloud.video.livestream.v1.Channel.streaming_state]
   * is
   * [STREAMING_ERROR][google.cloud.video.livestream.v1.Channel.StreamingState.STREAMING_ERROR].
   *
   * @generated from field: google.rpc.Status streaming_error = 18;
   */
  streamingError?: Status;

  /**
   * Configuration of platform logs for this channel.
   *
   * @generated from field: google.cloud.video.livestream.v1.LogConfig log_config = 19;
   */
  logConfig?: LogConfig;

  /**
   * Configuration of timecode for this channel.
   *
   * @generated from field: google.cloud.video.livestream.v1.TimecodeConfig timecode_config = 21;
   */
  timecodeConfig?: TimecodeConfig;

  /**
   * Encryption configurations for this channel. Each configuration has an ID
   * which is referred to by each MuxStream to indicate which configuration is
   * used for that output.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.Encryption encryptions = 24;
   */
  encryptions: Encryption[];

  /**
   * The configuration for input sources defined in
   * [input_attachments][google.cloud.video.livestream.v1.Channel.input_attachments].
   *
   * @generated from field: google.cloud.video.livestream.v1.InputConfig input_config = 25;
   */
  inputConfig?: InputConfig;

  /**
   * Optional. Configuration for retention of output files for this channel.
   *
   * @generated from field: google.cloud.video.livestream.v1.RetentionConfig retention_config = 26;
   */
  retentionConfig?: RetentionConfig;

  /**
   * Optional. List of static overlay images. Those images display over the
   * output content for the whole duration of the live stream.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.StaticOverlay static_overlays = 27;
   */
  staticOverlays: StaticOverlay[];
};

/**
 * Describes the message google.cloud.video.livestream.v1.Channel.
 * Use `create(ChannelSchema)` to create a new message.
 */
export const ChannelSchema: GenMessage<Channel> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 1);

/**
 * Location of output file(s) in a Google Cloud Storage bucket.
 *
 * @generated from message google.cloud.video.livestream.v1.Channel.Output
 */
export type Channel_Output = Message<"google.cloud.video.livestream.v1.Channel.Output"> & {
  /**
   * URI for the output file(s). For example, `gs://my-bucket/outputs/`.
   *
   * @generated from field: string uri = 1;
   */
  uri: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Channel.Output.
 * Use `create(Channel_OutputSchema)` to create a new message.
 */
export const Channel_OutputSchema: GenMessage<Channel_Output> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 1, 0);

/**
 * State of streaming operation that the channel is running.
 *
 * @generated from enum google.cloud.video.livestream.v1.Channel.StreamingState
 */
export enum Channel_StreamingState {
  /**
   * Streaming state is not specified.
   *
   * @generated from enum value: STREAMING_STATE_UNSPECIFIED = 0;
   */
  STREAMING_STATE_UNSPECIFIED = 0,

  /**
   * Channel is getting the input stream, generating the live streams to the
   * specified output location.
   *
   * @generated from enum value: STREAMING = 1;
   */
  STREAMING = 1,

  /**
   * Channel is waiting for the input stream through the input.
   *
   * @generated from enum value: AWAITING_INPUT = 2;
   */
  AWAITING_INPUT = 2,

  /**
   * Channel is running, but has trouble publishing the live streams onto the
   * specified output location (for example, the specified Cloud Storage
   * bucket is not writable).
   *
   * @generated from enum value: STREAMING_ERROR = 4;
   */
  STREAMING_ERROR = 4,

  /**
   * Channel is generating live streams with no input stream. Live streams are
   * filled out with black screen, while input stream is missing.
   * Not supported yet.
   *
   * @generated from enum value: STREAMING_NO_INPUT = 5;
   */
  STREAMING_NO_INPUT = 5,

  /**
   * Channel is stopped, finishing live streams.
   *
   * @generated from enum value: STOPPED = 6;
   */
  STOPPED = 6,

  /**
   * Channel is starting.
   *
   * @generated from enum value: STARTING = 7;
   */
  STARTING = 7,

  /**
   * Channel is stopping.
   *
   * @generated from enum value: STOPPING = 8;
   */
  STOPPING = 8,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.Channel.StreamingState.
 */
export const Channel_StreamingStateSchema: GenEnum<Channel_StreamingState> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 1, 0);

/**
 * 2D normalized coordinates.
 *
 * @generated from message google.cloud.video.livestream.v1.NormalizedCoordinate
 */
export type NormalizedCoordinate = Message<"google.cloud.video.livestream.v1.NormalizedCoordinate"> & {
  /**
   * Optional. Normalized x coordinate. Valid range is [0.0, 1.0]. Default is 0.
   *
   * @generated from field: double x = 1;
   */
  x: number;

  /**
   * Optional. Normalized y coordinate. Valid range is [0.0, 1.0]. Default is 0.
   *
   * @generated from field: double y = 2;
   */
  y: number;
};

/**
 * Describes the message google.cloud.video.livestream.v1.NormalizedCoordinate.
 * Use `create(NormalizedCoordinateSchema)` to create a new message.
 */
export const NormalizedCoordinateSchema: GenMessage<NormalizedCoordinate> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 2);

/**
 * Normalized resolution.
 *
 * @generated from message google.cloud.video.livestream.v1.NormalizedResolution
 */
export type NormalizedResolution = Message<"google.cloud.video.livestream.v1.NormalizedResolution"> & {
  /**
   * Optional. Normalized width. Valid range is [0.0, 1.0]. Default is 0.
   *
   * @generated from field: double w = 1;
   */
  w: number;

  /**
   * Optional. Normalized height. Valid range is [0.0, 1.0]. Default is 0.
   *
   * @generated from field: double h = 2;
   */
  h: number;
};

/**
 * Describes the message google.cloud.video.livestream.v1.NormalizedResolution.
 * Use `create(NormalizedResolutionSchema)` to create a new message.
 */
export const NormalizedResolutionSchema: GenMessage<NormalizedResolution> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 3);

/**
 * Configuration for the static overlay.
 *
 * @generated from message google.cloud.video.livestream.v1.StaticOverlay
 */
export type StaticOverlay = Message<"google.cloud.video.livestream.v1.StaticOverlay"> & {
  /**
   * Required. Asset to use for the overlaid image.
   * The asset must be represented in the form of:
   * `projects/{project}/locations/{location}/assets/{assetId}`.
   * The asset's resource type must be image.
   *
   * @generated from field: string asset = 1;
   */
  asset: string;

  /**
   * Optional. Normalized image resolution, based on output video resolution.
   * Valid values are [0.0, 1.0]. To respect the original image aspect ratio,
   * set either `w` or `h` to 0. To use the original image resolution, set both
   * `w` and `h` to 0. The default is {0, 0}.
   *
   * @generated from field: google.cloud.video.livestream.v1.NormalizedResolution resolution = 2;
   */
  resolution?: NormalizedResolution;

  /**
   * Optional. Position of the image in terms of normalized coordinates of the
   * upper-left corner of the image, based on output video resolution. For
   * example, use the x and y coordinates {0, 0} to position the top-left corner
   * of the overlay animation in the top-left corner of the output video.
   *
   * @generated from field: google.cloud.video.livestream.v1.NormalizedCoordinate position = 3;
   */
  position?: NormalizedCoordinate;

  /**
   * Optional. Target image opacity. Valid values are from `1.0` (solid,
   * default) to `0.0` (transparent), exclusive. Set this to a value greater
   * than `0.0`.
   *
   * @generated from field: double opacity = 4;
   */
  opacity: number;
};

/**
 * Describes the message google.cloud.video.livestream.v1.StaticOverlay.
 * Use `create(StaticOverlaySchema)` to create a new message.
 */
export const StaticOverlaySchema: GenMessage<StaticOverlay> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 4);

/**
 * Configuration for the input sources of a channel.
 *
 * @generated from message google.cloud.video.livestream.v1.InputConfig
 */
export type InputConfig = Message<"google.cloud.video.livestream.v1.InputConfig"> & {
  /**
   * Input switch mode. Default mode is `FAILOVER_PREFER_PRIMARY`.
   *
   * @generated from field: google.cloud.video.livestream.v1.InputConfig.InputSwitchMode input_switch_mode = 1;
   */
  inputSwitchMode: InputConfig_InputSwitchMode;
};

/**
 * Describes the message google.cloud.video.livestream.v1.InputConfig.
 * Use `create(InputConfigSchema)` to create a new message.
 */
export const InputConfigSchema: GenMessage<InputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 5);

/**
 * Input switch mode.
 *
 * @generated from enum google.cloud.video.livestream.v1.InputConfig.InputSwitchMode
 */
export enum InputConfig_InputSwitchMode {
  /**
   * The input switch mode is not specified.
   *
   * @generated from enum value: INPUT_SWITCH_MODE_UNSPECIFIED = 0;
   */
  INPUT_SWITCH_MODE_UNSPECIFIED = 0,

  /**
   * Automatic failover is enabled. The primary input stream is always
   * preferred over its backup input streams configured using the
   * [AutomaticFailover][google.cloud.video.livestream.v1.InputAttachment.AutomaticFailover]
   * field.
   *
   * @generated from enum value: FAILOVER_PREFER_PRIMARY = 1;
   */
  FAILOVER_PREFER_PRIMARY = 1,

  /**
   * Automatic failover is disabled. You must use the
   * [inputSwitch][google.cloud.video.livestream.v1.Event.input_switch] event
   * to switch the active input source for the channel to stream from. When
   * this mode is chosen, the
   * [AutomaticFailover][google.cloud.video.livestream.v1.InputAttachment.AutomaticFailover]
   * field is ignored.
   *
   * @generated from enum value: MANUAL = 3;
   */
  MANUAL = 3,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.InputConfig.InputSwitchMode.
 */
export const InputConfig_InputSwitchModeSchema: GenEnum<InputConfig_InputSwitchMode> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 5, 0);

/**
 * Configuration of platform logs.
 * See [Using and managing platform
 * logs](https://cloud.google.com/logging/docs/api/platform-logs#managing-logs)
 * for more information about how to view platform logs through Cloud Logging.
 *
 * @generated from message google.cloud.video.livestream.v1.LogConfig
 */
export type LogConfig = Message<"google.cloud.video.livestream.v1.LogConfig"> & {
  /**
   * The severity level of platform logging for this resource.
   *
   * @generated from field: google.cloud.video.livestream.v1.LogConfig.LogSeverity log_severity = 1;
   */
  logSeverity: LogConfig_LogSeverity;
};

/**
 * Describes the message google.cloud.video.livestream.v1.LogConfig.
 * Use `create(LogConfigSchema)` to create a new message.
 */
export const LogConfigSchema: GenMessage<LogConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 6);

/**
 * The severity level of platform logging for this channel. Logs with a
 * severity level higher than or equal to the chosen severity level will be
 * logged and can be viewed through Cloud Logging.
 * The severity level of a log is ranked as followed from low to high: DEBUG <
 * INFO < NOTICE < WARNING < ERROR < CRITICAL < ALERT < EMERGENCY.
 * See
 * [LogSeverity](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logseverity)
 * for more information.
 *
 * @generated from enum google.cloud.video.livestream.v1.LogConfig.LogSeverity
 */
export enum LogConfig_LogSeverity {
  /**
   * Log severity is not specified. This is the same as log severity is OFF.
   *
   * @generated from enum value: LOG_SEVERITY_UNSPECIFIED = 0;
   */
  LOG_SEVERITY_UNSPECIFIED = 0,

  /**
   * Log is turned off.
   *
   * @generated from enum value: OFF = 1;
   */
  OFF = 1,

  /**
   * Log with severity higher than or equal to DEBUG are logged.
   *
   * @generated from enum value: DEBUG = 100;
   */
  DEBUG = 100,

  /**
   * Logs with severity higher than or equal to INFO are logged.
   *
   * @generated from enum value: INFO = 200;
   */
  INFO = 200,

  /**
   * Logs with severity higher than or equal to WARNING are logged.
   *
   * @generated from enum value: WARNING = 400;
   */
  WARNING = 400,

  /**
   * Logs with severity higher than or equal to ERROR are logged.
   *
   * @generated from enum value: ERROR = 500;
   */
  ERROR = 500,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.LogConfig.LogSeverity.
 */
export const LogConfig_LogSeveritySchema: GenEnum<LogConfig_LogSeverity> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 6, 0);

/**
 * Configuration for retention of output files.
 *
 * @generated from message google.cloud.video.livestream.v1.RetentionConfig
 */
export type RetentionConfig = Message<"google.cloud.video.livestream.v1.RetentionConfig"> & {
  /**
   * The minimum duration for which the output files from the channel will
   * remain in the output bucket. After this duration, output files are
   * deleted asynchronously.
   *
   * When the channel is deleted, all output files are deleted from the output
   * bucket asynchronously.
   *
   * If omitted or set to zero, output files will remain in the output bucket
   * based on
   * [Manifest.segment_keep_duration][google.cloud.video.livestream.v1.Manifest.segment_keep_duration],
   * which defaults to 60s.
   *
   * If both retention_window_duration and
   * [Manifest.segment_keep_duration][google.cloud.video.livestream.v1.Manifest.segment_keep_duration]
   * are set, retention_window_duration is used and
   * [Manifest.segment_keep_duration][google.cloud.video.livestream.v1.Manifest.segment_keep_duration]
   * is ignored.
   *
   * @generated from field: google.protobuf.Duration retention_window_duration = 1;
   */
  retentionWindowDuration?: Duration;
};

/**
 * Describes the message google.cloud.video.livestream.v1.RetentionConfig.
 * Use `create(RetentionConfigSchema)` to create a new message.
 */
export const RetentionConfigSchema: GenMessage<RetentionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 7);

/**
 * Properties of the input stream.
 *
 * @generated from message google.cloud.video.livestream.v1.InputStreamProperty
 */
export type InputStreamProperty = Message<"google.cloud.video.livestream.v1.InputStreamProperty"> & {
  /**
   * The time that the current input stream is accepted and the connection is
   * established.
   *
   * @generated from field: google.protobuf.Timestamp last_establish_time = 1;
   */
  lastEstablishTime?: Timestamp;

  /**
   * Properties of the video streams.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.VideoStreamProperty video_streams = 2;
   */
  videoStreams: VideoStreamProperty[];

  /**
   * Properties of the audio streams.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.AudioStreamProperty audio_streams = 3;
   */
  audioStreams: AudioStreamProperty[];
};

/**
 * Describes the message google.cloud.video.livestream.v1.InputStreamProperty.
 * Use `create(InputStreamPropertySchema)` to create a new message.
 */
export const InputStreamPropertySchema: GenMessage<InputStreamProperty> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 8);

/**
 * Properties of the video stream.
 *
 * @generated from message google.cloud.video.livestream.v1.VideoStreamProperty
 */
export type VideoStreamProperty = Message<"google.cloud.video.livestream.v1.VideoStreamProperty"> & {
  /**
   * Index of this video stream.
   *
   * @generated from field: int32 index = 1;
   */
  index: number;

  /**
   * Properties of the video format.
   *
   * @generated from field: google.cloud.video.livestream.v1.VideoFormat video_format = 2;
   */
  videoFormat?: VideoFormat;
};

/**
 * Describes the message google.cloud.video.livestream.v1.VideoStreamProperty.
 * Use `create(VideoStreamPropertySchema)` to create a new message.
 */
export const VideoStreamPropertySchema: GenMessage<VideoStreamProperty> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 9);

/**
 * Properties of the video format.
 *
 * @generated from message google.cloud.video.livestream.v1.VideoFormat
 */
export type VideoFormat = Message<"google.cloud.video.livestream.v1.VideoFormat"> & {
  /**
   * Video codec used in this video stream.
   *
   * @generated from field: string codec = 1;
   */
  codec: string;

  /**
   * The width of the video stream in pixels.
   *
   * @generated from field: int32 width_pixels = 2;
   */
  widthPixels: number;

  /**
   * The height of the video stream in pixels.
   *
   * @generated from field: int32 height_pixels = 3;
   */
  heightPixels: number;

  /**
   * The frame rate of the input video stream.
   *
   * @generated from field: double frame_rate = 4;
   */
  frameRate: number;
};

/**
 * Describes the message google.cloud.video.livestream.v1.VideoFormat.
 * Use `create(VideoFormatSchema)` to create a new message.
 */
export const VideoFormatSchema: GenMessage<VideoFormat> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 10);

/**
 * Properties of the audio stream.
 *
 * @generated from message google.cloud.video.livestream.v1.AudioStreamProperty
 */
export type AudioStreamProperty = Message<"google.cloud.video.livestream.v1.AudioStreamProperty"> & {
  /**
   * Index of this audio stream.
   *
   * @generated from field: int32 index = 1;
   */
  index: number;

  /**
   * Properties of the audio format.
   *
   * @generated from field: google.cloud.video.livestream.v1.AudioFormat audio_format = 2;
   */
  audioFormat?: AudioFormat;
};

/**
 * Describes the message google.cloud.video.livestream.v1.AudioStreamProperty.
 * Use `create(AudioStreamPropertySchema)` to create a new message.
 */
export const AudioStreamPropertySchema: GenMessage<AudioStreamProperty> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 11);

/**
 * Properties of the audio format.
 *
 * @generated from message google.cloud.video.livestream.v1.AudioFormat
 */
export type AudioFormat = Message<"google.cloud.video.livestream.v1.AudioFormat"> & {
  /**
   * Audio codec used in this audio stream.
   *
   * @generated from field: string codec = 1;
   */
  codec: string;

  /**
   * The number of audio channels.
   *
   * @generated from field: int32 channel_count = 2;
   */
  channelCount: number;

  /**
   * A list of channel names specifying the layout of the audio channels.
   *
   * @generated from field: repeated string channel_layout = 3;
   */
  channelLayout: string[];
};

/**
 * Describes the message google.cloud.video.livestream.v1.AudioFormat.
 * Use `create(AudioFormatSchema)` to create a new message.
 */
export const AudioFormatSchema: GenMessage<AudioFormat> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 12);

/**
 * A group of information for attaching an input resource to this channel.
 *
 * @generated from message google.cloud.video.livestream.v1.InputAttachment
 */
export type InputAttachment = Message<"google.cloud.video.livestream.v1.InputAttachment"> & {
  /**
   * A unique key for this input attachment. The key must be 1-63
   * characters in length. The key must begin and end with a letter (regardless
   * of case) or a number, but can contain dashes or underscores in between.
   *
   * @generated from field: string key = 1;
   */
  key: string;

  /**
   * The resource name of an existing input, in the form of:
   * `projects/{project}/locations/{location}/inputs/{inputId}`.
   *
   * @generated from field: string input = 2;
   */
  input: string;

  /**
   * Automatic failover configurations.
   *
   * @generated from field: google.cloud.video.livestream.v1.InputAttachment.AutomaticFailover automatic_failover = 3;
   */
  automaticFailover?: InputAttachment_AutomaticFailover;
};

/**
 * Describes the message google.cloud.video.livestream.v1.InputAttachment.
 * Use `create(InputAttachmentSchema)` to create a new message.
 */
export const InputAttachmentSchema: GenMessage<InputAttachment> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 13);

/**
 * Configurations to follow when automatic failover happens.
 *
 * @generated from message google.cloud.video.livestream.v1.InputAttachment.AutomaticFailover
 */
export type InputAttachment_AutomaticFailover = Message<"google.cloud.video.livestream.v1.InputAttachment.AutomaticFailover"> & {
  /**
   * The
   * [InputAttachment.key][google.cloud.video.livestream.v1.InputAttachment.key]s
   * of inputs to failover to when this input is disconnected. Currently, only
   * up to one backup input is supported.
   *
   * @generated from field: repeated string input_keys = 1;
   */
  inputKeys: string[];
};

/**
 * Describes the message google.cloud.video.livestream.v1.InputAttachment.AutomaticFailover.
 * Use `create(InputAttachment_AutomaticFailoverSchema)` to create a new message.
 */
export const InputAttachment_AutomaticFailoverSchema: GenMessage<InputAttachment_AutomaticFailover> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 13, 0);

/**
 * Event is a sub-resource of a channel, which can be scheduled by the user to
 * execute operations on a channel resource without having to stop the channel.
 *
 * @generated from message google.cloud.video.livestream.v1.Event
 */
export type Event = Message<"google.cloud.video.livestream.v1.Event"> & {
  /**
   * The resource name of the event, in the form of:
   * `projects/{project}/locations/{location}/channels/{channelId}/events/{eventId}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. The update time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * User-defined key/value metadata.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Required. Operation to be executed by this event.
   *
   * @generated from oneof google.cloud.video.livestream.v1.Event.task
   */
  task: {
    /**
     * Switches to another input stream.
     *
     * @generated from field: google.cloud.video.livestream.v1.Event.InputSwitchTask input_switch = 5;
     */
    value: Event_InputSwitchTask;
    case: "inputSwitch";
  } | {
    /**
     * Inserts a new ad opportunity.
     *
     * @generated from field: google.cloud.video.livestream.v1.Event.AdBreakTask ad_break = 6;
     */
    value: Event_AdBreakTask;
    case: "adBreak";
  } | {
    /**
     * Stops any running ad break.
     *
     * @generated from field: google.cloud.video.livestream.v1.Event.ReturnToProgramTask return_to_program = 13;
     */
    value: Event_ReturnToProgramTask;
    case: "returnToProgram";
  } | {
    /**
     * Inserts a slate.
     *
     * @generated from field: google.cloud.video.livestream.v1.Event.SlateTask slate = 14;
     */
    value: Event_SlateTask;
    case: "slate";
  } | {
    /**
     * Mutes the stream.
     *
     * @generated from field: google.cloud.video.livestream.v1.Event.MuteTask mute = 15;
     */
    value: Event_MuteTask;
    case: "mute";
  } | {
    /**
     * Unmutes the stream.
     *
     * @generated from field: google.cloud.video.livestream.v1.Event.UnmuteTask unmute = 16;
     */
    value: Event_UnmuteTask;
    case: "unmute";
  } | { case: undefined; value?: undefined };

  /**
   * When this field is set to true, the event will be executed at the earliest
   * time that the server can schedule the event and
   * [execution_time][google.cloud.video.livestream.v1.Event.execution_time]
   * will be populated with the time that the server actually schedules the
   * event.
   *
   * @generated from field: bool execute_now = 9;
   */
  executeNow: boolean;

  /**
   * The time to execute the event. If you set
   * [execute_now][google.cloud.video.livestream.v1.Event.execute_now] to
   * `true`, then do not set this field in the `CreateEvent` request. In
   * this case, the server schedules the event and populates this field. If you
   * set [execute_now][google.cloud.video.livestream.v1.Event.execute_now] to
   * `false`, then you must set this field to at least 10 seconds in the future
   * or else the event can't be created.
   *
   * @generated from field: google.protobuf.Timestamp execution_time = 10;
   */
  executionTime?: Timestamp;

  /**
   * Output only. The state of the event.
   *
   * @generated from field: google.cloud.video.livestream.v1.Event.State state = 11;
   */
  state: Event_State;

  /**
   * Output only. An error object that describes the reason for the failure.
   * This property is always present when `state` is `FAILED`.
   *
   * @generated from field: google.rpc.Status error = 12;
   */
  error?: Status;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.
 * Use `create(EventSchema)` to create a new message.
 */
export const EventSchema: GenMessage<Event> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14);

/**
 * Switches to another input stream. Automatic failover is then disabled.
 *
 * @generated from message google.cloud.video.livestream.v1.Event.InputSwitchTask
 */
export type Event_InputSwitchTask = Message<"google.cloud.video.livestream.v1.Event.InputSwitchTask"> & {
  /**
   * The
   * [InputAttachment.key][google.cloud.video.livestream.v1.InputAttachment.key]
   * of the input to switch to.
   *
   * @generated from field: string input_key = 1;
   */
  inputKey: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.InputSwitchTask.
 * Use `create(Event_InputSwitchTaskSchema)` to create a new message.
 */
export const Event_InputSwitchTaskSchema: GenMessage<Event_InputSwitchTask> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14, 0);

/**
 * Inserts a new ad opportunity.
 *
 * @generated from message google.cloud.video.livestream.v1.Event.AdBreakTask
 */
export type Event_AdBreakTask = Message<"google.cloud.video.livestream.v1.Event.AdBreakTask"> & {
  /**
   * Duration of an ad opportunity. Must be greater than 0.
   *
   * @generated from field: google.protobuf.Duration duration = 1;
   */
  duration?: Duration;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.AdBreakTask.
 * Use `create(Event_AdBreakTaskSchema)` to create a new message.
 */
export const Event_AdBreakTaskSchema: GenMessage<Event_AdBreakTask> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14, 1);

/**
 * Inserts a slate.
 *
 * @generated from message google.cloud.video.livestream.v1.Event.SlateTask
 */
export type Event_SlateTask = Message<"google.cloud.video.livestream.v1.Event.SlateTask"> & {
  /**
   * Optional. Duration of the slate. Must be greater than 0 if specified.
   * Omit this field for a long running slate.
   *
   * @generated from field: google.protobuf.Duration duration = 1;
   */
  duration?: Duration;

  /**
   * Slate asset to use for the duration. If its duration is less than the
   * duration of the SlateTask, then the slate loops. The slate must be
   * represented in the form of:
   * `projects/{project}/locations/{location}/assets/{assetId}`.
   *
   * @generated from field: string asset = 2;
   */
  asset: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.SlateTask.
 * Use `create(Event_SlateTaskSchema)` to create a new message.
 */
export const Event_SlateTaskSchema: GenMessage<Event_SlateTask> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14, 2);

/**
 * Stops any events which are currently running. This only applies to events
 * with a duration.
 *
 * @generated from message google.cloud.video.livestream.v1.Event.ReturnToProgramTask
 */
export type Event_ReturnToProgramTask = Message<"google.cloud.video.livestream.v1.Event.ReturnToProgramTask"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.ReturnToProgramTask.
 * Use `create(Event_ReturnToProgramTaskSchema)` to create a new message.
 */
export const Event_ReturnToProgramTaskSchema: GenMessage<Event_ReturnToProgramTask> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14, 3);

/**
 * Mutes the stream.
 *
 * @generated from message google.cloud.video.livestream.v1.Event.MuteTask
 */
export type Event_MuteTask = Message<"google.cloud.video.livestream.v1.Event.MuteTask"> & {
  /**
   * Duration for which the stream should be muted. If omitted, the stream
   * will be muted until an UnmuteTask event is sent.
   *
   * @generated from field: google.protobuf.Duration duration = 1;
   */
  duration?: Duration;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.MuteTask.
 * Use `create(Event_MuteTaskSchema)` to create a new message.
 */
export const Event_MuteTaskSchema: GenMessage<Event_MuteTask> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14, 4);

/**
 * Unmutes the stream. The task fails if the stream is not currently muted.
 *
 * @generated from message google.cloud.video.livestream.v1.Event.UnmuteTask
 */
export type Event_UnmuteTask = Message<"google.cloud.video.livestream.v1.Event.UnmuteTask"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Event.UnmuteTask.
 * Use `create(Event_UnmuteTaskSchema)` to create a new message.
 */
export const Event_UnmuteTaskSchema: GenMessage<Event_UnmuteTask> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 14, 5);

/**
 * State of the event
 *
 * @generated from enum google.cloud.video.livestream.v1.Event.State
 */
export enum Event_State {
  /**
   * Event state is not specified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * Event is scheduled but not executed yet.
   *
   * @generated from enum value: SCHEDULED = 1;
   */
  SCHEDULED = 1,

  /**
   * Event is being executed.
   *
   * @generated from enum value: RUNNING = 2;
   */
  RUNNING = 2,

  /**
   * Event has been successfully executed.
   *
   * @generated from enum value: SUCCEEDED = 3;
   */
  SUCCEEDED = 3,

  /**
   * Event fails to be executed.
   *
   * @generated from enum value: FAILED = 4;
   */
  FAILED = 4,

  /**
   * Event has been created but not scheduled yet.
   *
   * @generated from enum value: PENDING = 5;
   */
  PENDING = 5,

  /**
   * Event was stopped before running for its full duration.
   *
   * @generated from enum value: STOPPED = 6;
   */
  STOPPED = 6,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.Event.State.
 */
export const Event_StateSchema: GenEnum<Event_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 14, 0);

/**
 * Clip is a sub-resource under channel. Each clip represents a clipping
 * operation that generates a VOD playlist from its channel given a set of
 * timestamp ranges.
 *
 * @generated from message google.cloud.video.livestream.v1.Clip
 */
export type Clip = Message<"google.cloud.video.livestream.v1.Clip"> & {
  /**
   * The resource name of the clip, in the following format:
   * `projects/{project}/locations/{location}/channels/{c}/clips/{clipId}`.
   * `{clipId}` is a user-specified resource id that conforms to the following
   * criteria:
   *
   * 1. 1 character minimum, 63 characters maximum
   * 2. Only contains letters, digits, underscores, and hyphens
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The creation timestamp of the clip resource.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. The timestamp when the clip request starts to be processed.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 3;
   */
  startTime?: Timestamp;

  /**
   * Output only. The update timestamp of the clip resource.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 4;
   */
  updateTime?: Timestamp;

  /**
   * The labels associated with this resource. Each label is a key-value pair.
   *
   * @generated from field: map<string, string> labels = 5;
   */
  labels: { [key: string]: string };

  /**
   * Output only. The state of the clip.
   *
   * @generated from field: google.cloud.video.livestream.v1.Clip.State state = 6;
   */
  state: Clip_State;

  /**
   * Specify the `output_uri` to determine where to place the clip segments and
   * clip manifest files in Cloud Storage. The manifests specified in
   * `clip_manifests` fields will be placed under this URI. The exact URI of the
   * generated manifests will be provided in `clip_manifests.output_uri` for
   * each manifest.
   * Example:
   * "output_uri": "gs://my-bucket/clip-outputs"
   * "clip_manifests.output_uri": "gs://my-bucket/clip-outputs/main.m3u8"
   *
   * @generated from field: string output_uri = 7;
   */
  outputUri: string;

  /**
   * Output only. An error object that describes the reason for the failure.
   * This property only presents when `state` is `FAILED`.
   *
   * @generated from field: google.rpc.Status error = 9;
   */
  error?: Status;

  /**
   * The specified ranges of segments to generate a clip.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.Clip.Slice slices = 10;
   */
  slices: Clip_Slice[];

  /**
   * Required. A list of clip manifests. Currently only one clip manifest is
   * allowed.
   *
   * @generated from field: repeated google.cloud.video.livestream.v1.Clip.ClipManifest clip_manifests = 12;
   */
  clipManifests: Clip_ClipManifest[];
};

/**
 * Describes the message google.cloud.video.livestream.v1.Clip.
 * Use `create(ClipSchema)` to create a new message.
 */
export const ClipSchema: GenMessage<Clip> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 15);

/**
 * TimeSlice represents a tuple of Unix epoch timestamps that specifies a time
 * range.
 *
 * @generated from message google.cloud.video.livestream.v1.Clip.TimeSlice
 */
export type Clip_TimeSlice = Message<"google.cloud.video.livestream.v1.Clip.TimeSlice"> & {
  /**
   * The mark-in Unix epoch time in the original live stream manifest.
   *
   * @generated from field: google.protobuf.Timestamp markin_time = 1;
   */
  markinTime?: Timestamp;

  /**
   * The mark-out Unix epoch time in the original live stream manifest.
   *
   * @generated from field: google.protobuf.Timestamp markout_time = 2;
   */
  markoutTime?: Timestamp;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Clip.TimeSlice.
 * Use `create(Clip_TimeSliceSchema)` to create a new message.
 */
export const Clip_TimeSliceSchema: GenMessage<Clip_TimeSlice> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 15, 0);

/**
 * Slice represents a slice of the requested clip.
 *
 * @generated from message google.cloud.video.livestream.v1.Clip.Slice
 */
export type Clip_Slice = Message<"google.cloud.video.livestream.v1.Clip.Slice"> & {
  /**
   * The allowlist forms of a slice.
   *
   * @generated from oneof google.cloud.video.livestream.v1.Clip.Slice.kind
   */
  kind: {
    /**
     * A slice in form of a tuple of Unix epoch time.
     *
     * @generated from field: google.cloud.video.livestream.v1.Clip.TimeSlice time_slice = 1;
     */
    value: Clip_TimeSlice;
    case: "timeSlice";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.livestream.v1.Clip.Slice.
 * Use `create(Clip_SliceSchema)` to create a new message.
 */
export const Clip_SliceSchema: GenMessage<Clip_Slice> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 15, 1);

/**
 * ClipManifest identifies a source manifest for the generated clip manifest.
 *
 * @generated from message google.cloud.video.livestream.v1.Clip.ClipManifest
 */
export type Clip_ClipManifest = Message<"google.cloud.video.livestream.v1.Clip.ClipManifest"> & {
  /**
   * Required. A unique key that identifies a manifest config in the parent
   * channel. This key is the same as `channel.manifests.key` for the selected
   * manifest.
   *
   * @generated from field: string manifest_key = 1;
   */
  manifestKey: string;

  /**
   * Output only. The output URI of the generated clip manifest. This field
   * will be populated when the CreateClip request is accepted. Current output
   * format is provided below but may change in the future. Please read this
   * field to get the uri to the generated clip manifest. Format:
   * {clip.output_uri}/{channel.manifest.fileName} Example:
   * gs://my-bucket/clip-outputs/main.m3u8
   *
   * @generated from field: string output_uri = 2;
   */
  outputUri: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Clip.ClipManifest.
 * Use `create(Clip_ClipManifestSchema)` to create a new message.
 */
export const Clip_ClipManifestSchema: GenMessage<Clip_ClipManifest> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 15, 2);

/**
 * State of clipping operation.
 *
 * @generated from enum google.cloud.video.livestream.v1.Clip.State
 */
export enum Clip_State {
  /**
   * State is not specified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The operation is pending to be picked up by the server.
   *
   * @generated from enum value: PENDING = 1;
   */
  PENDING = 1,

  /**
   * The server admitted this create clip request, and
   * outputs are under processing.
   *
   * @generated from enum value: CREATING = 2;
   */
  CREATING = 2,

  /**
   * Outputs are available in the specified Cloud Storage bucket. For
   * additional information, see the `outputs` field.
   *
   * @generated from enum value: SUCCEEDED = 3;
   */
  SUCCEEDED = 3,

  /**
   * The operation has failed. For additional information, see the `error`
   * field.
   *
   * @generated from enum value: FAILED = 4;
   */
  FAILED = 4,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.Clip.State.
 */
export const Clip_StateSchema: GenEnum<Clip_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 15, 0);

/**
 * An asset represents a video or an image.
 *
 * @generated from message google.cloud.video.livestream.v1.Asset
 */
export type Asset = Message<"google.cloud.video.livestream.v1.Asset"> & {
  /**
   * The resource name of the asset, in the form of:
   * `projects/{project}/locations/{location}/assets/{assetId}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. The update time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * User-defined key/value metadata.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * The reference to the asset.
   * The maximum size of the resource is 250 MB.
   *
   * @generated from oneof google.cloud.video.livestream.v1.Asset.resource
   */
  resource: {
    /**
     * VideoAsset represents a video.
     *
     * @generated from field: google.cloud.video.livestream.v1.Asset.VideoAsset video = 5;
     */
    value: Asset_VideoAsset;
    case: "video";
  } | {
    /**
     * ImageAsset represents an image.
     *
     * @generated from field: google.cloud.video.livestream.v1.Asset.ImageAsset image = 6;
     */
    value: Asset_ImageAsset;
    case: "image";
  } | { case: undefined; value?: undefined };

  /**
   * Based64-encoded CRC32c checksum of the asset file. For more information,
   * see the crc32c checksum of the [Cloud Storage Objects
   * resource](https://cloud.google.com/storage/docs/json_api/v1/objects).
   * If crc32c is omitted or left empty when the asset is created, this field is
   * filled by the crc32c checksum of the Cloud Storage object indicated by
   * [VideoAsset.uri][google.cloud.video.livestream.v1.Asset.VideoAsset.uri] or
   * [ImageAsset.uri][google.cloud.video.livestream.v1.Asset.ImageAsset.uri]. If
   * crc32c is set, the asset can't be created if the crc32c value does not
   * match with the crc32c checksum of the Cloud Storage object indicated by
   * [VideoAsset.uri][google.cloud.video.livestream.v1.Asset.VideoAsset.uri] or
   * [ImageAsset.uri][google.cloud.video.livestream.v1.Asset.ImageAsset.uri].
   *
   * @generated from field: string crc32c = 7;
   */
  crc32c: string;

  /**
   * Output only. The state of the asset resource.
   *
   * @generated from field: google.cloud.video.livestream.v1.Asset.State state = 8;
   */
  state: Asset_State;

  /**
   * Output only. Only present when `state` is `ERROR`. The reason for the error
   * state of the asset.
   *
   * @generated from field: google.rpc.Status error = 9;
   */
  error?: Status;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Asset.
 * Use `create(AssetSchema)` to create a new message.
 */
export const AssetSchema: GenMessage<Asset> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 16);

/**
 * VideoAsset represents a video. The supported formats are MP4, MPEG-TS, and
 * FLV. The supported video codec is H264. The supported audio codecs are
 * AAC, AC3, MP2, and MP3.
 *
 * @generated from message google.cloud.video.livestream.v1.Asset.VideoAsset
 */
export type Asset_VideoAsset = Message<"google.cloud.video.livestream.v1.Asset.VideoAsset"> & {
  /**
   * Cloud Storage URI of the video. The format is `gs://my-bucket/my-object`.
   *
   * @generated from field: string uri = 1;
   */
  uri: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Asset.VideoAsset.
 * Use `create(Asset_VideoAssetSchema)` to create a new message.
 */
export const Asset_VideoAssetSchema: GenMessage<Asset_VideoAsset> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 16, 0);

/**
 * Image represents an image. The supported formats are JPEG, PNG.
 *
 * @generated from message google.cloud.video.livestream.v1.Asset.ImageAsset
 */
export type Asset_ImageAsset = Message<"google.cloud.video.livestream.v1.Asset.ImageAsset"> & {
  /**
   * Cloud Storage URI of the image. The format is `gs://my-bucket/my-object`.
   *
   * @generated from field: string uri = 1;
   */
  uri: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Asset.ImageAsset.
 * Use `create(Asset_ImageAssetSchema)` to create a new message.
 */
export const Asset_ImageAssetSchema: GenMessage<Asset_ImageAsset> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 16, 1);

/**
 * State of the asset resource.
 *
 * @generated from enum google.cloud.video.livestream.v1.Asset.State
 */
export enum Asset_State {
  /**
   * State is not specified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The asset is being created.
   *
   * @generated from enum value: CREATING = 1;
   */
  CREATING = 1,

  /**
   * The asset is ready for use.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * The asset is being deleted.
   *
   * @generated from enum value: DELETING = 3;
   */
  DELETING = 3,

  /**
   * The asset has an error.
   *
   * @generated from enum value: ERROR = 4;
   */
  ERROR = 4,
}

/**
 * Describes the enum google.cloud.video.livestream.v1.Asset.State.
 */
export const Asset_StateSchema: GenEnum<Asset_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_video_livestream_v1_resources, 16, 0);

/**
 * Encryption settings.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption
 */
export type Encryption = Message<"google.cloud.video.livestream.v1.Encryption"> & {
  /**
   * Required. Identifier for this set of encryption options. The ID must be
   * 1-63 characters in length. The ID must begin and end with a letter
   * (regardless of case) or a number, but can contain dashes or underscores in
   * between.
   *
   * @generated from field: string id = 1;
   */
  id: string;

  /**
   * Defines where content keys are stored.
   *
   * @generated from oneof google.cloud.video.livestream.v1.Encryption.secret_source
   */
  secretSource: {
    /**
     * For keys stored in Google Secret Manager.
     *
     * @generated from field: google.cloud.video.livestream.v1.Encryption.SecretManagerSource secret_manager_key_source = 7;
     */
    value: Encryption_SecretManagerSource;
    case: "secretManagerKeySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. Configuration for DRM systems.
   *
   * @generated from field: google.cloud.video.livestream.v1.Encryption.DrmSystems drm_systems = 3;
   */
  drmSystems?: Encryption_DrmSystems;

  /**
   * Encryption modes for HLS and MPEG-Dash.
   *
   * @generated from oneof google.cloud.video.livestream.v1.Encryption.encryption_mode
   */
  encryptionMode: {
    /**
     * Configuration for HLS AES-128 encryption.
     *
     * @generated from field: google.cloud.video.livestream.v1.Encryption.Aes128Encryption aes128 = 4;
     */
    value: Encryption_Aes128Encryption;
    case: "aes128";
  } | {
    /**
     * Configuration for HLS SAMPLE-AES encryption.
     *
     * @generated from field: google.cloud.video.livestream.v1.Encryption.SampleAesEncryption sample_aes = 5;
     */
    value: Encryption_SampleAesEncryption;
    case: "sampleAes";
  } | {
    /**
     * Configuration for MPEG-Dash Common Encryption (MPEG-CENC).
     *
     * @generated from field: google.cloud.video.livestream.v1.Encryption.MpegCommonEncryption mpeg_cenc = 6;
     */
    value: Encryption_MpegCommonEncryption;
    case: "mpegCenc";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.
 * Use `create(EncryptionSchema)` to create a new message.
 */
export const EncryptionSchema: GenMessage<Encryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17);

/**
 * Configuration for secrets stored in Google Secret Manager.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.SecretManagerSource
 */
export type Encryption_SecretManagerSource = Message<"google.cloud.video.livestream.v1.Encryption.SecretManagerSource"> & {
  /**
   * Required. The name of the Secret Version containing the encryption key.
   * `projects/{project}/secrets/{secret_id}/versions/{version_number}`
   *
   * @generated from field: string secret_version = 1;
   */
  secretVersion: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.SecretManagerSource.
 * Use `create(Encryption_SecretManagerSourceSchema)` to create a new message.
 */
export const Encryption_SecretManagerSourceSchema: GenMessage<Encryption_SecretManagerSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 0);

/**
 * Widevine configuration.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.Widevine
 */
export type Encryption_Widevine = Message<"google.cloud.video.livestream.v1.Encryption.Widevine"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.Widevine.
 * Use `create(Encryption_WidevineSchema)` to create a new message.
 */
export const Encryption_WidevineSchema: GenMessage<Encryption_Widevine> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 1);

/**
 * Fairplay configuration.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.Fairplay
 */
export type Encryption_Fairplay = Message<"google.cloud.video.livestream.v1.Encryption.Fairplay"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.Fairplay.
 * Use `create(Encryption_FairplaySchema)` to create a new message.
 */
export const Encryption_FairplaySchema: GenMessage<Encryption_Fairplay> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 2);

/**
 * Playready configuration.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.Playready
 */
export type Encryption_Playready = Message<"google.cloud.video.livestream.v1.Encryption.Playready"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.Playready.
 * Use `create(Encryption_PlayreadySchema)` to create a new message.
 */
export const Encryption_PlayreadySchema: GenMessage<Encryption_Playready> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 3);

/**
 * Clearkey configuration.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.Clearkey
 */
export type Encryption_Clearkey = Message<"google.cloud.video.livestream.v1.Encryption.Clearkey"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.Clearkey.
 * Use `create(Encryption_ClearkeySchema)` to create a new message.
 */
export const Encryption_ClearkeySchema: GenMessage<Encryption_Clearkey> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 4);

/**
 * Defines configuration for DRM systems in use. If a field is omitted,
 * that DRM system will be considered to be disabled.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.DrmSystems
 */
export type Encryption_DrmSystems = Message<"google.cloud.video.livestream.v1.Encryption.DrmSystems"> & {
  /**
   * Widevine configuration.
   *
   * @generated from field: google.cloud.video.livestream.v1.Encryption.Widevine widevine = 1;
   */
  widevine?: Encryption_Widevine;

  /**
   * Fairplay configuration.
   *
   * @generated from field: google.cloud.video.livestream.v1.Encryption.Fairplay fairplay = 2;
   */
  fairplay?: Encryption_Fairplay;

  /**
   * Playready configuration.
   *
   * @generated from field: google.cloud.video.livestream.v1.Encryption.Playready playready = 3;
   */
  playready?: Encryption_Playready;

  /**
   * Clearkey configuration.
   *
   * @generated from field: google.cloud.video.livestream.v1.Encryption.Clearkey clearkey = 4;
   */
  clearkey?: Encryption_Clearkey;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.DrmSystems.
 * Use `create(Encryption_DrmSystemsSchema)` to create a new message.
 */
export const Encryption_DrmSystemsSchema: GenMessage<Encryption_DrmSystems> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 5);

/**
 * Configuration for HLS AES-128 encryption.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.Aes128Encryption
 */
export type Encryption_Aes128Encryption = Message<"google.cloud.video.livestream.v1.Encryption.Aes128Encryption"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.Aes128Encryption.
 * Use `create(Encryption_Aes128EncryptionSchema)` to create a new message.
 */
export const Encryption_Aes128EncryptionSchema: GenMessage<Encryption_Aes128Encryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 6);

/**
 * Configuration for HLS SAMPLE-AES encryption.
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.SampleAesEncryption
 */
export type Encryption_SampleAesEncryption = Message<"google.cloud.video.livestream.v1.Encryption.SampleAesEncryption"> & {
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.SampleAesEncryption.
 * Use `create(Encryption_SampleAesEncryptionSchema)` to create a new message.
 */
export const Encryption_SampleAesEncryptionSchema: GenMessage<Encryption_SampleAesEncryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 7);

/**
 * Configuration for MPEG-Dash Common Encryption (MPEG-CENC).
 *
 * @generated from message google.cloud.video.livestream.v1.Encryption.MpegCommonEncryption
 */
export type Encryption_MpegCommonEncryption = Message<"google.cloud.video.livestream.v1.Encryption.MpegCommonEncryption"> & {
  /**
   * Required. Specify the encryption scheme, supported schemes:
   * - `cenc` - AES-CTR subsample
   * - `cbcs`- AES-CBC subsample pattern
   *
   * @generated from field: string scheme = 1;
   */
  scheme: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Encryption.MpegCommonEncryption.
 * Use `create(Encryption_MpegCommonEncryptionSchema)` to create a new message.
 */
export const Encryption_MpegCommonEncryptionSchema: GenMessage<Encryption_MpegCommonEncryption> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 17, 8);

/**
 * Pool resource defines the configuration of Live Stream pools for a specific
 * location. Currently we support only one pool resource per project per
 * location. After the creation of the first input, a default pool is created
 * automatically at "projects/{project}/locations/{location}/pools/default".
 *
 * @generated from message google.cloud.video.livestream.v1.Pool
 */
export type Pool = Message<"google.cloud.video.livestream.v1.Pool"> & {
  /**
   * The resource name of the pool, in the form of:
   * `projects/{project}/locations/{location}/pools/{poolId}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. The update time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * User-defined key/value metadata.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Network configuration for the pool.
   *
   * @generated from field: google.cloud.video.livestream.v1.Pool.NetworkConfig network_config = 5;
   */
  networkConfig?: Pool_NetworkConfig;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Pool.
 * Use `create(PoolSchema)` to create a new message.
 */
export const PoolSchema: GenMessage<Pool> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 18);

/**
 * Defines the network configuration for the pool.
 *
 * @generated from message google.cloud.video.livestream.v1.Pool.NetworkConfig
 */
export type Pool_NetworkConfig = Message<"google.cloud.video.livestream.v1.Pool.NetworkConfig"> & {
  /**
   * peered_network is the network resource URL of the network that is peered
   * to the service provider network. Must be of the format
   * projects/NETWORK_PROJECT_NUMBER/global/networks/NETWORK_NAME, where
   * NETWORK_PROJECT_NUMBER is the project number of the Cloud project that
   * holds your VPC network and NETWORK_NAME is the name of your VPC network.
   * If peered_network is omitted or empty, the pool will use endpoints that
   * are publicly available.
   *
   * @generated from field: string peered_network = 1;
   */
  peeredNetwork: string;
};

/**
 * Describes the message google.cloud.video.livestream.v1.Pool.NetworkConfig.
 * Use `create(Pool_NetworkConfigSchema)` to create a new message.
 */
export const Pool_NetworkConfigSchema: GenMessage<Pool_NetworkConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_video_livestream_v1_resources, 18, 0);

