// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/visionai/v1alpha1/platform.proto (package google.cloud.visionai.v1alpha1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { StreamAnnotation, StreamAnnotationType } from "./annotations_pb";
import { file_google_cloud_visionai_v1alpha1_annotations } from "./annotations_pb";
import type { GcsSource } from "./common_pb";
import { file_google_cloud_visionai_v1alpha1_common } from "./common_pb";
import type { OperationSchema } from "../../../longrunning/operations_pb";
import { file_google_longrunning_operations } from "../../../longrunning/operations_pb";
import type { Duration, FieldMask, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_field_mask, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/visionai/v1alpha1/platform.proto.
 */
export const file_google_cloud_visionai_v1alpha1_platform: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_cloud_visionai_v1alpha1_annotations, file_google_cloud_visionai_v1alpha1_common, file_google_longrunning_operations, file_google_protobuf_duration, file_google_protobuf_field_mask, file_google_protobuf_timestamp]);

/**
 * Message for DeleteApplicationInstance Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeleteApplicationInstancesResponse
 */
export type DeleteApplicationInstancesResponse = Message<"google.cloud.visionai.v1alpha1.DeleteApplicationInstancesResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeleteApplicationInstancesResponse.
 * Use `create(DeleteApplicationInstancesResponseSchema)` to create a new message.
 */
export const DeleteApplicationInstancesResponseSchema: GenMessage<DeleteApplicationInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 0);

/**
 * Message for CreateApplicationInstance Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.CreateApplicationInstancesResponse
 */
export type CreateApplicationInstancesResponse = Message<"google.cloud.visionai.v1alpha1.CreateApplicationInstancesResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CreateApplicationInstancesResponse.
 * Use `create(CreateApplicationInstancesResponseSchema)` to create a new message.
 */
export const CreateApplicationInstancesResponseSchema: GenMessage<CreateApplicationInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 1);

/**
 * Message for UpdateApplicationInstances Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateApplicationInstancesResponse
 */
export type UpdateApplicationInstancesResponse = Message<"google.cloud.visionai.v1alpha1.UpdateApplicationInstancesResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateApplicationInstancesResponse.
 * Use `create(UpdateApplicationInstancesResponseSchema)` to create a new message.
 */
export const UpdateApplicationInstancesResponseSchema: GenMessage<UpdateApplicationInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 2);

/**
 * Message for adding stream input to an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.CreateApplicationInstancesRequest
 */
export type CreateApplicationInstancesRequest = Message<"google.cloud.visionai.v1alpha1.CreateApplicationInstancesRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The resources being created.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ApplicationInstance application_instances = 2;
   */
  applicationInstances: ApplicationInstance[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CreateApplicationInstancesRequest.
 * Use `create(CreateApplicationInstancesRequestSchema)` to create a new message.
 */
export const CreateApplicationInstancesRequestSchema: GenMessage<CreateApplicationInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 3);

/**
 * Message for removing stream input from an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeleteApplicationInstancesRequest
 */
export type DeleteApplicationInstancesRequest = Message<"google.cloud.visionai.v1alpha1.DeleteApplicationInstancesRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: repeated string instance_ids = 2;
   */
  instanceIds: string[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeleteApplicationInstancesRequest.
 * Use `create(DeleteApplicationInstancesRequestSchema)` to create a new message.
 */
export const DeleteApplicationInstancesRequestSchema: GenMessage<DeleteApplicationInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 4);

/**
 * RPC Request Messages.
 * Message for DeployApplication Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeployApplicationResponse
 */
export type DeployApplicationResponse = Message<"google.cloud.visionai.v1alpha1.DeployApplicationResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeployApplicationResponse.
 * Use `create(DeployApplicationResponseSchema)` to create a new message.
 */
export const DeployApplicationResponseSchema: GenMessage<DeployApplicationResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 5);

/**
 * Message for UndeployApplication Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UndeployApplicationResponse
 */
export type UndeployApplicationResponse = Message<"google.cloud.visionai.v1alpha1.UndeployApplicationResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UndeployApplicationResponse.
 * Use `create(UndeployApplicationResponseSchema)` to create a new message.
 */
export const UndeployApplicationResponseSchema: GenMessage<UndeployApplicationResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 6);

/**
 * Message for RemoveApplicationStreamInput Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputResponse
 */
export type RemoveApplicationStreamInputResponse = Message<"google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputResponse.
 * Use `create(RemoveApplicationStreamInputResponseSchema)` to create a new message.
 */
export const RemoveApplicationStreamInputResponseSchema: GenMessage<RemoveApplicationStreamInputResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 7);

/**
 * Message for AddApplicationStreamInput Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.AddApplicationStreamInputResponse
 */
export type AddApplicationStreamInputResponse = Message<"google.cloud.visionai.v1alpha1.AddApplicationStreamInputResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.AddApplicationStreamInputResponse.
 * Use `create(AddApplicationStreamInputResponseSchema)` to create a new message.
 */
export const AddApplicationStreamInputResponseSchema: GenMessage<AddApplicationStreamInputResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 8);

/**
 * Message for AddApplicationStreamInput Response.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateApplicationStreamInputResponse
 */
export type UpdateApplicationStreamInputResponse = Message<"google.cloud.visionai.v1alpha1.UpdateApplicationStreamInputResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateApplicationStreamInputResponse.
 * Use `create(UpdateApplicationStreamInputResponseSchema)` to create a new message.
 */
export const UpdateApplicationStreamInputResponseSchema: GenMessage<UpdateApplicationStreamInputResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 9);

/**
 * Message for requesting list of Applications.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListApplicationsRequest
 */
export type ListApplicationsRequest = Message<"google.cloud.visionai.v1alpha1.ListApplicationsRequest"> & {
  /**
   * Required. Parent value for ListApplicationsRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListApplicationsRequest.
 * Use `create(ListApplicationsRequestSchema)` to create a new message.
 */
export const ListApplicationsRequestSchema: GenMessage<ListApplicationsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 10);

/**
 * Message for response to listing Applications.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListApplicationsResponse
 */
export type ListApplicationsResponse = Message<"google.cloud.visionai.v1alpha1.ListApplicationsResponse"> & {
  /**
   * The list of Application.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Application applications = 1;
   */
  applications: Application[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListApplicationsResponse.
 * Use `create(ListApplicationsResponseSchema)` to create a new message.
 */
export const ListApplicationsResponseSchema: GenMessage<ListApplicationsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 11);

/**
 * Message for getting a Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.GetApplicationRequest
 */
export type GetApplicationRequest = Message<"google.cloud.visionai.v1alpha1.GetApplicationRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.GetApplicationRequest.
 * Use `create(GetApplicationRequestSchema)` to create a new message.
 */
export const GetApplicationRequestSchema: GenMessage<GetApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 12);

/**
 * Message for creating a Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.CreateApplicationRequest
 */
export type CreateApplicationRequest = Message<"google.cloud.visionai.v1alpha1.CreateApplicationRequest"> & {
  /**
   * Required. Value for parent.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string application_id = 2;
   */
  applicationId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Application application = 3;
   */
  application?: Application;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CreateApplicationRequest.
 * Use `create(CreateApplicationRequestSchema)` to create a new message.
 */
export const CreateApplicationRequestSchema: GenMessage<CreateApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 13);

/**
 * Message for updating an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateApplicationRequest
 */
export type UpdateApplicationRequest = Message<"google.cloud.visionai.v1alpha1.UpdateApplicationRequest"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Application resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Application application = 2;
   */
  application?: Application;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateApplicationRequest.
 * Use `create(UpdateApplicationRequestSchema)` to create a new message.
 */
export const UpdateApplicationRequestSchema: GenMessage<UpdateApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 14);

/**
 * Message for deleting an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeleteApplicationRequest
 */
export type DeleteApplicationRequest = Message<"google.cloud.visionai.v1alpha1.DeleteApplicationRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;

  /**
   * Optional. If set to true, any instances and drafts from this application will also be
   * deleted. (Otherwise, the request will only work if the application has no
   * instances and drafts.)
   *
   * @generated from field: bool force = 3;
   */
  force: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeleteApplicationRequest.
 * Use `create(DeleteApplicationRequestSchema)` to create a new message.
 */
export const DeleteApplicationRequestSchema: GenMessage<DeleteApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 15);

/**
 * Message for deploying an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeployApplicationRequest
 */
export type DeployApplicationRequest = Message<"google.cloud.visionai.v1alpha1.DeployApplicationRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * If set, validate the request and preview the application graph, but do not
   * actually deploy it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly: boolean;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * Optional. Whether or not to enable monitoring for the application on deployment.
   *
   * @generated from field: bool enable_monitoring = 4;
   */
  enableMonitoring: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeployApplicationRequest.
 * Use `create(DeployApplicationRequestSchema)` to create a new message.
 */
export const DeployApplicationRequestSchema: GenMessage<DeployApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 16);

/**
 * Message for undeploying an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UndeployApplicationRequest
 */
export type UndeployApplicationRequest = Message<"google.cloud.visionai.v1alpha1.UndeployApplicationRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UndeployApplicationRequest.
 * Use `create(UndeployApplicationRequestSchema)` to create a new message.
 */
export const UndeployApplicationRequestSchema: GenMessage<UndeployApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 17);

/**
 * Message about a single stream input config.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ApplicationStreamInput
 */
export type ApplicationStreamInput = Message<"google.cloud.visionai.v1alpha1.ApplicationStreamInput"> & {
  /**
   * @generated from field: google.cloud.visionai.v1alpha1.StreamWithAnnotation stream_with_annotation = 1;
   */
  streamWithAnnotation?: StreamWithAnnotation;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ApplicationStreamInput.
 * Use `create(ApplicationStreamInputSchema)` to create a new message.
 */
export const ApplicationStreamInputSchema: GenMessage<ApplicationStreamInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 18);

/**
 * Message for adding stream input to an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.AddApplicationStreamInputRequest
 */
export type AddApplicationStreamInputRequest = Message<"google.cloud.visionai.v1alpha1.AddApplicationStreamInputRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The stream inputs to add, the stream resource name is the key of each
   * StreamInput, and it must be unique within each application.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ApplicationStreamInput application_stream_inputs = 2;
   */
  applicationStreamInputs: ApplicationStreamInput[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.AddApplicationStreamInputRequest.
 * Use `create(AddApplicationStreamInputRequestSchema)` to create a new message.
 */
export const AddApplicationStreamInputRequestSchema: GenMessage<AddApplicationStreamInputRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 19);

/**
 * Message for updating stream input to an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateApplicationStreamInputRequest
 */
export type UpdateApplicationStreamInputRequest = Message<"google.cloud.visionai.v1alpha1.UpdateApplicationStreamInputRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The stream inputs to update, the stream resource name is the key of each
   * StreamInput, and it must be unique within each application.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ApplicationStreamInput application_stream_inputs = 2;
   */
  applicationStreamInputs: ApplicationStreamInput[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * If true, UpdateApplicationStreamInput will insert stream input to
   * application even if the target stream is not included in the application.
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateApplicationStreamInputRequest.
 * Use `create(UpdateApplicationStreamInputRequestSchema)` to create a new message.
 */
export const UpdateApplicationStreamInputRequestSchema: GenMessage<UpdateApplicationStreamInputRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 20);

/**
 * Message for removing stream input from an Application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest
 */
export type RemoveApplicationStreamInputRequest = Message<"google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The target stream to remove.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest.TargetStreamInput target_stream_inputs = 2;
   */
  targetStreamInputs: RemoveApplicationStreamInputRequest_TargetStreamInput[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest.
 * Use `create(RemoveApplicationStreamInputRequestSchema)` to create a new message.
 */
export const RemoveApplicationStreamInputRequestSchema: GenMessage<RemoveApplicationStreamInputRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 21);

/**
 * Message about target streamInput to remove.
 *
 * @generated from message google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest.TargetStreamInput
 */
export type RemoveApplicationStreamInputRequest_TargetStreamInput = Message<"google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest.TargetStreamInput"> & {
  /**
   * @generated from field: string stream = 1;
   */
  stream: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.RemoveApplicationStreamInputRequest.TargetStreamInput.
 * Use `create(RemoveApplicationStreamInputRequest_TargetStreamInputSchema)` to create a new message.
 */
export const RemoveApplicationStreamInputRequest_TargetStreamInputSchema: GenMessage<RemoveApplicationStreamInputRequest_TargetStreamInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 21, 0);

/**
 * Message for requesting list of Instances.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListInstancesRequest
 */
export type ListInstancesRequest = Message<"google.cloud.visionai.v1alpha1.ListInstancesRequest"> & {
  /**
   * Required. Parent value for ListInstancesRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListInstancesRequest.
 * Use `create(ListInstancesRequestSchema)` to create a new message.
 */
export const ListInstancesRequestSchema: GenMessage<ListInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 22);

/**
 * Message for response to listing Instances.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListInstancesResponse
 */
export type ListInstancesResponse = Message<"google.cloud.visionai.v1alpha1.ListInstancesResponse"> & {
  /**
   * The list of Instance.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Instance instances = 1;
   */
  instances: Instance[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListInstancesResponse.
 * Use `create(ListInstancesResponseSchema)` to create a new message.
 */
export const ListInstancesResponseSchema: GenMessage<ListInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 23);

/**
 * Message for getting a Instance.
 *
 * @generated from message google.cloud.visionai.v1alpha1.GetInstanceRequest
 */
export type GetInstanceRequest = Message<"google.cloud.visionai.v1alpha1.GetInstanceRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.GetInstanceRequest.
 * Use `create(GetInstanceRequestSchema)` to create a new message.
 */
export const GetInstanceRequestSchema: GenMessage<GetInstanceRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 24);

/**
 * Message for requesting list of Drafts.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListDraftsRequest
 */
export type ListDraftsRequest = Message<"google.cloud.visionai.v1alpha1.ListDraftsRequest"> & {
  /**
   * Required. Parent value for ListDraftsRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListDraftsRequest.
 * Use `create(ListDraftsRequestSchema)` to create a new message.
 */
export const ListDraftsRequestSchema: GenMessage<ListDraftsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 25);

/**
 * Message for response to listing Drafts.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListDraftsResponse
 */
export type ListDraftsResponse = Message<"google.cloud.visionai.v1alpha1.ListDraftsResponse"> & {
  /**
   * The list of Draft.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Draft drafts = 1;
   */
  drafts: Draft[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListDraftsResponse.
 * Use `create(ListDraftsResponseSchema)` to create a new message.
 */
export const ListDraftsResponseSchema: GenMessage<ListDraftsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 26);

/**
 * Message for getting a Draft.
 *
 * @generated from message google.cloud.visionai.v1alpha1.GetDraftRequest
 */
export type GetDraftRequest = Message<"google.cloud.visionai.v1alpha1.GetDraftRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.GetDraftRequest.
 * Use `create(GetDraftRequestSchema)` to create a new message.
 */
export const GetDraftRequestSchema: GenMessage<GetDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 27);

/**
 * Message for creating a Draft.
 *
 * @generated from message google.cloud.visionai.v1alpha1.CreateDraftRequest
 */
export type CreateDraftRequest = Message<"google.cloud.visionai.v1alpha1.CreateDraftRequest"> & {
  /**
   * Required. Value for parent.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string draft_id = 2;
   */
  draftId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Draft draft = 3;
   */
  draft?: Draft;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CreateDraftRequest.
 * Use `create(CreateDraftRequestSchema)` to create a new message.
 */
export const CreateDraftRequestSchema: GenMessage<CreateDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 28);

/**
 * Message for updating an Draft.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateDraftRequest
 */
export type UpdateDraftRequest = Message<"google.cloud.visionai.v1alpha1.UpdateDraftRequest"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Draft resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Draft draft = 2;
   */
  draft?: Draft;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * If true, UpdateDraftRequest will create one resource if the target resource
   * doesn't exist, this time, the field_mask will be ignored.
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateDraftRequest.
 * Use `create(UpdateDraftRequestSchema)` to create a new message.
 */
export const UpdateDraftRequestSchema: GenMessage<UpdateDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 29);

/**
 * Message for updating an ApplicationInstance.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest
 */
export type UpdateApplicationInstancesRequest = Message<"google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * @generated from field: repeated google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest.UpdateApplicationInstance application_instances = 2;
   */
  applicationInstances: UpdateApplicationInstancesRequest_UpdateApplicationInstance[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * If true, Update Request will create one resource if the target resource
   * doesn't exist, this time, the field_mask will be ignored.
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest.
 * Use `create(UpdateApplicationInstancesRequestSchema)` to create a new message.
 */
export const UpdateApplicationInstancesRequestSchema: GenMessage<UpdateApplicationInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 30);

/**
 * @generated from message google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest.UpdateApplicationInstance
 */
export type UpdateApplicationInstancesRequest_UpdateApplicationInstance = Message<"google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest.UpdateApplicationInstance"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Draft resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If
   * the user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Instance instance = 2;
   */
  instance?: Instance;

  /**
   * Required. The id of the instance.
   *
   * @generated from field: string instance_id = 3;
   */
  instanceId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateApplicationInstancesRequest.UpdateApplicationInstance.
 * Use `create(UpdateApplicationInstancesRequest_UpdateApplicationInstanceSchema)` to create a new message.
 */
export const UpdateApplicationInstancesRequest_UpdateApplicationInstanceSchema: GenMessage<UpdateApplicationInstancesRequest_UpdateApplicationInstance> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 30, 0);

/**
 * Message for deleting an Draft.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeleteDraftRequest
 */
export type DeleteDraftRequest = Message<"google.cloud.visionai.v1alpha1.DeleteDraftRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeleteDraftRequest.
 * Use `create(DeleteDraftRequestSchema)` to create a new message.
 */
export const DeleteDraftRequestSchema: GenMessage<DeleteDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 31);

/**
 * Message for requesting list of Processors.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListProcessorsRequest
 */
export type ListProcessorsRequest = Message<"google.cloud.visionai.v1alpha1.ListProcessorsRequest"> & {
  /**
   * Required. Parent value for ListProcessorsRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListProcessorsRequest.
 * Use `create(ListProcessorsRequestSchema)` to create a new message.
 */
export const ListProcessorsRequestSchema: GenMessage<ListProcessorsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 32);

/**
 * Message for response to listing Processors.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListProcessorsResponse
 */
export type ListProcessorsResponse = Message<"google.cloud.visionai.v1alpha1.ListProcessorsResponse"> & {
  /**
   * The list of Processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Processor processors = 1;
   */
  processors: Processor[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListProcessorsResponse.
 * Use `create(ListProcessorsResponseSchema)` to create a new message.
 */
export const ListProcessorsResponseSchema: GenMessage<ListProcessorsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 33);

/**
 * Request Message for listing Prebuilt Processors.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListPrebuiltProcessorsRequest
 */
export type ListPrebuiltProcessorsRequest = Message<"google.cloud.visionai.v1alpha1.ListPrebuiltProcessorsRequest"> & {
  /**
   * Required. Parent path.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListPrebuiltProcessorsRequest.
 * Use `create(ListPrebuiltProcessorsRequestSchema)` to create a new message.
 */
export const ListPrebuiltProcessorsRequestSchema: GenMessage<ListPrebuiltProcessorsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 34);

/**
 * Response Message for listing Prebuilt Processors.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ListPrebuiltProcessorsResponse
 */
export type ListPrebuiltProcessorsResponse = Message<"google.cloud.visionai.v1alpha1.ListPrebuiltProcessorsResponse"> & {
  /**
   * The list of Processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Processor processors = 1;
   */
  processors: Processor[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ListPrebuiltProcessorsResponse.
 * Use `create(ListPrebuiltProcessorsResponseSchema)` to create a new message.
 */
export const ListPrebuiltProcessorsResponseSchema: GenMessage<ListPrebuiltProcessorsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 35);

/**
 * Message for getting a Processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.GetProcessorRequest
 */
export type GetProcessorRequest = Message<"google.cloud.visionai.v1alpha1.GetProcessorRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.GetProcessorRequest.
 * Use `create(GetProcessorRequestSchema)` to create a new message.
 */
export const GetProcessorRequestSchema: GenMessage<GetProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 36);

/**
 * Message for creating a Processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.CreateProcessorRequest
 */
export type CreateProcessorRequest = Message<"google.cloud.visionai.v1alpha1.CreateProcessorRequest"> & {
  /**
   * Required. Value for parent.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string processor_id = 2;
   */
  processorId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Processor processor = 3;
   */
  processor?: Processor;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CreateProcessorRequest.
 * Use `create(CreateProcessorRequestSchema)` to create a new message.
 */
export const CreateProcessorRequestSchema: GenMessage<CreateProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 37);

/**
 * Message for updating a Processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.UpdateProcessorRequest
 */
export type UpdateProcessorRequest = Message<"google.cloud.visionai.v1alpha1.UpdateProcessorRequest"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Processor resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Processor processor = 2;
   */
  processor?: Processor;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.UpdateProcessorRequest.
 * Use `create(UpdateProcessorRequestSchema)` to create a new message.
 */
export const UpdateProcessorRequestSchema: GenMessage<UpdateProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 38);

/**
 * Message for deleting a Processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DeleteProcessorRequest
 */
export type DeleteProcessorRequest = Message<"google.cloud.visionai.v1alpha1.DeleteProcessorRequest"> & {
  /**
   * Required. Name of the resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique request ID
   * so that if you must retry your request, the server will know to ignore
   * the request if it has already been completed. The server will guarantee
   * that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and t
   * he request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DeleteProcessorRequest.
 * Use `create(DeleteProcessorRequestSchema)` to create a new message.
 */
export const DeleteProcessorRequestSchema: GenMessage<DeleteProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 39);

/**
 * Message describing Application object
 *
 * @generated from message google.cloud.visionai.v1alpha1.Application
 */
export type Application = Message<"google.cloud.visionai.v1alpha1.Application"> & {
  /**
   * name of resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Update timestamp
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the solution.
   *
   * @generated from field: string display_name = 5;
   */
  displayName: string;

  /**
   * A description for this application.
   *
   * @generated from field: string description = 6;
   */
  description: string;

  /**
   * Application graph configuration.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ApplicationConfigs application_configs = 7;
   */
  applicationConfigs?: ApplicationConfigs;

  /**
   * Output only. Application graph runtime info. Only exists when application state equals
   * to DEPLOYED.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo runtime_info = 8;
   */
  runtimeInfo?: Application_ApplicationRuntimeInfo;

  /**
   * Output only. State of the application.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Application.State state = 9;
   */
  state: Application_State;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Application.
 * Use `create(ApplicationSchema)` to create a new message.
 */
export const ApplicationSchema: GenMessage<Application> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 40);

/**
 * Message storing the runtime information of the application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo
 */
export type Application_ApplicationRuntimeInfo = Message<"google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo"> & {
  /**
   * Timestamp when the engine be deployed
   *
   * @generated from field: google.protobuf.Timestamp deploy_time = 1;
   */
  deployTime?: Timestamp;

  /**
   * Globally created resources like warehouse dataschemas.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.GlobalOutputResource global_output_resources = 3;
   */
  globalOutputResources: Application_ApplicationRuntimeInfo_GlobalOutputResource[];

  /**
   * Monitoring-related configuration for this application.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.MonitoringConfig monitoring_config = 4;
   */
  monitoringConfig?: Application_ApplicationRuntimeInfo_MonitoringConfig;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.
 * Use `create(Application_ApplicationRuntimeInfoSchema)` to create a new message.
 */
export const Application_ApplicationRuntimeInfoSchema: GenMessage<Application_ApplicationRuntimeInfo> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 40, 0);

/**
 * Message about output resources from application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.GlobalOutputResource
 */
export type Application_ApplicationRuntimeInfo_GlobalOutputResource = Message<"google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.GlobalOutputResource"> & {
  /**
   * The full resource name of the outputted resources.
   *
   * @generated from field: string output_resource = 1;
   */
  outputResource: string;

  /**
   * The name of graph node who produces the output resource name.
   * For example:
   * output_resource:
   * /projects/123/locations/us-central1/corpora/my-corpus/dataSchemas/my-schema
   * producer_node: occupancy-count
   *
   * @generated from field: string producer_node = 2;
   */
  producerNode: string;

  /**
   * The key of the output resource, it has to be unique within the same
   * producer node. One producer node can output several output resources,
   * the key can be used to match corresponding output resources.
   *
   * @generated from field: string key = 3;
   */
  key: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.GlobalOutputResource.
 * Use `create(Application_ApplicationRuntimeInfo_GlobalOutputResourceSchema)` to create a new message.
 */
export const Application_ApplicationRuntimeInfo_GlobalOutputResourceSchema: GenMessage<Application_ApplicationRuntimeInfo_GlobalOutputResource> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 40, 0, 0);

/**
 * Monitoring-related configuration for an application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.MonitoringConfig
 */
export type Application_ApplicationRuntimeInfo_MonitoringConfig = Message<"google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.MonitoringConfig"> & {
  /**
   * Whether this application has monitoring enabled.
   *
   * @generated from field: bool enabled = 1;
   */
  enabled: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Application.ApplicationRuntimeInfo.MonitoringConfig.
 * Use `create(Application_ApplicationRuntimeInfo_MonitoringConfigSchema)` to create a new message.
 */
export const Application_ApplicationRuntimeInfo_MonitoringConfigSchema: GenMessage<Application_ApplicationRuntimeInfo_MonitoringConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 40, 0, 1);

/**
 * State of the Application
 *
 * @generated from enum google.cloud.visionai.v1alpha1.Application.State
 */
export enum Application_State {
  /**
   * The default value. This value is used if the state is omitted.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * State CREATED.
   *
   * @generated from enum value: CREATED = 1;
   */
  CREATED = 1,

  /**
   * State DEPLOYING.
   *
   * @generated from enum value: DEPLOYING = 2;
   */
  DEPLOYING = 2,

  /**
   * State DEPLOYED.
   *
   * @generated from enum value: DEPLOYED = 3;
   */
  DEPLOYED = 3,

  /**
   * State UNDEPLOYING.
   *
   * @generated from enum value: UNDEPLOYING = 4;
   */
  UNDEPLOYING = 4,

  /**
   * State DELETED.
   *
   * @generated from enum value: DELETED = 5;
   */
  DELETED = 5,

  /**
   * State ERROR.
   *
   * @generated from enum value: ERROR = 6;
   */
  ERROR = 6,

  /**
   * State CREATING.
   *
   * @generated from enum value: CREATING = 7;
   */
  CREATING = 7,

  /**
   * State Updating.
   *
   * @generated from enum value: UPDATING = 8;
   */
  UPDATING = 8,

  /**
   * State Deleting.
   *
   * @generated from enum value: DELETING = 9;
   */
  DELETING = 9,

  /**
   * State Fixing.
   *
   * @generated from enum value: FIXING = 10;
   */
  FIXING = 10,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.Application.State.
 */
export const Application_StateSchema: GenEnum<Application_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 40, 0);

/**
 * Message storing the graph of the application.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ApplicationConfigs
 */
export type ApplicationConfigs = Message<"google.cloud.visionai.v1alpha1.ApplicationConfigs"> & {
  /**
   * A list of nodes  in the application graph.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Node nodes = 1;
   */
  nodes: Node[];

  /**
   * Event-related configuration for this application.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ApplicationConfigs.EventDeliveryConfig event_delivery_config = 3;
   */
  eventDeliveryConfig?: ApplicationConfigs_EventDeliveryConfig;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ApplicationConfigs.
 * Use `create(ApplicationConfigsSchema)` to create a new message.
 */
export const ApplicationConfigsSchema: GenMessage<ApplicationConfigs> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 41);

/**
 * message storing the config for event delivery
 *
 * @generated from message google.cloud.visionai.v1alpha1.ApplicationConfigs.EventDeliveryConfig
 */
export type ApplicationConfigs_EventDeliveryConfig = Message<"google.cloud.visionai.v1alpha1.ApplicationConfigs.EventDeliveryConfig"> & {
  /**
   * The delivery channel for the event notification, only pub/sub topic is
   * supported now.
   * Example channel:
   * [//pubsub.googleapis.com/projects/visionai-testing-stable/topics/test-topic]
   *
   * @generated from field: string channel = 1;
   */
  channel: string;

  /**
   * The expected delivery interval for the same event. The same event won't
   * be notified multiple times during this internal event that it is
   * happening multiple times during the period of time.The same event is
   * identified by <event_id, app_platform_metadata>.
   *
   * @generated from field: google.protobuf.Duration minimal_delivery_interval = 2;
   */
  minimalDeliveryInterval?: Duration;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ApplicationConfigs.EventDeliveryConfig.
 * Use `create(ApplicationConfigs_EventDeliveryConfigSchema)` to create a new message.
 */
export const ApplicationConfigs_EventDeliveryConfigSchema: GenMessage<ApplicationConfigs_EventDeliveryConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 41, 0);

/**
 * Message describing node object.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Node
 */
export type Node = Message<"google.cloud.visionai.v1alpha1.Node"> & {
  /**
   * @generated from oneof google.cloud.visionai.v1alpha1.Node.stream_output_config
   */
  streamOutputConfig: {
    /**
     * By default, the output of the node will only be available to downstream
     * nodes. To consume the direct output from the application node, the output
     * must be sent to Vision AI Streams at first.
     *
     * By setting output_all_output_channels_to_stream to true, App Platform
     * will automatically send all the outputs of the current node to Vision AI
     * Stream resources (one stream per output channel). The output stream
     * resource will be created by App Platform automatically during deployment
     * and deleted after application un-deployment.
     * Note that this config applies to all the Application Instances.
     *
     * The output stream can be override at instance level by
     * configuring the `output_resources` section of Instance resource.
     * `producer_node` should be current node, `output_resource_binding` should
     * be the output channel name (or leave it blank if there is only 1 output
     * channel of the processor) and `output_resource` should be the target
     * output stream.
     *
     * @generated from field: bool output_all_output_channels_to_stream = 6;
     */
    value: boolean;
    case: "outputAllOutputChannelsToStream";
  } | { case: undefined; value?: undefined };

  /**
   * Required. A unique name for the node.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * A user friendly display name for the node.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * Node config.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ProcessorConfig node_config = 3;
   */
  nodeConfig?: ProcessorConfig;

  /**
   * Processor name refer to the chosen processor resource.
   *
   * @generated from field: string processor = 4;
   */
  processor: string;

  /**
   * Parent node. Input node should not have parent node. For V1 Alpha1/Beta
   * only media warehouse node can have multiple parents, other types of nodes
   * will only have one parent.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Node.InputEdge parents = 5;
   */
  parents: Node_InputEdge[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Node.
 * Use `create(NodeSchema)` to create a new message.
 */
export const NodeSchema: GenMessage<Node> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 42);

/**
 * Message describing one edge pointing into a node.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Node.InputEdge
 */
export type Node_InputEdge = Message<"google.cloud.visionai.v1alpha1.Node.InputEdge"> & {
  /**
   * The name of the parent node.
   *
   * @generated from field: string parent_node = 1;
   */
  parentNode: string;

  /**
   * The connected output artifact of the parent node.
   * It can be omitted if target processor only has 1 output artifact.
   *
   * @generated from field: string parent_output_channel = 2;
   */
  parentOutputChannel: string;

  /**
   * The connected input channel of the current node's processor.
   * It can be omitted if target processor only has 1 input channel.
   *
   * @generated from field: string connected_input_channel = 3;
   */
  connectedInputChannel: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Node.InputEdge.
 * Use `create(Node_InputEdgeSchema)` to create a new message.
 */
export const Node_InputEdgeSchema: GenMessage<Node_InputEdge> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 42, 0);

/**
 * Message describing Draft object
 *
 * @generated from message google.cloud.visionai.v1alpha1.Draft
 */
export type Draft = Message<"google.cloud.visionai.v1alpha1.Draft"> & {
  /**
   * name of resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp update_time = 7;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs
   *
   * @generated from field: map<string, string> labels = 3;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the solution.
   *
   * @generated from field: string display_name = 4;
   */
  displayName: string;

  /**
   * A description for this application.
   *
   * @generated from field: string description = 5;
   */
  description: string;

  /**
   * The draft application configs which haven't been updated to an application.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ApplicationConfigs draft_application_configs = 6;
   */
  draftApplicationConfigs?: ApplicationConfigs;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Draft.
 * Use `create(DraftSchema)` to create a new message.
 */
export const DraftSchema: GenMessage<Draft> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 43);

/**
 * Message describing Instance object
 *
 * @generated from message google.cloud.visionai.v1alpha1.Instance
 */
export type Instance = Message<"google.cloud.visionai.v1alpha1.Instance"> & {
  /**
   * Output only. name of resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Update timestamp
   *
   * @generated from field: google.protobuf.Timestamp update_time = 8;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs
   *
   * @generated from field: map<string, string> labels = 3;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the solution.
   *
   * @generated from field: string display_name = 4;
   */
  displayName: string;

  /**
   * A description for this application.
   *
   * @generated from field: string description = 5;
   */
  description: string;

  /**
   * The input resources for the current application instance.
   * For example:
   * input_resources:
   * visionai.googleapis.com/v1/projects/123/locations/us-central1/clusters/456/streams/stream-a
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Instance.InputResource input_resources = 6;
   */
  inputResources: Instance_InputResource[];

  /**
   * All the output resources associated to one application instance.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.Instance.OutputResource output_resources = 7;
   */
  outputResources: Instance_OutputResource[];

  /**
   * State of the instance.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Instance.State state = 9;
   */
  state: Instance_State;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Instance.
 * Use `create(InstanceSchema)` to create a new message.
 */
export const InstanceSchema: GenMessage<Instance> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 44);

/**
 * Message of input resource used in one application instance.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Instance.InputResource
 */
export type Instance_InputResource = Message<"google.cloud.visionai.v1alpha1.Instance.InputResource"> & {
  /**
   * Required. Specify the input to the application instance.
   *
   * @generated from oneof google.cloud.visionai.v1alpha1.Instance.InputResource.input_resource_information
   */
  inputResourceInformation: {
    /**
     * The direct input resource name.
     *
     * @generated from field: string input_resource = 1;
     */
    value: string;
    case: "inputResource";
  } | {
    /**
     * If the input resource is VisionAI Stream, the associated annotations
     * can be specified using annotated_stream instead.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.StreamWithAnnotation annotated_stream = 4 [deprecated = true];
     * @deprecated
     */
    value: StreamWithAnnotation;
    case: "annotatedStream";
  } | { case: undefined; value?: undefined };

  /**
   * The name of graph node who receives the input resource.
   * For example:
   * input_resource:
   * visionai.googleapis.com/v1/projects/123/locations/us-central1/clusters/456/streams/input-stream-a
   * consumer_node: stream-input
   *
   * @generated from field: string consumer_node = 2;
   */
  consumerNode: string;

  /**
   * The specific input resource binding which will consume the current Input
   * Resource, can be ignored is there is only 1 input binding.
   *
   * @generated from field: string input_resource_binding = 3;
   */
  inputResourceBinding: string;

  /**
   * Contains resource annotations.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ResourceAnnotations annotations = 5;
   */
  annotations?: ResourceAnnotations;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Instance.InputResource.
 * Use `create(Instance_InputResourceSchema)` to create a new message.
 */
export const Instance_InputResourceSchema: GenMessage<Instance_InputResource> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 44, 0);

/**
 * Message of output resource used in one application instance.
 *
 * @generated from message google.cloud.visionai.v1alpha1.Instance.OutputResource
 */
export type Instance_OutputResource = Message<"google.cloud.visionai.v1alpha1.Instance.OutputResource"> & {
  /**
   * The output resource name for the current application instance.
   *
   * @generated from field: string output_resource = 1;
   */
  outputResource: string;

  /**
   * The name of graph node who produces the output resource name.
   * For example:
   * output_resource:
   * /projects/123/locations/us-central1/clusters/456/streams/output-application-789-stream-a-occupancy-counting
   * producer_node: occupancy-counting
   *
   * @generated from field: string producer_node = 2;
   */
  producerNode: string;

  /**
   * The specific output resource binding which produces the current
   * OutputResource.
   *
   * @generated from field: string output_resource_binding = 4;
   */
  outputResourceBinding: string;

  /**
   * Output only. Whether the output resource is temporary which means the resource is
   * generated during the deployment of the application.
   * Temporary resource will be deleted during the undeployment of the
   * application.
   *
   * @generated from field: bool is_temporary = 3;
   */
  isTemporary: boolean;

  /**
   * Output only. Whether the output resource is created automatically by the Vision AI App
   * Platform.
   *
   * @generated from field: bool autogen = 5;
   */
  autogen: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Instance.OutputResource.
 * Use `create(Instance_OutputResourceSchema)` to create a new message.
 */
export const Instance_OutputResourceSchema: GenMessage<Instance_OutputResource> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 44, 1);

/**
 * State of the Instance
 *
 * @generated from enum google.cloud.visionai.v1alpha1.Instance.State
 */
export enum Instance_State {
  /**
   * The default value. This value is used if the state is omitted.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * State CREATING.
   *
   * @generated from enum value: CREATING = 1;
   */
  CREATING = 1,

  /**
   * State CREATED.
   *
   * @generated from enum value: CREATED = 2;
   */
  CREATED = 2,

  /**
   * State DEPLOYING.
   *
   * @generated from enum value: DEPLOYING = 3;
   */
  DEPLOYING = 3,

  /**
   * State DEPLOYED.
   *
   * @generated from enum value: DEPLOYED = 4;
   */
  DEPLOYED = 4,

  /**
   * State UNDEPLOYING.
   *
   * @generated from enum value: UNDEPLOYING = 5;
   */
  UNDEPLOYING = 5,

  /**
   * State DELETED.
   *
   * @generated from enum value: DELETED = 6;
   */
  DELETED = 6,

  /**
   * State ERROR.
   *
   * @generated from enum value: ERROR = 7;
   */
  ERROR = 7,

  /**
   * State Updating
   *
   * @generated from enum value: UPDATING = 8;
   */
  UPDATING = 8,

  /**
   * State Deleting.
   *
   * @generated from enum value: DELETING = 9;
   */
  DELETING = 9,

  /**
   * State Fixing.
   *
   * @generated from enum value: FIXING = 10;
   */
  FIXING = 10,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.Instance.State.
 */
export const Instance_StateSchema: GenEnum<Instance_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 44, 0);

/**
 * Message for creating a Instance.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ApplicationInstance
 */
export type ApplicationInstance = Message<"google.cloud.visionai.v1alpha1.ApplicationInstance"> & {
  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string instance_id = 1;
   */
  instanceId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Instance instance = 2;
   */
  instance?: Instance;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ApplicationInstance.
 * Use `create(ApplicationInstanceSchema)` to create a new message.
 */
export const ApplicationInstanceSchema: GenMessage<ApplicationInstance> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 45);

/**
 * Message describing Processor object.
 * Next ID: 18
 *
 * @generated from message google.cloud.visionai.v1alpha1.Processor
 */
export type Processor = Message<"google.cloud.visionai.v1alpha1.Processor"> & {
  /**
   * name of resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Update timestamp.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the processor.
   *
   * @generated from field: string display_name = 5;
   */
  displayName: string;

  /**
   * Illustrative sentences for describing the functionality of the processor.
   *
   * @generated from field: string description = 10;
   */
  description: string;

  /**
   * Output only. Processor Type.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Processor.ProcessorType processor_type = 6;
   */
  processorType: Processor_ProcessorType;

  /**
   * Model Type.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ModelType model_type = 13;
   */
  modelType: ModelType;

  /**
   * Source info for customer created processor.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo custom_processor_source_info = 7;
   */
  customProcessorSourceInfo?: CustomProcessorSourceInfo;

  /**
   * Output only. State of the Processor.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.Processor.ProcessorState state = 8;
   */
  state: Processor_ProcessorState;

  /**
   * Output only. [Output only] The input / output specifications of a processor, each type
   * of processor has fixed input / output specs which cannot be altered by
   * customer.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ProcessorIOSpec processor_io_spec = 11;
   */
  processorIoSpec?: ProcessorIOSpec;

  /**
   * Output only. The corresponding configuration can be used in the Application to customize
   * the behavior of the processor.
   *
   * @generated from field: string configuration_typeurl = 14;
   */
  configurationTypeurl: string;

  /**
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamAnnotationType supported_annotation_types = 15;
   */
  supportedAnnotationTypes: StreamAnnotationType[];

  /**
   * Indicates if the processor supports post processing.
   *
   * @generated from field: bool supports_post_processing = 17;
   */
  supportsPostProcessing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.Processor.
 * Use `create(ProcessorSchema)` to create a new message.
 */
export const ProcessorSchema: GenMessage<Processor> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 46);

/**
 * Type
 *
 * @generated from enum google.cloud.visionai.v1alpha1.Processor.ProcessorType
 */
export enum Processor_ProcessorType {
  /**
   * Processor Type UNSPECIFIED.
   *
   * @generated from enum value: PROCESSOR_TYPE_UNSPECIFIED = 0;
   */
  PROCESSOR_TYPE_UNSPECIFIED = 0,

  /**
   * Processor Type PRETRAINED.
   * Pretrained processor is developed by Vision AI App Platform with
   * state-of-the-art vision data processing functionality, like occupancy
   * counting or person blur. Pretrained processor is usually publicly
   * available.
   *
   * @generated from enum value: PRETRAINED = 1;
   */
  PRETRAINED = 1,

  /**
   * Processor Type CUSTOM.
   * Custom processors are specialized processors which are either uploaded by
   * customers or imported from other GCP platform (for example Vertex AI).
   * Custom processor is only visible to the creator.
   *
   * @generated from enum value: CUSTOM = 2;
   */
  CUSTOM = 2,

  /**
   * Processor Type CONNECTOR.
   * Connector processors are special processors which perform I/O for the
   * application, they do not processing the data but either deliver the data
   * to other processors or receive data from other processors.
   *
   * @generated from enum value: CONNECTOR = 3;
   */
  CONNECTOR = 3,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.Processor.ProcessorType.
 */
export const Processor_ProcessorTypeSchema: GenEnum<Processor_ProcessorType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 46, 0);

/**
 * @generated from enum google.cloud.visionai.v1alpha1.Processor.ProcessorState
 */
export enum Processor_ProcessorState {
  /**
   * Unspecified Processor state.
   *
   * @generated from enum value: PROCESSOR_STATE_UNSPECIFIED = 0;
   */
  PROCESSOR_STATE_UNSPECIFIED = 0,

  /**
   * Processor is being created (not ready for use).
   *
   * @generated from enum value: CREATING = 1;
   */
  CREATING = 1,

  /**
   * Processor is and ready for use.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * Processor is being deleted (not ready for use).
   *
   * @generated from enum value: DELETING = 3;
   */
  DELETING = 3,

  /**
   * Processor deleted or creation failed .
   *
   * @generated from enum value: FAILED = 4;
   */
  FAILED = 4,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.Processor.ProcessorState.
 */
export const Processor_ProcessorStateSchema: GenEnum<Processor_ProcessorState> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 46, 1);

/**
 * Message describing the input / output specifications of a processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ProcessorIOSpec
 */
export type ProcessorIOSpec = Message<"google.cloud.visionai.v1alpha1.ProcessorIOSpec"> & {
  /**
   * For processors with input_channel_specs, the processor must be explicitly
   * connected to another processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphInputChannelSpec graph_input_channel_specs = 3;
   */
  graphInputChannelSpecs: ProcessorIOSpec_GraphInputChannelSpec[];

  /**
   * The output artifact specifications for the current processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphOutputChannelSpec graph_output_channel_specs = 4;
   */
  graphOutputChannelSpecs: ProcessorIOSpec_GraphOutputChannelSpec[];

  /**
   * The input resource that needs to be fed from the application instance.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceInputBindingSpec instance_resource_input_binding_specs = 5;
   */
  instanceResourceInputBindingSpecs: ProcessorIOSpec_InstanceResourceInputBindingSpec[];

  /**
   * The output resource that the processor will generate per instance.
   * Other than the explicitly listed output bindings here, all the processors'
   * GraphOutputChannels can be binded to stream resource. The bind name then is
   * the same as the GraphOutputChannel's name.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceOutputBindingSpec instance_resource_output_binding_specs = 6;
   */
  instanceResourceOutputBindingSpecs: ProcessorIOSpec_InstanceResourceOutputBindingSpec[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ProcessorIOSpec.
 * Use `create(ProcessorIOSpecSchema)` to create a new message.
 */
export const ProcessorIOSpecSchema: GenMessage<ProcessorIOSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 47);

/**
 * Message for input channel specification.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphInputChannelSpec
 */
export type ProcessorIOSpec_GraphInputChannelSpec = Message<"google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphInputChannelSpec"> & {
  /**
   * The name of the current input channel.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The data types of the current input channel.
   * When this field has more than 1 value, it means this input channel can be
   * connected to either of these different data types.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ProcessorIOSpec.DataType data_type = 2;
   */
  dataType: ProcessorIOSpec_DataType;

  /**
   * If specified, only those detailed data types can be connected to the
   * processor. For example, jpeg stream for MEDIA, or PredictionResult proto
   * for PROTO type. If unspecified, then any proto is accepted.
   *
   * @generated from field: repeated string accepted_data_type_uris = 5;
   */
  acceptedDataTypeUris: string[];

  /**
   * Whether the current input channel is required by the processor.
   * For example, for a processor with required video input and optional audio
   * input, if video input is missing, the application will be rejected while
   * the audio input can be missing as long as the video input exists.
   *
   * @generated from field: bool required = 3;
   */
  required: boolean;

  /**
   * How many input edges can be connected to this input channel. 0 means
   * unlimited.
   *
   * @generated from field: int64 max_connection_allowed = 4;
   */
  maxConnectionAllowed: bigint;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphInputChannelSpec.
 * Use `create(ProcessorIOSpec_GraphInputChannelSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_GraphInputChannelSpecSchema: GenMessage<ProcessorIOSpec_GraphInputChannelSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 47, 0);

/**
 * Message for output channel specification.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphOutputChannelSpec
 */
export type ProcessorIOSpec_GraphOutputChannelSpec = Message<"google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphOutputChannelSpec"> & {
  /**
   * The name of the current output channel.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The data type of the current output channel.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.ProcessorIOSpec.DataType data_type = 2;
   */
  dataType: ProcessorIOSpec_DataType;

  /**
   * @generated from field: string data_type_uri = 3;
   */
  dataTypeUri: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ProcessorIOSpec.GraphOutputChannelSpec.
 * Use `create(ProcessorIOSpec_GraphOutputChannelSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_GraphOutputChannelSpecSchema: GenMessage<ProcessorIOSpec_GraphOutputChannelSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 47, 1);

/**
 * Message for instance resource channel specification.
 * External resources are virtual nodes which are not expressed in the
 * application graph. Each processor expresses its out-graph spec, so customer
 * is able to override the external source or destinations to the
 *
 * @generated from message google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceInputBindingSpec
 */
export type ProcessorIOSpec_InstanceResourceInputBindingSpec = Message<"google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceInputBindingSpec"> & {
  /**
   * @generated from oneof google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceInputBindingSpec.resource_type
   */
  resourceType: {
    /**
     * The configuration proto that includes the Googleapis resources. I.e.
     * type.googleapis.com/google.cloud.vision.v1.StreamWithAnnotation
     *
     * @generated from field: string config_type_uri = 2;
     */
    value: string;
    case: "configTypeUri";
  } | {
    /**
     * The direct type url of Googleapis resource. i.e.
     * type.googleapis.com/google.cloud.vision.v1.Asset
     *
     * @generated from field: string resource_type_uri = 3;
     */
    value: string;
    case: "resourceTypeUri";
  } | { case: undefined; value?: undefined };

  /**
   * Name of the input binding, unique within the processor.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceInputBindingSpec.
 * Use `create(ProcessorIOSpec_InstanceResourceInputBindingSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_InstanceResourceInputBindingSpecSchema: GenMessage<ProcessorIOSpec_InstanceResourceInputBindingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 47, 2);

/**
 * @generated from message google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceOutputBindingSpec
 */
export type ProcessorIOSpec_InstanceResourceOutputBindingSpec = Message<"google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceOutputBindingSpec"> & {
  /**
   * Name of the output binding, unique within the processor.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The resource type uri of the acceptable output resource.
   *
   * @generated from field: string resource_type_uri = 2;
   */
  resourceTypeUri: string;

  /**
   * Whether the output resource needs to be explicitly set in the instance.
   * If it is false, the processor will automatically generate it if required.
   *
   * @generated from field: bool explicit = 3;
   */
  explicit: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ProcessorIOSpec.InstanceResourceOutputBindingSpec.
 * Use `create(ProcessorIOSpec_InstanceResourceOutputBindingSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_InstanceResourceOutputBindingSpecSchema: GenMessage<ProcessorIOSpec_InstanceResourceOutputBindingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 47, 3);

/**
 * High level data types supported by the processor.
 *
 * @generated from enum google.cloud.visionai.v1alpha1.ProcessorIOSpec.DataType
 */
export enum ProcessorIOSpec_DataType {
  /**
   * The default value of DataType.
   *
   * @generated from enum value: DATA_TYPE_UNSPECIFIED = 0;
   */
  DATA_TYPE_UNSPECIFIED = 0,

  /**
   * Video data type like H264.
   *
   * @generated from enum value: VIDEO = 1;
   */
  VIDEO = 1,

  /**
   * Protobuf data type, usually used for general data blob.
   *
   * @generated from enum value: PROTO = 2;
   */
  PROTO = 2,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.ProcessorIOSpec.DataType.
 */
export const ProcessorIOSpec_DataTypeSchema: GenEnum<ProcessorIOSpec_DataType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 47, 0);

/**
 * Describes the source info for a custom processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo
 */
export type CustomProcessorSourceInfo = Message<"google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo"> & {
  /**
   * The path where App Platform loads the artifacts for the custom processor.
   *
   * @generated from oneof google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.artifact_path
   */
  artifactPath: {
    /**
     * The resource name original model hosted in the vertex AI platform.
     *
     * @generated from field: string vertex_model = 2;
     */
    value: string;
    case: "vertexModel";
  } | { case: undefined; value?: undefined };

  /**
   * The original product which holds the custom processor's functionality.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.SourceType source_type = 1;
   */
  sourceType: CustomProcessorSourceInfo_SourceType;

  /**
   * Output only. Additional info related to the imported custom processor.
   * Data is filled in by app platform during the processor creation.
   *
   * @generated from field: map<string, string> additional_info = 4;
   */
  additionalInfo: { [key: string]: string };

  /**
   * Model schema files which specifies the signature of the model.
   * For VERTEX_CUSTOM models, instances schema is required.
   * If instances schema is not specified during the processor creation,
   * VisionAI Platform will try to get it from Vertex, if it doesn't exist, the
   * creation will fail.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.ModelSchema model_schema = 5;
   */
  modelSchema?: CustomProcessorSourceInfo_ModelSchema;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.
 * Use `create(CustomProcessorSourceInfoSchema)` to create a new message.
 */
export const CustomProcessorSourceInfoSchema: GenMessage<CustomProcessorSourceInfo> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 48);

/**
 * The schema is defined as an OpenAPI 3.0.2 [Schema
 * Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
 *
 * @generated from message google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.ModelSchema
 */
export type CustomProcessorSourceInfo_ModelSchema = Message<"google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.ModelSchema"> & {
  /**
   * Cloud Storage location to a YAML file that defines the format of a single
   * instance used in prediction and explanation requests.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.GcsSource instances_schema = 1;
   */
  instancesSchema?: GcsSource;

  /**
   * Cloud Storage location to a YAML file that defines the prediction and
   * explanation parameters.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.GcsSource parameters_schema = 2;
   */
  parametersSchema?: GcsSource;

  /**
   * Cloud Storage location to a YAML file that defines the format of a single
   * prediction or explanation.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.GcsSource predictions_schema = 3;
   */
  predictionsSchema?: GcsSource;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.ModelSchema.
 * Use `create(CustomProcessorSourceInfo_ModelSchemaSchema)` to create a new message.
 */
export const CustomProcessorSourceInfo_ModelSchemaSchema: GenMessage<CustomProcessorSourceInfo_ModelSchema> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 48, 0);

/**
 * Source type of the imported custom processor.
 *
 * @generated from enum google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.SourceType
 */
export enum CustomProcessorSourceInfo_SourceType {
  /**
   * Source type unspecified.
   *
   * @generated from enum value: SOURCE_TYPE_UNSPECIFIED = 0;
   */
  SOURCE_TYPE_UNSPECIFIED = 0,

  /**
   * Custom processors coming from Vertex AutoML product.
   *
   * @generated from enum value: VERTEX_AUTOML = 1;
   */
  VERTEX_AUTOML = 1,

  /**
   * Custom processors coming from general custom models from Vertex.
   *
   * @generated from enum value: VERTEX_CUSTOM = 2;
   */
  VERTEX_CUSTOM = 2,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.CustomProcessorSourceInfo.SourceType.
 */
export const CustomProcessorSourceInfo_SourceTypeSchema: GenEnum<CustomProcessorSourceInfo_SourceType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 48, 0);

/**
 * Next ID: 24
 *
 * @generated from message google.cloud.visionai.v1alpha1.ProcessorConfig
 */
export type ProcessorConfig = Message<"google.cloud.visionai.v1alpha1.ProcessorConfig"> & {
  /**
   * @generated from oneof google.cloud.visionai.v1alpha1.ProcessorConfig.processor_config
   */
  processorConfig: {
    /**
     * Configs of stream input processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.VideoStreamInputConfig video_stream_input_config = 9;
     */
    value: VideoStreamInputConfig;
    case: "videoStreamInputConfig";
  } | {
    /**
     * Config of AI-enabled input devices.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.AIEnabledDevicesInputConfig ai_enabled_devices_input_config = 20;
     */
    value: AIEnabledDevicesInputConfig;
    case: "aiEnabledDevicesInputConfig";
  } | {
    /**
     * Configs of media warehouse processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.MediaWarehouseConfig media_warehouse_config = 10;
     */
    value: MediaWarehouseConfig;
    case: "mediaWarehouseConfig";
  } | {
    /**
     * Configs of person blur processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.PersonBlurConfig person_blur_config = 11;
     */
    value: PersonBlurConfig;
    case: "personBlurConfig";
  } | {
    /**
     * Configs of occupancy count processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.OccupancyCountConfig occupancy_count_config = 12;
     */
    value: OccupancyCountConfig;
    case: "occupancyCountConfig";
  } | {
    /**
     * Configs of Person Vehicle Detection processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.PersonVehicleDetectionConfig person_vehicle_detection_config = 15;
     */
    value: PersonVehicleDetectionConfig;
    case: "personVehicleDetectionConfig";
  } | {
    /**
     * Configs of Vertex AutoML vision processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.VertexAutoMLVisionConfig vertex_automl_vision_config = 13;
     */
    value: VertexAutoMLVisionConfig;
    case: "vertexAutomlVisionConfig";
  } | {
    /**
     * Configs of Vertex AutoML video processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.VertexAutoMLVideoConfig vertex_automl_video_config = 14;
     */
    value: VertexAutoMLVideoConfig;
    case: "vertexAutomlVideoConfig";
  } | {
    /**
     * Configs of Vertex Custom processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.VertexCustomConfig vertex_custom_config = 17;
     */
    value: VertexCustomConfig;
    case: "vertexCustomConfig";
  } | {
    /**
     * Configs of General Object Detection processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.GeneralObjectDetectionConfig general_object_detection_config = 18;
     */
    value: GeneralObjectDetectionConfig;
    case: "generalObjectDetectionConfig";
  } | {
    /**
     * Configs of BigQuery processor.
     *
     * @generated from field: google.cloud.visionai.v1alpha1.BigQueryConfig big_query_config = 19;
     */
    value: BigQueryConfig;
    case: "bigQueryConfig";
  } | {
    /**
     * Configs of personal_protective_equipment_detection_config
     *
     * @generated from field: google.cloud.visionai.v1alpha1.PersonalProtectiveEquipmentDetectionConfig personal_protective_equipment_detection_config = 22;
     */
    value: PersonalProtectiveEquipmentDetectionConfig;
    case: "personalProtectiveEquipmentDetectionConfig";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ProcessorConfig.
 * Use `create(ProcessorConfigSchema)` to create a new message.
 */
export const ProcessorConfigSchema: GenMessage<ProcessorConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 49);

/**
 * Message describing Vision AI stream with application specific annotations.
 * All the StreamAnnotation object inside this message MUST have unique id.
 *
 * @generated from message google.cloud.visionai.v1alpha1.StreamWithAnnotation
 */
export type StreamWithAnnotation = Message<"google.cloud.visionai.v1alpha1.StreamWithAnnotation"> & {
  /**
   * Vision AI Stream resource name.
   *
   * @generated from field: string stream = 1;
   */
  stream: string;

  /**
   * Annotations that will be applied to the whole application.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamAnnotation application_annotations = 2;
   */
  applicationAnnotations: StreamAnnotation[];

  /**
   * Annotations that will be applied to the specific node of the application.
   * If the same type of the annotations is applied to both application and
   * node, the node annotation will be added in addition to the global
   * application one.
   * For example, if there is one active zone annotation for the whole
   * application and one active zone annotation for the Occupancy Analytic
   * processor, then the Occupancy Analytic processor will have two active zones
   * defined.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamWithAnnotation.NodeAnnotation node_annotations = 3;
   */
  nodeAnnotations: StreamWithAnnotation_NodeAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.StreamWithAnnotation.
 * Use `create(StreamWithAnnotationSchema)` to create a new message.
 */
export const StreamWithAnnotationSchema: GenMessage<StreamWithAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 50);

/**
 * Message describing annotations specific to application node.
 *
 * @generated from message google.cloud.visionai.v1alpha1.StreamWithAnnotation.NodeAnnotation
 */
export type StreamWithAnnotation_NodeAnnotation = Message<"google.cloud.visionai.v1alpha1.StreamWithAnnotation.NodeAnnotation"> & {
  /**
   * The node name of the application graph.
   *
   * @generated from field: string node = 1;
   */
  node: string;

  /**
   * The node specific stream annotations.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamAnnotation annotations = 2;
   */
  annotations: StreamAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.StreamWithAnnotation.NodeAnnotation.
 * Use `create(StreamWithAnnotation_NodeAnnotationSchema)` to create a new message.
 */
export const StreamWithAnnotation_NodeAnnotationSchema: GenMessage<StreamWithAnnotation_NodeAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 50, 0);

/**
 * Message describing annotations specific to application node.
 * This message is a duplication of StreamWithAnnotation.NodeAnnotation.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ApplicationNodeAnnotation
 */
export type ApplicationNodeAnnotation = Message<"google.cloud.visionai.v1alpha1.ApplicationNodeAnnotation"> & {
  /**
   * The node name of the application graph.
   *
   * @generated from field: string node = 1;
   */
  node: string;

  /**
   * The node specific stream annotations.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamAnnotation annotations = 2;
   */
  annotations: StreamAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ApplicationNodeAnnotation.
 * Use `create(ApplicationNodeAnnotationSchema)` to create a new message.
 */
export const ApplicationNodeAnnotationSchema: GenMessage<ApplicationNodeAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 51);

/**
 * Message describing general annotation for resources.
 *
 * @generated from message google.cloud.visionai.v1alpha1.ResourceAnnotations
 */
export type ResourceAnnotations = Message<"google.cloud.visionai.v1alpha1.ResourceAnnotations"> & {
  /**
   * Annotations that will be applied to the whole application.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamAnnotation application_annotations = 1;
   */
  applicationAnnotations: StreamAnnotation[];

  /**
   * Annotations that will be applied to the specific node of the application.
   * If the same type of the annotations is applied to both application and
   * node, the node annotation will be added in addition to the global
   * application one.
   * For example, if there is one active zone annotation for the whole
   * application and one active zone annotation for the Occupancy Analytic
   * processor, then the Occupancy Analytic processor will have two active zones
   * defined.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.ApplicationNodeAnnotation node_annotations = 2;
   */
  nodeAnnotations: ApplicationNodeAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.ResourceAnnotations.
 * Use `create(ResourceAnnotationsSchema)` to create a new message.
 */
export const ResourceAnnotationsSchema: GenMessage<ResourceAnnotations> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 52);

/**
 * Message describing Video Stream Input Config.
 * This message should only be used as a placeholder for builtin:stream-input
 * processor, actual stream binding should be specified using corresponding
 * API.
 *
 * @generated from message google.cloud.visionai.v1alpha1.VideoStreamInputConfig
 */
export type VideoStreamInputConfig = Message<"google.cloud.visionai.v1alpha1.VideoStreamInputConfig"> & {
  /**
   * @generated from field: repeated string streams = 1 [deprecated = true];
   * @deprecated
   */
  streams: string[];

  /**
   * @generated from field: repeated google.cloud.visionai.v1alpha1.StreamWithAnnotation streams_with_annotation = 2 [deprecated = true];
   * @deprecated
   */
  streamsWithAnnotation: StreamWithAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.VideoStreamInputConfig.
 * Use `create(VideoStreamInputConfigSchema)` to create a new message.
 */
export const VideoStreamInputConfigSchema: GenMessage<VideoStreamInputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 53);

/**
 * Message describing AI-enabled Devices Input Config.
 *
 * @generated from message google.cloud.visionai.v1alpha1.AIEnabledDevicesInputConfig
 */
export type AIEnabledDevicesInputConfig = Message<"google.cloud.visionai.v1alpha1.AIEnabledDevicesInputConfig"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.AIEnabledDevicesInputConfig.
 * Use `create(AIEnabledDevicesInputConfigSchema)` to create a new message.
 */
export const AIEnabledDevicesInputConfigSchema: GenMessage<AIEnabledDevicesInputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 54);

/**
 * Message describing MediaWarehouseConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.MediaWarehouseConfig
 */
export type MediaWarehouseConfig = Message<"google.cloud.visionai.v1alpha1.MediaWarehouseConfig"> & {
  /**
   * Resource name of the Media Warehouse corpus.
   * Format:
   * projects/${project_id}/locations/${location_id}/corpora/${corpus_id}
   *
   * @generated from field: string corpus = 1;
   */
  corpus: string;

  /**
   * Deprecated.
   *
   * @generated from field: string region = 2 [deprecated = true];
   * @deprecated
   */
  region: string;

  /**
   * The duration for which all media assets, associated metadata, and search
   * documents can exist.
   *
   * @generated from field: google.protobuf.Duration ttl = 3;
   */
  ttl?: Duration;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.MediaWarehouseConfig.
 * Use `create(MediaWarehouseConfigSchema)` to create a new message.
 */
export const MediaWarehouseConfigSchema: GenMessage<MediaWarehouseConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 55);

/**
 * Message describing FaceBlurConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.PersonBlurConfig
 */
export type PersonBlurConfig = Message<"google.cloud.visionai.v1alpha1.PersonBlurConfig"> & {
  /**
   * Person blur type.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.PersonBlurConfig.PersonBlurType person_blur_type = 1;
   */
  personBlurType: PersonBlurConfig_PersonBlurType;

  /**
   * Whether only blur faces other than the whole object in the processor.
   *
   * @generated from field: bool faces_only = 2;
   */
  facesOnly: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.PersonBlurConfig.
 * Use `create(PersonBlurConfigSchema)` to create a new message.
 */
export const PersonBlurConfigSchema: GenMessage<PersonBlurConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 56);

/**
 * Type of Person Blur
 *
 * @generated from enum google.cloud.visionai.v1alpha1.PersonBlurConfig.PersonBlurType
 */
export enum PersonBlurConfig_PersonBlurType {
  /**
   * PersonBlur Type UNSPECIFIED.
   *
   * @generated from enum value: PERSON_BLUR_TYPE_UNSPECIFIED = 0;
   */
  PERSON_BLUR_TYPE_UNSPECIFIED = 0,

  /**
   * FaceBlur Type full occlusion.
   *
   * @generated from enum value: FULL_OCCULUSION = 1;
   */
  FULL_OCCULUSION = 1,

  /**
   * FaceBlur Type blur filter.
   *
   * @generated from enum value: BLUR_FILTER = 2;
   */
  BLUR_FILTER = 2,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.PersonBlurConfig.PersonBlurType.
 */
export const PersonBlurConfig_PersonBlurTypeSchema: GenEnum<PersonBlurConfig_PersonBlurType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 56, 0);

/**
 * Message describing OccupancyCountConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.OccupancyCountConfig
 */
export type OccupancyCountConfig = Message<"google.cloud.visionai.v1alpha1.OccupancyCountConfig"> & {
  /**
   * Whether to count the appearances of people, output counts have 'people' as
   * the key.
   *
   * @generated from field: bool enable_people_counting = 1;
   */
  enablePeopleCounting: boolean;

  /**
   * Whether to count the appearances of vehicles, output counts will have
   * 'vehicle' as the key.
   *
   * @generated from field: bool enable_vehicle_counting = 2;
   */
  enableVehicleCounting: boolean;

  /**
   * Whether to track each invidual object's loitering time inside the scene or
   * specific zone.
   *
   * @generated from field: bool enable_dwelling_time_tracking = 3;
   */
  enableDwellingTimeTracking: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.OccupancyCountConfig.
 * Use `create(OccupancyCountConfigSchema)` to create a new message.
 */
export const OccupancyCountConfigSchema: GenMessage<OccupancyCountConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 57);

/**
 * Message describing PersonVehicleDetectionConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.PersonVehicleDetectionConfig
 */
export type PersonVehicleDetectionConfig = Message<"google.cloud.visionai.v1alpha1.PersonVehicleDetectionConfig"> & {
  /**
   * At least one of enable_people_counting and enable_vehicle_counting fields
   * must be set to true.
   * Whether to count the appearances of people, output counts have 'people' as
   * the key.
   *
   * @generated from field: bool enable_people_counting = 1;
   */
  enablePeopleCounting: boolean;

  /**
   * Whether to count the appearances of vehicles, output counts will have
   * 'vehicle' as the key.
   *
   * @generated from field: bool enable_vehicle_counting = 2;
   */
  enableVehicleCounting: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.PersonVehicleDetectionConfig.
 * Use `create(PersonVehicleDetectionConfigSchema)` to create a new message.
 */
export const PersonVehicleDetectionConfigSchema: GenMessage<PersonVehicleDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 58);

/**
 * Message describing PersonalProtectiveEquipmentDetectionConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.PersonalProtectiveEquipmentDetectionConfig
 */
export type PersonalProtectiveEquipmentDetectionConfig = Message<"google.cloud.visionai.v1alpha1.PersonalProtectiveEquipmentDetectionConfig"> & {
  /**
   * Whether to enable face coverage detection.
   *
   * @generated from field: bool enable_face_coverage_detection = 1;
   */
  enableFaceCoverageDetection: boolean;

  /**
   * Whether to enable head coverage detection.
   *
   * @generated from field: bool enable_head_coverage_detection = 2;
   */
  enableHeadCoverageDetection: boolean;

  /**
   * Whether to enable hands coverage detection.
   *
   * @generated from field: bool enable_hands_coverage_detection = 3;
   */
  enableHandsCoverageDetection: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.PersonalProtectiveEquipmentDetectionConfig.
 * Use `create(PersonalProtectiveEquipmentDetectionConfigSchema)` to create a new message.
 */
export const PersonalProtectiveEquipmentDetectionConfigSchema: GenMessage<PersonalProtectiveEquipmentDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 59);

/**
 * Message of configurations for General Object Detection processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.GeneralObjectDetectionConfig
 */
export type GeneralObjectDetectionConfig = Message<"google.cloud.visionai.v1alpha1.GeneralObjectDetectionConfig"> & {
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.GeneralObjectDetectionConfig.
 * Use `create(GeneralObjectDetectionConfigSchema)` to create a new message.
 */
export const GeneralObjectDetectionConfigSchema: GenMessage<GeneralObjectDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 60);

/**
 * Message of configurations for BigQuery processor.
 *
 * @generated from message google.cloud.visionai.v1alpha1.BigQueryConfig
 */
export type BigQueryConfig = Message<"google.cloud.visionai.v1alpha1.BigQueryConfig"> & {
  /**
   * BigQuery table resource for Vision AI Platform to ingest annotations to.
   *
   * @generated from field: string table = 1;
   */
  table: string;

  /**
   * Data Schema
   * By default, Vision AI Application will try to write annotations to the
   * target BigQuery table using the following schema:
   *
   * ingestion_time: TIMESTAMP, the ingestion time of the original data.
   *
   * application: STRING, name of the application which produces the annotation.
   *
   * instance: STRING, Id of the instance which produces the annotation.
   *
   * node: STRING, name of the application graph node which produces the
   * annotation.
   *
   * annotation: STRING or JSON, the actual annotation protobuf will be
   * converted to json string with bytes field as 64 encoded string. It can be
   * written to both String or Json type column.
   *
   * To forward annotation data to an existing BigQuery table, customer needs to
   * make sure the compatibility of the schema.
   * The map maps application node name to its corresponding cloud function
   * endpoint to transform the annotations directly to the
   * google.cloud.bigquery.storage.v1.AppendRowsRequest (only avro_rows or
   * proto_rows should be set). If configured, annotations produced by
   * corresponding application node will sent to the Cloud Function at first
   * before be forwarded to BigQuery.
   *
   * If the default table schema doesn't fit, customer is able to transform the
   * annotation output from Vision AI Application to arbitrary BigQuery table
   * schema with CloudFunction.
   * * The cloud function will receive AppPlatformCloudFunctionRequest where
   * the annotations field will be the json format of Vision AI annotation.
   * * The cloud function should return AppPlatformCloudFunctionResponse with
   * AppendRowsRequest stored in the annotations field.
   * * To drop the annotation, simply clear the annotations field in the
   * returned AppPlatformCloudFunctionResponse.
   *
   * @generated from field: map<string, string> cloud_function_mapping = 2;
   */
  cloudFunctionMapping: { [key: string]: string };

  /**
   * If true, App Platform will create the BigQuery DataSet and the
   * BigQuery Table with default schema if the specified table doesn't exist.
   * This doesn't work if any cloud function customized schema is specified
   * since the system doesn't know your desired schema.
   * JSON column will be used in the default table created by App Platform.
   *
   * @generated from field: bool create_default_table_if_not_exists = 3;
   */
  createDefaultTableIfNotExists: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.BigQueryConfig.
 * Use `create(BigQueryConfigSchema)` to create a new message.
 */
export const BigQueryConfigSchema: GenMessage<BigQueryConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 61);

/**
 * Message of configurations of Vertex AutoML Vision Processors.
 *
 * @generated from message google.cloud.visionai.v1alpha1.VertexAutoMLVisionConfig
 */
export type VertexAutoMLVisionConfig = Message<"google.cloud.visionai.v1alpha1.VertexAutoMLVisionConfig"> & {
  /**
   * Only entities with higher score than the threshold will be returned.
   * Value 0.0 means to return all the detected entities.
   *
   * @generated from field: float confidence_threshold = 1;
   */
  confidenceThreshold: number;

  /**
   * At most this many predictions will be returned per output frame.
   * Value 0 means to return all the detected entities.
   *
   * @generated from field: int32 max_predictions = 2;
   */
  maxPredictions: number;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.VertexAutoMLVisionConfig.
 * Use `create(VertexAutoMLVisionConfigSchema)` to create a new message.
 */
export const VertexAutoMLVisionConfigSchema: GenMessage<VertexAutoMLVisionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 62);

/**
 * Message describing VertexAutoMLVideoConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.VertexAutoMLVideoConfig
 */
export type VertexAutoMLVideoConfig = Message<"google.cloud.visionai.v1alpha1.VertexAutoMLVideoConfig"> & {
  /**
   * Only entities with higher score than the threshold will be returned.
   * Value 0.0 means returns all the detected entities.
   *
   * @generated from field: float confidence_threshold = 1;
   */
  confidenceThreshold: number;

  /**
   * Labels specified in this field won't be returned.
   *
   * @generated from field: repeated string blocked_labels = 2;
   */
  blockedLabels: string[];

  /**
   * At most this many predictions will be returned per output frame.
   * Value 0 means to return all the detected entities.
   *
   * @generated from field: int32 max_predictions = 3;
   */
  maxPredictions: number;

  /**
   * Only Bounding Box whose size is larger than this limit will be returned.
   * Object Tracking only.
   * Value 0.0 means to return all the detected entities.
   *
   * @generated from field: float bounding_box_size_limit = 4;
   */
  boundingBoxSizeLimit: number;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.VertexAutoMLVideoConfig.
 * Use `create(VertexAutoMLVideoConfigSchema)` to create a new message.
 */
export const VertexAutoMLVideoConfigSchema: GenMessage<VertexAutoMLVideoConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 63);

/**
 * Message describing VertexCustomConfig.
 *
 * @generated from message google.cloud.visionai.v1alpha1.VertexCustomConfig
 */
export type VertexCustomConfig = Message<"google.cloud.visionai.v1alpha1.VertexCustomConfig"> & {
  /**
   * The max prediction frame per second. This attribute sets how fast the
   * operator sends prediction requests to Vertex AI endpoint. Default value is
   * 0, which means there is no max prediction fps limit. The operator sends
   * prediction requests at input fps.
   *
   * @generated from field: int32 max_prediction_fps = 1;
   */
  maxPredictionFps: number;

  /**
   * A description of resources that are dedicated to the DeployedModel, and
   * that need a higher degree of manual configuration.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.DedicatedResources dedicated_resources = 2;
   */
  dedicatedResources?: DedicatedResources;

  /**
   * If not empty, the prediction result will be sent to the specified cloud
   * function for post processing.
   * * The cloud function will receive AppPlatformCloudFunctionRequest where
   * the annotations field will be the json format of proto PredictResponse.
   * * The cloud function should return AppPlatformCloudFunctionResponse with
   * PredictResponse stored in the annotations field.
   * * To drop the prediction output, simply clear the payload field in the
   * returned AppPlatformCloudFunctionResponse.
   *
   * @generated from field: string post_processing_cloud_function = 3;
   */
  postProcessingCloudFunction: string;

  /**
   * If true, the prediction request received by custom model will also contain
   * metadata with the following schema:
   * 'appPlatformMetadata': {
   *       'ingestionTime': DOUBLE; (UNIX timestamp)
   *       'application': STRING;
   *       'instanceId': STRING;
   *       'node': STRING;
   *       'processor': STRING;
   *  }
   *
   * @generated from field: bool attach_application_metadata = 4;
   */
  attachApplicationMetadata: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.VertexCustomConfig.
 * Use `create(VertexCustomConfigSchema)` to create a new message.
 */
export const VertexCustomConfigSchema: GenMessage<VertexCustomConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 64);

/**
 * Specification of a single machine.
 *
 * @generated from message google.cloud.visionai.v1alpha1.MachineSpec
 */
export type MachineSpec = Message<"google.cloud.visionai.v1alpha1.MachineSpec"> & {
  /**
   * Immutable. The type of the machine.
   *
   * See the [list of machine types supported for
   * prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
   *
   * See the [list of machine types supported for custom
   * training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
   *
   * For [DeployedModel][] this field is optional, and the default
   * value is `n1-standard-2`. For [BatchPredictionJob][] or as part of
   * [WorkerPoolSpec][] this field is required.
   *
   * @generated from field: string machine_type = 1;
   */
  machineType: string;

  /**
   * Immutable. The type of accelerator(s) that may be attached to the machine as per
   * [accelerator_count][google.cloud.visionai.v1alpha1.MachineSpec.accelerator_count].
   *
   * @generated from field: google.cloud.visionai.v1alpha1.AcceleratorType accelerator_type = 2;
   */
  acceleratorType: AcceleratorType;

  /**
   * The number of accelerators to attach to the machine.
   *
   * @generated from field: int32 accelerator_count = 3;
   */
  acceleratorCount: number;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.MachineSpec.
 * Use `create(MachineSpecSchema)` to create a new message.
 */
export const MachineSpecSchema: GenMessage<MachineSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 65);

/**
 * The metric specification that defines the target resource utilization
 * (CPU utilization, accelerator's duty cycle, and so on) for calculating the
 * desired replica count.
 *
 * @generated from message google.cloud.visionai.v1alpha1.AutoscalingMetricSpec
 */
export type AutoscalingMetricSpec = Message<"google.cloud.visionai.v1alpha1.AutoscalingMetricSpec"> & {
  /**
   * Required. The resource metric name.
   * Supported metrics:
   *
   * * For Online Prediction:
   * * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle`
   * * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
   *
   * @generated from field: string metric_name = 1;
   */
  metricName: string;

  /**
   * The target resource utilization in percentage (1% - 100%) for the given
   * metric; once the real usage deviates from the target by a certain
   * percentage, the machine replicas change. The default value is 60
   * (representing 60%) if not provided.
   *
   * @generated from field: int32 target = 2;
   */
  target: number;
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.AutoscalingMetricSpec.
 * Use `create(AutoscalingMetricSpecSchema)` to create a new message.
 */
export const AutoscalingMetricSpecSchema: GenMessage<AutoscalingMetricSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 66);

/**
 * A description of resources that are dedicated to a DeployedModel, and
 * that need a higher degree of manual configuration.
 *
 * @generated from message google.cloud.visionai.v1alpha1.DedicatedResources
 */
export type DedicatedResources = Message<"google.cloud.visionai.v1alpha1.DedicatedResources"> & {
  /**
   * Required. Immutable. The specification of a single machine used by the prediction.
   *
   * @generated from field: google.cloud.visionai.v1alpha1.MachineSpec machine_spec = 1;
   */
  machineSpec?: MachineSpec;

  /**
   * Required. Immutable. The minimum number of machine replicas this DeployedModel will be always
   * deployed on. This value must be greater than or equal to 1.
   *
   * If traffic against the DeployedModel increases, it may dynamically be
   * deployed onto more replicas, and as traffic decreases, some of these extra
   * replicas may be freed.
   *
   * @generated from field: int32 min_replica_count = 2;
   */
  minReplicaCount: number;

  /**
   * Immutable. The maximum number of replicas this DeployedModel may be deployed on when
   * the traffic against it increases. If the requested value is too large,
   * the deployment will error, but if deployment succeeds then the ability
   * to scale the model to that many replicas is guaranteed (barring service
   * outages). If traffic against the DeployedModel increases beyond what its
   * replicas at maximum may handle, a portion of the traffic will be dropped.
   * If this value is not provided, will use [min_replica_count][google.cloud.visionai.v1alpha1.DedicatedResources.min_replica_count] as the
   * default value.
   *
   * The value of this field impacts the charge against Vertex CPU and GPU
   * quotas. Specifically, you will be charged for max_replica_count *
   * number of cores in the selected machine type) and (max_replica_count *
   * number of GPUs per replica in the selected machine type).
   *
   * @generated from field: int32 max_replica_count = 3;
   */
  maxReplicaCount: number;

  /**
   * Immutable. The metric specifications that overrides a resource
   * utilization metric (CPU utilization, accelerator's duty cycle, and so on)
   * target value (default to 60 if not set). At most one entry is allowed per
   * metric.
   *
   * If [machine_spec.accelerator_count][google.cloud.visionai.v1alpha1.MachineSpec.accelerator_count] is
   * above 0, the autoscaling will be based on both CPU utilization and
   * accelerator's duty cycle metrics and scale up when either metrics exceeds
   * its target value while scale down if both metrics are under their target
   * value. The default target value is 60 for both metrics.
   *
   * If [machine_spec.accelerator_count][google.cloud.visionai.v1alpha1.MachineSpec.accelerator_count] is
   * 0, the autoscaling will be based on CPU utilization metric only with
   * default target value 60 if not explicitly set.
   *
   * For example, in the case of Online Prediction, if you want to override
   * target CPU utilization to 80, you should set
   * [autoscaling_metric_specs.metric_name][google.cloud.visionai.v1alpha1.AutoscalingMetricSpec.metric_name]
   * to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
   * [autoscaling_metric_specs.target][google.cloud.visionai.v1alpha1.AutoscalingMetricSpec.target] to `80`.
   *
   * @generated from field: repeated google.cloud.visionai.v1alpha1.AutoscalingMetricSpec autoscaling_metric_specs = 4;
   */
  autoscalingMetricSpecs: AutoscalingMetricSpec[];
};

/**
 * Describes the message google.cloud.visionai.v1alpha1.DedicatedResources.
 * Use `create(DedicatedResourcesSchema)` to create a new message.
 */
export const DedicatedResourcesSchema: GenMessage<DedicatedResources> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1alpha1_platform, 67);

/**
 * All the supported model types in Vision AI App Platform.
 *
 * @generated from enum google.cloud.visionai.v1alpha1.ModelType
 */
export enum ModelType {
  /**
   * Processor Type UNSPECIFIED.
   *
   * @generated from enum value: MODEL_TYPE_UNSPECIFIED = 0;
   */
  MODEL_TYPE_UNSPECIFIED = 0,

  /**
   * Model Type Image Classification.
   *
   * @generated from enum value: IMAGE_CLASSIFICATION = 1;
   */
  IMAGE_CLASSIFICATION = 1,

  /**
   * Model Type Object Detection.
   *
   * @generated from enum value: OBJECT_DETECTION = 2;
   */
  OBJECT_DETECTION = 2,

  /**
   * Model Type Video Classification.
   *
   * @generated from enum value: VIDEO_CLASSIFICATION = 3;
   */
  VIDEO_CLASSIFICATION = 3,

  /**
   * Model Type Object Tracking.
   *
   * @generated from enum value: VIDEO_OBJECT_TRACKING = 4;
   */
  VIDEO_OBJECT_TRACKING = 4,

  /**
   * Model Type Action Recognition.
   *
   * @generated from enum value: VIDEO_ACTION_RECOGNITION = 5;
   */
  VIDEO_ACTION_RECOGNITION = 5,

  /**
   * Model Type Occupancy Counting.
   *
   * @generated from enum value: OCCUPANCY_COUNTING = 6;
   */
  OCCUPANCY_COUNTING = 6,

  /**
   * Model Type Person Blur.
   *
   * @generated from enum value: PERSON_BLUR = 7;
   */
  PERSON_BLUR = 7,

  /**
   * Model Type Vertex Custom.
   *
   * @generated from enum value: VERTEX_CUSTOM = 8;
   */
  VERTEX_CUSTOM = 8,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.ModelType.
 */
export const ModelTypeSchema: GenEnum<ModelType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 0);

/**
 * Represents a hardware accelerator type.
 *
 * @generated from enum google.cloud.visionai.v1alpha1.AcceleratorType
 */
export enum AcceleratorType {
  /**
   * Unspecified accelerator type, which means no accelerator.
   *
   * @generated from enum value: ACCELERATOR_TYPE_UNSPECIFIED = 0;
   */
  ACCELERATOR_TYPE_UNSPECIFIED = 0,

  /**
   * Nvidia Tesla K80 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_K80 = 1;
   */
  NVIDIA_TESLA_K80 = 1,

  /**
   * Nvidia Tesla P100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_P100 = 2;
   */
  NVIDIA_TESLA_P100 = 2,

  /**
   * Nvidia Tesla V100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_V100 = 3;
   */
  NVIDIA_TESLA_V100 = 3,

  /**
   * Nvidia Tesla P4 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_P4 = 4;
   */
  NVIDIA_TESLA_P4 = 4,

  /**
   * Nvidia Tesla T4 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_T4 = 5;
   */
  NVIDIA_TESLA_T4 = 5,

  /**
   * Nvidia Tesla A100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_A100 = 8;
   */
  NVIDIA_TESLA_A100 = 8,

  /**
   * TPU v2.
   *
   * @generated from enum value: TPU_V2 = 6;
   */
  TPU_V2 = 6,

  /**
   * TPU v3.
   *
   * @generated from enum value: TPU_V3 = 7;
   */
  TPU_V3 = 7,
}

/**
 * Describes the enum google.cloud.visionai.v1alpha1.AcceleratorType.
 */
export const AcceleratorTypeSchema: GenEnum<AcceleratorType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1alpha1_platform, 1);

/**
 * Service describing handlers for resources
 *
 * @generated from service google.cloud.visionai.v1alpha1.AppPlatform
 */
export const AppPlatform: GenService<{
  /**
   * Lists Applications in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.ListApplications
   */
  listApplications: {
    methodKind: "unary";
    input: typeof ListApplicationsRequestSchema;
    output: typeof ListApplicationsResponseSchema;
  },
  /**
   * Gets details of a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.GetApplication
   */
  getApplication: {
    methodKind: "unary";
    input: typeof GetApplicationRequestSchema;
    output: typeof ApplicationSchema;
  },
  /**
   * Creates a new Application in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.CreateApplication
   */
  createApplication: {
    methodKind: "unary";
    input: typeof CreateApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates the parameters of a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.UpdateApplication
   */
  updateApplication: {
    methodKind: "unary";
    input: typeof UpdateApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deletes a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.DeleteApplication
   */
  deleteApplication: {
    methodKind: "unary";
    input: typeof DeleteApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deploys a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.DeployApplication
   */
  deployApplication: {
    methodKind: "unary";
    input: typeof DeployApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Undeploys a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.UndeployApplication
   */
  undeployApplication: {
    methodKind: "unary";
    input: typeof UndeployApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Adds target stream input to the Application.
   * If the Application is deployed, the corresponding new Application instance
   * will be created. If the stream has already been in the Application, the RPC
   * will fail.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.AddApplicationStreamInput
   */
  addApplicationStreamInput: {
    methodKind: "unary";
    input: typeof AddApplicationStreamInputRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Remove target stream input to the Application, if the Application is
   * deployed, the corresponding instance based will be deleted. If the stream
   * is not in the Application, the RPC will fail.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.RemoveApplicationStreamInput
   */
  removeApplicationStreamInput: {
    methodKind: "unary";
    input: typeof RemoveApplicationStreamInputRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Update target stream input to the Application, if the Application is
   * deployed, the corresponding instance based will be deployed. For
   * CreateOrUpdate behavior, set allow_missing to true.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.UpdateApplicationStreamInput
   */
  updateApplicationStreamInput: {
    methodKind: "unary";
    input: typeof UpdateApplicationStreamInputRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Lists Instances in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.ListInstances
   */
  listInstances: {
    methodKind: "unary";
    input: typeof ListInstancesRequestSchema;
    output: typeof ListInstancesResponseSchema;
  },
  /**
   * Gets details of a single Instance.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.GetInstance
   */
  getInstance: {
    methodKind: "unary";
    input: typeof GetInstanceRequestSchema;
    output: typeof InstanceSchema;
  },
  /**
   * Adds target stream input to the Application.
   * If the Application is deployed, the corresponding new Application instance
   * will be created. If the stream has already been in the Application, the RPC
   * will fail.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.CreateApplicationInstances
   */
  createApplicationInstances: {
    methodKind: "unary";
    input: typeof CreateApplicationInstancesRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Remove target stream input to the Application, if the Application is
   * deployed, the corresponding instance based will be deleted. If the stream
   * is not in the Application, the RPC will fail.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.DeleteApplicationInstances
   */
  deleteApplicationInstances: {
    methodKind: "unary";
    input: typeof DeleteApplicationInstancesRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Adds target stream input to the Application.
   * If the Application is deployed, the corresponding new Application instance
   * will be created. If the stream has already been in the Application, the RPC
   * will fail.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.UpdateApplicationInstances
   */
  updateApplicationInstances: {
    methodKind: "unary";
    input: typeof UpdateApplicationInstancesRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Lists Drafts in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.ListDrafts
   */
  listDrafts: {
    methodKind: "unary";
    input: typeof ListDraftsRequestSchema;
    output: typeof ListDraftsResponseSchema;
  },
  /**
   * Gets details of a single Draft.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.GetDraft
   */
  getDraft: {
    methodKind: "unary";
    input: typeof GetDraftRequestSchema;
    output: typeof DraftSchema;
  },
  /**
   * Creates a new Draft in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.CreateDraft
   */
  createDraft: {
    methodKind: "unary";
    input: typeof CreateDraftRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates the parameters of a single Draft.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.UpdateDraft
   */
  updateDraft: {
    methodKind: "unary";
    input: typeof UpdateDraftRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deletes a single Draft.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.DeleteDraft
   */
  deleteDraft: {
    methodKind: "unary";
    input: typeof DeleteDraftRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Lists Processors in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.ListProcessors
   */
  listProcessors: {
    methodKind: "unary";
    input: typeof ListProcessorsRequestSchema;
    output: typeof ListProcessorsResponseSchema;
  },
  /**
   * ListPrebuiltProcessors is a custom pass-through verb that Lists Prebuilt
   * Processors.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.ListPrebuiltProcessors
   */
  listPrebuiltProcessors: {
    methodKind: "unary";
    input: typeof ListPrebuiltProcessorsRequestSchema;
    output: typeof ListPrebuiltProcessorsResponseSchema;
  },
  /**
   * Gets details of a single Processor.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.GetProcessor
   */
  getProcessor: {
    methodKind: "unary";
    input: typeof GetProcessorRequestSchema;
    output: typeof ProcessorSchema;
  },
  /**
   * Creates a new Processor in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.CreateProcessor
   */
  createProcessor: {
    methodKind: "unary";
    input: typeof CreateProcessorRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates the parameters of a single Processor.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.UpdateProcessor
   */
  updateProcessor: {
    methodKind: "unary";
    input: typeof UpdateProcessorRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deletes a single Processor.
   *
   * @generated from rpc google.cloud.visionai.v1alpha1.AppPlatform.DeleteProcessor
   */
  deleteProcessor: {
    methodKind: "unary";
    input: typeof DeleteProcessorRequestSchema;
    output: typeof OperationSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_visionai_v1alpha1_platform, 0);

