// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/visionai/v1/platform.proto (package google.cloud.visionai.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { StreamAnnotation, StreamAnnotationType } from "./annotations_pb";
import { file_google_cloud_visionai_v1_annotations } from "./annotations_pb";
import type { GcsSource } from "./common_pb";
import { file_google_cloud_visionai_v1_common } from "./common_pb";
import type { OperationSchema } from "../../../longrunning/operations_pb";
import { file_google_longrunning_operations } from "../../../longrunning/operations_pb";
import type { Duration, FieldMask, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_empty, file_google_protobuf_field_mask, file_google_protobuf_struct, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { JsonObject, Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/visionai/v1/platform.proto.
 */
export const file_google_cloud_visionai_v1_platform: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_cloud_visionai_v1_annotations, file_google_cloud_visionai_v1_common, file_google_longrunning_operations, file_google_protobuf_duration, file_google_protobuf_empty, file_google_protobuf_field_mask, file_google_protobuf_struct, file_google_protobuf_timestamp]);

/**
 * Message for DeleteApplicationInstance Response.
 *
 * @generated from message google.cloud.visionai.v1.DeleteApplicationInstancesResponse
 */
export type DeleteApplicationInstancesResponse = Message<"google.cloud.visionai.v1.DeleteApplicationInstancesResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.DeleteApplicationInstancesResponse.
 * Use `create(DeleteApplicationInstancesResponseSchema)` to create a new message.
 */
export const DeleteApplicationInstancesResponseSchema: GenMessage<DeleteApplicationInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 0);

/**
 * Message for CreateApplicationInstance Response.
 *
 * @generated from message google.cloud.visionai.v1.CreateApplicationInstancesResponse
 */
export type CreateApplicationInstancesResponse = Message<"google.cloud.visionai.v1.CreateApplicationInstancesResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.CreateApplicationInstancesResponse.
 * Use `create(CreateApplicationInstancesResponseSchema)` to create a new message.
 */
export const CreateApplicationInstancesResponseSchema: GenMessage<CreateApplicationInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 1);

/**
 * Message for UpdateApplicationInstances Response.
 *
 * @generated from message google.cloud.visionai.v1.UpdateApplicationInstancesResponse
 */
export type UpdateApplicationInstancesResponse = Message<"google.cloud.visionai.v1.UpdateApplicationInstancesResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateApplicationInstancesResponse.
 * Use `create(UpdateApplicationInstancesResponseSchema)` to create a new message.
 */
export const UpdateApplicationInstancesResponseSchema: GenMessage<UpdateApplicationInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 2);

/**
 * Message for adding stream input to an Application.
 *
 * @generated from message google.cloud.visionai.v1.CreateApplicationInstancesRequest
 */
export type CreateApplicationInstancesRequest = Message<"google.cloud.visionai.v1.CreateApplicationInstancesRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The resources being created.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ApplicationInstance application_instances = 2;
   */
  applicationInstances: ApplicationInstance[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.CreateApplicationInstancesRequest.
 * Use `create(CreateApplicationInstancesRequestSchema)` to create a new message.
 */
export const CreateApplicationInstancesRequestSchema: GenMessage<CreateApplicationInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 3);

/**
 * Message for removing stream input from an Application.
 *
 * @generated from message google.cloud.visionai.v1.DeleteApplicationInstancesRequest
 */
export type DeleteApplicationInstancesRequest = Message<"google.cloud.visionai.v1.DeleteApplicationInstancesRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: repeated string instance_ids = 2;
   */
  instanceIds: string[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.DeleteApplicationInstancesRequest.
 * Use `create(DeleteApplicationInstancesRequestSchema)` to create a new message.
 */
export const DeleteApplicationInstancesRequestSchema: GenMessage<DeleteApplicationInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 4);

/**
 * RPC Request Messages.
 * Message for DeployApplication Response.
 *
 * @generated from message google.cloud.visionai.v1.DeployApplicationResponse
 */
export type DeployApplicationResponse = Message<"google.cloud.visionai.v1.DeployApplicationResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.DeployApplicationResponse.
 * Use `create(DeployApplicationResponseSchema)` to create a new message.
 */
export const DeployApplicationResponseSchema: GenMessage<DeployApplicationResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 5);

/**
 * Message for UndeployApplication Response.
 *
 * @generated from message google.cloud.visionai.v1.UndeployApplicationResponse
 */
export type UndeployApplicationResponse = Message<"google.cloud.visionai.v1.UndeployApplicationResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.UndeployApplicationResponse.
 * Use `create(UndeployApplicationResponseSchema)` to create a new message.
 */
export const UndeployApplicationResponseSchema: GenMessage<UndeployApplicationResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 6);

/**
 * Message for RemoveApplicationStreamInput Response.
 *
 * @generated from message google.cloud.visionai.v1.RemoveApplicationStreamInputResponse
 */
export type RemoveApplicationStreamInputResponse = Message<"google.cloud.visionai.v1.RemoveApplicationStreamInputResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.RemoveApplicationStreamInputResponse.
 * Use `create(RemoveApplicationStreamInputResponseSchema)` to create a new message.
 */
export const RemoveApplicationStreamInputResponseSchema: GenMessage<RemoveApplicationStreamInputResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 7);

/**
 * Message for AddApplicationStreamInput Response.
 *
 * @generated from message google.cloud.visionai.v1.AddApplicationStreamInputResponse
 */
export type AddApplicationStreamInputResponse = Message<"google.cloud.visionai.v1.AddApplicationStreamInputResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.AddApplicationStreamInputResponse.
 * Use `create(AddApplicationStreamInputResponseSchema)` to create a new message.
 */
export const AddApplicationStreamInputResponseSchema: GenMessage<AddApplicationStreamInputResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 8);

/**
 * Message for AddApplicationStreamInput Response.
 *
 * @generated from message google.cloud.visionai.v1.UpdateApplicationStreamInputResponse
 */
export type UpdateApplicationStreamInputResponse = Message<"google.cloud.visionai.v1.UpdateApplicationStreamInputResponse"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateApplicationStreamInputResponse.
 * Use `create(UpdateApplicationStreamInputResponseSchema)` to create a new message.
 */
export const UpdateApplicationStreamInputResponseSchema: GenMessage<UpdateApplicationStreamInputResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 9);

/**
 * Message for requesting list of Applications.
 *
 * @generated from message google.cloud.visionai.v1.ListApplicationsRequest
 */
export type ListApplicationsRequest = Message<"google.cloud.visionai.v1.ListApplicationsRequest"> & {
  /**
   * Required. Parent value for ListApplicationsRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ListApplicationsRequest.
 * Use `create(ListApplicationsRequestSchema)` to create a new message.
 */
export const ListApplicationsRequestSchema: GenMessage<ListApplicationsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 10);

/**
 * Message for response to listing Applications.
 *
 * @generated from message google.cloud.visionai.v1.ListApplicationsResponse
 */
export type ListApplicationsResponse = Message<"google.cloud.visionai.v1.ListApplicationsResponse"> & {
  /**
   * The list of Application.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Application applications = 1;
   */
  applications: Application[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1.ListApplicationsResponse.
 * Use `create(ListApplicationsResponseSchema)` to create a new message.
 */
export const ListApplicationsResponseSchema: GenMessage<ListApplicationsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 11);

/**
 * Message for getting a Application.
 *
 * @generated from message google.cloud.visionai.v1.GetApplicationRequest
 */
export type GetApplicationRequest = Message<"google.cloud.visionai.v1.GetApplicationRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1.GetApplicationRequest.
 * Use `create(GetApplicationRequestSchema)` to create a new message.
 */
export const GetApplicationRequestSchema: GenMessage<GetApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 12);

/**
 * Message for creating a Application.
 *
 * @generated from message google.cloud.visionai.v1.CreateApplicationRequest
 */
export type CreateApplicationRequest = Message<"google.cloud.visionai.v1.CreateApplicationRequest"> & {
  /**
   * Required. Value for parent.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string application_id = 2;
   */
  applicationId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1.Application application = 3;
   */
  application?: Application;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.CreateApplicationRequest.
 * Use `create(CreateApplicationRequestSchema)` to create a new message.
 */
export const CreateApplicationRequestSchema: GenMessage<CreateApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 13);

/**
 * Message for updating an Application.
 *
 * @generated from message google.cloud.visionai.v1.UpdateApplicationRequest
 */
export type UpdateApplicationRequest = Message<"google.cloud.visionai.v1.UpdateApplicationRequest"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Application resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1.Application application = 2;
   */
  application?: Application;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateApplicationRequest.
 * Use `create(UpdateApplicationRequestSchema)` to create a new message.
 */
export const UpdateApplicationRequestSchema: GenMessage<UpdateApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 14);

/**
 * Message for deleting an Application.
 *
 * @generated from message google.cloud.visionai.v1.DeleteApplicationRequest
 */
export type DeleteApplicationRequest = Message<"google.cloud.visionai.v1.DeleteApplicationRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;

  /**
   * Optional. If set to true, any instances and drafts from this application
   * will also be deleted. (Otherwise, the request will only work if the
   * application has no instances and drafts.)
   *
   * @generated from field: bool force = 3;
   */
  force: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.DeleteApplicationRequest.
 * Use `create(DeleteApplicationRequestSchema)` to create a new message.
 */
export const DeleteApplicationRequestSchema: GenMessage<DeleteApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 15);

/**
 * Message for deploying an Application.
 *
 * @generated from message google.cloud.visionai.v1.DeployApplicationRequest
 */
export type DeployApplicationRequest = Message<"google.cloud.visionai.v1.DeployApplicationRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * If set, validate the request and preview the application graph, but do not
   * actually deploy it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly: boolean;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * Optional. Whether or not to enable monitoring for the application on
   * deployment.
   *
   * @generated from field: bool enable_monitoring = 4;
   */
  enableMonitoring: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.DeployApplicationRequest.
 * Use `create(DeployApplicationRequestSchema)` to create a new message.
 */
export const DeployApplicationRequestSchema: GenMessage<DeployApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 16);

/**
 * Message for undeploying an Application.
 *
 * @generated from message google.cloud.visionai.v1.UndeployApplicationRequest
 */
export type UndeployApplicationRequest = Message<"google.cloud.visionai.v1.UndeployApplicationRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.UndeployApplicationRequest.
 * Use `create(UndeployApplicationRequestSchema)` to create a new message.
 */
export const UndeployApplicationRequestSchema: GenMessage<UndeployApplicationRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 17);

/**
 * Message about a single stream input config.
 *
 * @generated from message google.cloud.visionai.v1.ApplicationStreamInput
 */
export type ApplicationStreamInput = Message<"google.cloud.visionai.v1.ApplicationStreamInput"> & {
  /**
   * @generated from field: google.cloud.visionai.v1.StreamWithAnnotation stream_with_annotation = 1;
   */
  streamWithAnnotation?: StreamWithAnnotation;
};

/**
 * Describes the message google.cloud.visionai.v1.ApplicationStreamInput.
 * Use `create(ApplicationStreamInputSchema)` to create a new message.
 */
export const ApplicationStreamInputSchema: GenMessage<ApplicationStreamInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 18);

/**
 * Message for adding stream input to an Application.
 *
 * @generated from message google.cloud.visionai.v1.AddApplicationStreamInputRequest
 */
export type AddApplicationStreamInputRequest = Message<"google.cloud.visionai.v1.AddApplicationStreamInputRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The stream inputs to add, the stream resource name is the key of each
   * StreamInput, and it must be unique within each application.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ApplicationStreamInput application_stream_inputs = 2;
   */
  applicationStreamInputs: ApplicationStreamInput[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.AddApplicationStreamInputRequest.
 * Use `create(AddApplicationStreamInputRequestSchema)` to create a new message.
 */
export const AddApplicationStreamInputRequestSchema: GenMessage<AddApplicationStreamInputRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 19);

/**
 * Message for updating stream input to an Application.
 *
 * @generated from message google.cloud.visionai.v1.UpdateApplicationStreamInputRequest
 */
export type UpdateApplicationStreamInputRequest = Message<"google.cloud.visionai.v1.UpdateApplicationStreamInputRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The stream inputs to update, the stream resource name is the key of each
   * StreamInput, and it must be unique within each application.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ApplicationStreamInput application_stream_inputs = 2;
   */
  applicationStreamInputs: ApplicationStreamInput[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * If true, UpdateApplicationStreamInput will insert stream input to
   * application even if the target stream is not included in the application.
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateApplicationStreamInputRequest.
 * Use `create(UpdateApplicationStreamInputRequestSchema)` to create a new message.
 */
export const UpdateApplicationStreamInputRequestSchema: GenMessage<UpdateApplicationStreamInputRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 20);

/**
 * Message for removing stream input from an Application.
 *
 * @generated from message google.cloud.visionai.v1.RemoveApplicationStreamInputRequest
 */
export type RemoveApplicationStreamInputRequest = Message<"google.cloud.visionai.v1.RemoveApplicationStreamInputRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The target stream to remove.
   *
   * @generated from field: repeated google.cloud.visionai.v1.RemoveApplicationStreamInputRequest.TargetStreamInput target_stream_inputs = 2;
   */
  targetStreamInputs: RemoveApplicationStreamInputRequest_TargetStreamInput[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.RemoveApplicationStreamInputRequest.
 * Use `create(RemoveApplicationStreamInputRequestSchema)` to create a new message.
 */
export const RemoveApplicationStreamInputRequestSchema: GenMessage<RemoveApplicationStreamInputRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 21);

/**
 * Message about target streamInput to remove.
 *
 * @generated from message google.cloud.visionai.v1.RemoveApplicationStreamInputRequest.TargetStreamInput
 */
export type RemoveApplicationStreamInputRequest_TargetStreamInput = Message<"google.cloud.visionai.v1.RemoveApplicationStreamInputRequest.TargetStreamInput"> & {
  /**
   * @generated from field: string stream = 1;
   */
  stream: string;
};

/**
 * Describes the message google.cloud.visionai.v1.RemoveApplicationStreamInputRequest.TargetStreamInput.
 * Use `create(RemoveApplicationStreamInputRequest_TargetStreamInputSchema)` to create a new message.
 */
export const RemoveApplicationStreamInputRequest_TargetStreamInputSchema: GenMessage<RemoveApplicationStreamInputRequest_TargetStreamInput> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 21, 0);

/**
 * Message for requesting list of Instances.
 *
 * @generated from message google.cloud.visionai.v1.ListInstancesRequest
 */
export type ListInstancesRequest = Message<"google.cloud.visionai.v1.ListInstancesRequest"> & {
  /**
   * Required. Parent value for ListInstancesRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ListInstancesRequest.
 * Use `create(ListInstancesRequestSchema)` to create a new message.
 */
export const ListInstancesRequestSchema: GenMessage<ListInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 22);

/**
 * Message for response to listing Instances.
 *
 * @generated from message google.cloud.visionai.v1.ListInstancesResponse
 */
export type ListInstancesResponse = Message<"google.cloud.visionai.v1.ListInstancesResponse"> & {
  /**
   * The list of Instance.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Instance instances = 1;
   */
  instances: Instance[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1.ListInstancesResponse.
 * Use `create(ListInstancesResponseSchema)` to create a new message.
 */
export const ListInstancesResponseSchema: GenMessage<ListInstancesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 23);

/**
 * Message for getting a Instance.
 *
 * @generated from message google.cloud.visionai.v1.GetInstanceRequest
 */
export type GetInstanceRequest = Message<"google.cloud.visionai.v1.GetInstanceRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1.GetInstanceRequest.
 * Use `create(GetInstanceRequestSchema)` to create a new message.
 */
export const GetInstanceRequestSchema: GenMessage<GetInstanceRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 24);

/**
 * Message for requesting list of Drafts.
 *
 * @generated from message google.cloud.visionai.v1.ListDraftsRequest
 */
export type ListDraftsRequest = Message<"google.cloud.visionai.v1.ListDraftsRequest"> & {
  /**
   * Required. Parent value for ListDraftsRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ListDraftsRequest.
 * Use `create(ListDraftsRequestSchema)` to create a new message.
 */
export const ListDraftsRequestSchema: GenMessage<ListDraftsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 25);

/**
 * Message for response to listing Drafts.
 *
 * @generated from message google.cloud.visionai.v1.ListDraftsResponse
 */
export type ListDraftsResponse = Message<"google.cloud.visionai.v1.ListDraftsResponse"> & {
  /**
   * The list of Draft.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Draft drafts = 1;
   */
  drafts: Draft[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1.ListDraftsResponse.
 * Use `create(ListDraftsResponseSchema)` to create a new message.
 */
export const ListDraftsResponseSchema: GenMessage<ListDraftsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 26);

/**
 * Message for getting a Draft.
 *
 * @generated from message google.cloud.visionai.v1.GetDraftRequest
 */
export type GetDraftRequest = Message<"google.cloud.visionai.v1.GetDraftRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1.GetDraftRequest.
 * Use `create(GetDraftRequestSchema)` to create a new message.
 */
export const GetDraftRequestSchema: GenMessage<GetDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 27);

/**
 * Message for creating a Draft.
 *
 * @generated from message google.cloud.visionai.v1.CreateDraftRequest
 */
export type CreateDraftRequest = Message<"google.cloud.visionai.v1.CreateDraftRequest"> & {
  /**
   * Required. Value for parent.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string draft_id = 2;
   */
  draftId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1.Draft draft = 3;
   */
  draft?: Draft;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.CreateDraftRequest.
 * Use `create(CreateDraftRequestSchema)` to create a new message.
 */
export const CreateDraftRequestSchema: GenMessage<CreateDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 28);

/**
 * Message for updating a Draft.
 *
 * @generated from message google.cloud.visionai.v1.UpdateDraftRequest
 */
export type UpdateDraftRequest = Message<"google.cloud.visionai.v1.UpdateDraftRequest"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Draft resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1.Draft draft = 2;
   */
  draft?: Draft;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * If true, UpdateDraftRequest will create one resource if the target resource
   * doesn't exist, this time, the field_mask will be ignored.
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateDraftRequest.
 * Use `create(UpdateDraftRequestSchema)` to create a new message.
 */
export const UpdateDraftRequestSchema: GenMessage<UpdateDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 29);

/**
 * Message for updating an ApplicationInstance.
 *
 * @generated from message google.cloud.visionai.v1.UpdateApplicationInstancesRequest
 */
export type UpdateApplicationInstancesRequest = Message<"google.cloud.visionai.v1.UpdateApplicationInstancesRequest"> & {
  /**
   * Required. the name of the application to retrieve.
   * Format:
   * "projects/{project}/locations/{location}/applications/{application}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * @generated from field: repeated google.cloud.visionai.v1.UpdateApplicationInstancesRequest.UpdateApplicationInstance application_instances = 2;
   */
  applicationInstances: UpdateApplicationInstancesRequest_UpdateApplicationInstance[];

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;

  /**
   * If true, Update Request will create one resource if the target resource
   * doesn't exist, this time, the field_mask will be ignored.
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateApplicationInstancesRequest.
 * Use `create(UpdateApplicationInstancesRequestSchema)` to create a new message.
 */
export const UpdateApplicationInstancesRequestSchema: GenMessage<UpdateApplicationInstancesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 30);

/**
 * @generated from message google.cloud.visionai.v1.UpdateApplicationInstancesRequest.UpdateApplicationInstance
 */
export type UpdateApplicationInstancesRequest_UpdateApplicationInstance = Message<"google.cloud.visionai.v1.UpdateApplicationInstancesRequest.UpdateApplicationInstance"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in
   * the Draft resource by the update. The fields specified in the update_mask
   * are relative to the resource, not the full request. A field will be
   * overwritten if it is in the mask. If the user does not provide a mask
   * then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1.Instance instance = 2;
   */
  instance?: Instance;

  /**
   * Required. The id of the instance.
   *
   * @generated from field: string instance_id = 3;
   */
  instanceId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateApplicationInstancesRequest.UpdateApplicationInstance.
 * Use `create(UpdateApplicationInstancesRequest_UpdateApplicationInstanceSchema)` to create a new message.
 */
export const UpdateApplicationInstancesRequest_UpdateApplicationInstanceSchema: GenMessage<UpdateApplicationInstancesRequest_UpdateApplicationInstance> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 30, 0);

/**
 * Message for deleting a Draft.
 *
 * @generated from message google.cloud.visionai.v1.DeleteDraftRequest
 */
export type DeleteDraftRequest = Message<"google.cloud.visionai.v1.DeleteDraftRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.DeleteDraftRequest.
 * Use `create(DeleteDraftRequestSchema)` to create a new message.
 */
export const DeleteDraftRequestSchema: GenMessage<DeleteDraftRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 31);

/**
 * Message for requesting list of Processors.
 *
 * @generated from message google.cloud.visionai.v1.ListProcessorsRequest
 */
export type ListProcessorsRequest = Message<"google.cloud.visionai.v1.ListProcessorsRequest"> & {
  /**
   * Required. Parent value for ListProcessorsRequest.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Requested page size. Server may return fewer items than requested.
   * If unspecified, server will pick an appropriate default.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;

  /**
   * Filtering results.
   *
   * @generated from field: string filter = 4;
   */
  filter: string;

  /**
   * Hint for how to order the results.
   *
   * @generated from field: string order_by = 5;
   */
  orderBy: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ListProcessorsRequest.
 * Use `create(ListProcessorsRequestSchema)` to create a new message.
 */
export const ListProcessorsRequestSchema: GenMessage<ListProcessorsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 32);

/**
 * Message for response to listing Processors.
 *
 * @generated from message google.cloud.visionai.v1.ListProcessorsResponse
 */
export type ListProcessorsResponse = Message<"google.cloud.visionai.v1.ListProcessorsResponse"> & {
  /**
   * The list of Processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Processor processors = 1;
   */
  processors: Processor[];

  /**
   * A token identifying a page of results the server should return.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;

  /**
   * Locations that could not be reached.
   *
   * @generated from field: repeated string unreachable = 3;
   */
  unreachable: string[];
};

/**
 * Describes the message google.cloud.visionai.v1.ListProcessorsResponse.
 * Use `create(ListProcessorsResponseSchema)` to create a new message.
 */
export const ListProcessorsResponseSchema: GenMessage<ListProcessorsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 33);

/**
 * Request Message for listing Prebuilt Processors.
 *
 * @generated from message google.cloud.visionai.v1.ListPrebuiltProcessorsRequest
 */
export type ListPrebuiltProcessorsRequest = Message<"google.cloud.visionai.v1.ListPrebuiltProcessorsRequest"> & {
  /**
   * Required. Parent path.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ListPrebuiltProcessorsRequest.
 * Use `create(ListPrebuiltProcessorsRequestSchema)` to create a new message.
 */
export const ListPrebuiltProcessorsRequestSchema: GenMessage<ListPrebuiltProcessorsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 34);

/**
 * Response Message for listing Prebuilt Processors.
 *
 * @generated from message google.cloud.visionai.v1.ListPrebuiltProcessorsResponse
 */
export type ListPrebuiltProcessorsResponse = Message<"google.cloud.visionai.v1.ListPrebuiltProcessorsResponse"> & {
  /**
   * The list of Processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Processor processors = 1;
   */
  processors: Processor[];
};

/**
 * Describes the message google.cloud.visionai.v1.ListPrebuiltProcessorsResponse.
 * Use `create(ListPrebuiltProcessorsResponseSchema)` to create a new message.
 */
export const ListPrebuiltProcessorsResponseSchema: GenMessage<ListPrebuiltProcessorsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 35);

/**
 * Message for getting a Processor.
 *
 * @generated from message google.cloud.visionai.v1.GetProcessorRequest
 */
export type GetProcessorRequest = Message<"google.cloud.visionai.v1.GetProcessorRequest"> & {
  /**
   * Required. Name of the resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1.GetProcessorRequest.
 * Use `create(GetProcessorRequestSchema)` to create a new message.
 */
export const GetProcessorRequestSchema: GenMessage<GetProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 36);

/**
 * Message for creating a Processor.
 *
 * @generated from message google.cloud.visionai.v1.CreateProcessorRequest
 */
export type CreateProcessorRequest = Message<"google.cloud.visionai.v1.CreateProcessorRequest"> & {
  /**
   * Required. Value for parent.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string processor_id = 2;
   */
  processorId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1.Processor processor = 3;
   */
  processor?: Processor;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 4;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.CreateProcessorRequest.
 * Use `create(CreateProcessorRequestSchema)` to create a new message.
 */
export const CreateProcessorRequestSchema: GenMessage<CreateProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 37);

/**
 * Message for updating a Processor.
 *
 * @generated from message google.cloud.visionai.v1.UpdateProcessorRequest
 */
export type UpdateProcessorRequest = Message<"google.cloud.visionai.v1.UpdateProcessorRequest"> & {
  /**
   * Optional. Field mask is used to specify the fields to be overwritten in the
   * Processor resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then all fields will be overwritten.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 1;
   */
  updateMask?: FieldMask;

  /**
   * Required. The resource being updated.
   *
   * @generated from field: google.cloud.visionai.v1.Processor processor = 2;
   */
  processor?: Processor;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes since the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 3;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.UpdateProcessorRequest.
 * Use `create(UpdateProcessorRequestSchema)` to create a new message.
 */
export const UpdateProcessorRequestSchema: GenMessage<UpdateProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 38);

/**
 * Message for deleting a Processor.
 *
 * @generated from message google.cloud.visionai.v1.DeleteProcessorRequest
 */
export type DeleteProcessorRequest = Message<"google.cloud.visionai.v1.DeleteProcessorRequest"> & {
  /**
   * Required. Name of the resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. An optional request ID to identify requests. Specify a unique
   * request ID so that if you must retry your request, the server will know to
   * ignore the request if it has already been completed. The server will
   * guarantee that for at least 60 minutes after the first request.
   *
   * For example, consider a situation where you make an initial request and
   * the request times out. If you make the request again with the same request
   * ID, the server can check if original operation with the same request ID
   * was received, and if so, will ignore the second request. This prevents
   * clients from accidentally creating duplicate commitments.
   *
   * The request ID must be a valid UUID with the exception that zero UUID is
   * not supported (00000000-0000-0000-0000-000000000000).
   *
   * @generated from field: string request_id = 2;
   */
  requestId: string;
};

/**
 * Describes the message google.cloud.visionai.v1.DeleteProcessorRequest.
 * Use `create(DeleteProcessorRequestSchema)` to create a new message.
 */
export const DeleteProcessorRequestSchema: GenMessage<DeleteProcessorRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 39);

/**
 * Message describing Application object
 *
 * @generated from message google.cloud.visionai.v1.Application
 */
export type Application = Message<"google.cloud.visionai.v1.Application"> & {
  /**
   * name of resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Update timestamp
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the solution.
   *
   * @generated from field: string display_name = 5;
   */
  displayName: string;

  /**
   * A description for this application.
   *
   * @generated from field: string description = 6;
   */
  description: string;

  /**
   * Application graph configuration.
   *
   * @generated from field: google.cloud.visionai.v1.ApplicationConfigs application_configs = 7;
   */
  applicationConfigs?: ApplicationConfigs;

  /**
   * Output only. Application graph runtime info. Only exists when application
   * state equals to DEPLOYED.
   *
   * @generated from field: google.cloud.visionai.v1.Application.ApplicationRuntimeInfo runtime_info = 8;
   */
  runtimeInfo?: Application_ApplicationRuntimeInfo;

  /**
   * Output only. State of the application.
   *
   * @generated from field: google.cloud.visionai.v1.Application.State state = 9;
   */
  state: Application_State;

  /**
   * Billing mode of the application.
   *
   * @generated from field: google.cloud.visionai.v1.Application.BillingMode billing_mode = 12;
   */
  billingMode: Application_BillingMode;
};

/**
 * Describes the message google.cloud.visionai.v1.Application.
 * Use `create(ApplicationSchema)` to create a new message.
 */
export const ApplicationSchema: GenMessage<Application> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 40);

/**
 * Message storing the runtime information of the application.
 *
 * @generated from message google.cloud.visionai.v1.Application.ApplicationRuntimeInfo
 */
export type Application_ApplicationRuntimeInfo = Message<"google.cloud.visionai.v1.Application.ApplicationRuntimeInfo"> & {
  /**
   * Timestamp when the engine be deployed
   *
   * @generated from field: google.protobuf.Timestamp deploy_time = 1;
   */
  deployTime?: Timestamp;

  /**
   * Globally created resources like warehouse dataschemas.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.GlobalOutputResource global_output_resources = 3;
   */
  globalOutputResources: Application_ApplicationRuntimeInfo_GlobalOutputResource[];

  /**
   * Monitoring-related configuration for this application.
   *
   * @generated from field: google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.MonitoringConfig monitoring_config = 4;
   */
  monitoringConfig?: Application_ApplicationRuntimeInfo_MonitoringConfig;
};

/**
 * Describes the message google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.
 * Use `create(Application_ApplicationRuntimeInfoSchema)` to create a new message.
 */
export const Application_ApplicationRuntimeInfoSchema: GenMessage<Application_ApplicationRuntimeInfo> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 40, 0);

/**
 * Message about output resources from application.
 *
 * @generated from message google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.GlobalOutputResource
 */
export type Application_ApplicationRuntimeInfo_GlobalOutputResource = Message<"google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.GlobalOutputResource"> & {
  /**
   * The full resource name of the outputted resources.
   *
   * @generated from field: string output_resource = 1;
   */
  outputResource: string;

  /**
   * The name of graph node who produces the output resource name.
   * For example:
   * output_resource:
   * /projects/123/locations/us-central1/corpora/my-corpus/dataSchemas/my-schema
   * producer_node: occupancy-count
   *
   * @generated from field: string producer_node = 2;
   */
  producerNode: string;

  /**
   * The key of the output resource, it has to be unique within the same
   * producer node. One producer node can output several output resources,
   * the key can be used to match corresponding output resources.
   *
   * @generated from field: string key = 3;
   */
  key: string;
};

/**
 * Describes the message google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.GlobalOutputResource.
 * Use `create(Application_ApplicationRuntimeInfo_GlobalOutputResourceSchema)` to create a new message.
 */
export const Application_ApplicationRuntimeInfo_GlobalOutputResourceSchema: GenMessage<Application_ApplicationRuntimeInfo_GlobalOutputResource> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 40, 0, 0);

/**
 * Monitoring-related configuration for an application.
 *
 * @generated from message google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.MonitoringConfig
 */
export type Application_ApplicationRuntimeInfo_MonitoringConfig = Message<"google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.MonitoringConfig"> & {
  /**
   * Whether this application has monitoring enabled.
   *
   * @generated from field: bool enabled = 1;
   */
  enabled: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.Application.ApplicationRuntimeInfo.MonitoringConfig.
 * Use `create(Application_ApplicationRuntimeInfo_MonitoringConfigSchema)` to create a new message.
 */
export const Application_ApplicationRuntimeInfo_MonitoringConfigSchema: GenMessage<Application_ApplicationRuntimeInfo_MonitoringConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 40, 0, 1);

/**
 * State of the Application
 *
 * @generated from enum google.cloud.visionai.v1.Application.State
 */
export enum Application_State {
  /**
   * The default value. This value is used if the state is omitted.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * State CREATED.
   *
   * @generated from enum value: CREATED = 1;
   */
  CREATED = 1,

  /**
   * State DEPLOYING.
   *
   * @generated from enum value: DEPLOYING = 2;
   */
  DEPLOYING = 2,

  /**
   * State DEPLOYED.
   *
   * @generated from enum value: DEPLOYED = 3;
   */
  DEPLOYED = 3,

  /**
   * State UNDEPLOYING.
   *
   * @generated from enum value: UNDEPLOYING = 4;
   */
  UNDEPLOYING = 4,

  /**
   * State DELETED.
   *
   * @generated from enum value: DELETED = 5;
   */
  DELETED = 5,

  /**
   * State ERROR.
   *
   * @generated from enum value: ERROR = 6;
   */
  ERROR = 6,

  /**
   * State CREATING.
   *
   * @generated from enum value: CREATING = 7;
   */
  CREATING = 7,

  /**
   * State Updating.
   *
   * @generated from enum value: UPDATING = 8;
   */
  UPDATING = 8,

  /**
   * State Deleting.
   *
   * @generated from enum value: DELETING = 9;
   */
  DELETING = 9,

  /**
   * State Fixing.
   *
   * @generated from enum value: FIXING = 10;
   */
  FIXING = 10,
}

/**
 * Describes the enum google.cloud.visionai.v1.Application.State.
 */
export const Application_StateSchema: GenEnum<Application_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 40, 0);

/**
 * Billing mode of the Application
 *
 * @generated from enum google.cloud.visionai.v1.Application.BillingMode
 */
export enum Application_BillingMode {
  /**
   * The default value.
   *
   * @generated from enum value: BILLING_MODE_UNSPECIFIED = 0;
   */
  BILLING_MODE_UNSPECIFIED = 0,

  /**
   * Pay as you go billing mode.
   *
   * @generated from enum value: PAYG = 1;
   */
  PAYG = 1,

  /**
   * Monthly billing mode.
   *
   * @generated from enum value: MONTHLY = 2;
   */
  MONTHLY = 2,
}

/**
 * Describes the enum google.cloud.visionai.v1.Application.BillingMode.
 */
export const Application_BillingModeSchema: GenEnum<Application_BillingMode> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 40, 1);

/**
 * Message storing the graph of the application.
 *
 * @generated from message google.cloud.visionai.v1.ApplicationConfigs
 */
export type ApplicationConfigs = Message<"google.cloud.visionai.v1.ApplicationConfigs"> & {
  /**
   * A list of nodes  in the application graph.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Node nodes = 1;
   */
  nodes: Node[];

  /**
   * Event-related configuration for this application.
   *
   * @generated from field: google.cloud.visionai.v1.ApplicationConfigs.EventDeliveryConfig event_delivery_config = 3;
   */
  eventDeliveryConfig?: ApplicationConfigs_EventDeliveryConfig;
};

/**
 * Describes the message google.cloud.visionai.v1.ApplicationConfigs.
 * Use `create(ApplicationConfigsSchema)` to create a new message.
 */
export const ApplicationConfigsSchema: GenMessage<ApplicationConfigs> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 41);

/**
 * message storing the config for event delivery
 *
 * @generated from message google.cloud.visionai.v1.ApplicationConfigs.EventDeliveryConfig
 */
export type ApplicationConfigs_EventDeliveryConfig = Message<"google.cloud.visionai.v1.ApplicationConfigs.EventDeliveryConfig"> & {
  /**
   * The delivery channel for the event notification, only pub/sub topic is
   * supported now.
   * Example channel:
   * [//pubsub.googleapis.com/projects/visionai-testing-stable/topics/test-topic]
   *
   * @generated from field: string channel = 1;
   */
  channel: string;

  /**
   * The expected delivery interval for the same event. The same event won't
   * be notified multiple times during this internal event that it is
   * happening multiple times during the period of time.The same event is
   * identified by <event_id, app_platform_metadata>.
   *
   * @generated from field: google.protobuf.Duration minimal_delivery_interval = 2;
   */
  minimalDeliveryInterval?: Duration;
};

/**
 * Describes the message google.cloud.visionai.v1.ApplicationConfigs.EventDeliveryConfig.
 * Use `create(ApplicationConfigs_EventDeliveryConfigSchema)` to create a new message.
 */
export const ApplicationConfigs_EventDeliveryConfigSchema: GenMessage<ApplicationConfigs_EventDeliveryConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 41, 0);

/**
 * Message describing node object.
 *
 * @generated from message google.cloud.visionai.v1.Node
 */
export type Node = Message<"google.cloud.visionai.v1.Node"> & {
  /**
   * @generated from oneof google.cloud.visionai.v1.Node.stream_output_config
   */
  streamOutputConfig: {
    /**
     * By default, the output of the node will only be available to downstream
     * nodes. To consume the direct output from the application node, the output
     * must be sent to Vision AI Streams at first.
     *
     * By setting output_all_output_channels_to_stream to true, App Platform
     * will automatically send all the outputs of the current node to Vision AI
     * Stream resources (one stream per output channel). The output stream
     * resource will be created by App Platform automatically during deployment
     * and deleted after application un-deployment.
     * Note that this config applies to all the Application Instances.
     *
     * The output stream can be override at instance level by
     * configuring the `output_resources` section of Instance resource.
     * `producer_node` should be current node, `output_resource_binding` should
     * be the output channel name (or leave it blank if there is only 1 output
     * channel of the processor) and `output_resource` should be the target
     * output stream.
     *
     * @generated from field: bool output_all_output_channels_to_stream = 6;
     */
    value: boolean;
    case: "outputAllOutputChannelsToStream";
  } | { case: undefined; value?: undefined };

  /**
   * Required. A unique name for the node.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * A user friendly display name for the node.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * Node config.
   *
   * @generated from field: google.cloud.visionai.v1.ProcessorConfig node_config = 3;
   */
  nodeConfig?: ProcessorConfig;

  /**
   * Processor name refer to the chosen processor resource.
   *
   * @generated from field: string processor = 4;
   */
  processor: string;

  /**
   * Parent node. Input node should not have parent node. For V1 Alpha1/Beta
   * only media warehouse node can have multiple parents, other types of nodes
   * will only have one parent.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Node.InputEdge parents = 5;
   */
  parents: Node_InputEdge[];
};

/**
 * Describes the message google.cloud.visionai.v1.Node.
 * Use `create(NodeSchema)` to create a new message.
 */
export const NodeSchema: GenMessage<Node> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 42);

/**
 * Message describing one edge pointing into a node.
 *
 * @generated from message google.cloud.visionai.v1.Node.InputEdge
 */
export type Node_InputEdge = Message<"google.cloud.visionai.v1.Node.InputEdge"> & {
  /**
   * The name of the parent node.
   *
   * @generated from field: string parent_node = 1;
   */
  parentNode: string;

  /**
   * The connected output artifact of the parent node.
   * It can be omitted if target processor only has 1 output artifact.
   *
   * @generated from field: string parent_output_channel = 2;
   */
  parentOutputChannel: string;

  /**
   * The connected input channel of the current node's processor.
   * It can be omitted if target processor only has 1 input channel.
   *
   * @generated from field: string connected_input_channel = 3;
   */
  connectedInputChannel: string;
};

/**
 * Describes the message google.cloud.visionai.v1.Node.InputEdge.
 * Use `create(Node_InputEdgeSchema)` to create a new message.
 */
export const Node_InputEdgeSchema: GenMessage<Node_InputEdge> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 42, 0);

/**
 * Message describing Draft object
 *
 * @generated from message google.cloud.visionai.v1.Draft
 */
export type Draft = Message<"google.cloud.visionai.v1.Draft"> & {
  /**
   * name of resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp update_time = 7;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs
   *
   * @generated from field: map<string, string> labels = 3;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the solution.
   *
   * @generated from field: string display_name = 4;
   */
  displayName: string;

  /**
   * A description for this application.
   *
   * @generated from field: string description = 5;
   */
  description: string;

  /**
   * The draft application configs which haven't been updated to an application.
   *
   * @generated from field: google.cloud.visionai.v1.ApplicationConfigs draft_application_configs = 6;
   */
  draftApplicationConfigs?: ApplicationConfigs;
};

/**
 * Describes the message google.cloud.visionai.v1.Draft.
 * Use `create(DraftSchema)` to create a new message.
 */
export const DraftSchema: GenMessage<Draft> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 43);

/**
 * Message describing Instance object
 * Next ID: 12
 *
 * @generated from message google.cloud.visionai.v1.Instance
 */
export type Instance = Message<"google.cloud.visionai.v1.Instance"> & {
  /**
   * Output only. name of resource
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Update timestamp
   *
   * @generated from field: google.protobuf.Timestamp update_time = 8;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs
   *
   * @generated from field: map<string, string> labels = 3;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the solution.
   *
   * @generated from field: string display_name = 4;
   */
  displayName: string;

  /**
   * A description for this instance.
   *
   * @generated from field: string description = 5;
   */
  description: string;

  /**
   * The instance type for the current instance.
   *
   * @generated from field: google.cloud.visionai.v1.Instance.InstanceType instance_type = 10;
   */
  instanceType: Instance_InstanceType;

  /**
   * The input resources for the current application instance.
   * For example:
   * input_resources:
   * visionai.googleapis.com/v1/projects/123/locations/us-central1/clusters/456/streams/stream-a
   *
   * @generated from field: repeated google.cloud.visionai.v1.Instance.InputResource input_resources = 6;
   */
  inputResources: Instance_InputResource[];

  /**
   * All the output resources associated to one application instance.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Instance.OutputResource output_resources = 7;
   */
  outputResources: Instance_OutputResource[];

  /**
   * State of the instance.
   *
   * @generated from field: google.cloud.visionai.v1.Instance.State state = 9;
   */
  state: Instance_State;
};

/**
 * Describes the message google.cloud.visionai.v1.Instance.
 * Use `create(InstanceSchema)` to create a new message.
 */
export const InstanceSchema: GenMessage<Instance> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 44);

/**
 * Message of input resource used in one application instance.
 *
 * @generated from message google.cloud.visionai.v1.Instance.InputResource
 */
export type Instance_InputResource = Message<"google.cloud.visionai.v1.Instance.InputResource"> & {
  /**
   * Required. Specify the input to the application instance.
   *
   * @generated from oneof google.cloud.visionai.v1.Instance.InputResource.input_resource_information
   */
  inputResourceInformation: {
    /**
     * The direct input resource name.
     * If the instance type is STREAMING_PREDICTION, the input resource is in
     * format of
     * "projects/123/locations/us-central1/clusters/456/streams/stream-a".
     * If the instance type is BATCH_PREDICTION from Cloud Storage input
     * container, the input resource is in format of "gs://bucket-a".
     *
     * @generated from field: string input_resource = 1;
     */
    value: string;
    case: "inputResource";
  } | {
    /**
     * If the input resource is VisionAI Stream, the associated annotations
     * can be specified using annotated_stream instead.
     *
     * @generated from field: google.cloud.visionai.v1.StreamWithAnnotation annotated_stream = 4 [deprecated = true];
     * @deprecated
     */
    value: StreamWithAnnotation;
    case: "annotatedStream";
  } | { case: undefined; value?: undefined };

  /**
   * Data type for the current input resource.
   *
   * @generated from field: google.cloud.visionai.v1.DataType data_type = 6;
   */
  dataType: DataType;

  /**
   * The name of graph node who receives the input resource.
   * For example:
   * input_resource:
   * visionai.googleapis.com/v1/projects/123/locations/us-central1/clusters/456/streams/input-stream-a
   * consumer_node: stream-input
   *
   * @generated from field: string consumer_node = 2;
   */
  consumerNode: string;

  /**
   * The specific input resource binding which will consume the current Input
   * Resource, can be ignored is there is only 1 input binding.
   *
   * @generated from field: string input_resource_binding = 3;
   */
  inputResourceBinding: string;

  /**
   * Contains resource annotations.
   *
   * @generated from field: google.cloud.visionai.v1.ResourceAnnotations annotations = 5;
   */
  annotations?: ResourceAnnotations;
};

/**
 * Describes the message google.cloud.visionai.v1.Instance.InputResource.
 * Use `create(Instance_InputResourceSchema)` to create a new message.
 */
export const Instance_InputResourceSchema: GenMessage<Instance_InputResource> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 44, 0);

/**
 * Message of output resource used in one application instance.
 *
 * @generated from message google.cloud.visionai.v1.Instance.OutputResource
 */
export type Instance_OutputResource = Message<"google.cloud.visionai.v1.Instance.OutputResource"> & {
  /**
   * The output resource name for the current application instance.
   *
   * @generated from field: string output_resource = 1;
   */
  outputResource: string;

  /**
   * The name of graph node who produces the output resource name.
   * For example:
   * output_resource:
   * /projects/123/locations/us-central1/clusters/456/streams/output-application-789-stream-a-occupancy-counting
   * producer_node: occupancy-counting
   *
   * @generated from field: string producer_node = 2;
   */
  producerNode: string;

  /**
   * The specific output resource binding which produces the current
   * OutputResource.
   *
   * @generated from field: string output_resource_binding = 4;
   */
  outputResourceBinding: string;

  /**
   * Output only. Whether the output resource is temporary which means the
   * resource is generated during the deployment of the application. Temporary
   * resource will be deleted during the undeployment of the application.
   *
   * @generated from field: bool is_temporary = 3;
   */
  isTemporary: boolean;

  /**
   * Output only. Whether the output resource is created automatically by the
   * Vision AI App Platform.
   *
   * @generated from field: bool autogen = 5;
   */
  autogen: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.Instance.OutputResource.
 * Use `create(Instance_OutputResourceSchema)` to create a new message.
 */
export const Instance_OutputResourceSchema: GenMessage<Instance_OutputResource> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 44, 1);

/**
 * All the supported instance types.
 *
 * @generated from enum google.cloud.visionai.v1.Instance.InstanceType
 */
export enum Instance_InstanceType {
  /**
   * Unspecified instance type.
   * If the instance type is not specified, the default one is
   * STREAMING_PREDICTION.
   *
   * @generated from enum value: INSTANCE_TYPE_UNSPECIFIED = 0;
   */
  INSTANCE_TYPE_UNSPECIFIED = 0,

  /**
   * Instance type for streaming prediction.
   *
   * @generated from enum value: STREAMING_PREDICTION = 1;
   */
  STREAMING_PREDICTION = 1,

  /**
   * Instance type for batch prediction.
   *
   * @generated from enum value: BATCH_PREDICTION = 2;
   */
  BATCH_PREDICTION = 2,

  /**
   * Instance type for online prediction.
   *
   * @generated from enum value: ONLINE_PREDICTION = 3;
   */
  ONLINE_PREDICTION = 3,
}

/**
 * Describes the enum google.cloud.visionai.v1.Instance.InstanceType.
 */
export const Instance_InstanceTypeSchema: GenEnum<Instance_InstanceType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 44, 0);

/**
 * State of the Instance
 *
 * @generated from enum google.cloud.visionai.v1.Instance.State
 */
export enum Instance_State {
  /**
   * The default value. This value is used if the state is omitted.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * State CREATING.
   *
   * @generated from enum value: CREATING = 1;
   */
  CREATING = 1,

  /**
   * State CREATED.
   *
   * @generated from enum value: CREATED = 2;
   */
  CREATED = 2,

  /**
   * State DEPLOYING.
   *
   * @generated from enum value: DEPLOYING = 3;
   */
  DEPLOYING = 3,

  /**
   * State DEPLOYED.
   *
   * @generated from enum value: DEPLOYED = 4;
   */
  DEPLOYED = 4,

  /**
   * State UNDEPLOYING.
   *
   * @generated from enum value: UNDEPLOYING = 5;
   */
  UNDEPLOYING = 5,

  /**
   * State DELETED.
   *
   * @generated from enum value: DELETED = 6;
   */
  DELETED = 6,

  /**
   * State ERROR.
   *
   * @generated from enum value: ERROR = 7;
   */
  ERROR = 7,

  /**
   * State Updating
   *
   * @generated from enum value: UPDATING = 8;
   */
  UPDATING = 8,

  /**
   * State Deleting.
   *
   * @generated from enum value: DELETING = 9;
   */
  DELETING = 9,

  /**
   * State Fixing.
   *
   * @generated from enum value: FIXING = 10;
   */
  FIXING = 10,

  /**
   * State Finished.
   *
   * @generated from enum value: FINISHED = 11;
   */
  FINISHED = 11,
}

/**
 * Describes the enum google.cloud.visionai.v1.Instance.State.
 */
export const Instance_StateSchema: GenEnum<Instance_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 44, 1);

/**
 * Message for creating a Instance.
 *
 * @generated from message google.cloud.visionai.v1.ApplicationInstance
 */
export type ApplicationInstance = Message<"google.cloud.visionai.v1.ApplicationInstance"> & {
  /**
   * Required. Id of the requesting object.
   *
   * @generated from field: string instance_id = 1;
   */
  instanceId: string;

  /**
   * Required. The resource being created.
   *
   * @generated from field: google.cloud.visionai.v1.Instance instance = 2;
   */
  instance?: Instance;
};

/**
 * Describes the message google.cloud.visionai.v1.ApplicationInstance.
 * Use `create(ApplicationInstanceSchema)` to create a new message.
 */
export const ApplicationInstanceSchema: GenMessage<ApplicationInstance> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 45);

/**
 * Message describing Processor object.
 * Next ID: 19
 *
 * @generated from message google.cloud.visionai.v1.Processor
 */
export type Processor = Message<"google.cloud.visionai.v1.Processor"> & {
  /**
   * name of resource.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. [Output only] Create timestamp.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 2;
   */
  createTime?: Timestamp;

  /**
   * Output only. [Output only] Update timestamp.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  /**
   * Labels as key value pairs.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Required. A user friendly display name for the processor.
   *
   * @generated from field: string display_name = 5;
   */
  displayName: string;

  /**
   * Illustrative sentences for describing the functionality of the processor.
   *
   * @generated from field: string description = 10;
   */
  description: string;

  /**
   * Output only. Processor Type.
   *
   * @generated from field: google.cloud.visionai.v1.Processor.ProcessorType processor_type = 6;
   */
  processorType: Processor_ProcessorType;

  /**
   * Model Type.
   *
   * @generated from field: google.cloud.visionai.v1.ModelType model_type = 13;
   */
  modelType: ModelType;

  /**
   * Source info for customer created processor.
   *
   * @generated from field: google.cloud.visionai.v1.CustomProcessorSourceInfo custom_processor_source_info = 7;
   */
  customProcessorSourceInfo?: CustomProcessorSourceInfo;

  /**
   * Output only. State of the Processor.
   *
   * @generated from field: google.cloud.visionai.v1.Processor.ProcessorState state = 8;
   */
  state: Processor_ProcessorState;

  /**
   * Output only. [Output only] The input / output specifications of a
   * processor, each type of processor has fixed input / output specs which
   * cannot be altered by customer.
   *
   * @generated from field: google.cloud.visionai.v1.ProcessorIOSpec processor_io_spec = 11;
   */
  processorIoSpec?: ProcessorIOSpec;

  /**
   * Output only. The corresponding configuration can be used in the Application
   * to customize the behavior of the processor.
   *
   * @generated from field: string configuration_typeurl = 14;
   */
  configurationTypeurl: string;

  /**
   * @generated from field: repeated google.cloud.visionai.v1.StreamAnnotationType supported_annotation_types = 15;
   */
  supportedAnnotationTypes: StreamAnnotationType[];

  /**
   * Indicates if the processor supports post processing.
   *
   * @generated from field: bool supports_post_processing = 17;
   */
  supportsPostProcessing: boolean;

  /**
   * Which instance types this processor supports; if empty, this default to
   * STREAMING_PREDICTION.
   *
   * @generated from field: repeated google.cloud.visionai.v1.Instance.InstanceType supported_instance_types = 18;
   */
  supportedInstanceTypes: Instance_InstanceType[];
};

/**
 * Describes the message google.cloud.visionai.v1.Processor.
 * Use `create(ProcessorSchema)` to create a new message.
 */
export const ProcessorSchema: GenMessage<Processor> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 46);

/**
 * Type
 *
 * @generated from enum google.cloud.visionai.v1.Processor.ProcessorType
 */
export enum Processor_ProcessorType {
  /**
   * Processor Type UNSPECIFIED.
   *
   * @generated from enum value: PROCESSOR_TYPE_UNSPECIFIED = 0;
   */
  PROCESSOR_TYPE_UNSPECIFIED = 0,

  /**
   * Processor Type PRETRAINED.
   * Pretrained processor is developed by Vision AI App Platform with
   * state-of-the-art vision data processing functionality, like occupancy
   * counting or person blur. Pretrained processor is usually publicly
   * available.
   *
   * @generated from enum value: PRETRAINED = 1;
   */
  PRETRAINED = 1,

  /**
   * Processor Type CUSTOM.
   * Custom processors are specialized processors which are either uploaded by
   * customers or imported from other GCP platform (for example Vertex AI).
   * Custom processor is only visible to the creator.
   *
   * @generated from enum value: CUSTOM = 2;
   */
  CUSTOM = 2,

  /**
   * Processor Type CONNECTOR.
   * Connector processors are special processors which perform I/O for the
   * application, they do not processing the data but either deliver the data
   * to other processors or receive data from other processors.
   *
   * @generated from enum value: CONNECTOR = 3;
   */
  CONNECTOR = 3,
}

/**
 * Describes the enum google.cloud.visionai.v1.Processor.ProcessorType.
 */
export const Processor_ProcessorTypeSchema: GenEnum<Processor_ProcessorType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 46, 0);

/**
 * @generated from enum google.cloud.visionai.v1.Processor.ProcessorState
 */
export enum Processor_ProcessorState {
  /**
   * Unspecified Processor state.
   *
   * @generated from enum value: PROCESSOR_STATE_UNSPECIFIED = 0;
   */
  PROCESSOR_STATE_UNSPECIFIED = 0,

  /**
   * Processor is being created (not ready for use).
   *
   * @generated from enum value: CREATING = 1;
   */
  CREATING = 1,

  /**
   * Processor is and ready for use.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * Processor is being deleted (not ready for use).
   *
   * @generated from enum value: DELETING = 3;
   */
  DELETING = 3,

  /**
   * Processor deleted or creation failed .
   *
   * @generated from enum value: FAILED = 4;
   */
  FAILED = 4,
}

/**
 * Describes the enum google.cloud.visionai.v1.Processor.ProcessorState.
 */
export const Processor_ProcessorStateSchema: GenEnum<Processor_ProcessorState> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 46, 1);

/**
 * Message describing the input / output specifications of a processor.
 *
 * @generated from message google.cloud.visionai.v1.ProcessorIOSpec
 */
export type ProcessorIOSpec = Message<"google.cloud.visionai.v1.ProcessorIOSpec"> & {
  /**
   * For processors with input_channel_specs, the processor must be explicitly
   * connected to another processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ProcessorIOSpec.GraphInputChannelSpec graph_input_channel_specs = 3;
   */
  graphInputChannelSpecs: ProcessorIOSpec_GraphInputChannelSpec[];

  /**
   * The output artifact specifications for the current processor.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ProcessorIOSpec.GraphOutputChannelSpec graph_output_channel_specs = 4;
   */
  graphOutputChannelSpecs: ProcessorIOSpec_GraphOutputChannelSpec[];

  /**
   * The input resource that needs to be fed from the application instance.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceInputBindingSpec instance_resource_input_binding_specs = 5;
   */
  instanceResourceInputBindingSpecs: ProcessorIOSpec_InstanceResourceInputBindingSpec[];

  /**
   * The output resource that the processor will generate per instance.
   * Other than the explicitly listed output bindings here, all the processors'
   * GraphOutputChannels can be binded to stream resource. The bind name then is
   * the same as the GraphOutputChannel's name.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceOutputBindingSpec instance_resource_output_binding_specs = 6;
   */
  instanceResourceOutputBindingSpecs: ProcessorIOSpec_InstanceResourceOutputBindingSpec[];
};

/**
 * Describes the message google.cloud.visionai.v1.ProcessorIOSpec.
 * Use `create(ProcessorIOSpecSchema)` to create a new message.
 */
export const ProcessorIOSpecSchema: GenMessage<ProcessorIOSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 47);

/**
 * Message for input channel specification.
 *
 * @generated from message google.cloud.visionai.v1.ProcessorIOSpec.GraphInputChannelSpec
 */
export type ProcessorIOSpec_GraphInputChannelSpec = Message<"google.cloud.visionai.v1.ProcessorIOSpec.GraphInputChannelSpec"> & {
  /**
   * The name of the current input channel.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The data types of the current input channel.
   * When this field has more than 1 value, it means this input channel can be
   * connected to either of these different data types.
   *
   * @generated from field: google.cloud.visionai.v1.DataType data_type = 2;
   */
  dataType: DataType;

  /**
   * If specified, only those detailed data types can be connected to the
   * processor. For example, jpeg stream for MEDIA, or PredictionResult proto
   * for PROTO type. If unspecified, then any proto is accepted.
   *
   * @generated from field: repeated string accepted_data_type_uris = 5;
   */
  acceptedDataTypeUris: string[];

  /**
   * Whether the current input channel is required by the processor.
   * For example, for a processor with required video input and optional audio
   * input, if video input is missing, the application will be rejected while
   * the audio input can be missing as long as the video input exists.
   *
   * @generated from field: bool required = 3;
   */
  required: boolean;

  /**
   * How many input edges can be connected to this input channel. 0 means
   * unlimited.
   *
   * @generated from field: int64 max_connection_allowed = 4;
   */
  maxConnectionAllowed: bigint;
};

/**
 * Describes the message google.cloud.visionai.v1.ProcessorIOSpec.GraphInputChannelSpec.
 * Use `create(ProcessorIOSpec_GraphInputChannelSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_GraphInputChannelSpecSchema: GenMessage<ProcessorIOSpec_GraphInputChannelSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 47, 0);

/**
 * Message for output channel specification.
 *
 * @generated from message google.cloud.visionai.v1.ProcessorIOSpec.GraphOutputChannelSpec
 */
export type ProcessorIOSpec_GraphOutputChannelSpec = Message<"google.cloud.visionai.v1.ProcessorIOSpec.GraphOutputChannelSpec"> & {
  /**
   * The name of the current output channel.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The data type of the current output channel.
   *
   * @generated from field: google.cloud.visionai.v1.DataType data_type = 2;
   */
  dataType: DataType;

  /**
   * @generated from field: string data_type_uri = 3;
   */
  dataTypeUri: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ProcessorIOSpec.GraphOutputChannelSpec.
 * Use `create(ProcessorIOSpec_GraphOutputChannelSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_GraphOutputChannelSpecSchema: GenMessage<ProcessorIOSpec_GraphOutputChannelSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 47, 1);

/**
 * Message for instance resource channel specification.
 * External resources are virtual nodes which are not expressed in the
 * application graph. Each processor expresses its out-graph spec, so customer
 * is able to override the external source or destinations to the
 *
 * @generated from message google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceInputBindingSpec
 */
export type ProcessorIOSpec_InstanceResourceInputBindingSpec = Message<"google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceInputBindingSpec"> & {
  /**
   * @generated from oneof google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceInputBindingSpec.resource_type
   */
  resourceType: {
    /**
     * The configuration proto that includes the Googleapis resources. I.e.
     * type.googleapis.com/google.cloud.vision.v1.StreamWithAnnotation
     *
     * @generated from field: string config_type_uri = 2;
     */
    value: string;
    case: "configTypeUri";
  } | {
    /**
     * The direct type url of Googleapis resource. i.e.
     * type.googleapis.com/google.cloud.vision.v1.Asset
     *
     * @generated from field: string resource_type_uri = 3;
     */
    value: string;
    case: "resourceTypeUri";
  } | { case: undefined; value?: undefined };

  /**
   * Name of the input binding, unique within the processor.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceInputBindingSpec.
 * Use `create(ProcessorIOSpec_InstanceResourceInputBindingSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_InstanceResourceInputBindingSpecSchema: GenMessage<ProcessorIOSpec_InstanceResourceInputBindingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 47, 2);

/**
 * @generated from message google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceOutputBindingSpec
 */
export type ProcessorIOSpec_InstanceResourceOutputBindingSpec = Message<"google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceOutputBindingSpec"> & {
  /**
   * Name of the output binding, unique within the processor.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The resource type uri of the acceptable output resource.
   *
   * @generated from field: string resource_type_uri = 2;
   */
  resourceTypeUri: string;

  /**
   * Whether the output resource needs to be explicitly set in the instance.
   * If it is false, the processor will automatically generate it if required.
   *
   * @generated from field: bool explicit = 3;
   */
  explicit: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.ProcessorIOSpec.InstanceResourceOutputBindingSpec.
 * Use `create(ProcessorIOSpec_InstanceResourceOutputBindingSpecSchema)` to create a new message.
 */
export const ProcessorIOSpec_InstanceResourceOutputBindingSpecSchema: GenMessage<ProcessorIOSpec_InstanceResourceOutputBindingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 47, 3);

/**
 * Describes the source info for a custom processor.
 *
 * @generated from message google.cloud.visionai.v1.CustomProcessorSourceInfo
 */
export type CustomProcessorSourceInfo = Message<"google.cloud.visionai.v1.CustomProcessorSourceInfo"> & {
  /**
   * The path where App Platform loads the artifacts for the custom processor.
   *
   * @generated from oneof google.cloud.visionai.v1.CustomProcessorSourceInfo.artifact_path
   */
  artifactPath: {
    /**
     * The resource name original model hosted in the vertex AI platform.
     *
     * @generated from field: string vertex_model = 2;
     */
    value: string;
    case: "vertexModel";
  } | {
    /**
     * Artifact for product recognizer.
     *
     * @generated from field: google.cloud.visionai.v1.CustomProcessorSourceInfo.ProductRecognizerArtifact product_recognizer_artifact = 3;
     */
    value: CustomProcessorSourceInfo_ProductRecognizerArtifact;
    case: "productRecognizerArtifact";
  } | { case: undefined; value?: undefined };

  /**
   * The original product which holds the custom processor's functionality.
   *
   * @generated from field: google.cloud.visionai.v1.CustomProcessorSourceInfo.SourceType source_type = 1;
   */
  sourceType: CustomProcessorSourceInfo_SourceType;

  /**
   * Output only. Additional info related to the imported custom processor.
   * Data is filled in by app platform during the processor creation.
   *
   * @generated from field: map<string, string> additional_info = 4;
   */
  additionalInfo: { [key: string]: string };

  /**
   * Model schema files which specifies the signature of the model.
   * For VERTEX_CUSTOM models, instances schema is required.
   * If instances schema is not specified during the processor creation,
   * VisionAI Platform will try to get it from Vertex, if it doesn't exist, the
   * creation will fail.
   *
   * @generated from field: google.cloud.visionai.v1.CustomProcessorSourceInfo.ModelSchema model_schema = 5;
   */
  modelSchema?: CustomProcessorSourceInfo_ModelSchema;
};

/**
 * Describes the message google.cloud.visionai.v1.CustomProcessorSourceInfo.
 * Use `create(CustomProcessorSourceInfoSchema)` to create a new message.
 */
export const CustomProcessorSourceInfoSchema: GenMessage<CustomProcessorSourceInfo> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 48);

/**
 * Message describes product recognizer artifact.
 *
 * @generated from message google.cloud.visionai.v1.CustomProcessorSourceInfo.ProductRecognizerArtifact
 */
export type CustomProcessorSourceInfo_ProductRecognizerArtifact = Message<"google.cloud.visionai.v1.CustomProcessorSourceInfo.ProductRecognizerArtifact"> & {
  /**
   * Required. Resource name of RetailProductRecognitionIndex.
   * Format is
   * 'projects/*\/locations/*\/retailCatalogs/*\/retailProductRecognitionIndexes/*'
   *
   * @generated from field: string retail_product_recognition_index = 1;
   */
  retailProductRecognitionIndex: string;

  /**
   * Optional. The resource name of embedding model hosted in Vertex AI
   * Platform.
   *
   * @generated from field: string vertex_model = 2;
   */
  vertexModel: string;
};

/**
 * Describes the message google.cloud.visionai.v1.CustomProcessorSourceInfo.ProductRecognizerArtifact.
 * Use `create(CustomProcessorSourceInfo_ProductRecognizerArtifactSchema)` to create a new message.
 */
export const CustomProcessorSourceInfo_ProductRecognizerArtifactSchema: GenMessage<CustomProcessorSourceInfo_ProductRecognizerArtifact> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 48, 0);

/**
 * The schema is defined as an OpenAPI 3.0.2 [Schema
 * Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
 *
 * @generated from message google.cloud.visionai.v1.CustomProcessorSourceInfo.ModelSchema
 */
export type CustomProcessorSourceInfo_ModelSchema = Message<"google.cloud.visionai.v1.CustomProcessorSourceInfo.ModelSchema"> & {
  /**
   * Cloud Storage location to a YAML file that defines the format of a single
   * instance used in prediction and explanation requests.
   *
   * @generated from field: google.cloud.visionai.v1.GcsSource instances_schema = 1;
   */
  instancesSchema?: GcsSource;

  /**
   * Cloud Storage location to a YAML file that defines the prediction and
   * explanation parameters.
   *
   * @generated from field: google.cloud.visionai.v1.GcsSource parameters_schema = 2;
   */
  parametersSchema?: GcsSource;

  /**
   * Cloud Storage location to a YAML file that defines the format of a single
   * prediction or explanation.
   *
   * @generated from field: google.cloud.visionai.v1.GcsSource predictions_schema = 3;
   */
  predictionsSchema?: GcsSource;
};

/**
 * Describes the message google.cloud.visionai.v1.CustomProcessorSourceInfo.ModelSchema.
 * Use `create(CustomProcessorSourceInfo_ModelSchemaSchema)` to create a new message.
 */
export const CustomProcessorSourceInfo_ModelSchemaSchema: GenMessage<CustomProcessorSourceInfo_ModelSchema> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 48, 1);

/**
 * Source type of the imported custom processor.
 *
 * @generated from enum google.cloud.visionai.v1.CustomProcessorSourceInfo.SourceType
 */
export enum CustomProcessorSourceInfo_SourceType {
  /**
   * Source type unspecified.
   *
   * @generated from enum value: SOURCE_TYPE_UNSPECIFIED = 0;
   */
  SOURCE_TYPE_UNSPECIFIED = 0,

  /**
   * Custom processors coming from Vertex AutoML product.
   *
   * @generated from enum value: VERTEX_AUTOML = 1;
   */
  VERTEX_AUTOML = 1,

  /**
   * Custom processors coming from general custom models from Vertex.
   *
   * @generated from enum value: VERTEX_CUSTOM = 2;
   */
  VERTEX_CUSTOM = 2,

  /**
   * Source for Product Recognizer.
   *
   * @generated from enum value: PRODUCT_RECOGNIZER = 3;
   */
  PRODUCT_RECOGNIZER = 3,
}

/**
 * Describes the enum google.cloud.visionai.v1.CustomProcessorSourceInfo.SourceType.
 */
export const CustomProcessorSourceInfo_SourceTypeSchema: GenEnum<CustomProcessorSourceInfo_SourceType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 48, 0);

/**
 * Next ID: 35
 *
 * @generated from message google.cloud.visionai.v1.ProcessorConfig
 */
export type ProcessorConfig = Message<"google.cloud.visionai.v1.ProcessorConfig"> & {
  /**
   * @generated from oneof google.cloud.visionai.v1.ProcessorConfig.processor_config
   */
  processorConfig: {
    /**
     * Configs of stream input processor.
     *
     * @generated from field: google.cloud.visionai.v1.VideoStreamInputConfig video_stream_input_config = 9;
     */
    value: VideoStreamInputConfig;
    case: "videoStreamInputConfig";
  } | {
    /**
     * Config of AI-enabled input devices.
     *
     * @generated from field: google.cloud.visionai.v1.AIEnabledDevicesInputConfig ai_enabled_devices_input_config = 20;
     */
    value: AIEnabledDevicesInputConfig;
    case: "aiEnabledDevicesInputConfig";
  } | {
    /**
     * Configs of media warehouse processor.
     *
     * @generated from field: google.cloud.visionai.v1.MediaWarehouseConfig media_warehouse_config = 10;
     */
    value: MediaWarehouseConfig;
    case: "mediaWarehouseConfig";
  } | {
    /**
     * Configs of person blur processor.
     *
     * @generated from field: google.cloud.visionai.v1.PersonBlurConfig person_blur_config = 11;
     */
    value: PersonBlurConfig;
    case: "personBlurConfig";
  } | {
    /**
     * Configs of occupancy count processor.
     *
     * @generated from field: google.cloud.visionai.v1.OccupancyCountConfig occupancy_count_config = 12;
     */
    value: OccupancyCountConfig;
    case: "occupancyCountConfig";
  } | {
    /**
     * Configs of Person Vehicle Detection processor.
     *
     * @generated from field: google.cloud.visionai.v1.PersonVehicleDetectionConfig person_vehicle_detection_config = 15;
     */
    value: PersonVehicleDetectionConfig;
    case: "personVehicleDetectionConfig";
  } | {
    /**
     * Configs of Vertex AutoML vision processor.
     *
     * @generated from field: google.cloud.visionai.v1.VertexAutoMLVisionConfig vertex_automl_vision_config = 13;
     */
    value: VertexAutoMLVisionConfig;
    case: "vertexAutomlVisionConfig";
  } | {
    /**
     * Configs of Vertex AutoML video processor.
     *
     * @generated from field: google.cloud.visionai.v1.VertexAutoMLVideoConfig vertex_automl_video_config = 14;
     */
    value: VertexAutoMLVideoConfig;
    case: "vertexAutomlVideoConfig";
  } | {
    /**
     * Configs of Vertex Custom processor.
     *
     * @generated from field: google.cloud.visionai.v1.VertexCustomConfig vertex_custom_config = 17;
     */
    value: VertexCustomConfig;
    case: "vertexCustomConfig";
  } | {
    /**
     * Configs of General Object Detection processor.
     *
     * @generated from field: google.cloud.visionai.v1.GeneralObjectDetectionConfig general_object_detection_config = 18;
     */
    value: GeneralObjectDetectionConfig;
    case: "generalObjectDetectionConfig";
  } | {
    /**
     * Configs of BigQuery processor.
     *
     * @generated from field: google.cloud.visionai.v1.BigQueryConfig big_query_config = 19;
     */
    value: BigQueryConfig;
    case: "bigQueryConfig";
  } | {
    /**
     * Configs of Cloud Storage output processor.
     *
     * @generated from field: google.cloud.visionai.v1.GcsOutputConfig gcs_output_config = 27;
     */
    value: GcsOutputConfig;
    case: "gcsOutputConfig";
  } | {
    /**
     * Runtime configs of Product Recognizer processor.
     *
     * @generated from field: google.cloud.visionai.v1.ProductRecognizerConfig product_recognizer_config = 21;
     */
    value: ProductRecognizerConfig;
    case: "productRecognizerConfig";
  } | {
    /**
     * Configs of personal_protective_equipment_detection_config
     *
     * @generated from field: google.cloud.visionai.v1.PersonalProtectiveEquipmentDetectionConfig personal_protective_equipment_detection_config = 22;
     */
    value: PersonalProtectiveEquipmentDetectionConfig;
    case: "personalProtectiveEquipmentDetectionConfig";
  } | {
    /**
     * Runtime configs of Tag Recognizer processor.
     *
     * @generated from field: google.cloud.visionai.v1.TagRecognizerConfig tag_recognizer_config = 25;
     */
    value: TagRecognizerConfig;
    case: "tagRecognizerConfig";
  } | {
    /**
     * Runtime configs of UniversalInput processor.
     *
     * @generated from field: google.cloud.visionai.v1.UniversalInputConfig universal_input_config = 28;
     */
    value: UniversalInputConfig;
    case: "universalInputConfig";
  } | { case: undefined; value?: undefined };

  /**
   * Experimental configurations. Structured object containing not-yet-stable
   * processor parameters.
   *
   * @generated from field: google.protobuf.Struct experimental_config = 26;
   */
  experimentalConfig?: JsonObject;
};

/**
 * Describes the message google.cloud.visionai.v1.ProcessorConfig.
 * Use `create(ProcessorConfigSchema)` to create a new message.
 */
export const ProcessorConfigSchema: GenMessage<ProcessorConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 49);

/**
 * Message describing Vision AI stream with application specific annotations.
 * All the StreamAnnotation object inside this message MUST have unique id.
 *
 * @generated from message google.cloud.visionai.v1.StreamWithAnnotation
 */
export type StreamWithAnnotation = Message<"google.cloud.visionai.v1.StreamWithAnnotation"> & {
  /**
   * Vision AI Stream resource name.
   *
   * @generated from field: string stream = 1;
   */
  stream: string;

  /**
   * Annotations that will be applied to the whole application.
   *
   * @generated from field: repeated google.cloud.visionai.v1.StreamAnnotation application_annotations = 2;
   */
  applicationAnnotations: StreamAnnotation[];

  /**
   * Annotations that will be applied to the specific node of the application.
   * If the same type of the annotations is applied to both application and
   * node, the node annotation will be added in addition to the global
   * application one.
   * For example, if there is one active zone annotation for the whole
   * application and one active zone annotation for the Occupancy Analytic
   * processor, then the Occupancy Analytic processor will have two active zones
   * defined.
   *
   * @generated from field: repeated google.cloud.visionai.v1.StreamWithAnnotation.NodeAnnotation node_annotations = 3;
   */
  nodeAnnotations: StreamWithAnnotation_NodeAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1.StreamWithAnnotation.
 * Use `create(StreamWithAnnotationSchema)` to create a new message.
 */
export const StreamWithAnnotationSchema: GenMessage<StreamWithAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 50);

/**
 * Message describing annotations specific to application node.
 *
 * @generated from message google.cloud.visionai.v1.StreamWithAnnotation.NodeAnnotation
 */
export type StreamWithAnnotation_NodeAnnotation = Message<"google.cloud.visionai.v1.StreamWithAnnotation.NodeAnnotation"> & {
  /**
   * The node name of the application graph.
   *
   * @generated from field: string node = 1;
   */
  node: string;

  /**
   * The node specific stream annotations.
   *
   * @generated from field: repeated google.cloud.visionai.v1.StreamAnnotation annotations = 2;
   */
  annotations: StreamAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1.StreamWithAnnotation.NodeAnnotation.
 * Use `create(StreamWithAnnotation_NodeAnnotationSchema)` to create a new message.
 */
export const StreamWithAnnotation_NodeAnnotationSchema: GenMessage<StreamWithAnnotation_NodeAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 50, 0);

/**
 * Message describing annotations specific to application node.
 * This message is a duplication of StreamWithAnnotation.NodeAnnotation.
 *
 * @generated from message google.cloud.visionai.v1.ApplicationNodeAnnotation
 */
export type ApplicationNodeAnnotation = Message<"google.cloud.visionai.v1.ApplicationNodeAnnotation"> & {
  /**
   * The node name of the application graph.
   *
   * @generated from field: string node = 1;
   */
  node: string;

  /**
   * The node specific stream annotations.
   *
   * @generated from field: repeated google.cloud.visionai.v1.StreamAnnotation annotations = 2;
   */
  annotations: StreamAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1.ApplicationNodeAnnotation.
 * Use `create(ApplicationNodeAnnotationSchema)` to create a new message.
 */
export const ApplicationNodeAnnotationSchema: GenMessage<ApplicationNodeAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 51);

/**
 * Message describing general annotation for resources.
 *
 * @generated from message google.cloud.visionai.v1.ResourceAnnotations
 */
export type ResourceAnnotations = Message<"google.cloud.visionai.v1.ResourceAnnotations"> & {
  /**
   * Annotations that will be applied to the whole application.
   *
   * @generated from field: repeated google.cloud.visionai.v1.StreamAnnotation application_annotations = 1;
   */
  applicationAnnotations: StreamAnnotation[];

  /**
   * Annotations that will be applied to the specific node of the application.
   * If the same type of the annotations is applied to both application and
   * node, the node annotation will be added in addition to the global
   * application one.
   * For example, if there is one active zone annotation for the whole
   * application and one active zone annotation for the Occupancy Analytic
   * processor, then the Occupancy Analytic processor will have two active zones
   * defined.
   *
   * @generated from field: repeated google.cloud.visionai.v1.ApplicationNodeAnnotation node_annotations = 2;
   */
  nodeAnnotations: ApplicationNodeAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1.ResourceAnnotations.
 * Use `create(ResourceAnnotationsSchema)` to create a new message.
 */
export const ResourceAnnotationsSchema: GenMessage<ResourceAnnotations> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 52);

/**
 * Message describing Video Stream Input Config.
 * This message should only be used as a placeholder for builtin:stream-input
 * processor, actual stream binding should be specified using corresponding
 * API.
 *
 * @generated from message google.cloud.visionai.v1.VideoStreamInputConfig
 */
export type VideoStreamInputConfig = Message<"google.cloud.visionai.v1.VideoStreamInputConfig"> & {
  /**
   * @generated from field: repeated string streams = 1 [deprecated = true];
   * @deprecated
   */
  streams: string[];

  /**
   * @generated from field: repeated google.cloud.visionai.v1.StreamWithAnnotation streams_with_annotation = 2 [deprecated = true];
   * @deprecated
   */
  streamsWithAnnotation: StreamWithAnnotation[];
};

/**
 * Describes the message google.cloud.visionai.v1.VideoStreamInputConfig.
 * Use `create(VideoStreamInputConfigSchema)` to create a new message.
 */
export const VideoStreamInputConfigSchema: GenMessage<VideoStreamInputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 53);

/**
 * Message describing AI-enabled Devices Input Config.
 *
 * @generated from message google.cloud.visionai.v1.AIEnabledDevicesInputConfig
 */
export type AIEnabledDevicesInputConfig = Message<"google.cloud.visionai.v1.AIEnabledDevicesInputConfig"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.AIEnabledDevicesInputConfig.
 * Use `create(AIEnabledDevicesInputConfigSchema)` to create a new message.
 */
export const AIEnabledDevicesInputConfigSchema: GenMessage<AIEnabledDevicesInputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 54);

/**
 * Message describing MediaWarehouseConfig.
 *
 * @generated from message google.cloud.visionai.v1.MediaWarehouseConfig
 */
export type MediaWarehouseConfig = Message<"google.cloud.visionai.v1.MediaWarehouseConfig"> & {
  /**
   * Resource name of the Media Warehouse corpus.
   * Format:
   * projects/${project_id}/locations/${location_id}/corpora/${corpus_id}
   *
   * @generated from field: string corpus = 1;
   */
  corpus: string;

  /**
   * Deprecated.
   *
   * @generated from field: string region = 2 [deprecated = true];
   * @deprecated
   */
  region: string;

  /**
   * The duration for which all media assets, associated metadata, and search
   * documents can exist.
   *
   * @generated from field: google.protobuf.Duration ttl = 3;
   */
  ttl?: Duration;
};

/**
 * Describes the message google.cloud.visionai.v1.MediaWarehouseConfig.
 * Use `create(MediaWarehouseConfigSchema)` to create a new message.
 */
export const MediaWarehouseConfigSchema: GenMessage<MediaWarehouseConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 55);

/**
 * Message describing FaceBlurConfig.
 *
 * @generated from message google.cloud.visionai.v1.PersonBlurConfig
 */
export type PersonBlurConfig = Message<"google.cloud.visionai.v1.PersonBlurConfig"> & {
  /**
   * Person blur type.
   *
   * @generated from field: google.cloud.visionai.v1.PersonBlurConfig.PersonBlurType person_blur_type = 1;
   */
  personBlurType: PersonBlurConfig_PersonBlurType;

  /**
   * Whether only blur faces other than the whole object in the processor.
   *
   * @generated from field: bool faces_only = 2;
   */
  facesOnly: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.PersonBlurConfig.
 * Use `create(PersonBlurConfigSchema)` to create a new message.
 */
export const PersonBlurConfigSchema: GenMessage<PersonBlurConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 56);

/**
 * Type of Person Blur
 *
 * @generated from enum google.cloud.visionai.v1.PersonBlurConfig.PersonBlurType
 */
export enum PersonBlurConfig_PersonBlurType {
  /**
   * PersonBlur Type UNSPECIFIED.
   *
   * @generated from enum value: PERSON_BLUR_TYPE_UNSPECIFIED = 0;
   */
  PERSON_BLUR_TYPE_UNSPECIFIED = 0,

  /**
   * FaceBlur Type full occlusion.
   *
   * @generated from enum value: FULL_OCCULUSION = 1;
   */
  FULL_OCCULUSION = 1,

  /**
   * FaceBlur Type blur filter.
   *
   * @generated from enum value: BLUR_FILTER = 2;
   */
  BLUR_FILTER = 2,
}

/**
 * Describes the enum google.cloud.visionai.v1.PersonBlurConfig.PersonBlurType.
 */
export const PersonBlurConfig_PersonBlurTypeSchema: GenEnum<PersonBlurConfig_PersonBlurType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 56, 0);

/**
 * Message describing OccupancyCountConfig.
 *
 * @generated from message google.cloud.visionai.v1.OccupancyCountConfig
 */
export type OccupancyCountConfig = Message<"google.cloud.visionai.v1.OccupancyCountConfig"> & {
  /**
   * Whether to count the appearances of people, output counts have 'people' as
   * the key.
   *
   * @generated from field: bool enable_people_counting = 1;
   */
  enablePeopleCounting: boolean;

  /**
   * Whether to count the appearances of vehicles, output counts will have
   * 'vehicle' as the key.
   *
   * @generated from field: bool enable_vehicle_counting = 2;
   */
  enableVehicleCounting: boolean;

  /**
   * Whether to track each invidual object's loitering time inside the scene or
   * specific zone.
   *
   * @generated from field: bool enable_dwelling_time_tracking = 3;
   */
  enableDwellingTimeTracking: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.OccupancyCountConfig.
 * Use `create(OccupancyCountConfigSchema)` to create a new message.
 */
export const OccupancyCountConfigSchema: GenMessage<OccupancyCountConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 57);

/**
 * Message describing PersonVehicleDetectionConfig.
 *
 * @generated from message google.cloud.visionai.v1.PersonVehicleDetectionConfig
 */
export type PersonVehicleDetectionConfig = Message<"google.cloud.visionai.v1.PersonVehicleDetectionConfig"> & {
  /**
   * At least one of enable_people_counting and enable_vehicle_counting fields
   * must be set to true.
   * Whether to count the appearances of people, output counts have 'people' as
   * the key.
   *
   * @generated from field: bool enable_people_counting = 1;
   */
  enablePeopleCounting: boolean;

  /**
   * Whether to count the appearances of vehicles, output counts will have
   * 'vehicle' as the key.
   *
   * @generated from field: bool enable_vehicle_counting = 2;
   */
  enableVehicleCounting: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.PersonVehicleDetectionConfig.
 * Use `create(PersonVehicleDetectionConfigSchema)` to create a new message.
 */
export const PersonVehicleDetectionConfigSchema: GenMessage<PersonVehicleDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 58);

/**
 * Message describing PersonalProtectiveEquipmentDetectionConfig.
 *
 * @generated from message google.cloud.visionai.v1.PersonalProtectiveEquipmentDetectionConfig
 */
export type PersonalProtectiveEquipmentDetectionConfig = Message<"google.cloud.visionai.v1.PersonalProtectiveEquipmentDetectionConfig"> & {
  /**
   * Whether to enable face coverage detection.
   *
   * @generated from field: bool enable_face_coverage_detection = 1;
   */
  enableFaceCoverageDetection: boolean;

  /**
   * Whether to enable head coverage detection.
   *
   * @generated from field: bool enable_head_coverage_detection = 2;
   */
  enableHeadCoverageDetection: boolean;

  /**
   * Whether to enable hands coverage detection.
   *
   * @generated from field: bool enable_hands_coverage_detection = 3;
   */
  enableHandsCoverageDetection: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.PersonalProtectiveEquipmentDetectionConfig.
 * Use `create(PersonalProtectiveEquipmentDetectionConfigSchema)` to create a new message.
 */
export const PersonalProtectiveEquipmentDetectionConfigSchema: GenMessage<PersonalProtectiveEquipmentDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 59);

/**
 * Message of configurations for General Object Detection processor.
 *
 * @generated from message google.cloud.visionai.v1.GeneralObjectDetectionConfig
 */
export type GeneralObjectDetectionConfig = Message<"google.cloud.visionai.v1.GeneralObjectDetectionConfig"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.GeneralObjectDetectionConfig.
 * Use `create(GeneralObjectDetectionConfigSchema)` to create a new message.
 */
export const GeneralObjectDetectionConfigSchema: GenMessage<GeneralObjectDetectionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 60);

/**
 * Message of configurations for BigQuery processor.
 *
 * @generated from message google.cloud.visionai.v1.BigQueryConfig
 */
export type BigQueryConfig = Message<"google.cloud.visionai.v1.BigQueryConfig"> & {
  /**
   * BigQuery table resource for Vision AI Platform to ingest annotations to.
   *
   * @generated from field: string table = 1;
   */
  table: string;

  /**
   * Data Schema
   * By default, Vision AI Application will try to write annotations to the
   * target BigQuery table using the following schema:
   *
   * ingestion_time: TIMESTAMP, the ingestion time of the original data.
   *
   * application: STRING, name of the application which produces the annotation.
   *
   * instance: STRING, Id of the instance which produces the annotation.
   *
   * node: STRING, name of the application graph node which produces the
   * annotation.
   *
   * annotation: STRING or JSON, the actual annotation protobuf will be
   * converted to json string with bytes field as 64 encoded string. It can be
   * written to both String or Json type column.
   *
   * To forward annotation data to an existing BigQuery table, customer needs to
   * make sure the compatibility of the schema.
   * The map maps application node name to its corresponding cloud function
   * endpoint to transform the annotations directly to the
   * google.cloud.bigquery.storage.v1.AppendRowsRequest (only avro_rows or
   * proto_rows should be set). If configured, annotations produced by
   * corresponding application node will sent to the Cloud Function at first
   * before be forwarded to BigQuery.
   *
   * If the default table schema doesn't fit, customer is able to transform the
   * annotation output from Vision AI Application to arbitrary BigQuery table
   * schema with CloudFunction.
   * * The cloud function will receive AppPlatformCloudFunctionRequest where
   * the annotations field will be the json format of Vision AI annotation.
   * * The cloud function should return AppPlatformCloudFunctionResponse with
   * AppendRowsRequest stored in the annotations field.
   * * To drop the annotation, simply clear the annotations field in the
   * returned AppPlatformCloudFunctionResponse.
   *
   * @generated from field: map<string, string> cloud_function_mapping = 2;
   */
  cloudFunctionMapping: { [key: string]: string };

  /**
   * If true, App Platform will create the BigQuery DataSet and the
   * BigQuery Table with default schema if the specified table doesn't exist.
   * This doesn't work if any cloud function customized schema is specified
   * since the system doesn't know your desired schema.
   * JSON column will be used in the default table created by App Platform.
   *
   * @generated from field: bool create_default_table_if_not_exists = 3;
   */
  createDefaultTableIfNotExists: boolean;
};

/**
 * Describes the message google.cloud.visionai.v1.BigQueryConfig.
 * Use `create(BigQueryConfigSchema)` to create a new message.
 */
export const BigQueryConfigSchema: GenMessage<BigQueryConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 61);

/**
 * Message of configurations of Vertex AutoML Vision Processors.
 *
 * @generated from message google.cloud.visionai.v1.VertexAutoMLVisionConfig
 */
export type VertexAutoMLVisionConfig = Message<"google.cloud.visionai.v1.VertexAutoMLVisionConfig"> & {
  /**
   * Only entities with higher score than the threshold will be returned.
   * Value 0.0 means to return all the detected entities.
   *
   * @generated from field: float confidence_threshold = 1;
   */
  confidenceThreshold: number;

  /**
   * At most this many predictions will be returned per output frame.
   * Value 0 means to return all the detected entities.
   *
   * @generated from field: int32 max_predictions = 2;
   */
  maxPredictions: number;
};

/**
 * Describes the message google.cloud.visionai.v1.VertexAutoMLVisionConfig.
 * Use `create(VertexAutoMLVisionConfigSchema)` to create a new message.
 */
export const VertexAutoMLVisionConfigSchema: GenMessage<VertexAutoMLVisionConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 62);

/**
 * Message describing VertexAutoMLVideoConfig.
 *
 * @generated from message google.cloud.visionai.v1.VertexAutoMLVideoConfig
 */
export type VertexAutoMLVideoConfig = Message<"google.cloud.visionai.v1.VertexAutoMLVideoConfig"> & {
  /**
   * Only entities with higher score than the threshold will be returned.
   * Value 0.0 means returns all the detected entities.
   *
   * @generated from field: float confidence_threshold = 1;
   */
  confidenceThreshold: number;

  /**
   * Labels specified in this field won't be returned.
   *
   * @generated from field: repeated string blocked_labels = 2;
   */
  blockedLabels: string[];

  /**
   * At most this many predictions will be returned per output frame.
   * Value 0 means to return all the detected entities.
   *
   * @generated from field: int32 max_predictions = 3;
   */
  maxPredictions: number;

  /**
   * Only Bounding Box whose size is larger than this limit will be returned.
   * Object Tracking only.
   * Value 0.0 means to return all the detected entities.
   *
   * @generated from field: float bounding_box_size_limit = 4;
   */
  boundingBoxSizeLimit: number;
};

/**
 * Describes the message google.cloud.visionai.v1.VertexAutoMLVideoConfig.
 * Use `create(VertexAutoMLVideoConfigSchema)` to create a new message.
 */
export const VertexAutoMLVideoConfigSchema: GenMessage<VertexAutoMLVideoConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 63);

/**
 * Message describing VertexCustomConfig.
 *
 * @generated from message google.cloud.visionai.v1.VertexCustomConfig
 */
export type VertexCustomConfig = Message<"google.cloud.visionai.v1.VertexCustomConfig"> & {
  /**
   * The max prediction frame per second. This attribute sets how fast the
   * operator sends prediction requests to Vertex AI endpoint. Default value is
   * 0, which means there is no max prediction fps limit. The operator sends
   * prediction requests at input fps.
   *
   * @generated from field: int32 max_prediction_fps = 1;
   */
  maxPredictionFps: number;

  /**
   * A description of resources that are dedicated to the DeployedModel, and
   * that need a higher degree of manual configuration.
   *
   * @generated from field: google.cloud.visionai.v1.DedicatedResources dedicated_resources = 2;
   */
  dedicatedResources?: DedicatedResources;

  /**
   * If not empty, the prediction result will be sent to the specified cloud
   * function for post processing.
   * * The cloud function will receive AppPlatformCloudFunctionRequest where
   * the annotations field will be the json format of proto PredictResponse.
   * * The cloud function should return AppPlatformCloudFunctionResponse with
   * PredictResponse stored in the annotations field.
   * * To drop the prediction output, simply clear the payload field in the
   * returned AppPlatformCloudFunctionResponse.
   *
   * @generated from field: string post_processing_cloud_function = 3;
   */
  postProcessingCloudFunction: string;

  /**
   * If true, the prediction request received by custom model will also contain
   * metadata with the following schema:
   * 'appPlatformMetadata': {
   *       'ingestionTime': DOUBLE; (UNIX timestamp)
   *       'application': STRING;
   *       'instanceId': STRING;
   *       'node': STRING;
   *       'processor': STRING;
   *  }
   *
   * @generated from field: bool attach_application_metadata = 4;
   */
  attachApplicationMetadata: boolean;

  /**
   * Optional. By setting the configuration_input_topic, processor will
   * subscribe to given topic, only pub/sub topic is supported now. Example
   * channel:
   * //pubsub.googleapis.com/projects/visionai-testing-stable/topics/test-topic
   * message schema should be:
   * message Message {
   * // The ID of the stream that associates with the application instance.
   * string stream_id = 1;
   * // The target fps. By default, the custom processor will *not* send any
   * data to the Vertex Prediction container. Note that once the
   * dynamic_config_input_topic is set, max_prediction_fps will not work and be
   * preceded by the fps set inside the topic.
   * int32 fps = 2;
   * }
   *
   * @generated from field: optional string dynamic_config_input_topic = 6;
   */
  dynamicConfigInputTopic?: string;
};

/**
 * Describes the message google.cloud.visionai.v1.VertexCustomConfig.
 * Use `create(VertexCustomConfigSchema)` to create a new message.
 */
export const VertexCustomConfigSchema: GenMessage<VertexCustomConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 64);

/**
 * Message describing GcsOutputConfig.
 *
 * @generated from message google.cloud.visionai.v1.GcsOutputConfig
 */
export type GcsOutputConfig = Message<"google.cloud.visionai.v1.GcsOutputConfig"> & {
  /**
   * The Cloud Storage path for Vision AI Platform to ingest annotations to.
   *
   * @generated from field: string gcs_path = 1;
   */
  gcsPath: string;
};

/**
 * Describes the message google.cloud.visionai.v1.GcsOutputConfig.
 * Use `create(GcsOutputConfigSchema)` to create a new message.
 */
export const GcsOutputConfigSchema: GenMessage<GcsOutputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 65);

/**
 * Message describing UniversalInputConfig.
 *
 * @generated from message google.cloud.visionai.v1.UniversalInputConfig
 */
export type UniversalInputConfig = Message<"google.cloud.visionai.v1.UniversalInputConfig"> & {
};

/**
 * Describes the message google.cloud.visionai.v1.UniversalInputConfig.
 * Use `create(UniversalInputConfigSchema)` to create a new message.
 */
export const UniversalInputConfigSchema: GenMessage<UniversalInputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 66);

/**
 * Specification of a single machine.
 *
 * @generated from message google.cloud.visionai.v1.MachineSpec
 */
export type MachineSpec = Message<"google.cloud.visionai.v1.MachineSpec"> & {
  /**
   * Immutable. The type of the machine.
   *
   * See the [list of machine types supported for
   * prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
   *
   * See the [list of machine types supported for custom
   * training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
   *
   * For [DeployedModel][] this field is optional, and the default
   * value is `n1-standard-2`. For [BatchPredictionJob][] or as part of
   * [WorkerPoolSpec][] this field is required.
   *
   * @generated from field: string machine_type = 1;
   */
  machineType: string;

  /**
   * Immutable. The type of accelerator(s) that may be attached to the machine
   * as per
   * [accelerator_count][google.cloud.visionai.v1.MachineSpec.accelerator_count].
   *
   * @generated from field: google.cloud.visionai.v1.AcceleratorType accelerator_type = 2;
   */
  acceleratorType: AcceleratorType;

  /**
   * The number of accelerators to attach to the machine.
   *
   * @generated from field: int32 accelerator_count = 3;
   */
  acceleratorCount: number;
};

/**
 * Describes the message google.cloud.visionai.v1.MachineSpec.
 * Use `create(MachineSpecSchema)` to create a new message.
 */
export const MachineSpecSchema: GenMessage<MachineSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 67);

/**
 * The metric specification that defines the target resource utilization
 * (CPU utilization, accelerator's duty cycle, and so on) for calculating the
 * desired replica count.
 *
 * @generated from message google.cloud.visionai.v1.AutoscalingMetricSpec
 */
export type AutoscalingMetricSpec = Message<"google.cloud.visionai.v1.AutoscalingMetricSpec"> & {
  /**
   * Required. The resource metric name.
   * Supported metrics:
   *
   * * For Online Prediction:
   * * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle`
   * * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
   *
   * @generated from field: string metric_name = 1;
   */
  metricName: string;

  /**
   * The target resource utilization in percentage (1% - 100%) for the given
   * metric; once the real usage deviates from the target by a certain
   * percentage, the machine replicas change. The default value is 60
   * (representing 60%) if not provided.
   *
   * @generated from field: int32 target = 2;
   */
  target: number;
};

/**
 * Describes the message google.cloud.visionai.v1.AutoscalingMetricSpec.
 * Use `create(AutoscalingMetricSpecSchema)` to create a new message.
 */
export const AutoscalingMetricSpecSchema: GenMessage<AutoscalingMetricSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 68);

/**
 * A description of resources that are dedicated to a DeployedModel, and
 * that need a higher degree of manual configuration.
 *
 * @generated from message google.cloud.visionai.v1.DedicatedResources
 */
export type DedicatedResources = Message<"google.cloud.visionai.v1.DedicatedResources"> & {
  /**
   * Required. Immutable. The specification of a single machine used by the
   * prediction.
   *
   * @generated from field: google.cloud.visionai.v1.MachineSpec machine_spec = 1;
   */
  machineSpec?: MachineSpec;

  /**
   * Required. Immutable. The minimum number of machine replicas this
   * DeployedModel will be always deployed on. This value must be greater than
   * or equal to 1.
   *
   * If traffic against the DeployedModel increases, it may dynamically be
   * deployed onto more replicas, and as traffic decreases, some of these extra
   * replicas may be freed.
   *
   * @generated from field: int32 min_replica_count = 2;
   */
  minReplicaCount: number;

  /**
   * Immutable. The maximum number of replicas this DeployedModel may be
   * deployed on when the traffic against it increases. If the requested value
   * is too large, the deployment will error, but if deployment succeeds then
   * the ability to scale the model to that many replicas is guaranteed (barring
   * service outages). If traffic against the DeployedModel increases beyond
   * what its replicas at maximum may handle, a portion of the traffic will be
   * dropped. If this value is not provided, will use
   * [min_replica_count][google.cloud.visionai.v1.DedicatedResources.min_replica_count]
   * as the default value.
   *
   * The value of this field impacts the charge against Vertex CPU and GPU
   * quotas. Specifically, you will be charged for max_replica_count *
   * number of cores in the selected machine type) and (max_replica_count *
   * number of GPUs per replica in the selected machine type).
   *
   * @generated from field: int32 max_replica_count = 3;
   */
  maxReplicaCount: number;

  /**
   * Immutable. The metric specifications that overrides a resource
   * utilization metric (CPU utilization, accelerator's duty cycle, and so on)
   * target value (default to 60 if not set). At most one entry is allowed per
   * metric.
   *
   * If
   * [machine_spec.accelerator_count][google.cloud.visionai.v1.MachineSpec.accelerator_count]
   * is above 0, the autoscaling will be based on both CPU utilization and
   * accelerator's duty cycle metrics and scale up when either metrics exceeds
   * its target value while scale down if both metrics are under their target
   * value. The default target value is 60 for both metrics.
   *
   * If
   * [machine_spec.accelerator_count][google.cloud.visionai.v1.MachineSpec.accelerator_count]
   * is 0, the autoscaling will be based on CPU utilization metric only with
   * default target value 60 if not explicitly set.
   *
   * For example, in the case of Online Prediction, if you want to override
   * target CPU utilization to 80, you should set
   * [autoscaling_metric_specs.metric_name][google.cloud.visionai.v1.AutoscalingMetricSpec.metric_name]
   * to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
   * [autoscaling_metric_specs.target][google.cloud.visionai.v1.AutoscalingMetricSpec.target]
   * to `80`.
   *
   * @generated from field: repeated google.cloud.visionai.v1.AutoscalingMetricSpec autoscaling_metric_specs = 4;
   */
  autoscalingMetricSpecs: AutoscalingMetricSpec[];
};

/**
 * Describes the message google.cloud.visionai.v1.DedicatedResources.
 * Use `create(DedicatedResourcesSchema)` to create a new message.
 */
export const DedicatedResourcesSchema: GenMessage<DedicatedResources> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 69);

/**
 * Message describing ProductRecognizerConfig.
 *
 * @generated from message google.cloud.visionai.v1.ProductRecognizerConfig
 */
export type ProductRecognizerConfig = Message<"google.cloud.visionai.v1.ProductRecognizerConfig"> & {
  /**
   * The resource name of retail endpoint to use.
   *
   * @generated from field: string retail_endpoint = 1;
   */
  retailEndpoint: string;

  /**
   * Confidence threshold to filter detection results. If not set, a system
   * default value will be used.
   *
   * @generated from field: float recognition_confidence_threshold = 2;
   */
  recognitionConfidenceThreshold: number;
};

/**
 * Describes the message google.cloud.visionai.v1.ProductRecognizerConfig.
 * Use `create(ProductRecognizerConfigSchema)` to create a new message.
 */
export const ProductRecognizerConfigSchema: GenMessage<ProductRecognizerConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 70);

/**
 * Message describing TagRecognizerConfig.
 *
 * @generated from message google.cloud.visionai.v1.TagRecognizerConfig
 */
export type TagRecognizerConfig = Message<"google.cloud.visionai.v1.TagRecognizerConfig"> & {
  /**
   * Confidence threshold to filter detection results. If not set, a system
   * default value will be used.
   *
   * @generated from field: float entity_detection_confidence_threshold = 1;
   */
  entityDetectionConfidenceThreshold: number;

  /**
   * Configuration to customize how tags are parsed.
   *
   * @generated from field: google.cloud.visionai.v1.TagParsingConfig tag_parsing_config = 2;
   */
  tagParsingConfig?: TagParsingConfig;
};

/**
 * Describes the message google.cloud.visionai.v1.TagRecognizerConfig.
 * Use `create(TagRecognizerConfigSchema)` to create a new message.
 */
export const TagRecognizerConfigSchema: GenMessage<TagRecognizerConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 71);

/**
 * Configuration for tag parsing.
 *
 * @generated from message google.cloud.visionai.v1.TagParsingConfig
 */
export type TagParsingConfig = Message<"google.cloud.visionai.v1.TagParsingConfig"> & {
  /**
   * Each tag entity class may have an optional EntityParsingConfig which is
   * used to help parse the entities of the class.
   *
   * @generated from field: repeated google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig entity_parsing_configs = 1;
   */
  entityParsingConfigs: TagParsingConfig_EntityParsingConfig[];
};

/**
 * Describes the message google.cloud.visionai.v1.TagParsingConfig.
 * Use `create(TagParsingConfigSchema)` to create a new message.
 */
export const TagParsingConfigSchema: GenMessage<TagParsingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 72);

/**
 * Configuration for parsing a tag entity class.
 *
 * @generated from message google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig
 */
export type TagParsingConfig_EntityParsingConfig = Message<"google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig"> & {
  /**
   * Required. The tag entity class name. This should match the class name
   * produced by the tag entity detection model.
   *
   * @generated from field: string entity_class = 1;
   */
  entityClass: string;

  /**
   * Optional. An regular expression hint.
   *
   * @generated from field: string regex = 2;
   */
  regex: string;

  /**
   * Optional. Entity matching strategy.
   *
   * @generated from field: google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig.EntityMatchingStrategy entity_matching_strategy = 3;
   */
  entityMatchingStrategy: TagParsingConfig_EntityParsingConfig_EntityMatchingStrategy;
};

/**
 * Describes the message google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig.
 * Use `create(TagParsingConfig_EntityParsingConfigSchema)` to create a new message.
 */
export const TagParsingConfig_EntityParsingConfigSchema: GenMessage<TagParsingConfig_EntityParsingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_visionai_v1_platform, 72, 0);

/**
 * Type of entity matching strategy.
 *
 * @generated from enum google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig.EntityMatchingStrategy
 */
export enum TagParsingConfig_EntityParsingConfig_EntityMatchingStrategy {
  /**
   * If unspecified, multi-line matching will be used by default.
   *
   * @generated from enum value: ENTITY_MATCHING_STRATEGY_UNSPECIFIED = 0;
   */
  ENTITY_MATCHING_STRATEGY_UNSPECIFIED = 0,

  /**
   * Matches multiple lines of text.
   *
   * @generated from enum value: MULTI_LINE_MATCHING = 1;
   */
  MULTI_LINE_MATCHING = 1,

  /**
   * Matches the line with the maximum overlap area with entity bounding
   * box.
   *
   * @generated from enum value: MAX_OVERLAP_AREA = 2;
   */
  MAX_OVERLAP_AREA = 2,
}

/**
 * Describes the enum google.cloud.visionai.v1.TagParsingConfig.EntityParsingConfig.EntityMatchingStrategy.
 */
export const TagParsingConfig_EntityParsingConfig_EntityMatchingStrategySchema: GenEnum<TagParsingConfig_EntityParsingConfig_EntityMatchingStrategy> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 72, 0, 0);

/**
 * All the supported model types in Vision AI App Platform.
 *
 * @generated from enum google.cloud.visionai.v1.ModelType
 */
export enum ModelType {
  /**
   * Processor Type UNSPECIFIED.
   *
   * @generated from enum value: MODEL_TYPE_UNSPECIFIED = 0;
   */
  MODEL_TYPE_UNSPECIFIED = 0,

  /**
   * Model Type Image Classification.
   *
   * @generated from enum value: IMAGE_CLASSIFICATION = 1;
   */
  IMAGE_CLASSIFICATION = 1,

  /**
   * Model Type Object Detection.
   *
   * @generated from enum value: OBJECT_DETECTION = 2;
   */
  OBJECT_DETECTION = 2,

  /**
   * Model Type Video Classification.
   *
   * @generated from enum value: VIDEO_CLASSIFICATION = 3;
   */
  VIDEO_CLASSIFICATION = 3,

  /**
   * Model Type Object Tracking.
   *
   * @generated from enum value: VIDEO_OBJECT_TRACKING = 4;
   */
  VIDEO_OBJECT_TRACKING = 4,

  /**
   * Model Type Action Recognition.
   *
   * @generated from enum value: VIDEO_ACTION_RECOGNITION = 5;
   */
  VIDEO_ACTION_RECOGNITION = 5,

  /**
   * Model Type Occupancy Counting.
   *
   * @generated from enum value: OCCUPANCY_COUNTING = 6;
   */
  OCCUPANCY_COUNTING = 6,

  /**
   * Model Type Person Blur.
   *
   * @generated from enum value: PERSON_BLUR = 7;
   */
  PERSON_BLUR = 7,

  /**
   * Model Type Vertex Custom.
   *
   * @generated from enum value: VERTEX_CUSTOM = 8;
   */
  VERTEX_CUSTOM = 8,

  /**
   * Model Type Product Recognizer.
   *
   * @generated from enum value: PRODUCT_RECOGNIZER = 9;
   */
  PRODUCT_RECOGNIZER = 9,

  /**
   * Model Type Tag Recognizer.
   *
   * @generated from enum value: TAG_RECOGNIZER = 10;
   */
  TAG_RECOGNIZER = 10,

  /**
   * Model Type SynthID.
   *
   * @generated from enum value: SYNTH_ID = 15;
   */
  SYNTH_ID = 15,
}

/**
 * Describes the enum google.cloud.visionai.v1.ModelType.
 */
export const ModelTypeSchema: GenEnum<ModelType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 0);

/**
 * Represents a hardware accelerator type.
 *
 * @generated from enum google.cloud.visionai.v1.AcceleratorType
 */
export enum AcceleratorType {
  /**
   * Unspecified accelerator type, which means no accelerator.
   *
   * @generated from enum value: ACCELERATOR_TYPE_UNSPECIFIED = 0;
   */
  ACCELERATOR_TYPE_UNSPECIFIED = 0,

  /**
   * Nvidia Tesla K80 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_K80 = 1;
   */
  NVIDIA_TESLA_K80 = 1,

  /**
   * Nvidia Tesla P100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_P100 = 2;
   */
  NVIDIA_TESLA_P100 = 2,

  /**
   * Nvidia Tesla V100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_V100 = 3;
   */
  NVIDIA_TESLA_V100 = 3,

  /**
   * Nvidia Tesla P4 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_P4 = 4;
   */
  NVIDIA_TESLA_P4 = 4,

  /**
   * Nvidia Tesla T4 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_T4 = 5;
   */
  NVIDIA_TESLA_T4 = 5,

  /**
   * Nvidia Tesla A100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_A100 = 8;
   */
  NVIDIA_TESLA_A100 = 8,

  /**
   * TPU v2.
   *
   * @generated from enum value: TPU_V2 = 6;
   */
  TPU_V2 = 6,

  /**
   * TPU v3.
   *
   * @generated from enum value: TPU_V3 = 7;
   */
  TPU_V3 = 7,
}

/**
 * Describes the enum google.cloud.visionai.v1.AcceleratorType.
 */
export const AcceleratorTypeSchema: GenEnum<AcceleratorType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 1);

/**
 * All supported data types.
 *
 * @generated from enum google.cloud.visionai.v1.DataType
 */
export enum DataType {
  /**
   * The default value of DataType.
   *
   * @generated from enum value: DATA_TYPE_UNSPECIFIED = 0;
   */
  DATA_TYPE_UNSPECIFIED = 0,

  /**
   * Video data type like H264.
   *
   * @generated from enum value: VIDEO = 1;
   */
  VIDEO = 1,

  /**
   * Image data type.
   *
   * @generated from enum value: IMAGE = 3;
   */
  IMAGE = 3,

  /**
   * Protobuf data type, usually used for general data blob.
   *
   * @generated from enum value: PROTO = 2;
   */
  PROTO = 2,

  /**
   * A placeholder data type, applicable for the universal input processor which
   * supports any data type. This will be instantiated and replaced by a
   * concrete underlying `DataType` during instance deployment.
   *
   * @generated from enum value: PLACEHOLDER = 4;
   */
  PLACEHOLDER = 4,
}

/**
 * Describes the enum google.cloud.visionai.v1.DataType.
 */
export const DataTypeSchema: GenEnum<DataType> = /*@__PURE__*/
  enumDesc(file_google_cloud_visionai_v1_platform, 2);

/**
 * Service describing handlers for resources
 *
 * @generated from service google.cloud.visionai.v1.AppPlatform
 */
export const AppPlatform: GenService<{
  /**
   * Lists Applications in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.ListApplications
   */
  listApplications: {
    methodKind: "unary";
    input: typeof ListApplicationsRequestSchema;
    output: typeof ListApplicationsResponseSchema;
  },
  /**
   * Gets details of a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.GetApplication
   */
  getApplication: {
    methodKind: "unary";
    input: typeof GetApplicationRequestSchema;
    output: typeof ApplicationSchema;
  },
  /**
   * Creates a new Application in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.CreateApplication
   */
  createApplication: {
    methodKind: "unary";
    input: typeof CreateApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates the parameters of a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.UpdateApplication
   */
  updateApplication: {
    methodKind: "unary";
    input: typeof UpdateApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deletes a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.DeleteApplication
   */
  deleteApplication: {
    methodKind: "unary";
    input: typeof DeleteApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deploys a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.DeployApplication
   */
  deployApplication: {
    methodKind: "unary";
    input: typeof DeployApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Undeploys a single Application.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.UndeployApplication
   */
  undeployApplication: {
    methodKind: "unary";
    input: typeof UndeployApplicationRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Adds target stream input to the Application.
   * If the Application is deployed, the corresponding new Application instance
   * will be created. If the stream has already been in the Application, the RPC
   * will fail.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.AddApplicationStreamInput
   */
  addApplicationStreamInput: {
    methodKind: "unary";
    input: typeof AddApplicationStreamInputRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Remove target stream input to the Application, if the Application is
   * deployed, the corresponding instance based will be deleted. If the stream
   * is not in the Application, the RPC will fail.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.RemoveApplicationStreamInput
   */
  removeApplicationStreamInput: {
    methodKind: "unary";
    input: typeof RemoveApplicationStreamInputRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Update target stream input to the Application, if the Application is
   * deployed, the corresponding instance based will be deployed. For
   * CreateOrUpdate behavior, set allow_missing to true.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.UpdateApplicationStreamInput
   */
  updateApplicationStreamInput: {
    methodKind: "unary";
    input: typeof UpdateApplicationStreamInputRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Lists Instances in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.ListInstances
   */
  listInstances: {
    methodKind: "unary";
    input: typeof ListInstancesRequestSchema;
    output: typeof ListInstancesResponseSchema;
  },
  /**
   * Gets details of a single Instance.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.GetInstance
   */
  getInstance: {
    methodKind: "unary";
    input: typeof GetInstanceRequestSchema;
    output: typeof InstanceSchema;
  },
  /**
   * Adds target stream input to the Application.
   * If the Application is deployed, the corresponding new Application instance
   * will be created. If the stream has already been in the Application, the RPC
   * will fail.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.CreateApplicationInstances
   */
  createApplicationInstances: {
    methodKind: "unary";
    input: typeof CreateApplicationInstancesRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Remove target stream input to the Application, if the Application is
   * deployed, the corresponding instance based will be deleted. If the stream
   * is not in the Application, the RPC will fail.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.DeleteApplicationInstances
   */
  deleteApplicationInstances: {
    methodKind: "unary";
    input: typeof DeleteApplicationInstancesRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Adds target stream input to the Application.
   * If the Application is deployed, the corresponding new Application instance
   * will be created. If the stream has already been in the Application, the RPC
   * will fail.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.UpdateApplicationInstances
   */
  updateApplicationInstances: {
    methodKind: "unary";
    input: typeof UpdateApplicationInstancesRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Lists Drafts in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.ListDrafts
   */
  listDrafts: {
    methodKind: "unary";
    input: typeof ListDraftsRequestSchema;
    output: typeof ListDraftsResponseSchema;
  },
  /**
   * Gets details of a single Draft.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.GetDraft
   */
  getDraft: {
    methodKind: "unary";
    input: typeof GetDraftRequestSchema;
    output: typeof DraftSchema;
  },
  /**
   * Creates a new Draft in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.CreateDraft
   */
  createDraft: {
    methodKind: "unary";
    input: typeof CreateDraftRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates the parameters of a single Draft.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.UpdateDraft
   */
  updateDraft: {
    methodKind: "unary";
    input: typeof UpdateDraftRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deletes a single Draft.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.DeleteDraft
   */
  deleteDraft: {
    methodKind: "unary";
    input: typeof DeleteDraftRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Lists Processors in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.ListProcessors
   */
  listProcessors: {
    methodKind: "unary";
    input: typeof ListProcessorsRequestSchema;
    output: typeof ListProcessorsResponseSchema;
  },
  /**
   * ListPrebuiltProcessors is a custom pass-through verb that Lists Prebuilt
   * Processors.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.ListPrebuiltProcessors
   */
  listPrebuiltProcessors: {
    methodKind: "unary";
    input: typeof ListPrebuiltProcessorsRequestSchema;
    output: typeof ListPrebuiltProcessorsResponseSchema;
  },
  /**
   * Gets details of a single Processor.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.GetProcessor
   */
  getProcessor: {
    methodKind: "unary";
    input: typeof GetProcessorRequestSchema;
    output: typeof ProcessorSchema;
  },
  /**
   * Creates a new Processor in a given project and location.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.CreateProcessor
   */
  createProcessor: {
    methodKind: "unary";
    input: typeof CreateProcessorRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates the parameters of a single Processor.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.UpdateProcessor
   */
  updateProcessor: {
    methodKind: "unary";
    input: typeof UpdateProcessorRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Deletes a single Processor.
   *
   * @generated from rpc google.cloud.visionai.v1.AppPlatform.DeleteProcessor
   */
  deleteProcessor: {
    methodKind: "unary";
    input: typeof DeleteProcessorRequestSchema;
    output: typeof OperationSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_visionai_v1_platform, 0);

