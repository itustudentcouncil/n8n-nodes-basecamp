// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1beta1/dataset.proto (package google.cloud.aiplatform.v1beta1, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { EncryptionSpec } from "./encryption_spec_pb";
import { file_google_cloud_aiplatform_v1beta1_encryption_spec } from "./encryption_spec_pb";
import type { GcsDestination, GcsSource } from "./io_pb";
import { file_google_cloud_aiplatform_v1beta1_io } from "./io_pb";
import type { SavedQuery } from "./saved_query_pb";
import { file_google_cloud_aiplatform_v1beta1_saved_query } from "./saved_query_pb";
import type { Timestamp, Value } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_struct, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1beta1/dataset.proto.
 */
export const file_google_cloud_aiplatform_v1beta1_dataset: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_aiplatform_v1beta1_encryption_spec, file_google_cloud_aiplatform_v1beta1_io, file_google_cloud_aiplatform_v1beta1_saved_query, file_google_protobuf_struct, file_google_protobuf_timestamp]);

/**
 * A collection of DataItems and Annotations on them.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.Dataset
 */
export type Dataset = Message<"google.cloud.aiplatform.v1beta1.Dataset"> & {
  /**
   * Output only. Identifier. The resource name of the Dataset.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The user-defined name of the Dataset.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * The description of the Dataset.
   *
   * @generated from field: string description = 16;
   */
  description: string;

  /**
   * Required. Points to a YAML file stored on Google Cloud Storage describing
   * additional information about the Dataset. The schema is defined as an
   * OpenAPI 3.0.2 Schema Object. The schema files that can be used here are
   * found in gs://google-cloud-aiplatform/schema/dataset/metadata/.
   *
   * @generated from field: string metadata_schema_uri = 3;
   */
  metadataSchemaUri: string;

  /**
   * Required. Additional information about the Dataset.
   *
   * @generated from field: google.protobuf.Value metadata = 8;
   */
  metadata?: Value;

  /**
   * Output only. The number of DataItems in this Dataset. Only apply for
   * non-structured Dataset.
   *
   * @generated from field: int64 data_item_count = 10;
   */
  dataItemCount: bigint;

  /**
   * Output only. Timestamp when this Dataset was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 4;
   */
  createTime?: Timestamp;

  /**
   * Output only. Timestamp when this Dataset was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 5;
   */
  updateTime?: Timestamp;

  /**
   * Used to perform consistent read-modify-write updates. If not set, a blind
   * "overwrite" update happens.
   *
   * @generated from field: string etag = 6;
   */
  etag: string;

  /**
   * The labels with user-defined metadata to organize your Datasets.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   * No more than 64 user labels can be associated with one Dataset (System
   * labels are excluded).
   *
   * See https://goo.gl/xmQnxf for more information and examples of labels.
   * System reserved label keys are prefixed with "aiplatform.googleapis.com/"
   * and are immutable. Following system labels exist for each Dataset:
   *
   * * "aiplatform.googleapis.com/dataset_metadata_schema": output only, its
   *   value is the
   *   [metadata_schema's][google.cloud.aiplatform.v1beta1.Dataset.metadata_schema_uri]
   *   title.
   *
   * @generated from field: map<string, string> labels = 7;
   */
  labels: { [key: string]: string };

  /**
   * All SavedQueries belong to the Dataset will be returned in List/Get
   * Dataset response. The annotation_specs field
   * will not be populated except for UI cases which will only use
   * [annotation_spec_count][google.cloud.aiplatform.v1beta1.SavedQuery.annotation_spec_count].
   * In CreateDataset request, a SavedQuery is created together if
   * this field is set, up to one SavedQuery can be set in CreateDatasetRequest.
   * The SavedQuery should not contain any AnnotationSpec.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1beta1.SavedQuery saved_queries = 9;
   */
  savedQueries: SavedQuery[];

  /**
   * Customer-managed encryption key spec for a Dataset. If set, this Dataset
   * and all sub-resources of this Dataset will be secured by this key.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.EncryptionSpec encryption_spec = 11;
   */
  encryptionSpec?: EncryptionSpec;

  /**
   * Output only. The resource name of the Artifact that was created in
   * MetadataStore when creating the Dataset. The Artifact resource name pattern
   * is
   * `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
   *
   * @generated from field: string metadata_artifact = 17;
   */
  metadataArtifact: string;

  /**
   * Optional. Reference to the public base model last used by the dataset. Only
   * set for prompt datasets.
   *
   * @generated from field: string model_reference = 18;
   */
  modelReference: string;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzs = 19;
   */
  satisfiesPzs: boolean;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzi = 20;
   */
  satisfiesPzi: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.Dataset.
 * Use `create(DatasetSchema)` to create a new message.
 */
export const DatasetSchema: GenMessage<Dataset> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_dataset, 0);

/**
 * Describes the location from where we import data into a Dataset, together
 * with the labels that will be applied to the DataItems and the Annotations.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.ImportDataConfig
 */
export type ImportDataConfig = Message<"google.cloud.aiplatform.v1beta1.ImportDataConfig"> & {
  /**
   * The source of the input.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.ImportDataConfig.source
   */
  source: {
    /**
     * The Google Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsSource gcs_source = 1;
     */
    value: GcsSource;
    case: "gcsSource";
  } | { case: undefined; value?: undefined };

  /**
   * Labels that will be applied to newly imported DataItems. If an identical
   * DataItem as one being imported already exists in the Dataset, then these
   * labels will be appended to these of the already existing one, and if labels
   * with identical key is imported before, the old label value will be
   * overwritten. If two DataItems are identical in the same import data
   * operation, the labels will be combined and if key collision happens in this
   * case, one of the values will be picked randomly. Two DataItems are
   * considered identical if their content bytes are identical (e.g. image bytes
   * or pdf bytes).
   * These labels will be overridden by Annotation labels specified inside index
   * file referenced by
   * [import_schema_uri][google.cloud.aiplatform.v1beta1.ImportDataConfig.import_schema_uri],
   * e.g. jsonl file.
   *
   * @generated from field: map<string, string> data_item_labels = 2;
   */
  dataItemLabels: { [key: string]: string };

  /**
   * Labels that will be applied to newly imported Annotations. If two
   * Annotations are identical, one of them will be deduped. Two Annotations are
   * considered identical if their
   * [payload][google.cloud.aiplatform.v1beta1.Annotation.payload],
   * [payload_schema_uri][google.cloud.aiplatform.v1beta1.Annotation.payload_schema_uri]
   * and all of their
   * [labels][google.cloud.aiplatform.v1beta1.Annotation.labels] are the same.
   * These labels will be overridden by Annotation labels specified inside index
   * file referenced by
   * [import_schema_uri][google.cloud.aiplatform.v1beta1.ImportDataConfig.import_schema_uri],
   * e.g. jsonl file.
   *
   * @generated from field: map<string, string> annotation_labels = 3;
   */
  annotationLabels: { [key: string]: string };

  /**
   * Required. Points to a YAML file stored on Google Cloud Storage describing
   * the import format. Validation will be done against the schema. The schema
   * is defined as an [OpenAPI 3.0.2 Schema
   * Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
   *
   * @generated from field: string import_schema_uri = 4;
   */
  importSchemaUri: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.ImportDataConfig.
 * Use `create(ImportDataConfigSchema)` to create a new message.
 */
export const ImportDataConfigSchema: GenMessage<ImportDataConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_dataset, 1);

/**
 * Describes what part of the Dataset is to be exported, the destination of
 * the export and how to export.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.ExportDataConfig
 */
export type ExportDataConfig = Message<"google.cloud.aiplatform.v1beta1.ExportDataConfig"> & {
  /**
   * The destination of the output.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.ExportDataConfig.destination
   */
  destination: {
    /**
     * The Google Cloud Storage location where the output is to be written to.
     * In the given directory a new directory will be created with name:
     * `export-data-<dataset-display-name>-<timestamp-of-export-call>` where
     * timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All export
     * output will be written into that directory. Inside that directory,
     * annotations with the same schema will be grouped into sub directories
     * which are named with the corresponding annotations' schema title. Inside
     * these sub directories, a schema.yaml will be created to describe the
     * output format.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsDestination gcs_destination = 1;
     */
    value: GcsDestination;
    case: "gcsDestination";
  } | { case: undefined; value?: undefined };

  /**
   * The instructions how the export data should be split between the
   * training, validation and test sets.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.ExportDataConfig.split
   */
  split: {
    /**
     * Split based on fractions defining the size of each set.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.ExportFractionSplit fraction_split = 5;
     */
    value: ExportFractionSplit;
    case: "fractionSplit";
  } | { case: undefined; value?: undefined };

  /**
   * An expression for filtering what part of the Dataset is to be exported.
   * Only Annotations that match this filter will be exported. The filter syntax
   * is the same as in
   * [ListAnnotations][google.cloud.aiplatform.v1beta1.DatasetService.ListAnnotations].
   *
   * @generated from field: string annotations_filter = 2;
   */
  annotationsFilter: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.ExportDataConfig.
 * Use `create(ExportDataConfigSchema)` to create a new message.
 */
export const ExportDataConfigSchema: GenMessage<ExportDataConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_dataset, 2);

/**
 * Assigns the input data to training, validation, and test sets as per the
 * given fractions. Any of `training_fraction`, `validation_fraction` and
 * `test_fraction` may optionally be provided, they must sum to up to 1. If the
 * provided ones sum to less than 1, the remainder is assigned to sets as
 * decided by Vertex AI. If none of the fractions are set, by default roughly
 * 80% of data is used for training, 10% for validation, and 10% for test.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.ExportFractionSplit
 */
export type ExportFractionSplit = Message<"google.cloud.aiplatform.v1beta1.ExportFractionSplit"> & {
  /**
   * The fraction of the input data that is to be used to train the Model.
   *
   * @generated from field: double training_fraction = 1;
   */
  trainingFraction: number;

  /**
   * The fraction of the input data that is to be used to validate the Model.
   *
   * @generated from field: double validation_fraction = 2;
   */
  validationFraction: number;

  /**
   * The fraction of the input data that is to be used to evaluate the Model.
   *
   * @generated from field: double test_fraction = 3;
   */
  testFraction: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.ExportFractionSplit.
 * Use `create(ExportFractionSplitSchema)` to create a new message.
 */
export const ExportFractionSplitSchema: GenMessage<ExportFractionSplit> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_dataset, 3);

