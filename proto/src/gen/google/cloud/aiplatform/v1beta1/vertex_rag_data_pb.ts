// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1beta1/vertex_rag_data.proto (package google.cloud.aiplatform.v1beta1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { ApiAuth } from "./api_auth_pb";
import { file_google_cloud_aiplatform_v1beta1_api_auth } from "./api_auth_pb";
import type { BigQueryDestination, DirectUploadSource, GcsDestination, GcsSource, GoogleDriveSource, JiraSource, SharePointSources, SlackSource } from "./io_pb";
import { file_google_cloud_aiplatform_v1beta1_io } from "./io_pb";
import type { Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1beta1/vertex_rag_data.proto.
 */
export const file_google_cloud_aiplatform_v1beta1_vertex_rag_data: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_aiplatform_v1beta1_api_auth, file_google_cloud_aiplatform_v1beta1_io, file_google_protobuf_timestamp]);

/**
 * Config for the embedding model to use for RAG.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig
 */
export type RagEmbeddingModelConfig = Message<"google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig"> & {
  /**
   * The model config to use.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.model_config
   */
  modelConfig: {
    /**
     * The Vertex AI Prediction Endpoint that either refers to a publisher model
     * or an endpoint that is hosting a 1P fine-tuned text embedding model.
     * Endpoints hosting non-1P fine-tuned text embedding models are
     * currently not supported.
     * This is used for dense vector search.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.VertexPredictionEndpoint vertex_prediction_endpoint = 1;
     */
    value: RagEmbeddingModelConfig_VertexPredictionEndpoint;
    case: "vertexPredictionEndpoint";
  } | {
    /**
     * Configuration for hybrid search.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.HybridSearchConfig hybrid_search_config = 2;
     */
    value: RagEmbeddingModelConfig_HybridSearchConfig;
    case: "hybridSearchConfig";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.
 * Use `create(RagEmbeddingModelConfigSchema)` to create a new message.
 */
export const RagEmbeddingModelConfigSchema: GenMessage<RagEmbeddingModelConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 0);

/**
 * Config representing a model hosted on Vertex Prediction Endpoint.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.VertexPredictionEndpoint
 */
export type RagEmbeddingModelConfig_VertexPredictionEndpoint = Message<"google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.VertexPredictionEndpoint"> & {
  /**
   * Required. The endpoint resource name.
   * Format:
   * `projects/{project}/locations/{location}/publishers/{publisher}/models/{model}`
   * or
   * `projects/{project}/locations/{location}/endpoints/{endpoint}`
   *
   * @generated from field: string endpoint = 1;
   */
  endpoint: string;

  /**
   * Output only. The resource name of the model that is deployed on the
   * endpoint. Present only when the endpoint is not a publisher model.
   * Pattern:
   * `projects/{project}/locations/{location}/models/{model}`
   *
   * @generated from field: string model = 2;
   */
  model: string;

  /**
   * Output only. Version ID of the model that is deployed on the endpoint.
   * Present only when the endpoint is not a publisher model.
   *
   * @generated from field: string model_version_id = 3;
   */
  modelVersionId: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.VertexPredictionEndpoint.
 * Use `create(RagEmbeddingModelConfig_VertexPredictionEndpointSchema)` to create a new message.
 */
export const RagEmbeddingModelConfig_VertexPredictionEndpointSchema: GenMessage<RagEmbeddingModelConfig_VertexPredictionEndpoint> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 0, 0);

/**
 * Configuration for sparse emebdding generation.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig
 */
export type RagEmbeddingModelConfig_SparseEmbeddingConfig = Message<"google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig"> & {
  /**
   * The model to use for sparse embedding generation.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig.model
   */
  model: {
    /**
     * Use BM25 scoring algorithm.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig.Bm25 bm25 = 1;
     */
    value: RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25;
    case: "bm25";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig.
 * Use `create(RagEmbeddingModelConfig_SparseEmbeddingConfigSchema)` to create a new message.
 */
export const RagEmbeddingModelConfig_SparseEmbeddingConfigSchema: GenMessage<RagEmbeddingModelConfig_SparseEmbeddingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 0, 1);

/**
 * Message for BM25 parameters.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig.Bm25
 */
export type RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25 = Message<"google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig.Bm25"> & {
  /**
   * Optional. Use multilingual tokenizer if set to true.
   *
   * @generated from field: bool multilingual = 1;
   */
  multilingual: boolean;

  /**
   * Optional. The parameter to control term frequency saturation. It
   * determines the scaling between the matching term frequency and final
   * score. k1 is in the range of [1.2, 3]. The default value is 1.2.
   *
   * @generated from field: optional float k1 = 2;
   */
  k1?: number;

  /**
   * Optional. The parameter to control document length normalization. It
   * determines how much the document length affects the final score. b is
   * in the range of [0, 1]. The default value is 0.75.
   *
   * @generated from field: optional float b = 3;
   */
  b?: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig.Bm25.
 * Use `create(RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25Schema)` to create a new message.
 */
export const RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25Schema: GenMessage<RagEmbeddingModelConfig_SparseEmbeddingConfig_Bm25> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 0, 1, 0);

/**
 * Config for hybrid search.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.HybridSearchConfig
 */
export type RagEmbeddingModelConfig_HybridSearchConfig = Message<"google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.HybridSearchConfig"> & {
  /**
   * Optional. The configuration for sparse embedding generation. This field
   * is optional the default behavior depends on the vector database choice on
   * the RagCorpus.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.SparseEmbeddingConfig sparse_embedding_config = 1;
   */
  sparseEmbeddingConfig?: RagEmbeddingModelConfig_SparseEmbeddingConfig;

  /**
   * Required. The Vertex AI Prediction Endpoint that hosts the embedding
   * model for dense embedding generations.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.VertexPredictionEndpoint dense_embedding_model_prediction_endpoint = 2;
   */
  denseEmbeddingModelPredictionEndpoint?: RagEmbeddingModelConfig_VertexPredictionEndpoint;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig.HybridSearchConfig.
 * Use `create(RagEmbeddingModelConfig_HybridSearchConfigSchema)` to create a new message.
 */
export const RagEmbeddingModelConfig_HybridSearchConfigSchema: GenMessage<RagEmbeddingModelConfig_HybridSearchConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 0, 2);

/**
 * Config for the Vector DB to use for RAG.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagVectorDbConfig
 */
export type RagVectorDbConfig = Message<"google.cloud.aiplatform.v1beta1.RagVectorDbConfig"> & {
  /**
   * The config for the Vector DB.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.RagVectorDbConfig.vector_db
   */
  vectorDb: {
    /**
     * The config for the RAG-managed Vector DB.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagVectorDbConfig.RagManagedDb rag_managed_db = 1;
     */
    value: RagVectorDbConfig_RagManagedDb;
    case: "ragManagedDb";
  } | {
    /**
     * The config for the Weaviate.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Weaviate weaviate = 2;
     */
    value: RagVectorDbConfig_Weaviate;
    case: "weaviate";
  } | {
    /**
     * The config for the Pinecone.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Pinecone pinecone = 3;
     */
    value: RagVectorDbConfig_Pinecone;
    case: "pinecone";
  } | {
    /**
     * The config for the Vertex Feature Store.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexFeatureStore vertex_feature_store = 4;
     */
    value: RagVectorDbConfig_VertexFeatureStore;
    case: "vertexFeatureStore";
  } | {
    /**
     * The config for the Vertex Vector Search.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexVectorSearch vertex_vector_search = 6;
     */
    value: RagVectorDbConfig_VertexVectorSearch;
    case: "vertexVectorSearch";
  } | { case: undefined; value?: undefined };

  /**
   * Authentication config for the chosen Vector DB.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.ApiAuth api_auth = 5;
   */
  apiAuth?: ApiAuth;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.
 * Use `create(RagVectorDbConfigSchema)` to create a new message.
 */
export const RagVectorDbConfigSchema: GenMessage<RagVectorDbConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 1);

/**
 * The config for the default RAG-managed Vector DB.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.RagManagedDb
 */
export type RagVectorDbConfig_RagManagedDb = Message<"google.cloud.aiplatform.v1beta1.RagVectorDbConfig.RagManagedDb"> & {
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.RagManagedDb.
 * Use `create(RagVectorDbConfig_RagManagedDbSchema)` to create a new message.
 */
export const RagVectorDbConfig_RagManagedDbSchema: GenMessage<RagVectorDbConfig_RagManagedDb> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 1, 0);

/**
 * The config for the Weaviate.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Weaviate
 */
export type RagVectorDbConfig_Weaviate = Message<"google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Weaviate"> & {
  /**
   * Weaviate DB instance HTTP endpoint. e.g. 34.56.78.90:8080
   * Vertex RAG only supports HTTP connection to Weaviate.
   * This value cannot be changed after it's set.
   *
   * @generated from field: string http_endpoint = 1;
   */
  httpEndpoint: string;

  /**
   * The corresponding collection this corpus maps to.
   * This value cannot be changed after it's set.
   *
   * @generated from field: string collection_name = 2;
   */
  collectionName: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Weaviate.
 * Use `create(RagVectorDbConfig_WeaviateSchema)` to create a new message.
 */
export const RagVectorDbConfig_WeaviateSchema: GenMessage<RagVectorDbConfig_Weaviate> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 1, 1);

/**
 * The config for the Pinecone.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Pinecone
 */
export type RagVectorDbConfig_Pinecone = Message<"google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Pinecone"> & {
  /**
   * Pinecone index name.
   * This value cannot be changed after it's set.
   *
   * @generated from field: string index_name = 1;
   */
  indexName: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.Pinecone.
 * Use `create(RagVectorDbConfig_PineconeSchema)` to create a new message.
 */
export const RagVectorDbConfig_PineconeSchema: GenMessage<RagVectorDbConfig_Pinecone> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 1, 2);

/**
 * The config for the Vertex Feature Store.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexFeatureStore
 */
export type RagVectorDbConfig_VertexFeatureStore = Message<"google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexFeatureStore"> & {
  /**
   * The resource name of the FeatureView.
   * Format:
   * `projects/{project}/locations/{location}/featureOnlineStores/{feature_online_store}/featureViews/{feature_view}`
   *
   * @generated from field: string feature_view_resource_name = 1;
   */
  featureViewResourceName: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexFeatureStore.
 * Use `create(RagVectorDbConfig_VertexFeatureStoreSchema)` to create a new message.
 */
export const RagVectorDbConfig_VertexFeatureStoreSchema: GenMessage<RagVectorDbConfig_VertexFeatureStore> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 1, 3);

/**
 * The config for the Vertex Vector Search.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexVectorSearch
 */
export type RagVectorDbConfig_VertexVectorSearch = Message<"google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexVectorSearch"> & {
  /**
   * The resource name of the Index Endpoint.
   * Format:
   * `projects/{project}/locations/{location}/indexEndpoints/{index_endpoint}`
   *
   * @generated from field: string index_endpoint = 1;
   */
  indexEndpoint: string;

  /**
   * The resource name of the Index.
   * Format:
   * `projects/{project}/locations/{location}/indexes/{index}`
   *
   * @generated from field: string index = 2;
   */
  index: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagVectorDbConfig.VertexVectorSearch.
 * Use `create(RagVectorDbConfig_VertexVectorSearchSchema)` to create a new message.
 */
export const RagVectorDbConfig_VertexVectorSearchSchema: GenMessage<RagVectorDbConfig_VertexVectorSearch> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 1, 4);

/**
 * RagFile status.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.FileStatus
 */
export type FileStatus = Message<"google.cloud.aiplatform.v1beta1.FileStatus"> & {
  /**
   * Output only. RagFile state.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.FileStatus.State state = 1;
   */
  state: FileStatus_State;

  /**
   * Output only. Only when the `state` field is ERROR.
   *
   * @generated from field: string error_status = 2;
   */
  errorStatus: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.FileStatus.
 * Use `create(FileStatusSchema)` to create a new message.
 */
export const FileStatusSchema: GenMessage<FileStatus> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 2);

/**
 * RagFile state.
 *
 * @generated from enum google.cloud.aiplatform.v1beta1.FileStatus.State
 */
export enum FileStatus_State {
  /**
   * RagFile state is unspecified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * RagFile resource has been created and indexed successfully.
   *
   * @generated from enum value: ACTIVE = 1;
   */
  ACTIVE = 1,

  /**
   * RagFile resource is in a problematic state.
   * See `error_message` field for details.
   *
   * @generated from enum value: ERROR = 2;
   */
  ERROR = 2,
}

/**
 * Describes the enum google.cloud.aiplatform.v1beta1.FileStatus.State.
 */
export const FileStatus_StateSchema: GenEnum<FileStatus_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 2, 0);

/**
 * RagCorpus status.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.CorpusStatus
 */
export type CorpusStatus = Message<"google.cloud.aiplatform.v1beta1.CorpusStatus"> & {
  /**
   * Output only. RagCorpus life state.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.CorpusStatus.State state = 1;
   */
  state: CorpusStatus_State;

  /**
   * Output only. Only when the `state` field is ERROR.
   *
   * @generated from field: string error_status = 2;
   */
  errorStatus: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.CorpusStatus.
 * Use `create(CorpusStatusSchema)` to create a new message.
 */
export const CorpusStatusSchema: GenMessage<CorpusStatus> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 3);

/**
 * RagCorpus life state.
 *
 * @generated from enum google.cloud.aiplatform.v1beta1.CorpusStatus.State
 */
export enum CorpusStatus_State {
  /**
   * This state is not supposed to happen.
   *
   * @generated from enum value: UNKNOWN = 0;
   */
  UNKNOWN = 0,

  /**
   * RagCorpus resource entry is initialized, but hasn't done validation.
   *
   * @generated from enum value: INITIALIZED = 1;
   */
  INITIALIZED = 1,

  /**
   * RagCorpus is provisioned successfully and is ready to serve.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * RagCorpus is in a problematic situation.
   * See `error_message` field for details.
   *
   * @generated from enum value: ERROR = 3;
   */
  ERROR = 3,
}

/**
 * Describes the enum google.cloud.aiplatform.v1beta1.CorpusStatus.State.
 */
export const CorpusStatus_StateSchema: GenEnum<CorpusStatus_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 3, 0);

/**
 * A RagCorpus is a RagFile container and a project can have multiple
 * RagCorpora.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagCorpus
 */
export type RagCorpus = Message<"google.cloud.aiplatform.v1beta1.RagCorpus"> & {
  /**
   * Output only. The resource name of the RagCorpus.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The display name of the RagCorpus.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * Optional. The description of the RagCorpus.
   *
   * @generated from field: string description = 3;
   */
  description: string;

  /**
   * Optional. Immutable. The embedding model config of the RagCorpus.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagEmbeddingModelConfig rag_embedding_model_config = 6;
   */
  ragEmbeddingModelConfig?: RagEmbeddingModelConfig;

  /**
   * Optional. Immutable. The Vector DB config of the RagCorpus.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagVectorDbConfig rag_vector_db_config = 7;
   */
  ragVectorDbConfig?: RagVectorDbConfig;

  /**
   * Output only. Timestamp when this RagCorpus was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 4;
   */
  createTime?: Timestamp;

  /**
   * Output only. Timestamp when this RagCorpus was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 5;
   */
  updateTime?: Timestamp;

  /**
   * Output only. RagCorpus state.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.CorpusStatus corpus_status = 8;
   */
  corpusStatus?: CorpusStatus;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagCorpus.
 * Use `create(RagCorpusSchema)` to create a new message.
 */
export const RagCorpusSchema: GenMessage<RagCorpus> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 4);

/**
 * A RagFile contains user data for chunking, embedding and indexing.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagFile
 */
export type RagFile = Message<"google.cloud.aiplatform.v1beta1.RagFile"> & {
  /**
   * The origin location of the RagFile if it is imported from Google Cloud
   * Storage or Google Drive.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.RagFile.rag_file_source
   */
  ragFileSource: {
    /**
     * Output only. Google Cloud Storage location of the RagFile.
     * It does not support wildcards in the Cloud Storage uri for now.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsSource gcs_source = 8;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * Output only. Google Drive location. Supports importing individual files
     * as well as Google Drive folders.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GoogleDriveSource google_drive_source = 9;
     */
    value: GoogleDriveSource;
    case: "googleDriveSource";
  } | {
    /**
     * Output only. The RagFile is encapsulated and uploaded in the
     * UploadRagFile request.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.DirectUploadSource direct_upload_source = 10;
     */
    value: DirectUploadSource;
    case: "directUploadSource";
  } | {
    /**
     * The RagFile is imported from a Slack channel.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.SlackSource slack_source = 11;
     */
    value: SlackSource;
    case: "slackSource";
  } | {
    /**
     * The RagFile is imported from a Jira query.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.JiraSource jira_source = 12;
     */
    value: JiraSource;
    case: "jiraSource";
  } | {
    /**
     * The RagFile is imported from a SharePoint source.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.SharePointSources share_point_sources = 14;
     */
    value: SharePointSources;
    case: "sharePointSources";
  } | { case: undefined; value?: undefined };

  /**
   * Output only. The resource name of the RagFile.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The display name of the RagFile.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * Optional. The description of the RagFile.
   *
   * @generated from field: string description = 3;
   */
  description: string;

  /**
   * Output only. The size of the RagFile in bytes.
   *
   * @generated from field: int64 size_bytes = 4;
   */
  sizeBytes: bigint;

  /**
   * Output only. The type of the RagFile.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagFile.RagFileType rag_file_type = 5;
   */
  ragFileType: RagFile_RagFileType;

  /**
   * Output only. Timestamp when this RagFile was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 6;
   */
  createTime?: Timestamp;

  /**
   * Output only. Timestamp when this RagFile was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 7;
   */
  updateTime?: Timestamp;

  /**
   * Output only. State of the RagFile.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.FileStatus file_status = 13;
   */
  fileStatus?: FileStatus;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagFile.
 * Use `create(RagFileSchema)` to create a new message.
 */
export const RagFileSchema: GenMessage<RagFile> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 5);

/**
 * The type of the RagFile.
 *
 * @generated from enum google.cloud.aiplatform.v1beta1.RagFile.RagFileType
 */
export enum RagFile_RagFileType {
  /**
   * RagFile type is unspecified.
   *
   * @generated from enum value: RAG_FILE_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * RagFile type is TXT.
   *
   * @generated from enum value: RAG_FILE_TYPE_TXT = 1;
   */
  TXT = 1,

  /**
   * RagFile type is PDF.
   *
   * @generated from enum value: RAG_FILE_TYPE_PDF = 2;
   */
  PDF = 2,
}

/**
 * Describes the enum google.cloud.aiplatform.v1beta1.RagFile.RagFileType.
 */
export const RagFile_RagFileTypeSchema: GenEnum<RagFile_RagFileType> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 5, 0);

/**
 * Specifies the size and overlap of chunks for RagFiles.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagFileChunkingConfig
 */
export type RagFileChunkingConfig = Message<"google.cloud.aiplatform.v1beta1.RagFileChunkingConfig"> & {
  /**
   * The size of the chunks.
   *
   * @generated from field: int32 chunk_size = 1;
   */
  chunkSize: number;

  /**
   * The overlap between chunks.
   *
   * @generated from field: int32 chunk_overlap = 2;
   */
  chunkOverlap: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagFileChunkingConfig.
 * Use `create(RagFileChunkingConfigSchema)` to create a new message.
 */
export const RagFileChunkingConfigSchema: GenMessage<RagFileChunkingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 6);

/**
 * Specifies the parsing config for RagFiles.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.RagFileParsingConfig
 */
export type RagFileParsingConfig = Message<"google.cloud.aiplatform.v1beta1.RagFileParsingConfig"> & {
  /**
   * Whether to use advanced PDF parsing.
   *
   * @generated from field: bool use_advanced_pdf_parsing = 2;
   */
  useAdvancedPdfParsing: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.RagFileParsingConfig.
 * Use `create(RagFileParsingConfigSchema)` to create a new message.
 */
export const RagFileParsingConfigSchema: GenMessage<RagFileParsingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 7);

/**
 * Config for uploading RagFile.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.UploadRagFileConfig
 */
export type UploadRagFileConfig = Message<"google.cloud.aiplatform.v1beta1.UploadRagFileConfig"> & {
  /**
   * Specifies the size and overlap of chunks after uploading RagFile.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagFileChunkingConfig rag_file_chunking_config = 1;
   */
  ragFileChunkingConfig?: RagFileChunkingConfig;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.UploadRagFileConfig.
 * Use `create(UploadRagFileConfigSchema)` to create a new message.
 */
export const UploadRagFileConfigSchema: GenMessage<UploadRagFileConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 8);

/**
 * Config for importing RagFiles.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.ImportRagFilesConfig
 */
export type ImportRagFilesConfig = Message<"google.cloud.aiplatform.v1beta1.ImportRagFilesConfig"> & {
  /**
   * The source of the import.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.ImportRagFilesConfig.import_source
   */
  importSource: {
    /**
     * Google Cloud Storage location. Supports importing individual files as
     * well as entire Google Cloud Storage directories. Sample formats:
     * - `gs://bucket_name/my_directory/object_name/my_file.txt`
     * - `gs://bucket_name/my_directory`
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsSource gcs_source = 2;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * Google Drive location. Supports importing individual files as
     * well as Google Drive folders.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GoogleDriveSource google_drive_source = 3;
     */
    value: GoogleDriveSource;
    case: "googleDriveSource";
  } | {
    /**
     * Slack channels with their corresponding access tokens.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.SlackSource slack_source = 6;
     */
    value: SlackSource;
    case: "slackSource";
  } | {
    /**
     * Jira queries with their corresponding authentication.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.JiraSource jira_source = 7;
     */
    value: JiraSource;
    case: "jiraSource";
  } | {
    /**
     * SharePoint sources.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.SharePointSources share_point_sources = 13;
     */
    value: SharePointSources;
    case: "sharePointSources";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. If provided, all partial failures are written to the sink.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.ImportRagFilesConfig.partial_failure_sink
   */
  partialFailureSink: {
    /**
     * The Cloud Storage path to write partial failures to.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsDestination partial_failure_gcs_sink = 11;
     */
    value: GcsDestination;
    case: "partialFailureGcsSink";
  } | {
    /**
     * The BigQuery destination to write partial failures to. It should be a
     * bigquery table resource name (e.g.
     * "bq://projectId.bqDatasetId.bqTableId"). If the dataset id does not
     * exist, it will be created. If the table does not exist, it will be
     * created with the expected schema. If the table exists, the schema will be
     * validated and data will be added to this existing table.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.BigQueryDestination partial_failure_bigquery_sink = 12;
     */
    value: BigQueryDestination;
    case: "partialFailureBigquerySink";
  } | { case: undefined; value?: undefined };

  /**
   * Specifies the size and overlap of chunks after importing RagFiles.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagFileChunkingConfig rag_file_chunking_config = 4;
   */
  ragFileChunkingConfig?: RagFileChunkingConfig;

  /**
   * Specifies the parsing config for RagFiles.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.RagFileParsingConfig rag_file_parsing_config = 8;
   */
  ragFileParsingConfig?: RagFileParsingConfig;

  /**
   * Optional. The max number of queries per minute that this job is allowed to
   * make to the embedding model specified on the corpus. This value is specific
   * to this job and not shared across other import jobs. Consult the Quotas
   * page on the project to set an appropriate value here.
   * If unspecified, a default value of 1,000 QPM would be used.
   *
   * @generated from field: int32 max_embedding_requests_per_min = 5;
   */
  maxEmbeddingRequestsPerMin: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.ImportRagFilesConfig.
 * Use `create(ImportRagFilesConfigSchema)` to create a new message.
 */
export const ImportRagFilesConfigSchema: GenMessage<ImportRagFilesConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_vertex_rag_data, 9);

