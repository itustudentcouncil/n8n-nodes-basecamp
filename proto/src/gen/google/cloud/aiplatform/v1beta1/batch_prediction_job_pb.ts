// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1beta1/batch_prediction_job.proto (package google.cloud.aiplatform.v1beta1, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { CompletionStats } from "./completion_stats_pb";
import { file_google_cloud_aiplatform_v1beta1_completion_stats } from "./completion_stats_pb";
import type { EncryptionSpec } from "./encryption_spec_pb";
import { file_google_cloud_aiplatform_v1beta1_encryption_spec } from "./encryption_spec_pb";
import type { ExplanationSpec } from "./explanation_pb";
import { file_google_cloud_aiplatform_v1beta1_explanation } from "./explanation_pb";
import type { BigQueryDestination, BigQuerySource, GcsDestination, GcsSource } from "./io_pb";
import { file_google_cloud_aiplatform_v1beta1_io } from "./io_pb";
import type { JobState } from "./job_state_pb";
import { file_google_cloud_aiplatform_v1beta1_job_state } from "./job_state_pb";
import type { BatchDedicatedResources, ResourcesConsumed } from "./machine_resources_pb";
import { file_google_cloud_aiplatform_v1beta1_machine_resources } from "./machine_resources_pb";
import type { ManualBatchTuningParameters } from "./manual_batch_tuning_parameters_pb";
import { file_google_cloud_aiplatform_v1beta1_manual_batch_tuning_parameters } from "./manual_batch_tuning_parameters_pb";
import type { ModelMonitoringStatsAnomalies } from "./model_deployment_monitoring_job_pb";
import { file_google_cloud_aiplatform_v1beta1_model_deployment_monitoring_job } from "./model_deployment_monitoring_job_pb";
import type { ModelMonitoringConfig } from "./model_monitoring_pb";
import { file_google_cloud_aiplatform_v1beta1_model_monitoring } from "./model_monitoring_pb";
import type { UnmanagedContainerModel } from "./unmanaged_container_model_pb";
import { file_google_cloud_aiplatform_v1beta1_unmanaged_container_model } from "./unmanaged_container_model_pb";
import type { Timestamp, Value } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_struct, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../rpc/status_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1beta1/batch_prediction_job.proto.
 */
export const file_google_cloud_aiplatform_v1beta1_batch_prediction_job: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_aiplatform_v1beta1_completion_stats, file_google_cloud_aiplatform_v1beta1_encryption_spec, file_google_cloud_aiplatform_v1beta1_explanation, file_google_cloud_aiplatform_v1beta1_io, file_google_cloud_aiplatform_v1beta1_job_state, file_google_cloud_aiplatform_v1beta1_machine_resources, file_google_cloud_aiplatform_v1beta1_manual_batch_tuning_parameters, file_google_cloud_aiplatform_v1beta1_model_deployment_monitoring_job, file_google_cloud_aiplatform_v1beta1_model_monitoring, file_google_cloud_aiplatform_v1beta1_unmanaged_container_model, file_google_protobuf_struct, file_google_protobuf_timestamp, file_google_rpc_status]);

/**
 * A job that uses a
 * [Model][google.cloud.aiplatform.v1beta1.BatchPredictionJob.model] to produce
 * predictions on multiple [input
 * instances][google.cloud.aiplatform.v1beta1.BatchPredictionJob.input_config].
 * If predictions for significant portion of the instances fail, the job may
 * finish without attempting predictions for all remaining instances.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.BatchPredictionJob
 */
export type BatchPredictionJob = Message<"google.cloud.aiplatform.v1beta1.BatchPredictionJob"> & {
  /**
   * Output only. Resource name of the BatchPredictionJob.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The user-defined name of this BatchPredictionJob.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * The name of the Model resource that produces the predictions via this job,
   * must share the same ancestor Location.
   * Starting this job has no impact on any existing deployments of the Model
   * and their resources.
   * Exactly one of model and unmanaged_container_model must be set.
   *
   * The model resource name may contain version id or version alias to specify
   * the version.
   *  Example: `projects/{project}/locations/{location}/models/{model}@2`
   *              or
   *            `projects/{project}/locations/{location}/models/{model}@golden`
   * if no version is specified, the default version will be deployed.
   *
   * The model resource could also be a publisher model.
   *  Example: `publishers/{publisher}/models/{model}`
   *              or
   *           `projects/{project}/locations/{location}/publishers/{publisher}/models/{model}`
   *
   * @generated from field: string model = 3;
   */
  model: string;

  /**
   * Output only. The version ID of the Model that produces the predictions via
   * this job.
   *
   * @generated from field: string model_version_id = 30;
   */
  modelVersionId: string;

  /**
   * Contains model information necessary to perform batch prediction without
   * requiring uploading to model registry.
   * Exactly one of model and unmanaged_container_model must be set.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.UnmanagedContainerModel unmanaged_container_model = 28;
   */
  unmanagedContainerModel?: UnmanagedContainerModel;

  /**
   * Required. Input configuration of the instances on which predictions are
   * performed. The schema of any single instance may be specified via the
   * [Model's][google.cloud.aiplatform.v1beta1.BatchPredictionJob.model]
   * [PredictSchemata's][google.cloud.aiplatform.v1beta1.Model.predict_schemata]
   * [instance_schema_uri][google.cloud.aiplatform.v1beta1.PredictSchemata.instance_schema_uri].
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.BatchPredictionJob.InputConfig input_config = 4;
   */
  inputConfig?: BatchPredictionJob_InputConfig;

  /**
   * Configuration for how to convert batch prediction input instances to the
   * prediction instances that are sent to the Model.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig instance_config = 27;
   */
  instanceConfig?: BatchPredictionJob_InstanceConfig;

  /**
   * The parameters that govern the predictions. The schema of the parameters
   * may be specified via the
   * [Model's][google.cloud.aiplatform.v1beta1.BatchPredictionJob.model]
   * [PredictSchemata's][google.cloud.aiplatform.v1beta1.Model.predict_schemata]
   * [parameters_schema_uri][google.cloud.aiplatform.v1beta1.PredictSchemata.parameters_schema_uri].
   *
   * @generated from field: google.protobuf.Value model_parameters = 5;
   */
  modelParameters?: Value;

  /**
   * Required. The Configuration specifying where output predictions should
   * be written.
   * The schema of any single prediction may be specified as a concatenation
   * of [Model's][google.cloud.aiplatform.v1beta1.BatchPredictionJob.model]
   * [PredictSchemata's][google.cloud.aiplatform.v1beta1.Model.predict_schemata]
   * [instance_schema_uri][google.cloud.aiplatform.v1beta1.PredictSchemata.instance_schema_uri]
   * and
   * [prediction_schema_uri][google.cloud.aiplatform.v1beta1.PredictSchemata.prediction_schema_uri].
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig output_config = 6;
   */
  outputConfig?: BatchPredictionJob_OutputConfig;

  /**
   * The config of resources used by the Model during the batch prediction. If
   * the Model
   * [supports][google.cloud.aiplatform.v1beta1.Model.supported_deployment_resources_types]
   * DEDICATED_RESOURCES this config may be provided (and the job will use these
   * resources), if the Model doesn't support AUTOMATIC_RESOURCES, this config
   * must be provided.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.BatchDedicatedResources dedicated_resources = 7;
   */
  dedicatedResources?: BatchDedicatedResources;

  /**
   * The service account that the DeployedModel's container runs as. If not
   * specified, a system generated one will be used, which
   * has minimal permissions and the custom container, if used, may not have
   * enough permission to access other Google Cloud resources.
   *
   * Users deploying the Model must have the `iam.serviceAccounts.actAs`
   * permission on this service account.
   *
   * @generated from field: string service_account = 29;
   */
  serviceAccount: string;

  /**
   * Immutable. Parameters configuring the batch behavior. Currently only
   * applicable when
   * [dedicated_resources][google.cloud.aiplatform.v1beta1.BatchPredictionJob.dedicated_resources]
   * are used (in other cases Vertex AI does the tuning itself).
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.ManualBatchTuningParameters manual_batch_tuning_parameters = 8;
   */
  manualBatchTuningParameters?: ManualBatchTuningParameters;

  /**
   * Generate explanation with the batch prediction results.
   *
   * When set to `true`, the batch prediction output changes based on the
   * `predictions_format` field of the
   * [BatchPredictionJob.output_config][google.cloud.aiplatform.v1beta1.BatchPredictionJob.output_config]
   * object:
   *
   *  * `bigquery`: output includes a column named `explanation`. The value
   *    is a struct that conforms to the
   *    [Explanation][google.cloud.aiplatform.v1beta1.Explanation] object.
   *  * `jsonl`: The JSON objects on each line include an additional entry
   *    keyed `explanation`. The value of the entry is a JSON object that
   *    conforms to the
   *    [Explanation][google.cloud.aiplatform.v1beta1.Explanation] object.
   *  * `csv`: Generating explanations for CSV format is not supported.
   *
   * If this field is set to true, either the
   * [Model.explanation_spec][google.cloud.aiplatform.v1beta1.Model.explanation_spec]
   * or
   * [explanation_spec][google.cloud.aiplatform.v1beta1.BatchPredictionJob.explanation_spec]
   * must be populated.
   *
   * @generated from field: bool generate_explanation = 23;
   */
  generateExplanation: boolean;

  /**
   * Explanation configuration for this BatchPredictionJob. Can be
   * specified only if
   * [generate_explanation][google.cloud.aiplatform.v1beta1.BatchPredictionJob.generate_explanation]
   * is set to `true`.
   *
   * This value overrides the value of
   * [Model.explanation_spec][google.cloud.aiplatform.v1beta1.Model.explanation_spec].
   * All fields of
   * [explanation_spec][google.cloud.aiplatform.v1beta1.BatchPredictionJob.explanation_spec]
   * are optional in the request. If a field of the
   * [explanation_spec][google.cloud.aiplatform.v1beta1.BatchPredictionJob.explanation_spec]
   * object is not populated, the corresponding field of the
   * [Model.explanation_spec][google.cloud.aiplatform.v1beta1.Model.explanation_spec]
   * object is inherited.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.ExplanationSpec explanation_spec = 25;
   */
  explanationSpec?: ExplanationSpec;

  /**
   * Output only. Information further describing the output of this job.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputInfo output_info = 9;
   */
  outputInfo?: BatchPredictionJob_OutputInfo;

  /**
   * Output only. The detailed state of the job.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.JobState state = 10;
   */
  state: JobState;

  /**
   * Output only. Only populated when the job's state is JOB_STATE_FAILED or
   * JOB_STATE_CANCELLED.
   *
   * @generated from field: google.rpc.Status error = 11;
   */
  error?: Status;

  /**
   * Output only. Partial failures encountered.
   * For example, single files that can't be read.
   * This field never exceeds 20 entries.
   * Status details fields contain standard Google Cloud error details.
   *
   * @generated from field: repeated google.rpc.Status partial_failures = 12;
   */
  partialFailures: Status[];

  /**
   * Output only. Information about resources that had been consumed by this
   * job. Provided in real time at best effort basis, as well as a final value
   * once the job completes.
   *
   * Note: This field currently may be not populated for batch predictions that
   * use AutoML Models.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.ResourcesConsumed resources_consumed = 13;
   */
  resourcesConsumed?: ResourcesConsumed;

  /**
   * Output only. Statistics on completed and failed prediction instances.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.CompletionStats completion_stats = 14;
   */
  completionStats?: CompletionStats;

  /**
   * Output only. Time when the BatchPredictionJob was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 15;
   */
  createTime?: Timestamp;

  /**
   * Output only. Time when the BatchPredictionJob for the first time entered
   * the `JOB_STATE_RUNNING` state.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 16;
   */
  startTime?: Timestamp;

  /**
   * Output only. Time when the BatchPredictionJob entered any of the following
   * states: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 17;
   */
  endTime?: Timestamp;

  /**
   * Output only. Time when the BatchPredictionJob was most recently updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 18;
   */
  updateTime?: Timestamp;

  /**
   * The labels with user-defined metadata to organize BatchPredictionJobs.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   *
   * See https://goo.gl/xmQnxf for more information and examples of labels.
   *
   * @generated from field: map<string, string> labels = 19;
   */
  labels: { [key: string]: string };

  /**
   * Customer-managed encryption key options for a BatchPredictionJob. If this
   * is set, then all resources created by the BatchPredictionJob will be
   * encrypted with the provided encryption key.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.EncryptionSpec encryption_spec = 24;
   */
  encryptionSpec?: EncryptionSpec;

  /**
   * Model monitoring config will be used for analysis model behaviors, based on
   * the input and output to the batch prediction job, as well as the provided
   * training dataset.
   *
   * @generated from field: google.cloud.aiplatform.v1beta1.ModelMonitoringConfig model_monitoring_config = 26;
   */
  modelMonitoringConfig?: ModelMonitoringConfig;

  /**
   * Get batch prediction job monitoring statistics.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1beta1.ModelMonitoringStatsAnomalies model_monitoring_stats_anomalies = 31;
   */
  modelMonitoringStatsAnomalies: ModelMonitoringStatsAnomalies[];

  /**
   * Output only. The running status of the model monitoring pipeline.
   *
   * @generated from field: google.rpc.Status model_monitoring_status = 32;
   */
  modelMonitoringStatus?: Status;

  /**
   * For custom-trained Models and AutoML Tabular Models, the container of the
   * DeployedModel instances will send `stderr` and `stdout` streams to
   * Cloud Logging by default. Please note that the logs incur cost,
   * which are subject to [Cloud Logging
   * pricing](https://cloud.google.com/logging/pricing).
   *
   * User can disable container logging by setting this flag to true.
   *
   * @generated from field: bool disable_container_logging = 34;
   */
  disableContainerLogging: boolean;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzs = 36;
   */
  satisfiesPzs: boolean;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzi = 37;
   */
  satisfiesPzi: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.BatchPredictionJob.
 * Use `create(BatchPredictionJobSchema)` to create a new message.
 */
export const BatchPredictionJobSchema: GenMessage<BatchPredictionJob> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_batch_prediction_job, 0);

/**
 * Configures the input to
 * [BatchPredictionJob][google.cloud.aiplatform.v1beta1.BatchPredictionJob].
 * See
 * [Model.supported_input_storage_formats][google.cloud.aiplatform.v1beta1.Model.supported_input_storage_formats]
 * for Model's supported input formats, and how instances should be expressed
 * via any of them.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.BatchPredictionJob.InputConfig
 */
export type BatchPredictionJob_InputConfig = Message<"google.cloud.aiplatform.v1beta1.BatchPredictionJob.InputConfig"> & {
  /**
   * Required. The source of the input.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.BatchPredictionJob.InputConfig.source
   */
  source: {
    /**
     * The Cloud Storage location for the input instances.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsSource gcs_source = 2;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * The BigQuery location of the input table.
     * The schema of the table should be in the format described by the given
     * context OpenAPI Schema, if one is provided. The table may contain
     * additional columns that are not described by the schema, and they will
     * be ignored.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.BigQuerySource bigquery_source = 3;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The format in which instances are given, must be one of the
   * [Model's][google.cloud.aiplatform.v1beta1.BatchPredictionJob.model]
   * [supported_input_storage_formats][google.cloud.aiplatform.v1beta1.Model.supported_input_storage_formats].
   *
   * @generated from field: string instances_format = 1;
   */
  instancesFormat: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.BatchPredictionJob.InputConfig.
 * Use `create(BatchPredictionJob_InputConfigSchema)` to create a new message.
 */
export const BatchPredictionJob_InputConfigSchema: GenMessage<BatchPredictionJob_InputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_batch_prediction_job, 0, 0);

/**
 * Configuration defining how to transform batch prediction input instances to
 * the instances that the Model accepts.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig
 */
export type BatchPredictionJob_InstanceConfig = Message<"google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig"> & {
  /**
   * The format of the instance that the Model accepts. Vertex AI will
   * convert compatible
   * [batch prediction input instance
   * formats][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InputConfig.instances_format]
   * to the specified format.
   *
   * Supported values are:
   *
   * * `object`: Each input is converted to JSON object format.
   *     * For `bigquery`, each row is converted to an object.
   *     * For `jsonl`, each line of the JSONL input must be an object.
   *     * Does not apply to `csv`, `file-list`, `tf-record`, or
   *       `tf-record-gzip`.
   *
   * * `array`: Each input is converted to JSON array format.
   *     * For `bigquery`, each row is converted to an array. The order
   *       of columns is determined by the BigQuery column order, unless
   *       [included_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.included_fields]
   *       is populated.
   *       [included_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.included_fields]
   *       must be populated for specifying field orders.
   *     * For `jsonl`, if each line of the JSONL input is an object,
   *       [included_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.included_fields]
   *       must be populated for specifying field orders.
   *     * Does not apply to `csv`, `file-list`, `tf-record`, or
   *       `tf-record-gzip`.
   *
   * If not specified, Vertex AI converts the batch prediction input as
   * follows:
   *
   *  * For `bigquery` and `csv`, the behavior is the same as `array`. The
   *    order of columns is the same as defined in the file or table, unless
   *    [included_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.included_fields]
   *    is populated.
   *  * For `jsonl`, the prediction instance format is determined by
   *    each line of the input.
   *  * For `tf-record`/`tf-record-gzip`, each record will be converted to
   *    an object in the format of `{"b64": <value>}`, where `<value>` is
   *    the Base64-encoded string of the content of the record.
   *  * For `file-list`, each file in the list will be converted to an
   *    object in the format of `{"b64": <value>}`, where `<value>` is
   *    the Base64-encoded string of the content of the file.
   *
   * @generated from field: string instance_type = 1;
   */
  instanceType: string;

  /**
   * The name of the field that is considered as a key.
   *
   * The values identified by the key field is not included in the transformed
   * instances that is sent to the Model. This is similar to
   * specifying this name of the field in
   * [excluded_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.excluded_fields].
   * In addition, the batch prediction output will not include the instances.
   * Instead the output will only include the value of the key field, in a
   * field named `key` in the output:
   *
   *  * For `jsonl` output format, the output will have a `key` field
   *    instead of the `instance` field.
   *  * For `csv`/`bigquery` output format, the output will have have a `key`
   *    column instead of the instance feature columns.
   *
   * The input must be JSONL with objects at each line, CSV, BigQuery
   * or TfRecord.
   *
   * @generated from field: string key_field = 2;
   */
  keyField: string;

  /**
   * Fields that will be included in the prediction instance that is
   * sent to the Model.
   *
   * If
   * [instance_type][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.instance_type]
   * is `array`, the order of field names in included_fields also determines
   * the order of the values in the array.
   *
   * When included_fields is populated,
   * [excluded_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.excluded_fields]
   * must be empty.
   *
   * The input must be JSONL with objects at each line, BigQuery
   * or TfRecord.
   *
   * @generated from field: repeated string included_fields = 3;
   */
  includedFields: string[];

  /**
   * Fields that will be excluded in the prediction instance that is
   * sent to the Model.
   *
   * Excluded will be attached to the batch prediction output if
   * [key_field][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.key_field]
   * is not specified.
   *
   * When excluded_fields is populated,
   * [included_fields][google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.included_fields]
   * must be empty.
   *
   * The input must be JSONL with objects at each line, BigQuery
   * or TfRecord.
   *
   * @generated from field: repeated string excluded_fields = 4;
   */
  excludedFields: string[];
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.BatchPredictionJob.InstanceConfig.
 * Use `create(BatchPredictionJob_InstanceConfigSchema)` to create a new message.
 */
export const BatchPredictionJob_InstanceConfigSchema: GenMessage<BatchPredictionJob_InstanceConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_batch_prediction_job, 0, 1);

/**
 * Configures the output of
 * [BatchPredictionJob][google.cloud.aiplatform.v1beta1.BatchPredictionJob].
 * See
 * [Model.supported_output_storage_formats][google.cloud.aiplatform.v1beta1.Model.supported_output_storage_formats]
 * for supported output formats, and how predictions are expressed via any of
 * them.
 *
 * @generated from message google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig
 */
export type BatchPredictionJob_OutputConfig = Message<"google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig"> & {
  /**
   * Required. The destination of the output.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig.destination
   */
  destination: {
    /**
     * The Cloud Storage location of the directory where the output is
     * to be written to. In the given directory a new directory is created.
     * Its name is `prediction-<model-display-name>-<job-create-time>`,
     * where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.
     * Inside of it files `predictions_0001.<extension>`,
     * `predictions_0002.<extension>`, ..., `predictions_N.<extension>`
     * are created where `<extension>` depends on chosen
     * [predictions_format][google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig.predictions_format],
     * and N may equal 0001 and depends on the total number of successfully
     * predicted instances. If the Model has both
     * [instance][google.cloud.aiplatform.v1beta1.PredictSchemata.instance_schema_uri]
     * and
     * [prediction][google.cloud.aiplatform.v1beta1.PredictSchemata.parameters_schema_uri]
     * schemata defined then each such file contains predictions as per the
     * [predictions_format][google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig.predictions_format].
     * If prediction for any instance failed (partially or completely), then
     * an additional `errors_0001.<extension>`, `errors_0002.<extension>`,...,
     * `errors_N.<extension>` files are created (N depends on total number
     * of failed predictions). These files contain the failed instances,
     * as per their schema, followed by an additional `error` field which as
     * value has [google.rpc.Status][google.rpc.Status]
     * containing only `code` and `message` fields.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.GcsDestination gcs_destination = 2;
     */
    value: GcsDestination;
    case: "gcsDestination";
  } | {
    /**
     * The BigQuery project or dataset location where the output is to be
     * written to. If project is provided, a new dataset is created with name
     * `prediction_<model-display-name>_<job-create-time>`
     * where <model-display-name> is made
     * BigQuery-dataset-name compatible (for example, most special characters
     * become underscores), and timestamp is in
     * YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset
     * two tables will be created, `predictions`, and `errors`.
     * If the Model has both
     * [instance][google.cloud.aiplatform.v1beta1.PredictSchemata.instance_schema_uri]
     * and
     * [prediction][google.cloud.aiplatform.v1beta1.PredictSchemata.parameters_schema_uri]
     * schemata defined then the tables have columns as follows: The
     * `predictions` table contains instances for which the prediction
     * succeeded, it has columns as per a concatenation of the Model's
     * instance and prediction schemata. The `errors` table contains rows for
     * which the prediction has failed, it has instance columns, as per the
     * instance schema, followed by a single "errors" column, which as values
     * has [google.rpc.Status][google.rpc.Status]
     * represented as a STRUCT, and containing only `code` and `message`.
     *
     * @generated from field: google.cloud.aiplatform.v1beta1.BigQueryDestination bigquery_destination = 3;
     */
    value: BigQueryDestination;
    case: "bigqueryDestination";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The format in which Vertex AI gives the predictions, must be
   * one of the
   * [Model's][google.cloud.aiplatform.v1beta1.BatchPredictionJob.model]
   * [supported_output_storage_formats][google.cloud.aiplatform.v1beta1.Model.supported_output_storage_formats].
   *
   * @generated from field: string predictions_format = 1;
   */
  predictionsFormat: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputConfig.
 * Use `create(BatchPredictionJob_OutputConfigSchema)` to create a new message.
 */
export const BatchPredictionJob_OutputConfigSchema: GenMessage<BatchPredictionJob_OutputConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_batch_prediction_job, 0, 2);

/**
 * Further describes this job's output.
 * Supplements
 * [output_config][google.cloud.aiplatform.v1beta1.BatchPredictionJob.output_config].
 *
 * @generated from message google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputInfo
 */
export type BatchPredictionJob_OutputInfo = Message<"google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputInfo"> & {
  /**
   * The output location into which prediction output is written.
   *
   * @generated from oneof google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputInfo.output_location
   */
  outputLocation: {
    /**
     * Output only. The full path of the Cloud Storage directory created, into
     * which the prediction output is written.
     *
     * @generated from field: string gcs_output_directory = 1;
     */
    value: string;
    case: "gcsOutputDirectory";
  } | {
    /**
     * Output only. The path of the BigQuery dataset created, in
     * `bq://projectId.bqDatasetId`
     * format, into which the prediction output is written.
     *
     * @generated from field: string bigquery_output_dataset = 2;
     */
    value: string;
    case: "bigqueryOutputDataset";
  } | { case: undefined; value?: undefined };

  /**
   * Output only. The name of the BigQuery table created, in
   * `predictions_<timestamp>`
   * format, into which the prediction output is written.
   * Can be used by UI to generate the BigQuery output path, for example.
   *
   * @generated from field: string bigquery_output_table = 4;
   */
  bigqueryOutputTable: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1beta1.BatchPredictionJob.OutputInfo.
 * Use `create(BatchPredictionJob_OutputInfoSchema)` to create a new message.
 */
export const BatchPredictionJob_OutputInfoSchema: GenMessage<BatchPredictionJob_OutputInfo> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1beta1_batch_prediction_job, 0, 3);

