// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1/dataset.proto (package google.cloud.aiplatform.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { EncryptionSpec } from "./encryption_spec_pb";
import { file_google_cloud_aiplatform_v1_encryption_spec } from "./encryption_spec_pb";
import type { GcsDestination, GcsSource } from "./io_pb";
import { file_google_cloud_aiplatform_v1_io } from "./io_pb";
import type { SavedQuery } from "./saved_query_pb";
import { file_google_cloud_aiplatform_v1_saved_query } from "./saved_query_pb";
import type { Timestamp, Value } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_struct, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1/dataset.proto.
 */
export const file_google_cloud_aiplatform_v1_dataset: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_aiplatform_v1_encryption_spec, file_google_cloud_aiplatform_v1_io, file_google_cloud_aiplatform_v1_saved_query, file_google_protobuf_struct, file_google_protobuf_timestamp]);

/**
 * A collection of DataItems and Annotations on them.
 *
 * @generated from message google.cloud.aiplatform.v1.Dataset
 */
export type Dataset = Message<"google.cloud.aiplatform.v1.Dataset"> & {
  /**
   * Output only. Identifier. The resource name of the Dataset.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The user-defined name of the Dataset.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * The description of the Dataset.
   *
   * @generated from field: string description = 16;
   */
  description: string;

  /**
   * Required. Points to a YAML file stored on Google Cloud Storage describing
   * additional information about the Dataset. The schema is defined as an
   * OpenAPI 3.0.2 Schema Object. The schema files that can be used here are
   * found in gs://google-cloud-aiplatform/schema/dataset/metadata/.
   *
   * @generated from field: string metadata_schema_uri = 3;
   */
  metadataSchemaUri: string;

  /**
   * Required. Additional information about the Dataset.
   *
   * @generated from field: google.protobuf.Value metadata = 8;
   */
  metadata?: Value;

  /**
   * Output only. The number of DataItems in this Dataset. Only apply for
   * non-structured Dataset.
   *
   * @generated from field: int64 data_item_count = 10;
   */
  dataItemCount: bigint;

  /**
   * Output only. Timestamp when this Dataset was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 4;
   */
  createTime?: Timestamp;

  /**
   * Output only. Timestamp when this Dataset was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 5;
   */
  updateTime?: Timestamp;

  /**
   * Used to perform consistent read-modify-write updates. If not set, a blind
   * "overwrite" update happens.
   *
   * @generated from field: string etag = 6;
   */
  etag: string;

  /**
   * The labels with user-defined metadata to organize your Datasets.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   * No more than 64 user labels can be associated with one Dataset (System
   * labels are excluded).
   *
   * See https://goo.gl/xmQnxf for more information and examples of labels.
   * System reserved label keys are prefixed with "aiplatform.googleapis.com/"
   * and are immutable. Following system labels exist for each Dataset:
   *
   * * "aiplatform.googleapis.com/dataset_metadata_schema": output only, its
   *   value is the
   *   [metadata_schema's][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri]
   *   title.
   *
   * @generated from field: map<string, string> labels = 7;
   */
  labels: { [key: string]: string };

  /**
   * All SavedQueries belong to the Dataset will be returned in List/Get
   * Dataset response. The annotation_specs field
   * will not be populated except for UI cases which will only use
   * [annotation_spec_count][google.cloud.aiplatform.v1.SavedQuery.annotation_spec_count].
   * In CreateDataset request, a SavedQuery is created together if
   * this field is set, up to one SavedQuery can be set in CreateDatasetRequest.
   * The SavedQuery should not contain any AnnotationSpec.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.SavedQuery saved_queries = 9;
   */
  savedQueries: SavedQuery[];

  /**
   * Customer-managed encryption key spec for a Dataset. If set, this Dataset
   * and all sub-resources of this Dataset will be secured by this key.
   *
   * @generated from field: google.cloud.aiplatform.v1.EncryptionSpec encryption_spec = 11;
   */
  encryptionSpec?: EncryptionSpec;

  /**
   * Output only. The resource name of the Artifact that was created in
   * MetadataStore when creating the Dataset. The Artifact resource name pattern
   * is
   * `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
   *
   * @generated from field: string metadata_artifact = 17;
   */
  metadataArtifact: string;

  /**
   * Optional. Reference to the public base model last used by the dataset. Only
   * set for prompt datasets.
   *
   * @generated from field: string model_reference = 18;
   */
  modelReference: string;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzs = 19;
   */
  satisfiesPzs: boolean;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzi = 20;
   */
  satisfiesPzi: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1.Dataset.
 * Use `create(DatasetSchema)` to create a new message.
 */
export const DatasetSchema: GenMessage<Dataset> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_dataset, 0);

/**
 * Describes the location from where we import data into a Dataset, together
 * with the labels that will be applied to the DataItems and the Annotations.
 *
 * @generated from message google.cloud.aiplatform.v1.ImportDataConfig
 */
export type ImportDataConfig = Message<"google.cloud.aiplatform.v1.ImportDataConfig"> & {
  /**
   * The source of the input.
   *
   * @generated from oneof google.cloud.aiplatform.v1.ImportDataConfig.source
   */
  source: {
    /**
     * The Google Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.aiplatform.v1.GcsSource gcs_source = 1;
     */
    value: GcsSource;
    case: "gcsSource";
  } | { case: undefined; value?: undefined };

  /**
   * Labels that will be applied to newly imported DataItems. If an identical
   * DataItem as one being imported already exists in the Dataset, then these
   * labels will be appended to these of the already existing one, and if labels
   * with identical key is imported before, the old label value will be
   * overwritten. If two DataItems are identical in the same import data
   * operation, the labels will be combined and if key collision happens in this
   * case, one of the values will be picked randomly. Two DataItems are
   * considered identical if their content bytes are identical (e.g. image bytes
   * or pdf bytes).
   * These labels will be overridden by Annotation labels specified inside index
   * file referenced by
   * [import_schema_uri][google.cloud.aiplatform.v1.ImportDataConfig.import_schema_uri],
   * e.g. jsonl file.
   *
   * @generated from field: map<string, string> data_item_labels = 2;
   */
  dataItemLabels: { [key: string]: string };

  /**
   * Labels that will be applied to newly imported Annotations. If two
   * Annotations are identical, one of them will be deduped. Two Annotations are
   * considered identical if their
   * [payload][google.cloud.aiplatform.v1.Annotation.payload],
   * [payload_schema_uri][google.cloud.aiplatform.v1.Annotation.payload_schema_uri]
   * and all of their [labels][google.cloud.aiplatform.v1.Annotation.labels] are
   * the same. These labels will be overridden by Annotation labels specified
   * inside index file referenced by
   * [import_schema_uri][google.cloud.aiplatform.v1.ImportDataConfig.import_schema_uri],
   * e.g. jsonl file.
   *
   * @generated from field: map<string, string> annotation_labels = 3;
   */
  annotationLabels: { [key: string]: string };

  /**
   * Required. Points to a YAML file stored on Google Cloud Storage describing
   * the import format. Validation will be done against the schema. The schema
   * is defined as an [OpenAPI 3.0.2 Schema
   * Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
   *
   * @generated from field: string import_schema_uri = 4;
   */
  importSchemaUri: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1.ImportDataConfig.
 * Use `create(ImportDataConfigSchema)` to create a new message.
 */
export const ImportDataConfigSchema: GenMessage<ImportDataConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_dataset, 1);

/**
 * Describes what part of the Dataset is to be exported, the destination of
 * the export and how to export.
 *
 * @generated from message google.cloud.aiplatform.v1.ExportDataConfig
 */
export type ExportDataConfig = Message<"google.cloud.aiplatform.v1.ExportDataConfig"> & {
  /**
   * The destination of the output.
   *
   * @generated from oneof google.cloud.aiplatform.v1.ExportDataConfig.destination
   */
  destination: {
    /**
     * The Google Cloud Storage location where the output is to be written to.
     * In the given directory a new directory will be created with name:
     * `export-data-<dataset-display-name>-<timestamp-of-export-call>` where
     * timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All export
     * output will be written into that directory. Inside that directory,
     * annotations with the same schema will be grouped into sub directories
     * which are named with the corresponding annotations' schema title. Inside
     * these sub directories, a schema.yaml will be created to describe the
     * output format.
     *
     * @generated from field: google.cloud.aiplatform.v1.GcsDestination gcs_destination = 1;
     */
    value: GcsDestination;
    case: "gcsDestination";
  } | { case: undefined; value?: undefined };

  /**
   * The instructions how the export data should be split between the
   * training, validation and test sets.
   *
   * @generated from oneof google.cloud.aiplatform.v1.ExportDataConfig.split
   */
  split: {
    /**
     * Split based on fractions defining the size of each set.
     *
     * @generated from field: google.cloud.aiplatform.v1.ExportFractionSplit fraction_split = 5;
     */
    value: ExportFractionSplit;
    case: "fractionSplit";
  } | {
    /**
     * Split based on the provided filters for each set.
     *
     * @generated from field: google.cloud.aiplatform.v1.ExportFilterSplit filter_split = 7;
     */
    value: ExportFilterSplit;
    case: "filterSplit";
  } | { case: undefined; value?: undefined };

  /**
   * An expression for filtering what part of the Dataset is to be exported.
   * Only Annotations that match this filter will be exported. The filter syntax
   * is the same as in
   * [ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations].
   *
   * @generated from field: string annotations_filter = 2;
   */
  annotationsFilter: string;

  /**
   * The ID of a SavedQuery (annotation set) under the Dataset specified by
   * [dataset_id][] used for filtering Annotations for training.
   *
   * Only used for custom training data export use cases.
   * Only applicable to Datasets that have SavedQueries.
   *
   * Only Annotations that are associated with this SavedQuery are used in
   * respectively training. When used in conjunction with
   * [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter],
   * the Annotations used for training are filtered by both
   * [saved_query_id][google.cloud.aiplatform.v1.ExportDataConfig.saved_query_id]
   * and
   * [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter].
   *
   * Only one of
   * [saved_query_id][google.cloud.aiplatform.v1.ExportDataConfig.saved_query_id]
   * and
   * [annotation_schema_uri][google.cloud.aiplatform.v1.ExportDataConfig.annotation_schema_uri]
   * should be specified as both of them represent the same thing: problem type.
   *
   * @generated from field: string saved_query_id = 11;
   */
  savedQueryId: string;

  /**
   * The Cloud Storage URI that points to a YAML file describing the annotation
   * schema. The schema is defined as an OpenAPI 3.0.2 [Schema
   * Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
   * The schema files that can be used here are found in
   * gs://google-cloud-aiplatform/schema/dataset/annotation/, note that the
   * chosen schema must be consistent with
   * [metadata][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] of the
   * Dataset specified by [dataset_id][].
   *
   * Only used for custom training data export use cases.
   * Only applicable to Datasets that have DataItems and Annotations.
   *
   * Only Annotations that both match this schema and belong to DataItems not
   * ignored by the split method are used in respectively training, validation
   * or test role, depending on the role of the DataItem they are on.
   *
   * When used in conjunction with
   * [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter],
   * the Annotations used for training are filtered by both
   * [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter]
   * and
   * [annotation_schema_uri][google.cloud.aiplatform.v1.ExportDataConfig.annotation_schema_uri].
   *
   * @generated from field: string annotation_schema_uri = 12;
   */
  annotationSchemaUri: string;

  /**
   * Indicates the usage of the exported files.
   *
   * @generated from field: google.cloud.aiplatform.v1.ExportDataConfig.ExportUse export_use = 4;
   */
  exportUse: ExportDataConfig_ExportUse;
};

/**
 * Describes the message google.cloud.aiplatform.v1.ExportDataConfig.
 * Use `create(ExportDataConfigSchema)` to create a new message.
 */
export const ExportDataConfigSchema: GenMessage<ExportDataConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_dataset, 2);

/**
 * ExportUse indicates the usage of the exported files. It restricts file
 * destination, format, annotations to be exported, whether to allow
 * unannotated data to be exported and whether to clone files to temp Cloud
 * Storage bucket.
 *
 * @generated from enum google.cloud.aiplatform.v1.ExportDataConfig.ExportUse
 */
export enum ExportDataConfig_ExportUse {
  /**
   * Regular user export.
   *
   * @generated from enum value: EXPORT_USE_UNSPECIFIED = 0;
   */
  EXPORT_USE_UNSPECIFIED = 0,

  /**
   * Export for custom code training.
   *
   * @generated from enum value: CUSTOM_CODE_TRAINING = 6;
   */
  CUSTOM_CODE_TRAINING = 6,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.ExportDataConfig.ExportUse.
 */
export const ExportDataConfig_ExportUseSchema: GenEnum<ExportDataConfig_ExportUse> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_dataset, 2, 0);

/**
 * Assigns the input data to training, validation, and test sets as per the
 * given fractions. Any of `training_fraction`, `validation_fraction` and
 * `test_fraction` may optionally be provided, they must sum to up to 1. If the
 * provided ones sum to less than 1, the remainder is assigned to sets as
 * decided by Vertex AI. If none of the fractions are set, by default roughly
 * 80% of data is used for training, 10% for validation, and 10% for test.
 *
 * @generated from message google.cloud.aiplatform.v1.ExportFractionSplit
 */
export type ExportFractionSplit = Message<"google.cloud.aiplatform.v1.ExportFractionSplit"> & {
  /**
   * The fraction of the input data that is to be used to train the Model.
   *
   * @generated from field: double training_fraction = 1;
   */
  trainingFraction: number;

  /**
   * The fraction of the input data that is to be used to validate the Model.
   *
   * @generated from field: double validation_fraction = 2;
   */
  validationFraction: number;

  /**
   * The fraction of the input data that is to be used to evaluate the Model.
   *
   * @generated from field: double test_fraction = 3;
   */
  testFraction: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1.ExportFractionSplit.
 * Use `create(ExportFractionSplitSchema)` to create a new message.
 */
export const ExportFractionSplitSchema: GenMessage<ExportFractionSplit> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_dataset, 3);

/**
 * Assigns input data to training, validation, and test sets based on the given
 * filters, data pieces not matched by any filter are ignored. Currently only
 * supported for Datasets containing DataItems.
 * If any of the filters in this message are to match nothing, then they can be
 * set as '-' (the minus sign).
 *
 * Supported only for unstructured Datasets.
 *
 * @generated from message google.cloud.aiplatform.v1.ExportFilterSplit
 */
export type ExportFilterSplit = Message<"google.cloud.aiplatform.v1.ExportFilterSplit"> & {
  /**
   * Required. A filter on DataItems of the Dataset. DataItems that match
   * this filter are used to train the Model. A filter with same syntax
   * as the one used in
   * [DatasetService.ListDataItems][google.cloud.aiplatform.v1.DatasetService.ListDataItems]
   * may be used. If a single DataItem is matched by more than one of the
   * FilterSplit filters, then it is assigned to the first set that applies to
   * it in the training, validation, test order.
   *
   * @generated from field: string training_filter = 1;
   */
  trainingFilter: string;

  /**
   * Required. A filter on DataItems of the Dataset. DataItems that match
   * this filter are used to validate the Model. A filter with same syntax
   * as the one used in
   * [DatasetService.ListDataItems][google.cloud.aiplatform.v1.DatasetService.ListDataItems]
   * may be used. If a single DataItem is matched by more than one of the
   * FilterSplit filters, then it is assigned to the first set that applies to
   * it in the training, validation, test order.
   *
   * @generated from field: string validation_filter = 2;
   */
  validationFilter: string;

  /**
   * Required. A filter on DataItems of the Dataset. DataItems that match
   * this filter are used to test the Model. A filter with same syntax
   * as the one used in
   * [DatasetService.ListDataItems][google.cloud.aiplatform.v1.DatasetService.ListDataItems]
   * may be used. If a single DataItem is matched by more than one of the
   * FilterSplit filters, then it is assigned to the first set that applies to
   * it in the training, validation, test order.
   *
   * @generated from field: string test_filter = 3;
   */
  testFilter: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1.ExportFilterSplit.
 * Use `create(ExportFilterSplitSchema)` to create a new message.
 */
export const ExportFilterSplitSchema: GenMessage<ExportFilterSplit> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_dataset, 4);

