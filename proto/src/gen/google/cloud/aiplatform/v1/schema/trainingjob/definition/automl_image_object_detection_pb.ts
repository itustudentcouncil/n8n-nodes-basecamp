// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1/schema/trainingjob/definition/automl_image_object_detection.proto (package google.cloud.aiplatform.v1.schema.trainingjob.definition, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1/schema/trainingjob/definition/automl_image_object_detection.proto.
 */
export const file_google_cloud_aiplatform_v1_schema_trainingjob_definition_automl_image_object_detection: GenFile = /*@__PURE__*/
  fileDesc("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");

/**
 * A TrainingJob that trains and uploads an AutoML Image Object Detection Model.
 *
 * @generated from message google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetection
 */
export type AutoMlImageObjectDetection = Message<"google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetection"> & {
  /**
   * The input parameters of this TrainingJob.
   *
   * @generated from field: google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs inputs = 1;
   */
  inputs?: AutoMlImageObjectDetectionInputs;

  /**
   * The metadata information
   *
   * @generated from field: google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata metadata = 2;
   */
  metadata?: AutoMlImageObjectDetectionMetadata;
};

/**
 * Describes the message google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetection.
 * Use `create(AutoMlImageObjectDetectionSchema)` to create a new message.
 */
export const AutoMlImageObjectDetectionSchema: GenMessage<AutoMlImageObjectDetection> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_schema_trainingjob_definition_automl_image_object_detection, 0);

/**
 * @generated from message google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs
 */
export type AutoMlImageObjectDetectionInputs = Message<"google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs"> & {
  /**
   * @generated from field: google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs.ModelType model_type = 1;
   */
  modelType: AutoMlImageObjectDetectionInputs_ModelType;

  /**
   * The training budget of creating this model, expressed in milli node
   * hours i.e. 1,000 value in this field means 1 node hour. The actual
   * metadata.costMilliNodeHours will be equal or less than this value.
   * If further model training ceases to provide any improvements, it will
   * stop without using the full budget and the metadata.successfulStopReason
   * will be `model-converged`.
   * Note, node_hour  = actual_hour * number_of_nodes_involved.
   * For modelType `cloud`(default), the budget must be between 20,000
   * and 900,000 milli node hours, inclusive. The default value is 216,000
   * which represents one day in wall time, considering 9 nodes are used.
   * For model types `mobile-tf-low-latency-1`, `mobile-tf-versatile-1`,
   * `mobile-tf-high-accuracy-1`
   * the training budget must be between 1,000 and 100,000 milli node hours,
   * inclusive. The default value is 24,000 which represents one day in
   * wall time on a single node that is used.
   *
   * @generated from field: int64 budget_milli_node_hours = 2;
   */
  budgetMilliNodeHours: bigint;

  /**
   * Use the entire training budget. This disables the early stopping feature.
   * When false the early stopping feature is enabled, which means that AutoML
   * Image Object Detection might stop training before the entire training
   * budget has been used.
   *
   * @generated from field: bool disable_early_stopping = 3;
   */
  disableEarlyStopping: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs.
 * Use `create(AutoMlImageObjectDetectionInputsSchema)` to create a new message.
 */
export const AutoMlImageObjectDetectionInputsSchema: GenMessage<AutoMlImageObjectDetectionInputs> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_schema_trainingjob_definition_automl_image_object_detection, 1);

/**
 * @generated from enum google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs.ModelType
 */
export enum AutoMlImageObjectDetectionInputs_ModelType {
  /**
   * Should not be set.
   *
   * @generated from enum value: MODEL_TYPE_UNSPECIFIED = 0;
   */
  MODEL_TYPE_UNSPECIFIED = 0,

  /**
   * A model best tailored to be used within Google Cloud, and which cannot
   * be exported. Expected to have a higher latency, but should also have a
   * higher prediction quality than other cloud models.
   *
   * @generated from enum value: CLOUD_HIGH_ACCURACY_1 = 1;
   */
  CLOUD_HIGH_ACCURACY_1 = 1,

  /**
   * A model best tailored to be used within Google Cloud, and which cannot
   * be exported. Expected to have a low latency, but may have lower
   * prediction quality than other cloud models.
   *
   * @generated from enum value: CLOUD_LOW_LATENCY_1 = 2;
   */
  CLOUD_LOW_LATENCY_1 = 2,

  /**
   * A model that, in addition to being available within Google
   * Cloud can also be exported (see ModelService.ExportModel) and
   * used on a mobile or edge device with TensorFlow afterwards.
   * Expected to have low latency, but may have lower prediction
   * quality than other mobile models.
   *
   * @generated from enum value: MOBILE_TF_LOW_LATENCY_1 = 3;
   */
  MOBILE_TF_LOW_LATENCY_1 = 3,

  /**
   * A model that, in addition to being available within Google
   * Cloud can also be exported (see ModelService.ExportModel) and
   * used on a mobile or edge device with TensorFlow afterwards.
   *
   * @generated from enum value: MOBILE_TF_VERSATILE_1 = 4;
   */
  MOBILE_TF_VERSATILE_1 = 4,

  /**
   * A model that, in addition to being available within Google
   * Cloud, can also be exported (see ModelService.ExportModel) and
   * used on a mobile or edge device with TensorFlow afterwards.
   * Expected to have a higher latency, but should also have a higher
   * prediction quality than other mobile models.
   *
   * @generated from enum value: MOBILE_TF_HIGH_ACCURACY_1 = 5;
   */
  MOBILE_TF_HIGH_ACCURACY_1 = 5,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionInputs.ModelType.
 */
export const AutoMlImageObjectDetectionInputs_ModelTypeSchema: GenEnum<AutoMlImageObjectDetectionInputs_ModelType> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_schema_trainingjob_definition_automl_image_object_detection, 1, 0);

/**
 * @generated from message google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata
 */
export type AutoMlImageObjectDetectionMetadata = Message<"google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata"> & {
  /**
   * The actual training cost of creating this model, expressed in
   * milli node hours, i.e. 1,000 value in this field means 1 node hour.
   * Guaranteed to not exceed inputs.budgetMilliNodeHours.
   *
   * @generated from field: int64 cost_milli_node_hours = 1;
   */
  costMilliNodeHours: bigint;

  /**
   * For successful job completions, this is the reason why the job has
   * finished.
   *
   * @generated from field: google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata.SuccessfulStopReason successful_stop_reason = 2;
   */
  successfulStopReason: AutoMlImageObjectDetectionMetadata_SuccessfulStopReason;
};

/**
 * Describes the message google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata.
 * Use `create(AutoMlImageObjectDetectionMetadataSchema)` to create a new message.
 */
export const AutoMlImageObjectDetectionMetadataSchema: GenMessage<AutoMlImageObjectDetectionMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_schema_trainingjob_definition_automl_image_object_detection, 2);

/**
 * @generated from enum google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata.SuccessfulStopReason
 */
export enum AutoMlImageObjectDetectionMetadata_SuccessfulStopReason {
  /**
   * Should not be set.
   *
   * @generated from enum value: SUCCESSFUL_STOP_REASON_UNSPECIFIED = 0;
   */
  SUCCESSFUL_STOP_REASON_UNSPECIFIED = 0,

  /**
   * The inputs.budgetMilliNodeHours had been reached.
   *
   * @generated from enum value: BUDGET_REACHED = 1;
   */
  BUDGET_REACHED = 1,

  /**
   * Further training of the Model ceased to increase its quality, since it
   * already has converged.
   *
   * @generated from enum value: MODEL_CONVERGED = 2;
   */
  MODEL_CONVERGED = 2,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.schema.trainingjob.definition.AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.
 */
export const AutoMlImageObjectDetectionMetadata_SuccessfulStopReasonSchema: GenEnum<AutoMlImageObjectDetectionMetadata_SuccessfulStopReason> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_schema_trainingjob_definition_automl_image_object_detection, 2, 0);

