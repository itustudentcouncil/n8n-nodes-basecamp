// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1/study.proto (package google.cloud.aiplatform.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Duration, Timestamp, Value } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_struct, file_google_protobuf_timestamp, file_google_protobuf_wrappers } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1/study.proto.
 */
export const file_google_cloud_aiplatform_v1_study: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_protobuf_duration, file_google_protobuf_struct, file_google_protobuf_timestamp, file_google_protobuf_wrappers]);

/**
 * A message representing a Study.
 *
 * @generated from message google.cloud.aiplatform.v1.Study
 */
export type Study = Message<"google.cloud.aiplatform.v1.Study"> & {
  /**
   * Output only. The name of a study. The study's globally unique identifier.
   * Format: `projects/{project}/locations/{location}/studies/{study}`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. Describes the Study, default value is empty string.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * Required. Configuration of the Study.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec study_spec = 3;
   */
  studySpec?: StudySpec;

  /**
   * Output only. The detailed state of a Study.
   *
   * @generated from field: google.cloud.aiplatform.v1.Study.State state = 4;
   */
  state: Study_State;

  /**
   * Output only. Time at which the study was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 5;
   */
  createTime?: Timestamp;

  /**
   * Output only. A human readable reason why the Study is inactive.
   * This should be empty if a study is ACTIVE or COMPLETED.
   *
   * @generated from field: string inactive_reason = 6;
   */
  inactiveReason: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1.Study.
 * Use `create(StudySchema)` to create a new message.
 */
export const StudySchema: GenMessage<Study> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 0);

/**
 * Describes the Study state.
 *
 * @generated from enum google.cloud.aiplatform.v1.Study.State
 */
export enum Study_State {
  /**
   * The study state is unspecified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The study is active.
   *
   * @generated from enum value: ACTIVE = 1;
   */
  ACTIVE = 1,

  /**
   * The study is stopped due to an internal error.
   *
   * @generated from enum value: INACTIVE = 2;
   */
  INACTIVE = 2,

  /**
   * The study is done when the service exhausts the parameter search space
   * or max_trial_count is reached.
   *
   * @generated from enum value: COMPLETED = 3;
   */
  COMPLETED = 3,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.Study.State.
 */
export const Study_StateSchema: GenEnum<Study_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 0, 0);

/**
 * A message representing a Trial. A Trial contains a unique set of Parameters
 * that has been or will be evaluated, along with the objective metrics got by
 * running the Trial.
 *
 * @generated from message google.cloud.aiplatform.v1.Trial
 */
export type Trial = Message<"google.cloud.aiplatform.v1.Trial"> & {
  /**
   * Output only. Resource name of the Trial assigned by the service.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. The identifier of the Trial assigned by the service.
   *
   * @generated from field: string id = 2;
   */
  id: string;

  /**
   * Output only. The detailed state of the Trial.
   *
   * @generated from field: google.cloud.aiplatform.v1.Trial.State state = 3;
   */
  state: Trial_State;

  /**
   * Output only. The parameters of the Trial.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.Trial.Parameter parameters = 4;
   */
  parameters: Trial_Parameter[];

  /**
   * Output only. The final measurement containing the objective value.
   *
   * @generated from field: google.cloud.aiplatform.v1.Measurement final_measurement = 5;
   */
  finalMeasurement?: Measurement;

  /**
   * Output only. A list of measurements that are strictly lexicographically
   * ordered by their induced tuples (steps, elapsed_duration).
   * These are used for early stopping computations.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.Measurement measurements = 6;
   */
  measurements: Measurement[];

  /**
   * Output only. Time when the Trial was started.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 7;
   */
  startTime?: Timestamp;

  /**
   * Output only. Time when the Trial's status changed to `SUCCEEDED` or
   * `INFEASIBLE`.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 8;
   */
  endTime?: Timestamp;

  /**
   * Output only. The identifier of the client that originally requested this
   * Trial. Each client is identified by a unique client_id. When a client asks
   * for a suggestion, Vertex AI Vizier will assign it a Trial. The client
   * should evaluate the Trial, complete it, and report back to Vertex AI
   * Vizier. If suggestion is asked again by same client_id before the Trial is
   * completed, the same Trial will be returned. Multiple clients with
   * different client_ids can ask for suggestions simultaneously, each of them
   * will get their own Trial.
   *
   * @generated from field: string client_id = 9;
   */
  clientId: string;

  /**
   * Output only. A human readable string describing why the Trial is
   * infeasible. This is set only if Trial state is `INFEASIBLE`.
   *
   * @generated from field: string infeasible_reason = 10;
   */
  infeasibleReason: string;

  /**
   * Output only. The CustomJob name linked to the Trial.
   * It's set for a HyperparameterTuningJob's Trial.
   *
   * @generated from field: string custom_job = 11;
   */
  customJob: string;

  /**
   * Output only. URIs for accessing [interactive
   * shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
   * (one URI for each training node). Only available if this trial is part of
   * a
   * [HyperparameterTuningJob][google.cloud.aiplatform.v1.HyperparameterTuningJob]
   * and the job's
   * [trial_job_spec.enable_web_access][google.cloud.aiplatform.v1.CustomJobSpec.enable_web_access]
   * field is `true`.
   *
   * The keys are names of each node used for the trial; for example,
   * `workerpool0-0` for the primary node, `workerpool1-0` for the first node in
   * the second worker pool, and `workerpool1-1` for the second node in the
   * second worker pool.
   *
   * The values are the URIs for each node's interactive shell.
   *
   * @generated from field: map<string, string> web_access_uris = 12;
   */
  webAccessUris: { [key: string]: string };
};

/**
 * Describes the message google.cloud.aiplatform.v1.Trial.
 * Use `create(TrialSchema)` to create a new message.
 */
export const TrialSchema: GenMessage<Trial> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 1);

/**
 * A message representing a parameter to be tuned.
 *
 * @generated from message google.cloud.aiplatform.v1.Trial.Parameter
 */
export type Trial_Parameter = Message<"google.cloud.aiplatform.v1.Trial.Parameter"> & {
  /**
   * Output only. The ID of the parameter. The parameter should be defined in
   * [StudySpec's
   * Parameters][google.cloud.aiplatform.v1.StudySpec.parameters].
   *
   * @generated from field: string parameter_id = 1;
   */
  parameterId: string;

  /**
   * Output only. The value of the parameter.
   * `number_value` will be set if a parameter defined in StudySpec is
   * in type 'INTEGER', 'DOUBLE' or 'DISCRETE'.
   * `string_value` will be set if a parameter defined in StudySpec is
   * in type 'CATEGORICAL'.
   *
   * @generated from field: google.protobuf.Value value = 2;
   */
  value?: Value;
};

/**
 * Describes the message google.cloud.aiplatform.v1.Trial.Parameter.
 * Use `create(Trial_ParameterSchema)` to create a new message.
 */
export const Trial_ParameterSchema: GenMessage<Trial_Parameter> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 1, 0);

/**
 * Describes a Trial state.
 *
 * @generated from enum google.cloud.aiplatform.v1.Trial.State
 */
export enum Trial_State {
  /**
   * The Trial state is unspecified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * Indicates that a specific Trial has been requested, but it has not yet
   * been suggested by the service.
   *
   * @generated from enum value: REQUESTED = 1;
   */
  REQUESTED = 1,

  /**
   * Indicates that the Trial has been suggested.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * Indicates that the Trial should stop according to the service.
   *
   * @generated from enum value: STOPPING = 3;
   */
  STOPPING = 3,

  /**
   * Indicates that the Trial is completed successfully.
   *
   * @generated from enum value: SUCCEEDED = 4;
   */
  SUCCEEDED = 4,

  /**
   * Indicates that the Trial should not be attempted again.
   * The service will set a Trial to INFEASIBLE when it's done but missing
   * the final_measurement.
   *
   * @generated from enum value: INFEASIBLE = 5;
   */
  INFEASIBLE = 5,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.Trial.State.
 */
export const Trial_StateSchema: GenEnum<Trial_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 1, 0);

/**
 * @generated from message google.cloud.aiplatform.v1.TrialContext
 */
export type TrialContext = Message<"google.cloud.aiplatform.v1.TrialContext"> & {
  /**
   * A human-readable field which can store a description of this context.
   * This will become part of the resulting Trial's description field.
   *
   * @generated from field: string description = 1;
   */
  description: string;

  /**
   * If/when a Trial is generated or selected from this Context,
   * its Parameters will match any parameters specified here.
   * (I.e. if this context specifies parameter name:'a' int_value:3,
   * then a resulting Trial will have int_value:3 for its parameter named
   * 'a'.) Note that we first attempt to match existing REQUESTED Trials with
   * contexts, and if there are no matches, we generate suggestions in the
   * subspace defined by the parameters specified here.
   * NOTE: a Context without any Parameters matches the entire feasible search
   *   space.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.Trial.Parameter parameters = 2;
   */
  parameters: Trial_Parameter[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.TrialContext.
 * Use `create(TrialContextSchema)` to create a new message.
 */
export const TrialContextSchema: GenMessage<TrialContext> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 2);

/**
 * Time-based Constraint for Study
 *
 * @generated from message google.cloud.aiplatform.v1.StudyTimeConstraint
 */
export type StudyTimeConstraint = Message<"google.cloud.aiplatform.v1.StudyTimeConstraint"> & {
  /**
   * @generated from oneof google.cloud.aiplatform.v1.StudyTimeConstraint.constraint
   */
  constraint: {
    /**
     * Counts the wallclock time passed since the creation of this Study.
     *
     * @generated from field: google.protobuf.Duration max_duration = 1;
     */
    value: Duration;
    case: "maxDuration";
  } | {
    /**
     * Compares the wallclock time to this time. Must use UTC timezone.
     *
     * @generated from field: google.protobuf.Timestamp end_time = 2;
     */
    value: Timestamp;
    case: "endTime";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudyTimeConstraint.
 * Use `create(StudyTimeConstraintSchema)` to create a new message.
 */
export const StudyTimeConstraintSchema: GenMessage<StudyTimeConstraint> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 3);

/**
 * Represents specification of a Study.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec
 */
export type StudySpec = Message<"google.cloud.aiplatform.v1.StudySpec"> & {
  /**
   * @generated from oneof google.cloud.aiplatform.v1.StudySpec.automated_stopping_spec
   */
  automatedStoppingSpec: {
    /**
     * The automated early stopping spec using decay curve rule.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.DecayCurveAutomatedStoppingSpec decay_curve_stopping_spec = 4;
     */
    value: StudySpec_DecayCurveAutomatedStoppingSpec;
    case: "decayCurveStoppingSpec";
  } | {
    /**
     * The automated early stopping spec using median rule.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.MedianAutomatedStoppingSpec median_automated_stopping_spec = 5;
     */
    value: StudySpec_MedianAutomatedStoppingSpec;
    case: "medianAutomatedStoppingSpec";
  } | {
    /**
     * The automated early stopping spec using convex stopping rule.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ConvexAutomatedStoppingSpec convex_automated_stopping_spec = 9;
     */
    value: StudySpec_ConvexAutomatedStoppingSpec;
    case: "convexAutomatedStoppingSpec";
  } | { case: undefined; value?: undefined };

  /**
   * Required. Metric specs for the Study.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.StudySpec.MetricSpec metrics = 1;
   */
  metrics: StudySpec_MetricSpec[];

  /**
   * Required. The set of parameters to tune.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.StudySpec.ParameterSpec parameters = 2;
   */
  parameters: StudySpec_ParameterSpec[];

  /**
   * The search algorithm specified for the Study.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec.Algorithm algorithm = 3;
   */
  algorithm: StudySpec_Algorithm;

  /**
   * The observation noise level of the study.
   * Currently only supported by the Vertex AI Vizier service. Not supported by
   * HyperparameterTuningJob or TrainingPipeline.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec.ObservationNoise observation_noise = 6;
   */
  observationNoise: StudySpec_ObservationNoise;

  /**
   * Describe which measurement selection type will be used
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec.MeasurementSelectionType measurement_selection_type = 7;
   */
  measurementSelectionType: StudySpec_MeasurementSelectionType;

  /**
   * Conditions for automated stopping of a Study. Enable automated stopping by
   * configuring at least one condition.
   *
   * @generated from field: optional google.cloud.aiplatform.v1.StudySpec.StudyStoppingConfig study_stopping_config = 11;
   */
  studyStoppingConfig?: StudySpec_StudyStoppingConfig;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.
 * Use `create(StudySpecSchema)` to create a new message.
 */
export const StudySpecSchema: GenMessage<StudySpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4);

/**
 * Represents a metric to optimize.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.MetricSpec
 */
export type StudySpec_MetricSpec = Message<"google.cloud.aiplatform.v1.StudySpec.MetricSpec"> & {
  /**
   * Required. The ID of the metric. Must not contain whitespaces and must be
   * unique amongst all MetricSpecs.
   *
   * @generated from field: string metric_id = 1;
   */
  metricId: string;

  /**
   * Required. The optimization goal of the metric.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec.MetricSpec.GoalType goal = 2;
   */
  goal: StudySpec_MetricSpec_GoalType;

  /**
   * Used for safe search. In the case, the metric will be a safety
   * metric. You must provide a separate metric for objective metric.
   *
   * @generated from field: optional google.cloud.aiplatform.v1.StudySpec.MetricSpec.SafetyMetricConfig safety_config = 3;
   */
  safetyConfig?: StudySpec_MetricSpec_SafetyMetricConfig;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.MetricSpec.
 * Use `create(StudySpec_MetricSpecSchema)` to create a new message.
 */
export const StudySpec_MetricSpecSchema: GenMessage<StudySpec_MetricSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 0);

/**
 * Used in safe optimization to specify threshold levels and risk tolerance.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.MetricSpec.SafetyMetricConfig
 */
export type StudySpec_MetricSpec_SafetyMetricConfig = Message<"google.cloud.aiplatform.v1.StudySpec.MetricSpec.SafetyMetricConfig"> & {
  /**
   * Safety threshold (boundary value between safe and unsafe). NOTE that if
   * you leave SafetyMetricConfig unset, a default value of 0 will be used.
   *
   * @generated from field: double safety_threshold = 1;
   */
  safetyThreshold: number;

  /**
   * Desired minimum fraction of safe trials (over total number of trials)
   * that should be targeted by the algorithm at any time during the
   * study (best effort). This should be between 0.0 and 1.0 and a value of
   * 0.0 means that there is no minimum and an algorithm proceeds without
   * targeting any specific fraction. A value of 1.0 means that the
   * algorithm attempts to only Suggest safe Trials.
   *
   * @generated from field: optional double desired_min_safe_trials_fraction = 2;
   */
  desiredMinSafeTrialsFraction?: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.MetricSpec.SafetyMetricConfig.
 * Use `create(StudySpec_MetricSpec_SafetyMetricConfigSchema)` to create a new message.
 */
export const StudySpec_MetricSpec_SafetyMetricConfigSchema: GenMessage<StudySpec_MetricSpec_SafetyMetricConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 0, 0);

/**
 * The available types of optimization goals.
 *
 * @generated from enum google.cloud.aiplatform.v1.StudySpec.MetricSpec.GoalType
 */
export enum StudySpec_MetricSpec_GoalType {
  /**
   * Goal Type will default to maximize.
   *
   * @generated from enum value: GOAL_TYPE_UNSPECIFIED = 0;
   */
  GOAL_TYPE_UNSPECIFIED = 0,

  /**
   * Maximize the goal metric.
   *
   * @generated from enum value: MAXIMIZE = 1;
   */
  MAXIMIZE = 1,

  /**
   * Minimize the goal metric.
   *
   * @generated from enum value: MINIMIZE = 2;
   */
  MINIMIZE = 2,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.StudySpec.MetricSpec.GoalType.
 */
export const StudySpec_MetricSpec_GoalTypeSchema: GenEnum<StudySpec_MetricSpec_GoalType> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 4, 0, 0);

/**
 * Represents a single parameter to optimize.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec
 */
export type StudySpec_ParameterSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec"> & {
  /**
   * @generated from oneof google.cloud.aiplatform.v1.StudySpec.ParameterSpec.parameter_value_spec
   */
  parameterValueSpec: {
    /**
     * The value spec for a 'DOUBLE' parameter.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DoubleValueSpec double_value_spec = 2;
     */
    value: StudySpec_ParameterSpec_DoubleValueSpec;
    case: "doubleValueSpec";
  } | {
    /**
     * The value spec for an 'INTEGER' parameter.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.IntegerValueSpec integer_value_spec = 3;
     */
    value: StudySpec_ParameterSpec_IntegerValueSpec;
    case: "integerValueSpec";
  } | {
    /**
     * The value spec for a 'CATEGORICAL' parameter.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.CategoricalValueSpec categorical_value_spec = 4;
     */
    value: StudySpec_ParameterSpec_CategoricalValueSpec;
    case: "categoricalValueSpec";
  } | {
    /**
     * The value spec for a 'DISCRETE' parameter.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DiscreteValueSpec discrete_value_spec = 5;
     */
    value: StudySpec_ParameterSpec_DiscreteValueSpec;
    case: "discreteValueSpec";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The ID of the parameter. Must not contain whitespaces and must
   * be unique amongst all ParameterSpecs.
   *
   * @generated from field: string parameter_id = 1;
   */
  parameterId: string;

  /**
   * How the parameter should be scaled.
   * Leave unset for `CATEGORICAL` parameters.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ScaleType scale_type = 6;
   */
  scaleType: StudySpec_ParameterSpec_ScaleType;

  /**
   * A conditional parameter node is active if the parameter's value matches
   * the conditional node's parent_value_condition.
   *
   * If two items in conditional_parameter_specs have the same name, they
   * must have disjoint parent_value_condition.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec conditional_parameter_specs = 10;
   */
  conditionalParameterSpecs: StudySpec_ParameterSpec_ConditionalParameterSpec[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.
 * Use `create(StudySpec_ParameterSpecSchema)` to create a new message.
 */
export const StudySpec_ParameterSpecSchema: GenMessage<StudySpec_ParameterSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1);

/**
 * Value specification for a parameter in `DOUBLE` type.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DoubleValueSpec
 */
export type StudySpec_ParameterSpec_DoubleValueSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DoubleValueSpec"> & {
  /**
   * Required. Inclusive minimum value of the parameter.
   *
   * @generated from field: double min_value = 1;
   */
  minValue: number;

  /**
   * Required. Inclusive maximum value of the parameter.
   *
   * @generated from field: double max_value = 2;
   */
  maxValue: number;

  /**
   * A default value for a `DOUBLE` parameter that is assumed to be a
   * relatively good starting point.  Unset value signals that there is no
   * offered starting point.
   *
   * Currently only supported by the Vertex AI Vizier service. Not supported
   * by HyperparameterTuningJob or TrainingPipeline.
   *
   * @generated from field: optional double default_value = 4;
   */
  defaultValue?: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DoubleValueSpec.
 * Use `create(StudySpec_ParameterSpec_DoubleValueSpecSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_DoubleValueSpecSchema: GenMessage<StudySpec_ParameterSpec_DoubleValueSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 0);

/**
 * Value specification for a parameter in `INTEGER` type.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.IntegerValueSpec
 */
export type StudySpec_ParameterSpec_IntegerValueSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.IntegerValueSpec"> & {
  /**
   * Required. Inclusive minimum value of the parameter.
   *
   * @generated from field: int64 min_value = 1;
   */
  minValue: bigint;

  /**
   * Required. Inclusive maximum value of the parameter.
   *
   * @generated from field: int64 max_value = 2;
   */
  maxValue: bigint;

  /**
   * A default value for an `INTEGER` parameter that is assumed to be a
   * relatively good starting point.  Unset value signals that there is no
   * offered starting point.
   *
   * Currently only supported by the Vertex AI Vizier service. Not supported
   * by HyperparameterTuningJob or TrainingPipeline.
   *
   * @generated from field: optional int64 default_value = 4;
   */
  defaultValue?: bigint;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.IntegerValueSpec.
 * Use `create(StudySpec_ParameterSpec_IntegerValueSpecSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_IntegerValueSpecSchema: GenMessage<StudySpec_ParameterSpec_IntegerValueSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 1);

/**
 * Value specification for a parameter in `CATEGORICAL` type.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.CategoricalValueSpec
 */
export type StudySpec_ParameterSpec_CategoricalValueSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.CategoricalValueSpec"> & {
  /**
   * Required. The list of possible categories.
   *
   * @generated from field: repeated string values = 1;
   */
  values: string[];

  /**
   * A default value for a `CATEGORICAL` parameter that is assumed to be a
   * relatively good starting point.  Unset value signals that there is no
   * offered starting point.
   *
   * Currently only supported by the Vertex AI Vizier service. Not supported
   * by HyperparameterTuningJob or TrainingPipeline.
   *
   * @generated from field: optional string default_value = 3;
   */
  defaultValue?: string;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.CategoricalValueSpec.
 * Use `create(StudySpec_ParameterSpec_CategoricalValueSpecSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_CategoricalValueSpecSchema: GenMessage<StudySpec_ParameterSpec_CategoricalValueSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 2);

/**
 * Value specification for a parameter in `DISCRETE` type.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DiscreteValueSpec
 */
export type StudySpec_ParameterSpec_DiscreteValueSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DiscreteValueSpec"> & {
  /**
   * Required. A list of possible values.
   * The list should be in increasing order and at least 1e-10 apart.
   * For instance, this parameter might have possible settings of 1.5, 2.5,
   * and 4.0. This list should not contain more than 1,000 values.
   *
   * @generated from field: repeated double values = 1;
   */
  values: number[];

  /**
   * A default value for a `DISCRETE` parameter that is assumed to be a
   * relatively good starting point.  Unset value signals that there is no
   * offered starting point.  It automatically rounds to the
   * nearest feasible discrete point.
   *
   * Currently only supported by the Vertex AI Vizier service. Not supported
   * by HyperparameterTuningJob or TrainingPipeline.
   *
   * @generated from field: optional double default_value = 3;
   */
  defaultValue?: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DiscreteValueSpec.
 * Use `create(StudySpec_ParameterSpec_DiscreteValueSpecSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_DiscreteValueSpecSchema: GenMessage<StudySpec_ParameterSpec_DiscreteValueSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 3);

/**
 * Represents a parameter spec with condition from its parent parameter.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec
 */
export type StudySpec_ParameterSpec_ConditionalParameterSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec"> & {
  /**
   * A set of parameter values from the parent ParameterSpec's feasible
   * space.
   *
   * @generated from oneof google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.parent_value_condition
   */
  parentValueCondition: {
    /**
     * The spec for matching values from a parent parameter of
     * `DISCRETE` type.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.DiscreteValueCondition parent_discrete_values = 2;
     */
    value: StudySpec_ParameterSpec_ConditionalParameterSpec_DiscreteValueCondition;
    case: "parentDiscreteValues";
  } | {
    /**
     * The spec for matching values from a parent parameter of `INTEGER`
     * type.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.IntValueCondition parent_int_values = 3;
     */
    value: StudySpec_ParameterSpec_ConditionalParameterSpec_IntValueCondition;
    case: "parentIntValues";
  } | {
    /**
     * The spec for matching values from a parent parameter of
     * `CATEGORICAL` type.
     *
     * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.CategoricalValueCondition parent_categorical_values = 4;
     */
    value: StudySpec_ParameterSpec_ConditionalParameterSpec_CategoricalValueCondition;
    case: "parentCategoricalValues";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The spec for a conditional parameter.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudySpec.ParameterSpec parameter_spec = 1;
   */
  parameterSpec?: StudySpec_ParameterSpec;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.
 * Use `create(StudySpec_ParameterSpec_ConditionalParameterSpecSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_ConditionalParameterSpecSchema: GenMessage<StudySpec_ParameterSpec_ConditionalParameterSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 4);

/**
 * Represents the spec to match discrete values from parent parameter.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.DiscreteValueCondition
 */
export type StudySpec_ParameterSpec_ConditionalParameterSpec_DiscreteValueCondition = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.DiscreteValueCondition"> & {
  /**
   * Required. Matches values of the parent parameter of 'DISCRETE' type.
   * All values must exist in `discrete_value_spec` of parent parameter.
   *
   * The Epsilon of the value matching is 1e-10.
   *
   * @generated from field: repeated double values = 1;
   */
  values: number[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.DiscreteValueCondition.
 * Use `create(StudySpec_ParameterSpec_ConditionalParameterSpec_DiscreteValueConditionSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_ConditionalParameterSpec_DiscreteValueConditionSchema: GenMessage<StudySpec_ParameterSpec_ConditionalParameterSpec_DiscreteValueCondition> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 4, 0);

/**
 * Represents the spec to match integer values from parent parameter.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.IntValueCondition
 */
export type StudySpec_ParameterSpec_ConditionalParameterSpec_IntValueCondition = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.IntValueCondition"> & {
  /**
   * Required. Matches values of the parent parameter of 'INTEGER' type.
   * All values must lie in `integer_value_spec` of parent parameter.
   *
   * @generated from field: repeated int64 values = 1;
   */
  values: bigint[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.IntValueCondition.
 * Use `create(StudySpec_ParameterSpec_ConditionalParameterSpec_IntValueConditionSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_ConditionalParameterSpec_IntValueConditionSchema: GenMessage<StudySpec_ParameterSpec_ConditionalParameterSpec_IntValueCondition> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 4, 1);

/**
 * Represents the spec to match categorical values from parent parameter.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.CategoricalValueCondition
 */
export type StudySpec_ParameterSpec_ConditionalParameterSpec_CategoricalValueCondition = Message<"google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.CategoricalValueCondition"> & {
  /**
   * Required. Matches values of the parent parameter of 'CATEGORICAL'
   * type. All values must exist in `categorical_value_spec` of parent
   * parameter.
   *
   * @generated from field: repeated string values = 1;
   */
  values: string[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.CategoricalValueCondition.
 * Use `create(StudySpec_ParameterSpec_ConditionalParameterSpec_CategoricalValueConditionSchema)` to create a new message.
 */
export const StudySpec_ParameterSpec_ConditionalParameterSpec_CategoricalValueConditionSchema: GenMessage<StudySpec_ParameterSpec_ConditionalParameterSpec_CategoricalValueCondition> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 4, 2);

/**
 * The type of scaling that should be applied to this parameter.
 *
 * @generated from enum google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ScaleType
 */
export enum StudySpec_ParameterSpec_ScaleType {
  /**
   * By default, no scaling is applied.
   *
   * @generated from enum value: SCALE_TYPE_UNSPECIFIED = 0;
   */
  SCALE_TYPE_UNSPECIFIED = 0,

  /**
   * Scales the feasible space to (0, 1) linearly.
   *
   * @generated from enum value: UNIT_LINEAR_SCALE = 1;
   */
  UNIT_LINEAR_SCALE = 1,

  /**
   * Scales the feasible space logarithmically to (0, 1). The entire
   * feasible space must be strictly positive.
   *
   * @generated from enum value: UNIT_LOG_SCALE = 2;
   */
  UNIT_LOG_SCALE = 2,

  /**
   * Scales the feasible space "reverse" logarithmically to (0, 1). The
   * result is that values close to the top of the feasible space are spread
   * out more than points near the bottom. The entire feasible space must be
   * strictly positive.
   *
   * @generated from enum value: UNIT_REVERSE_LOG_SCALE = 3;
   */
  UNIT_REVERSE_LOG_SCALE = 3,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ScaleType.
 */
export const StudySpec_ParameterSpec_ScaleTypeSchema: GenEnum<StudySpec_ParameterSpec_ScaleType> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 4, 1, 0);

/**
 * The decay curve automated stopping rule builds a Gaussian Process
 * Regressor to predict the final objective value of a Trial based on the
 * already completed Trials and the intermediate measurements of the current
 * Trial. Early stopping is requested for the current Trial if there is very
 * low probability to exceed the optimal value found so far.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.DecayCurveAutomatedStoppingSpec
 */
export type StudySpec_DecayCurveAutomatedStoppingSpec = Message<"google.cloud.aiplatform.v1.StudySpec.DecayCurveAutomatedStoppingSpec"> & {
  /**
   * True if
   * [Measurement.elapsed_duration][google.cloud.aiplatform.v1.Measurement.elapsed_duration]
   * is used as the x-axis of each Trials Decay Curve. Otherwise,
   * [Measurement.step_count][google.cloud.aiplatform.v1.Measurement.step_count]
   * will be used as the x-axis.
   *
   * @generated from field: bool use_elapsed_duration = 1;
   */
  useElapsedDuration: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.DecayCurveAutomatedStoppingSpec.
 * Use `create(StudySpec_DecayCurveAutomatedStoppingSpecSchema)` to create a new message.
 */
export const StudySpec_DecayCurveAutomatedStoppingSpecSchema: GenMessage<StudySpec_DecayCurveAutomatedStoppingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 2);

/**
 * The median automated stopping rule stops a pending Trial if the Trial's
 * best objective_value is strictly below the median 'performance' of all
 * completed Trials reported up to the Trial's last measurement.
 * Currently, 'performance' refers to the running average of the objective
 * values reported by the Trial in each measurement.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.MedianAutomatedStoppingSpec
 */
export type StudySpec_MedianAutomatedStoppingSpec = Message<"google.cloud.aiplatform.v1.StudySpec.MedianAutomatedStoppingSpec"> & {
  /**
   * True if median automated stopping rule applies on
   * [Measurement.elapsed_duration][google.cloud.aiplatform.v1.Measurement.elapsed_duration].
   * It means that elapsed_duration field of latest measurement of current
   * Trial is used to compute median objective value for each completed
   * Trials.
   *
   * @generated from field: bool use_elapsed_duration = 1;
   */
  useElapsedDuration: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.MedianAutomatedStoppingSpec.
 * Use `create(StudySpec_MedianAutomatedStoppingSpecSchema)` to create a new message.
 */
export const StudySpec_MedianAutomatedStoppingSpecSchema: GenMessage<StudySpec_MedianAutomatedStoppingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 3);

/**
 * Configuration for ConvexAutomatedStoppingSpec.
 * When there are enough completed trials (configured by
 * min_measurement_count), for pending trials with enough measurements and
 * steps, the policy first computes an overestimate of the objective value at
 * max_num_steps according to the slope of the incomplete objective value
 * curve. No prediction can be made if the curve is completely flat. If the
 * overestimation is worse than the best objective value of the completed
 * trials, this pending trial will be early-stopped, but a last measurement
 * will be added to the pending trial with max_num_steps and predicted
 * objective value from the autoregression model.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.ConvexAutomatedStoppingSpec
 */
export type StudySpec_ConvexAutomatedStoppingSpec = Message<"google.cloud.aiplatform.v1.StudySpec.ConvexAutomatedStoppingSpec"> & {
  /**
   * Steps used in predicting the final objective for early stopped trials. In
   * general, it's set to be the same as the defined steps in training /
   * tuning. If not defined, it will learn it from the completed trials. When
   * use_steps is false, this field is set to the maximum elapsed seconds.
   *
   * @generated from field: int64 max_step_count = 1;
   */
  maxStepCount: bigint;

  /**
   * Minimum number of steps for a trial to complete. Trials which do not have
   * a measurement with step_count > min_step_count won't be considered for
   * early stopping. It's ok to set it to 0, and a trial can be early stopped
   * at any stage. By default, min_step_count is set to be one-tenth of the
   * max_step_count.
   * When use_elapsed_duration is true, this field is set to the minimum
   * elapsed seconds.
   *
   * @generated from field: int64 min_step_count = 2;
   */
  minStepCount: bigint;

  /**
   * The minimal number of measurements in a Trial.  Early-stopping checks
   * will not trigger if less than min_measurement_count+1 completed trials or
   * pending trials with less than min_measurement_count measurements. If not
   * defined, the default value is 5.
   *
   * @generated from field: int64 min_measurement_count = 3;
   */
  minMeasurementCount: bigint;

  /**
   * The hyper-parameter name used in the tuning job that stands for learning
   * rate. Leave it blank if learning rate is not in a parameter in tuning.
   * The learning_rate is used to estimate the objective value of the ongoing
   * trial.
   *
   * @generated from field: string learning_rate_parameter_name = 4;
   */
  learningRateParameterName: string;

  /**
   * This bool determines whether or not the rule is applied based on
   * elapsed_secs or steps. If use_elapsed_duration==false, the early stopping
   * decision is made according to the predicted objective values according to
   * the target steps. If use_elapsed_duration==true, elapsed_secs is used
   * instead of steps. Also, in this case, the parameters max_num_steps and
   * min_num_steps are overloaded to contain max_elapsed_seconds and
   * min_elapsed_seconds.
   *
   * @generated from field: bool use_elapsed_duration = 5;
   */
  useElapsedDuration: boolean;

  /**
   * ConvexAutomatedStoppingSpec by default only updates the trials that needs
   * to be early stopped using a newly trained auto-regressive model. When
   * this flag is set to True, all stopped trials from the beginning are
   * potentially updated in terms of their `final_measurement`. Also, note
   * that the training logic of autoregressive models is different in this
   * case. Enabling this option has shown better results and this may be the
   * default option in the future.
   *
   * @generated from field: optional bool update_all_stopped_trials = 6;
   */
  updateAllStoppedTrials?: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.ConvexAutomatedStoppingSpec.
 * Use `create(StudySpec_ConvexAutomatedStoppingSpecSchema)` to create a new message.
 */
export const StudySpec_ConvexAutomatedStoppingSpecSchema: GenMessage<StudySpec_ConvexAutomatedStoppingSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 4);

/**
 * The configuration (stopping conditions) for automated stopping of a Study.
 * Conditions include trial budgets, time budgets, and convergence detection.
 *
 * @generated from message google.cloud.aiplatform.v1.StudySpec.StudyStoppingConfig
 */
export type StudySpec_StudyStoppingConfig = Message<"google.cloud.aiplatform.v1.StudySpec.StudyStoppingConfig"> & {
  /**
   * If true, a Study enters STOPPING_ASAP whenever it would normally enters
   * STOPPING state.
   *
   * The bottom line is: set to true if you want to interrupt on-going
   * evaluations of Trials as soon as the study stopping condition is met.
   * (Please see Study.State documentation for the source of truth).
   *
   * @generated from field: google.protobuf.BoolValue should_stop_asap = 1;
   */
  shouldStopAsap?: boolean;

  /**
   * Each "stopping rule" in this proto specifies an "if" condition. Before
   * Vizier would generate a new suggestion, it first checks each specified
   * stopping rule, from top to bottom in this list.
   * Note that the first few rules (e.g. minimum_runtime_constraint,
   * min_num_trials) will prevent other stopping rules from being evaluated
   * until they are met. For example, setting `min_num_trials=5` and
   * `always_stop_after= 1 hour` means that the Study will ONLY stop after it
   * has 5 COMPLETED trials, even if more than an hour has passed since its
   * creation. It follows the first applicable rule (whose "if" condition is
   * satisfied) to make a stopping decision. If none of the specified rules
   * are applicable, then Vizier decides that the study should not stop.
   * If Vizier decides that the study should stop, the study enters
   * STOPPING state (or STOPPING_ASAP if should_stop_asap = true).
   * IMPORTANT: The automatic study state transition happens precisely as
   * described above; that is, deleting trials or updating StudyConfig NEVER
   * automatically moves the study state back to ACTIVE. If you want to
   * _resume_ a Study that was stopped, 1) change the stopping conditions if
   * necessary, 2) activate the study, and then 3) ask for suggestions.
   * If the specified time or duration has not passed, do not stop the
   * study.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudyTimeConstraint minimum_runtime_constraint = 2;
   */
  minimumRuntimeConstraint?: StudyTimeConstraint;

  /**
   * If the specified time or duration has passed, stop the study.
   *
   * @generated from field: google.cloud.aiplatform.v1.StudyTimeConstraint maximum_runtime_constraint = 3;
   */
  maximumRuntimeConstraint?: StudyTimeConstraint;

  /**
   * If there are fewer than this many COMPLETED trials, do not stop the
   * study.
   *
   * @generated from field: google.protobuf.Int32Value min_num_trials = 4;
   */
  minNumTrials?: number;

  /**
   * If there are more than this many trials, stop the study.
   *
   * @generated from field: google.protobuf.Int32Value max_num_trials = 5;
   */
  maxNumTrials?: number;

  /**
   * If the objective value has not improved for this many consecutive
   * trials, stop the study.
   *
   * WARNING: Effective only for single-objective studies.
   *
   * @generated from field: google.protobuf.Int32Value max_num_trials_no_progress = 6;
   */
  maxNumTrialsNoProgress?: number;

  /**
   * If the objective value has not improved for this much time, stop the
   * study.
   *
   * WARNING: Effective only for single-objective studies.
   *
   * @generated from field: google.protobuf.Duration max_duration_no_progress = 7;
   */
  maxDurationNoProgress?: Duration;
};

/**
 * Describes the message google.cloud.aiplatform.v1.StudySpec.StudyStoppingConfig.
 * Use `create(StudySpec_StudyStoppingConfigSchema)` to create a new message.
 */
export const StudySpec_StudyStoppingConfigSchema: GenMessage<StudySpec_StudyStoppingConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 4, 5);

/**
 * The available search algorithms for the Study.
 *
 * @generated from enum google.cloud.aiplatform.v1.StudySpec.Algorithm
 */
export enum StudySpec_Algorithm {
  /**
   * The default algorithm used by Vertex AI for [hyperparameter
   * tuning](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)
   * and [Vertex AI Vizier](https://cloud.google.com/vertex-ai/docs/vizier).
   *
   * @generated from enum value: ALGORITHM_UNSPECIFIED = 0;
   */
  ALGORITHM_UNSPECIFIED = 0,

  /**
   * Simple grid search within the feasible space. To use grid search,
   * all parameters must be `INTEGER`, `CATEGORICAL`, or `DISCRETE`.
   *
   * @generated from enum value: GRID_SEARCH = 2;
   */
  GRID_SEARCH = 2,

  /**
   * Simple random search within the feasible space.
   *
   * @generated from enum value: RANDOM_SEARCH = 3;
   */
  RANDOM_SEARCH = 3,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.StudySpec.Algorithm.
 */
export const StudySpec_AlgorithmSchema: GenEnum<StudySpec_Algorithm> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 4, 0);

/**
 * Describes the noise level of the repeated observations.
 *
 * "Noisy" means that the repeated observations with the same Trial parameters
 * may lead to different metric evaluations.
 *
 * @generated from enum google.cloud.aiplatform.v1.StudySpec.ObservationNoise
 */
export enum StudySpec_ObservationNoise {
  /**
   * The default noise level chosen by Vertex AI.
   *
   * @generated from enum value: OBSERVATION_NOISE_UNSPECIFIED = 0;
   */
  OBSERVATION_NOISE_UNSPECIFIED = 0,

  /**
   * Vertex AI assumes that the objective function is (nearly)
   * perfectly reproducible, and will never repeat the same Trial
   * parameters.
   *
   * @generated from enum value: LOW = 1;
   */
  LOW = 1,

  /**
   * Vertex AI will estimate the amount of noise in metric
   * evaluations, it may repeat the same Trial parameters more than once.
   *
   * @generated from enum value: HIGH = 2;
   */
  HIGH = 2,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.StudySpec.ObservationNoise.
 */
export const StudySpec_ObservationNoiseSchema: GenEnum<StudySpec_ObservationNoise> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 4, 1);

/**
 * This indicates which measurement to use if/when the service automatically
 * selects the final measurement from previously reported intermediate
 * measurements. Choose this based on two considerations:
 *  A) Do you expect your measurements to monotonically improve?
 *     If so, choose LAST_MEASUREMENT. On the other hand, if you're in a
 *     situation where your system can "over-train" and you expect the
 *     performance to get better for a while but then start declining,
 *     choose BEST_MEASUREMENT.
 *  B) Are your measurements significantly noisy and/or irreproducible?
 *     If so, BEST_MEASUREMENT will tend to be over-optimistic, and it
 *     may be better to choose LAST_MEASUREMENT.
 *  If both or neither of (A) and (B) apply, it doesn't matter which
 *  selection type is chosen.
 *
 * @generated from enum google.cloud.aiplatform.v1.StudySpec.MeasurementSelectionType
 */
export enum StudySpec_MeasurementSelectionType {
  /**
   * Will be treated as LAST_MEASUREMENT.
   *
   * @generated from enum value: MEASUREMENT_SELECTION_TYPE_UNSPECIFIED = 0;
   */
  MEASUREMENT_SELECTION_TYPE_UNSPECIFIED = 0,

  /**
   * Use the last measurement reported.
   *
   * @generated from enum value: LAST_MEASUREMENT = 1;
   */
  LAST_MEASUREMENT = 1,

  /**
   * Use the best measurement reported.
   *
   * @generated from enum value: BEST_MEASUREMENT = 2;
   */
  BEST_MEASUREMENT = 2,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.StudySpec.MeasurementSelectionType.
 */
export const StudySpec_MeasurementSelectionTypeSchema: GenEnum<StudySpec_MeasurementSelectionType> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_study, 4, 2);

/**
 * A message representing a Measurement of a Trial. A Measurement contains
 * the Metrics got by executing a Trial using suggested hyperparameter
 * values.
 *
 * @generated from message google.cloud.aiplatform.v1.Measurement
 */
export type Measurement = Message<"google.cloud.aiplatform.v1.Measurement"> & {
  /**
   * Output only. Time that the Trial has been running at the point of this
   * Measurement.
   *
   * @generated from field: google.protobuf.Duration elapsed_duration = 1;
   */
  elapsedDuration?: Duration;

  /**
   * Output only. The number of steps the machine learning model has been
   * trained for. Must be non-negative.
   *
   * @generated from field: int64 step_count = 2;
   */
  stepCount: bigint;

  /**
   * Output only. A list of metrics got by evaluating the objective functions
   * using suggested Parameter values.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.Measurement.Metric metrics = 3;
   */
  metrics: Measurement_Metric[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.Measurement.
 * Use `create(MeasurementSchema)` to create a new message.
 */
export const MeasurementSchema: GenMessage<Measurement> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 5);

/**
 * A message representing a metric in the measurement.
 *
 * @generated from message google.cloud.aiplatform.v1.Measurement.Metric
 */
export type Measurement_Metric = Message<"google.cloud.aiplatform.v1.Measurement.Metric"> & {
  /**
   * Output only. The ID of the Metric. The Metric should be defined in
   * [StudySpec's Metrics][google.cloud.aiplatform.v1.StudySpec.metrics].
   *
   * @generated from field: string metric_id = 1;
   */
  metricId: string;

  /**
   * Output only. The value for this metric.
   *
   * @generated from field: double value = 2;
   */
  value: number;
};

/**
 * Describes the message google.cloud.aiplatform.v1.Measurement.Metric.
 * Use `create(Measurement_MetricSchema)` to create a new message.
 */
export const Measurement_MetricSchema: GenMessage<Measurement_Metric> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_study, 5, 0);

