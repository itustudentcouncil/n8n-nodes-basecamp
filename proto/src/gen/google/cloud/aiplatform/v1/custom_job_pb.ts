// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/aiplatform/v1/custom_job.proto (package google.cloud.aiplatform.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { EncryptionSpec } from "./encryption_spec_pb";
import { file_google_cloud_aiplatform_v1_encryption_spec } from "./encryption_spec_pb";
import type { EnvVar } from "./env_var_pb";
import { file_google_cloud_aiplatform_v1_env_var } from "./env_var_pb";
import type { GcsDestination } from "./io_pb";
import { file_google_cloud_aiplatform_v1_io } from "./io_pb";
import type { JobState } from "./job_state_pb";
import { file_google_cloud_aiplatform_v1_job_state } from "./job_state_pb";
import type { DiskSpec, MachineSpec, NfsMount } from "./machine_resources_pb";
import { file_google_cloud_aiplatform_v1_machine_resources } from "./machine_resources_pb";
import type { Duration, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../rpc/status_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/aiplatform/v1/custom_job.proto.
 */
export const file_google_cloud_aiplatform_v1_custom_job: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_aiplatform_v1_encryption_spec, file_google_cloud_aiplatform_v1_env_var, file_google_cloud_aiplatform_v1_io, file_google_cloud_aiplatform_v1_job_state, file_google_cloud_aiplatform_v1_machine_resources, file_google_protobuf_duration, file_google_protobuf_timestamp, file_google_rpc_status]);

/**
 * Represents a job that runs custom workloads such as a Docker container or a
 * Python package. A CustomJob can have multiple worker pools and each worker
 * pool can have its own machine and input spec. A CustomJob will be cleaned up
 * once the job enters terminal state (failed or succeeded).
 *
 * @generated from message google.cloud.aiplatform.v1.CustomJob
 */
export type CustomJob = Message<"google.cloud.aiplatform.v1.CustomJob"> & {
  /**
   * Output only. Resource name of a CustomJob.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. The display name of the CustomJob.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   *
   * @generated from field: string display_name = 2;
   */
  displayName: string;

  /**
   * Required. Job spec.
   *
   * @generated from field: google.cloud.aiplatform.v1.CustomJobSpec job_spec = 4;
   */
  jobSpec?: CustomJobSpec;

  /**
   * Output only. The detailed state of the job.
   *
   * @generated from field: google.cloud.aiplatform.v1.JobState state = 5;
   */
  state: JobState;

  /**
   * Output only. Time when the CustomJob was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 6;
   */
  createTime?: Timestamp;

  /**
   * Output only. Time when the CustomJob for the first time entered the
   * `JOB_STATE_RUNNING` state.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 7;
   */
  startTime?: Timestamp;

  /**
   * Output only. Time when the CustomJob entered any of the following states:
   * `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 8;
   */
  endTime?: Timestamp;

  /**
   * Output only. Time when the CustomJob was most recently updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 9;
   */
  updateTime?: Timestamp;

  /**
   * Output only. Only populated when job's state is `JOB_STATE_FAILED` or
   * `JOB_STATE_CANCELLED`.
   *
   * @generated from field: google.rpc.Status error = 10;
   */
  error?: Status;

  /**
   * The labels with user-defined metadata to organize CustomJobs.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   *
   * See https://goo.gl/xmQnxf for more information and examples of labels.
   *
   * @generated from field: map<string, string> labels = 11;
   */
  labels: { [key: string]: string };

  /**
   * Customer-managed encryption key options for a CustomJob. If this is set,
   * then all resources created by the CustomJob will be encrypted with the
   * provided encryption key.
   *
   * @generated from field: google.cloud.aiplatform.v1.EncryptionSpec encryption_spec = 12;
   */
  encryptionSpec?: EncryptionSpec;

  /**
   * Output only. URIs for accessing [interactive
   * shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
   * (one URI for each training node). Only available if
   * [job_spec.enable_web_access][google.cloud.aiplatform.v1.CustomJobSpec.enable_web_access]
   * is `true`.
   *
   * The keys are names of each node in the training job; for example,
   * `workerpool0-0` for the primary node, `workerpool1-0` for the first node in
   * the second worker pool, and `workerpool1-1` for the second node in the
   * second worker pool.
   *
   * The values are the URIs for each node's interactive shell.
   *
   * @generated from field: map<string, string> web_access_uris = 16;
   */
  webAccessUris: { [key: string]: string };

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzs = 18;
   */
  satisfiesPzs: boolean;

  /**
   * Output only. Reserved for future use.
   *
   * @generated from field: bool satisfies_pzi = 19;
   */
  satisfiesPzi: boolean;
};

/**
 * Describes the message google.cloud.aiplatform.v1.CustomJob.
 * Use `create(CustomJobSchema)` to create a new message.
 */
export const CustomJobSchema: GenMessage<CustomJob> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_custom_job, 0);

/**
 * Represents the spec of a CustomJob.
 *
 * @generated from message google.cloud.aiplatform.v1.CustomJobSpec
 */
export type CustomJobSpec = Message<"google.cloud.aiplatform.v1.CustomJobSpec"> & {
  /**
   * Optional. The ID of the PersistentResource in the same Project and Location
   * which to run
   *
   * If this is specified, the job will be run on existing machines held by the
   * PersistentResource instead of on-demand short-live machines.
   * The network and CMEK configs on the job should be consistent with those on
   * the PersistentResource, otherwise, the job will be rejected.
   *
   * @generated from field: string persistent_resource_id = 14;
   */
  persistentResourceId: string;

  /**
   * Required. The spec of the worker pools including machine type and Docker
   * image. All worker pools except the first one are optional and can be
   * skipped by providing an empty value.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.WorkerPoolSpec worker_pool_specs = 1;
   */
  workerPoolSpecs: WorkerPoolSpec[];

  /**
   * Scheduling options for a CustomJob.
   *
   * @generated from field: google.cloud.aiplatform.v1.Scheduling scheduling = 3;
   */
  scheduling?: Scheduling;

  /**
   * Specifies the service account for workload run-as account.
   * Users submitting jobs must have act-as permission on this run-as account.
   * If unspecified, the [Vertex AI Custom Code Service
   * Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
   * for the CustomJob's project is used.
   *
   * @generated from field: string service_account = 4;
   */
  serviceAccount: string;

  /**
   * Optional. The full name of the Compute Engine
   * [network](/compute/docs/networks-and-firewalls#networks) to which the Job
   * should be peered. For example, `projects/12345/global/networks/myVPC`.
   * [Format](/compute/docs/reference/rest/v1/networks/insert)
   * is of the form `projects/{project}/global/networks/{network}`.
   * Where {project} is a project number, as in `12345`, and {network} is a
   * network name.
   *
   * To specify this field, you must have already [configured VPC Network
   * Peering for Vertex
   * AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering).
   *
   * If this field is left unspecified, the job is not peered with any network.
   *
   * @generated from field: string network = 5;
   */
  network: string;

  /**
   * Optional. A list of names for the reserved ip ranges under the VPC network
   * that can be used for this job.
   *
   * If set, we will deploy the job within the provided ip ranges. Otherwise,
   * the job will be deployed to any ip ranges under the provided VPC
   * network.
   *
   * Example: ['vertex-ai-ip-range'].
   *
   * @generated from field: repeated string reserved_ip_ranges = 13;
   */
  reservedIpRanges: string[];

  /**
   * The Cloud Storage location to store the output of this CustomJob or
   * HyperparameterTuningJob. For HyperparameterTuningJob,
   * the baseOutputDirectory of
   * each child CustomJob backing a Trial is set to a subdirectory of name
   * [id][google.cloud.aiplatform.v1.Trial.id] under its parent
   * HyperparameterTuningJob's baseOutputDirectory.
   *
   * The following Vertex AI environment variables will be passed to
   * containers or python modules when this field is set:
   *
   *   For CustomJob:
   *
   *   * AIP_MODEL_DIR = `<base_output_directory>/model/`
   *   * AIP_CHECKPOINT_DIR = `<base_output_directory>/checkpoints/`
   *   * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/logs/`
   *
   *   For CustomJob backing a Trial of HyperparameterTuningJob:
   *
   *   * AIP_MODEL_DIR = `<base_output_directory>/<trial_id>/model/`
   *   * AIP_CHECKPOINT_DIR = `<base_output_directory>/<trial_id>/checkpoints/`
   *   * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/<trial_id>/logs/`
   *
   * @generated from field: google.cloud.aiplatform.v1.GcsDestination base_output_directory = 6;
   */
  baseOutputDirectory?: GcsDestination;

  /**
   * The ID of the location to store protected artifacts. e.g. us-central1.
   * Populate only when the location is different than CustomJob location.
   * List of supported locations:
   * https://cloud.google.com/vertex-ai/docs/general/locations
   *
   * @generated from field: string protected_artifact_location_id = 19;
   */
  protectedArtifactLocationId: string;

  /**
   * Optional. The name of a Vertex AI
   * [Tensorboard][google.cloud.aiplatform.v1.Tensorboard] resource to which
   * this CustomJob will upload Tensorboard logs. Format:
   * `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
   *
   * @generated from field: string tensorboard = 7;
   */
  tensorboard: string;

  /**
   * Optional. Whether you want Vertex AI to enable [interactive shell
   * access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
   * to training containers.
   *
   * If set to `true`, you can access interactive shells at the URIs given
   * by
   * [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris]
   * or
   * [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris]
   * (within
   * [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
   *
   * @generated from field: bool enable_web_access = 10;
   */
  enableWebAccess: boolean;

  /**
   * Optional. Whether you want Vertex AI to enable access to the customized
   * dashboard in training chief container.
   *
   * If set to `true`, you can access the dashboard at the URIs given
   * by
   * [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris]
   * or
   * [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris]
   * (within
   * [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
   *
   * @generated from field: bool enable_dashboard_access = 16;
   */
  enableDashboardAccess: boolean;

  /**
   * Optional. The Experiment associated with this job.
   * Format:
   * `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
   *
   * @generated from field: string experiment = 17;
   */
  experiment: string;

  /**
   * Optional. The Experiment Run associated with this job.
   * Format:
   * `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
   *
   * @generated from field: string experiment_run = 18;
   */
  experimentRun: string;

  /**
   * Optional. The name of the Model resources for which to generate a mapping
   * to artifact URIs. Applicable only to some of the Google-provided custom
   * jobs. Format: `projects/{project}/locations/{location}/models/{model}`
   *
   * In order to retrieve a specific version of the model, also provide
   * the version ID or version alias.
   *   Example: `projects/{project}/locations/{location}/models/{model}@2`
   *              or
   *            `projects/{project}/locations/{location}/models/{model}@golden`
   * If no version ID or alias is specified, the "default" version will be
   * returned. The "default" version alias is created for the first version of
   * the model, and can be moved to other versions later on. There will be
   * exactly one default version.
   *
   * @generated from field: repeated string models = 20;
   */
  models: string[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.CustomJobSpec.
 * Use `create(CustomJobSpecSchema)` to create a new message.
 */
export const CustomJobSpecSchema: GenMessage<CustomJobSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_custom_job, 1);

/**
 * Represents the spec of a worker pool in a job.
 *
 * @generated from message google.cloud.aiplatform.v1.WorkerPoolSpec
 */
export type WorkerPoolSpec = Message<"google.cloud.aiplatform.v1.WorkerPoolSpec"> & {
  /**
   * The custom task to be executed in this worker pool.
   *
   * @generated from oneof google.cloud.aiplatform.v1.WorkerPoolSpec.task
   */
  task: {
    /**
     * The custom container task.
     *
     * @generated from field: google.cloud.aiplatform.v1.ContainerSpec container_spec = 6;
     */
    value: ContainerSpec;
    case: "containerSpec";
  } | {
    /**
     * The Python packaged task.
     *
     * @generated from field: google.cloud.aiplatform.v1.PythonPackageSpec python_package_spec = 7;
     */
    value: PythonPackageSpec;
    case: "pythonPackageSpec";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. Immutable. The specification of a single machine.
   *
   * @generated from field: google.cloud.aiplatform.v1.MachineSpec machine_spec = 1;
   */
  machineSpec?: MachineSpec;

  /**
   * Optional. The number of worker replicas to use for this worker pool.
   *
   * @generated from field: int64 replica_count = 2;
   */
  replicaCount: bigint;

  /**
   * Optional. List of NFS mount spec.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.NfsMount nfs_mounts = 4;
   */
  nfsMounts: NfsMount[];

  /**
   * Disk spec.
   *
   * @generated from field: google.cloud.aiplatform.v1.DiskSpec disk_spec = 5;
   */
  diskSpec?: DiskSpec;
};

/**
 * Describes the message google.cloud.aiplatform.v1.WorkerPoolSpec.
 * Use `create(WorkerPoolSpecSchema)` to create a new message.
 */
export const WorkerPoolSpecSchema: GenMessage<WorkerPoolSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_custom_job, 2);

/**
 * The spec of a Container.
 *
 * @generated from message google.cloud.aiplatform.v1.ContainerSpec
 */
export type ContainerSpec = Message<"google.cloud.aiplatform.v1.ContainerSpec"> & {
  /**
   * Required. The URI of a container image in the Container Registry that is to
   * be run on each worker replica.
   *
   * @generated from field: string image_uri = 1;
   */
  imageUri: string;

  /**
   * The command to be invoked when the container is started.
   * It overrides the entrypoint instruction in Dockerfile when provided.
   *
   * @generated from field: repeated string command = 2;
   */
  command: string[];

  /**
   * The arguments to be passed when starting the container.
   *
   * @generated from field: repeated string args = 3;
   */
  args: string[];

  /**
   * Environment variables to be passed to the container.
   * Maximum limit is 100.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.EnvVar env = 4;
   */
  env: EnvVar[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.ContainerSpec.
 * Use `create(ContainerSpecSchema)` to create a new message.
 */
export const ContainerSpecSchema: GenMessage<ContainerSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_custom_job, 3);

/**
 * The spec of a Python packaged code.
 *
 * @generated from message google.cloud.aiplatform.v1.PythonPackageSpec
 */
export type PythonPackageSpec = Message<"google.cloud.aiplatform.v1.PythonPackageSpec"> & {
  /**
   * Required. The URI of a container image in Artifact Registry that will run
   * the provided Python package. Vertex AI provides a wide range of executor
   * images with pre-installed packages to meet users' various use cases. See
   * the list of [pre-built containers for
   * training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers).
   * You must use an image from this list.
   *
   * @generated from field: string executor_image_uri = 1;
   */
  executorImageUri: string;

  /**
   * Required. The Google Cloud Storage location of the Python package files
   * which are the training program and its dependent packages. The maximum
   * number of package URIs is 100.
   *
   * @generated from field: repeated string package_uris = 2;
   */
  packageUris: string[];

  /**
   * Required. The Python module name to run after installing the packages.
   *
   * @generated from field: string python_module = 3;
   */
  pythonModule: string;

  /**
   * Command line arguments to be passed to the Python task.
   *
   * @generated from field: repeated string args = 4;
   */
  args: string[];

  /**
   * Environment variables to be passed to the python module.
   * Maximum limit is 100.
   *
   * @generated from field: repeated google.cloud.aiplatform.v1.EnvVar env = 5;
   */
  env: EnvVar[];
};

/**
 * Describes the message google.cloud.aiplatform.v1.PythonPackageSpec.
 * Use `create(PythonPackageSpecSchema)` to create a new message.
 */
export const PythonPackageSpecSchema: GenMessage<PythonPackageSpec> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_custom_job, 4);

/**
 * All parameters related to queuing and scheduling of custom jobs.
 *
 * @generated from message google.cloud.aiplatform.v1.Scheduling
 */
export type Scheduling = Message<"google.cloud.aiplatform.v1.Scheduling"> & {
  /**
   * The maximum job running time. The default is 7 days.
   *
   * @generated from field: google.protobuf.Duration timeout = 1;
   */
  timeout?: Duration;

  /**
   * Restarts the entire CustomJob if a worker gets restarted.
   * This feature can be used by distributed training jobs that are not
   * resilient to workers leaving and joining a job.
   *
   * @generated from field: bool restart_job_on_worker_restart = 3;
   */
  restartJobOnWorkerRestart: boolean;

  /**
   * Optional. This determines which type of scheduling strategy to use.
   *
   * @generated from field: google.cloud.aiplatform.v1.Scheduling.Strategy strategy = 4;
   */
  strategy: Scheduling_Strategy;

  /**
   * Optional. Indicates if the job should retry for internal errors after the
   * job starts running. If true, overrides
   * `Scheduling.restart_job_on_worker_restart` to false.
   *
   * @generated from field: bool disable_retries = 5;
   */
  disableRetries: boolean;

  /**
   * Optional. This is the maximum duration that a job will wait for the
   * requested resources to be provisioned if the scheduling strategy is set to
   * [Strategy.DWS_FLEX_START].
   * If set to 0, the job will wait indefinitely. The default is 24 hours.
   *
   * @generated from field: google.protobuf.Duration max_wait_duration = 6;
   */
  maxWaitDuration?: Duration;
};

/**
 * Describes the message google.cloud.aiplatform.v1.Scheduling.
 * Use `create(SchedulingSchema)` to create a new message.
 */
export const SchedulingSchema: GenMessage<Scheduling> = /*@__PURE__*/
  messageDesc(file_google_cloud_aiplatform_v1_custom_job, 5);

/**
 * Optional. This determines which type of scheduling strategy to use. Right
 * now users have two options such as STANDARD which will use regular on
 * demand resources to schedule the job, the other is SPOT which would
 * leverage spot resources alongwith regular resources to schedule
 * the job.
 *
 * @generated from enum google.cloud.aiplatform.v1.Scheduling.Strategy
 */
export enum Scheduling_Strategy {
  /**
   * Strategy will default to STANDARD.
   *
   * @generated from enum value: STRATEGY_UNSPECIFIED = 0;
   */
  STRATEGY_UNSPECIFIED = 0,

  /**
   * Deprecated. Regular on-demand provisioning strategy.
   *
   * @generated from enum value: ON_DEMAND = 1 [deprecated = true];
   * @deprecated
   */
  ON_DEMAND = 1,

  /**
   * Deprecated. Low cost by making potential use of spot resources.
   *
   * @generated from enum value: LOW_COST = 2 [deprecated = true];
   * @deprecated
   */
  LOW_COST = 2,

  /**
   * Standard provisioning strategy uses regular on-demand resources.
   *
   * @generated from enum value: STANDARD = 3;
   */
  STANDARD = 3,

  /**
   * Spot provisioning strategy uses spot resources.
   *
   * @generated from enum value: SPOT = 4;
   */
  SPOT = 4,

  /**
   * Flex Start strategy uses DWS to queue for resources.
   *
   * @generated from enum value: FLEX_START = 6;
   */
  FLEX_START = 6,
}

/**
 * Describes the enum google.cloud.aiplatform.v1.Scheduling.Strategy.
 */
export const Scheduling_StrategySchema: GenEnum<Scheduling_Strategy> = /*@__PURE__*/
  enumDesc(file_google_cloud_aiplatform_v1_custom_job, 5, 0);

