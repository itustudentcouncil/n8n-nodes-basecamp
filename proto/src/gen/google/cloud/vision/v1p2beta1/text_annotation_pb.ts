// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/vision/v1p2beta1/text_annotation.proto (package google.cloud.vision.v1p2beta1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { BoundingPoly } from "./geometry_pb";
import { file_google_cloud_vision_v1p2beta1_geometry } from "./geometry_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/vision/v1p2beta1/text_annotation.proto.
 */
export const file_google_cloud_vision_v1p2beta1_text_annotation: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_cloud_vision_v1p2beta1_geometry]);

/**
 * TextAnnotation contains a structured representation of OCR extracted text.
 * The hierarchy of an OCR extracted text structure is like this:
 *     TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol
 * Each structural component, starting from Page, may further have their own
 * properties. Properties describe detected languages, breaks etc.. Please refer
 * to the
 * [TextAnnotation.TextProperty][google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty]
 * message definition below for more detail.
 *
 * @generated from message google.cloud.vision.v1p2beta1.TextAnnotation
 */
export type TextAnnotation = Message<"google.cloud.vision.v1p2beta1.TextAnnotation"> & {
  /**
   * List of pages detected by OCR.
   *
   * @generated from field: repeated google.cloud.vision.v1p2beta1.Page pages = 1;
   */
  pages: Page[];

  /**
   * UTF-8 text detected on the pages.
   *
   * @generated from field: string text = 2;
   */
  text: string;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.TextAnnotation.
 * Use `create(TextAnnotationSchema)` to create a new message.
 */
export const TextAnnotationSchema: GenMessage<TextAnnotation> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 0);

/**
 * Detected language for a structural component.
 *
 * @generated from message google.cloud.vision.v1p2beta1.TextAnnotation.DetectedLanguage
 */
export type TextAnnotation_DetectedLanguage = Message<"google.cloud.vision.v1p2beta1.TextAnnotation.DetectedLanguage"> & {
  /**
   * The BCP-47 language code, such as "en-US" or "sr-Latn". For more
   * information, see
   * http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
   *
   * @generated from field: string language_code = 1;
   */
  languageCode: string;

  /**
   * Confidence of detected language. Range [0, 1].
   *
   * @generated from field: float confidence = 2;
   */
  confidence: number;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.TextAnnotation.DetectedLanguage.
 * Use `create(TextAnnotation_DetectedLanguageSchema)` to create a new message.
 */
export const TextAnnotation_DetectedLanguageSchema: GenMessage<TextAnnotation_DetectedLanguage> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 0, 0);

/**
 * Detected start or end of a structural component.
 *
 * @generated from message google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak
 */
export type TextAnnotation_DetectedBreak = Message<"google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak"> & {
  /**
   * Detected break type.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak.BreakType type = 1;
   */
  type: TextAnnotation_DetectedBreak_BreakType;

  /**
   * True if break prepends the element.
   *
   * @generated from field: bool is_prefix = 2;
   */
  isPrefix: boolean;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak.
 * Use `create(TextAnnotation_DetectedBreakSchema)` to create a new message.
 */
export const TextAnnotation_DetectedBreakSchema: GenMessage<TextAnnotation_DetectedBreak> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 0, 1);

/**
 * Enum to denote the type of break found. New line, space etc.
 *
 * @generated from enum google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak.BreakType
 */
export enum TextAnnotation_DetectedBreak_BreakType {
  /**
   * Unknown break label type.
   *
   * @generated from enum value: UNKNOWN = 0;
   */
  UNKNOWN = 0,

  /**
   * Regular space.
   *
   * @generated from enum value: SPACE = 1;
   */
  SPACE = 1,

  /**
   * Sure space (very wide).
   *
   * @generated from enum value: SURE_SPACE = 2;
   */
  SURE_SPACE = 2,

  /**
   * Line-wrapping break.
   *
   * @generated from enum value: EOL_SURE_SPACE = 3;
   */
  EOL_SURE_SPACE = 3,

  /**
   * End-line hyphen that is not present in text; does not co-occur with
   * `SPACE`, `LEADER_SPACE`, or `LINE_BREAK`.
   *
   * @generated from enum value: HYPHEN = 4;
   */
  HYPHEN = 4,

  /**
   * Line break that ends a paragraph.
   *
   * @generated from enum value: LINE_BREAK = 5;
   */
  LINE_BREAK = 5,
}

/**
 * Describes the enum google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak.BreakType.
 */
export const TextAnnotation_DetectedBreak_BreakTypeSchema: GenEnum<TextAnnotation_DetectedBreak_BreakType> = /*@__PURE__*/
  enumDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 0, 1, 0);

/**
 * Additional information detected on the structural component.
 *
 * @generated from message google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty
 */
export type TextAnnotation_TextProperty = Message<"google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty"> & {
  /**
   * A list of detected languages together with confidence.
   *
   * @generated from field: repeated google.cloud.vision.v1p2beta1.TextAnnotation.DetectedLanguage detected_languages = 1;
   */
  detectedLanguages: TextAnnotation_DetectedLanguage[];

  /**
   * Detected start or end of a text segment.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.DetectedBreak detected_break = 2;
   */
  detectedBreak?: TextAnnotation_DetectedBreak;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty.
 * Use `create(TextAnnotation_TextPropertySchema)` to create a new message.
 */
export const TextAnnotation_TextPropertySchema: GenMessage<TextAnnotation_TextProperty> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 0, 2);

/**
 * Detected page from OCR.
 *
 * @generated from message google.cloud.vision.v1p2beta1.Page
 */
export type Page = Message<"google.cloud.vision.v1p2beta1.Page"> & {
  /**
   * Additional information detected on the page.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty property = 1;
   */
  property?: TextAnnotation_TextProperty;

  /**
   * Page width. For PDFs the unit is points. For images (including
   * TIFFs) the unit is pixels.
   *
   * @generated from field: int32 width = 2;
   */
  width: number;

  /**
   * Page height. For PDFs the unit is points. For images (including
   * TIFFs) the unit is pixels.
   *
   * @generated from field: int32 height = 3;
   */
  height: number;

  /**
   * List of blocks of text, images etc on this page.
   *
   * @generated from field: repeated google.cloud.vision.v1p2beta1.Block blocks = 4;
   */
  blocks: Block[];

  /**
   * Confidence of the OCR results on the page. Range [0, 1].
   *
   * @generated from field: float confidence = 5;
   */
  confidence: number;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.Page.
 * Use `create(PageSchema)` to create a new message.
 */
export const PageSchema: GenMessage<Page> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 1);

/**
 * Logical element on the page.
 *
 * @generated from message google.cloud.vision.v1p2beta1.Block
 */
export type Block = Message<"google.cloud.vision.v1p2beta1.Block"> & {
  /**
   * Additional information detected for the block.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty property = 1;
   */
  property?: TextAnnotation_TextProperty;

  /**
   * The bounding box for the block.
   * The vertices are in the order of top-left, top-right, bottom-right,
   * bottom-left. When a rotation of the bounding box is detected the rotation
   * is represented as around the top-left corner as defined when the text is
   * read in the 'natural' orientation.
   * For example:
   *
   * * when the text is horizontal it might look like:
   *
   *         0----1
   *         |    |
   *         3----2
   *
   * * when it's rotated 180 degrees around the top-left corner it becomes:
   *
   *         2----3
   *         |    |
   *         1----0
   *
   *   and the vertice order will still be (0, 1, 2, 3).
   *
   * @generated from field: google.cloud.vision.v1p2beta1.BoundingPoly bounding_box = 2;
   */
  boundingBox?: BoundingPoly;

  /**
   * List of paragraphs in this block (if this blocks is of type text).
   *
   * @generated from field: repeated google.cloud.vision.v1p2beta1.Paragraph paragraphs = 3;
   */
  paragraphs: Paragraph[];

  /**
   * Detected block type (text, image etc) for this block.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.Block.BlockType block_type = 4;
   */
  blockType: Block_BlockType;

  /**
   * Confidence of the OCR results on the block. Range [0, 1].
   *
   * @generated from field: float confidence = 5;
   */
  confidence: number;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.Block.
 * Use `create(BlockSchema)` to create a new message.
 */
export const BlockSchema: GenMessage<Block> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 2);

/**
 * Type of a block (text, image etc) as identified by OCR.
 *
 * @generated from enum google.cloud.vision.v1p2beta1.Block.BlockType
 */
export enum Block_BlockType {
  /**
   * Unknown block type.
   *
   * @generated from enum value: UNKNOWN = 0;
   */
  UNKNOWN = 0,

  /**
   * Regular text block.
   *
   * @generated from enum value: TEXT = 1;
   */
  TEXT = 1,

  /**
   * Table block.
   *
   * @generated from enum value: TABLE = 2;
   */
  TABLE = 2,

  /**
   * Image block.
   *
   * @generated from enum value: PICTURE = 3;
   */
  PICTURE = 3,

  /**
   * Horizontal/vertical line box.
   *
   * @generated from enum value: RULER = 4;
   */
  RULER = 4,

  /**
   * Barcode block.
   *
   * @generated from enum value: BARCODE = 5;
   */
  BARCODE = 5,
}

/**
 * Describes the enum google.cloud.vision.v1p2beta1.Block.BlockType.
 */
export const Block_BlockTypeSchema: GenEnum<Block_BlockType> = /*@__PURE__*/
  enumDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 2, 0);

/**
 * Structural unit of text representing a number of words in certain order.
 *
 * @generated from message google.cloud.vision.v1p2beta1.Paragraph
 */
export type Paragraph = Message<"google.cloud.vision.v1p2beta1.Paragraph"> & {
  /**
   * Additional information detected for the paragraph.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty property = 1;
   */
  property?: TextAnnotation_TextProperty;

  /**
   * The bounding box for the paragraph.
   * The vertices are in the order of top-left, top-right, bottom-right,
   * bottom-left. When a rotation of the bounding box is detected the rotation
   * is represented as around the top-left corner as defined when the text is
   * read in the 'natural' orientation.
   * For example:
   *   * when the text is horizontal it might look like:
   *      0----1
   *      |    |
   *      3----2
   *   * when it's rotated 180 degrees around the top-left corner it becomes:
   *      2----3
   *      |    |
   *      1----0
   *   and the vertice order will still be (0, 1, 2, 3).
   *
   * @generated from field: google.cloud.vision.v1p2beta1.BoundingPoly bounding_box = 2;
   */
  boundingBox?: BoundingPoly;

  /**
   * List of words in this paragraph.
   *
   * @generated from field: repeated google.cloud.vision.v1p2beta1.Word words = 3;
   */
  words: Word[];

  /**
   * Confidence of the OCR results for the paragraph. Range [0, 1].
   *
   * @generated from field: float confidence = 4;
   */
  confidence: number;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.Paragraph.
 * Use `create(ParagraphSchema)` to create a new message.
 */
export const ParagraphSchema: GenMessage<Paragraph> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 3);

/**
 * A word representation.
 *
 * @generated from message google.cloud.vision.v1p2beta1.Word
 */
export type Word = Message<"google.cloud.vision.v1p2beta1.Word"> & {
  /**
   * Additional information detected for the word.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty property = 1;
   */
  property?: TextAnnotation_TextProperty;

  /**
   * The bounding box for the word.
   * The vertices are in the order of top-left, top-right, bottom-right,
   * bottom-left. When a rotation of the bounding box is detected the rotation
   * is represented as around the top-left corner as defined when the text is
   * read in the 'natural' orientation.
   * For example:
   *   * when the text is horizontal it might look like:
   *      0----1
   *      |    |
   *      3----2
   *   * when it's rotated 180 degrees around the top-left corner it becomes:
   *      2----3
   *      |    |
   *      1----0
   *   and the vertice order will still be (0, 1, 2, 3).
   *
   * @generated from field: google.cloud.vision.v1p2beta1.BoundingPoly bounding_box = 2;
   */
  boundingBox?: BoundingPoly;

  /**
   * List of symbols in the word.
   * The order of the symbols follows the natural reading order.
   *
   * @generated from field: repeated google.cloud.vision.v1p2beta1.Symbol symbols = 3;
   */
  symbols: Symbol[];

  /**
   * Confidence of the OCR results for the word. Range [0, 1].
   *
   * @generated from field: float confidence = 4;
   */
  confidence: number;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.Word.
 * Use `create(WordSchema)` to create a new message.
 */
export const WordSchema: GenMessage<Word> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 4);

/**
 * A single symbol representation.
 *
 * @generated from message google.cloud.vision.v1p2beta1.Symbol
 */
export type Symbol = Message<"google.cloud.vision.v1p2beta1.Symbol"> & {
  /**
   * Additional information detected for the symbol.
   *
   * @generated from field: google.cloud.vision.v1p2beta1.TextAnnotation.TextProperty property = 1;
   */
  property?: TextAnnotation_TextProperty;

  /**
   * The bounding box for the symbol.
   * The vertices are in the order of top-left, top-right, bottom-right,
   * bottom-left. When a rotation of the bounding box is detected the rotation
   * is represented as around the top-left corner as defined when the text is
   * read in the 'natural' orientation.
   * For example:
   *   * when the text is horizontal it might look like:
   *      0----1
   *      |    |
   *      3----2
   *   * when it's rotated 180 degrees around the top-left corner it becomes:
   *      2----3
   *      |    |
   *      1----0
   *   and the vertice order will still be (0, 1, 2, 3).
   *
   * @generated from field: google.cloud.vision.v1p2beta1.BoundingPoly bounding_box = 2;
   */
  boundingBox?: BoundingPoly;

  /**
   * The actual UTF-8 representation of the symbol.
   *
   * @generated from field: string text = 3;
   */
  text: string;

  /**
   * Confidence of the OCR results for the symbol. Range [0, 1].
   *
   * @generated from field: float confidence = 4;
   */
  confidence: number;
};

/**
 * Describes the message google.cloud.vision.v1p2beta1.Symbol.
 * Use `create(SymbolSchema)` to create a new message.
 */
export const SymbolSchema: GenMessage<Symbol> = /*@__PURE__*/
  messageDesc(file_google_cloud_vision_v1p2beta1_text_annotation, 5);

