// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/bigquery/storage/v1/stream.proto (package google.cloud.bigquery.storage.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../../api/resource_pb";
import type { ArrowSchema, ArrowSerializationOptions } from "./arrow_pb";
import { file_google_cloud_bigquery_storage_v1_arrow } from "./arrow_pb";
import type { AvroSchema, AvroSerializationOptions } from "./avro_pb";
import { file_google_cloud_bigquery_storage_v1_avro } from "./avro_pb";
import type { TableSchema } from "./table_pb";
import { file_google_cloud_bigquery_storage_v1_table } from "./table_pb";
import type { Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/bigquery/storage/v1/stream.proto.
 */
export const file_google_cloud_bigquery_storage_v1_stream: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_bigquery_storage_v1_arrow, file_google_cloud_bigquery_storage_v1_avro, file_google_cloud_bigquery_storage_v1_table, file_google_protobuf_timestamp]);

/**
 * Information about the ReadSession.
 *
 * @generated from message google.cloud.bigquery.storage.v1.ReadSession
 */
export type ReadSession = Message<"google.cloud.bigquery.storage.v1.ReadSession"> & {
  /**
   * Output only. Unique identifier for the session, in the form
   * `projects/{project_id}/locations/{location}/sessions/{session_id}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Output only. Time at which the session becomes invalid. After this time,
   * subsequent requests to read this Session will return errors. The
   * expire_time is automatically assigned and currently cannot be specified or
   * updated.
   *
   * @generated from field: google.protobuf.Timestamp expire_time = 2;
   */
  expireTime?: Timestamp;

  /**
   * Immutable. Data format of the output data. DATA_FORMAT_UNSPECIFIED not
   * supported.
   *
   * @generated from field: google.cloud.bigquery.storage.v1.DataFormat data_format = 3;
   */
  dataFormat: DataFormat;

  /**
   * The schema for the read. If read_options.selected_fields is set, the
   * schema may be different from the table schema as it will only contain
   * the selected fields.
   *
   * @generated from oneof google.cloud.bigquery.storage.v1.ReadSession.schema
   */
  schema: {
    /**
     * Output only. Avro schema.
     *
     * @generated from field: google.cloud.bigquery.storage.v1.AvroSchema avro_schema = 4;
     */
    value: AvroSchema;
    case: "avroSchema";
  } | {
    /**
     * Output only. Arrow schema.
     *
     * @generated from field: google.cloud.bigquery.storage.v1.ArrowSchema arrow_schema = 5;
     */
    value: ArrowSchema;
    case: "arrowSchema";
  } | { case: undefined; value?: undefined };

  /**
   * Immutable. Table that this ReadSession is reading from, in the form
   * `projects/{project_id}/datasets/{dataset_id}/tables/{table_id}`
   *
   * @generated from field: string table = 6;
   */
  table: string;

  /**
   * Optional. Any modifiers which are applied when reading from the specified
   * table.
   *
   * @generated from field: google.cloud.bigquery.storage.v1.ReadSession.TableModifiers table_modifiers = 7;
   */
  tableModifiers?: ReadSession_TableModifiers;

  /**
   * Optional. Read options for this session (e.g. column selection, filters).
   *
   * @generated from field: google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions read_options = 8;
   */
  readOptions?: ReadSession_TableReadOptions;

  /**
   * Output only. A list of streams created with the session.
   *
   * At least one stream is created with the session. In the future, larger
   * request_stream_count values *may* result in this list being unpopulated,
   * in that case, the user will need to use a List method to get the streams
   * instead, which is not yet available.
   *
   * @generated from field: repeated google.cloud.bigquery.storage.v1.ReadStream streams = 10;
   */
  streams: ReadStream[];

  /**
   * Output only. An estimate on the number of bytes this session will scan when
   * all streams are completely consumed. This estimate is based on
   * metadata from the table which might be incomplete or stale.
   *
   * @generated from field: int64 estimated_total_bytes_scanned = 12;
   */
  estimatedTotalBytesScanned: bigint;

  /**
   * Output only. A pre-projected estimate of the total physical size of files
   * (in bytes) that this session will scan when all streams are consumed. This
   * estimate is independent of the selected columns and can be based on
   * incomplete or stale metadata from the table.  This field is only set for
   * BigLake tables.
   *
   * @generated from field: int64 estimated_total_physical_file_size = 15;
   */
  estimatedTotalPhysicalFileSize: bigint;

  /**
   * Output only. An estimate on the number of rows present in this session's
   * streams. This estimate is based on metadata from the table which might be
   * incomplete or stale.
   *
   * @generated from field: int64 estimated_row_count = 14;
   */
  estimatedRowCount: bigint;

  /**
   * Optional. ID set by client to annotate a session identity.  This does not
   * need to be strictly unique, but instead the same ID should be used to group
   * logically connected sessions (e.g. All using the same ID for all sessions
   * needed to complete a Spark SQL query is reasonable).
   *
   * Maximum length is 256 bytes.
   *
   * @generated from field: string trace_id = 13;
   */
  traceId: string;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1.ReadSession.
 * Use `create(ReadSessionSchema)` to create a new message.
 */
export const ReadSessionSchema: GenMessage<ReadSession> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1_stream, 0);

/**
 * Additional attributes when reading a table.
 *
 * @generated from message google.cloud.bigquery.storage.v1.ReadSession.TableModifiers
 */
export type ReadSession_TableModifiers = Message<"google.cloud.bigquery.storage.v1.ReadSession.TableModifiers"> & {
  /**
   * The snapshot time of the table. If not set, interpreted as now.
   *
   * @generated from field: google.protobuf.Timestamp snapshot_time = 1;
   */
  snapshotTime?: Timestamp;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1.ReadSession.TableModifiers.
 * Use `create(ReadSession_TableModifiersSchema)` to create a new message.
 */
export const ReadSession_TableModifiersSchema: GenMessage<ReadSession_TableModifiers> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1_stream, 0, 0);

/**
 * Options dictating how we read a table.
 *
 * @generated from message google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions
 */
export type ReadSession_TableReadOptions = Message<"google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions"> & {
  /**
   * Optional. The names of the fields in the table to be returned. If no
   * field names are specified, then all fields in the table are returned.
   *
   * Nested fields -- the child elements of a STRUCT field -- can be selected
   * individually using their fully-qualified names, and will be returned as
   * record fields containing only the selected nested fields. If a STRUCT
   * field is specified in the selected fields list, all of the child elements
   * will be returned.
   *
   * As an example, consider a table with the following schema:
   *
   *   {
   *       "name": "struct_field",
   *       "type": "RECORD",
   *       "mode": "NULLABLE",
   *       "fields": [
   *           {
   *               "name": "string_field1",
   *               "type": "STRING",
   * .              "mode": "NULLABLE"
   *           },
   *           {
   *               "name": "string_field2",
   *               "type": "STRING",
   *               "mode": "NULLABLE"
   *           }
   *       ]
   *   }
   *
   * Specifying "struct_field" in the selected fields list will result in a
   * read session schema with the following logical structure:
   *
   *   struct_field {
   *       string_field1
   *       string_field2
   *   }
   *
   * Specifying "struct_field.string_field1" in the selected fields list will
   * result in a read session schema with the following logical structure:
   *
   *   struct_field {
   *       string_field1
   *   }
   *
   * The order of the fields in the read session schema is derived from the
   * table schema and does not correspond to the order in which the fields are
   * specified in this list.
   *
   * @generated from field: repeated string selected_fields = 1;
   */
  selectedFields: string[];

  /**
   * SQL text filtering statement, similar to a WHERE clause in a query.
   * Aggregates are not supported.
   *
   * Examples: "int_field > 5"
   *           "date_field = CAST('2014-9-27' as DATE)"
   *           "nullable_field is not NULL"
   *           "st_equals(geo_field, st_geofromtext("POINT(2, 2)"))"
   *           "numeric_field BETWEEN 1.0 AND 5.0"
   *
   * Restricted to a maximum length for 1 MB.
   *
   * @generated from field: string row_restriction = 2;
   */
  rowRestriction: string;

  /**
   * @generated from oneof google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions.output_format_serialization_options
   */
  outputFormatSerializationOptions: {
    /**
     * Optional. Options specific to the Apache Arrow output format.
     *
     * @generated from field: google.cloud.bigquery.storage.v1.ArrowSerializationOptions arrow_serialization_options = 3;
     */
    value: ArrowSerializationOptions;
    case: "arrowSerializationOptions";
  } | {
    /**
     * Optional. Options specific to the Apache Avro output format
     *
     * @generated from field: google.cloud.bigquery.storage.v1.AvroSerializationOptions avro_serialization_options = 4;
     */
    value: AvroSerializationOptions;
    case: "avroSerializationOptions";
  } | { case: undefined; value?: undefined };

  /**
   * Optional. Specifies a table sampling percentage. Specifically, the query
   * planner will use TABLESAMPLE SYSTEM (sample_percentage PERCENT). The
   * sampling percentage is applied at the data block granularity. It will
   * randomly choose for each data block whether to read the rows in that data
   * block. For more details, see
   * https://cloud.google.com/bigquery/docs/table-sampling)
   *
   * @generated from field: optional double sample_percentage = 5;
   */
  samplePercentage?: number;

  /**
   * Optional. Set response_compression_codec when creating a read session to
   * enable application-level compression of ReadRows responses.
   *
   * @generated from field: optional google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions.ResponseCompressionCodec response_compression_codec = 6;
   */
  responseCompressionCodec?: ReadSession_TableReadOptions_ResponseCompressionCodec;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions.
 * Use `create(ReadSession_TableReadOptionsSchema)` to create a new message.
 */
export const ReadSession_TableReadOptionsSchema: GenMessage<ReadSession_TableReadOptions> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1_stream, 0, 1);

/**
 * Specifies which compression codec to attempt on the entire serialized
 * response payload (either Arrow record batch or Avro rows). This is
 * not to be confused with the Apache Arrow native compression codecs
 * specified in ArrowSerializationOptions. For performance reasons, when
 * creating a read session requesting Arrow responses, setting both native
 * Arrow compression and application-level response compression will not be
 * allowed - choose, at most, one kind of compression.
 *
 * @generated from enum google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions.ResponseCompressionCodec
 */
export enum ReadSession_TableReadOptions_ResponseCompressionCodec {
  /**
   * Default is no compression.
   *
   * @generated from enum value: RESPONSE_COMPRESSION_CODEC_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * Use raw LZ4 compression.
   *
   * @generated from enum value: RESPONSE_COMPRESSION_CODEC_LZ4 = 2;
   */
  LZ4 = 2,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1.ReadSession.TableReadOptions.ResponseCompressionCodec.
 */
export const ReadSession_TableReadOptions_ResponseCompressionCodecSchema: GenEnum<ReadSession_TableReadOptions_ResponseCompressionCodec> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1_stream, 0, 1, 0);

/**
 * Information about a single stream that gets data out of the storage system.
 * Most of the information about `ReadStream` instances is aggregated, making
 * `ReadStream` lightweight.
 *
 * @generated from message google.cloud.bigquery.storage.v1.ReadStream
 */
export type ReadStream = Message<"google.cloud.bigquery.storage.v1.ReadStream"> & {
  /**
   * Output only. Name of the stream, in the form
   * `projects/{project_id}/locations/{location}/sessions/{session_id}/streams/{stream_id}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1.ReadStream.
 * Use `create(ReadStreamSchema)` to create a new message.
 */
export const ReadStreamSchema: GenMessage<ReadStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1_stream, 1);

/**
 * Information about a single stream that gets data inside the storage system.
 *
 * @generated from message google.cloud.bigquery.storage.v1.WriteStream
 */
export type WriteStream = Message<"google.cloud.bigquery.storage.v1.WriteStream"> & {
  /**
   * Output only. Name of the stream, in the form
   * `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Immutable. Type of the stream.
   *
   * @generated from field: google.cloud.bigquery.storage.v1.WriteStream.Type type = 2;
   */
  type: WriteStream_Type;

  /**
   * Output only. Create time of the stream. For the _default stream, this is
   * the creation_time of the table.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 3;
   */
  createTime?: Timestamp;

  /**
   * Output only. Commit time of the stream.
   * If a stream is of `COMMITTED` type, then it will have a commit_time same as
   * `create_time`. If the stream is of `PENDING` type, empty commit_time
   * means it is not committed.
   *
   * @generated from field: google.protobuf.Timestamp commit_time = 4;
   */
  commitTime?: Timestamp;

  /**
   * Output only. The schema of the destination table. It is only returned in
   * `CreateWriteStream` response. Caller should generate data that's
   * compatible with this schema to send in initial `AppendRowsRequest`.
   * The table schema could go out of date during the life time of the stream.
   *
   * @generated from field: google.cloud.bigquery.storage.v1.TableSchema table_schema = 5;
   */
  tableSchema?: TableSchema;

  /**
   * Immutable. Mode of the stream.
   *
   * @generated from field: google.cloud.bigquery.storage.v1.WriteStream.WriteMode write_mode = 7;
   */
  writeMode: WriteStream_WriteMode;

  /**
   * Immutable. The geographic location where the stream's dataset resides. See
   * https://cloud.google.com/bigquery/docs/locations for supported
   * locations.
   *
   * @generated from field: string location = 8;
   */
  location: string;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1.WriteStream.
 * Use `create(WriteStreamSchema)` to create a new message.
 */
export const WriteStreamSchema: GenMessage<WriteStream> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1_stream, 2);

/**
 * Type enum of the stream.
 *
 * @generated from enum google.cloud.bigquery.storage.v1.WriteStream.Type
 */
export enum WriteStream_Type {
  /**
   * Unknown type.
   *
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  TYPE_UNSPECIFIED = 0,

  /**
   * Data will commit automatically and appear as soon as the write is
   * acknowledged.
   *
   * @generated from enum value: COMMITTED = 1;
   */
  COMMITTED = 1,

  /**
   * Data is invisible until the stream is committed.
   *
   * @generated from enum value: PENDING = 2;
   */
  PENDING = 2,

  /**
   * Data is only visible up to the offset to which it was flushed.
   *
   * @generated from enum value: BUFFERED = 3;
   */
  BUFFERED = 3,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1.WriteStream.Type.
 */
export const WriteStream_TypeSchema: GenEnum<WriteStream_Type> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1_stream, 2, 0);

/**
 * Mode enum of the stream.
 *
 * @generated from enum google.cloud.bigquery.storage.v1.WriteStream.WriteMode
 */
export enum WriteStream_WriteMode {
  /**
   * Unknown type.
   *
   * @generated from enum value: WRITE_MODE_UNSPECIFIED = 0;
   */
  WRITE_MODE_UNSPECIFIED = 0,

  /**
   * Insert new records into the table.
   * It is the default value if customers do not specify it.
   *
   * @generated from enum value: INSERT = 1;
   */
  INSERT = 1,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1.WriteStream.WriteMode.
 */
export const WriteStream_WriteModeSchema: GenEnum<WriteStream_WriteMode> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1_stream, 2, 1);

/**
 * Data format for input or output data.
 *
 * @generated from enum google.cloud.bigquery.storage.v1.DataFormat
 */
export enum DataFormat {
  /**
   * Data format is unspecified.
   *
   * @generated from enum value: DATA_FORMAT_UNSPECIFIED = 0;
   */
  DATA_FORMAT_UNSPECIFIED = 0,

  /**
   * Avro is a standard open source row based file format.
   * See https://avro.apache.org/ for more details.
   *
   * @generated from enum value: AVRO = 1;
   */
  AVRO = 1,

  /**
   * Arrow is a standard open source column-based message format.
   * See https://arrow.apache.org/ for more details.
   *
   * @generated from enum value: ARROW = 2;
   */
  ARROW = 2,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1.DataFormat.
 */
export const DataFormatSchema: GenEnum<DataFormat> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1_stream, 0);

/**
 * WriteStreamView is a view enum that controls what details about a write
 * stream should be returned.
 *
 * @generated from enum google.cloud.bigquery.storage.v1.WriteStreamView
 */
export enum WriteStreamView {
  /**
   * The default / unset value.
   *
   * @generated from enum value: WRITE_STREAM_VIEW_UNSPECIFIED = 0;
   */
  WRITE_STREAM_VIEW_UNSPECIFIED = 0,

  /**
   * The BASIC projection returns basic metadata about a write stream.  The
   * basic view does not include schema information.  This is the default view
   * returned by GetWriteStream.
   *
   * @generated from enum value: BASIC = 1;
   */
  BASIC = 1,

  /**
   * The FULL projection returns all available write stream metadata, including
   * the schema.  CreateWriteStream returns the full projection of write stream
   * metadata.
   *
   * @generated from enum value: FULL = 2;
   */
  FULL = 2,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1.WriteStreamView.
 */
export const WriteStreamViewSchema: GenEnum<WriteStreamView> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1_stream, 1);

