// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/bigquery/storage/v1beta1/storage.proto (package google.cloud.bigquery.storage.v1beta1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../../api/annotations_pb";
import { file_google_api_client } from "../../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../../api/resource_pb";
import type { ArrowRecordBatch, ArrowSchema } from "./arrow_pb";
import { file_google_cloud_bigquery_storage_v1beta1_arrow } from "./arrow_pb";
import type { AvroRows, AvroSchema } from "./avro_pb";
import { file_google_cloud_bigquery_storage_v1beta1_avro } from "./avro_pb";
import type { TableReadOptions } from "./read_options_pb";
import { file_google_cloud_bigquery_storage_v1beta1_read_options } from "./read_options_pb";
import type { TableModifiers, TableReference } from "./table_reference_pb";
import { file_google_cloud_bigquery_storage_v1beta1_table_reference } from "./table_reference_pb";
import type { EmptySchema, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_empty, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/bigquery/storage/v1beta1/storage.proto.
 */
export const file_google_cloud_bigquery_storage_v1beta1_storage: GenFile = /*@__PURE__*/
  fileDesc("CjNnb29nbGUvY2xvdWQvYmlncXVlcnkvc3RvcmFnZS92MWJldGExL3N0b3JhZ2UucHJvdG8SJWdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEifAoGU3RyZWFtEgwKBG5hbWUYASABKAk6ZOpBYQolYmlncXVlcnlzdG9yYWdlLmdvb2dsZWFwaXMuY29tL1N0cmVhbRI4cHJvamVjdHMve3Byb2plY3R9L2xvY2F0aW9ucy97bG9jYXRpb259L3N0cmVhbXMve3N0cmVhbX0iXwoOU3RyZWFtUG9zaXRpb24SPQoGc3RyZWFtGAEgASgLMi0uZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TdHJlYW0SDgoGb2Zmc2V0GAIgASgDIo0FCgtSZWFkU2Vzc2lvbhIMCgRuYW1lGAEgASgJEi8KC2V4cGlyZV90aW1lGAIgASgLMhouZ29vZ2xlLnByb3RvYnVmLlRpbWVzdGFtcBJICgthdnJvX3NjaGVtYRgFIAEoCzIxLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuQXZyb1NjaGVtYUgAEkoKDGFycm93X3NjaGVtYRgGIAEoCzIyLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuQXJyb3dTY2hlbWFIABI+CgdzdHJlYW1zGAQgAygLMi0uZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TdHJlYW0STgoPdGFibGVfcmVmZXJlbmNlGAcgASgLMjUuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5UYWJsZVJlZmVyZW5jZRJOCg90YWJsZV9tb2RpZmllcnMYCCABKAsyNS5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLlRhYmxlTW9kaWZpZXJzElIKEXNoYXJkaW5nX3N0cmF0ZWd5GAkgASgOMjcuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TaGFyZGluZ1N0cmF0ZWd5OmvqQWgKKmJpZ3F1ZXJ5c3RvcmFnZS5nb29nbGVhcGlzLmNvbS9SZWFkU2Vzc2lvbhI6cHJvamVjdHMve3Byb2plY3R9L2xvY2F0aW9ucy97bG9jYXRpb259L3Nlc3Npb25zL3tzZXNzaW9ufUIICgZzY2hlbWEihQQKGENyZWF0ZVJlYWRTZXNzaW9uUmVxdWVzdBJTCg90YWJsZV9yZWZlcmVuY2UYASABKAsyNS5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLlRhYmxlUmVmZXJlbmNlQgPgQQISQwoGcGFyZW50GAYgASgJQjPgQQL6QS0KK2Nsb3VkcmVzb3VyY2VtYW5hZ2VyLmdvb2dsZWFwaXMuY29tL1Byb2plY3QSTgoPdGFibGVfbW9kaWZpZXJzGAIgASgLMjUuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5UYWJsZU1vZGlmaWVycxIZChFyZXF1ZXN0ZWRfc3RyZWFtcxgDIAEoBRJNCgxyZWFkX29wdGlvbnMYBCABKAsyNy5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLlRhYmxlUmVhZE9wdGlvbnMSQQoGZm9ybWF0GAUgASgOMjEuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5EYXRhRm9ybWF0ElIKEXNoYXJkaW5nX3N0cmF0ZWd5GAcgASgOMjcuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TaGFyZGluZ1N0cmF0ZWd5ImQKD1JlYWRSb3dzUmVxdWVzdBJRCg1yZWFkX3Bvc2l0aW9uGAEgASgLMjUuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TdHJlYW1Qb3NpdGlvbkID4EECIqABCgxTdHJlYW1TdGF0dXMSGwoTZXN0aW1hdGVkX3Jvd19jb3VudBgBIAEoAxIZChFmcmFjdGlvbl9jb25zdW1lZBgCIAEoAhJBCghwcm9ncmVzcxgEIAEoCzIvLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuUHJvZ3Jlc3MSFQoNaXNfc3BsaXR0YWJsZRgDIAEoCCI+CghQcm9ncmVzcxIZChFhdF9yZXNwb25zZV9zdGFydBgBIAEoAhIXCg9hdF9yZXNwb25zZV9lbmQYAiABKAIiKgoOVGhyb3R0bGVTdGF0dXMSGAoQdGhyb3R0bGVfcGVyY2VudBgBIAEoBSKJBAoQUmVhZFJvd3NSZXNwb25zZRJECglhdnJvX3Jvd3MYAyABKAsyLy5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLkF2cm9Sb3dzSAASVQoSYXJyb3dfcmVjb3JkX2JhdGNoGAQgASgLMjcuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5BcnJvd1JlY29yZEJhdGNoSAASEQoJcm93X2NvdW50GAYgASgDEkMKBnN0YXR1cxgCIAEoCzIzLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuU3RyZWFtU3RhdHVzEk4KD3Rocm90dGxlX3N0YXR1cxgFIAEoCzI1Lmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuVGhyb3R0bGVTdGF0dXMSTQoLYXZyb19zY2hlbWEYByABKAsyMS5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLkF2cm9TY2hlbWFCA+BBA0gBEk8KDGFycm93X3NjaGVtYRgIIAEoCzIyLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuQXJyb3dTY2hlbWFCA+BBA0gBQgYKBHJvd3NCCAoGc2NoZW1hIpABCiRCYXRjaENyZWF0ZVJlYWRTZXNzaW9uU3RyZWFtc1JlcXVlc3QSSAoHc2Vzc2lvbhgBIAEoCzIyLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuUmVhZFNlc3Npb25CA+BBAhIeChFyZXF1ZXN0ZWRfc3RyZWFtcxgCIAEoBUID4EECImcKJUJhdGNoQ3JlYXRlUmVhZFNlc3Npb25TdHJlYW1zUmVzcG9uc2USPgoHc3RyZWFtcxgBIAMoCzItLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuU3RyZWFtIlsKFUZpbmFsaXplU3RyZWFtUmVxdWVzdBJCCgZzdHJlYW0YAiABKAsyLS5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLlN0cmVhbUID4EECIncKFlNwbGl0UmVhZFN0cmVhbVJlcXVlc3QSSwoPb3JpZ2luYWxfc3RyZWFtGAEgASgLMi0uZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TdHJlYW1CA+BBAhIQCghmcmFjdGlvbhgCIAEoAiKpAQoXU3BsaXRSZWFkU3RyZWFtUmVzcG9uc2USRQoOcHJpbWFyeV9zdHJlYW0YASABKAsyLS5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLlN0cmVhbRJHChByZW1haW5kZXJfc3RyZWFtGAIgASgLMi0uZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5TdHJlYW0qPgoKRGF0YUZvcm1hdBIbChdEQVRBX0ZPUk1BVF9VTlNQRUNJRklFRBAAEggKBEFWUk8QARIJCgVBUlJPVxADKk8KEFNoYXJkaW5nU3RyYXRlZ3kSIQodU0hBUkRJTkdfU1RSQVRFR1lfVU5TUEVDSUZJRUQQABIKCgZMSVFVSUQQARIMCghCQUxBTkNFRBACMrcKCg9CaWdRdWVyeVN0b3JhZ2USswIKEUNyZWF0ZVJlYWRTZXNzaW9uEj8uZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5DcmVhdGVSZWFkU2Vzc2lvblJlcXVlc3QaMi5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLlJlYWRTZXNzaW9uIqgB2kEodGFibGVfcmVmZXJlbmNlLHBhcmVudCxyZXF1ZXN0ZWRfc3RyZWFtc4LT5JMCdzoBKlpAOgEqIjsvdjFiZXRhMS97dGFibGVfcmVmZXJlbmNlLmRhdGFzZXRfaWQ9cHJvamVjdHMvKi9kYXRhc2V0cy8qfSIwL3YxYmV0YTEve3RhYmxlX3JlZmVyZW5jZS5wcm9qZWN0X2lkPXByb2plY3RzLyp9EtABCghSZWFkUm93cxI2Lmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuUmVhZFJvd3NSZXF1ZXN0GjcuZ29vZ2xlLmNsb3VkLmJpZ3F1ZXJ5LnN0b3JhZ2UudjFiZXRhMS5SZWFkUm93c1Jlc3BvbnNlIlHaQQ1yZWFkX3Bvc2l0aW9ugtPkkwI7EjkvdjFiZXRhMS97cmVhZF9wb3NpdGlvbi5zdHJlYW0ubmFtZT1wcm9qZWN0cy8qL3N0cmVhbXMvKn0wARKQAgodQmF0Y2hDcmVhdGVSZWFkU2Vzc2lvblN0cmVhbXMSSy5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExLkJhdGNoQ3JlYXRlUmVhZFNlc3Npb25TdHJlYW1zUmVxdWVzdBpMLmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuQmF0Y2hDcmVhdGVSZWFkU2Vzc2lvblN0cmVhbXNSZXNwb25zZSJU2kEZc2Vzc2lvbixyZXF1ZXN0ZWRfc3RyZWFtc4LT5JMCMjoBKiItL3YxYmV0YTEve3Nlc3Npb24ubmFtZT1wcm9qZWN0cy8qL3Nlc3Npb25zLyp9EqcBCg5GaW5hbGl6ZVN0cmVhbRI8Lmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuRmluYWxpemVTdHJlYW1SZXF1ZXN0GhYuZ29vZ2xlLnByb3RvYnVmLkVtcHR5Ij/aQQZzdHJlYW2C0+STAjA6ASoiKy92MWJldGExL3tzdHJlYW0ubmFtZT1wcm9qZWN0cy8qL3N0cmVhbXMvKn0S4AEKD1NwbGl0UmVhZFN0cmVhbRI9Lmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuU3BsaXRSZWFkU3RyZWFtUmVxdWVzdBo+Lmdvb2dsZS5jbG91ZC5iaWdxdWVyeS5zdG9yYWdlLnYxYmV0YTEuU3BsaXRSZWFkU3RyZWFtUmVzcG9uc2UiTtpBD29yaWdpbmFsX3N0cmVhbYLT5JMCNhI0L3YxYmV0YTEve29yaWdpbmFsX3N0cmVhbS5uYW1lPXByb2plY3RzLyovc3RyZWFtcy8qfRp7ykEeYmlncXVlcnlzdG9yYWdlLmdvb2dsZWFwaXMuY29t0kFXaHR0cHM6Ly93d3cuZ29vZ2xlYXBpcy5jb20vYXV0aC9iaWdxdWVyeSxodHRwczovL3d3dy5nb29nbGVhcGlzLmNvbS9hdXRoL2Nsb3VkLXBsYXRmb3JtQnAKKWNvbS5nb29nbGUuY2xvdWQuYmlncXVlcnkuc3RvcmFnZS52MWJldGExWkNjbG91ZC5nb29nbGUuY29tL2dvL2JpZ3F1ZXJ5L3N0b3JhZ2UvYXBpdjFiZXRhMS9zdG9yYWdlcGI7c3RvcmFnZXBiYgZwcm90bzM", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_cloud_bigquery_storage_v1beta1_arrow, file_google_cloud_bigquery_storage_v1beta1_avro, file_google_cloud_bigquery_storage_v1beta1_read_options, file_google_cloud_bigquery_storage_v1beta1_table_reference, file_google_protobuf_empty, file_google_protobuf_timestamp]);

/**
 * Information about a single data stream within a read session.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.Stream
 */
export type Stream = Message<"google.cloud.bigquery.storage.v1beta1.Stream"> & {
  /**
   * Name of the stream, in the form
   * `projects/{project_id}/locations/{location}/streams/{stream_id}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.Stream.
 * Use `create(StreamSchema)` to create a new message.
 */
export const StreamSchema: GenMessage<Stream> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 0);

/**
 * Expresses a point within a given stream using an offset position.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.StreamPosition
 */
export type StreamPosition = Message<"google.cloud.bigquery.storage.v1beta1.StreamPosition"> & {
  /**
   * Identifier for a given Stream.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.Stream stream = 1;
   */
  stream?: Stream;

  /**
   * Position in the stream.
   *
   * @generated from field: int64 offset = 2;
   */
  offset: bigint;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.StreamPosition.
 * Use `create(StreamPositionSchema)` to create a new message.
 */
export const StreamPositionSchema: GenMessage<StreamPosition> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 1);

/**
 * Information returned from a `CreateReadSession` request.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.ReadSession
 */
export type ReadSession = Message<"google.cloud.bigquery.storage.v1beta1.ReadSession"> & {
  /**
   * Unique identifier for the session, in the form
   * `projects/{project_id}/locations/{location}/sessions/{session_id}`.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Time at which the session becomes invalid. After this time, subsequent
   * requests to read this Session will return errors.
   *
   * @generated from field: google.protobuf.Timestamp expire_time = 2;
   */
  expireTime?: Timestamp;

  /**
   * The schema for the read. If read_options.selected_fields is set, the
   * schema may be different from the table schema as it will only contain
   * the selected fields.
   *
   * @generated from oneof google.cloud.bigquery.storage.v1beta1.ReadSession.schema
   */
  schema: {
    /**
     * Avro schema.
     *
     * @generated from field: google.cloud.bigquery.storage.v1beta1.AvroSchema avro_schema = 5;
     */
    value: AvroSchema;
    case: "avroSchema";
  } | {
    /**
     * Arrow schema.
     *
     * @generated from field: google.cloud.bigquery.storage.v1beta1.ArrowSchema arrow_schema = 6;
     */
    value: ArrowSchema;
    case: "arrowSchema";
  } | { case: undefined; value?: undefined };

  /**
   * Streams associated with this session.
   *
   * @generated from field: repeated google.cloud.bigquery.storage.v1beta1.Stream streams = 4;
   */
  streams: Stream[];

  /**
   * Table that this ReadSession is reading from.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.TableReference table_reference = 7;
   */
  tableReference?: TableReference;

  /**
   * Any modifiers which are applied when reading from the specified table.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.TableModifiers table_modifiers = 8;
   */
  tableModifiers?: TableModifiers;

  /**
   * The strategy to use for distributing data among the streams.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.ShardingStrategy sharding_strategy = 9;
   */
  shardingStrategy: ShardingStrategy;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.ReadSession.
 * Use `create(ReadSessionSchema)` to create a new message.
 */
export const ReadSessionSchema: GenMessage<ReadSession> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 2);

/**
 * Creates a new read session, which may include additional options such as
 * requested parallelism, projection filters and constraints.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.CreateReadSessionRequest
 */
export type CreateReadSessionRequest = Message<"google.cloud.bigquery.storage.v1beta1.CreateReadSessionRequest"> & {
  /**
   * Required. Reference to the table to read.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.TableReference table_reference = 1;
   */
  tableReference?: TableReference;

  /**
   * Required. String of the form `projects/{project_id}` indicating the
   * project this ReadSession is associated with. This is the project that will
   * be billed for usage.
   *
   * @generated from field: string parent = 6;
   */
  parent: string;

  /**
   * Any modifiers to the Table (e.g. snapshot timestamp).
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.TableModifiers table_modifiers = 2;
   */
  tableModifiers?: TableModifiers;

  /**
   * Initial number of streams. If unset or 0, we will
   * provide a value of streams so as to produce reasonable throughput. Must be
   * non-negative. The number of streams may be lower than the requested number,
   * depending on the amount parallelism that is reasonable for the table and
   * the maximum amount of parallelism allowed by the system.
   *
   * Streams must be read starting from offset 0.
   *
   * @generated from field: int32 requested_streams = 3;
   */
  requestedStreams: number;

  /**
   * Read options for this session (e.g. column selection, filters).
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.TableReadOptions read_options = 4;
   */
  readOptions?: TableReadOptions;

  /**
   * Data output format. Currently default to Avro.
   * DATA_FORMAT_UNSPECIFIED not supported.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.DataFormat format = 5;
   */
  format: DataFormat;

  /**
   * The strategy to use for distributing data among multiple streams. Currently
   * defaults to liquid sharding.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.ShardingStrategy sharding_strategy = 7;
   */
  shardingStrategy: ShardingStrategy;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.CreateReadSessionRequest.
 * Use `create(CreateReadSessionRequestSchema)` to create a new message.
 */
export const CreateReadSessionRequestSchema: GenMessage<CreateReadSessionRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 3);

/**
 * Requesting row data via `ReadRows` must provide Stream position information.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.ReadRowsRequest
 */
export type ReadRowsRequest = Message<"google.cloud.bigquery.storage.v1beta1.ReadRowsRequest"> & {
  /**
   * Required. Identifier of the position in the stream to start reading from.
   * The offset requested must be less than the last row read from ReadRows.
   * Requesting a larger offset is undefined.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.StreamPosition read_position = 1;
   */
  readPosition?: StreamPosition;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.ReadRowsRequest.
 * Use `create(ReadRowsRequestSchema)` to create a new message.
 */
export const ReadRowsRequestSchema: GenMessage<ReadRowsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 4);

/**
 * Progress information for a given Stream.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.StreamStatus
 */
export type StreamStatus = Message<"google.cloud.bigquery.storage.v1beta1.StreamStatus"> & {
  /**
   * Number of estimated rows in the current stream. May change over time as
   * different readers in the stream progress at rates which are relatively fast
   * or slow.
   *
   * @generated from field: int64 estimated_row_count = 1;
   */
  estimatedRowCount: bigint;

  /**
   * A value in the range [0.0, 1.0] that represents the fraction of rows
   * assigned to this stream that have been processed by the server. In the
   * presence of read filters, the server may process more rows than it returns,
   * so this value reflects progress through the pre-filtering rows.
   *
   * This value is only populated for sessions created through the BALANCED
   * sharding strategy.
   *
   * @generated from field: float fraction_consumed = 2;
   */
  fractionConsumed: number;

  /**
   * Represents the progress of the current stream.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.Progress progress = 4;
   */
  progress?: Progress;

  /**
   * Whether this stream can be split. For sessions that use the LIQUID sharding
   * strategy, this value is always false. For BALANCED sessions, this value is
   * false when enough data have been read such that no more splits are possible
   * at that point or beyond. For small tables or streams that are the result of
   * a chain of splits, this value may never be true.
   *
   * @generated from field: bool is_splittable = 3;
   */
  isSplittable: boolean;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.StreamStatus.
 * Use `create(StreamStatusSchema)` to create a new message.
 */
export const StreamStatusSchema: GenMessage<StreamStatus> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 5);

/**
 * @generated from message google.cloud.bigquery.storage.v1beta1.Progress
 */
export type Progress = Message<"google.cloud.bigquery.storage.v1beta1.Progress"> & {
  /**
   * The fraction of rows assigned to the stream that have been processed by the
   * server so far, not including the rows in the current response message.
   *
   * This value, along with `at_response_end`, can be used to interpolate the
   * progress made as the rows in the message are being processed using the
   * following formula: `at_response_start + (at_response_end -
   * at_response_start) * rows_processed_from_response / rows_in_response`.
   *
   * Note that if a filter is provided, the `at_response_end` value of the
   * previous response may not necessarily be equal to the `at_response_start`
   * value of the current response.
   *
   * @generated from field: float at_response_start = 1;
   */
  atResponseStart: number;

  /**
   * Similar to `at_response_start`, except that this value includes the rows in
   * the current response.
   *
   * @generated from field: float at_response_end = 2;
   */
  atResponseEnd: number;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.Progress.
 * Use `create(ProgressSchema)` to create a new message.
 */
export const ProgressSchema: GenMessage<Progress> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 6);

/**
 * Information on if the current connection is being throttled.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.ThrottleStatus
 */
export type ThrottleStatus = Message<"google.cloud.bigquery.storage.v1beta1.ThrottleStatus"> & {
  /**
   * How much this connection is being throttled.
   * 0 is no throttling, 100 is completely throttled.
   *
   * @generated from field: int32 throttle_percent = 1;
   */
  throttlePercent: number;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.ThrottleStatus.
 * Use `create(ThrottleStatusSchema)` to create a new message.
 */
export const ThrottleStatusSchema: GenMessage<ThrottleStatus> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 7);

/**
 * Response from calling `ReadRows` may include row data, progress and
 * throttling information.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.ReadRowsResponse
 */
export type ReadRowsResponse = Message<"google.cloud.bigquery.storage.v1beta1.ReadRowsResponse"> & {
  /**
   * Row data is returned in format specified during session creation.
   *
   * @generated from oneof google.cloud.bigquery.storage.v1beta1.ReadRowsResponse.rows
   */
  rows: {
    /**
     * Serialized row data in AVRO format.
     *
     * @generated from field: google.cloud.bigquery.storage.v1beta1.AvroRows avro_rows = 3;
     */
    value: AvroRows;
    case: "avroRows";
  } | {
    /**
     * Serialized row data in Arrow RecordBatch format.
     *
     * @generated from field: google.cloud.bigquery.storage.v1beta1.ArrowRecordBatch arrow_record_batch = 4;
     */
    value: ArrowRecordBatch;
    case: "arrowRecordBatch";
  } | { case: undefined; value?: undefined };

  /**
   * Number of serialized rows in the rows block. This value is recorded here,
   * in addition to the row_count values in the output-specific messages in
   * `rows`, so that code which needs to record progress through the stream can
   * do so in an output format-independent way.
   *
   * @generated from field: int64 row_count = 6;
   */
  rowCount: bigint;

  /**
   * Estimated stream statistics.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.StreamStatus status = 2;
   */
  status?: StreamStatus;

  /**
   * Throttling status. If unset, the latest response still describes
   * the current throttling status.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.ThrottleStatus throttle_status = 5;
   */
  throttleStatus?: ThrottleStatus;

  /**
   * The schema for the read. If read_options.selected_fields is set, the
   * schema may be different from the table schema as it will only contain
   * the selected fields. This schema is equivalent to the one returned by
   * CreateSession. This field is only populated in the first ReadRowsResponse
   * RPC.
   *
   * @generated from oneof google.cloud.bigquery.storage.v1beta1.ReadRowsResponse.schema
   */
  schema: {
    /**
     * Output only. Avro schema.
     *
     * @generated from field: google.cloud.bigquery.storage.v1beta1.AvroSchema avro_schema = 7;
     */
    value: AvroSchema;
    case: "avroSchema";
  } | {
    /**
     * Output only. Arrow schema.
     *
     * @generated from field: google.cloud.bigquery.storage.v1beta1.ArrowSchema arrow_schema = 8;
     */
    value: ArrowSchema;
    case: "arrowSchema";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.ReadRowsResponse.
 * Use `create(ReadRowsResponseSchema)` to create a new message.
 */
export const ReadRowsResponseSchema: GenMessage<ReadRowsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 8);

/**
 * Information needed to request additional streams for an established read
 * session.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.BatchCreateReadSessionStreamsRequest
 */
export type BatchCreateReadSessionStreamsRequest = Message<"google.cloud.bigquery.storage.v1beta1.BatchCreateReadSessionStreamsRequest"> & {
  /**
   * Required. Must be a non-expired session obtained from a call to
   * CreateReadSession. Only the name field needs to be set.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.ReadSession session = 1;
   */
  session?: ReadSession;

  /**
   * Required. Number of new streams requested. Must be positive.
   * Number of added streams may be less than this, see CreateReadSessionRequest
   * for more information.
   *
   * @generated from field: int32 requested_streams = 2;
   */
  requestedStreams: number;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.BatchCreateReadSessionStreamsRequest.
 * Use `create(BatchCreateReadSessionStreamsRequestSchema)` to create a new message.
 */
export const BatchCreateReadSessionStreamsRequestSchema: GenMessage<BatchCreateReadSessionStreamsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 9);

/**
 * The response from `BatchCreateReadSessionStreams` returns the stream
 * identifiers for the newly created streams.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.BatchCreateReadSessionStreamsResponse
 */
export type BatchCreateReadSessionStreamsResponse = Message<"google.cloud.bigquery.storage.v1beta1.BatchCreateReadSessionStreamsResponse"> & {
  /**
   * Newly added streams.
   *
   * @generated from field: repeated google.cloud.bigquery.storage.v1beta1.Stream streams = 1;
   */
  streams: Stream[];
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.BatchCreateReadSessionStreamsResponse.
 * Use `create(BatchCreateReadSessionStreamsResponseSchema)` to create a new message.
 */
export const BatchCreateReadSessionStreamsResponseSchema: GenMessage<BatchCreateReadSessionStreamsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 10);

/**
 * Request information for invoking `FinalizeStream`.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.FinalizeStreamRequest
 */
export type FinalizeStreamRequest = Message<"google.cloud.bigquery.storage.v1beta1.FinalizeStreamRequest"> & {
  /**
   * Required. Stream to finalize.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.Stream stream = 2;
   */
  stream?: Stream;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.FinalizeStreamRequest.
 * Use `create(FinalizeStreamRequestSchema)` to create a new message.
 */
export const FinalizeStreamRequestSchema: GenMessage<FinalizeStreamRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 11);

/**
 * Request information for `SplitReadStream`.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.SplitReadStreamRequest
 */
export type SplitReadStreamRequest = Message<"google.cloud.bigquery.storage.v1beta1.SplitReadStreamRequest"> & {
  /**
   * Required. Stream to split.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.Stream original_stream = 1;
   */
  originalStream?: Stream;

  /**
   * A value in the range (0.0, 1.0) that specifies the fractional point at
   * which the original stream should be split. The actual split point is
   * evaluated on pre-filtered rows, so if a filter is provided, then there is
   * no guarantee that the division of the rows between the new child streams
   * will be proportional to this fractional value. Additionally, because the
   * server-side unit for assigning data is collections of rows, this fraction
   * will always map to to a data storage boundary on the server side.
   *
   * @generated from field: float fraction = 2;
   */
  fraction: number;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.SplitReadStreamRequest.
 * Use `create(SplitReadStreamRequestSchema)` to create a new message.
 */
export const SplitReadStreamRequestSchema: GenMessage<SplitReadStreamRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 12);

/**
 * Response from `SplitReadStream`.
 *
 * @generated from message google.cloud.bigquery.storage.v1beta1.SplitReadStreamResponse
 */
export type SplitReadStreamResponse = Message<"google.cloud.bigquery.storage.v1beta1.SplitReadStreamResponse"> & {
  /**
   * Primary stream, which contains the beginning portion of
   * |original_stream|. An empty value indicates that the original stream can no
   * longer be split.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.Stream primary_stream = 1;
   */
  primaryStream?: Stream;

  /**
   * Remainder stream, which contains the tail of |original_stream|. An empty
   * value indicates that the original stream can no longer be split.
   *
   * @generated from field: google.cloud.bigquery.storage.v1beta1.Stream remainder_stream = 2;
   */
  remainderStream?: Stream;
};

/**
 * Describes the message google.cloud.bigquery.storage.v1beta1.SplitReadStreamResponse.
 * Use `create(SplitReadStreamResponseSchema)` to create a new message.
 */
export const SplitReadStreamResponseSchema: GenMessage<SplitReadStreamResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 13);

/**
 * Data format for input or output data.
 *
 * @generated from enum google.cloud.bigquery.storage.v1beta1.DataFormat
 */
export enum DataFormat {
  /**
   * Data format is unspecified.
   *
   * @generated from enum value: DATA_FORMAT_UNSPECIFIED = 0;
   */
  DATA_FORMAT_UNSPECIFIED = 0,

  /**
   * Avro is a standard open source row based file format.
   * See https://avro.apache.org/ for more details.
   *
   * @generated from enum value: AVRO = 1;
   */
  AVRO = 1,

  /**
   * Arrow is a standard open source column-based message format.
   * See https://arrow.apache.org/ for more details.
   *
   * @generated from enum value: ARROW = 3;
   */
  ARROW = 3,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1beta1.DataFormat.
 */
export const DataFormatSchema: GenEnum<DataFormat> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 0);

/**
 * Strategy for distributing data among multiple streams in a read session.
 *
 * @generated from enum google.cloud.bigquery.storage.v1beta1.ShardingStrategy
 */
export enum ShardingStrategy {
  /**
   * Same as LIQUID.
   *
   * @generated from enum value: SHARDING_STRATEGY_UNSPECIFIED = 0;
   */
  SHARDING_STRATEGY_UNSPECIFIED = 0,

  /**
   * Assigns data to each stream based on the client's read rate. The faster the
   * client reads from a stream, the more data is assigned to the stream. In
   * this strategy, it's possible to read all data from a single stream even if
   * there are other streams present.
   *
   * @generated from enum value: LIQUID = 1;
   */
  LIQUID = 1,

  /**
   * Assigns data to each stream such that roughly the same number of rows can
   * be read from each stream. Because the server-side unit for assigning data
   * is collections of rows, the API does not guarantee that each stream will
   * return the same number or rows. Additionally, the limits are enforced based
   * on the number of pre-filtering rows, so some filters can lead to lopsided
   * assignments.
   *
   * @generated from enum value: BALANCED = 2;
   */
  BALANCED = 2,
}

/**
 * Describes the enum google.cloud.bigquery.storage.v1beta1.ShardingStrategy.
 */
export const ShardingStrategySchema: GenEnum<ShardingStrategy> = /*@__PURE__*/
  enumDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 1);

/**
 * BigQuery storage API.
 *
 * The BigQuery storage API can be used to read data stored in BigQuery.
 *
 * The v1beta1 API is not yet officially deprecated, and will go through a full
 * deprecation cycle (https://cloud.google.com/products#product-launch-stages)
 * before the service is turned down. However, new code should use the v1 API
 * going forward.
 *
 * @generated from service google.cloud.bigquery.storage.v1beta1.BigQueryStorage
 */
export const BigQueryStorage: GenService<{
  /**
   * Creates a new read session. A read session divides the contents of a
   * BigQuery table into one or more streams, which can then be used to read
   * data from the table. The read session also specifies properties of the
   * data to be read, such as a list of columns or a push-down filter describing
   * the rows to be returned.
   *
   * A particular row can be read by at most one stream. When the caller has
   * reached the end of each stream in the session, then all the data in the
   * table has been read.
   *
   * Read sessions automatically expire 6 hours after they are created and do
   * not require manual clean-up by the caller.
   *
   * @generated from rpc google.cloud.bigquery.storage.v1beta1.BigQueryStorage.CreateReadSession
   */
  createReadSession: {
    methodKind: "unary";
    input: typeof CreateReadSessionRequestSchema;
    output: typeof ReadSessionSchema;
  },
  /**
   * Reads rows from the table in the format prescribed by the read session.
   * Each response contains one or more table rows, up to a maximum of 10 MiB
   * per response; read requests which attempt to read individual rows larger
   * than this will fail.
   *
   * Each request also returns a set of stream statistics reflecting the
   * estimated total number of rows in the read stream. This number is computed
   * based on the total table size and the number of active streams in the read
   * session, and may change as other streams continue to read data.
   *
   * @generated from rpc google.cloud.bigquery.storage.v1beta1.BigQueryStorage.ReadRows
   */
  readRows: {
    methodKind: "server_streaming";
    input: typeof ReadRowsRequestSchema;
    output: typeof ReadRowsResponseSchema;
  },
  /**
   * Creates additional streams for a ReadSession. This API can be used to
   * dynamically adjust the parallelism of a batch processing task upwards by
   * adding additional workers.
   *
   * @generated from rpc google.cloud.bigquery.storage.v1beta1.BigQueryStorage.BatchCreateReadSessionStreams
   */
  batchCreateReadSessionStreams: {
    methodKind: "unary";
    input: typeof BatchCreateReadSessionStreamsRequestSchema;
    output: typeof BatchCreateReadSessionStreamsResponseSchema;
  },
  /**
   * Causes a single stream in a ReadSession to gracefully stop. This
   * API can be used to dynamically adjust the parallelism of a batch processing
   * task downwards without losing data.
   *
   * This API does not delete the stream -- it remains visible in the
   * ReadSession, and any data processed by the stream is not released to other
   * streams. However, no additional data will be assigned to the stream once
   * this call completes. Callers must continue reading data on the stream until
   * the end of the stream is reached so that data which has already been
   * assigned to the stream will be processed.
   *
   * This method will return an error if there are no other live streams
   * in the Session, or if SplitReadStream() has been called on the given
   * Stream.
   *
   * @generated from rpc google.cloud.bigquery.storage.v1beta1.BigQueryStorage.FinalizeStream
   */
  finalizeStream: {
    methodKind: "unary";
    input: typeof FinalizeStreamRequestSchema;
    output: typeof EmptySchema;
  },
  /**
   * Splits a given read stream into two Streams. These streams are referred to
   * as the primary and the residual of the split. The original stream can still
   * be read from in the same manner as before. Both of the returned streams can
   * also be read from, and the total rows return by both child streams will be
   * the same as the rows read from the original stream.
   *
   * Moreover, the two child streams will be allocated back to back in the
   * original Stream. Concretely, it is guaranteed that for streams Original,
   * Primary, and Residual, that Original[0-j] = Primary[0-j] and
   * Original[j-n] = Residual[0-m] once the streams have been read to
   * completion.
   *
   * This method is guaranteed to be idempotent.
   *
   * @generated from rpc google.cloud.bigquery.storage.v1beta1.BigQueryStorage.SplitReadStream
   */
  splitReadStream: {
    methodKind: "unary";
    input: typeof SplitReadStreamRequestSchema;
    output: typeof SplitReadStreamResponseSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_bigquery_storage_v1beta1_storage, 0);

