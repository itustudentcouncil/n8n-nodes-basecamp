// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/notebooks/v1/execution.proto (package google.cloud.notebooks.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/notebooks/v1/execution.proto.
 */
export const file_google_cloud_notebooks_v1_execution: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_protobuf_timestamp]);

/**
 * The description a notebook execution workload.
 *
 * @generated from message google.cloud.notebooks.v1.ExecutionTemplate
 */
export type ExecutionTemplate = Message<"google.cloud.notebooks.v1.ExecutionTemplate"> & {
  /**
   * Required. Scale tier of the hardware used for notebook execution.
   * DEPRECATED Will be discontinued. As right now only CUSTOM is supported.
   *
   * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate.ScaleTier scale_tier = 1 [deprecated = true];
   * @deprecated
   */
  scaleTier: ExecutionTemplate_ScaleTier;

  /**
   * Specifies the type of virtual machine to use for your training
   * job's master worker. You must specify this field when `scaleTier` is set to
   * `CUSTOM`.
   *
   * You can use certain Compute Engine machine types directly in this field.
   * The following types are supported:
   *
   * - `n1-standard-4`
   * - `n1-standard-8`
   * - `n1-standard-16`
   * - `n1-standard-32`
   * - `n1-standard-64`
   * - `n1-standard-96`
   * - `n1-highmem-2`
   * - `n1-highmem-4`
   * - `n1-highmem-8`
   * - `n1-highmem-16`
   * - `n1-highmem-32`
   * - `n1-highmem-64`
   * - `n1-highmem-96`
   * - `n1-highcpu-16`
   * - `n1-highcpu-32`
   * - `n1-highcpu-64`
   * - `n1-highcpu-96`
   *
   *
   * Alternatively, you can use the following legacy machine types:
   *
   * - `standard`
   * - `large_model`
   * - `complex_model_s`
   * - `complex_model_m`
   * - `complex_model_l`
   * - `standard_gpu`
   * - `complex_model_m_gpu`
   * - `complex_model_l_gpu`
   * - `standard_p100`
   * - `complex_model_m_p100`
   * - `standard_v100`
   * - `large_model_v100`
   * - `complex_model_m_v100`
   * - `complex_model_l_v100`
   *
   *
   * Finally, if you want to use a TPU for training, specify `cloud_tpu` in this
   * field. Learn more about the [special configuration options for training
   * with
   * TPU](https://cloud.google.com/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
   *
   * @generated from field: string master_type = 2;
   */
  masterType: string;

  /**
   * Configuration (count and accelerator type) for hardware running notebook
   * execution.
   *
   * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorConfig accelerator_config = 3;
   */
  acceleratorConfig?: ExecutionTemplate_SchedulerAcceleratorConfig;

  /**
   * Labels for execution.
   * If execution is scheduled, a field included will be 'nbs-scheduled'.
   * Otherwise, it is an immediate execution, and an included field will be
   * 'nbs-immediate'. Use fields to efficiently index between various types of
   * executions.
   *
   * @generated from field: map<string, string> labels = 4;
   */
  labels: { [key: string]: string };

  /**
   * Path to the notebook file to execute.
   * Must be in a Google Cloud Storage bucket.
   * Format: `gs://{bucket_name}/{folder}/{notebook_file_name}`
   * Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook.ipynb`
   *
   * @generated from field: string input_notebook_file = 5;
   */
  inputNotebookFile: string;

  /**
   * Container Image URI to a DLVM
   * Example: 'gcr.io/deeplearning-platform-release/base-cu100'
   * More examples can be found at:
   * https://cloud.google.com/ai-platform/deep-learning-containers/docs/choosing-container
   *
   * @generated from field: string container_image_uri = 6;
   */
  containerImageUri: string;

  /**
   * Path to the notebook folder to write to.
   * Must be in a Google Cloud Storage bucket path.
   * Format: `gs://{bucket_name}/{folder}`
   * Ex: `gs://notebook_user/scheduled_notebooks`
   *
   * @generated from field: string output_notebook_folder = 7;
   */
  outputNotebookFolder: string;

  /**
   * Parameters to be overridden in the notebook during execution.
   * Ref https://papermill.readthedocs.io/en/latest/usage-parameterize.html on
   * how to specifying parameters in the input notebook and pass them here
   * in an YAML file.
   * Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook_params.yaml`
   *
   * @generated from field: string params_yaml_file = 8;
   */
  paramsYamlFile: string;

  /**
   * Parameters used within the 'input_notebook_file' notebook.
   *
   * @generated from field: string parameters = 9;
   */
  parameters: string;

  /**
   * The email address of a service account to use when running the execution.
   * You must have the `iam.serviceAccounts.actAs` permission for the specified
   * service account.
   *
   * @generated from field: string service_account = 10;
   */
  serviceAccount: string;

  /**
   * The type of Job to be used on this execution.
   *
   * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate.JobType job_type = 11;
   */
  jobType: ExecutionTemplate_JobType;

  /**
   * Parameters for an execution type.
   * NOTE: There are currently no extra parameters for VertexAI jobs.
   *
   * @generated from oneof google.cloud.notebooks.v1.ExecutionTemplate.job_parameters
   */
  jobParameters: {
    /**
     * Parameters used in Dataproc JobType executions.
     *
     * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate.DataprocParameters dataproc_parameters = 12;
     */
    value: ExecutionTemplate_DataprocParameters;
    case: "dataprocParameters";
  } | {
    /**
     * Parameters used in Vertex AI JobType executions.
     *
     * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate.VertexAIParameters vertex_ai_parameters = 13;
     */
    value: ExecutionTemplate_VertexAIParameters;
    case: "vertexAiParameters";
  } | { case: undefined; value?: undefined };

  /**
   * Name of the kernel spec to use. This must be specified if the
   * kernel spec name on the execution target does not match the name in the
   * input notebook file.
   *
   * @generated from field: string kernel_spec = 14;
   */
  kernelSpec: string;

  /**
   * The name of a Vertex AI [Tensorboard] resource to which this execution
   * will upload Tensorboard logs.
   * Format:
   * `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
   *
   * @generated from field: string tensorboard = 15;
   */
  tensorboard: string;
};

/**
 * Describes the message google.cloud.notebooks.v1.ExecutionTemplate.
 * Use `create(ExecutionTemplateSchema)` to create a new message.
 */
export const ExecutionTemplateSchema: GenMessage<ExecutionTemplate> = /*@__PURE__*/
  messageDesc(file_google_cloud_notebooks_v1_execution, 0);

/**
 * Definition of a hardware accelerator. Note that not all combinations
 * of `type` and `core_count` are valid. Check [GPUs on
 * Compute Engine](https://cloud.google.com/compute/docs/gpus) to find a valid
 * combination. TPUs are not supported.
 *
 * @generated from message google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorConfig
 */
export type ExecutionTemplate_SchedulerAcceleratorConfig = Message<"google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorConfig"> & {
  /**
   * Type of this accelerator.
   *
   * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorType type = 1;
   */
  type: ExecutionTemplate_SchedulerAcceleratorType;

  /**
   * Count of cores of this accelerator.
   *
   * @generated from field: int64 core_count = 2;
   */
  coreCount: bigint;
};

/**
 * Describes the message google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorConfig.
 * Use `create(ExecutionTemplate_SchedulerAcceleratorConfigSchema)` to create a new message.
 */
export const ExecutionTemplate_SchedulerAcceleratorConfigSchema: GenMessage<ExecutionTemplate_SchedulerAcceleratorConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_notebooks_v1_execution, 0, 0);

/**
 * Parameters used in Dataproc JobType executions.
 *
 * @generated from message google.cloud.notebooks.v1.ExecutionTemplate.DataprocParameters
 */
export type ExecutionTemplate_DataprocParameters = Message<"google.cloud.notebooks.v1.ExecutionTemplate.DataprocParameters"> & {
  /**
   * URI for cluster used to run Dataproc execution.
   * Format: `projects/{PROJECT_ID}/regions/{REGION}/clusters/{CLUSTER_NAME}`
   *
   * @generated from field: string cluster = 1;
   */
  cluster: string;
};

/**
 * Describes the message google.cloud.notebooks.v1.ExecutionTemplate.DataprocParameters.
 * Use `create(ExecutionTemplate_DataprocParametersSchema)` to create a new message.
 */
export const ExecutionTemplate_DataprocParametersSchema: GenMessage<ExecutionTemplate_DataprocParameters> = /*@__PURE__*/
  messageDesc(file_google_cloud_notebooks_v1_execution, 0, 1);

/**
 * Parameters used in Vertex AI JobType executions.
 *
 * @generated from message google.cloud.notebooks.v1.ExecutionTemplate.VertexAIParameters
 */
export type ExecutionTemplate_VertexAIParameters = Message<"google.cloud.notebooks.v1.ExecutionTemplate.VertexAIParameters"> & {
  /**
   * The full name of the Compute Engine
   * [network](https://cloud.google.com/compute/docs/networks-and-firewalls#networks)
   * to which the Job should be peered. For example,
   * `projects/12345/global/networks/myVPC`.
   * [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert)
   * is of the form `projects/{project}/global/networks/{network}`.
   * Where `{project}` is a project number, as in `12345`, and `{network}` is
   * a network name.
   *
   * Private services access must already be configured for the network. If
   * left unspecified, the job is not peered with any network.
   *
   * @generated from field: string network = 1;
   */
  network: string;

  /**
   * Environment variables.
   * At most 100 environment variables can be specified and unique.
   * Example: `GCP_BUCKET=gs://my-bucket/samples/`
   *
   * @generated from field: map<string, string> env = 2;
   */
  env: { [key: string]: string };
};

/**
 * Describes the message google.cloud.notebooks.v1.ExecutionTemplate.VertexAIParameters.
 * Use `create(ExecutionTemplate_VertexAIParametersSchema)` to create a new message.
 */
export const ExecutionTemplate_VertexAIParametersSchema: GenMessage<ExecutionTemplate_VertexAIParameters> = /*@__PURE__*/
  messageDesc(file_google_cloud_notebooks_v1_execution, 0, 2);

/**
 * Required. Specifies the machine types, the number of replicas for workers
 * and parameter servers.
 *
 * @generated from enum google.cloud.notebooks.v1.ExecutionTemplate.ScaleTier
 */
export enum ExecutionTemplate_ScaleTier {
  /**
   * Unspecified Scale Tier.
   *
   * @generated from enum value: SCALE_TIER_UNSPECIFIED = 0;
   */
  SCALE_TIER_UNSPECIFIED = 0,

  /**
   * A single worker instance. This tier is suitable for learning how to use
   * Cloud ML, and for experimenting with new models using small datasets.
   *
   * @generated from enum value: BASIC = 1;
   */
  BASIC = 1,

  /**
   * Many workers and a few parameter servers.
   *
   * @generated from enum value: STANDARD_1 = 2;
   */
  STANDARD_1 = 2,

  /**
   * A large number of workers with many parameter servers.
   *
   * @generated from enum value: PREMIUM_1 = 3;
   */
  PREMIUM_1 = 3,

  /**
   * A single worker instance with a K80 GPU.
   *
   * @generated from enum value: BASIC_GPU = 4;
   */
  BASIC_GPU = 4,

  /**
   * A single worker instance with a Cloud TPU.
   *
   * @generated from enum value: BASIC_TPU = 5;
   */
  BASIC_TPU = 5,

  /**
   * The CUSTOM tier is not a set tier, but rather enables you to use your
   * own cluster specification. When you use this tier, set values to
   * configure your processing cluster according to these guidelines:
   *
   * *   You _must_ set `ExecutionTemplate.masterType` to specify the type
   *     of machine to use for your master node. This is the only required
   *     setting.
   *
   * @generated from enum value: CUSTOM = 6;
   */
  CUSTOM = 6,
}

/**
 * Describes the enum google.cloud.notebooks.v1.ExecutionTemplate.ScaleTier.
 */
export const ExecutionTemplate_ScaleTierSchema: GenEnum<ExecutionTemplate_ScaleTier> = /*@__PURE__*/
  enumDesc(file_google_cloud_notebooks_v1_execution, 0, 0);

/**
 * Hardware accelerator types for AI Platform Training jobs.
 *
 * @generated from enum google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorType
 */
export enum ExecutionTemplate_SchedulerAcceleratorType {
  /**
   * Unspecified accelerator type. Default to no GPU.
   *
   * @generated from enum value: SCHEDULER_ACCELERATOR_TYPE_UNSPECIFIED = 0;
   */
  SCHEDULER_ACCELERATOR_TYPE_UNSPECIFIED = 0,

  /**
   * Nvidia Tesla K80 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_K80 = 1;
   */
  NVIDIA_TESLA_K80 = 1,

  /**
   * Nvidia Tesla P100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_P100 = 2;
   */
  NVIDIA_TESLA_P100 = 2,

  /**
   * Nvidia Tesla V100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_V100 = 3;
   */
  NVIDIA_TESLA_V100 = 3,

  /**
   * Nvidia Tesla P4 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_P4 = 4;
   */
  NVIDIA_TESLA_P4 = 4,

  /**
   * Nvidia Tesla T4 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_T4 = 5;
   */
  NVIDIA_TESLA_T4 = 5,

  /**
   * Nvidia Tesla A100 GPU.
   *
   * @generated from enum value: NVIDIA_TESLA_A100 = 10;
   */
  NVIDIA_TESLA_A100 = 10,

  /**
   * TPU v2.
   *
   * @generated from enum value: TPU_V2 = 6;
   */
  TPU_V2 = 6,

  /**
   * TPU v3.
   *
   * @generated from enum value: TPU_V3 = 7;
   */
  TPU_V3 = 7,
}

/**
 * Describes the enum google.cloud.notebooks.v1.ExecutionTemplate.SchedulerAcceleratorType.
 */
export const ExecutionTemplate_SchedulerAcceleratorTypeSchema: GenEnum<ExecutionTemplate_SchedulerAcceleratorType> = /*@__PURE__*/
  enumDesc(file_google_cloud_notebooks_v1_execution, 0, 1);

/**
 * The backend used for this execution.
 *
 * @generated from enum google.cloud.notebooks.v1.ExecutionTemplate.JobType
 */
export enum ExecutionTemplate_JobType {
  /**
   * No type specified.
   *
   * @generated from enum value: JOB_TYPE_UNSPECIFIED = 0;
   */
  JOB_TYPE_UNSPECIFIED = 0,

  /**
   * Custom Job in `aiplatform.googleapis.com`.
   * Default value for an execution.
   *
   * @generated from enum value: VERTEX_AI = 1;
   */
  VERTEX_AI = 1,

  /**
   * Run execution on a cluster with Dataproc as a job.
   * https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.jobs
   *
   * @generated from enum value: DATAPROC = 2;
   */
  DATAPROC = 2,
}

/**
 * Describes the enum google.cloud.notebooks.v1.ExecutionTemplate.JobType.
 */
export const ExecutionTemplate_JobTypeSchema: GenEnum<ExecutionTemplate_JobType> = /*@__PURE__*/
  enumDesc(file_google_cloud_notebooks_v1_execution, 0, 2);

/**
 * The definition of a single executed notebook.
 *
 * @generated from message google.cloud.notebooks.v1.Execution
 */
export type Execution = Message<"google.cloud.notebooks.v1.Execution"> & {
  /**
   * execute metadata including name, hardware spec, region, labels, etc.
   *
   * @generated from field: google.cloud.notebooks.v1.ExecutionTemplate execution_template = 1;
   */
  executionTemplate?: ExecutionTemplate;

  /**
   * Output only. The resource name of the execute. Format:
   * `projects/{project_id}/locations/{location}/executions/{execution_id}`
   *
   * @generated from field: string name = 2;
   */
  name: string;

  /**
   * Output only. Name used for UI purposes.
   * Name can only contain alphanumeric characters and underscores '_'.
   *
   * @generated from field: string display_name = 3;
   */
  displayName: string;

  /**
   * A brief description of this execution.
   *
   * @generated from field: string description = 4;
   */
  description: string;

  /**
   * Output only. Time the Execution was instantiated.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 5;
   */
  createTime?: Timestamp;

  /**
   * Output only. Time the Execution was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 6;
   */
  updateTime?: Timestamp;

  /**
   * Output only. State of the underlying AI Platform job.
   *
   * @generated from field: google.cloud.notebooks.v1.Execution.State state = 7;
   */
  state: Execution_State;

  /**
   * Output notebook file generated by this execution
   *
   * @generated from field: string output_notebook_file = 8;
   */
  outputNotebookFile: string;

  /**
   * Output only. The URI of the external job used to execute the notebook.
   *
   * @generated from field: string job_uri = 9;
   */
  jobUri: string;
};

/**
 * Describes the message google.cloud.notebooks.v1.Execution.
 * Use `create(ExecutionSchema)` to create a new message.
 */
export const ExecutionSchema: GenMessage<Execution> = /*@__PURE__*/
  messageDesc(file_google_cloud_notebooks_v1_execution, 1);

/**
 * Enum description of the state of the underlying AIP job.
 *
 * @generated from enum google.cloud.notebooks.v1.Execution.State
 */
export enum Execution_State {
  /**
   * The job state is unspecified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The job has been just created and processing has not yet begun.
   *
   * @generated from enum value: QUEUED = 1;
   */
  QUEUED = 1,

  /**
   * The service is preparing to execution the job.
   *
   * @generated from enum value: PREPARING = 2;
   */
  PREPARING = 2,

  /**
   * The job is in progress.
   *
   * @generated from enum value: RUNNING = 3;
   */
  RUNNING = 3,

  /**
   * The job completed successfully.
   *
   * @generated from enum value: SUCCEEDED = 4;
   */
  SUCCEEDED = 4,

  /**
   * The job failed.
   * `error_message` should contain the details of the failure.
   *
   * @generated from enum value: FAILED = 5;
   */
  FAILED = 5,

  /**
   * The job is being cancelled.
   * `error_message` should describe the reason for the cancellation.
   *
   * @generated from enum value: CANCELLING = 6;
   */
  CANCELLING = 6,

  /**
   * The job has been cancelled.
   * `error_message` should describe the reason for the cancellation.
   *
   * @generated from enum value: CANCELLED = 7;
   */
  CANCELLED = 7,

  /**
   * The job has become expired (relevant to Vertex AI jobs)
   * https://cloud.google.com/vertex-ai/docs/reference/rest/v1/JobState
   *
   * @generated from enum value: EXPIRED = 9;
   */
  EXPIRED = 9,

  /**
   * The Execution is being created.
   *
   * @generated from enum value: INITIALIZING = 10;
   */
  INITIALIZING = 10,
}

/**
 * Describes the enum google.cloud.notebooks.v1.Execution.State.
 */
export const Execution_StateSchema: GenEnum<Execution_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_notebooks_v1_execution, 1, 0);

