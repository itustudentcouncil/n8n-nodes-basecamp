// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/timeseriesinsights/v1/timeseries_insights.proto (package google.cloud.timeseriesinsights.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Duration, EmptySchema, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_duration, file_google_protobuf_empty, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../rpc/status_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/timeseriesinsights/v1/timeseries_insights.proto.
 */
export const file_google_cloud_timeseriesinsights_v1_timeseries_insights: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_protobuf_duration, file_google_protobuf_empty, file_google_protobuf_timestamp, file_google_rpc_status]);

/**
 * Mapping of BigQuery columns to timestamp, group_id and dimensions.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.BigqueryMapping
 */
export type BigqueryMapping = Message<"google.cloud.timeseriesinsights.v1.BigqueryMapping"> & {
  /**
   * The column which should be used as the event timestamps. If not specified
   * 'Timestamp' is used by default. The column may have TIMESTAMP or INT64
   * type (the latter is interpreted as microseconds since the Unix epoch).
   *
   * @generated from field: string timestamp_column = 1;
   */
  timestampColumn: string;

  /**
   * The column which should be used as the group ID (grouping events into
   * sessions). If not specified 'GroupId' is used by default, if the input
   * table does not have such a column, random unique group IDs are
   * generated automatically (different group ID per input row).
   *
   * @generated from field: string group_id_column = 2;
   */
  groupIdColumn: string;

  /**
   * The list of columns that should be translated to dimensions. If empty,
   * all columns are translated to dimensions. The timestamp and group_id
   * columns should not be listed here again. Columns are expected to have
   * primitive types (STRING, INT64, FLOAT64 or NUMERIC).
   *
   * @generated from field: repeated string dimension_column = 3;
   */
  dimensionColumn: string[];
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.BigqueryMapping.
 * Use `create(BigqueryMappingSchema)` to create a new message.
 */
export const BigqueryMappingSchema: GenMessage<BigqueryMapping> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 0);

/**
 * A data source consists of multiple [Event][google.cloud.timeseriesinsights.v1.Event] objects stored on
 * Cloud Storage.  Each Event should be in JSON format, with one Event
 * per line, also known as JSON Lines format.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.DataSource
 */
export type DataSource = Message<"google.cloud.timeseriesinsights.v1.DataSource"> & {
  /**
   * Data source URI.
   *
   * 1) Google Cloud Storage files (JSON) are defined in the following form.
   * `gs://bucket_name/object_name`. For more information on Cloud Storage URIs,
   * please see https://cloud.google.com/storage/docs/reference-uris.
   *
   * @generated from field: string uri = 1;
   */
  uri: string;

  /**
   * For BigQuery inputs defines the columns that should be used for dimensions
   * (including time and group ID).
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.BigqueryMapping bq_mapping = 2;
   */
  bqMapping?: BigqueryMapping;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.DataSource.
 * Use `create(DataSourceSchema)` to create a new message.
 */
export const DataSourceSchema: GenMessage<DataSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 1);

/**
 * A collection of data sources sent for processing.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.DataSet
 */
export type DataSet = Message<"google.cloud.timeseriesinsights.v1.DataSet"> & {
  /**
   * The dataset name, which will be used for querying, status and unload
   * requests. This must be unique within a project.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * [Data dimension names][google.cloud.timeseriesinsights.v1.EventDimension.name] allowed for this `DataSet`.
   *
   * If left empty, all dimension names are included. This field works as a
   * filter to avoid regenerating the data.
   *
   * @generated from field: repeated string data_names = 2;
   */
  dataNames: string[];

  /**
   * Input data.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.DataSource data_sources = 3;
   */
  dataSources: DataSource[];

  /**
   * Dataset state in the system.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.DataSet.State state = 4;
   */
  state: DataSet_State;

  /**
   * Dataset processing status.
   *
   * @generated from field: google.rpc.Status status = 5;
   */
  status?: Status;

  /**
   * Periodically we discard dataset [Event][google.cloud.timeseriesinsights.v1.Event] objects that have
   * timestamps older than 'ttl'.  Omitting this field or a zero value means no
   * events are discarded.
   *
   * @generated from field: google.protobuf.Duration ttl = 6;
   */
  ttl?: Duration;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.DataSet.
 * Use `create(DataSetSchema)` to create a new message.
 */
export const DataSetSchema: GenMessage<DataSet> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 2);

/**
 * DataSet state.
 *
 * @generated from enum google.cloud.timeseriesinsights.v1.DataSet.State
 */
export enum DataSet_State {
  /**
   * Unspecified / undefined state.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * Dataset is unknown to the system; we have never seen this dataset before
   * or we have seen this dataset but have fully GC-ed it.
   *
   * @generated from enum value: UNKNOWN = 1;
   */
  UNKNOWN = 1,

  /**
   * Dataset processing is pending.
   *
   * @generated from enum value: PENDING = 2;
   */
  PENDING = 2,

  /**
   * Dataset is loading.
   *
   * @generated from enum value: LOADING = 3;
   */
  LOADING = 3,

  /**
   * Dataset is loaded and can be queried.
   *
   * @generated from enum value: LOADED = 4;
   */
  LOADED = 4,

  /**
   * Dataset is unloading.
   *
   * @generated from enum value: UNLOADING = 5;
   */
  UNLOADING = 5,

  /**
   * Dataset is unloaded and is removed from the system.
   *
   * @generated from enum value: UNLOADED = 6;
   */
  UNLOADED = 6,

  /**
   * Dataset processing failed.
   *
   * @generated from enum value: FAILED = 7;
   */
  FAILED = 7,
}

/**
 * Describes the enum google.cloud.timeseriesinsights.v1.DataSet.State.
 */
export const DataSet_StateSchema: GenEnum<DataSet_State> = /*@__PURE__*/
  enumDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 2, 0);

/**
 * Represents an event dimension.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.EventDimension
 */
export type EventDimension = Message<"google.cloud.timeseriesinsights.v1.EventDimension"> & {
  /**
   * Dimension name.
   *
   * **NOTE**: `EventDimension` names must be composed of alphanumeric
   * characters only, and are case insensitive. Unicode characters are *not*
   * supported. The underscore '_' is also allowed.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Dimension value.
   *
   * **NOTE**: All entries of the dimension `name` must have the same `value`
   * type.
   *
   * @generated from oneof google.cloud.timeseriesinsights.v1.EventDimension.value
   */
  value: {
    /**
     * String representation.
     *
     * **NOTE**: String values are case insensitive. Unicode characters are
     * supported.
     *
     * @generated from field: string string_val = 2;
     */
    value: string;
    case: "stringVal";
  } | {
    /**
     * Long representation.
     *
     * @generated from field: int64 long_val = 3;
     */
    value: bigint;
    case: "longVal";
  } | {
    /**
     * Bool representation.
     *
     * @generated from field: bool bool_val = 4;
     */
    value: boolean;
    case: "boolVal";
  } | {
    /**
     * Double representation.
     *
     * @generated from field: double double_val = 5;
     */
    value: number;
    case: "doubleVal";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.EventDimension.
 * Use `create(EventDimensionSchema)` to create a new message.
 */
export const EventDimensionSchema: GenMessage<EventDimension> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 3);

/**
 * Represents an entry in a data source.
 *
 * Each Event has:
 *
 * * A timestamp at which the event occurs.
 * * One or multiple dimensions.
 * * Optionally, a group ID that allows clients to group logically related
 *   events (for example, all events representing payments transactions done by
 *   a user in a day have the same group ID).  If a group ID is not provided, an
 *   internal one will be generated based on the content and `eventTime`.
 *
 * **NOTE**:
 *
 * * Internally, we discretize time in equal-sized chunks and we assume an
 *   event has a 0
 *   [TimeseriesPoint.value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value]
 *   in a chunk that does not contain any occurrences of an event in the input.
 * * The number of Events with the same group ID should be limited.
 * * Group ID *cannot* be queried.
 * * Group ID does *not* correspond to a user ID or the like. If a user ID is of
 *   interest to be queried, use a user ID `dimension` instead.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.Event
 */
export type Event = Message<"google.cloud.timeseriesinsights.v1.Event"> & {
  /**
   * Event dimensions.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.EventDimension dimensions = 1;
   */
  dimensions: EventDimension[];

  /**
   * Event group ID.
   *
   * **NOTE**: JSON encoding should use a string to hold a 64-bit integer value,
   * because a native JSON number holds only 53 binary bits for an integer.
   *
   * @generated from field: int64 group_id = 2;
   */
  groupId: bigint;

  /**
   * Event timestamp.
   *
   * @generated from field: google.protobuf.Timestamp event_time = 3;
   */
  eventTime?: Timestamp;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.Event.
 * Use `create(EventSchema)` to create a new message.
 */
export const EventSchema: GenMessage<Event> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 4);

/**
 * Appends events to an existing DataSet.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.AppendEventsRequest
 */
export type AppendEventsRequest = Message<"google.cloud.timeseriesinsights.v1.AppendEventsRequest"> & {
  /**
   * Events to be appended.
   *
   * Note:
   *
   * 0. The [DataSet][google.cloud.timeseriesinsights.v1.DataSet] must be shown in a `LOADED` state
   *    in the results of `list` method; otherwise, all events from
   *    the append request will be dropped, and a `NOT_FOUND` status will be
   *    returned.
   * 0. All events in a single request must have the same
   *    [groupId][google.cloud.timeseriesinsights.v1.Event.group_id] if set; otherwise, an
   *    `INVALID_ARGUMENT` status will be returned.
   * 0. If [groupId][google.cloud.timeseriesinsights.v1.Event.group_id] is not set (or 0), there
   *    should be only 1 event; otherwise, an `INVALID_ARGUMENT` status will be
   *    returned.
   * 0. The events must be newer than the current time minus
   *    [DataSet TTL][google.cloud.timeseriesinsights.v1.DataSet.ttl] or they will be dropped.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.Event events = 1;
   */
  events: Event[];

  /**
   * Required. The DataSet to which we want to append to in the format of
   * "projects/{project}/datasets/{dataset}"
   *
   * @generated from field: string dataset = 2;
   */
  dataset: string;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.AppendEventsRequest.
 * Use `create(AppendEventsRequestSchema)` to create a new message.
 */
export const AppendEventsRequestSchema: GenMessage<AppendEventsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 5);

/**
 * Response for an AppendEvents RPC.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.AppendEventsResponse
 */
export type AppendEventsResponse = Message<"google.cloud.timeseriesinsights.v1.AppendEventsResponse"> & {
  /**
   * Dropped events; empty if all events are successfully added.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.Event dropped_events = 1;
   */
  droppedEvents: Event[];
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.AppendEventsResponse.
 * Use `create(AppendEventsResponseSchema)` to create a new message.
 */
export const AppendEventsResponseSchema: GenMessage<AppendEventsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 6);

/**
 * Create a DataSet request.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.CreateDataSetRequest
 */
export type CreateDataSetRequest = Message<"google.cloud.timeseriesinsights.v1.CreateDataSetRequest"> & {
  /**
   * Required. Client project name which will own this DataSet in the format of
   * 'projects/{project}'.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Required. Dataset to be loaded.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.DataSet dataset = 2;
   */
  dataset?: DataSet;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.CreateDataSetRequest.
 * Use `create(CreateDataSetRequestSchema)` to create a new message.
 */
export const CreateDataSetRequestSchema: GenMessage<CreateDataSetRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 7);

/**
 * Unload DataSet request from the serving system.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.DeleteDataSetRequest
 */
export type DeleteDataSetRequest = Message<"google.cloud.timeseriesinsights.v1.DeleteDataSetRequest"> & {
  /**
   * Required. Dataset name in the format of "projects/{project}/datasets/{dataset}"
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.DeleteDataSetRequest.
 * Use `create(DeleteDataSetRequestSchema)` to create a new message.
 */
export const DeleteDataSetRequestSchema: GenMessage<DeleteDataSetRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 8);

/**
 * List the DataSets created by the current project.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.ListDataSetsRequest
 */
export type ListDataSetsRequest = Message<"google.cloud.timeseriesinsights.v1.ListDataSetsRequest"> & {
  /**
   * Required. Project owning the DataSet in the format of "projects/{project}".
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Number of results to return in the list.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * Token to provide to skip to a particular spot in the list.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.ListDataSetsRequest.
 * Use `create(ListDataSetsRequestSchema)` to create a new message.
 */
export const ListDataSetsRequestSchema: GenMessage<ListDataSetsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 9);

/**
 * Created DataSets list response.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.ListDataSetsResponse
 */
export type ListDataSetsResponse = Message<"google.cloud.timeseriesinsights.v1.ListDataSetsResponse"> & {
  /**
   * The list of created DataSets.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.DataSet datasets = 1;
   */
  datasets: DataSet[];

  /**
   * Token to receive the next page of results.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.ListDataSetsResponse.
 * Use `create(ListDataSetsResponseSchema)` to create a new message.
 */
export const ListDataSetsResponseSchema: GenMessage<ListDataSetsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 10);

/**
 * A categorical dimension fixed to a certain value.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.PinnedDimension
 */
export type PinnedDimension = Message<"google.cloud.timeseriesinsights.v1.PinnedDimension"> & {
  /**
   * The name of the dimension for which we are fixing its value.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Dimension value.
   *
   * **NOTE**: The `value` type must match that in the data with the same
   * `dimension` as name.
   *
   * @generated from oneof google.cloud.timeseriesinsights.v1.PinnedDimension.value
   */
  value: {
    /**
     * A string value. This can be used for [dimensions][google.cloud.timeseriesinsights.v1.EventDimension], which
     * have their value field set to [string_val][google.cloud.timeseriesinsights.v1.EventDimension.string_val].
     *
     * @generated from field: string string_val = 2;
     */
    value: string;
    case: "stringVal";
  } | {
    /**
     * A bool value. This can be used for [dimensions][google.cloud.timeseriesinsights.v1.EventDimension], which
     * have their value field set to [bool_val][google.cloud.timeseriesinsights.v1.EventDimension.bool_val].
     *
     * @generated from field: bool bool_val = 3;
     */
    value: boolean;
    case: "boolVal";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.PinnedDimension.
 * Use `create(PinnedDimensionSchema)` to create a new message.
 */
export const PinnedDimensionSchema: GenMessage<PinnedDimension> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 11);

/**
 * Parameters that control the sensitivity and other options for the time series
 * forecast.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.ForecastParams
 */
export type ForecastParams = Message<"google.cloud.timeseriesinsights.v1.ForecastParams"> & {
  /**
   * Optional. Penalize variations between the actual and forecasted values smaller than
   * this. For more information about how this parameter affects the score, see
   * the [anomalyScore](EvaluatedSlice.anomaly_score) formula.
   *
   * Intuitively, anomaly scores summarize how statistically significant the
   * change between the actual and forecasted value is compared with what we
   * expect the change to be (see
   * [expectedDeviation](EvaluatedSlice.expected_deviation)). However, in
   * practice, depending on the application, changes smaller than certain
   * absolute values, while statistically significant, may not be important.
   *
   * This parameter allows us to penalize such low absolute value changes.
   *
   * Must be in the (0.0, inf) range.
   *
   * If unspecified, it defaults to 0.000001.
   *
   * @generated from field: optional double noise_threshold = 12;
   */
  noiseThreshold?: number;

  /**
   * Optional. Specifying any known seasonality/periodicity in the time series
   * for the slices we will analyze can improve the quality of the results.
   *
   * If unsure, simply leave it unspecified by not setting a value for this
   * field.
   *
   * If your time series has multiple seasonal patterns, then set it to the most
   * granular one (e.g. if it has daily and weekly patterns, set this to DAILY).
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.ForecastParams.Period seasonality_hint = 10;
   */
  seasonalityHint: ForecastParams_Period;

  /**
   * Optional. The length of the returned [forecasted
   * timeseries][EvaluatedSlice.forecast].
   *
   * This duration is currently capped at 100 x
   * [granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity].
   *
   * Example: If the detection point is set to "2020-12-27T00:00:00Z", the
   * [granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to "3600s" and the
   * horizon_duration to "10800s", then we will generate 3 time
   * series points (from "2020-12-27T01:00:00Z" to "2020-12-27T04:00:00Z"), for
   * which we will return their forecasted values.
   *
   * Note: The horizon time is only used for forecasting not for anormaly
   * detection. To detect anomalies for multiple points of time,
   * simply send multiple queries with those as
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time].
   *
   * @generated from field: google.protobuf.Duration horizon_duration = 13;
   */
  horizonDuration?: Duration;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.ForecastParams.
 * Use `create(ForecastParamsSchema)` to create a new message.
 */
export const ForecastParamsSchema: GenMessage<ForecastParams> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 12);

/**
 * A time period of a fixed interval.
 *
 * @generated from enum google.cloud.timeseriesinsights.v1.ForecastParams.Period
 */
export enum ForecastParams_Period {
  /**
   * Unknown or simply not given.
   *
   * @generated from enum value: PERIOD_UNSPECIFIED = 0;
   */
  PERIOD_UNSPECIFIED = 0,

  /**
   * 1 hour
   *
   * @generated from enum value: HOURLY = 5;
   */
  HOURLY = 5,

  /**
   * 24 hours
   *
   * @generated from enum value: DAILY = 1;
   */
  DAILY = 1,

  /**
   * 7 days
   *
   * @generated from enum value: WEEKLY = 2;
   */
  WEEKLY = 2,

  /**
   * 30 days
   *
   * @generated from enum value: MONTHLY = 3;
   */
  MONTHLY = 3,

  /**
   * 365 days
   *
   * @generated from enum value: YEARLY = 4;
   */
  YEARLY = 4,
}

/**
 * Describes the enum google.cloud.timeseriesinsights.v1.ForecastParams.Period.
 */
export const ForecastParams_PeriodSchema: GenEnum<ForecastParams_Period> = /*@__PURE__*/
  enumDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 12, 0);

/**
 * A point in a time series.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.TimeseriesPoint
 */
export type TimeseriesPoint = Message<"google.cloud.timeseriesinsights.v1.TimeseriesPoint"> & {
  /**
   * The timestamp of this point.
   *
   * @generated from field: google.protobuf.Timestamp time = 1;
   */
  time?: Timestamp;

  /**
   * The value for this point.
   *
   * It is computed by aggregating all events in the associated slice that are
   * in the `[time, time + granularity]` range (see
   * [granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity]) using the specified
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric].
   *
   * @generated from field: optional double value = 2;
   */
  value?: number;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.TimeseriesPoint.
 * Use `create(TimeseriesPointSchema)` to create a new message.
 */
export const TimeseriesPointSchema: GenMessage<TimeseriesPoint> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 13);

/**
 * A time series.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.Timeseries
 */
export type Timeseries = Message<"google.cloud.timeseriesinsights.v1.Timeseries"> & {
  /**
   * The points in this time series, ordered by their timestamp.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.TimeseriesPoint point = 1;
   */
  point: TimeseriesPoint[];
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.Timeseries.
 * Use `create(TimeseriesSchema)` to create a new message.
 */
export const TimeseriesSchema: GenMessage<Timeseries> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 14);

/**
 * Forecast result for a given slice.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.EvaluatedSlice
 */
export type EvaluatedSlice = Message<"google.cloud.timeseriesinsights.v1.EvaluatedSlice"> & {
  /**
   * Values for all categorical dimensions that uniquely identify this slice.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.PinnedDimension dimensions = 1;
   */
  dimensions: PinnedDimension[];

  /**
   * The actual value at the detection time (see
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time]).
   *
   * **NOTE**: This value can be an estimate, so it should not be used as a
   * source of truth.
   *
   * @generated from field: optional double detection_point_actual = 11;
   */
  detectionPointActual?: number;

  /**
   * The expected value at the detection time, which is obtained by forecasting
   * on the historical time series.
   *
   * @generated from field: optional double detection_point_forecast = 12;
   */
  detectionPointForecast?: number;

  /**
   * How much our forecast model expects the detection point actual will
   * deviate from its forecasted value based on how well it fit the input time
   * series.
   *
   * In general, we expect the `detectionPointActual` to
   * be in the `[detectionPointForecast - expectedDeviation,
   * detectionPointForecast + expectedDeviation]` range. The more the actual
   * value is outside this range, the more statistically significant the
   * anomaly is.
   *
   * The expected deviation is always positive.
   *
   * @generated from field: optional double expected_deviation = 16;
   */
  expectedDeviation?: number;

  /**
   * Summarizes how significant the change between the actual and forecasted
   * detection points are compared with the historical patterns observed on the
   * [history][google.cloud.timeseriesinsights.v1.EvaluatedSlice.history] time series.
   *
   * Defined as *|a - f| / (e + nt)*, where:
   *
   * - *a* is the [detectionPointActual][google.cloud.timeseriesinsights.v1.EvaluatedSlice.detection_point_actual].
   * - *f* is the [detectionPointForecast][google.cloud.timeseriesinsights.v1.EvaluatedSlice.detection_point_forecast].
   * - *e* is the [expectedDeviation][google.cloud.timeseriesinsights.v1.EvaluatedSlice.expected_deviation].
   * - *nt` is the [noiseThreshold][google.cloud.timeseriesinsights.v1.ForecastParams.noise_threshold].
   *
   * Anomaly scores between different requests and datasets are comparable. As
   * a guideline, the risk of a slice being an anomaly based on the anomaly
   * score is:
   *
   * - **Very High** if `anomalyScore` > 5.
   * - **High** if the `anomalyScore` is in the [2, 5] range.
   * - **Medium** if the `anomalyScore` is in the [1, 2) range.
   * - **Low** if the `anomalyScore` is < 1.
   *
   * If there were issues evaluating this slice, then the anomaly score will be
   * set to -1.0 and the [status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status] field will contain details on what
   * went wrong.
   *
   * @generated from field: optional double anomaly_score = 17;
   */
  anomalyScore?: number;

  /**
   * The actual values in the `[`
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] `-`
   * [forecastHistory][google.cloud.timeseriesinsights.v1.TimeseriesParams.forecast_history]`,`
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] `]` time
   * range.
   *
   * **NOTE**: This field is only populated if
   * [returnTimeseries][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.return_timeseries] is true.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.Timeseries history = 5;
   */
  history?: Timeseries;

  /**
   * The forecasted values in the `[`
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] `+`
   * [granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity]`,`
   * [forecastParams.horizonTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.forecast_params] `]` time
   * range.
   *
   * **NOTE**: This field is only populated if
   * [returnTimeseries][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.return_timeseries] is true.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.Timeseries forecast = 10;
   */
  forecast?: Timeseries;

  /**
   * Evaluation status. Contains an error message if the `anomalyScore` is < 0.
   *
   * Possible error messages:
   *
   * - **"Time series too sparse"**: The returned time series for this slice did
   * not contain enough data points (we require a minimum of 10).
   * - **"Not enough recent time series points"**: The time series contains the
   * minimum of 10 points, but there are not enough close in time to the
   * detection point.
   * - **"Missing detection point data"**: There were not events to be
   * aggregated within the `[detectionTime, detectionTime + granularity]` time
   * interval, so we don't have an actual value with which we can compare our
   * prediction.
   * - **"Data retrieval error"**: We failed to retrieve the time series data
   * for this slice and could not evaluate it successfully. Should be a
   * transient error.
   * - **"Internal server error"**: Internal unexpected error.
   *
   * @generated from field: google.rpc.Status status = 18;
   */
  status?: Status;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.EvaluatedSlice.
 * Use `create(EvaluatedSliceSchema)` to create a new message.
 */
export const EvaluatedSliceSchema: GenMessage<EvaluatedSlice> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 15);

/**
 * Parameters that control how we slice the dataset and, optionally, filter
 * slices that have some specific values on some dimensions (pinned dimensions).
 *
 * @generated from message google.cloud.timeseriesinsights.v1.SlicingParams
 */
export type SlicingParams = Message<"google.cloud.timeseriesinsights.v1.SlicingParams"> & {
  /**
   * Required. Dimensions over which we will group the events in slices. The names
   * specified here come from the
   * [EventDimension.name][google.cloud.timeseriesinsights.v1.EventDimension.name] field. At least
   * one dimension name must be specified. All dimension names that do not exist
   * in the queried `DataSet` will be ignored.
   *
   * Currently only dimensions that hold string values can be specified here.
   *
   * @generated from field: repeated string dimension_names = 1;
   */
  dimensionNames: string[];

  /**
   * Optional. We will only analyze slices for which
   * [EvaluatedSlice.dimensions][google.cloud.timeseriesinsights.v1.EvaluatedSlice.dimensions] contain all of the
   * following pinned dimensions. A query with a pinned dimension `{ name: "d3"
   * stringVal: "v3" }` will only analyze events which contain the dimension `{
   * name: "d3" stringVal: "v3" }`.
   * The [pinnedDimensions][google.cloud.timeseriesinsights.v1.SlicingParams.pinned_dimensions] and
   * [dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] fields can **not**
   * share the same dimension names.
   *
   * Example a valid specification:
   *
   * ```json
   * {
   *   dimensionNames: ["d1", "d2"],
   *   pinnedDimensions: [
   *     { name: "d3" stringVal: "v3" },
   *     { name: "d4" stringVal: "v4" }
   *   ]
   * }
   * ```
   *
   * In the previous example we will slice the dataset by dimensions "d1",
   * "d2", "d3" and "d4", but we will only analyze slices for which "d3=v3" and
   * "d4=v4".
   *
   * The following example is **invalid** as "d2" is present in both
   * dimensionNames and pinnedDimensions:
   *
   * ```json
   * {
   *   dimensionNames: ["d1", "d2"],
   *   pinnedDimensions: [
   *     { name: "d2" stringVal: "v2" },
   *     { name: "d4" stringVal: "v4" }
   *   ]
   * }
   * ```
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.PinnedDimension pinned_dimensions = 2;
   */
  pinnedDimensions: PinnedDimension[];
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.SlicingParams.
 * Use `create(SlicingParamsSchema)` to create a new message.
 */
export const SlicingParamsSchema: GenMessage<SlicingParams> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 16);

/**
 * Parameters that control how we construct the time series for each slice.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.TimeseriesParams
 */
export type TimeseriesParams = Message<"google.cloud.timeseriesinsights.v1.TimeseriesParams"> & {
  /**
   * Required. How long should we go in the past when fetching the timeline used for
   * forecasting each slice.
   *
   * This is used in combination with the
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
   * The time series we construct will have the following time range:
   * `[detectionTime - forecastHistory, detectionTime + granularity]`.
   *
   * The forecast history might be rounded up, so that a multiple of
   * `granularity` is used to process the query.
   *
   * Note: If there are not enough events in the
   * `[detectionTime - forecastHistory, detectionTime + granularity]` time
   * interval, the slice evaluation can fail. For more information, see
   * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
   *
   * @generated from field: google.protobuf.Duration forecast_history = 1;
   */
  forecastHistory?: Duration;

  /**
   * Required. The time granularity of the time series (on the x-axis). Each time series
   * point starting at time T will aggregate all events for a particular slice
   * in *[T, T + granularity)* time windows.
   *
   * Note: The aggregation is decided based on the
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
   *
   * This granularity defines the query-time aggregation windows and is not
   * necessarily related to any event time granularity in the raw data (though
   * we do recommend that the query-time granularity is not finer than the
   * ingestion-time one).
   *
   * Currently, the minimal supported granularity is 10 seconds.
   *
   * @generated from field: google.protobuf.Duration granularity = 2;
   */
  granularity?: Duration;

  /**
   * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
   * dimension that will have its values aggregated to compute the y-axis of the
   * time series.
   *
   * The aggregation method must also be specified by setting the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * field.
   *
   * Note: Currently, if the aggregation method is unspecified, we will
   * default to SUM for backward compatibility reasons, but new implementations
   * should set the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * explicitly.
   *
   * If the metric is unspecified, we will use the number of events that each
   * time series point contains as the point value.
   *
   * Example: Let's assume we have the following three events in our dataset:
   * ```json
   * {
   *   eventTime: "2020-12-27T00:00:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 100 }
   *     { name: "m2" longVal: 11 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:10:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 200 }
   *     { name: "m2" longVal: 22 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:20:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 300 }
   *     { name: "m2" longVal: 33 }
   *   ]
   * }
   * ```
   *
   * These events are all within the same hour, spaced 10 minutes between each
   * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
   * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
   * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
   * "3600s", then all the previous events will be aggregated into the same
   * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
   *
   * The time series point that they're all part of will have the
   * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
   * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
   *
   * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
   * the value of the point will be 600.
   * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
   * the value of the point will be 66.
   * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 200.
   * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 22.
   * - If the metric field is "" or unspecified, then the value of the point
   * will be 3, as we will simply count the events.
   *
   * @generated from field: optional string metric = 4;
   */
  metric?: string;

  /**
   * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
   * we will aggregate multiple events to obtain the value of a time series
   * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
   * details.
   *
   * If the metric is not specified or "", then this field will be ignored.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5;
   */
  metricAggregationMethod: TimeseriesParams_AggregationMethod;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.TimeseriesParams.
 * Use `create(TimeseriesParamsSchema)` to create a new message.
 */
export const TimeseriesParamsSchema: GenMessage<TimeseriesParams> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 17);

/**
 * Methods by which we can aggregate multiple events by a given
 * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric].
 *
 * @generated from enum google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod
 */
export enum TimeseriesParams_AggregationMethod {
  /**
   * Unspecified.
   *
   * @generated from enum value: AGGREGATION_METHOD_UNSPECIFIED = 0;
   */
  AGGREGATION_METHOD_UNSPECIFIED = 0,

  /**
   * Aggregate multiple events by summing up the values found in the
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] dimension.
   *
   * @generated from enum value: SUM = 1;
   */
  SUM = 1,

  /**
   * Aggregate multiple events by averaging out the values found in the
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] dimension.
   *
   * @generated from enum value: AVERAGE = 2;
   */
  AVERAGE = 2,
}

/**
 * Describes the enum google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.
 */
export const TimeseriesParams_AggregationMethodSchema: GenEnum<TimeseriesParams_AggregationMethod> = /*@__PURE__*/
  enumDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 17, 0);

/**
 * Request for performing a query against a loaded DataSet.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.QueryDataSetRequest
 */
export type QueryDataSetRequest = Message<"google.cloud.timeseriesinsights.v1.QueryDataSetRequest"> & {
  /**
   * Required. Loaded DataSet to be queried in the format of
   * "projects/{project}/datasets/{dataset}"
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Required. This is the point in time that we want to probe for anomalies.
   *
   * The corresponding [TimeseriesPoint][google.cloud.timeseriesinsights.v1.TimeseriesPoint] is referred to as the
   * detection point.
   *
   * **NOTE**: As with any other time series point, the value is given by
   * aggregating all events in the slice that are in the
   * [detectionTime, detectionTime + granularity) time interval, where
   * the granularity is specified in the
   * [timeseriesParams.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] field.
   *
   * @generated from field: google.protobuf.Timestamp detection_time = 11;
   */
  detectionTime?: Timestamp;

  /**
   * How many slices are returned in
   * [QueryDataSetResponse.slices][google.cloud.timeseriesinsights.v1.QueryDataSetResponse.slices].
   *
   * The returned slices are tentatively the ones with the highest
   * [anomaly scores][google.cloud.timeseriesinsights.v1.EvaluatedSlice.anomaly_score] in the dataset that match
   * the query, but it is not guaranteed.
   *
   * Reducing this number will improve query performance, both in terms of
   * latency and resource usage.
   *
   * Defaults to 50.
   *
   * @generated from field: optional int32 num_returned_slices = 13;
   */
  numReturnedSlices?: number;

  /**
   * Parameters controlling how we will split the dataset into the slices that
   * we will analyze.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.SlicingParams slicing_params = 9;
   */
  slicingParams?: SlicingParams;

  /**
   * Parameters controlling how we will build the time series used to predict
   * the [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] value for each slice.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.TimeseriesParams timeseries_params = 10;
   */
  timeseriesParams?: TimeseriesParams;

  /**
   * Parameters that control the time series forecasting models, such as the
   * sensitivity of the anomaly detection.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.ForecastParams forecast_params = 5;
   */
  forecastParams?: ForecastParams;

  /**
   * If specified, we will return the actual and forecasted time for all
   * returned slices.
   *
   * The time series are returned in the
   * [EvaluatedSlice.history][google.cloud.timeseriesinsights.v1.EvaluatedSlice.history] and
   * [EvaluatedSlice.forecast][google.cloud.timeseriesinsights.v1.EvaluatedSlice.forecast] fields.
   *
   * @generated from field: bool return_timeseries = 8;
   */
  returnTimeseries: boolean;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.QueryDataSetRequest.
 * Use `create(QueryDataSetRequestSchema)` to create a new message.
 */
export const QueryDataSetRequestSchema: GenMessage<QueryDataSetRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 18);

/**
 * Response for a query executed by the system.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.QueryDataSetResponse
 */
export type QueryDataSetResponse = Message<"google.cloud.timeseriesinsights.v1.QueryDataSetResponse"> & {
  /**
   * Loaded DataSet that was queried.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Slices sorted in descending order by their
   * [anomalyScore][google.cloud.timeseriesinsights.v1.EvaluatedSlice.anomaly_score].
   *
   * At most [numReturnedSlices][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.num_returned_slices]
   * slices are present in this field.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.EvaluatedSlice slices = 3;
   */
  slices: EvaluatedSlice[];
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.QueryDataSetResponse.
 * Use `create(QueryDataSetResponseSchema)` to create a new message.
 */
export const QueryDataSetResponseSchema: GenMessage<QueryDataSetResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 19);

/**
 * Request for evaluateSlice.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.EvaluateSliceRequest
 */
export type EvaluateSliceRequest = Message<"google.cloud.timeseriesinsights.v1.EvaluateSliceRequest"> & {
  /**
   * Required. Loaded DataSet to be queried in the format of
   * "projects/{project}/datasets/{dataset}"
   *
   * @generated from field: string dataset = 1;
   */
  dataset: string;

  /**
   * Required. Dimensions with pinned values that specify the slice for which we will
   * fetch the time series.
   *
   * @generated from field: repeated google.cloud.timeseriesinsights.v1.PinnedDimension pinned_dimensions = 2;
   */
  pinnedDimensions: PinnedDimension[];

  /**
   * Required. This is the point in time that we want to probe for anomalies.
   *
   * See documentation for
   * [QueryDataSetRequest.detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time].
   *
   * @generated from field: google.protobuf.Timestamp detection_time = 3;
   */
  detectionTime?: Timestamp;

  /**
   * Parameters controlling how we will build the time series used to predict
   * the [detectionTime][google.cloud.timeseriesinsights.v1.EvaluateSliceRequest.detection_time] value for this slice.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.TimeseriesParams timeseries_params = 4;
   */
  timeseriesParams?: TimeseriesParams;

  /**
   * Parameters that control the time series forecasting models, such as the
   * sensitivity of the anomaly detection.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.ForecastParams forecast_params = 5;
   */
  forecastParams?: ForecastParams;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.EvaluateSliceRequest.
 * Use `create(EvaluateSliceRequestSchema)` to create a new message.
 */
export const EvaluateSliceRequestSchema: GenMessage<EvaluateSliceRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 20);

/**
 * Request for evaluateTimeseries.
 *
 * @generated from message google.cloud.timeseriesinsights.v1.EvaluateTimeseriesRequest
 */
export type EvaluateTimeseriesRequest = Message<"google.cloud.timeseriesinsights.v1.EvaluateTimeseriesRequest"> & {
  /**
   * Required. Client project name in the format of 'projects/{project}'.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * Evaluate this time series without requiring it was previously loaded in
   * a data set.
   *
   * The evaluated time series point is the last one, analogous to calling
   * evaluateSlice or query with
   * [detectionTime][google.cloud.timeseriesinsights.v1.EvaluateSliceRequest.detection_time] set to
   * `timeseries.point(timeseries.point_size() - 1).time`.
   *
   * The length of the time series must be at least 10.
   *
   * All points must have the same time offset relative to the granularity. For
   * example, if the [granularity][google.cloud.timeseriesinsights.v1.EvaluateTimeseriesRequest.granularity] is "5s", then the following
   * point.time sequences are valid:
   * - "100s", "105s", "120s", "125s" (no offset)
   * - "102s", "107s", "122s", "127s" (offset is "2s")
   * However, the following sequence is invalid as it has inconsistent offsets:
   * - "100s", "105s", "122s", "127s" (offsets are either "0s" or "2s")
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.Timeseries timeseries = 2;
   */
  timeseries?: Timeseries;

  /**
   * The granularity of the time series (time distance between two consecutive
   * points).
   *
   * @generated from field: google.protobuf.Duration granularity = 3;
   */
  granularity?: Duration;

  /**
   * The forecast parameters.
   *
   * @generated from field: google.cloud.timeseriesinsights.v1.ForecastParams forecast_params = 4;
   */
  forecastParams?: ForecastParams;
};

/**
 * Describes the message google.cloud.timeseriesinsights.v1.EvaluateTimeseriesRequest.
 * Use `create(EvaluateTimeseriesRequestSchema)` to create a new message.
 */
export const EvaluateTimeseriesRequestSchema: GenMessage<EvaluateTimeseriesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 21);

/**
 * @generated from service google.cloud.timeseriesinsights.v1.TimeseriesInsightsController
 */
export const TimeseriesInsightsController: GenService<{
  /**
   * Lists [DataSets][google.cloud.timeseriesinsights.v1.DataSet] under the project.
   *
   * The order of the results is unspecified but deterministic. Newly created
   * [DataSets][google.cloud.timeseriesinsights.v1.DataSet] will not necessarily be added to the end
   * of this list.
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.ListDataSets
   */
  listDataSets: {
    methodKind: "unary";
    input: typeof ListDataSetsRequestSchema;
    output: typeof ListDataSetsResponseSchema;
  },
  /**
   * Create a [DataSet][google.cloud.timeseriesinsights.v1.DataSet] from data stored on Cloud
   * Storage.
   *
   * The data must stay immutable while we process the
   * [DataSet][google.cloud.timeseriesinsights.v1.DataSet] creation; otherwise, undefined outcomes
   * might result.  For more information, see [DataSet][google.cloud.timeseriesinsights.v1.DataSet].
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.CreateDataSet
   */
  createDataSet: {
    methodKind: "unary";
    input: typeof CreateDataSetRequestSchema;
    output: typeof DataSetSchema;
  },
  /**
   * Delete a [DataSet][google.cloud.timeseriesinsights.v1.DataSet] from the system.
   *
   * **NOTE**: If the [DataSet][google.cloud.timeseriesinsights.v1.DataSet] is still being
   * processed, it will be aborted and deleted.
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.DeleteDataSet
   */
  deleteDataSet: {
    methodKind: "unary";
    input: typeof DeleteDataSetRequestSchema;
    output: typeof EmptySchema;
  },
  /**
   * Append events to a `LOADED` [DataSet][google.cloud.timeseriesinsights.v1.DataSet].
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.AppendEvents
   */
  appendEvents: {
    methodKind: "unary";
    input: typeof AppendEventsRequestSchema;
    output: typeof AppendEventsResponseSchema;
  },
  /**
   * Execute a Timeseries Insights query over a loaded
   * [DataSet][google.cloud.timeseriesinsights.v1.DataSet].
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.QueryDataSet
   */
  queryDataSet: {
    methodKind: "unary";
    input: typeof QueryDataSetRequestSchema;
    output: typeof QueryDataSetResponseSchema;
  },
  /**
   * Evaluate an explicit slice from a loaded [DataSet][google.cloud.timeseriesinsights.v1.DataSet].
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.EvaluateSlice
   */
  evaluateSlice: {
    methodKind: "unary";
    input: typeof EvaluateSliceRequestSchema;
    output: typeof EvaluatedSliceSchema;
  },
  /**
   * Evaluate an explicit timeseries.
   *
   * @generated from rpc google.cloud.timeseriesinsights.v1.TimeseriesInsightsController.EvaluateTimeseries
   */
  evaluateTimeseries: {
    methodKind: "unary";
    input: typeof EvaluateTimeseriesRequestSchema;
    output: typeof EvaluatedSliceSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_cloud_timeseriesinsights_v1_timeseries_insights, 0);

