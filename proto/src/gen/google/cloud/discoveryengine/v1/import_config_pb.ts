// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/discoveryengine/v1/import_config.proto (package google.cloud.discoveryengine.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { CompletionSuggestion, SuggestionDenyListEntry } from "./completion_pb";
import { file_google_cloud_discoveryengine_v1_completion } from "./completion_pb";
import type { Document } from "./document_pb";
import { file_google_cloud_discoveryengine_v1_document } from "./document_pb";
import type { UserEvent } from "./user_event_pb";
import { file_google_cloud_discoveryengine_v1_user_event } from "./user_event_pb";
import type { FieldMask, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_field_mask, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../rpc/status_pb";
import type { Date } from "../../../type/date_pb";
import { file_google_type_date } from "../../../type/date_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/discoveryengine/v1/import_config.proto.
 */
export const file_google_cloud_discoveryengine_v1_import_config: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_discoveryengine_v1_completion, file_google_cloud_discoveryengine_v1_document, file_google_cloud_discoveryengine_v1_user_event, file_google_protobuf_field_mask, file_google_protobuf_timestamp, file_google_rpc_status, file_google_type_date]);

/**
 * Cloud Storage location for input content.
 *
 * @generated from message google.cloud.discoveryengine.v1.GcsSource
 */
export type GcsSource = Message<"google.cloud.discoveryengine.v1.GcsSource"> & {
  /**
   * Required. Cloud Storage URIs to input files. Each URI can be up to
   * 2000 characters long. URIs can match the full object path (for example,
   * `gs://bucket/directory/object.json`) or a pattern matching one or more
   * files, such as `gs://bucket/directory/*.json`.
   *
   * A request can contain at most 100 files (or 100,000 files if `data_schema`
   * is `content`). Each file can be up to 2 GB (or 100 MB if `data_schema` is
   * `content`).
   *
   * @generated from field: repeated string input_uris = 1;
   */
  inputUris: string[];

  /**
   * The schema to use when parsing the data from the source.
   *
   * Supported values for document imports:
   *
   * * `document` (default): One JSON
   * [Document][google.cloud.discoveryengine.v1.Document] per line. Each
   * document must
   *   have a valid [Document.id][google.cloud.discoveryengine.v1.Document.id].
   * * `content`: Unstructured data (e.g. PDF, HTML). Each file matched by
   *   `input_uris` becomes a document, with the ID set to the first 128
   *   bits of SHA256(URI) encoded as a hex string.
   * * `custom`: One custom data JSON per row in arbitrary format that conforms
   *   to the defined [Schema][google.cloud.discoveryengine.v1.Schema] of the
   *   data store. This can only be used by the GENERIC Data Store vertical.
   * * `csv`: A CSV file with header conforming to the defined
   * [Schema][google.cloud.discoveryengine.v1.Schema] of the
   *   data store. Each entry after the header is imported as a Document.
   *   This can only be used by the GENERIC Data Store vertical.
   *
   * Supported values for user event imports:
   *
   * * `user_event` (default): One JSON
   * [UserEvent][google.cloud.discoveryengine.v1.UserEvent] per line.
   *
   * @generated from field: string data_schema = 2;
   */
  dataSchema: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.GcsSource.
 * Use `create(GcsSourceSchema)` to create a new message.
 */
export const GcsSourceSchema: GenMessage<GcsSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 0);

/**
 * BigQuery source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1.BigQuerySource
 */
export type BigQuerySource = Message<"google.cloud.discoveryengine.v1.BigQuerySource"> & {
  /**
   * BigQuery table partition info. Leave this empty if the BigQuery table
   * is not partitioned.
   *
   * @generated from oneof google.cloud.discoveryengine.v1.BigQuerySource.partition
   */
  partition: {
    /**
     * BigQuery time partitioned table's _PARTITIONDATE in YYYY-MM-DD format.
     *
     * @generated from field: google.type.Date partition_date = 5;
     */
    value: Date;
    case: "partitionDate";
  } | { case: undefined; value?: undefined };

  /**
   * The project ID or the project number that contains the BigQuery source. Has
   * a length limit of 128 characters. If not specified, inherits the project
   * ID from the parent request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The BigQuery data set to copy the data from with a length limit
   * of 1,024 characters.
   *
   * @generated from field: string dataset_id = 2;
   */
  datasetId: string;

  /**
   * Required. The BigQuery table to copy the data from with a length limit of
   * 1,024 characters.
   *
   * @generated from field: string table_id = 3;
   */
  tableId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * BigQuery export to a specific Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 4;
   */
  gcsStagingDir: string;

  /**
   * The schema to use when parsing the data from the source.
   *
   * Supported values for user event imports:
   *
   * * `user_event` (default): One
   * [UserEvent][google.cloud.discoveryengine.v1.UserEvent] per row.
   *
   * Supported values for document imports:
   *
   * * `document` (default): One
   * [Document][google.cloud.discoveryengine.v1.Document] format per
   *   row. Each document must have a valid
   *   [Document.id][google.cloud.discoveryengine.v1.Document.id] and one of
   *   [Document.json_data][google.cloud.discoveryengine.v1.Document.json_data]
   *   or
   *   [Document.struct_data][google.cloud.discoveryengine.v1.Document.struct_data].
   * * `custom`: One custom data per row in arbitrary format that conforms to
   *   the defined [Schema][google.cloud.discoveryengine.v1.Schema] of the data
   *   store. This can only be used by the GENERIC Data Store vertical.
   *
   * @generated from field: string data_schema = 6;
   */
  dataSchema: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.BigQuerySource.
 * Use `create(BigQuerySourceSchema)` to create a new message.
 */
export const BigQuerySourceSchema: GenMessage<BigQuerySource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 1);

/**
 * The Spanner source for importing data
 *
 * @generated from message google.cloud.discoveryengine.v1.SpannerSource
 */
export type SpannerSource = Message<"google.cloud.discoveryengine.v1.SpannerSource"> & {
  /**
   * The project ID that contains the Spanner source. Has a length limit of 128
   * characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The instance ID of the source Spanner table.
   *
   * @generated from field: string instance_id = 2;
   */
  instanceId: string;

  /**
   * Required. The database ID of the source Spanner table.
   *
   * @generated from field: string database_id = 3;
   */
  databaseId: string;

  /**
   * Required. The table name of the Spanner database that needs to be imported.
   *
   * @generated from field: string table_id = 4;
   */
  tableId: string;

  /**
   * Whether to apply data boost on Spanner export. Enabling this option will
   * incur additional cost. More info can be found
   * [here](https://cloud.google.com/spanner/docs/databoost/databoost-overview#billing_and_quotas).
   *
   * @generated from field: bool enable_data_boost = 5;
   */
  enableDataBoost: boolean;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.SpannerSource.
 * Use `create(SpannerSourceSchema)` to create a new message.
 */
export const SpannerSourceSchema: GenMessage<SpannerSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 2);

/**
 * The Bigtable Options object that contains information to support
 * the import.
 *
 * @generated from message google.cloud.discoveryengine.v1.BigtableOptions
 */
export type BigtableOptions = Message<"google.cloud.discoveryengine.v1.BigtableOptions"> & {
  /**
   * The field name used for saving row key value in the document. The name has
   * to match the pattern `[a-zA-Z0-9][a-zA-Z0-9-_]*`.
   *
   * @generated from field: string key_field_name = 1;
   */
  keyFieldName: string;

  /**
   * The mapping from family names to an object that contains column families
   * level information for the given column family. If a family is not present
   * in this map it will be ignored.
   *
   * @generated from field: map<string, google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumnFamily> families = 2;
   */
  families: { [key: string]: BigtableOptions_BigtableColumnFamily };
};

/**
 * Describes the message google.cloud.discoveryengine.v1.BigtableOptions.
 * Use `create(BigtableOptionsSchema)` to create a new message.
 */
export const BigtableOptionsSchema: GenMessage<BigtableOptions> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 3);

/**
 * The column family of the Bigtable.
 *
 * @generated from message google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumnFamily
 */
export type BigtableOptions_BigtableColumnFamily = Message<"google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumnFamily"> & {
  /**
   * The field name to use for this column family in the document. The
   * name has to match the pattern `[a-zA-Z0-9][a-zA-Z0-9-_]*`. If not set,
   * it is parsed from the family name with best effort. However, due to
   * different naming patterns, field name collisions could happen, where
   * parsing behavior is undefined.
   *
   * @generated from field: string field_name = 1;
   */
  fieldName: string;

  /**
   * The encoding mode of the values when the type is not STRING.
   * Acceptable encoding values are:
   *
   * * `TEXT`: indicates values are alphanumeric text strings.
   * * `BINARY`: indicates values are encoded using `HBase Bytes.toBytes`
   * family of functions. This can be overridden for a specific column
   * by listing that column in `columns` and specifying an encoding for it.
   *
   * @generated from field: google.cloud.discoveryengine.v1.BigtableOptions.Encoding encoding = 2;
   */
  encoding: BigtableOptions_Encoding;

  /**
   * The type of values in this column family.
   * The values are expected to be encoded using `HBase Bytes.toBytes`
   * function when the encoding value is set to `BINARY`.
   *
   * @generated from field: google.cloud.discoveryengine.v1.BigtableOptions.Type type = 3;
   */
  type: BigtableOptions_Type;

  /**
   * The list of objects that contains column level information for each
   * column. If a column is not present in this list it will be ignored.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumn columns = 4;
   */
  columns: BigtableOptions_BigtableColumn[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumnFamily.
 * Use `create(BigtableOptions_BigtableColumnFamilySchema)` to create a new message.
 */
export const BigtableOptions_BigtableColumnFamilySchema: GenMessage<BigtableOptions_BigtableColumnFamily> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 3, 0);

/**
 * The column of the Bigtable.
 *
 * @generated from message google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumn
 */
export type BigtableOptions_BigtableColumn = Message<"google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumn"> & {
  /**
   * Required. Qualifier of the column. If it cannot be decoded with utf-8,
   * use a base-64 encoded string instead.
   *
   * @generated from field: bytes qualifier = 1;
   */
  qualifier: Uint8Array;

  /**
   * The field name to use for this column in the document. The name has to
   * match the pattern `[a-zA-Z0-9][a-zA-Z0-9-_]*`.
   * If not set, it is parsed from the qualifier bytes with best effort.
   * However, due to different naming patterns, field name collisions could
   * happen, where parsing behavior is undefined.
   *
   * @generated from field: string field_name = 2;
   */
  fieldName: string;

  /**
   * The encoding mode of the values when the type is not `STRING`.
   * Acceptable encoding values are:
   *
   * * `TEXT`: indicates values are alphanumeric text strings.
   * * `BINARY`: indicates values are encoded using `HBase Bytes.toBytes`
   * family of functions. This can be overridden for a specific column
   * by listing that column in `columns` and specifying an encoding for it.
   *
   * @generated from field: google.cloud.discoveryengine.v1.BigtableOptions.Encoding encoding = 3;
   */
  encoding: BigtableOptions_Encoding;

  /**
   * The type of values in this column family.
   * The values are expected to be encoded using `HBase Bytes.toBytes`
   * function when the encoding value is set to `BINARY`.
   *
   * @generated from field: google.cloud.discoveryengine.v1.BigtableOptions.Type type = 4;
   */
  type: BigtableOptions_Type;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.BigtableOptions.BigtableColumn.
 * Use `create(BigtableOptions_BigtableColumnSchema)` to create a new message.
 */
export const BigtableOptions_BigtableColumnSchema: GenMessage<BigtableOptions_BigtableColumn> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 3, 1);

/**
 * The type of values in a Bigtable column or column family.
 * The values are expected to be encoded using
 * [HBase
 * Bytes.toBytes](https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/util/Bytes.html)
 * function when the encoding value is set to `BINARY`.
 *
 * @generated from enum google.cloud.discoveryengine.v1.BigtableOptions.Type
 */
export enum BigtableOptions_Type {
  /**
   * The type is unspecified.
   *
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  TYPE_UNSPECIFIED = 0,

  /**
   * String type.
   *
   * @generated from enum value: STRING = 1;
   */
  STRING = 1,

  /**
   * Numerical type.
   *
   * @generated from enum value: NUMBER = 2;
   */
  NUMBER = 2,

  /**
   * Integer type.
   *
   * @generated from enum value: INTEGER = 3;
   */
  INTEGER = 3,

  /**
   * Variable length integer type.
   *
   * @generated from enum value: VAR_INTEGER = 4;
   */
  VAR_INTEGER = 4,

  /**
   * BigDecimal type.
   *
   * @generated from enum value: BIG_NUMERIC = 5;
   */
  BIG_NUMERIC = 5,

  /**
   * Boolean type.
   *
   * @generated from enum value: BOOLEAN = 6;
   */
  BOOLEAN = 6,

  /**
   * JSON type.
   *
   * @generated from enum value: JSON = 7;
   */
  JSON = 7,
}

/**
 * Describes the enum google.cloud.discoveryengine.v1.BigtableOptions.Type.
 */
export const BigtableOptions_TypeSchema: GenEnum<BigtableOptions_Type> = /*@__PURE__*/
  enumDesc(file_google_cloud_discoveryengine_v1_import_config, 3, 0);

/**
 * The encoding mode of a Bigtable column or column family.
 *
 * @generated from enum google.cloud.discoveryengine.v1.BigtableOptions.Encoding
 */
export enum BigtableOptions_Encoding {
  /**
   * The encoding is unspecified.
   *
   * @generated from enum value: ENCODING_UNSPECIFIED = 0;
   */
  ENCODING_UNSPECIFIED = 0,

  /**
   * Text encoding.
   *
   * @generated from enum value: TEXT = 1;
   */
  TEXT = 1,

  /**
   * Binary encoding.
   *
   * @generated from enum value: BINARY = 2;
   */
  BINARY = 2,
}

/**
 * Describes the enum google.cloud.discoveryengine.v1.BigtableOptions.Encoding.
 */
export const BigtableOptions_EncodingSchema: GenEnum<BigtableOptions_Encoding> = /*@__PURE__*/
  enumDesc(file_google_cloud_discoveryengine_v1_import_config, 3, 1);

/**
 * The Cloud Bigtable source for importing data.
 *
 * @generated from message google.cloud.discoveryengine.v1.BigtableSource
 */
export type BigtableSource = Message<"google.cloud.discoveryengine.v1.BigtableSource"> & {
  /**
   * The project ID that contains the Bigtable source. Has a length limit of 128
   * characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The instance ID of the Cloud Bigtable that needs to be imported.
   *
   * @generated from field: string instance_id = 2;
   */
  instanceId: string;

  /**
   * Required. The table ID of the Cloud Bigtable that needs to be imported.
   *
   * @generated from field: string table_id = 3;
   */
  tableId: string;

  /**
   * Required. Bigtable options that contains information needed when parsing
   * data into typed structures. For example, column type annotations.
   *
   * @generated from field: google.cloud.discoveryengine.v1.BigtableOptions bigtable_options = 4;
   */
  bigtableOptions?: BigtableOptions;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.BigtableSource.
 * Use `create(BigtableSourceSchema)` to create a new message.
 */
export const BigtableSourceSchema: GenMessage<BigtableSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 4);

/**
 * Cloud FhirStore source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1.FhirStoreSource
 */
export type FhirStoreSource = Message<"google.cloud.discoveryengine.v1.FhirStoreSource"> & {
  /**
   * Required. The full resource name of the FHIR store to import data from, in
   * the format of
   * `projects/{project}/locations/{location}/datasets/{dataset}/fhirStores/{fhir_store}`.
   *
   * @generated from field: string fhir_store = 1;
   */
  fhirStore: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * FhirStore export to a specific Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 2;
   */
  gcsStagingDir: string;

  /**
   * The FHIR resource types to import. The resource types should be a subset of
   * all [supported FHIR resource
   * types](https://cloud.google.com/generative-ai-app-builder/docs/fhir-schema-reference#resource-level-specification).
   * Default to all supported FHIR resource types if empty.
   *
   * @generated from field: repeated string resource_types = 3;
   */
  resourceTypes: string[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1.FhirStoreSource.
 * Use `create(FhirStoreSourceSchema)` to create a new message.
 */
export const FhirStoreSourceSchema: GenMessage<FhirStoreSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 5);

/**
 * Cloud SQL source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1.CloudSqlSource
 */
export type CloudSqlSource = Message<"google.cloud.discoveryengine.v1.CloudSqlSource"> & {
  /**
   * The project ID that contains the Cloud SQL source. Has a length limit of
   * 128 characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The Cloud SQL instance to copy the data from with a length limit
   * of 256 characters.
   *
   * @generated from field: string instance_id = 2;
   */
  instanceId: string;

  /**
   * Required. The Cloud SQL database to copy the data from with a length limit
   * of 256 characters.
   *
   * @generated from field: string database_id = 3;
   */
  databaseId: string;

  /**
   * Required. The Cloud SQL table to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string table_id = 4;
   */
  tableId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * Cloud SQL export to a specific Cloud Storage directory.
   *
   * Ensure that the Cloud SQL service account has the necessary Cloud
   * Storage Admin permissions to access the specified Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 5;
   */
  gcsStagingDir: string;

  /**
   * Option for serverless export. Enabling this option will incur additional
   * cost. More info can be found
   * [here](https://cloud.google.com/sql/pricing#serverless).
   *
   * @generated from field: bool offload = 6;
   */
  offload: boolean;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.CloudSqlSource.
 * Use `create(CloudSqlSourceSchema)` to create a new message.
 */
export const CloudSqlSourceSchema: GenMessage<CloudSqlSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 6);

/**
 * AlloyDB source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1.AlloyDbSource
 */
export type AlloyDbSource = Message<"google.cloud.discoveryengine.v1.AlloyDbSource"> & {
  /**
   * The project ID that contains the AlloyDB source.
   * Has a length limit of 128 characters. If not specified, inherits the
   * project ID from the parent request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The AlloyDB location to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string location_id = 2;
   */
  locationId: string;

  /**
   * Required. The AlloyDB cluster to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string cluster_id = 3;
   */
  clusterId: string;

  /**
   * Required. The AlloyDB database to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string database_id = 4;
   */
  databaseId: string;

  /**
   * Required. The AlloyDB table to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string table_id = 5;
   */
  tableId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * AlloyDB export to a specific Cloud Storage directory.
   *
   * Ensure that the AlloyDB service account has the necessary Cloud
   * Storage Admin permissions to access the specified Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 6;
   */
  gcsStagingDir: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.AlloyDbSource.
 * Use `create(AlloyDbSourceSchema)` to create a new message.
 */
export const AlloyDbSourceSchema: GenMessage<AlloyDbSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 7);

/**
 * Firestore source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1.FirestoreSource
 */
export type FirestoreSource = Message<"google.cloud.discoveryengine.v1.FirestoreSource"> & {
  /**
   * The project ID that the Cloud SQL source is in with a length limit of 128
   * characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The Firestore database to copy the data from with a length limit
   * of 256 characters.
   *
   * @generated from field: string database_id = 2;
   */
  databaseId: string;

  /**
   * Required. The Firestore collection (or entity) to copy the data from with a
   * length limit of 1,500 characters.
   *
   * @generated from field: string collection_id = 3;
   */
  collectionId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * Firestore export to a specific Cloud Storage directory.
   *
   * Ensure that the Firestore service account has the necessary Cloud
   * Storage Admin permissions to access the specified Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 4;
   */
  gcsStagingDir: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.FirestoreSource.
 * Use `create(FirestoreSourceSchema)` to create a new message.
 */
export const FirestoreSourceSchema: GenMessage<FirestoreSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 8);

/**
 * Configuration of destination for Import related errors.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportErrorConfig
 */
export type ImportErrorConfig = Message<"google.cloud.discoveryengine.v1.ImportErrorConfig"> & {
  /**
   * Required. Errors destination.
   *
   * @generated from oneof google.cloud.discoveryengine.v1.ImportErrorConfig.destination
   */
  destination: {
    /**
     * Cloud Storage prefix for import errors. This must be an empty,
     * existing Cloud Storage directory. Import errors are written to
     * sharded files in this directory, one per line, as a JSON-encoded
     * `google.rpc.Status` message.
     *
     * @generated from field: string gcs_prefix = 1;
     */
    value: string;
    case: "gcsPrefix";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportErrorConfig.
 * Use `create(ImportErrorConfigSchema)` to create a new message.
 */
export const ImportErrorConfigSchema: GenMessage<ImportErrorConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 9);

/**
 * Request message for the ImportUserEvents request.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportUserEventsRequest
 */
export type ImportUserEventsRequest = Message<"google.cloud.discoveryengine.v1.ImportUserEventsRequest"> & {
  /**
   * Required - The desired input source of the user event data.
   *
   * @generated from oneof google.cloud.discoveryengine.v1.ImportUserEventsRequest.source
   */
  source: {
    /**
     * The Inline source for the input content for UserEvents.
     *
     * @generated from field: google.cloud.discoveryengine.v1.ImportUserEventsRequest.InlineSource inline_source = 2;
     */
    value: ImportUserEventsRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. Parent DataStore resource name, of the form
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import. Cannot be set
   * for inline user event imports.
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportUserEventsRequest.
 * Use `create(ImportUserEventsRequestSchema)` to create a new message.
 */
export const ImportUserEventsRequestSchema: GenMessage<ImportUserEventsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 10);

/**
 * The inline source for the input config for ImportUserEvents method.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportUserEventsRequest.InlineSource
 */
export type ImportUserEventsRequest_InlineSource = Message<"google.cloud.discoveryengine.v1.ImportUserEventsRequest.InlineSource"> & {
  /**
   * Required. A list of user events to import. Recommended max of 10k items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1.UserEvent user_events = 1;
   */
  userEvents: UserEvent[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportUserEventsRequest.InlineSource.
 * Use `create(ImportUserEventsRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportUserEventsRequest_InlineSourceSchema: GenMessage<ImportUserEventsRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 10, 0);

/**
 * Response of the ImportUserEventsRequest. If the long running
 * operation was successful, then this message is returned by the
 * google.longrunning.Operations.response field if the operation was successful.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportUserEventsResponse
 */
export type ImportUserEventsResponse = Message<"google.cloud.discoveryengine.v1.ImportUserEventsResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * Echoes the destination for the complete errors if this field was set in
   * the request.
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;

  /**
   * Count of user events imported with complete existing Documents.
   *
   * @generated from field: int64 joined_events_count = 3;
   */
  joinedEventsCount: bigint;

  /**
   * Count of user events imported, but with Document information not found
   * in the existing Branch.
   *
   * @generated from field: int64 unjoined_events_count = 4;
   */
  unjoinedEventsCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportUserEventsResponse.
 * Use `create(ImportUserEventsResponseSchema)` to create a new message.
 */
export const ImportUserEventsResponseSchema: GenMessage<ImportUserEventsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 11);

/**
 * Metadata related to the progress of the Import operation. This is
 * returned by the google.longrunning.Operation.metadata field.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportUserEventsMetadata
 */
export type ImportUserEventsMetadata = Message<"google.cloud.discoveryengine.v1.ImportUserEventsMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of entries that were processed successfully.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of entries that encountered errors while processing.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportUserEventsMetadata.
 * Use `create(ImportUserEventsMetadataSchema)` to create a new message.
 */
export const ImportUserEventsMetadataSchema: GenMessage<ImportUserEventsMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 12);

/**
 * Metadata related to the progress of the ImportDocuments operation. This is
 * returned by the google.longrunning.Operation.metadata field.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportDocumentsMetadata
 */
export type ImportDocumentsMetadata = Message<"google.cloud.discoveryengine.v1.ImportDocumentsMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of entries that were processed successfully.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of entries that encountered errors while processing.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;

  /**
   * Total count of entries that were processed.
   *
   * @generated from field: int64 total_count = 5;
   */
  totalCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportDocumentsMetadata.
 * Use `create(ImportDocumentsMetadataSchema)` to create a new message.
 */
export const ImportDocumentsMetadataSchema: GenMessage<ImportDocumentsMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 13);

/**
 * Request message for Import methods.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportDocumentsRequest
 */
export type ImportDocumentsRequest = Message<"google.cloud.discoveryengine.v1.ImportDocumentsRequest"> & {
  /**
   * Required. The source of the input.
   *
   * @generated from oneof google.cloud.discoveryengine.v1.ImportDocumentsRequest.source
   */
  source: {
    /**
     * The Inline source for the input content for documents.
     *
     * @generated from field: google.cloud.discoveryengine.v1.ImportDocumentsRequest.InlineSource inline_source = 2;
     */
    value: ImportDocumentsRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | {
    /**
     * FhirStore input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.FhirStoreSource fhir_store_source = 10;
     */
    value: FhirStoreSource;
    case: "fhirStoreSource";
  } | {
    /**
     * Spanner input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.SpannerSource spanner_source = 11;
     */
    value: SpannerSource;
    case: "spannerSource";
  } | {
    /**
     * Cloud SQL input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.CloudSqlSource cloud_sql_source = 12;
     */
    value: CloudSqlSource;
    case: "cloudSqlSource";
  } | {
    /**
     * Firestore input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.FirestoreSource firestore_source = 13;
     */
    value: FirestoreSource;
    case: "firestoreSource";
  } | {
    /**
     * AlloyDB input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.AlloyDbSource alloy_db_source = 14;
     */
    value: AlloyDbSource;
    case: "alloyDbSource";
  } | {
    /**
     * Cloud Bigtable input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.BigtableSource bigtable_source = 15;
     */
    value: BigtableSource;
    case: "bigtableSource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent branch resource name, such as
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/branches/{branch}`.
   * Requires create/update permission.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;

  /**
   * The mode of reconciliation between existing documents and the documents to
   * be imported. Defaults to
   * [ReconciliationMode.INCREMENTAL][google.cloud.discoveryengine.v1.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL].
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportDocumentsRequest.ReconciliationMode reconciliation_mode = 6;
   */
  reconciliationMode: ImportDocumentsRequest_ReconciliationMode;

  /**
   * Indicates which fields in the provided imported documents to update. If
   * not set, the default is to update all fields.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 7;
   */
  updateMask?: FieldMask;

  /**
   * Whether to automatically generate IDs for the documents if absent.
   *
   * If set to `true`,
   * [Document.id][google.cloud.discoveryengine.v1.Document.id]s are
   * automatically generated based on the hash of the payload, where IDs may not
   * be consistent during multiple imports. In which case
   * [ReconciliationMode.FULL][google.cloud.discoveryengine.v1.ImportDocumentsRequest.ReconciliationMode.FULL]
   * is highly recommended to avoid duplicate contents. If unset or set to
   * `false`, [Document.id][google.cloud.discoveryengine.v1.Document.id]s have
   * to be specified using
   * [id_field][google.cloud.discoveryengine.v1.ImportDocumentsRequest.id_field],
   * otherwise, documents without IDs fail to be imported.
   *
   * Supported data sources:
   *
   * * [GcsSource][google.cloud.discoveryengine.v1.GcsSource].
   * [GcsSource.data_schema][google.cloud.discoveryengine.v1.GcsSource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [BigQuerySource][google.cloud.discoveryengine.v1.BigQuerySource].
   * [BigQuerySource.data_schema][google.cloud.discoveryengine.v1.BigQuerySource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [SpannerSource][google.cloud.discoveryengine.v1.SpannerSource].
   * * [CloudSqlSource][google.cloud.discoveryengine.v1.CloudSqlSource].
   * * [FirestoreSource][google.cloud.discoveryengine.v1.FirestoreSource].
   * * [BigtableSource][google.cloud.discoveryengine.v1.BigtableSource].
   *
   * @generated from field: bool auto_generate_ids = 8;
   */
  autoGenerateIds: boolean;

  /**
   * The field indicates the ID field or column to be used as unique IDs of
   * the documents.
   *
   * For [GcsSource][google.cloud.discoveryengine.v1.GcsSource] it is the key of
   * the JSON field. For instance, `my_id` for JSON `{"my_id": "some_uuid"}`.
   * For others, it may be the column name of the table where the unique ids are
   * stored.
   *
   * The values of the JSON field or the table column are used as the
   * [Document.id][google.cloud.discoveryengine.v1.Document.id]s. The JSON field
   * or the table column must be of string type, and the values must be set as
   * valid strings conform to [RFC-1034](https://tools.ietf.org/html/rfc1034)
   * with 1-63 characters. Otherwise, documents without valid IDs fail to be
   * imported.
   *
   * Only set this field when
   * [auto_generate_ids][google.cloud.discoveryengine.v1.ImportDocumentsRequest.auto_generate_ids]
   * is unset or set as `false`. Otherwise, an INVALID_ARGUMENT error is thrown.
   *
   * If it is unset, a default value `_id` is used when importing from the
   * allowed data sources.
   *
   * Supported data sources:
   *
   * * [GcsSource][google.cloud.discoveryengine.v1.GcsSource].
   * [GcsSource.data_schema][google.cloud.discoveryengine.v1.GcsSource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [BigQuerySource][google.cloud.discoveryengine.v1.BigQuerySource].
   * [BigQuerySource.data_schema][google.cloud.discoveryengine.v1.BigQuerySource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [SpannerSource][google.cloud.discoveryengine.v1.SpannerSource].
   * * [CloudSqlSource][google.cloud.discoveryengine.v1.CloudSqlSource].
   * * [FirestoreSource][google.cloud.discoveryengine.v1.FirestoreSource].
   * * [BigtableSource][google.cloud.discoveryengine.v1.BigtableSource].
   *
   * @generated from field: string id_field = 9;
   */
  idField: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportDocumentsRequest.
 * Use `create(ImportDocumentsRequestSchema)` to create a new message.
 */
export const ImportDocumentsRequestSchema: GenMessage<ImportDocumentsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 14);

/**
 * The inline source for the input config for ImportDocuments method.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportDocumentsRequest.InlineSource
 */
export type ImportDocumentsRequest_InlineSource = Message<"google.cloud.discoveryengine.v1.ImportDocumentsRequest.InlineSource"> & {
  /**
   * Required. A list of documents to update/create. Each document must have a
   * valid [Document.id][google.cloud.discoveryengine.v1.Document.id].
   * Recommended max of 100 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1.Document documents = 1;
   */
  documents: Document[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportDocumentsRequest.InlineSource.
 * Use `create(ImportDocumentsRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportDocumentsRequest_InlineSourceSchema: GenMessage<ImportDocumentsRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 14, 0);

/**
 * Indicates how imported documents are reconciled with the existing documents
 * created or imported before.
 *
 * @generated from enum google.cloud.discoveryengine.v1.ImportDocumentsRequest.ReconciliationMode
 */
export enum ImportDocumentsRequest_ReconciliationMode {
  /**
   * Defaults to `INCREMENTAL`.
   *
   * @generated from enum value: RECONCILIATION_MODE_UNSPECIFIED = 0;
   */
  RECONCILIATION_MODE_UNSPECIFIED = 0,

  /**
   * Inserts new documents or updates existing documents.
   *
   * @generated from enum value: INCREMENTAL = 1;
   */
  INCREMENTAL = 1,

  /**
   * Calculates diff and replaces the entire document dataset. Existing
   * documents may be deleted if they are not present in the source location.
   *
   * @generated from enum value: FULL = 2;
   */
  FULL = 2,
}

/**
 * Describes the enum google.cloud.discoveryengine.v1.ImportDocumentsRequest.ReconciliationMode.
 */
export const ImportDocumentsRequest_ReconciliationModeSchema: GenEnum<ImportDocumentsRequest_ReconciliationMode> = /*@__PURE__*/
  enumDesc(file_google_cloud_discoveryengine_v1_import_config, 14, 0);

/**
 * Response of the
 * [ImportDocumentsRequest][google.cloud.discoveryengine.v1.ImportDocumentsRequest].
 * If the long running operation is done, then this message is returned by the
 * google.longrunning.Operations.response field if the operation was successful.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportDocumentsResponse
 */
export type ImportDocumentsResponse = Message<"google.cloud.discoveryengine.v1.ImportDocumentsResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * Echoes the destination for the complete errors in the request if set.
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportDocumentsResponse.
 * Use `create(ImportDocumentsResponseSchema)` to create a new message.
 */
export const ImportDocumentsResponseSchema: GenMessage<ImportDocumentsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 15);

/**
 * Request message for
 * [CompletionService.ImportSuggestionDenyListEntries][google.cloud.discoveryengine.v1.CompletionService.ImportSuggestionDenyListEntries]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest
 */
export type ImportSuggestionDenyListEntriesRequest = Message<"google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest"> & {
  /**
   * The source of the updated SuggestionDenyList.
   *
   * @generated from oneof google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest.source
   */
  source: {
    /**
     * The Inline source for the input content for suggestion deny list entries.
     *
     * @generated from field: google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest.InlineSource inline_source = 2;
     */
    value: ImportSuggestionDenyListEntriesRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * Only 1 file can be specified that contains all entries to import.
     * Supported values `gcs_source.schema` for autocomplete suggestion deny
     * list entry imports:
     *
     * * `suggestion_deny_list` (default): One JSON [SuggestionDenyListEntry]
     * per line.
     *
     * @generated from field: google.cloud.discoveryengine.v1.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent data store resource name for which to import denylist
   * entries. Follows pattern projects/*\/locations/*\/collections/*\/dataStores/*.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest.
 * Use `create(ImportSuggestionDenyListEntriesRequestSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesRequestSchema: GenMessage<ImportSuggestionDenyListEntriesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 16);

/**
 * The inline source for SuggestionDenyListEntry.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest.InlineSource
 */
export type ImportSuggestionDenyListEntriesRequest_InlineSource = Message<"google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest.InlineSource"> & {
  /**
   * Required. A list of all denylist entries to import. Max of 1000 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1.SuggestionDenyListEntry entries = 1;
   */
  entries: SuggestionDenyListEntry[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesRequest.InlineSource.
 * Use `create(ImportSuggestionDenyListEntriesRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesRequest_InlineSourceSchema: GenMessage<ImportSuggestionDenyListEntriesRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 16, 0);

/**
 * Response message for
 * [CompletionService.ImportSuggestionDenyListEntries][google.cloud.discoveryengine.v1.CompletionService.ImportSuggestionDenyListEntries]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesResponse
 */
export type ImportSuggestionDenyListEntriesResponse = Message<"google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * Count of deny list entries successfully imported.
   *
   * @generated from field: int64 imported_entries_count = 2;
   */
  importedEntriesCount: bigint;

  /**
   * Count of deny list entries that failed to be imported.
   *
   * @generated from field: int64 failed_entries_count = 3;
   */
  failedEntriesCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesResponse.
 * Use `create(ImportSuggestionDenyListEntriesResponseSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesResponseSchema: GenMessage<ImportSuggestionDenyListEntriesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 17);

/**
 * Metadata related to the progress of the ImportSuggestionDenyListEntries
 * operation. This is returned by the google.longrunning.Operation.metadata
 * field.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesMetadata
 */
export type ImportSuggestionDenyListEntriesMetadata = Message<"google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportSuggestionDenyListEntriesMetadata.
 * Use `create(ImportSuggestionDenyListEntriesMetadataSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesMetadataSchema: GenMessage<ImportSuggestionDenyListEntriesMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 18);

/**
 * Request message for
 * [CompletionService.ImportCompletionSuggestions][google.cloud.discoveryengine.v1.CompletionService.ImportCompletionSuggestions]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest
 */
export type ImportCompletionSuggestionsRequest = Message<"google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest"> & {
  /**
   * The source of the autocomplete suggestions.
   *
   * @generated from oneof google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest.source
   */
  source: {
    /**
     * The Inline source for suggestion entries.
     *
     * @generated from field: google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest.InlineSource inline_source = 2;
     */
    value: ImportCompletionSuggestionsRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent data store resource name for which to import customer
   * autocomplete suggestions.
   *
   * Follows pattern `projects/*\/locations/*\/collections/*\/dataStores/*`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest.
 * Use `create(ImportCompletionSuggestionsRequestSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsRequestSchema: GenMessage<ImportCompletionSuggestionsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 19);

/**
 * The inline source for CompletionSuggestions.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest.InlineSource
 */
export type ImportCompletionSuggestionsRequest_InlineSource = Message<"google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest.InlineSource"> & {
  /**
   * Required. A list of all denylist entries to import. Max of 1000 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1.CompletionSuggestion suggestions = 1;
   */
  suggestions: CompletionSuggestion[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsRequest.InlineSource.
 * Use `create(ImportCompletionSuggestionsRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsRequest_InlineSourceSchema: GenMessage<ImportCompletionSuggestionsRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 19, 0);

/**
 * Response of the
 * [CompletionService.ImportCompletionSuggestions][google.cloud.discoveryengine.v1.CompletionService.ImportCompletionSuggestions]
 * method. If the long running operation is done, this message is returned by
 * the google.longrunning.Operations.response field if the operation is
 * successful.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsResponse
 */
export type ImportCompletionSuggestionsResponse = Message<"google.cloud.discoveryengine.v1.ImportCompletionSuggestionsResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsResponse.
 * Use `create(ImportCompletionSuggestionsResponseSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsResponseSchema: GenMessage<ImportCompletionSuggestionsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 20);

/**
 * Metadata related to the progress of the ImportCompletionSuggestions
 * operation. This will be returned by the google.longrunning.Operation.metadata
 * field.
 *
 * @generated from message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsMetadata
 */
export type ImportCompletionSuggestionsMetadata = Message<"google.cloud.discoveryengine.v1.ImportCompletionSuggestionsMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of
   * [CompletionSuggestion][google.cloud.discoveryengine.v1.CompletionSuggestion]s
   * successfully imported.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of
   * [CompletionSuggestion][google.cloud.discoveryengine.v1.CompletionSuggestion]s
   * that failed to be imported.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1.ImportCompletionSuggestionsMetadata.
 * Use `create(ImportCompletionSuggestionsMetadataSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsMetadataSchema: GenMessage<ImportCompletionSuggestionsMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1_import_config, 21);

