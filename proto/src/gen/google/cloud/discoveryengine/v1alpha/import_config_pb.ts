// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/cloud/discoveryengine/v1alpha/import_config.proto (package google.cloud.discoveryengine.v1alpha, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { CompletionSuggestion, SuggestionDenyListEntry } from "./completion_pb";
import { file_google_cloud_discoveryengine_v1alpha_completion } from "./completion_pb";
import type { Document } from "./document_pb";
import { file_google_cloud_discoveryengine_v1alpha_document } from "./document_pb";
import type { SampleQuery } from "./sample_query_pb";
import { file_google_cloud_discoveryengine_v1alpha_sample_query } from "./sample_query_pb";
import type { UserEvent } from "./user_event_pb";
import { file_google_cloud_discoveryengine_v1alpha_user_event } from "./user_event_pb";
import type { FieldMask, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_field_mask, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Status } from "../../../rpc/status_pb";
import { file_google_rpc_status } from "../../../rpc/status_pb";
import type { Date } from "../../../type/date_pb";
import { file_google_type_date } from "../../../type/date_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/cloud/discoveryengine/v1alpha/import_config.proto.
 */
export const file_google_cloud_discoveryengine_v1alpha_import_config: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_cloud_discoveryengine_v1alpha_completion, file_google_cloud_discoveryengine_v1alpha_document, file_google_cloud_discoveryengine_v1alpha_sample_query, file_google_cloud_discoveryengine_v1alpha_user_event, file_google_protobuf_field_mask, file_google_protobuf_timestamp, file_google_rpc_status, file_google_type_date]);

/**
 * Cloud Storage location for input content.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.GcsSource
 */
export type GcsSource = Message<"google.cloud.discoveryengine.v1alpha.GcsSource"> & {
  /**
   * Required. Cloud Storage URIs to input files. Each URI can be up to
   * 2000 characters long. URIs can match the full object path (for example,
   * `gs://bucket/directory/object.json`) or a pattern matching one or more
   * files, such as `gs://bucket/directory/*.json`.
   *
   * A request can contain at most 100 files (or 100,000 files if `data_schema`
   * is `content`). Each file can be up to 2 GB (or 100 MB if `data_schema` is
   * `content`).
   *
   * @generated from field: repeated string input_uris = 1;
   */
  inputUris: string[];

  /**
   * The schema to use when parsing the data from the source.
   *
   * Supported values for document imports:
   *
   * * `document` (default): One JSON
   * [Document][google.cloud.discoveryengine.v1alpha.Document] per line. Each
   * document must
   *   have a valid
   *   [Document.id][google.cloud.discoveryengine.v1alpha.Document.id].
   * * `content`: Unstructured data (e.g. PDF, HTML). Each file matched by
   *   `input_uris` becomes a document, with the ID set to the first 128
   *   bits of SHA256(URI) encoded as a hex string.
   * * `custom`: One custom data JSON per row in arbitrary format that conforms
   *   to the defined [Schema][google.cloud.discoveryengine.v1alpha.Schema] of
   *   the data store. This can only be used by the GENERIC Data Store vertical.
   * * `csv`: A CSV file with header conforming to the defined
   * [Schema][google.cloud.discoveryengine.v1alpha.Schema] of the
   *   data store. Each entry after the header is imported as a Document.
   *   This can only be used by the GENERIC Data Store vertical.
   *
   * Supported values for user event imports:
   *
   * * `user_event` (default): One JSON
   * [UserEvent][google.cloud.discoveryengine.v1alpha.UserEvent] per line.
   *
   * @generated from field: string data_schema = 2;
   */
  dataSchema: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.GcsSource.
 * Use `create(GcsSourceSchema)` to create a new message.
 */
export const GcsSourceSchema: GenMessage<GcsSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 0);

/**
 * BigQuery source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.BigQuerySource
 */
export type BigQuerySource = Message<"google.cloud.discoveryengine.v1alpha.BigQuerySource"> & {
  /**
   * BigQuery table partition info. Leave this empty if the BigQuery table
   * is not partitioned.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.BigQuerySource.partition
   */
  partition: {
    /**
     * BigQuery time partitioned table's _PARTITIONDATE in YYYY-MM-DD format.
     *
     * @generated from field: google.type.Date partition_date = 5;
     */
    value: Date;
    case: "partitionDate";
  } | { case: undefined; value?: undefined };

  /**
   * The project ID or the project number that contains the BigQuery source. Has
   * a length limit of 128 characters. If not specified, inherits the project
   * ID from the parent request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The BigQuery data set to copy the data from with a length limit
   * of 1,024 characters.
   *
   * @generated from field: string dataset_id = 2;
   */
  datasetId: string;

  /**
   * Required. The BigQuery table to copy the data from with a length limit of
   * 1,024 characters.
   *
   * @generated from field: string table_id = 3;
   */
  tableId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * BigQuery export to a specific Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 4;
   */
  gcsStagingDir: string;

  /**
   * The schema to use when parsing the data from the source.
   *
   * Supported values for user event imports:
   *
   * * `user_event` (default): One
   * [UserEvent][google.cloud.discoveryengine.v1alpha.UserEvent] per row.
   *
   * Supported values for document imports:
   *
   * * `document` (default): One
   * [Document][google.cloud.discoveryengine.v1alpha.Document] format per
   *   row. Each document must have a valid
   *   [Document.id][google.cloud.discoveryengine.v1alpha.Document.id] and one
   *   of
   *   [Document.json_data][google.cloud.discoveryengine.v1alpha.Document.json_data]
   *   or
   *   [Document.struct_data][google.cloud.discoveryengine.v1alpha.Document.struct_data].
   * * `custom`: One custom data per row in arbitrary format that conforms to
   *   the defined [Schema][google.cloud.discoveryengine.v1alpha.Schema] of the
   *   data store. This can only be used by the GENERIC Data Store vertical.
   *
   * @generated from field: string data_schema = 6;
   */
  dataSchema: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.BigQuerySource.
 * Use `create(BigQuerySourceSchema)` to create a new message.
 */
export const BigQuerySourceSchema: GenMessage<BigQuerySource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 1);

/**
 * The Spanner source for importing data
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.SpannerSource
 */
export type SpannerSource = Message<"google.cloud.discoveryengine.v1alpha.SpannerSource"> & {
  /**
   * The project ID that contains the Spanner source. Has a length limit of 128
   * characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The instance ID of the source Spanner table.
   *
   * @generated from field: string instance_id = 2;
   */
  instanceId: string;

  /**
   * Required. The database ID of the source Spanner table.
   *
   * @generated from field: string database_id = 3;
   */
  databaseId: string;

  /**
   * Required. The table name of the Spanner database that needs to be imported.
   *
   * @generated from field: string table_id = 4;
   */
  tableId: string;

  /**
   * Whether to apply data boost on Spanner export. Enabling this option will
   * incur additional cost. More info can be found
   * [here](https://cloud.google.com/spanner/docs/databoost/databoost-overview#billing_and_quotas).
   *
   * @generated from field: bool enable_data_boost = 5;
   */
  enableDataBoost: boolean;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.SpannerSource.
 * Use `create(SpannerSourceSchema)` to create a new message.
 */
export const SpannerSourceSchema: GenMessage<SpannerSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 2);

/**
 * The Bigtable Options object that contains information to support
 * the import.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.BigtableOptions
 */
export type BigtableOptions = Message<"google.cloud.discoveryengine.v1alpha.BigtableOptions"> & {
  /**
   * The field name used for saving row key value in the document. The name has
   * to match the pattern `[a-zA-Z0-9][a-zA-Z0-9-_]*`.
   *
   * @generated from field: string key_field_name = 1;
   */
  keyFieldName: string;

  /**
   * The mapping from family names to an object that contains column families
   * level information for the given column family. If a family is not present
   * in this map it will be ignored.
   *
   * @generated from field: map<string, google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumnFamily> families = 2;
   */
  families: { [key: string]: BigtableOptions_BigtableColumnFamily };
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.BigtableOptions.
 * Use `create(BigtableOptionsSchema)` to create a new message.
 */
export const BigtableOptionsSchema: GenMessage<BigtableOptions> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 3);

/**
 * The column family of the Bigtable.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumnFamily
 */
export type BigtableOptions_BigtableColumnFamily = Message<"google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumnFamily"> & {
  /**
   * The field name to use for this column family in the document. The
   * name has to match the pattern `[a-zA-Z0-9][a-zA-Z0-9-_]*`. If not set,
   * it is parsed from the family name with best effort. However, due to
   * different naming patterns, field name collisions could happen, where
   * parsing behavior is undefined.
   *
   * @generated from field: string field_name = 1;
   */
  fieldName: string;

  /**
   * The encoding mode of the values when the type is not STRING.
   * Acceptable encoding values are:
   *
   * * `TEXT`: indicates values are alphanumeric text strings.
   * * `BINARY`: indicates values are encoded using `HBase Bytes.toBytes`
   * family of functions. This can be overridden for a specific column
   * by listing that column in `columns` and specifying an encoding for it.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.BigtableOptions.Encoding encoding = 2;
   */
  encoding: BigtableOptions_Encoding;

  /**
   * The type of values in this column family.
   * The values are expected to be encoded using `HBase Bytes.toBytes`
   * function when the encoding value is set to `BINARY`.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.BigtableOptions.Type type = 3;
   */
  type: BigtableOptions_Type;

  /**
   * The list of objects that contains column level information for each
   * column. If a column is not present in this list it will be ignored.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumn columns = 4;
   */
  columns: BigtableOptions_BigtableColumn[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumnFamily.
 * Use `create(BigtableOptions_BigtableColumnFamilySchema)` to create a new message.
 */
export const BigtableOptions_BigtableColumnFamilySchema: GenMessage<BigtableOptions_BigtableColumnFamily> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 3, 0);

/**
 * The column of the Bigtable.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumn
 */
export type BigtableOptions_BigtableColumn = Message<"google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumn"> & {
  /**
   * Required. Qualifier of the column. If it cannot be decoded with utf-8,
   * use a base-64 encoded string instead.
   *
   * @generated from field: bytes qualifier = 1;
   */
  qualifier: Uint8Array;

  /**
   * The field name to use for this column in the document. The name has to
   * match the pattern `[a-zA-Z0-9][a-zA-Z0-9-_]*`.
   * If not set, it is parsed from the qualifier bytes with best effort.
   * However, due to different naming patterns, field name collisions could
   * happen, where parsing behavior is undefined.
   *
   * @generated from field: string field_name = 2;
   */
  fieldName: string;

  /**
   * The encoding mode of the values when the type is not `STRING`.
   * Acceptable encoding values are:
   *
   * * `TEXT`: indicates values are alphanumeric text strings.
   * * `BINARY`: indicates values are encoded using `HBase Bytes.toBytes`
   * family of functions. This can be overridden for a specific column
   * by listing that column in `columns` and specifying an encoding for it.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.BigtableOptions.Encoding encoding = 3;
   */
  encoding: BigtableOptions_Encoding;

  /**
   * The type of values in this column family.
   * The values are expected to be encoded using `HBase Bytes.toBytes`
   * function when the encoding value is set to `BINARY`.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.BigtableOptions.Type type = 4;
   */
  type: BigtableOptions_Type;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.BigtableOptions.BigtableColumn.
 * Use `create(BigtableOptions_BigtableColumnSchema)` to create a new message.
 */
export const BigtableOptions_BigtableColumnSchema: GenMessage<BigtableOptions_BigtableColumn> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 3, 1);

/**
 * The type of values in a Bigtable column or column family.
 * The values are expected to be encoded using
 * [HBase
 * Bytes.toBytes](https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/util/Bytes.html)
 * function when the encoding value is set to `BINARY`.
 *
 * @generated from enum google.cloud.discoveryengine.v1alpha.BigtableOptions.Type
 */
export enum BigtableOptions_Type {
  /**
   * The type is unspecified.
   *
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  TYPE_UNSPECIFIED = 0,

  /**
   * String type.
   *
   * @generated from enum value: STRING = 1;
   */
  STRING = 1,

  /**
   * Numerical type.
   *
   * @generated from enum value: NUMBER = 2;
   */
  NUMBER = 2,

  /**
   * Integer type.
   *
   * @generated from enum value: INTEGER = 3;
   */
  INTEGER = 3,

  /**
   * Variable length integer type.
   *
   * @generated from enum value: VAR_INTEGER = 4;
   */
  VAR_INTEGER = 4,

  /**
   * BigDecimal type.
   *
   * @generated from enum value: BIG_NUMERIC = 5;
   */
  BIG_NUMERIC = 5,

  /**
   * Boolean type.
   *
   * @generated from enum value: BOOLEAN = 6;
   */
  BOOLEAN = 6,

  /**
   * JSON type.
   *
   * @generated from enum value: JSON = 7;
   */
  JSON = 7,
}

/**
 * Describes the enum google.cloud.discoveryengine.v1alpha.BigtableOptions.Type.
 */
export const BigtableOptions_TypeSchema: GenEnum<BigtableOptions_Type> = /*@__PURE__*/
  enumDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 3, 0);

/**
 * The encoding mode of a Bigtable column or column family.
 *
 * @generated from enum google.cloud.discoveryengine.v1alpha.BigtableOptions.Encoding
 */
export enum BigtableOptions_Encoding {
  /**
   * The encoding is unspecified.
   *
   * @generated from enum value: ENCODING_UNSPECIFIED = 0;
   */
  ENCODING_UNSPECIFIED = 0,

  /**
   * Text encoding.
   *
   * @generated from enum value: TEXT = 1;
   */
  TEXT = 1,

  /**
   * Binary encoding.
   *
   * @generated from enum value: BINARY = 2;
   */
  BINARY = 2,
}

/**
 * Describes the enum google.cloud.discoveryengine.v1alpha.BigtableOptions.Encoding.
 */
export const BigtableOptions_EncodingSchema: GenEnum<BigtableOptions_Encoding> = /*@__PURE__*/
  enumDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 3, 1);

/**
 * The Cloud Bigtable source for importing data.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.BigtableSource
 */
export type BigtableSource = Message<"google.cloud.discoveryengine.v1alpha.BigtableSource"> & {
  /**
   * The project ID that contains the Bigtable source. Has a length limit of 128
   * characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The instance ID of the Cloud Bigtable that needs to be imported.
   *
   * @generated from field: string instance_id = 2;
   */
  instanceId: string;

  /**
   * Required. The table ID of the Cloud Bigtable that needs to be imported.
   *
   * @generated from field: string table_id = 3;
   */
  tableId: string;

  /**
   * Required. Bigtable options that contains information needed when parsing
   * data into typed structures. For example, column type annotations.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.BigtableOptions bigtable_options = 4;
   */
  bigtableOptions?: BigtableOptions;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.BigtableSource.
 * Use `create(BigtableSourceSchema)` to create a new message.
 */
export const BigtableSourceSchema: GenMessage<BigtableSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 4);

/**
 * Cloud FhirStore source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.FhirStoreSource
 */
export type FhirStoreSource = Message<"google.cloud.discoveryengine.v1alpha.FhirStoreSource"> & {
  /**
   * Required. The full resource name of the FHIR store to import data from, in
   * the format of
   * `projects/{project}/locations/{location}/datasets/{dataset}/fhirStores/{fhir_store}`.
   *
   * @generated from field: string fhir_store = 1;
   */
  fhirStore: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * FhirStore export to a specific Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 2;
   */
  gcsStagingDir: string;

  /**
   * The FHIR resource types to import. The resource types should be a subset of
   * all [supported FHIR resource
   * types](https://cloud.google.com/generative-ai-app-builder/docs/fhir-schema-reference#resource-level-specification).
   * Default to all supported FHIR resource types if empty.
   *
   * @generated from field: repeated string resource_types = 3;
   */
  resourceTypes: string[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.FhirStoreSource.
 * Use `create(FhirStoreSourceSchema)` to create a new message.
 */
export const FhirStoreSourceSchema: GenMessage<FhirStoreSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 5);

/**
 * Cloud SQL source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.CloudSqlSource
 */
export type CloudSqlSource = Message<"google.cloud.discoveryengine.v1alpha.CloudSqlSource"> & {
  /**
   * The project ID that contains the Cloud SQL source. Has a length limit of
   * 128 characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The Cloud SQL instance to copy the data from with a length limit
   * of 256 characters.
   *
   * @generated from field: string instance_id = 2;
   */
  instanceId: string;

  /**
   * Required. The Cloud SQL database to copy the data from with a length limit
   * of 256 characters.
   *
   * @generated from field: string database_id = 3;
   */
  databaseId: string;

  /**
   * Required. The Cloud SQL table to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string table_id = 4;
   */
  tableId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * Cloud SQL export to a specific Cloud Storage directory.
   *
   * Ensure that the Cloud SQL service account has the necessary Cloud
   * Storage Admin permissions to access the specified Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 5;
   */
  gcsStagingDir: string;

  /**
   * Option for serverless export. Enabling this option will incur additional
   * cost. More info can be found
   * [here](https://cloud.google.com/sql/pricing#serverless).
   *
   * @generated from field: bool offload = 6;
   */
  offload: boolean;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.CloudSqlSource.
 * Use `create(CloudSqlSourceSchema)` to create a new message.
 */
export const CloudSqlSourceSchema: GenMessage<CloudSqlSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 6);

/**
 * AlloyDB source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.AlloyDbSource
 */
export type AlloyDbSource = Message<"google.cloud.discoveryengine.v1alpha.AlloyDbSource"> & {
  /**
   * The project ID that contains the AlloyDB source.
   * Has a length limit of 128 characters. If not specified, inherits the
   * project ID from the parent request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The AlloyDB location to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string location_id = 2;
   */
  locationId: string;

  /**
   * Required. The AlloyDB cluster to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string cluster_id = 3;
   */
  clusterId: string;

  /**
   * Required. The AlloyDB database to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string database_id = 4;
   */
  databaseId: string;

  /**
   * Required. The AlloyDB table to copy the data from with a length limit of
   * 256 characters.
   *
   * @generated from field: string table_id = 5;
   */
  tableId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * AlloyDB export to a specific Cloud Storage directory.
   *
   * Ensure that the AlloyDB service account has the necessary Cloud
   * Storage Admin permissions to access the specified Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 6;
   */
  gcsStagingDir: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.AlloyDbSource.
 * Use `create(AlloyDbSourceSchema)` to create a new message.
 */
export const AlloyDbSourceSchema: GenMessage<AlloyDbSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 7);

/**
 * Firestore source import data from.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.FirestoreSource
 */
export type FirestoreSource = Message<"google.cloud.discoveryengine.v1alpha.FirestoreSource"> & {
  /**
   * The project ID that the Cloud SQL source is in with a length limit of 128
   * characters. If not specified, inherits the project ID from the parent
   * request.
   *
   * @generated from field: string project_id = 1;
   */
  projectId: string;

  /**
   * Required. The Firestore database to copy the data from with a length limit
   * of 256 characters.
   *
   * @generated from field: string database_id = 2;
   */
  databaseId: string;

  /**
   * Required. The Firestore collection (or entity) to copy the data from with a
   * length limit of 1,500 characters.
   *
   * @generated from field: string collection_id = 3;
   */
  collectionId: string;

  /**
   * Intermediate Cloud Storage directory used for the import with a length
   * limit of 2,000 characters. Can be specified if one wants to have the
   * Firestore export to a specific Cloud Storage directory.
   *
   * Ensure that the Firestore service account has the necessary Cloud
   * Storage Admin permissions to access the specified Cloud Storage directory.
   *
   * @generated from field: string gcs_staging_dir = 4;
   */
  gcsStagingDir: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.FirestoreSource.
 * Use `create(FirestoreSourceSchema)` to create a new message.
 */
export const FirestoreSourceSchema: GenMessage<FirestoreSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 8);

/**
 * Configuration of destination for Import related errors.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportErrorConfig
 */
export type ImportErrorConfig = Message<"google.cloud.discoveryengine.v1alpha.ImportErrorConfig"> & {
  /**
   * Required. Errors destination.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.ImportErrorConfig.destination
   */
  destination: {
    /**
     * Cloud Storage prefix for import errors. This must be an empty,
     * existing Cloud Storage directory. Import errors are written to
     * sharded files in this directory, one per line, as a JSON-encoded
     * `google.rpc.Status` message.
     *
     * @generated from field: string gcs_prefix = 1;
     */
    value: string;
    case: "gcsPrefix";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportErrorConfig.
 * Use `create(ImportErrorConfigSchema)` to create a new message.
 */
export const ImportErrorConfigSchema: GenMessage<ImportErrorConfig> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 9);

/**
 * Request message for the ImportUserEvents request.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest
 */
export type ImportUserEventsRequest = Message<"google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest"> & {
  /**
   * Required - The desired input source of the user event data.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest.source
   */
  source: {
    /**
     * The Inline source for the input content for UserEvents.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest.InlineSource inline_source = 2;
     */
    value: ImportUserEventsRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. Parent DataStore resource name, of the form
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import. Cannot be set
   * for inline user event imports.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest.
 * Use `create(ImportUserEventsRequestSchema)` to create a new message.
 */
export const ImportUserEventsRequestSchema: GenMessage<ImportUserEventsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 10);

/**
 * The inline source for the input config for ImportUserEvents method.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest.InlineSource
 */
export type ImportUserEventsRequest_InlineSource = Message<"google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest.InlineSource"> & {
  /**
   * Required. A list of user events to import. Recommended max of 10k items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1alpha.UserEvent user_events = 1;
   */
  userEvents: UserEvent[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportUserEventsRequest.InlineSource.
 * Use `create(ImportUserEventsRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportUserEventsRequest_InlineSourceSchema: GenMessage<ImportUserEventsRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 10, 0);

/**
 * Response of the ImportUserEventsRequest. If the long running
 * operation was successful, then this message is returned by the
 * google.longrunning.Operations.response field if the operation was successful.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportUserEventsResponse
 */
export type ImportUserEventsResponse = Message<"google.cloud.discoveryengine.v1alpha.ImportUserEventsResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * Echoes the destination for the complete errors if this field was set in
   * the request.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;

  /**
   * Count of user events imported with complete existing Documents.
   *
   * @generated from field: int64 joined_events_count = 3;
   */
  joinedEventsCount: bigint;

  /**
   * Count of user events imported, but with Document information not found
   * in the existing Branch.
   *
   * @generated from field: int64 unjoined_events_count = 4;
   */
  unjoinedEventsCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportUserEventsResponse.
 * Use `create(ImportUserEventsResponseSchema)` to create a new message.
 */
export const ImportUserEventsResponseSchema: GenMessage<ImportUserEventsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 11);

/**
 * Metadata related to the progress of the Import operation. This is
 * returned by the google.longrunning.Operation.metadata field.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportUserEventsMetadata
 */
export type ImportUserEventsMetadata = Message<"google.cloud.discoveryengine.v1alpha.ImportUserEventsMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of entries that were processed successfully.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of entries that encountered errors while processing.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportUserEventsMetadata.
 * Use `create(ImportUserEventsMetadataSchema)` to create a new message.
 */
export const ImportUserEventsMetadataSchema: GenMessage<ImportUserEventsMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 12);

/**
 * Metadata related to the progress of the ImportDocuments operation. This is
 * returned by the google.longrunning.Operation.metadata field.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportDocumentsMetadata
 */
export type ImportDocumentsMetadata = Message<"google.cloud.discoveryengine.v1alpha.ImportDocumentsMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of entries that were processed successfully.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of entries that encountered errors while processing.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;

  /**
   * Total count of entries that were processed.
   *
   * @generated from field: int64 total_count = 5;
   */
  totalCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportDocumentsMetadata.
 * Use `create(ImportDocumentsMetadataSchema)` to create a new message.
 */
export const ImportDocumentsMetadataSchema: GenMessage<ImportDocumentsMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 13);

/**
 * Request message for Import methods.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest
 */
export type ImportDocumentsRequest = Message<"google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest"> & {
  /**
   * Required. The source of the input.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.source
   */
  source: {
    /**
     * The Inline source for the input content for documents.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.InlineSource inline_source = 2;
     */
    value: ImportDocumentsRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | {
    /**
     * FhirStore input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.FhirStoreSource fhir_store_source = 10;
     */
    value: FhirStoreSource;
    case: "fhirStoreSource";
  } | {
    /**
     * Spanner input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.SpannerSource spanner_source = 11;
     */
    value: SpannerSource;
    case: "spannerSource";
  } | {
    /**
     * Cloud SQL input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.CloudSqlSource cloud_sql_source = 12;
     */
    value: CloudSqlSource;
    case: "cloudSqlSource";
  } | {
    /**
     * Firestore input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.FirestoreSource firestore_source = 13;
     */
    value: FirestoreSource;
    case: "firestoreSource";
  } | {
    /**
     * AlloyDB input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.AlloyDbSource alloy_db_source = 14;
     */
    value: AlloyDbSource;
    case: "alloyDbSource";
  } | {
    /**
     * Cloud Bigtable input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.BigtableSource bigtable_source = 15;
     */
    value: BigtableSource;
    case: "bigtableSource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent branch resource name, such as
   * `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/branches/{branch}`.
   * Requires create/update permission.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;

  /**
   * The mode of reconciliation between existing documents and the documents to
   * be imported. Defaults to
   * [ReconciliationMode.INCREMENTAL][google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL].
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.ReconciliationMode reconciliation_mode = 6;
   */
  reconciliationMode: ImportDocumentsRequest_ReconciliationMode;

  /**
   * Indicates which fields in the provided imported documents to update. If
   * not set, the default is to update all fields.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 7;
   */
  updateMask?: FieldMask;

  /**
   * Whether to automatically generate IDs for the documents if absent.
   *
   * If set to `true`,
   * [Document.id][google.cloud.discoveryengine.v1alpha.Document.id]s are
   * automatically generated based on the hash of the payload, where IDs may not
   * be consistent during multiple imports. In which case
   * [ReconciliationMode.FULL][google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.ReconciliationMode.FULL]
   * is highly recommended to avoid duplicate contents. If unset or set to
   * `false`, [Document.id][google.cloud.discoveryengine.v1alpha.Document.id]s
   * have to be specified using
   * [id_field][google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.id_field],
   * otherwise, documents without IDs fail to be imported.
   *
   * Supported data sources:
   *
   * * [GcsSource][google.cloud.discoveryengine.v1alpha.GcsSource].
   * [GcsSource.data_schema][google.cloud.discoveryengine.v1alpha.GcsSource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [BigQuerySource][google.cloud.discoveryengine.v1alpha.BigQuerySource].
   * [BigQuerySource.data_schema][google.cloud.discoveryengine.v1alpha.BigQuerySource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [SpannerSource][google.cloud.discoveryengine.v1alpha.SpannerSource].
   * * [CloudSqlSource][google.cloud.discoveryengine.v1alpha.CloudSqlSource].
   * * [FirestoreSource][google.cloud.discoveryengine.v1alpha.FirestoreSource].
   * * [BigtableSource][google.cloud.discoveryengine.v1alpha.BigtableSource].
   *
   * @generated from field: bool auto_generate_ids = 8;
   */
  autoGenerateIds: boolean;

  /**
   * The field indicates the ID field or column to be used as unique IDs of
   * the documents.
   *
   * For [GcsSource][google.cloud.discoveryengine.v1alpha.GcsSource] it is the
   * key of the JSON field. For instance, `my_id` for JSON `{"my_id":
   * "some_uuid"}`. For others, it may be the column name of the table where the
   * unique ids are stored.
   *
   * The values of the JSON field or the table column are used as the
   * [Document.id][google.cloud.discoveryengine.v1alpha.Document.id]s. The JSON
   * field or the table column must be of string type, and the values must be
   * set as valid strings conform to
   * [RFC-1034](https://tools.ietf.org/html/rfc1034) with 1-63 characters.
   * Otherwise, documents without valid IDs fail to be imported.
   *
   * Only set this field when
   * [auto_generate_ids][google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.auto_generate_ids]
   * is unset or set as `false`. Otherwise, an INVALID_ARGUMENT error is thrown.
   *
   * If it is unset, a default value `_id` is used when importing from the
   * allowed data sources.
   *
   * Supported data sources:
   *
   * * [GcsSource][google.cloud.discoveryengine.v1alpha.GcsSource].
   * [GcsSource.data_schema][google.cloud.discoveryengine.v1alpha.GcsSource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [BigQuerySource][google.cloud.discoveryengine.v1alpha.BigQuerySource].
   * [BigQuerySource.data_schema][google.cloud.discoveryengine.v1alpha.BigQuerySource.data_schema]
   * must be `custom` or `csv`. Otherwise, an INVALID_ARGUMENT error is thrown.
   * * [SpannerSource][google.cloud.discoveryengine.v1alpha.SpannerSource].
   * * [CloudSqlSource][google.cloud.discoveryengine.v1alpha.CloudSqlSource].
   * * [FirestoreSource][google.cloud.discoveryengine.v1alpha.FirestoreSource].
   * * [BigtableSource][google.cloud.discoveryengine.v1alpha.BigtableSource].
   *
   * @generated from field: string id_field = 9;
   */
  idField: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.
 * Use `create(ImportDocumentsRequestSchema)` to create a new message.
 */
export const ImportDocumentsRequestSchema: GenMessage<ImportDocumentsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 14);

/**
 * The inline source for the input config for ImportDocuments method.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.InlineSource
 */
export type ImportDocumentsRequest_InlineSource = Message<"google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.InlineSource"> & {
  /**
   * Required. A list of documents to update/create. Each document must have a
   * valid [Document.id][google.cloud.discoveryengine.v1alpha.Document.id].
   * Recommended max of 100 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1alpha.Document documents = 1;
   */
  documents: Document[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.InlineSource.
 * Use `create(ImportDocumentsRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportDocumentsRequest_InlineSourceSchema: GenMessage<ImportDocumentsRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 14, 0);

/**
 * Indicates how imported documents are reconciled with the existing documents
 * created or imported before.
 *
 * @generated from enum google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.ReconciliationMode
 */
export enum ImportDocumentsRequest_ReconciliationMode {
  /**
   * Defaults to `INCREMENTAL`.
   *
   * @generated from enum value: RECONCILIATION_MODE_UNSPECIFIED = 0;
   */
  RECONCILIATION_MODE_UNSPECIFIED = 0,

  /**
   * Inserts new documents or updates existing documents.
   *
   * @generated from enum value: INCREMENTAL = 1;
   */
  INCREMENTAL = 1,

  /**
   * Calculates diff and replaces the entire document dataset. Existing
   * documents may be deleted if they are not present in the source location.
   *
   * @generated from enum value: FULL = 2;
   */
  FULL = 2,
}

/**
 * Describes the enum google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest.ReconciliationMode.
 */
export const ImportDocumentsRequest_ReconciliationModeSchema: GenEnum<ImportDocumentsRequest_ReconciliationMode> = /*@__PURE__*/
  enumDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 14, 0);

/**
 * Response of the
 * [ImportDocumentsRequest][google.cloud.discoveryengine.v1alpha.ImportDocumentsRequest].
 * If the long running operation is done, then this message is returned by the
 * google.longrunning.Operations.response field if the operation was successful.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportDocumentsResponse
 */
export type ImportDocumentsResponse = Message<"google.cloud.discoveryengine.v1alpha.ImportDocumentsResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * Echoes the destination for the complete errors in the request if set.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportDocumentsResponse.
 * Use `create(ImportDocumentsResponseSchema)` to create a new message.
 */
export const ImportDocumentsResponseSchema: GenMessage<ImportDocumentsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 15);

/**
 * Request message for
 * [CompletionService.ImportSuggestionDenyListEntries][google.cloud.discoveryengine.v1alpha.CompletionService.ImportSuggestionDenyListEntries]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest
 */
export type ImportSuggestionDenyListEntriesRequest = Message<"google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest"> & {
  /**
   * The source of the updated SuggestionDenyList.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest.source
   */
  source: {
    /**
     * The Inline source for the input content for suggestion deny list entries.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest.InlineSource inline_source = 2;
     */
    value: ImportSuggestionDenyListEntriesRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * Only 1 file can be specified that contains all entries to import.
     * Supported values `gcs_source.schema` for autocomplete suggestion deny
     * list entry imports:
     *
     * * `suggestion_deny_list` (default): One JSON [SuggestionDenyListEntry]
     * per line.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent data store resource name for which to import denylist
   * entries. Follows pattern projects/*\/locations/*\/collections/*\/dataStores/*.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest.
 * Use `create(ImportSuggestionDenyListEntriesRequestSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesRequestSchema: GenMessage<ImportSuggestionDenyListEntriesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 16);

/**
 * The inline source for SuggestionDenyListEntry.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest.InlineSource
 */
export type ImportSuggestionDenyListEntriesRequest_InlineSource = Message<"google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest.InlineSource"> & {
  /**
   * Required. A list of all denylist entries to import. Max of 1000 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1alpha.SuggestionDenyListEntry entries = 1;
   */
  entries: SuggestionDenyListEntry[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesRequest.InlineSource.
 * Use `create(ImportSuggestionDenyListEntriesRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesRequest_InlineSourceSchema: GenMessage<ImportSuggestionDenyListEntriesRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 16, 0);

/**
 * Response message for
 * [CompletionService.ImportSuggestionDenyListEntries][google.cloud.discoveryengine.v1alpha.CompletionService.ImportSuggestionDenyListEntries]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesResponse
 */
export type ImportSuggestionDenyListEntriesResponse = Message<"google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * Count of deny list entries successfully imported.
   *
   * @generated from field: int64 imported_entries_count = 2;
   */
  importedEntriesCount: bigint;

  /**
   * Count of deny list entries that failed to be imported.
   *
   * @generated from field: int64 failed_entries_count = 3;
   */
  failedEntriesCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesResponse.
 * Use `create(ImportSuggestionDenyListEntriesResponseSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesResponseSchema: GenMessage<ImportSuggestionDenyListEntriesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 17);

/**
 * Metadata related to the progress of the ImportSuggestionDenyListEntries
 * operation. This is returned by the google.longrunning.Operation.metadata
 * field.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesMetadata
 */
export type ImportSuggestionDenyListEntriesMetadata = Message<"google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSuggestionDenyListEntriesMetadata.
 * Use `create(ImportSuggestionDenyListEntriesMetadataSchema)` to create a new message.
 */
export const ImportSuggestionDenyListEntriesMetadataSchema: GenMessage<ImportSuggestionDenyListEntriesMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 18);

/**
 * Request message for
 * [CompletionService.ImportCompletionSuggestions][google.cloud.discoveryengine.v1alpha.CompletionService.ImportCompletionSuggestions]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest
 */
export type ImportCompletionSuggestionsRequest = Message<"google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest"> & {
  /**
   * The source of the autocomplete suggestions.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest.source
   */
  source: {
    /**
     * The Inline source for suggestion entries.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest.InlineSource inline_source = 2;
     */
    value: ImportCompletionSuggestionsRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent data store resource name for which to import customer
   * autocomplete suggestions.
   *
   * Follows pattern `projects/*\/locations/*\/collections/*\/dataStores/*`
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest.
 * Use `create(ImportCompletionSuggestionsRequestSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsRequestSchema: GenMessage<ImportCompletionSuggestionsRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 19);

/**
 * The inline source for CompletionSuggestions.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest.InlineSource
 */
export type ImportCompletionSuggestionsRequest_InlineSource = Message<"google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest.InlineSource"> & {
  /**
   * Required. A list of all denylist entries to import. Max of 1000 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1alpha.CompletionSuggestion suggestions = 1;
   */
  suggestions: CompletionSuggestion[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsRequest.InlineSource.
 * Use `create(ImportCompletionSuggestionsRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsRequest_InlineSourceSchema: GenMessage<ImportCompletionSuggestionsRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 19, 0);

/**
 * Response of the
 * [CompletionService.ImportCompletionSuggestions][google.cloud.discoveryengine.v1alpha.CompletionService.ImportCompletionSuggestions]
 * method. If the long running operation is done, this message is returned by
 * the google.longrunning.Operations.response field if the operation is
 * successful.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsResponse
 */
export type ImportCompletionSuggestionsResponse = Message<"google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsResponse.
 * Use `create(ImportCompletionSuggestionsResponseSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsResponseSchema: GenMessage<ImportCompletionSuggestionsResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 20);

/**
 * Metadata related to the progress of the ImportCompletionSuggestions
 * operation. This will be returned by the google.longrunning.Operation.metadata
 * field.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsMetadata
 */
export type ImportCompletionSuggestionsMetadata = Message<"google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsMetadata"> & {
  /**
   * Operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * Operation last update time. If the operation is done, this is also the
   * finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of
   * [CompletionSuggestion][google.cloud.discoveryengine.v1alpha.CompletionSuggestion]s
   * successfully imported.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of
   * [CompletionSuggestion][google.cloud.discoveryengine.v1alpha.CompletionSuggestion]s
   * that failed to be imported.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportCompletionSuggestionsMetadata.
 * Use `create(ImportCompletionSuggestionsMetadataSchema)` to create a new message.
 */
export const ImportCompletionSuggestionsMetadataSchema: GenMessage<ImportCompletionSuggestionsMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 21);

/**
 * Request message for
 * [SampleQueryService.ImportSampleQueries][google.cloud.discoveryengine.v1alpha.SampleQueryService.ImportSampleQueries]
 * method.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest
 */
export type ImportSampleQueriesRequest = Message<"google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest"> & {
  /**
   * The source of the sample queries.
   *
   * @generated from oneof google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest.source
   */
  source: {
    /**
     * The Inline source for sample query entries.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest.InlineSource inline_source = 2;
     */
    value: ImportSampleQueriesRequest_InlineSource;
    case: "inlineSource";
  } | {
    /**
     * Cloud Storage location for the input content.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.GcsSource gcs_source = 3;
     */
    value: GcsSource;
    case: "gcsSource";
  } | {
    /**
     * BigQuery input source.
     *
     * @generated from field: google.cloud.discoveryengine.v1alpha.BigQuerySource bigquery_source = 4;
     */
    value: BigQuerySource;
    case: "bigquerySource";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The parent sample query set resource name, such as
   * `projects/{project}/locations/{location}/sampleQuerySets/{sampleQuerySet}`.
   *
   * If the caller does not have permission to list
   * [SampleQuery][google.cloud.discoveryengine.v1alpha.SampleQuery]s under this
   * sample query set, regardless of whether or not this sample query set
   * exists, a `PERMISSION_DENIED` error is returned.
   *
   * @generated from field: string parent = 1;
   */
  parent: string;

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 5;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest.
 * Use `create(ImportSampleQueriesRequestSchema)` to create a new message.
 */
export const ImportSampleQueriesRequestSchema: GenMessage<ImportSampleQueriesRequest> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 22);

/**
 * The inline source for
 * [SampleQuery][google.cloud.discoveryengine.v1alpha.SampleQuery]s.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest.InlineSource
 */
export type ImportSampleQueriesRequest_InlineSource = Message<"google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest.InlineSource"> & {
  /**
   * Required. A list of
   * [SampleQuery][google.cloud.discoveryengine.v1alpha.SampleQuery]s to
   * import. Max of 1000 items.
   *
   * @generated from field: repeated google.cloud.discoveryengine.v1alpha.SampleQuery sample_queries = 1;
   */
  sampleQueries: SampleQuery[];
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesRequest.InlineSource.
 * Use `create(ImportSampleQueriesRequest_InlineSourceSchema)` to create a new message.
 */
export const ImportSampleQueriesRequest_InlineSourceSchema: GenMessage<ImportSampleQueriesRequest_InlineSource> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 22, 0);

/**
 * Response of the
 * [SampleQueryService.ImportSampleQueries][google.cloud.discoveryengine.v1alpha.SampleQueryService.ImportSampleQueries]
 * method. If the long running operation is done, this message is returned by
 * the google.longrunning.Operations.response field if the operation is
 * successful.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesResponse
 */
export type ImportSampleQueriesResponse = Message<"google.cloud.discoveryengine.v1alpha.ImportSampleQueriesResponse"> & {
  /**
   * A sample of errors encountered while processing the request.
   *
   * @generated from field: repeated google.rpc.Status error_samples = 1;
   */
  errorSamples: Status[];

  /**
   * The desired location of errors incurred during the Import.
   *
   * @generated from field: google.cloud.discoveryengine.v1alpha.ImportErrorConfig error_config = 2;
   */
  errorConfig?: ImportErrorConfig;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesResponse.
 * Use `create(ImportSampleQueriesResponseSchema)` to create a new message.
 */
export const ImportSampleQueriesResponseSchema: GenMessage<ImportSampleQueriesResponse> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 23);

/**
 * Metadata related to the progress of the ImportSampleQueries
 * operation. This will be returned by the google.longrunning.Operation.metadata
 * field.
 *
 * @generated from message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesMetadata
 */
export type ImportSampleQueriesMetadata = Message<"google.cloud.discoveryengine.v1alpha.ImportSampleQueriesMetadata"> & {
  /**
   * ImportSampleQueries operation create time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * ImportSampleQueries operation last update time. If the operation is done,
   * this is also the finish time.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * Count of [SampleQuery][google.cloud.discoveryengine.v1alpha.SampleQuery]s
   * successfully imported.
   *
   * @generated from field: int64 success_count = 3;
   */
  successCount: bigint;

  /**
   * Count of [SampleQuery][google.cloud.discoveryengine.v1alpha.SampleQuery]s
   * that failed to be imported.
   *
   * @generated from field: int64 failure_count = 4;
   */
  failureCount: bigint;

  /**
   * Total count of
   * [SampleQuery][google.cloud.discoveryengine.v1alpha.SampleQuery]s that were
   * processed.
   *
   * @generated from field: int64 total_count = 5;
   */
  totalCount: bigint;
};

/**
 * Describes the message google.cloud.discoveryengine.v1alpha.ImportSampleQueriesMetadata.
 * Use `create(ImportSampleQueriesMetadataSchema)` to create a new message.
 */
export const ImportSampleQueriesMetadataSchema: GenMessage<ImportSampleQueriesMetadata> = /*@__PURE__*/
  messageDesc(file_google_cloud_discoveryengine_v1alpha_import_config, 24);

