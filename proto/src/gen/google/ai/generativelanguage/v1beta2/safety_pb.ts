// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/ai/generativelanguage/v1beta2/safety.proto (package google.ai.generativelanguage.v1beta2, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/ai/generativelanguage/v1beta2/safety.proto.
 */
export const file_google_ai_generativelanguage_v1beta2_safety: GenFile = /*@__PURE__*/
  fileDesc("CjFnb29nbGUvYWkvZ2VuZXJhdGl2ZWxhbmd1YWdlL3YxYmV0YTIvc2FmZXR5LnByb3RvEiRnb29nbGUuYWkuZ2VuZXJhdGl2ZWxhbmd1YWdlLnYxYmV0YTIizAEKDUNvbnRlbnRGaWx0ZXISUQoGcmVhc29uGAEgASgOMkEuZ29vZ2xlLmFpLmdlbmVyYXRpdmVsYW5ndWFnZS52MWJldGEyLkNvbnRlbnRGaWx0ZXIuQmxvY2tlZFJlYXNvbhIUCgdtZXNzYWdlGAIgASgJSACIAQEiRgoNQmxvY2tlZFJlYXNvbhIeChpCTE9DS0VEX1JFQVNPTl9VTlNQRUNJRklFRBAAEgoKBlNBRkVUWRABEgkKBU9USEVSEAJCCgoIX21lc3NhZ2UimgEKDlNhZmV0eUZlZWRiYWNrEkIKBnJhdGluZxgBIAEoCzIyLmdvb2dsZS5haS5nZW5lcmF0aXZlbGFuZ3VhZ2UudjFiZXRhMi5TYWZldHlSYXRpbmcSRAoHc2V0dGluZxgCIAEoCzIzLmdvb2dsZS5haS5nZW5lcmF0aXZlbGFuZ3VhZ2UudjFiZXRhMi5TYWZldHlTZXR0aW5nIpsCCgxTYWZldHlSYXRpbmcSSQoIY2F0ZWdvcnkYAyABKA4yMi5nb29nbGUuYWkuZ2VuZXJhdGl2ZWxhbmd1YWdlLnYxYmV0YTIuSGFybUNhdGVnb3J5QgPgQQISXAoLcHJvYmFiaWxpdHkYBCABKA4yQi5nb29nbGUuYWkuZ2VuZXJhdGl2ZWxhbmd1YWdlLnYxYmV0YTIuU2FmZXR5UmF0aW5nLkhhcm1Qcm9iYWJpbGl0eUID4EECImIKD0hhcm1Qcm9iYWJpbGl0eRIgChxIQVJNX1BST0JBQklMSVRZX1VOU1BFQ0lGSUVEEAASDgoKTkVHTElHSUJMRRABEgcKA0xPVxACEgoKBk1FRElVTRADEggKBEhJR0gQBCLBAgoNU2FmZXR5U2V0dGluZxJJCghjYXRlZ29yeRgDIAEoDjIyLmdvb2dsZS5haS5nZW5lcmF0aXZlbGFuZ3VhZ2UudjFiZXRhMi5IYXJtQ2F0ZWdvcnlCA+BBAhJeCgl0aHJlc2hvbGQYBCABKA4yRi5nb29nbGUuYWkuZ2VuZXJhdGl2ZWxhbmd1YWdlLnYxYmV0YTIuU2FmZXR5U2V0dGluZy5IYXJtQmxvY2tUaHJlc2hvbGRCA+BBAiKEAQoSSGFybUJsb2NrVGhyZXNob2xkEiQKIEhBUk1fQkxPQ0tfVEhSRVNIT0xEX1VOU1BFQ0lGSUVEEAASFwoTQkxPQ0tfTE9XX0FORF9BQk9WRRABEhoKFkJMT0NLX01FRElVTV9BTkRfQUJPVkUQAhITCg9CTE9DS19PTkxZX0hJR0gQAyrVAQoMSGFybUNhdGVnb3J5Eh0KGUhBUk1fQ0FURUdPUllfVU5TUEVDSUZJRUQQABIcChhIQVJNX0NBVEVHT1JZX0RFUk9HQVRPUlkQARIaChZIQVJNX0NBVEVHT1JZX1RPWElDSVRZEAISGgoWSEFSTV9DQVRFR09SWV9WSU9MRU5DRRADEhgKFEhBUk1fQ0FURUdPUllfU0VYVUFMEAQSGQoVSEFSTV9DQVRFR09SWV9NRURJQ0FMEAUSGwoXSEFSTV9DQVRFR09SWV9EQU5HRVJPVVMQBkKZAQooY29tLmdvb2dsZS5haS5nZW5lcmF0aXZlbGFuZ3VhZ2UudjFiZXRhMkILU2FmZXR5UHJvdG9QAVpeY2xvdWQuZ29vZ2xlLmNvbS9nby9haS9nZW5lcmF0aXZlbGFuZ3VhZ2UvYXBpdjFiZXRhMi9nZW5lcmF0aXZlbGFuZ3VhZ2VwYjtnZW5lcmF0aXZlbGFuZ3VhZ2VwYmIGcHJvdG8z", [file_google_api_field_behavior]);

/**
 * Content filtering metadata associated with processing a single request.
 *
 * ContentFilter contains a reason and an optional supporting string. The reason
 * may be unspecified.
 *
 * @generated from message google.ai.generativelanguage.v1beta2.ContentFilter
 */
export type ContentFilter = Message<"google.ai.generativelanguage.v1beta2.ContentFilter"> & {
  /**
   * The reason content was blocked during request processing.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.ContentFilter.BlockedReason reason = 1;
   */
  reason: ContentFilter_BlockedReason;

  /**
   * A string that describes the filtering behavior in more detail.
   *
   * @generated from field: optional string message = 2;
   */
  message?: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta2.ContentFilter.
 * Use `create(ContentFilterSchema)` to create a new message.
 */
export const ContentFilterSchema: GenMessage<ContentFilter> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta2_safety, 0);

/**
 * A list of reasons why content may have been blocked.
 *
 * @generated from enum google.ai.generativelanguage.v1beta2.ContentFilter.BlockedReason
 */
export enum ContentFilter_BlockedReason {
  /**
   * A blocked reason was not specified.
   *
   * @generated from enum value: BLOCKED_REASON_UNSPECIFIED = 0;
   */
  BLOCKED_REASON_UNSPECIFIED = 0,

  /**
   * Content was blocked by safety settings.
   *
   * @generated from enum value: SAFETY = 1;
   */
  SAFETY = 1,

  /**
   * Content was blocked, but the reason is uncategorized.
   *
   * @generated from enum value: OTHER = 2;
   */
  OTHER = 2,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta2.ContentFilter.BlockedReason.
 */
export const ContentFilter_BlockedReasonSchema: GenEnum<ContentFilter_BlockedReason> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta2_safety, 0, 0);

/**
 * Safety feedback for an entire request.
 *
 * This field is populated if content in the input and/or response is blocked
 * due to safety settings. SafetyFeedback may not exist for every HarmCategory.
 * Each SafetyFeedback will return the safety settings used by the request as
 * well as the lowest HarmProbability that should be allowed in order to return
 * a result.
 *
 * @generated from message google.ai.generativelanguage.v1beta2.SafetyFeedback
 */
export type SafetyFeedback = Message<"google.ai.generativelanguage.v1beta2.SafetyFeedback"> & {
  /**
   * Safety rating evaluated from content.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.SafetyRating rating = 1;
   */
  rating?: SafetyRating;

  /**
   * Safety settings applied to the request.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.SafetySetting setting = 2;
   */
  setting?: SafetySetting;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta2.SafetyFeedback.
 * Use `create(SafetyFeedbackSchema)` to create a new message.
 */
export const SafetyFeedbackSchema: GenMessage<SafetyFeedback> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta2_safety, 1);

/**
 * Safety rating for a piece of content.
 *
 * The safety rating contains the category of harm and the
 * harm probability level in that category for a piece of content.
 * Content is classified for safety across a number of
 * harm categories and the probability of the harm classification is included
 * here.
 *
 * @generated from message google.ai.generativelanguage.v1beta2.SafetyRating
 */
export type SafetyRating = Message<"google.ai.generativelanguage.v1beta2.SafetyRating"> & {
  /**
   * Required. The category for this rating.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.HarmCategory category = 3;
   */
  category: HarmCategory;

  /**
   * Required. The probability of harm for this content.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.SafetyRating.HarmProbability probability = 4;
   */
  probability: SafetyRating_HarmProbability;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta2.SafetyRating.
 * Use `create(SafetyRatingSchema)` to create a new message.
 */
export const SafetyRatingSchema: GenMessage<SafetyRating> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta2_safety, 2);

/**
 * The probability that a piece of content is harmful.
 *
 * The classification system gives the probability of the content being
 * unsafe. This does not indicate the severity of harm for a piece of content.
 *
 * @generated from enum google.ai.generativelanguage.v1beta2.SafetyRating.HarmProbability
 */
export enum SafetyRating_HarmProbability {
  /**
   * Probability is unspecified.
   *
   * @generated from enum value: HARM_PROBABILITY_UNSPECIFIED = 0;
   */
  HARM_PROBABILITY_UNSPECIFIED = 0,

  /**
   * Content has a negligible chance of being unsafe.
   *
   * @generated from enum value: NEGLIGIBLE = 1;
   */
  NEGLIGIBLE = 1,

  /**
   * Content has a low chance of being unsafe.
   *
   * @generated from enum value: LOW = 2;
   */
  LOW = 2,

  /**
   * Content has a medium chance of being unsafe.
   *
   * @generated from enum value: MEDIUM = 3;
   */
  MEDIUM = 3,

  /**
   * Content has a high chance of being unsafe.
   *
   * @generated from enum value: HIGH = 4;
   */
  HIGH = 4,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta2.SafetyRating.HarmProbability.
 */
export const SafetyRating_HarmProbabilitySchema: GenEnum<SafetyRating_HarmProbability> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta2_safety, 2, 0);

/**
 * Safety setting, affecting the safety-blocking behavior.
 *
 * Passing a safety setting for a category changes the allowed proability that
 * content is blocked.
 *
 * @generated from message google.ai.generativelanguage.v1beta2.SafetySetting
 */
export type SafetySetting = Message<"google.ai.generativelanguage.v1beta2.SafetySetting"> & {
  /**
   * Required. The category for this setting.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.HarmCategory category = 3;
   */
  category: HarmCategory;

  /**
   * Required. Controls the probability threshold at which harm is blocked.
   *
   * @generated from field: google.ai.generativelanguage.v1beta2.SafetySetting.HarmBlockThreshold threshold = 4;
   */
  threshold: SafetySetting_HarmBlockThreshold;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta2.SafetySetting.
 * Use `create(SafetySettingSchema)` to create a new message.
 */
export const SafetySettingSchema: GenMessage<SafetySetting> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta2_safety, 3);

/**
 * Block at and beyond a specified harm probability.
 *
 * @generated from enum google.ai.generativelanguage.v1beta2.SafetySetting.HarmBlockThreshold
 */
export enum SafetySetting_HarmBlockThreshold {
  /**
   * Threshold is unspecified.
   *
   * @generated from enum value: HARM_BLOCK_THRESHOLD_UNSPECIFIED = 0;
   */
  HARM_BLOCK_THRESHOLD_UNSPECIFIED = 0,

  /**
   * Content with NEGLIGIBLE will be allowed.
   *
   * @generated from enum value: BLOCK_LOW_AND_ABOVE = 1;
   */
  BLOCK_LOW_AND_ABOVE = 1,

  /**
   * Content with NEGLIGIBLE and LOW will be allowed.
   *
   * @generated from enum value: BLOCK_MEDIUM_AND_ABOVE = 2;
   */
  BLOCK_MEDIUM_AND_ABOVE = 2,

  /**
   * Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
   *
   * @generated from enum value: BLOCK_ONLY_HIGH = 3;
   */
  BLOCK_ONLY_HIGH = 3,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta2.SafetySetting.HarmBlockThreshold.
 */
export const SafetySetting_HarmBlockThresholdSchema: GenEnum<SafetySetting_HarmBlockThreshold> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta2_safety, 3, 0);

/**
 * The category of a rating.
 *
 * These categories cover various kinds of harms that developers
 * may wish to adjust.
 *
 * @generated from enum google.ai.generativelanguage.v1beta2.HarmCategory
 */
export enum HarmCategory {
  /**
   * Category is unspecified.
   *
   * @generated from enum value: HARM_CATEGORY_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * Negative or harmful comments targeting identity and/or protected attribute.
   *
   * @generated from enum value: HARM_CATEGORY_DEROGATORY = 1;
   */
  DEROGATORY = 1,

  /**
   * Content that is rude, disrepspectful, or profane.
   *
   * @generated from enum value: HARM_CATEGORY_TOXICITY = 2;
   */
  TOXICITY = 2,

  /**
   * Describes scenarios depictng violence against an individual or group, or
   * general descriptions of gore.
   *
   * @generated from enum value: HARM_CATEGORY_VIOLENCE = 3;
   */
  VIOLENCE = 3,

  /**
   * Contains references to sexual acts or other lewd content.
   *
   * @generated from enum value: HARM_CATEGORY_SEXUAL = 4;
   */
  SEXUAL = 4,

  /**
   * Promotes unchecked medical advice.
   *
   * @generated from enum value: HARM_CATEGORY_MEDICAL = 5;
   */
  MEDICAL = 5,

  /**
   * Dangerous content that promotes, facilitates, or encourages harmful acts.
   *
   * @generated from enum value: HARM_CATEGORY_DANGEROUS = 6;
   */
  DANGEROUS = 6,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta2.HarmCategory.
 */
export const HarmCategorySchema: GenEnum<HarmCategory> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta2_safety, 0);

