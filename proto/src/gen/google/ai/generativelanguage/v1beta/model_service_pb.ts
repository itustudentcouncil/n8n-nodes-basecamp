// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/ai/generativelanguage/v1beta/model_service.proto (package google.ai.generativelanguage.v1beta, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv1";
import type { Model, ModelSchema } from "./model_pb";
import { file_google_ai_generativelanguage_v1beta_model } from "./model_pb";
import type { TunedModel, TunedModelSchema, TuningSnapshot } from "./tuned_model_pb";
import { file_google_ai_generativelanguage_v1beta_tuned_model } from "./tuned_model_pb";
import { file_google_api_annotations } from "../../../api/annotations_pb";
import { file_google_api_client } from "../../../api/client_pb";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { OperationSchema } from "../../../longrunning/operations_pb";
import { file_google_longrunning_operations } from "../../../longrunning/operations_pb";
import type { EmptySchema, FieldMask } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_empty, file_google_protobuf_field_mask } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/ai/generativelanguage/v1beta/model_service.proto.
 */
export const file_google_ai_generativelanguage_v1beta_model_service: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_ai_generativelanguage_v1beta_model, file_google_ai_generativelanguage_v1beta_tuned_model, file_google_api_annotations, file_google_api_client, file_google_api_field_behavior, file_google_api_resource, file_google_longrunning_operations, file_google_protobuf_empty, file_google_protobuf_field_mask]);

/**
 * Request for getting information about a specific Model.
 *
 * @generated from message google.ai.generativelanguage.v1beta.GetModelRequest
 */
export type GetModelRequest = Message<"google.ai.generativelanguage.v1beta.GetModelRequest"> & {
  /**
   * Required. The resource name of the model.
   *
   * This name should match a model name returned by the `ListModels` method.
   *
   * Format: `models/{model}`
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.GetModelRequest.
 * Use `create(GetModelRequestSchema)` to create a new message.
 */
export const GetModelRequestSchema: GenMessage<GetModelRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 0);

/**
 * Request for listing all Models.
 *
 * @generated from message google.ai.generativelanguage.v1beta.ListModelsRequest
 */
export type ListModelsRequest = Message<"google.ai.generativelanguage.v1beta.ListModelsRequest"> & {
  /**
   * The maximum number of `Models` to return (per page).
   *
   * If unspecified, 50 models will be returned per page.
   * This method returns at most 1000 models per page, even if you pass a larger
   * page_size.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize: number;

  /**
   * A page token, received from a previous `ListModels` call.
   *
   * Provide the `page_token` returned by one request as an argument to the next
   * request to retrieve the next page.
   *
   * When paginating, all other parameters provided to `ListModels` must match
   * the call that provided the page token.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.ListModelsRequest.
 * Use `create(ListModelsRequestSchema)` to create a new message.
 */
export const ListModelsRequestSchema: GenMessage<ListModelsRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 1);

/**
 * Response from `ListModel` containing a paginated list of Models.
 *
 * @generated from message google.ai.generativelanguage.v1beta.ListModelsResponse
 */
export type ListModelsResponse = Message<"google.ai.generativelanguage.v1beta.ListModelsResponse"> & {
  /**
   * The returned Models.
   *
   * @generated from field: repeated google.ai.generativelanguage.v1beta.Model models = 1;
   */
  models: Model[];

  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   *
   * If this field is omitted, there are no more pages.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.ListModelsResponse.
 * Use `create(ListModelsResponseSchema)` to create a new message.
 */
export const ListModelsResponseSchema: GenMessage<ListModelsResponse> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 2);

/**
 * Request for getting information about a specific Model.
 *
 * @generated from message google.ai.generativelanguage.v1beta.GetTunedModelRequest
 */
export type GetTunedModelRequest = Message<"google.ai.generativelanguage.v1beta.GetTunedModelRequest"> & {
  /**
   * Required. The resource name of the model.
   *
   * Format: `tunedModels/my-model-id`
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.GetTunedModelRequest.
 * Use `create(GetTunedModelRequestSchema)` to create a new message.
 */
export const GetTunedModelRequestSchema: GenMessage<GetTunedModelRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 3);

/**
 * Request for listing TunedModels.
 *
 * @generated from message google.ai.generativelanguage.v1beta.ListTunedModelsRequest
 */
export type ListTunedModelsRequest = Message<"google.ai.generativelanguage.v1beta.ListTunedModelsRequest"> & {
  /**
   * Optional. The maximum number of `TunedModels` to return (per page).
   * The service may return fewer tuned models.
   *
   * If unspecified, at most 10 tuned models will be returned.
   * This method returns at most 1000 models per page, even if you pass a larger
   * page_size.
   *
   * @generated from field: int32 page_size = 1;
   */
  pageSize: number;

  /**
   * Optional. A page token, received from a previous `ListTunedModels` call.
   *
   * Provide the `page_token` returned by one request as an argument to the next
   * request to retrieve the next page.
   *
   * When paginating, all other parameters provided to `ListTunedModels`
   * must match the call that provided the page token.
   *
   * @generated from field: string page_token = 2;
   */
  pageToken: string;

  /**
   * Optional. A filter is a full text search over the tuned model's description
   * and display name. By default, results will not include tuned models shared
   * with everyone.
   *
   * Additional operators:
   *   - owner:me
   *   - writers:me
   *   - readers:me
   *   - readers:everyone
   *
   * Examples:
   *   "owner:me" returns all tuned models to which caller has owner role
   *   "readers:me" returns all tuned models to which caller has reader role
   *   "readers:everyone" returns all tuned models that are shared with everyone
   *
   * @generated from field: string filter = 3;
   */
  filter: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.ListTunedModelsRequest.
 * Use `create(ListTunedModelsRequestSchema)` to create a new message.
 */
export const ListTunedModelsRequestSchema: GenMessage<ListTunedModelsRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 4);

/**
 * Response from `ListTunedModels` containing a paginated list of Models.
 *
 * @generated from message google.ai.generativelanguage.v1beta.ListTunedModelsResponse
 */
export type ListTunedModelsResponse = Message<"google.ai.generativelanguage.v1beta.ListTunedModelsResponse"> & {
  /**
   * The returned Models.
   *
   * @generated from field: repeated google.ai.generativelanguage.v1beta.TunedModel tuned_models = 1;
   */
  tunedModels: TunedModel[];

  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   *
   * If this field is omitted, there are no more pages.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.ListTunedModelsResponse.
 * Use `create(ListTunedModelsResponseSchema)` to create a new message.
 */
export const ListTunedModelsResponseSchema: GenMessage<ListTunedModelsResponse> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 5);

/**
 * Request to create a TunedModel.
 *
 * @generated from message google.ai.generativelanguage.v1beta.CreateTunedModelRequest
 */
export type CreateTunedModelRequest = Message<"google.ai.generativelanguage.v1beta.CreateTunedModelRequest"> & {
  /**
   * Optional. The unique id for the tuned model if specified.
   * This value should be up to 40 characters, the first character must be a
   * letter, the last could be a letter or a number. The id must match the
   * regular expression: `[a-z]([a-z0-9-]{0,38}[a-z0-9])?`.
   *
   * @generated from field: optional string tuned_model_id = 1;
   */
  tunedModelId?: string;

  /**
   * Required. The tuned model to create.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.TunedModel tuned_model = 2;
   */
  tunedModel?: TunedModel;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.CreateTunedModelRequest.
 * Use `create(CreateTunedModelRequestSchema)` to create a new message.
 */
export const CreateTunedModelRequestSchema: GenMessage<CreateTunedModelRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 6);

/**
 * Metadata about the state and progress of creating a tuned model returned from
 * the long-running operation
 *
 * @generated from message google.ai.generativelanguage.v1beta.CreateTunedModelMetadata
 */
export type CreateTunedModelMetadata = Message<"google.ai.generativelanguage.v1beta.CreateTunedModelMetadata"> & {
  /**
   * Name of the tuned model associated with the tuning operation.
   *
   * @generated from field: string tuned_model = 5;
   */
  tunedModel: string;

  /**
   * The total number of tuning steps.
   *
   * @generated from field: int32 total_steps = 1;
   */
  totalSteps: number;

  /**
   * The number of steps completed.
   *
   * @generated from field: int32 completed_steps = 2;
   */
  completedSteps: number;

  /**
   * The completed percentage for the tuning operation.
   *
   * @generated from field: float completed_percent = 3;
   */
  completedPercent: number;

  /**
   * Metrics collected during tuning.
   *
   * @generated from field: repeated google.ai.generativelanguage.v1beta.TuningSnapshot snapshots = 4;
   */
  snapshots: TuningSnapshot[];
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.CreateTunedModelMetadata.
 * Use `create(CreateTunedModelMetadataSchema)` to create a new message.
 */
export const CreateTunedModelMetadataSchema: GenMessage<CreateTunedModelMetadata> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 7);

/**
 * Request to update a TunedModel.
 *
 * @generated from message google.ai.generativelanguage.v1beta.UpdateTunedModelRequest
 */
export type UpdateTunedModelRequest = Message<"google.ai.generativelanguage.v1beta.UpdateTunedModelRequest"> & {
  /**
   * Required. The tuned model to update.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.TunedModel tuned_model = 1;
   */
  tunedModel?: TunedModel;

  /**
   * Required. The list of fields to update.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 2;
   */
  updateMask?: FieldMask;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.UpdateTunedModelRequest.
 * Use `create(UpdateTunedModelRequestSchema)` to create a new message.
 */
export const UpdateTunedModelRequestSchema: GenMessage<UpdateTunedModelRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 8);

/**
 * Request to delete a TunedModel.
 *
 * @generated from message google.ai.generativelanguage.v1beta.DeleteTunedModelRequest
 */
export type DeleteTunedModelRequest = Message<"google.ai.generativelanguage.v1beta.DeleteTunedModelRequest"> & {
  /**
   * Required. The resource name of the model.
   * Format: `tunedModels/my-model-id`
   *
   * @generated from field: string name = 1;
   */
  name: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.DeleteTunedModelRequest.
 * Use `create(DeleteTunedModelRequestSchema)` to create a new message.
 */
export const DeleteTunedModelRequestSchema: GenMessage<DeleteTunedModelRequest> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_model_service, 9);

/**
 * Provides methods for getting metadata information about Generative Models.
 *
 * @generated from service google.ai.generativelanguage.v1beta.ModelService
 */
export const ModelService: GenService<{
  /**
   * Gets information about a specific `Model` such as its version number, token
   * limits,
   * [parameters](https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters)
   * and other metadata. Refer to the [Gemini models
   * guide](https://ai.google.dev/gemini-api/docs/models/gemini) for detailed
   * model information.
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.GetModel
   */
  getModel: {
    methodKind: "unary";
    input: typeof GetModelRequestSchema;
    output: typeof ModelSchema;
  },
  /**
   * Lists the [`Model`s](https://ai.google.dev/gemini-api/docs/models/gemini)
   * available through the Gemini API.
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.ListModels
   */
  listModels: {
    methodKind: "unary";
    input: typeof ListModelsRequestSchema;
    output: typeof ListModelsResponseSchema;
  },
  /**
   * Gets information about a specific TunedModel.
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.GetTunedModel
   */
  getTunedModel: {
    methodKind: "unary";
    input: typeof GetTunedModelRequestSchema;
    output: typeof TunedModelSchema;
  },
  /**
   * Lists created tuned models.
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.ListTunedModels
   */
  listTunedModels: {
    methodKind: "unary";
    input: typeof ListTunedModelsRequestSchema;
    output: typeof ListTunedModelsResponseSchema;
  },
  /**
   * Creates a tuned model.
   * Check intermediate tuning progress (if any) through the
   * [google.longrunning.Operations] service.
   *
   * Access status and results through the Operations service.
   * Example:
   *   GET /v1/tunedModels/az2mb0bpw6i/operations/000-111-222
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.CreateTunedModel
   */
  createTunedModel: {
    methodKind: "unary";
    input: typeof CreateTunedModelRequestSchema;
    output: typeof OperationSchema;
  },
  /**
   * Updates a tuned model.
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.UpdateTunedModel
   */
  updateTunedModel: {
    methodKind: "unary";
    input: typeof UpdateTunedModelRequestSchema;
    output: typeof TunedModelSchema;
  },
  /**
   * Deletes a tuned model.
   *
   * @generated from rpc google.ai.generativelanguage.v1beta.ModelService.DeleteTunedModel
   */
  deleteTunedModel: {
    methodKind: "unary";
    input: typeof DeleteTunedModelRequestSchema;
    output: typeof EmptySchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_google_ai_generativelanguage_v1beta_model_service, 0);

