// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/ai/generativelanguage/v1beta/tuned_model.proto (package google.ai.generativelanguage.v1beta, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import { file_google_api_resource } from "../../../api/resource_pb";
import type { Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/ai/generativelanguage/v1beta/tuned_model.proto.
 */
export const file_google_ai_generativelanguage_v1beta_tuned_model: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior, file_google_api_resource, file_google_protobuf_timestamp]);

/**
 * A fine-tuned model created using ModelService.CreateTunedModel.
 *
 * @generated from message google.ai.generativelanguage.v1beta.TunedModel
 */
export type TunedModel = Message<"google.ai.generativelanguage.v1beta.TunedModel"> & {
  /**
   * The model used as the starting point for tuning.
   *
   * @generated from oneof google.ai.generativelanguage.v1beta.TunedModel.source_model
   */
  sourceModel: {
    /**
     * Optional. TunedModel to use as the starting point for training the new
     * model.
     *
     * @generated from field: google.ai.generativelanguage.v1beta.TunedModelSource tuned_model_source = 3;
     */
    value: TunedModelSource;
    case: "tunedModelSource";
  } | {
    /**
     * Immutable. The name of the `Model` to tune.
     * Example: `models/gemini-1.5-flash-001`
     *
     * @generated from field: string base_model = 4;
     */
    value: string;
    case: "baseModel";
  } | { case: undefined; value?: undefined };

  /**
   * Output only. The tuned model name. A unique name will be generated on
   * create. Example: `tunedModels/az2mb0bpw6i` If display_name is set on
   * create, the id portion of the name will be set by concatenating the words
   * of the display_name with hyphens and adding a random portion for
   * uniqueness.
   *
   * Example:
   *
   *  * display_name = `Sentence Translator`
   *  * name = `tunedModels/sentence-translator-u3b7m`
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Optional. The name to display for this model in user interfaces.
   * The display name must be up to 40 characters including spaces.
   *
   * @generated from field: string display_name = 5;
   */
  displayName: string;

  /**
   * Optional. A short description of this model.
   *
   * @generated from field: string description = 6;
   */
  description: string;

  /**
   * Optional. Controls the randomness of the output.
   *
   * Values can range over `[0.0,1.0]`, inclusive. A value closer to `1.0` will
   * produce responses that are more varied, while a value closer to `0.0` will
   * typically result in less surprising responses from the model.
   *
   * This value specifies default to be the one used by the base model while
   * creating the model.
   *
   * @generated from field: optional float temperature = 11;
   */
  temperature?: number;

  /**
   * Optional. For Nucleus sampling.
   *
   * Nucleus sampling considers the smallest set of tokens whose probability
   * sum is at least `top_p`.
   *
   * This value specifies default to be the one used by the base model while
   * creating the model.
   *
   * @generated from field: optional float top_p = 12;
   */
  topP?: number;

  /**
   * Optional. For Top-k sampling.
   *
   * Top-k sampling considers the set of `top_k` most probable tokens.
   * This value specifies default to be used by the backend while making the
   * call to the model.
   *
   * This value specifies default to be the one used by the base model while
   * creating the model.
   *
   * @generated from field: optional int32 top_k = 13;
   */
  topK?: number;

  /**
   * Output only. The state of the tuned model.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.TunedModel.State state = 7;
   */
  state: TunedModel_State;

  /**
   * Output only. The timestamp when this model was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 8;
   */
  createTime?: Timestamp;

  /**
   * Output only. The timestamp when this model was updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 9;
   */
  updateTime?: Timestamp;

  /**
   * Required. The tuning task that creates the tuned model.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.TuningTask tuning_task = 10;
   */
  tuningTask?: TuningTask;

  /**
   * Optional. List of project numbers that have read access to the tuned model.
   *
   * @generated from field: repeated int64 reader_project_numbers = 14;
   */
  readerProjectNumbers: bigint[];
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.TunedModel.
 * Use `create(TunedModelSchema)` to create a new message.
 */
export const TunedModelSchema: GenMessage<TunedModel> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 0);

/**
 * The state of the tuned model.
 *
 * @generated from enum google.ai.generativelanguage.v1beta.TunedModel.State
 */
export enum TunedModel_State {
  /**
   * The default value. This value is unused.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The model is being created.
   *
   * @generated from enum value: CREATING = 1;
   */
  CREATING = 1,

  /**
   * The model is ready to be used.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * The model failed to be created.
   *
   * @generated from enum value: FAILED = 3;
   */
  FAILED = 3,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta.TunedModel.State.
 */
export const TunedModel_StateSchema: GenEnum<TunedModel_State> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 0, 0);

/**
 * Tuned model as a source for training a new model.
 *
 * @generated from message google.ai.generativelanguage.v1beta.TunedModelSource
 */
export type TunedModelSource = Message<"google.ai.generativelanguage.v1beta.TunedModelSource"> & {
  /**
   * Immutable. The name of the `TunedModel` to use as the starting point for
   * training the new model.
   * Example: `tunedModels/my-tuned-model`
   *
   * @generated from field: string tuned_model = 1;
   */
  tunedModel: string;

  /**
   * Output only. The name of the base `Model` this `TunedModel` was tuned from.
   * Example: `models/gemini-1.5-flash-001`
   *
   * @generated from field: string base_model = 2;
   */
  baseModel: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.TunedModelSource.
 * Use `create(TunedModelSourceSchema)` to create a new message.
 */
export const TunedModelSourceSchema: GenMessage<TunedModelSource> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 1);

/**
 * Tuning tasks that create tuned models.
 *
 * @generated from message google.ai.generativelanguage.v1beta.TuningTask
 */
export type TuningTask = Message<"google.ai.generativelanguage.v1beta.TuningTask"> & {
  /**
   * Output only. The timestamp when tuning this model started.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 1;
   */
  startTime?: Timestamp;

  /**
   * Output only. The timestamp when tuning this model completed.
   *
   * @generated from field: google.protobuf.Timestamp complete_time = 2;
   */
  completeTime?: Timestamp;

  /**
   * Output only. Metrics collected during tuning.
   *
   * @generated from field: repeated google.ai.generativelanguage.v1beta.TuningSnapshot snapshots = 3;
   */
  snapshots: TuningSnapshot[];

  /**
   * Required. Input only. Immutable. The model training data.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.Dataset training_data = 4;
   */
  trainingData?: Dataset;

  /**
   * Immutable. Hyperparameters controlling the tuning process. If not provided,
   * default values will be used.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.Hyperparameters hyperparameters = 5;
   */
  hyperparameters?: Hyperparameters;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.TuningTask.
 * Use `create(TuningTaskSchema)` to create a new message.
 */
export const TuningTaskSchema: GenMessage<TuningTask> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 2);

/**
 * Hyperparameters controlling the tuning process. Read more at
 * https://ai.google.dev/docs/model_tuning_guidance
 *
 * @generated from message google.ai.generativelanguage.v1beta.Hyperparameters
 */
export type Hyperparameters = Message<"google.ai.generativelanguage.v1beta.Hyperparameters"> & {
  /**
   * Options for specifying learning rate during tuning.
   *
   * @generated from oneof google.ai.generativelanguage.v1beta.Hyperparameters.learning_rate_option
   */
  learningRateOption: {
    /**
     * Optional. Immutable. The learning rate hyperparameter for tuning.
     * If not set, a default of 0.001 or 0.0002 will be calculated based on the
     * number of training examples.
     *
     * @generated from field: float learning_rate = 16;
     */
    value: number;
    case: "learningRate";
  } | {
    /**
     * Optional. Immutable. The learning rate multiplier is used to calculate a
     * final learning_rate based on the default (recommended) value. Actual
     * learning rate := learning_rate_multiplier * default learning rate Default
     * learning rate is dependent on base model and dataset size. If not set, a
     * default of 1.0 will be used.
     *
     * @generated from field: float learning_rate_multiplier = 17;
     */
    value: number;
    case: "learningRateMultiplier";
  } | { case: undefined; value?: undefined };

  /**
   * Immutable. The number of training epochs. An epoch is one pass through the
   * training data. If not set, a default of 5 will be used.
   *
   * @generated from field: optional int32 epoch_count = 14;
   */
  epochCount?: number;

  /**
   * Immutable. The batch size hyperparameter for tuning.
   * If not set, a default of 4 or 16 will be used based on the number of
   * training examples.
   *
   * @generated from field: optional int32 batch_size = 15;
   */
  batchSize?: number;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.Hyperparameters.
 * Use `create(HyperparametersSchema)` to create a new message.
 */
export const HyperparametersSchema: GenMessage<Hyperparameters> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 3);

/**
 * Dataset for training or validation.
 *
 * @generated from message google.ai.generativelanguage.v1beta.Dataset
 */
export type Dataset = Message<"google.ai.generativelanguage.v1beta.Dataset"> & {
  /**
   * Inline data or a reference to the data.
   *
   * @generated from oneof google.ai.generativelanguage.v1beta.Dataset.dataset
   */
  dataset: {
    /**
     * Optional. Inline examples.
     *
     * @generated from field: google.ai.generativelanguage.v1beta.TuningExamples examples = 1;
     */
    value: TuningExamples;
    case: "examples";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.Dataset.
 * Use `create(DatasetSchema)` to create a new message.
 */
export const DatasetSchema: GenMessage<Dataset> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 4);

/**
 * A set of tuning examples. Can be training or validation data.
 *
 * @generated from message google.ai.generativelanguage.v1beta.TuningExamples
 */
export type TuningExamples = Message<"google.ai.generativelanguage.v1beta.TuningExamples"> & {
  /**
   * Required. The examples. Example input can be for text or discuss, but all
   * examples in a set must be of the same type.
   *
   * @generated from field: repeated google.ai.generativelanguage.v1beta.TuningExample examples = 1;
   */
  examples: TuningExample[];
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.TuningExamples.
 * Use `create(TuningExamplesSchema)` to create a new message.
 */
export const TuningExamplesSchema: GenMessage<TuningExamples> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 5);

/**
 * A single example for tuning.
 *
 * @generated from message google.ai.generativelanguage.v1beta.TuningExample
 */
export type TuningExample = Message<"google.ai.generativelanguage.v1beta.TuningExample"> & {
  /**
   * The input to the model for this example.
   *
   * @generated from oneof google.ai.generativelanguage.v1beta.TuningExample.model_input
   */
  modelInput: {
    /**
     * Optional. Text model input.
     *
     * @generated from field: string text_input = 1;
     */
    value: string;
    case: "textInput";
  } | { case: undefined; value?: undefined };

  /**
   * Required. The expected model output.
   *
   * @generated from field: string output = 3;
   */
  output: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.TuningExample.
 * Use `create(TuningExampleSchema)` to create a new message.
 */
export const TuningExampleSchema: GenMessage<TuningExample> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 6);

/**
 * Record for a single tuning step.
 *
 * @generated from message google.ai.generativelanguage.v1beta.TuningSnapshot
 */
export type TuningSnapshot = Message<"google.ai.generativelanguage.v1beta.TuningSnapshot"> & {
  /**
   * Output only. The tuning step.
   *
   * @generated from field: int32 step = 1;
   */
  step: number;

  /**
   * Output only. The epoch this step was part of.
   *
   * @generated from field: int32 epoch = 2;
   */
  epoch: number;

  /**
   * Output only. The mean loss of the training examples for this step.
   *
   * @generated from field: float mean_loss = 3;
   */
  meanLoss: number;

  /**
   * Output only. The timestamp when this metric was computed.
   *
   * @generated from field: google.protobuf.Timestamp compute_time = 4;
   */
  computeTime?: Timestamp;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.TuningSnapshot.
 * Use `create(TuningSnapshotSchema)` to create a new message.
 */
export const TuningSnapshotSchema: GenMessage<TuningSnapshot> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_tuned_model, 7);

