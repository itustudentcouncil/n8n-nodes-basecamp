// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.1.0 with parameter "target=ts"
// @generated from file google/ai/generativelanguage/v1beta/safety.proto (package google.ai.generativelanguage.v1beta, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_google_api_field_behavior } from "../../../api/field_behavior_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file google/ai/generativelanguage/v1beta/safety.proto.
 */
export const file_google_ai_generativelanguage_v1beta_safety: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_api_field_behavior]);

/**
 * Content filtering metadata associated with processing a single request.
 *
 * ContentFilter contains a reason and an optional supporting string. The reason
 * may be unspecified.
 *
 * @generated from message google.ai.generativelanguage.v1beta.ContentFilter
 */
export type ContentFilter = Message<"google.ai.generativelanguage.v1beta.ContentFilter"> & {
  /**
   * The reason content was blocked during request processing.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.ContentFilter.BlockedReason reason = 1;
   */
  reason: ContentFilter_BlockedReason;

  /**
   * A string that describes the filtering behavior in more detail.
   *
   * @generated from field: optional string message = 2;
   */
  message?: string;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.ContentFilter.
 * Use `create(ContentFilterSchema)` to create a new message.
 */
export const ContentFilterSchema: GenMessage<ContentFilter> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_safety, 0);

/**
 * A list of reasons why content may have been blocked.
 *
 * @generated from enum google.ai.generativelanguage.v1beta.ContentFilter.BlockedReason
 */
export enum ContentFilter_BlockedReason {
  /**
   * A blocked reason was not specified.
   *
   * @generated from enum value: BLOCKED_REASON_UNSPECIFIED = 0;
   */
  BLOCKED_REASON_UNSPECIFIED = 0,

  /**
   * Content was blocked by safety settings.
   *
   * @generated from enum value: SAFETY = 1;
   */
  SAFETY = 1,

  /**
   * Content was blocked, but the reason is uncategorized.
   *
   * @generated from enum value: OTHER = 2;
   */
  OTHER = 2,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta.ContentFilter.BlockedReason.
 */
export const ContentFilter_BlockedReasonSchema: GenEnum<ContentFilter_BlockedReason> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta_safety, 0, 0);

/**
 * Safety feedback for an entire request.
 *
 * This field is populated if content in the input and/or response is blocked
 * due to safety settings. SafetyFeedback may not exist for every HarmCategory.
 * Each SafetyFeedback will return the safety settings used by the request as
 * well as the lowest HarmProbability that should be allowed in order to return
 * a result.
 *
 * @generated from message google.ai.generativelanguage.v1beta.SafetyFeedback
 */
export type SafetyFeedback = Message<"google.ai.generativelanguage.v1beta.SafetyFeedback"> & {
  /**
   * Safety rating evaluated from content.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.SafetyRating rating = 1;
   */
  rating?: SafetyRating;

  /**
   * Safety settings applied to the request.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.SafetySetting setting = 2;
   */
  setting?: SafetySetting;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.SafetyFeedback.
 * Use `create(SafetyFeedbackSchema)` to create a new message.
 */
export const SafetyFeedbackSchema: GenMessage<SafetyFeedback> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_safety, 1);

/**
 * Safety rating for a piece of content.
 *
 * The safety rating contains the category of harm and the
 * harm probability level in that category for a piece of content.
 * Content is classified for safety across a number of
 * harm categories and the probability of the harm classification is included
 * here.
 *
 * @generated from message google.ai.generativelanguage.v1beta.SafetyRating
 */
export type SafetyRating = Message<"google.ai.generativelanguage.v1beta.SafetyRating"> & {
  /**
   * Required. The category for this rating.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.HarmCategory category = 3;
   */
  category: HarmCategory;

  /**
   * Required. The probability of harm for this content.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.SafetyRating.HarmProbability probability = 4;
   */
  probability: SafetyRating_HarmProbability;

  /**
   * Was this content blocked because of this rating?
   *
   * @generated from field: bool blocked = 5;
   */
  blocked: boolean;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.SafetyRating.
 * Use `create(SafetyRatingSchema)` to create a new message.
 */
export const SafetyRatingSchema: GenMessage<SafetyRating> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_safety, 2);

/**
 * The probability that a piece of content is harmful.
 *
 * The classification system gives the probability of the content being
 * unsafe. This does not indicate the severity of harm for a piece of content.
 *
 * @generated from enum google.ai.generativelanguage.v1beta.SafetyRating.HarmProbability
 */
export enum SafetyRating_HarmProbability {
  /**
   * Probability is unspecified.
   *
   * @generated from enum value: HARM_PROBABILITY_UNSPECIFIED = 0;
   */
  HARM_PROBABILITY_UNSPECIFIED = 0,

  /**
   * Content has a negligible chance of being unsafe.
   *
   * @generated from enum value: NEGLIGIBLE = 1;
   */
  NEGLIGIBLE = 1,

  /**
   * Content has a low chance of being unsafe.
   *
   * @generated from enum value: LOW = 2;
   */
  LOW = 2,

  /**
   * Content has a medium chance of being unsafe.
   *
   * @generated from enum value: MEDIUM = 3;
   */
  MEDIUM = 3,

  /**
   * Content has a high chance of being unsafe.
   *
   * @generated from enum value: HIGH = 4;
   */
  HIGH = 4,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta.SafetyRating.HarmProbability.
 */
export const SafetyRating_HarmProbabilitySchema: GenEnum<SafetyRating_HarmProbability> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta_safety, 2, 0);

/**
 * Safety setting, affecting the safety-blocking behavior.
 *
 * Passing a safety setting for a category changes the allowed probability that
 * content is blocked.
 *
 * @generated from message google.ai.generativelanguage.v1beta.SafetySetting
 */
export type SafetySetting = Message<"google.ai.generativelanguage.v1beta.SafetySetting"> & {
  /**
   * Required. The category for this setting.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.HarmCategory category = 3;
   */
  category: HarmCategory;

  /**
   * Required. Controls the probability threshold at which harm is blocked.
   *
   * @generated from field: google.ai.generativelanguage.v1beta.SafetySetting.HarmBlockThreshold threshold = 4;
   */
  threshold: SafetySetting_HarmBlockThreshold;
};

/**
 * Describes the message google.ai.generativelanguage.v1beta.SafetySetting.
 * Use `create(SafetySettingSchema)` to create a new message.
 */
export const SafetySettingSchema: GenMessage<SafetySetting> = /*@__PURE__*/
  messageDesc(file_google_ai_generativelanguage_v1beta_safety, 3);

/**
 * Block at and beyond a specified harm probability.
 *
 * @generated from enum google.ai.generativelanguage.v1beta.SafetySetting.HarmBlockThreshold
 */
export enum SafetySetting_HarmBlockThreshold {
  /**
   * Threshold is unspecified.
   *
   * @generated from enum value: HARM_BLOCK_THRESHOLD_UNSPECIFIED = 0;
   */
  HARM_BLOCK_THRESHOLD_UNSPECIFIED = 0,

  /**
   * Content with NEGLIGIBLE will be allowed.
   *
   * @generated from enum value: BLOCK_LOW_AND_ABOVE = 1;
   */
  BLOCK_LOW_AND_ABOVE = 1,

  /**
   * Content with NEGLIGIBLE and LOW will be allowed.
   *
   * @generated from enum value: BLOCK_MEDIUM_AND_ABOVE = 2;
   */
  BLOCK_MEDIUM_AND_ABOVE = 2,

  /**
   * Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
   *
   * @generated from enum value: BLOCK_ONLY_HIGH = 3;
   */
  BLOCK_ONLY_HIGH = 3,

  /**
   * All content will be allowed.
   *
   * @generated from enum value: BLOCK_NONE = 4;
   */
  BLOCK_NONE = 4,

  /**
   * Turn off the safety filter.
   *
   * @generated from enum value: OFF = 5;
   */
  OFF = 5,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta.SafetySetting.HarmBlockThreshold.
 */
export const SafetySetting_HarmBlockThresholdSchema: GenEnum<SafetySetting_HarmBlockThreshold> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta_safety, 3, 0);

/**
 * The category of a rating.
 *
 * These categories cover various kinds of harms that developers
 * may wish to adjust.
 *
 * @generated from enum google.ai.generativelanguage.v1beta.HarmCategory
 */
export enum HarmCategory {
  /**
   * Category is unspecified.
   *
   * @generated from enum value: HARM_CATEGORY_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * **PaLM** - Negative or harmful comments targeting identity and/or protected
   * attribute.
   *
   * @generated from enum value: HARM_CATEGORY_DEROGATORY = 1;
   */
  DEROGATORY = 1,

  /**
   * **PaLM** - Content that is rude, disrespectful, or profane.
   *
   * @generated from enum value: HARM_CATEGORY_TOXICITY = 2;
   */
  TOXICITY = 2,

  /**
   * **PaLM** - Describes scenarios depicting violence against an individual or
   * group, or general descriptions of gore.
   *
   * @generated from enum value: HARM_CATEGORY_VIOLENCE = 3;
   */
  VIOLENCE = 3,

  /**
   * **PaLM** - Contains references to sexual acts or other lewd content.
   *
   * @generated from enum value: HARM_CATEGORY_SEXUAL = 4;
   */
  SEXUAL = 4,

  /**
   * **PaLM** - Promotes unchecked medical advice.
   *
   * @generated from enum value: HARM_CATEGORY_MEDICAL = 5;
   */
  MEDICAL = 5,

  /**
   * **PaLM** - Dangerous content that promotes, facilitates, or encourages
   * harmful acts.
   *
   * @generated from enum value: HARM_CATEGORY_DANGEROUS = 6;
   */
  DANGEROUS = 6,

  /**
   * **Gemini** - Harassment content.
   *
   * @generated from enum value: HARM_CATEGORY_HARASSMENT = 7;
   */
  HARASSMENT = 7,

  /**
   * **Gemini** - Hate speech and content.
   *
   * @generated from enum value: HARM_CATEGORY_HATE_SPEECH = 8;
   */
  HATE_SPEECH = 8,

  /**
   * **Gemini** - Sexually explicit content.
   *
   * @generated from enum value: HARM_CATEGORY_SEXUALLY_EXPLICIT = 9;
   */
  SEXUALLY_EXPLICIT = 9,

  /**
   * **Gemini** - Dangerous content.
   *
   * @generated from enum value: HARM_CATEGORY_DANGEROUS_CONTENT = 10;
   */
  DANGEROUS_CONTENT = 10,

  /**
   * **Gemini** - Content that may be used to harm civic integrity.
   *
   * @generated from enum value: HARM_CATEGORY_CIVIC_INTEGRITY = 11;
   */
  CIVIC_INTEGRITY = 11,
}

/**
 * Describes the enum google.ai.generativelanguage.v1beta.HarmCategory.
 */
export const HarmCategorySchema: GenEnum<HarmCategory> = /*@__PURE__*/
  enumDesc(file_google_ai_generativelanguage_v1beta_safety, 0);

