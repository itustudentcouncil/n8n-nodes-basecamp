// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/storagetransfer/logging/transfer_activity_log.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../protobuf/timestamp.js";

export const protobufPackage = "google.storagetransfer.logging";

/** Type of the storage system. */
export enum StorageSystemType {
  /** STORAGE_SYSTEM_TYPE_UNSPECIFIED - Unspecified. */
  STORAGE_SYSTEM_TYPE_UNSPECIFIED = 0,
  /** AWS_S3 - AWS S3. */
  AWS_S3 = 1,
  /** AZURE_BLOB - Azure Blob Storage. */
  AZURE_BLOB = 2,
  /** GCS - Google Cloud Storage. */
  GCS = 3,
  /** POSIX_FS - POSIX file system. */
  POSIX_FS = 4,
  /** HTTP - HTTP/HTTPS servers. */
  HTTP = 5,
  UNRECOGNIZED = -1,
}

export function storageSystemTypeFromJSON(object: any): StorageSystemType {
  switch (object) {
    case 0:
    case "STORAGE_SYSTEM_TYPE_UNSPECIFIED":
      return StorageSystemType.STORAGE_SYSTEM_TYPE_UNSPECIFIED;
    case 1:
    case "AWS_S3":
      return StorageSystemType.AWS_S3;
    case 2:
    case "AZURE_BLOB":
      return StorageSystemType.AZURE_BLOB;
    case 3:
    case "GCS":
      return StorageSystemType.GCS;
    case 4:
    case "POSIX_FS":
      return StorageSystemType.POSIX_FS;
    case 5:
    case "HTTP":
      return StorageSystemType.HTTP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StorageSystemType.UNRECOGNIZED;
  }
}

export function storageSystemTypeToJSON(object: StorageSystemType): string {
  switch (object) {
    case StorageSystemType.STORAGE_SYSTEM_TYPE_UNSPECIFIED:
      return "STORAGE_SYSTEM_TYPE_UNSPECIFIED";
    case StorageSystemType.AWS_S3:
      return "AWS_S3";
    case StorageSystemType.AZURE_BLOB:
      return "AZURE_BLOB";
    case StorageSystemType.GCS:
      return "GCS";
    case StorageSystemType.POSIX_FS:
      return "POSIX_FS";
    case StorageSystemType.HTTP:
      return "HTTP";
    case StorageSystemType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** AWS S3 object metadata. */
export interface AwsS3ObjectMetadata {
  /** Required. Name of the S3 bucket. */
  bucket: string;
  /** Required. Name/key of the object. */
  objectKey: string;
  /** Last modified time of the object. */
  lastModifiedTime:
    | Date
    | undefined;
  /** The MD5 checksum of the object's content. */
  md5: string;
  /** Required. Size of the object in bytes. */
  size: Long;
}

/** AWS S3 bucket metadata. */
export interface AwsS3BucketMetadata {
  /** Required. Name of the S3 bucket. */
  bucket: string;
  /** The path of transfer objects as an object key prefix ending with "/". */
  path: string;
}

/** Google Cloud Storage object metadata. */
export interface GcsObjectMetadata {
  /** Required. Name of the Cloud Storage bucket. */
  bucket: string;
  /** Required. Name/key of the object. */
  objectKey: string;
  /** Last modified time of the object. */
  lastModifiedTime:
    | Date
    | undefined;
  /** The MD5 checksum of the object's content. */
  md5: string;
  /** The CRC32C checksum of the object's content. */
  crc32c: string;
  /** Required. Size of the object in bytes. */
  size: Long;
}

/** Google Cloud Storage bucket metadata. */
export interface GcsBucketMetadata {
  /** Required. Name of the Cloud Storage bucket. */
  bucket: string;
  /** The path of transfer objects as an object key prefix ending with "/". */
  path: string;
}

/** Azure Blob Storage blob metadata. */
export interface AzureBlobMetadata {
  /** Required. Name of the Azure Blob storage account. */
  account: string;
  /** Required. Name of the container. */
  container: string;
  /** Required. Name of the blob. */
  blobName: string;
  /** Last modified time of the blob. */
  lastModifiedTime:
    | Date
    | undefined;
  /** The MD5 checksum of the object's content. */
  md5: string;
  /** Required. Size of the blob in bytes. */
  size: Long;
}

/** Azure Blob Storage container metadata. */
export interface AzureBlobContainerMetadata {
  /** Required. Name of the Azure Blob storage account. */
  account: string;
  /** Required. Name of the container. */
  container: string;
  /** The path of transfer blobs as a blob name prefix ending with "/". */
  path: string;
}

/** POSIX file metadata. */
export interface PosixFileMetadata {
  /** Required. Path of a file. */
  path: string;
  /** Last modified time (mtime) of the file. */
  lastModifiedTime:
    | Date
    | undefined;
  /** The CRC32C checksum of the object's content. */
  crc32c: string;
  /** Required. Size of the file in bytes. */
  size: Long;
}

/** HTTP file metadata. */
export interface HttpFileMetadata {
  /** Required. Url of the HTTP file. */
  url: string;
  /** The MD5 checksum of the file's content. */
  md5: string;
  /** Size of the file in bytes. */
  size: Long;
}

/** HTTP manifest file metadata. */
export interface HttpManifestMetadata {
  /**
   * Required. Url of the HTTP manifest which contains the list of HTTP files to
   * transfer.
   */
  url: string;
}

/** Metadata of a blob/file/object. */
export interface ObjectMetadata {
  /** Required. Storage system type of the object. */
  type: StorageSystemType;
  /** Object metadata of AWS S3. */
  awsS3Object?:
    | AwsS3ObjectMetadata
    | undefined;
  /** Blob metadata of Azure Blob Storage. */
  azureBlob?:
    | AzureBlobMetadata
    | undefined;
  /** Object metadata of Google Cloud Storage. */
  gcsObject?:
    | GcsObjectMetadata
    | undefined;
  /** File/directory metadata of POSIX file system. */
  posixFile?:
    | PosixFileMetadata
    | undefined;
  /** Metadata of a file on a HTTP server. */
  httpFile?: HttpFileMetadata | undefined;
}

/** Metadata of a bucket/container/directory */
export interface ContainerMetadata {
  /** Required. Storage system type of the object. */
  type: StorageSystemType;
  /** Bucket metadata of AWS S3. */
  awsS3Bucket?:
    | AwsS3BucketMetadata
    | undefined;
  /** Container metadata of Azure Blob Storage. */
  azureBlobContainer?:
    | AzureBlobContainerMetadata
    | undefined;
  /** Bucket metadata of Google Cloud Storage. */
  gcsBucket?:
    | GcsBucketMetadata
    | undefined;
  /** Directory metadata of POSIX file system. */
  posixDirectory?:
    | PosixFileMetadata
    | undefined;
  /** Metadata of a manifest file on a HTTP server. */
  httpManifest?: HttpManifestMetadata | undefined;
}

/** Schema of log payload of transfer activity. */
export interface TransferActivityLog {
  /** Required. Name of the transfer operation. */
  operation: string;
  /** Required. The action which the transfer operation made. */
  action: TransferActivityLog_Action;
  /** Required. Status of the action. */
  status:
    | TransferActivityLog_Status
    | undefined;
  /**
   * Metadata of source bucket/container/directory. Only set if the action is
   * FIND.
   */
  sourceContainer:
    | ContainerMetadata
    | undefined;
  /**
   * Metadata of destination bucket/container/directory. Only set if the action
   * is FIND.
   */
  destinationContainer:
    | ContainerMetadata
    | undefined;
  /**
   * Metadata of the source blob/file/object. Only set if the action is COPY or
   * DELETE when deletion is applied to source.
   */
  sourceObject:
    | ObjectMetadata
    | undefined;
  /**
   * Metadata of the destination blob/file/object. Only set if the action is
   * or DELETE when deletion is applied to destination.
   */
  destinationObject:
    | ObjectMetadata
    | undefined;
  /** Required. Completion time of the action. */
  completeTime: Date | undefined;
}

/** Possible actions which a transfer operation can make. */
export enum TransferActivityLog_Action {
  /** ACTION_UNSPECIFIED - Unspeficied action. */
  ACTION_UNSPECIFIED = 0,
  /**
   * FIND - Finding work to do, such as listing files in a directory or listing
   * objects in a bucket.
   */
  FIND = 1,
  /** COPY - Copying files or objects. */
  COPY = 2,
  /** DELETE - Deleting files or objects at destination. */
  DELETE = 3,
  UNRECOGNIZED = -1,
}

export function transferActivityLog_ActionFromJSON(object: any): TransferActivityLog_Action {
  switch (object) {
    case 0:
    case "ACTION_UNSPECIFIED":
      return TransferActivityLog_Action.ACTION_UNSPECIFIED;
    case 1:
    case "FIND":
      return TransferActivityLog_Action.FIND;
    case 2:
    case "COPY":
      return TransferActivityLog_Action.COPY;
    case 3:
    case "DELETE":
      return TransferActivityLog_Action.DELETE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TransferActivityLog_Action.UNRECOGNIZED;
  }
}

export function transferActivityLog_ActionToJSON(object: TransferActivityLog_Action): string {
  switch (object) {
    case TransferActivityLog_Action.ACTION_UNSPECIFIED:
      return "ACTION_UNSPECIFIED";
    case TransferActivityLog_Action.FIND:
      return "FIND";
    case TransferActivityLog_Action.COPY:
      return "COPY";
    case TransferActivityLog_Action.DELETE:
      return "DELETE";
    case TransferActivityLog_Action.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Status of an action. */
export interface TransferActivityLog_Status {
  /**
   * Required. A string value of the Google RPC code as the status of the
   * action. The action succeeded if it's `OK`, and failed otherwise.
   */
  statusCode: string;
  /**
   * A string that represents the type of error encountered. Populated only if
   * status_code is not `OK`.
   */
  errorType: string;
  /**
   * A human-readable error message for the failure. Populated only if
   * status_code is not `OK`.
   */
  errorMessage: string;
}

function createBaseAwsS3ObjectMetadata(): AwsS3ObjectMetadata {
  return { bucket: "", objectKey: "", lastModifiedTime: undefined, md5: "", size: Long.ZERO };
}

export const AwsS3ObjectMetadata: MessageFns<AwsS3ObjectMetadata> = {
  encode(message: AwsS3ObjectMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.objectKey !== "") {
      writer.uint32(18).string(message.objectKey);
    }
    if (message.lastModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedTime), writer.uint32(26).fork()).join();
    }
    if (message.md5 !== "") {
      writer.uint32(34).string(message.md5);
    }
    if (!message.size.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.size.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsS3ObjectMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsS3ObjectMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.objectKey = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.lastModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.md5 = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.size = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsS3ObjectMetadata {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      objectKey: isSet(object.objectKey) ? globalThis.String(object.objectKey) : "",
      lastModifiedTime: isSet(object.lastModifiedTime) ? fromJsonTimestamp(object.lastModifiedTime) : undefined,
      md5: isSet(object.md5) ? globalThis.String(object.md5) : "",
      size: isSet(object.size) ? Long.fromValue(object.size) : Long.ZERO,
    };
  },

  toJSON(message: AwsS3ObjectMetadata): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.objectKey !== "") {
      obj.objectKey = message.objectKey;
    }
    if (message.lastModifiedTime !== undefined) {
      obj.lastModifiedTime = message.lastModifiedTime.toISOString();
    }
    if (message.md5 !== "") {
      obj.md5 = message.md5;
    }
    if (!message.size.equals(Long.ZERO)) {
      obj.size = (message.size || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<AwsS3ObjectMetadata>): AwsS3ObjectMetadata {
    return AwsS3ObjectMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsS3ObjectMetadata>): AwsS3ObjectMetadata {
    const message = createBaseAwsS3ObjectMetadata();
    message.bucket = object.bucket ?? "";
    message.objectKey = object.objectKey ?? "";
    message.lastModifiedTime = object.lastModifiedTime ?? undefined;
    message.md5 = object.md5 ?? "";
    message.size = (object.size !== undefined && object.size !== null) ? Long.fromValue(object.size) : Long.ZERO;
    return message;
  },
};

function createBaseAwsS3BucketMetadata(): AwsS3BucketMetadata {
  return { bucket: "", path: "" };
}

export const AwsS3BucketMetadata: MessageFns<AwsS3BucketMetadata> = {
  encode(message: AwsS3BucketMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsS3BucketMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsS3BucketMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsS3BucketMetadata {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: AwsS3BucketMetadata): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<AwsS3BucketMetadata>): AwsS3BucketMetadata {
    return AwsS3BucketMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AwsS3BucketMetadata>): AwsS3BucketMetadata {
    const message = createBaseAwsS3BucketMetadata();
    message.bucket = object.bucket ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseGcsObjectMetadata(): GcsObjectMetadata {
  return { bucket: "", objectKey: "", lastModifiedTime: undefined, md5: "", crc32c: "", size: Long.ZERO };
}

export const GcsObjectMetadata: MessageFns<GcsObjectMetadata> = {
  encode(message: GcsObjectMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.objectKey !== "") {
      writer.uint32(18).string(message.objectKey);
    }
    if (message.lastModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedTime), writer.uint32(26).fork()).join();
    }
    if (message.md5 !== "") {
      writer.uint32(34).string(message.md5);
    }
    if (message.crc32c !== "") {
      writer.uint32(42).string(message.crc32c);
    }
    if (!message.size.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.size.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsObjectMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsObjectMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.objectKey = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.lastModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.md5 = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.crc32c = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.size = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsObjectMetadata {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      objectKey: isSet(object.objectKey) ? globalThis.String(object.objectKey) : "",
      lastModifiedTime: isSet(object.lastModifiedTime) ? fromJsonTimestamp(object.lastModifiedTime) : undefined,
      md5: isSet(object.md5) ? globalThis.String(object.md5) : "",
      crc32c: isSet(object.crc32c) ? globalThis.String(object.crc32c) : "",
      size: isSet(object.size) ? Long.fromValue(object.size) : Long.ZERO,
    };
  },

  toJSON(message: GcsObjectMetadata): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.objectKey !== "") {
      obj.objectKey = message.objectKey;
    }
    if (message.lastModifiedTime !== undefined) {
      obj.lastModifiedTime = message.lastModifiedTime.toISOString();
    }
    if (message.md5 !== "") {
      obj.md5 = message.md5;
    }
    if (message.crc32c !== "") {
      obj.crc32c = message.crc32c;
    }
    if (!message.size.equals(Long.ZERO)) {
      obj.size = (message.size || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<GcsObjectMetadata>): GcsObjectMetadata {
    return GcsObjectMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsObjectMetadata>): GcsObjectMetadata {
    const message = createBaseGcsObjectMetadata();
    message.bucket = object.bucket ?? "";
    message.objectKey = object.objectKey ?? "";
    message.lastModifiedTime = object.lastModifiedTime ?? undefined;
    message.md5 = object.md5 ?? "";
    message.crc32c = object.crc32c ?? "";
    message.size = (object.size !== undefined && object.size !== null) ? Long.fromValue(object.size) : Long.ZERO;
    return message;
  },
};

function createBaseGcsBucketMetadata(): GcsBucketMetadata {
  return { bucket: "", path: "" };
}

export const GcsBucketMetadata: MessageFns<GcsBucketMetadata> = {
  encode(message: GcsBucketMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsBucketMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsBucketMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsBucketMetadata {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: GcsBucketMetadata): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsBucketMetadata>): GcsBucketMetadata {
    return GcsBucketMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsBucketMetadata>): GcsBucketMetadata {
    const message = createBaseGcsBucketMetadata();
    message.bucket = object.bucket ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseAzureBlobMetadata(): AzureBlobMetadata {
  return { account: "", container: "", blobName: "", lastModifiedTime: undefined, md5: "", size: Long.ZERO };
}

export const AzureBlobMetadata: MessageFns<AzureBlobMetadata> = {
  encode(message: AzureBlobMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.account !== "") {
      writer.uint32(10).string(message.account);
    }
    if (message.container !== "") {
      writer.uint32(18).string(message.container);
    }
    if (message.blobName !== "") {
      writer.uint32(26).string(message.blobName);
    }
    if (message.lastModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedTime), writer.uint32(34).fork()).join();
    }
    if (message.md5 !== "") {
      writer.uint32(42).string(message.md5);
    }
    if (!message.size.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.size.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureBlobMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureBlobMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.account = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.container = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.blobName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lastModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.md5 = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.size = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureBlobMetadata {
    return {
      account: isSet(object.account) ? globalThis.String(object.account) : "",
      container: isSet(object.container) ? globalThis.String(object.container) : "",
      blobName: isSet(object.blobName) ? globalThis.String(object.blobName) : "",
      lastModifiedTime: isSet(object.lastModifiedTime) ? fromJsonTimestamp(object.lastModifiedTime) : undefined,
      md5: isSet(object.md5) ? globalThis.String(object.md5) : "",
      size: isSet(object.size) ? Long.fromValue(object.size) : Long.ZERO,
    };
  },

  toJSON(message: AzureBlobMetadata): unknown {
    const obj: any = {};
    if (message.account !== "") {
      obj.account = message.account;
    }
    if (message.container !== "") {
      obj.container = message.container;
    }
    if (message.blobName !== "") {
      obj.blobName = message.blobName;
    }
    if (message.lastModifiedTime !== undefined) {
      obj.lastModifiedTime = message.lastModifiedTime.toISOString();
    }
    if (message.md5 !== "") {
      obj.md5 = message.md5;
    }
    if (!message.size.equals(Long.ZERO)) {
      obj.size = (message.size || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<AzureBlobMetadata>): AzureBlobMetadata {
    return AzureBlobMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureBlobMetadata>): AzureBlobMetadata {
    const message = createBaseAzureBlobMetadata();
    message.account = object.account ?? "";
    message.container = object.container ?? "";
    message.blobName = object.blobName ?? "";
    message.lastModifiedTime = object.lastModifiedTime ?? undefined;
    message.md5 = object.md5 ?? "";
    message.size = (object.size !== undefined && object.size !== null) ? Long.fromValue(object.size) : Long.ZERO;
    return message;
  },
};

function createBaseAzureBlobContainerMetadata(): AzureBlobContainerMetadata {
  return { account: "", container: "", path: "" };
}

export const AzureBlobContainerMetadata: MessageFns<AzureBlobContainerMetadata> = {
  encode(message: AzureBlobContainerMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.account !== "") {
      writer.uint32(10).string(message.account);
    }
    if (message.container !== "") {
      writer.uint32(18).string(message.container);
    }
    if (message.path !== "") {
      writer.uint32(26).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AzureBlobContainerMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAzureBlobContainerMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.account = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.container = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.path = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AzureBlobContainerMetadata {
    return {
      account: isSet(object.account) ? globalThis.String(object.account) : "",
      container: isSet(object.container) ? globalThis.String(object.container) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: AzureBlobContainerMetadata): unknown {
    const obj: any = {};
    if (message.account !== "") {
      obj.account = message.account;
    }
    if (message.container !== "") {
      obj.container = message.container;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create(base?: DeepPartial<AzureBlobContainerMetadata>): AzureBlobContainerMetadata {
    return AzureBlobContainerMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AzureBlobContainerMetadata>): AzureBlobContainerMetadata {
    const message = createBaseAzureBlobContainerMetadata();
    message.account = object.account ?? "";
    message.container = object.container ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBasePosixFileMetadata(): PosixFileMetadata {
  return { path: "", lastModifiedTime: undefined, crc32c: "", size: Long.ZERO };
}

export const PosixFileMetadata: MessageFns<PosixFileMetadata> = {
  encode(message: PosixFileMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    if (message.lastModifiedTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedTime), writer.uint32(18).fork()).join();
    }
    if (message.crc32c !== "") {
      writer.uint32(26).string(message.crc32c);
    }
    if (!message.size.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.size.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PosixFileMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePosixFileMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.lastModifiedTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.crc32c = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.size = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PosixFileMetadata {
    return {
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      lastModifiedTime: isSet(object.lastModifiedTime) ? fromJsonTimestamp(object.lastModifiedTime) : undefined,
      crc32c: isSet(object.crc32c) ? globalThis.String(object.crc32c) : "",
      size: isSet(object.size) ? Long.fromValue(object.size) : Long.ZERO,
    };
  },

  toJSON(message: PosixFileMetadata): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.lastModifiedTime !== undefined) {
      obj.lastModifiedTime = message.lastModifiedTime.toISOString();
    }
    if (message.crc32c !== "") {
      obj.crc32c = message.crc32c;
    }
    if (!message.size.equals(Long.ZERO)) {
      obj.size = (message.size || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<PosixFileMetadata>): PosixFileMetadata {
    return PosixFileMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PosixFileMetadata>): PosixFileMetadata {
    const message = createBasePosixFileMetadata();
    message.path = object.path ?? "";
    message.lastModifiedTime = object.lastModifiedTime ?? undefined;
    message.crc32c = object.crc32c ?? "";
    message.size = (object.size !== undefined && object.size !== null) ? Long.fromValue(object.size) : Long.ZERO;
    return message;
  },
};

function createBaseHttpFileMetadata(): HttpFileMetadata {
  return { url: "", md5: "", size: Long.ZERO };
}

export const HttpFileMetadata: MessageFns<HttpFileMetadata> = {
  encode(message: HttpFileMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.url !== "") {
      writer.uint32(10).string(message.url);
    }
    if (message.md5 !== "") {
      writer.uint32(18).string(message.md5);
    }
    if (!message.size.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.size.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HttpFileMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHttpFileMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.url = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.md5 = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.size = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HttpFileMetadata {
    return {
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      md5: isSet(object.md5) ? globalThis.String(object.md5) : "",
      size: isSet(object.size) ? Long.fromValue(object.size) : Long.ZERO,
    };
  },

  toJSON(message: HttpFileMetadata): unknown {
    const obj: any = {};
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.md5 !== "") {
      obj.md5 = message.md5;
    }
    if (!message.size.equals(Long.ZERO)) {
      obj.size = (message.size || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<HttpFileMetadata>): HttpFileMetadata {
    return HttpFileMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HttpFileMetadata>): HttpFileMetadata {
    const message = createBaseHttpFileMetadata();
    message.url = object.url ?? "";
    message.md5 = object.md5 ?? "";
    message.size = (object.size !== undefined && object.size !== null) ? Long.fromValue(object.size) : Long.ZERO;
    return message;
  },
};

function createBaseHttpManifestMetadata(): HttpManifestMetadata {
  return { url: "" };
}

export const HttpManifestMetadata: MessageFns<HttpManifestMetadata> = {
  encode(message: HttpManifestMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.url !== "") {
      writer.uint32(10).string(message.url);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HttpManifestMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHttpManifestMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.url = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HttpManifestMetadata {
    return { url: isSet(object.url) ? globalThis.String(object.url) : "" };
  },

  toJSON(message: HttpManifestMetadata): unknown {
    const obj: any = {};
    if (message.url !== "") {
      obj.url = message.url;
    }
    return obj;
  },

  create(base?: DeepPartial<HttpManifestMetadata>): HttpManifestMetadata {
    return HttpManifestMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HttpManifestMetadata>): HttpManifestMetadata {
    const message = createBaseHttpManifestMetadata();
    message.url = object.url ?? "";
    return message;
  },
};

function createBaseObjectMetadata(): ObjectMetadata {
  return {
    type: 0,
    awsS3Object: undefined,
    azureBlob: undefined,
    gcsObject: undefined,
    posixFile: undefined,
    httpFile: undefined,
  };
}

export const ObjectMetadata: MessageFns<ObjectMetadata> = {
  encode(message: ObjectMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.awsS3Object !== undefined) {
      AwsS3ObjectMetadata.encode(message.awsS3Object, writer.uint32(26).fork()).join();
    }
    if (message.azureBlob !== undefined) {
      AzureBlobMetadata.encode(message.azureBlob, writer.uint32(34).fork()).join();
    }
    if (message.gcsObject !== undefined) {
      GcsObjectMetadata.encode(message.gcsObject, writer.uint32(42).fork()).join();
    }
    if (message.posixFile !== undefined) {
      PosixFileMetadata.encode(message.posixFile, writer.uint32(50).fork()).join();
    }
    if (message.httpFile !== undefined) {
      HttpFileMetadata.encode(message.httpFile, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ObjectMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseObjectMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.awsS3Object = AwsS3ObjectMetadata.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.azureBlob = AzureBlobMetadata.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.gcsObject = GcsObjectMetadata.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.posixFile = PosixFileMetadata.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.httpFile = HttpFileMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ObjectMetadata {
    return {
      type: isSet(object.type) ? storageSystemTypeFromJSON(object.type) : 0,
      awsS3Object: isSet(object.awsS3Object) ? AwsS3ObjectMetadata.fromJSON(object.awsS3Object) : undefined,
      azureBlob: isSet(object.azureBlob) ? AzureBlobMetadata.fromJSON(object.azureBlob) : undefined,
      gcsObject: isSet(object.gcsObject) ? GcsObjectMetadata.fromJSON(object.gcsObject) : undefined,
      posixFile: isSet(object.posixFile) ? PosixFileMetadata.fromJSON(object.posixFile) : undefined,
      httpFile: isSet(object.httpFile) ? HttpFileMetadata.fromJSON(object.httpFile) : undefined,
    };
  },

  toJSON(message: ObjectMetadata): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = storageSystemTypeToJSON(message.type);
    }
    if (message.awsS3Object !== undefined) {
      obj.awsS3Object = AwsS3ObjectMetadata.toJSON(message.awsS3Object);
    }
    if (message.azureBlob !== undefined) {
      obj.azureBlob = AzureBlobMetadata.toJSON(message.azureBlob);
    }
    if (message.gcsObject !== undefined) {
      obj.gcsObject = GcsObjectMetadata.toJSON(message.gcsObject);
    }
    if (message.posixFile !== undefined) {
      obj.posixFile = PosixFileMetadata.toJSON(message.posixFile);
    }
    if (message.httpFile !== undefined) {
      obj.httpFile = HttpFileMetadata.toJSON(message.httpFile);
    }
    return obj;
  },

  create(base?: DeepPartial<ObjectMetadata>): ObjectMetadata {
    return ObjectMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ObjectMetadata>): ObjectMetadata {
    const message = createBaseObjectMetadata();
    message.type = object.type ?? 0;
    message.awsS3Object = (object.awsS3Object !== undefined && object.awsS3Object !== null)
      ? AwsS3ObjectMetadata.fromPartial(object.awsS3Object)
      : undefined;
    message.azureBlob = (object.azureBlob !== undefined && object.azureBlob !== null)
      ? AzureBlobMetadata.fromPartial(object.azureBlob)
      : undefined;
    message.gcsObject = (object.gcsObject !== undefined && object.gcsObject !== null)
      ? GcsObjectMetadata.fromPartial(object.gcsObject)
      : undefined;
    message.posixFile = (object.posixFile !== undefined && object.posixFile !== null)
      ? PosixFileMetadata.fromPartial(object.posixFile)
      : undefined;
    message.httpFile = (object.httpFile !== undefined && object.httpFile !== null)
      ? HttpFileMetadata.fromPartial(object.httpFile)
      : undefined;
    return message;
  },
};

function createBaseContainerMetadata(): ContainerMetadata {
  return {
    type: 0,
    awsS3Bucket: undefined,
    azureBlobContainer: undefined,
    gcsBucket: undefined,
    posixDirectory: undefined,
    httpManifest: undefined,
  };
}

export const ContainerMetadata: MessageFns<ContainerMetadata> = {
  encode(message: ContainerMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.awsS3Bucket !== undefined) {
      AwsS3BucketMetadata.encode(message.awsS3Bucket, writer.uint32(26).fork()).join();
    }
    if (message.azureBlobContainer !== undefined) {
      AzureBlobContainerMetadata.encode(message.azureBlobContainer, writer.uint32(34).fork()).join();
    }
    if (message.gcsBucket !== undefined) {
      GcsBucketMetadata.encode(message.gcsBucket, writer.uint32(42).fork()).join();
    }
    if (message.posixDirectory !== undefined) {
      PosixFileMetadata.encode(message.posixDirectory, writer.uint32(50).fork()).join();
    }
    if (message.httpManifest !== undefined) {
      HttpManifestMetadata.encode(message.httpManifest, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ContainerMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseContainerMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.awsS3Bucket = AwsS3BucketMetadata.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.azureBlobContainer = AzureBlobContainerMetadata.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.gcsBucket = GcsBucketMetadata.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.posixDirectory = PosixFileMetadata.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.httpManifest = HttpManifestMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ContainerMetadata {
    return {
      type: isSet(object.type) ? storageSystemTypeFromJSON(object.type) : 0,
      awsS3Bucket: isSet(object.awsS3Bucket) ? AwsS3BucketMetadata.fromJSON(object.awsS3Bucket) : undefined,
      azureBlobContainer: isSet(object.azureBlobContainer)
        ? AzureBlobContainerMetadata.fromJSON(object.azureBlobContainer)
        : undefined,
      gcsBucket: isSet(object.gcsBucket) ? GcsBucketMetadata.fromJSON(object.gcsBucket) : undefined,
      posixDirectory: isSet(object.posixDirectory) ? PosixFileMetadata.fromJSON(object.posixDirectory) : undefined,
      httpManifest: isSet(object.httpManifest) ? HttpManifestMetadata.fromJSON(object.httpManifest) : undefined,
    };
  },

  toJSON(message: ContainerMetadata): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = storageSystemTypeToJSON(message.type);
    }
    if (message.awsS3Bucket !== undefined) {
      obj.awsS3Bucket = AwsS3BucketMetadata.toJSON(message.awsS3Bucket);
    }
    if (message.azureBlobContainer !== undefined) {
      obj.azureBlobContainer = AzureBlobContainerMetadata.toJSON(message.azureBlobContainer);
    }
    if (message.gcsBucket !== undefined) {
      obj.gcsBucket = GcsBucketMetadata.toJSON(message.gcsBucket);
    }
    if (message.posixDirectory !== undefined) {
      obj.posixDirectory = PosixFileMetadata.toJSON(message.posixDirectory);
    }
    if (message.httpManifest !== undefined) {
      obj.httpManifest = HttpManifestMetadata.toJSON(message.httpManifest);
    }
    return obj;
  },

  create(base?: DeepPartial<ContainerMetadata>): ContainerMetadata {
    return ContainerMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ContainerMetadata>): ContainerMetadata {
    const message = createBaseContainerMetadata();
    message.type = object.type ?? 0;
    message.awsS3Bucket = (object.awsS3Bucket !== undefined && object.awsS3Bucket !== null)
      ? AwsS3BucketMetadata.fromPartial(object.awsS3Bucket)
      : undefined;
    message.azureBlobContainer = (object.azureBlobContainer !== undefined && object.azureBlobContainer !== null)
      ? AzureBlobContainerMetadata.fromPartial(object.azureBlobContainer)
      : undefined;
    message.gcsBucket = (object.gcsBucket !== undefined && object.gcsBucket !== null)
      ? GcsBucketMetadata.fromPartial(object.gcsBucket)
      : undefined;
    message.posixDirectory = (object.posixDirectory !== undefined && object.posixDirectory !== null)
      ? PosixFileMetadata.fromPartial(object.posixDirectory)
      : undefined;
    message.httpManifest = (object.httpManifest !== undefined && object.httpManifest !== null)
      ? HttpManifestMetadata.fromPartial(object.httpManifest)
      : undefined;
    return message;
  },
};

function createBaseTransferActivityLog(): TransferActivityLog {
  return {
    operation: "",
    action: 0,
    status: undefined,
    sourceContainer: undefined,
    destinationContainer: undefined,
    sourceObject: undefined,
    destinationObject: undefined,
    completeTime: undefined,
  };
}

export const TransferActivityLog: MessageFns<TransferActivityLog> = {
  encode(message: TransferActivityLog, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.operation !== "") {
      writer.uint32(10).string(message.operation);
    }
    if (message.action !== 0) {
      writer.uint32(16).int32(message.action);
    }
    if (message.status !== undefined) {
      TransferActivityLog_Status.encode(message.status, writer.uint32(26).fork()).join();
    }
    if (message.sourceContainer !== undefined) {
      ContainerMetadata.encode(message.sourceContainer, writer.uint32(34).fork()).join();
    }
    if (message.destinationContainer !== undefined) {
      ContainerMetadata.encode(message.destinationContainer, writer.uint32(42).fork()).join();
    }
    if (message.sourceObject !== undefined) {
      ObjectMetadata.encode(message.sourceObject, writer.uint32(50).fork()).join();
    }
    if (message.destinationObject !== undefined) {
      ObjectMetadata.encode(message.destinationObject, writer.uint32(58).fork()).join();
    }
    if (message.completeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.completeTime), writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransferActivityLog {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransferActivityLog();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.operation = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.action = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.status = TransferActivityLog_Status.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sourceContainer = ContainerMetadata.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.destinationContainer = ContainerMetadata.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.sourceObject = ObjectMetadata.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.destinationObject = ObjectMetadata.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.completeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransferActivityLog {
    return {
      operation: isSet(object.operation) ? globalThis.String(object.operation) : "",
      action: isSet(object.action) ? transferActivityLog_ActionFromJSON(object.action) : 0,
      status: isSet(object.status) ? TransferActivityLog_Status.fromJSON(object.status) : undefined,
      sourceContainer: isSet(object.sourceContainer) ? ContainerMetadata.fromJSON(object.sourceContainer) : undefined,
      destinationContainer: isSet(object.destinationContainer)
        ? ContainerMetadata.fromJSON(object.destinationContainer)
        : undefined,
      sourceObject: isSet(object.sourceObject) ? ObjectMetadata.fromJSON(object.sourceObject) : undefined,
      destinationObject: isSet(object.destinationObject)
        ? ObjectMetadata.fromJSON(object.destinationObject)
        : undefined,
      completeTime: isSet(object.completeTime) ? fromJsonTimestamp(object.completeTime) : undefined,
    };
  },

  toJSON(message: TransferActivityLog): unknown {
    const obj: any = {};
    if (message.operation !== "") {
      obj.operation = message.operation;
    }
    if (message.action !== 0) {
      obj.action = transferActivityLog_ActionToJSON(message.action);
    }
    if (message.status !== undefined) {
      obj.status = TransferActivityLog_Status.toJSON(message.status);
    }
    if (message.sourceContainer !== undefined) {
      obj.sourceContainer = ContainerMetadata.toJSON(message.sourceContainer);
    }
    if (message.destinationContainer !== undefined) {
      obj.destinationContainer = ContainerMetadata.toJSON(message.destinationContainer);
    }
    if (message.sourceObject !== undefined) {
      obj.sourceObject = ObjectMetadata.toJSON(message.sourceObject);
    }
    if (message.destinationObject !== undefined) {
      obj.destinationObject = ObjectMetadata.toJSON(message.destinationObject);
    }
    if (message.completeTime !== undefined) {
      obj.completeTime = message.completeTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<TransferActivityLog>): TransferActivityLog {
    return TransferActivityLog.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransferActivityLog>): TransferActivityLog {
    const message = createBaseTransferActivityLog();
    message.operation = object.operation ?? "";
    message.action = object.action ?? 0;
    message.status = (object.status !== undefined && object.status !== null)
      ? TransferActivityLog_Status.fromPartial(object.status)
      : undefined;
    message.sourceContainer = (object.sourceContainer !== undefined && object.sourceContainer !== null)
      ? ContainerMetadata.fromPartial(object.sourceContainer)
      : undefined;
    message.destinationContainer = (object.destinationContainer !== undefined && object.destinationContainer !== null)
      ? ContainerMetadata.fromPartial(object.destinationContainer)
      : undefined;
    message.sourceObject = (object.sourceObject !== undefined && object.sourceObject !== null)
      ? ObjectMetadata.fromPartial(object.sourceObject)
      : undefined;
    message.destinationObject = (object.destinationObject !== undefined && object.destinationObject !== null)
      ? ObjectMetadata.fromPartial(object.destinationObject)
      : undefined;
    message.completeTime = object.completeTime ?? undefined;
    return message;
  },
};

function createBaseTransferActivityLog_Status(): TransferActivityLog_Status {
  return { statusCode: "", errorType: "", errorMessage: "" };
}

export const TransferActivityLog_Status: MessageFns<TransferActivityLog_Status> = {
  encode(message: TransferActivityLog_Status, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.statusCode !== "") {
      writer.uint32(10).string(message.statusCode);
    }
    if (message.errorType !== "") {
      writer.uint32(18).string(message.errorType);
    }
    if (message.errorMessage !== "") {
      writer.uint32(26).string(message.errorMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TransferActivityLog_Status {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTransferActivityLog_Status();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.statusCode = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.errorType = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.errorMessage = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TransferActivityLog_Status {
    return {
      statusCode: isSet(object.statusCode) ? globalThis.String(object.statusCode) : "",
      errorType: isSet(object.errorType) ? globalThis.String(object.errorType) : "",
      errorMessage: isSet(object.errorMessage) ? globalThis.String(object.errorMessage) : "",
    };
  },

  toJSON(message: TransferActivityLog_Status): unknown {
    const obj: any = {};
    if (message.statusCode !== "") {
      obj.statusCode = message.statusCode;
    }
    if (message.errorType !== "") {
      obj.errorType = message.errorType;
    }
    if (message.errorMessage !== "") {
      obj.errorMessage = message.errorMessage;
    }
    return obj;
  },

  create(base?: DeepPartial<TransferActivityLog_Status>): TransferActivityLog_Status {
    return TransferActivityLog_Status.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TransferActivityLog_Status>): TransferActivityLog_Status {
    const message = createBaseTransferActivityLog_Status();
    message.statusCode = object.statusCode ?? "";
    message.errorType = object.errorType ?? "";
    message.errorMessage = object.errorMessage ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
