// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/bigtable/admin/v2/bigtable_table_admin.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import {
  GetIamPolicyRequest,
  SetIamPolicyRequest,
  TestIamPermissionsRequest,
  TestIamPermissionsResponse,
} from "../../../iam/v1/iam_policy.js";
import { Policy } from "../../../iam/v1/policy.js";
import { Operation } from "../../../longrunning/operations.js";
import { Duration } from "../../../protobuf/duration.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { OperationProgress } from "./common.js";
import {
  AuthorizedView,
  AuthorizedView_ResponseView,
  authorizedView_ResponseViewFromJSON,
  authorizedView_ResponseViewToJSON,
  Backup,
  BackupInfo,
  ColumnFamily,
  RestoreSourceType,
  restoreSourceTypeFromJSON,
  restoreSourceTypeToJSON,
  Snapshot,
  Table,
  Table_View,
  table_ViewFromJSON,
  table_ViewToJSON,
} from "./table.js";

export const protobufPackage = "google.bigtable.admin.v2";

/**
 * The request for
 * [RestoreTable][google.bigtable.admin.v2.BigtableTableAdmin.RestoreTable].
 */
export interface RestoreTableRequest {
  /**
   * Required. The name of the instance in which to create the restored
   * table. Values are of the form `projects/<project>/instances/<instance>`.
   */
  parent: string;
  /**
   * Required. The id of the table to create and restore to. This
   * table must not already exist. The `table_id` appended to
   * `parent` forms the full table name of the form
   * `projects/<project>/instances/<instance>/tables/<table_id>`.
   */
  tableId: string;
  /**
   * Name of the backup from which to restore.  Values are of the form
   * `projects/<project>/instances/<instance>/clusters/<cluster>/backups/<backup>`.
   */
  backup?: string | undefined;
}

/**
 * Metadata type for the long-running operation returned by
 * [RestoreTable][google.bigtable.admin.v2.BigtableTableAdmin.RestoreTable].
 */
export interface RestoreTableMetadata {
  /** Name of the table being created and restored to. */
  name: string;
  /** The type of the restore source. */
  sourceType: RestoreSourceType;
  backupInfo?:
    | BackupInfo
    | undefined;
  /**
   * If exists, the name of the long-running operation that will be used to
   * track the post-restore optimization process to optimize the performance of
   * the restored table. The metadata type of the long-running operation is
   * [OptimizeRestoreTableMetadata][]. The response type is
   * [Empty][google.protobuf.Empty]. This long-running operation may be
   * automatically created by the system if applicable after the
   * RestoreTable long-running operation completes successfully. This operation
   * may not be created if the table is already optimized or the restore was
   * not successful.
   */
  optimizeTableOperationName: string;
  /**
   * The progress of the
   * [RestoreTable][google.bigtable.admin.v2.BigtableTableAdmin.RestoreTable]
   * operation.
   */
  progress: OperationProgress | undefined;
}

/**
 * Metadata type for the long-running operation used to track the progress
 * of optimizations performed on a newly restored table. This long-running
 * operation is automatically created by the system after the successful
 * completion of a table restore, and cannot be cancelled.
 */
export interface OptimizeRestoredTableMetadata {
  /** Name of the restored table being optimized. */
  name: string;
  /** The progress of the post-restore optimizations. */
  progress: OperationProgress | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.CreateTable][google.bigtable.admin.v2.BigtableTableAdmin.CreateTable]
 */
export interface CreateTableRequest {
  /**
   * Required. The unique name of the instance in which to create the table.
   * Values are of the form `projects/{project}/instances/{instance}`.
   */
  parent: string;
  /**
   * Required. The name by which the new table should be referred to within the
   * parent instance, e.g., `foobar` rather than `{parent}/tables/foobar`.
   * Maximum 50 characters.
   */
  tableId: string;
  /** Required. The Table to create. */
  table:
    | Table
    | undefined;
  /**
   * The optional list of row keys that will be used to initially split the
   * table into several tablets (tablets are similar to HBase regions).
   * Given two split keys, `s1` and `s2`, three tablets will be created,
   * spanning the key ranges: `[, s1), [s1, s2), [s2, )`.
   *
   * Example:
   *
   * * Row keys := `["a", "apple", "custom", "customer_1", "customer_2",`
   *                `"other", "zz"]`
   * * initial_split_keys := `["apple", "customer_1", "customer_2", "other"]`
   * * Key assignment:
   *     - Tablet 1 `[, apple)                => {"a"}.`
   *     - Tablet 2 `[apple, customer_1)      => {"apple", "custom"}.`
   *     - Tablet 3 `[customer_1, customer_2) => {"customer_1"}.`
   *     - Tablet 4 `[customer_2, other)      => {"customer_2"}.`
   *     - Tablet 5 `[other, )                => {"other", "zz"}.`
   */
  initialSplits: CreateTableRequest_Split[];
}

/** An initial split point for a newly created table. */
export interface CreateTableRequest_Split {
  /** Row key to use as an initial tablet boundary. */
  key: Buffer;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.CreateTableFromSnapshot][google.bigtable.admin.v2.BigtableTableAdmin.CreateTableFromSnapshot]
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface CreateTableFromSnapshotRequest {
  /**
   * Required. The unique name of the instance in which to create the table.
   * Values are of the form `projects/{project}/instances/{instance}`.
   */
  parent: string;
  /**
   * Required. The name by which the new table should be referred to within the
   * parent instance, e.g., `foobar` rather than `{parent}/tables/foobar`.
   */
  tableId: string;
  /**
   * Required. The unique name of the snapshot from which to restore the table.
   * The snapshot and the table must be in the same instance. Values are of the
   * form
   * `projects/{project}/instances/{instance}/clusters/{cluster}/snapshots/{snapshot}`.
   */
  sourceSnapshot: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.DropRowRange][google.bigtable.admin.v2.BigtableTableAdmin.DropRowRange]
 */
export interface DropRowRangeRequest {
  /**
   * Required. The unique name of the table on which to drop a range of rows.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
  /**
   * Delete all rows that start with this row key prefix. Prefix cannot be
   * zero length.
   */
  rowKeyPrefix?:
    | Buffer
    | undefined;
  /** Delete all rows in the table. Setting this to false is a no-op. */
  deleteAllDataFromTable?: boolean | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ListTables][google.bigtable.admin.v2.BigtableTableAdmin.ListTables]
 */
export interface ListTablesRequest {
  /**
   * Required. The unique name of the instance for which tables should be
   * listed. Values are of the form `projects/{project}/instances/{instance}`.
   */
  parent: string;
  /**
   * The view to be applied to the returned tables' fields.
   * NAME_ONLY view (default) and REPLICATION_VIEW are supported.
   */
  view: Table_View;
  /**
   * Maximum number of results per page.
   *
   * A page_size of zero lets the server choose the number of items to return.
   * A page_size which is strictly positive will return at most that many items.
   * A negative page_size will cause an error.
   *
   * Following the first request, subsequent paginated calls are not required
   * to pass a page_size. If a page_size is set in subsequent calls, it must
   * match the page_size given in the first request.
   */
  pageSize: number;
  /** The value of `next_page_token` returned by a previous call. */
  pageToken: string;
}

/**
 * Response message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ListTables][google.bigtable.admin.v2.BigtableTableAdmin.ListTables]
 */
export interface ListTablesResponse {
  /** The tables present in the requested instance. */
  tables: Table[];
  /**
   * Set if not all tables could be returned in a single response.
   * Pass this value to `page_token` in another request to get the next
   * page of results.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.GetTable][google.bigtable.admin.v2.BigtableTableAdmin.GetTable]
 */
export interface GetTableRequest {
  /**
   * Required. The unique name of the requested table.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
  /**
   * The view to be applied to the returned table's fields.
   * Defaults to `SCHEMA_VIEW` if unspecified.
   */
  view: Table_View;
}

/**
 * The request for
 * [UpdateTable][google.bigtable.admin.v2.BigtableTableAdmin.UpdateTable].
 */
export interface UpdateTableRequest {
  /**
   * Required. The table to update.
   * The table's `name` field is used to identify the table to update.
   */
  table:
    | Table
    | undefined;
  /**
   * Required. The list of fields to update.
   * A mask specifying which fields (e.g. `change_stream_config`) in the `table`
   * field should be updated. This mask is relative to the `table` field, not to
   * the request message. The wildcard (*) path is currently not supported.
   * Currently UpdateTable is only supported for the following fields:
   *
   * * `change_stream_config`
   * * `change_stream_config.retention_period`
   * * `deletion_protection`
   *
   * If `column_families` is set in `update_mask`, it will return an
   * UNIMPLEMENTED error.
   */
  updateMask: string[] | undefined;
}

/**
 * Metadata type for the operation returned by
 * [UpdateTable][google.bigtable.admin.v2.BigtableTableAdmin.UpdateTable].
 */
export interface UpdateTableMetadata {
  /** The name of the table being updated. */
  name: string;
  /** The time at which this operation started. */
  startTime:
    | Date
    | undefined;
  /** If set, the time at which this operation finished or was canceled. */
  endTime: Date | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.DeleteTable][google.bigtable.admin.v2.BigtableTableAdmin.DeleteTable]
 */
export interface DeleteTableRequest {
  /**
   * Required. The unique name of the table to be deleted.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.UndeleteTable][google.bigtable.admin.v2.BigtableTableAdmin.UndeleteTable]
 */
export interface UndeleteTableRequest {
  /**
   * Required. The unique name of the table to be restored.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
}

/**
 * Metadata type for the operation returned by
 * [google.bigtable.admin.v2.BigtableTableAdmin.UndeleteTable][google.bigtable.admin.v2.BigtableTableAdmin.UndeleteTable].
 */
export interface UndeleteTableMetadata {
  /** The name of the table being restored. */
  name: string;
  /** The time at which this operation started. */
  startTime:
    | Date
    | undefined;
  /** If set, the time at which this operation finished or was cancelled. */
  endTime: Date | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ModifyColumnFamilies][google.bigtable.admin.v2.BigtableTableAdmin.ModifyColumnFamilies]
 */
export interface ModifyColumnFamiliesRequest {
  /**
   * Required. The unique name of the table whose families should be modified.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
  /**
   * Required. Modifications to be atomically applied to the specified table's
   * families. Entries are applied in order, meaning that earlier modifications
   * can be masked by later ones (in the case of repeated updates to the same
   * family, for example).
   */
  modifications: ModifyColumnFamiliesRequest_Modification[];
  /** Optional. If true, ignore safety checks when modifying the column families. */
  ignoreWarnings: boolean;
}

/** A create, update, or delete of a particular column family. */
export interface ModifyColumnFamiliesRequest_Modification {
  /** The ID of the column family to be modified. */
  id: string;
  /**
   * Create a new column family with the specified schema, or fail if
   * one already exists with the given ID.
   */
  create?:
    | ColumnFamily
    | undefined;
  /**
   * Update an existing column family to the specified schema, or fail
   * if no column family exists with the given ID.
   */
  update?:
    | ColumnFamily
    | undefined;
  /**
   * Drop (delete) the column family with the given ID, or fail if no such
   * family exists.
   */
  drop?:
    | boolean
    | undefined;
  /**
   * Optional. A mask specifying which fields (e.g. `gc_rule`) in the `update`
   * mod should be updated, ignored for other modification types. If unset or
   * empty, we treat it as updating `gc_rule` to be backward compatible.
   */
  updateMask: string[] | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.GenerateConsistencyToken][google.bigtable.admin.v2.BigtableTableAdmin.GenerateConsistencyToken]
 */
export interface GenerateConsistencyTokenRequest {
  /**
   * Required. The unique name of the Table for which to create a consistency
   * token. Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
}

/**
 * Response message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.GenerateConsistencyToken][google.bigtable.admin.v2.BigtableTableAdmin.GenerateConsistencyToken]
 */
export interface GenerateConsistencyTokenResponse {
  /** The generated consistency token. */
  consistencyToken: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.CheckConsistency][google.bigtable.admin.v2.BigtableTableAdmin.CheckConsistency]
 */
export interface CheckConsistencyRequest {
  /**
   * Required. The unique name of the Table for which to check replication
   * consistency. Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
  /** Required. The token created using GenerateConsistencyToken for the Table. */
  consistencyToken: string;
  /**
   * Checks that reads using an app profile with `StandardIsolation` can
   * see all writes committed before the token was created, even if the
   * read and write target different clusters.
   */
  standardReadRemoteWrites?:
    | StandardReadRemoteWrites
    | undefined;
  /**
   * Checks that reads using an app profile with `DataBoostIsolationReadOnly`
   * can see all writes committed before the token was created, but only if
   * the read and write target the same cluster.
   */
  dataBoostReadLocalWrites?: DataBoostReadLocalWrites | undefined;
}

/**
 * Checks that all writes before the consistency token was generated are
 * replicated in every cluster and readable.
 */
export interface StandardReadRemoteWrites {
}

/**
 * Checks that all writes before the consistency token was generated in the same
 * cluster are readable by Databoost.
 */
export interface DataBoostReadLocalWrites {
}

/**
 * Response message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.CheckConsistency][google.bigtable.admin.v2.BigtableTableAdmin.CheckConsistency]
 */
export interface CheckConsistencyResponse {
  /**
   * True only if the token is consistent. A token is consistent if replication
   * has caught up with the restrictions specified in the request.
   */
  consistent: boolean;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.SnapshotTable][google.bigtable.admin.v2.BigtableTableAdmin.SnapshotTable]
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface SnapshotTableRequest {
  /**
   * Required. The unique name of the table to have the snapshot taken.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  name: string;
  /**
   * Required. The name of the cluster where the snapshot will be created in.
   * Values are of the form
   * `projects/{project}/instances/{instance}/clusters/{cluster}`.
   */
  cluster: string;
  /**
   * Required. The ID by which the new snapshot should be referred to within the
   * parent cluster, e.g., `mysnapshot` of the form:
   * `[_a-zA-Z0-9][-_.a-zA-Z0-9]*` rather than
   * `projects/{project}/instances/{instance}/clusters/{cluster}/snapshots/mysnapshot`.
   */
  snapshotId: string;
  /**
   * The amount of time that the new snapshot can stay active after it is
   * created. Once 'ttl' expires, the snapshot will get deleted. The maximum
   * amount of time a snapshot can stay active is 7 days. If 'ttl' is not
   * specified, the default value of 24 hours will be used.
   */
  ttl:
    | Duration
    | undefined;
  /** Description of the snapshot. */
  description: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.GetSnapshot][google.bigtable.admin.v2.BigtableTableAdmin.GetSnapshot]
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface GetSnapshotRequest {
  /**
   * Required. The unique name of the requested snapshot.
   * Values are of the form
   * `projects/{project}/instances/{instance}/clusters/{cluster}/snapshots/{snapshot}`.
   */
  name: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ListSnapshots][google.bigtable.admin.v2.BigtableTableAdmin.ListSnapshots]
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface ListSnapshotsRequest {
  /**
   * Required. The unique name of the cluster for which snapshots should be
   * listed. Values are of the form
   * `projects/{project}/instances/{instance}/clusters/{cluster}`.
   * Use `{cluster} = '-'` to list snapshots for all clusters in an instance,
   * e.g., `projects/{project}/instances/{instance}/clusters/-`.
   */
  parent: string;
  /**
   * The maximum number of snapshots to return per page.
   * CURRENTLY UNIMPLEMENTED AND IGNORED.
   */
  pageSize: number;
  /** The value of `next_page_token` returned by a previous call. */
  pageToken: string;
}

/**
 * Response message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ListSnapshots][google.bigtable.admin.v2.BigtableTableAdmin.ListSnapshots]
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface ListSnapshotsResponse {
  /** The snapshots present in the requested cluster. */
  snapshots: Snapshot[];
  /**
   * Set if not all snapshots could be returned in a single response.
   * Pass this value to `page_token` in another request to get the next
   * page of results.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.DeleteSnapshot][google.bigtable.admin.v2.BigtableTableAdmin.DeleteSnapshot]
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface DeleteSnapshotRequest {
  /**
   * Required. The unique name of the snapshot to be deleted.
   * Values are of the form
   * `projects/{project}/instances/{instance}/clusters/{cluster}/snapshots/{snapshot}`.
   */
  name: string;
}

/**
 * The metadata for the Operation returned by SnapshotTable.
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface SnapshotTableMetadata {
  /** The request that prompted the initiation of this SnapshotTable operation. */
  originalRequest:
    | SnapshotTableRequest
    | undefined;
  /** The time at which the original request was received. */
  requestTime:
    | Date
    | undefined;
  /** The time at which the operation failed or was completed successfully. */
  finishTime: Date | undefined;
}

/**
 * The metadata for the Operation returned by CreateTableFromSnapshot.
 *
 * Note: This is a private alpha release of Cloud Bigtable snapshots. This
 * feature is not currently available to most Cloud Bigtable customers. This
 * feature might be changed in backward-incompatible ways and is not recommended
 * for production use. It is not subject to any SLA or deprecation policy.
 */
export interface CreateTableFromSnapshotMetadata {
  /**
   * The request that prompted the initiation of this CreateTableFromSnapshot
   * operation.
   */
  originalRequest:
    | CreateTableFromSnapshotRequest
    | undefined;
  /** The time at which the original request was received. */
  requestTime:
    | Date
    | undefined;
  /** The time at which the operation failed or was completed successfully. */
  finishTime: Date | undefined;
}

/**
 * The request for
 * [CreateBackup][google.bigtable.admin.v2.BigtableTableAdmin.CreateBackup].
 */
export interface CreateBackupRequest {
  /**
   * Required. This must be one of the clusters in the instance in which this
   * table is located. The backup will be stored in this cluster. Values are
   * of the form `projects/{project}/instances/{instance}/clusters/{cluster}`.
   */
  parent: string;
  /**
   * Required. The id of the backup to be created. The `backup_id` along with
   * the parent `parent` are combined as {parent}/backups/{backup_id} to create
   * the full backup name, of the form:
   * `projects/{project}/instances/{instance}/clusters/{cluster}/backups/{backup_id}`.
   * This string must be between 1 and 50 characters in length and match the
   * regex [_a-zA-Z0-9][-_.a-zA-Z0-9]*.
   */
  backupId: string;
  /** Required. The backup to create. */
  backup: Backup | undefined;
}

/**
 * Metadata type for the operation returned by
 * [CreateBackup][google.bigtable.admin.v2.BigtableTableAdmin.CreateBackup].
 */
export interface CreateBackupMetadata {
  /** The name of the backup being created. */
  name: string;
  /** The name of the table the backup is created from. */
  sourceTable: string;
  /** The time at which this operation started. */
  startTime:
    | Date
    | undefined;
  /** If set, the time at which this operation finished or was cancelled. */
  endTime: Date | undefined;
}

/**
 * The request for
 * [UpdateBackup][google.bigtable.admin.v2.BigtableTableAdmin.UpdateBackup].
 */
export interface UpdateBackupRequest {
  /**
   * Required. The backup to update. `backup.name`, and the fields to be updated
   * as specified by `update_mask` are required. Other fields are ignored.
   * Update is only supported for the following fields:
   *
   *  * `backup.expire_time`.
   */
  backup:
    | Backup
    | undefined;
  /**
   * Required. A mask specifying which fields (e.g. `expire_time`) in the
   * Backup resource should be updated. This mask is relative to the Backup
   * resource, not to the request message. The field mask must always be
   * specified; this prevents any future fields from being erased accidentally
   * by clients that do not know about them.
   */
  updateMask: string[] | undefined;
}

/**
 * The request for
 * [GetBackup][google.bigtable.admin.v2.BigtableTableAdmin.GetBackup].
 */
export interface GetBackupRequest {
  /**
   * Required. Name of the backup.
   * Values are of the form
   * `projects/{project}/instances/{instance}/clusters/{cluster}/backups/{backup}`.
   */
  name: string;
}

/**
 * The request for
 * [DeleteBackup][google.bigtable.admin.v2.BigtableTableAdmin.DeleteBackup].
 */
export interface DeleteBackupRequest {
  /**
   * Required. Name of the backup to delete.
   * Values are of the form
   * `projects/{project}/instances/{instance}/clusters/{cluster}/backups/{backup}`.
   */
  name: string;
}

/**
 * The request for
 * [ListBackups][google.bigtable.admin.v2.BigtableTableAdmin.ListBackups].
 */
export interface ListBackupsRequest {
  /**
   * Required. The cluster to list backups from.  Values are of the
   * form `projects/{project}/instances/{instance}/clusters/{cluster}`.
   * Use `{cluster} = '-'` to list backups for all clusters in an instance,
   * e.g., `projects/{project}/instances/{instance}/clusters/-`.
   */
  parent: string;
  /**
   * A filter expression that filters backups listed in the response.
   * The expression must specify the field name, a comparison operator,
   * and the value that you want to use for filtering. The value must be a
   * string, a number, or a boolean. The comparison operator must be
   * <, >, <=, >=, !=, =, or :. Colon ':' represents a HAS operator which is
   * roughly synonymous with equality. Filter rules are case insensitive.
   *
   * The fields eligible for filtering are:
   *
   * * `name`
   * * `source_table`
   * * `state`
   * * `start_time` (and values are of the format YYYY-MM-DDTHH:MM:SSZ)
   * * `end_time` (and values are of the format YYYY-MM-DDTHH:MM:SSZ)
   * * `expire_time` (and values are of the format YYYY-MM-DDTHH:MM:SSZ)
   * * `size_bytes`
   *
   * To filter on multiple expressions, provide each separate expression within
   * parentheses. By default, each expression is an AND expression. However,
   * you can include AND, OR, and NOT expressions explicitly.
   *
   * Some examples of using filters are:
   *
   * * `name:"exact"` --> The backup's name is the string "exact".
   * * `name:howl` --> The backup's name contains the string "howl".
   * * `source_table:prod`
   *        --> The source_table's name contains the string "prod".
   * * `state:CREATING` --> The backup is pending creation.
   * * `state:READY` --> The backup is fully created and ready for use.
   * * `(name:howl) AND (start_time < \"2018-03-28T14:50:00Z\")`
   *        --> The backup name contains the string "howl" and start_time
   *            of the backup is before 2018-03-28T14:50:00Z.
   * * `size_bytes > 10000000000` --> The backup's size is greater than 10GB
   */
  filter: string;
  /**
   * An expression for specifying the sort order of the results of the request.
   * The string value should specify one or more fields in
   * [Backup][google.bigtable.admin.v2.Backup]. The full syntax is described at
   * https://aip.dev/132#ordering.
   *
   * Fields supported are:
   *
   * * name
   * * source_table
   * * expire_time
   * * start_time
   * * end_time
   * * size_bytes
   * * state
   *
   * For example, "start_time". The default sorting order is ascending.
   * To specify descending order for the field, a suffix " desc" should
   * be appended to the field name. For example, "start_time desc".
   * Redundant space characters in the syntax are insigificant.
   *
   * If order_by is empty, results will be sorted by `start_time` in descending
   * order starting from the most recently created backup.
   */
  orderBy: string;
  /**
   * Number of backups to be returned in the response. If 0 or
   * less, defaults to the server's maximum allowed page size.
   */
  pageSize: number;
  /**
   * If non-empty, `page_token` should contain a
   * [next_page_token][google.bigtable.admin.v2.ListBackupsResponse.next_page_token]
   * from a previous
   * [ListBackupsResponse][google.bigtable.admin.v2.ListBackupsResponse] to the
   * same `parent` and with the same `filter`.
   */
  pageToken: string;
}

/**
 * The response for
 * [ListBackups][google.bigtable.admin.v2.BigtableTableAdmin.ListBackups].
 */
export interface ListBackupsResponse {
  /** The list of matching backups. */
  backups: Backup[];
  /**
   * `next_page_token` can be sent in a subsequent
   * [ListBackups][google.bigtable.admin.v2.BigtableTableAdmin.ListBackups] call
   * to fetch more of the matching backups.
   */
  nextPageToken: string;
}

/**
 * The request for
 * [CopyBackup][google.bigtable.admin.v2.BigtableTableAdmin.CopyBackup].
 */
export interface CopyBackupRequest {
  /**
   * Required. The name of the destination cluster that will contain the backup
   * copy. The cluster must already exist. Values are of the form:
   * `projects/{project}/instances/{instance}/clusters/{cluster}`.
   */
  parent: string;
  /**
   * Required. The id of the new backup. The `backup_id` along with `parent`
   * are combined as {parent}/backups/{backup_id} to create the full backup
   * name, of the form:
   * `projects/{project}/instances/{instance}/clusters/{cluster}/backups/{backup_id}`.
   * This string must be between 1 and 50 characters in length and match the
   * regex [_a-zA-Z0-9][-_.a-zA-Z0-9]*.
   */
  backupId: string;
  /**
   * Required. The source backup to be copied from.
   * The source backup needs to be in READY state for it to be copied.
   * Copying a copied backup is not allowed.
   * Once CopyBackup is in progress, the source backup cannot be deleted or
   * cleaned up on expiration until CopyBackup is finished.
   * Values are of the form:
   * `projects/<project>/instances/<instance>/clusters/<cluster>/backups/<backup>`.
   */
  sourceBackup: string;
  /**
   * Required. Required. The expiration time of the copied backup with
   * microsecond granularity that must be at least 6 hours and at most 30 days
   * from the time the request is received. Once the `expire_time` has
   * passed, Cloud Bigtable will delete the backup and free the resources used
   * by the backup.
   */
  expireTime: Date | undefined;
}

/**
 * Metadata type for the google.longrunning.Operation returned by
 * [CopyBackup][google.bigtable.admin.v2.BigtableTableAdmin.CopyBackup].
 */
export interface CopyBackupMetadata {
  /**
   * The name of the backup being created through the copy operation.
   * Values are of the form
   * `projects/<project>/instances/<instance>/clusters/<cluster>/backups/<backup>`.
   */
  name: string;
  /** Information about the source backup that is being copied from. */
  sourceBackupInfo:
    | BackupInfo
    | undefined;
  /**
   * The progress of the
   * [CopyBackup][google.bigtable.admin.v2.BigtableTableAdmin.CopyBackup]
   * operation.
   */
  progress: OperationProgress | undefined;
}

/**
 * The request for
 * [CreateAuthorizedView][google.bigtable.admin.v2.BigtableTableAdmin.CreateAuthorizedView]
 */
export interface CreateAuthorizedViewRequest {
  /**
   * Required. This is the name of the table the AuthorizedView belongs to.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  parent: string;
  /**
   * Required. The id of the AuthorizedView to create. This AuthorizedView must
   * not already exist. The `authorized_view_id` appended to `parent` forms the
   * full AuthorizedView name of the form
   * `projects/{project}/instances/{instance}/tables/{table}/authorizedView/{authorized_view}`.
   */
  authorizedViewId: string;
  /** Required. The AuthorizedView to create. */
  authorizedView: AuthorizedView | undefined;
}

/** The metadata for the Operation returned by CreateAuthorizedView. */
export interface CreateAuthorizedViewMetadata {
  /** The request that prompted the initiation of this CreateInstance operation. */
  originalRequest:
    | CreateAuthorizedViewRequest
    | undefined;
  /** The time at which the original request was received. */
  requestTime:
    | Date
    | undefined;
  /** The time at which the operation failed or was completed successfully. */
  finishTime: Date | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ListAuthorizedViews][google.bigtable.admin.v2.BigtableTableAdmin.ListAuthorizedViews]
 */
export interface ListAuthorizedViewsRequest {
  /**
   * Required. The unique name of the table for which AuthorizedViews should be
   * listed. Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}`.
   */
  parent: string;
  /**
   * Optional. Maximum number of results per page.
   *
   * A page_size of zero lets the server choose the number of items to return.
   * A page_size which is strictly positive will return at most that many items.
   * A negative page_size will cause an error.
   *
   * Following the first request, subsequent paginated calls are not required
   * to pass a page_size. If a page_size is set in subsequent calls, it must
   * match the page_size given in the first request.
   */
  pageSize: number;
  /** Optional. The value of `next_page_token` returned by a previous call. */
  pageToken: string;
  /**
   * Optional. The resource_view to be applied to the returned views' fields.
   * Default to NAME_ONLY.
   */
  view: AuthorizedView_ResponseView;
}

/**
 * Response message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.ListAuthorizedViews][google.bigtable.admin.v2.BigtableTableAdmin.ListAuthorizedViews]
 */
export interface ListAuthorizedViewsResponse {
  /** The AuthorizedViews present in the requested table. */
  authorizedViews: AuthorizedView[];
  /**
   * Set if not all tables could be returned in a single response.
   * Pass this value to `page_token` in another request to get the next
   * page of results.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.GetAuthorizedView][google.bigtable.admin.v2.BigtableTableAdmin.GetAuthorizedView]
 */
export interface GetAuthorizedViewRequest {
  /**
   * Required. The unique name of the requested AuthorizedView.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}/authorizedViews/{authorized_view}`.
   */
  name: string;
  /**
   * Optional. The resource_view to be applied to the returned AuthorizedView's
   * fields. Default to BASIC.
   */
  view: AuthorizedView_ResponseView;
}

/**
 * The request for
 * [UpdateAuthorizedView][google.bigtable.admin.v2.BigtableTableAdmin.UpdateAuthorizedView].
 */
export interface UpdateAuthorizedViewRequest {
  /**
   * Required. The AuthorizedView to update. The `name` in `authorized_view` is
   * used to identify the AuthorizedView. AuthorizedView name must in this
   * format
   * projects/<project>/instances/<instance>/tables/<table>/authorizedViews/<authorized_view>
   */
  authorizedView:
    | AuthorizedView
    | undefined;
  /**
   * Optional. The list of fields to update.
   * A mask specifying which fields in the AuthorizedView resource should be
   * updated. This mask is relative to the AuthorizedView resource, not to the
   * request message. A field will be overwritten if it is in the mask. If
   * empty, all fields set in the request will be overwritten. A special value
   * `*` means to overwrite all fields (including fields not set in the
   * request).
   */
  updateMask:
    | string[]
    | undefined;
  /**
   * Optional. If true, ignore the safety checks when updating the
   * AuthorizedView.
   */
  ignoreWarnings: boolean;
}

/**
 * Metadata for the google.longrunning.Operation returned by
 * [UpdateAuthorizedView][google.bigtable.admin.v2.BigtableTableAdmin.UpdateAuthorizedView].
 */
export interface UpdateAuthorizedViewMetadata {
  /**
   * The request that prompted the initiation of this UpdateAuthorizedView
   * operation.
   */
  originalRequest:
    | UpdateAuthorizedViewRequest
    | undefined;
  /** The time at which the original request was received. */
  requestTime:
    | Date
    | undefined;
  /** The time at which the operation failed or was completed successfully. */
  finishTime: Date | undefined;
}

/**
 * Request message for
 * [google.bigtable.admin.v2.BigtableTableAdmin.DeleteAuthorizedView][google.bigtable.admin.v2.BigtableTableAdmin.DeleteAuthorizedView]
 */
export interface DeleteAuthorizedViewRequest {
  /**
   * Required. The unique name of the AuthorizedView to be deleted.
   * Values are of the form
   * `projects/{project}/instances/{instance}/tables/{table}/authorizedViews/{authorized_view}`.
   */
  name: string;
  /**
   * Optional. The current etag of the AuthorizedView.
   * If an etag is provided and does not match the current etag of the
   * AuthorizedView, deletion will be blocked and an ABORTED error will be
   * returned.
   */
  etag: string;
}

function createBaseRestoreTableRequest(): RestoreTableRequest {
  return { parent: "", tableId: "", backup: undefined };
}

export const RestoreTableRequest: MessageFns<RestoreTableRequest> = {
  encode(message: RestoreTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.tableId !== "") {
      writer.uint32(18).string(message.tableId);
    }
    if (message.backup !== undefined) {
      writer.uint32(26).string(message.backup);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tableId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backup = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreTableRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      tableId: isSet(object.tableId) ? globalThis.String(object.tableId) : "",
      backup: isSet(object.backup) ? globalThis.String(object.backup) : undefined,
    };
  },

  toJSON(message: RestoreTableRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.tableId !== "") {
      obj.tableId = message.tableId;
    }
    if (message.backup !== undefined) {
      obj.backup = message.backup;
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreTableRequest>): RestoreTableRequest {
    return RestoreTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreTableRequest>): RestoreTableRequest {
    const message = createBaseRestoreTableRequest();
    message.parent = object.parent ?? "";
    message.tableId = object.tableId ?? "";
    message.backup = object.backup ?? undefined;
    return message;
  },
};

function createBaseRestoreTableMetadata(): RestoreTableMetadata {
  return { name: "", sourceType: 0, backupInfo: undefined, optimizeTableOperationName: "", progress: undefined };
}

export const RestoreTableMetadata: MessageFns<RestoreTableMetadata> = {
  encode(message: RestoreTableMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sourceType !== 0) {
      writer.uint32(16).int32(message.sourceType);
    }
    if (message.backupInfo !== undefined) {
      BackupInfo.encode(message.backupInfo, writer.uint32(26).fork()).join();
    }
    if (message.optimizeTableOperationName !== "") {
      writer.uint32(34).string(message.optimizeTableOperationName);
    }
    if (message.progress !== undefined) {
      OperationProgress.encode(message.progress, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreTableMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreTableMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sourceType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backupInfo = BackupInfo.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.optimizeTableOperationName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.progress = OperationProgress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreTableMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sourceType: isSet(object.sourceType) ? restoreSourceTypeFromJSON(object.sourceType) : 0,
      backupInfo: isSet(object.backupInfo) ? BackupInfo.fromJSON(object.backupInfo) : undefined,
      optimizeTableOperationName: isSet(object.optimizeTableOperationName)
        ? globalThis.String(object.optimizeTableOperationName)
        : "",
      progress: isSet(object.progress) ? OperationProgress.fromJSON(object.progress) : undefined,
    };
  },

  toJSON(message: RestoreTableMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sourceType !== 0) {
      obj.sourceType = restoreSourceTypeToJSON(message.sourceType);
    }
    if (message.backupInfo !== undefined) {
      obj.backupInfo = BackupInfo.toJSON(message.backupInfo);
    }
    if (message.optimizeTableOperationName !== "") {
      obj.optimizeTableOperationName = message.optimizeTableOperationName;
    }
    if (message.progress !== undefined) {
      obj.progress = OperationProgress.toJSON(message.progress);
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreTableMetadata>): RestoreTableMetadata {
    return RestoreTableMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreTableMetadata>): RestoreTableMetadata {
    const message = createBaseRestoreTableMetadata();
    message.name = object.name ?? "";
    message.sourceType = object.sourceType ?? 0;
    message.backupInfo = (object.backupInfo !== undefined && object.backupInfo !== null)
      ? BackupInfo.fromPartial(object.backupInfo)
      : undefined;
    message.optimizeTableOperationName = object.optimizeTableOperationName ?? "";
    message.progress = (object.progress !== undefined && object.progress !== null)
      ? OperationProgress.fromPartial(object.progress)
      : undefined;
    return message;
  },
};

function createBaseOptimizeRestoredTableMetadata(): OptimizeRestoredTableMetadata {
  return { name: "", progress: undefined };
}

export const OptimizeRestoredTableMetadata: MessageFns<OptimizeRestoredTableMetadata> = {
  encode(message: OptimizeRestoredTableMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.progress !== undefined) {
      OperationProgress.encode(message.progress, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OptimizeRestoredTableMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOptimizeRestoredTableMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.progress = OperationProgress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OptimizeRestoredTableMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      progress: isSet(object.progress) ? OperationProgress.fromJSON(object.progress) : undefined,
    };
  },

  toJSON(message: OptimizeRestoredTableMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.progress !== undefined) {
      obj.progress = OperationProgress.toJSON(message.progress);
    }
    return obj;
  },

  create(base?: DeepPartial<OptimizeRestoredTableMetadata>): OptimizeRestoredTableMetadata {
    return OptimizeRestoredTableMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OptimizeRestoredTableMetadata>): OptimizeRestoredTableMetadata {
    const message = createBaseOptimizeRestoredTableMetadata();
    message.name = object.name ?? "";
    message.progress = (object.progress !== undefined && object.progress !== null)
      ? OperationProgress.fromPartial(object.progress)
      : undefined;
    return message;
  },
};

function createBaseCreateTableRequest(): CreateTableRequest {
  return { parent: "", tableId: "", table: undefined, initialSplits: [] };
}

export const CreateTableRequest: MessageFns<CreateTableRequest> = {
  encode(message: CreateTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.tableId !== "") {
      writer.uint32(18).string(message.tableId);
    }
    if (message.table !== undefined) {
      Table.encode(message.table, writer.uint32(26).fork()).join();
    }
    for (const v of message.initialSplits) {
      CreateTableRequest_Split.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tableId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.table = Table.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.initialSplits.push(CreateTableRequest_Split.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTableRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      tableId: isSet(object.tableId) ? globalThis.String(object.tableId) : "",
      table: isSet(object.table) ? Table.fromJSON(object.table) : undefined,
      initialSplits: globalThis.Array.isArray(object?.initialSplits)
        ? object.initialSplits.map((e: any) => CreateTableRequest_Split.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CreateTableRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.tableId !== "") {
      obj.tableId = message.tableId;
    }
    if (message.table !== undefined) {
      obj.table = Table.toJSON(message.table);
    }
    if (message.initialSplits?.length) {
      obj.initialSplits = message.initialSplits.map((e) => CreateTableRequest_Split.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTableRequest>): CreateTableRequest {
    return CreateTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTableRequest>): CreateTableRequest {
    const message = createBaseCreateTableRequest();
    message.parent = object.parent ?? "";
    message.tableId = object.tableId ?? "";
    message.table = (object.table !== undefined && object.table !== null) ? Table.fromPartial(object.table) : undefined;
    message.initialSplits = object.initialSplits?.map((e) => CreateTableRequest_Split.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCreateTableRequest_Split(): CreateTableRequest_Split {
  return { key: Buffer.alloc(0) };
}

export const CreateTableRequest_Split: MessageFns<CreateTableRequest_Split> = {
  encode(message: CreateTableRequest_Split, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key.length !== 0) {
      writer.uint32(10).bytes(message.key);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTableRequest_Split {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTableRequest_Split();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = Buffer.from(reader.bytes());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTableRequest_Split {
    return { key: isSet(object.key) ? Buffer.from(bytesFromBase64(object.key)) : Buffer.alloc(0) };
  },

  toJSON(message: CreateTableRequest_Split): unknown {
    const obj: any = {};
    if (message.key.length !== 0) {
      obj.key = base64FromBytes(message.key);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTableRequest_Split>): CreateTableRequest_Split {
    return CreateTableRequest_Split.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTableRequest_Split>): CreateTableRequest_Split {
    const message = createBaseCreateTableRequest_Split();
    message.key = object.key ?? Buffer.alloc(0);
    return message;
  },
};

function createBaseCreateTableFromSnapshotRequest(): CreateTableFromSnapshotRequest {
  return { parent: "", tableId: "", sourceSnapshot: "" };
}

export const CreateTableFromSnapshotRequest: MessageFns<CreateTableFromSnapshotRequest> = {
  encode(message: CreateTableFromSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.tableId !== "") {
      writer.uint32(18).string(message.tableId);
    }
    if (message.sourceSnapshot !== "") {
      writer.uint32(26).string(message.sourceSnapshot);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTableFromSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTableFromSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tableId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sourceSnapshot = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTableFromSnapshotRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      tableId: isSet(object.tableId) ? globalThis.String(object.tableId) : "",
      sourceSnapshot: isSet(object.sourceSnapshot) ? globalThis.String(object.sourceSnapshot) : "",
    };
  },

  toJSON(message: CreateTableFromSnapshotRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.tableId !== "") {
      obj.tableId = message.tableId;
    }
    if (message.sourceSnapshot !== "") {
      obj.sourceSnapshot = message.sourceSnapshot;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTableFromSnapshotRequest>): CreateTableFromSnapshotRequest {
    return CreateTableFromSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTableFromSnapshotRequest>): CreateTableFromSnapshotRequest {
    const message = createBaseCreateTableFromSnapshotRequest();
    message.parent = object.parent ?? "";
    message.tableId = object.tableId ?? "";
    message.sourceSnapshot = object.sourceSnapshot ?? "";
    return message;
  },
};

function createBaseDropRowRangeRequest(): DropRowRangeRequest {
  return { name: "", rowKeyPrefix: undefined, deleteAllDataFromTable: undefined };
}

export const DropRowRangeRequest: MessageFns<DropRowRangeRequest> = {
  encode(message: DropRowRangeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.rowKeyPrefix !== undefined) {
      writer.uint32(18).bytes(message.rowKeyPrefix);
    }
    if (message.deleteAllDataFromTable !== undefined) {
      writer.uint32(24).bool(message.deleteAllDataFromTable);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DropRowRangeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDropRowRangeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rowKeyPrefix = Buffer.from(reader.bytes());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.deleteAllDataFromTable = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DropRowRangeRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      rowKeyPrefix: isSet(object.rowKeyPrefix) ? Buffer.from(bytesFromBase64(object.rowKeyPrefix)) : undefined,
      deleteAllDataFromTable: isSet(object.deleteAllDataFromTable)
        ? globalThis.Boolean(object.deleteAllDataFromTable)
        : undefined,
    };
  },

  toJSON(message: DropRowRangeRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.rowKeyPrefix !== undefined) {
      obj.rowKeyPrefix = base64FromBytes(message.rowKeyPrefix);
    }
    if (message.deleteAllDataFromTable !== undefined) {
      obj.deleteAllDataFromTable = message.deleteAllDataFromTable;
    }
    return obj;
  },

  create(base?: DeepPartial<DropRowRangeRequest>): DropRowRangeRequest {
    return DropRowRangeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DropRowRangeRequest>): DropRowRangeRequest {
    const message = createBaseDropRowRangeRequest();
    message.name = object.name ?? "";
    message.rowKeyPrefix = object.rowKeyPrefix ?? undefined;
    message.deleteAllDataFromTable = object.deleteAllDataFromTable ?? undefined;
    return message;
  },
};

function createBaseListTablesRequest(): ListTablesRequest {
  return { parent: "", view: 0, pageSize: 0, pageToken: "" };
}

export const ListTablesRequest: MessageFns<ListTablesRequest> = {
  encode(message: ListTablesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.view !== 0) {
      writer.uint32(16).int32(message.view);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTablesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTablesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTablesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      view: isSet(object.view) ? table_ViewFromJSON(object.view) : 0,
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListTablesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.view !== 0) {
      obj.view = table_ViewToJSON(message.view);
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTablesRequest>): ListTablesRequest {
    return ListTablesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTablesRequest>): ListTablesRequest {
    const message = createBaseListTablesRequest();
    message.parent = object.parent ?? "";
    message.view = object.view ?? 0;
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListTablesResponse(): ListTablesResponse {
  return { tables: [], nextPageToken: "" };
}

export const ListTablesResponse: MessageFns<ListTablesResponse> = {
  encode(message: ListTablesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tables) {
      Table.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTablesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTablesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tables.push(Table.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTablesResponse {
    return {
      tables: globalThis.Array.isArray(object?.tables) ? object.tables.map((e: any) => Table.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTablesResponse): unknown {
    const obj: any = {};
    if (message.tables?.length) {
      obj.tables = message.tables.map((e) => Table.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTablesResponse>): ListTablesResponse {
    return ListTablesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTablesResponse>): ListTablesResponse {
    const message = createBaseListTablesResponse();
    message.tables = object.tables?.map((e) => Table.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetTableRequest(): GetTableRequest {
  return { name: "", view: 0 };
}

export const GetTableRequest: MessageFns<GetTableRequest> = {
  encode(message: GetTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.view !== 0) {
      writer.uint32(16).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetTableRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      view: isSet(object.view) ? table_ViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: GetTableRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.view !== 0) {
      obj.view = table_ViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<GetTableRequest>): GetTableRequest {
    return GetTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetTableRequest>): GetTableRequest {
    const message = createBaseGetTableRequest();
    message.name = object.name ?? "";
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseUpdateTableRequest(): UpdateTableRequest {
  return { table: undefined, updateMask: undefined };
}

export const UpdateTableRequest: MessageFns<UpdateTableRequest> = {
  encode(message: UpdateTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== undefined) {
      Table.encode(message.table, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = Table.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateTableRequest {
    return {
      table: isSet(object.table) ? Table.fromJSON(object.table) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateTableRequest): unknown {
    const obj: any = {};
    if (message.table !== undefined) {
      obj.table = Table.toJSON(message.table);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateTableRequest>): UpdateTableRequest {
    return UpdateTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateTableRequest>): UpdateTableRequest {
    const message = createBaseUpdateTableRequest();
    message.table = (object.table !== undefined && object.table !== null) ? Table.fromPartial(object.table) : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseUpdateTableMetadata(): UpdateTableMetadata {
  return { name: "", startTime: undefined, endTime: undefined };
}

export const UpdateTableMetadata: MessageFns<UpdateTableMetadata> = {
  encode(message: UpdateTableMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateTableMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateTableMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateTableMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: UpdateTableMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateTableMetadata>): UpdateTableMetadata {
    return UpdateTableMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateTableMetadata>): UpdateTableMetadata {
    const message = createBaseUpdateTableMetadata();
    message.name = object.name ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseDeleteTableRequest(): DeleteTableRequest {
  return { name: "" };
}

export const DeleteTableRequest: MessageFns<DeleteTableRequest> = {
  encode(message: DeleteTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteTableRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteTableRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteTableRequest>): DeleteTableRequest {
    return DeleteTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteTableRequest>): DeleteTableRequest {
    const message = createBaseDeleteTableRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUndeleteTableRequest(): UndeleteTableRequest {
  return { name: "" };
}

export const UndeleteTableRequest: MessageFns<UndeleteTableRequest> = {
  encode(message: UndeleteTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeleteTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeleteTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeleteTableRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: UndeleteTableRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<UndeleteTableRequest>): UndeleteTableRequest {
    return UndeleteTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UndeleteTableRequest>): UndeleteTableRequest {
    const message = createBaseUndeleteTableRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUndeleteTableMetadata(): UndeleteTableMetadata {
  return { name: "", startTime: undefined, endTime: undefined };
}

export const UndeleteTableMetadata: MessageFns<UndeleteTableMetadata> = {
  encode(message: UndeleteTableMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UndeleteTableMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUndeleteTableMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UndeleteTableMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: UndeleteTableMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<UndeleteTableMetadata>): UndeleteTableMetadata {
    return UndeleteTableMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UndeleteTableMetadata>): UndeleteTableMetadata {
    const message = createBaseUndeleteTableMetadata();
    message.name = object.name ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseModifyColumnFamiliesRequest(): ModifyColumnFamiliesRequest {
  return { name: "", modifications: [], ignoreWarnings: false };
}

export const ModifyColumnFamiliesRequest: MessageFns<ModifyColumnFamiliesRequest> = {
  encode(message: ModifyColumnFamiliesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.modifications) {
      ModifyColumnFamiliesRequest_Modification.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.ignoreWarnings !== false) {
      writer.uint32(24).bool(message.ignoreWarnings);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModifyColumnFamiliesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModifyColumnFamiliesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.modifications.push(ModifyColumnFamiliesRequest_Modification.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ignoreWarnings = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModifyColumnFamiliesRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      modifications: globalThis.Array.isArray(object?.modifications)
        ? object.modifications.map((e: any) => ModifyColumnFamiliesRequest_Modification.fromJSON(e))
        : [],
      ignoreWarnings: isSet(object.ignoreWarnings) ? globalThis.Boolean(object.ignoreWarnings) : false,
    };
  },

  toJSON(message: ModifyColumnFamiliesRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.modifications?.length) {
      obj.modifications = message.modifications.map((e) => ModifyColumnFamiliesRequest_Modification.toJSON(e));
    }
    if (message.ignoreWarnings !== false) {
      obj.ignoreWarnings = message.ignoreWarnings;
    }
    return obj;
  },

  create(base?: DeepPartial<ModifyColumnFamiliesRequest>): ModifyColumnFamiliesRequest {
    return ModifyColumnFamiliesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModifyColumnFamiliesRequest>): ModifyColumnFamiliesRequest {
    const message = createBaseModifyColumnFamiliesRequest();
    message.name = object.name ?? "";
    message.modifications = object.modifications?.map((e) => ModifyColumnFamiliesRequest_Modification.fromPartial(e)) ||
      [];
    message.ignoreWarnings = object.ignoreWarnings ?? false;
    return message;
  },
};

function createBaseModifyColumnFamiliesRequest_Modification(): ModifyColumnFamiliesRequest_Modification {
  return { id: "", create: undefined, update: undefined, drop: undefined, updateMask: undefined };
}

export const ModifyColumnFamiliesRequest_Modification: MessageFns<ModifyColumnFamiliesRequest_Modification> = {
  encode(message: ModifyColumnFamiliesRequest_Modification, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.create !== undefined) {
      ColumnFamily.encode(message.create, writer.uint32(18).fork()).join();
    }
    if (message.update !== undefined) {
      ColumnFamily.encode(message.update, writer.uint32(26).fork()).join();
    }
    if (message.drop !== undefined) {
      writer.uint32(32).bool(message.drop);
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModifyColumnFamiliesRequest_Modification {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModifyColumnFamiliesRequest_Modification();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.create = ColumnFamily.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.update = ColumnFamily.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.drop = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModifyColumnFamiliesRequest_Modification {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      create: isSet(object.create) ? ColumnFamily.fromJSON(object.create) : undefined,
      update: isSet(object.update) ? ColumnFamily.fromJSON(object.update) : undefined,
      drop: isSet(object.drop) ? globalThis.Boolean(object.drop) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: ModifyColumnFamiliesRequest_Modification): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.create !== undefined) {
      obj.create = ColumnFamily.toJSON(message.create);
    }
    if (message.update !== undefined) {
      obj.update = ColumnFamily.toJSON(message.update);
    }
    if (message.drop !== undefined) {
      obj.drop = message.drop;
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ModifyColumnFamiliesRequest_Modification>): ModifyColumnFamiliesRequest_Modification {
    return ModifyColumnFamiliesRequest_Modification.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModifyColumnFamiliesRequest_Modification>): ModifyColumnFamiliesRequest_Modification {
    const message = createBaseModifyColumnFamiliesRequest_Modification();
    message.id = object.id ?? "";
    message.create = (object.create !== undefined && object.create !== null)
      ? ColumnFamily.fromPartial(object.create)
      : undefined;
    message.update = (object.update !== undefined && object.update !== null)
      ? ColumnFamily.fromPartial(object.update)
      : undefined;
    message.drop = object.drop ?? undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGenerateConsistencyTokenRequest(): GenerateConsistencyTokenRequest {
  return { name: "" };
}

export const GenerateConsistencyTokenRequest: MessageFns<GenerateConsistencyTokenRequest> = {
  encode(message: GenerateConsistencyTokenRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateConsistencyTokenRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateConsistencyTokenRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateConsistencyTokenRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GenerateConsistencyTokenRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateConsistencyTokenRequest>): GenerateConsistencyTokenRequest {
    return GenerateConsistencyTokenRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateConsistencyTokenRequest>): GenerateConsistencyTokenRequest {
    const message = createBaseGenerateConsistencyTokenRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseGenerateConsistencyTokenResponse(): GenerateConsistencyTokenResponse {
  return { consistencyToken: "" };
}

export const GenerateConsistencyTokenResponse: MessageFns<GenerateConsistencyTokenResponse> = {
  encode(message: GenerateConsistencyTokenResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.consistencyToken !== "") {
      writer.uint32(10).string(message.consistencyToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GenerateConsistencyTokenResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenerateConsistencyTokenResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.consistencyToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenerateConsistencyTokenResponse {
    return { consistencyToken: isSet(object.consistencyToken) ? globalThis.String(object.consistencyToken) : "" };
  },

  toJSON(message: GenerateConsistencyTokenResponse): unknown {
    const obj: any = {};
    if (message.consistencyToken !== "") {
      obj.consistencyToken = message.consistencyToken;
    }
    return obj;
  },

  create(base?: DeepPartial<GenerateConsistencyTokenResponse>): GenerateConsistencyTokenResponse {
    return GenerateConsistencyTokenResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenerateConsistencyTokenResponse>): GenerateConsistencyTokenResponse {
    const message = createBaseGenerateConsistencyTokenResponse();
    message.consistencyToken = object.consistencyToken ?? "";
    return message;
  },
};

function createBaseCheckConsistencyRequest(): CheckConsistencyRequest {
  return { name: "", consistencyToken: "", standardReadRemoteWrites: undefined, dataBoostReadLocalWrites: undefined };
}

export const CheckConsistencyRequest: MessageFns<CheckConsistencyRequest> = {
  encode(message: CheckConsistencyRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.consistencyToken !== "") {
      writer.uint32(18).string(message.consistencyToken);
    }
    if (message.standardReadRemoteWrites !== undefined) {
      StandardReadRemoteWrites.encode(message.standardReadRemoteWrites, writer.uint32(26).fork()).join();
    }
    if (message.dataBoostReadLocalWrites !== undefined) {
      DataBoostReadLocalWrites.encode(message.dataBoostReadLocalWrites, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CheckConsistencyRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCheckConsistencyRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.consistencyToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.standardReadRemoteWrites = StandardReadRemoteWrites.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.dataBoostReadLocalWrites = DataBoostReadLocalWrites.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CheckConsistencyRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      consistencyToken: isSet(object.consistencyToken) ? globalThis.String(object.consistencyToken) : "",
      standardReadRemoteWrites: isSet(object.standardReadRemoteWrites)
        ? StandardReadRemoteWrites.fromJSON(object.standardReadRemoteWrites)
        : undefined,
      dataBoostReadLocalWrites: isSet(object.dataBoostReadLocalWrites)
        ? DataBoostReadLocalWrites.fromJSON(object.dataBoostReadLocalWrites)
        : undefined,
    };
  },

  toJSON(message: CheckConsistencyRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.consistencyToken !== "") {
      obj.consistencyToken = message.consistencyToken;
    }
    if (message.standardReadRemoteWrites !== undefined) {
      obj.standardReadRemoteWrites = StandardReadRemoteWrites.toJSON(message.standardReadRemoteWrites);
    }
    if (message.dataBoostReadLocalWrites !== undefined) {
      obj.dataBoostReadLocalWrites = DataBoostReadLocalWrites.toJSON(message.dataBoostReadLocalWrites);
    }
    return obj;
  },

  create(base?: DeepPartial<CheckConsistencyRequest>): CheckConsistencyRequest {
    return CheckConsistencyRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CheckConsistencyRequest>): CheckConsistencyRequest {
    const message = createBaseCheckConsistencyRequest();
    message.name = object.name ?? "";
    message.consistencyToken = object.consistencyToken ?? "";
    message.standardReadRemoteWrites =
      (object.standardReadRemoteWrites !== undefined && object.standardReadRemoteWrites !== null)
        ? StandardReadRemoteWrites.fromPartial(object.standardReadRemoteWrites)
        : undefined;
    message.dataBoostReadLocalWrites =
      (object.dataBoostReadLocalWrites !== undefined && object.dataBoostReadLocalWrites !== null)
        ? DataBoostReadLocalWrites.fromPartial(object.dataBoostReadLocalWrites)
        : undefined;
    return message;
  },
};

function createBaseStandardReadRemoteWrites(): StandardReadRemoteWrites {
  return {};
}

export const StandardReadRemoteWrites: MessageFns<StandardReadRemoteWrites> = {
  encode(_: StandardReadRemoteWrites, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StandardReadRemoteWrites {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStandardReadRemoteWrites();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): StandardReadRemoteWrites {
    return {};
  },

  toJSON(_: StandardReadRemoteWrites): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<StandardReadRemoteWrites>): StandardReadRemoteWrites {
    return StandardReadRemoteWrites.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<StandardReadRemoteWrites>): StandardReadRemoteWrites {
    const message = createBaseStandardReadRemoteWrites();
    return message;
  },
};

function createBaseDataBoostReadLocalWrites(): DataBoostReadLocalWrites {
  return {};
}

export const DataBoostReadLocalWrites: MessageFns<DataBoostReadLocalWrites> = {
  encode(_: DataBoostReadLocalWrites, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataBoostReadLocalWrites {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataBoostReadLocalWrites();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataBoostReadLocalWrites {
    return {};
  },

  toJSON(_: DataBoostReadLocalWrites): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DataBoostReadLocalWrites>): DataBoostReadLocalWrites {
    return DataBoostReadLocalWrites.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DataBoostReadLocalWrites>): DataBoostReadLocalWrites {
    const message = createBaseDataBoostReadLocalWrites();
    return message;
  },
};

function createBaseCheckConsistencyResponse(): CheckConsistencyResponse {
  return { consistent: false };
}

export const CheckConsistencyResponse: MessageFns<CheckConsistencyResponse> = {
  encode(message: CheckConsistencyResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.consistent !== false) {
      writer.uint32(8).bool(message.consistent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CheckConsistencyResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCheckConsistencyResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.consistent = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CheckConsistencyResponse {
    return { consistent: isSet(object.consistent) ? globalThis.Boolean(object.consistent) : false };
  },

  toJSON(message: CheckConsistencyResponse): unknown {
    const obj: any = {};
    if (message.consistent !== false) {
      obj.consistent = message.consistent;
    }
    return obj;
  },

  create(base?: DeepPartial<CheckConsistencyResponse>): CheckConsistencyResponse {
    return CheckConsistencyResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CheckConsistencyResponse>): CheckConsistencyResponse {
    const message = createBaseCheckConsistencyResponse();
    message.consistent = object.consistent ?? false;
    return message;
  },
};

function createBaseSnapshotTableRequest(): SnapshotTableRequest {
  return { name: "", cluster: "", snapshotId: "", ttl: undefined, description: "" };
}

export const SnapshotTableRequest: MessageFns<SnapshotTableRequest> = {
  encode(message: SnapshotTableRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.cluster !== "") {
      writer.uint32(18).string(message.cluster);
    }
    if (message.snapshotId !== "") {
      writer.uint32(26).string(message.snapshotId);
    }
    if (message.ttl !== undefined) {
      Duration.encode(message.ttl, writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SnapshotTableRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSnapshotTableRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.cluster = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.snapshotId = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.ttl = Duration.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SnapshotTableRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : "",
      snapshotId: isSet(object.snapshotId) ? globalThis.String(object.snapshotId) : "",
      ttl: isSet(object.ttl) ? Duration.fromJSON(object.ttl) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: SnapshotTableRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.cluster !== "") {
      obj.cluster = message.cluster;
    }
    if (message.snapshotId !== "") {
      obj.snapshotId = message.snapshotId;
    }
    if (message.ttl !== undefined) {
      obj.ttl = Duration.toJSON(message.ttl);
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create(base?: DeepPartial<SnapshotTableRequest>): SnapshotTableRequest {
    return SnapshotTableRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SnapshotTableRequest>): SnapshotTableRequest {
    const message = createBaseSnapshotTableRequest();
    message.name = object.name ?? "";
    message.cluster = object.cluster ?? "";
    message.snapshotId = object.snapshotId ?? "";
    message.ttl = (object.ttl !== undefined && object.ttl !== null) ? Duration.fromPartial(object.ttl) : undefined;
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseGetSnapshotRequest(): GetSnapshotRequest {
  return { name: "" };
}

export const GetSnapshotRequest: MessageFns<GetSnapshotRequest> = {
  encode(message: GetSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetSnapshotRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetSnapshotRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetSnapshotRequest>): GetSnapshotRequest {
    return GetSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetSnapshotRequest>): GetSnapshotRequest {
    const message = createBaseGetSnapshotRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListSnapshotsRequest(): ListSnapshotsRequest {
  return { parent: "", pageSize: 0, pageToken: "" };
}

export const ListSnapshotsRequest: MessageFns<ListSnapshotsRequest> = {
  encode(message: ListSnapshotsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSnapshotsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSnapshotsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSnapshotsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListSnapshotsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSnapshotsRequest>): ListSnapshotsRequest {
    return ListSnapshotsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSnapshotsRequest>): ListSnapshotsRequest {
    const message = createBaseListSnapshotsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListSnapshotsResponse(): ListSnapshotsResponse {
  return { snapshots: [], nextPageToken: "" };
}

export const ListSnapshotsResponse: MessageFns<ListSnapshotsResponse> = {
  encode(message: ListSnapshotsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.snapshots) {
      Snapshot.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListSnapshotsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListSnapshotsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshots.push(Snapshot.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListSnapshotsResponse {
    return {
      snapshots: globalThis.Array.isArray(object?.snapshots)
        ? object.snapshots.map((e: any) => Snapshot.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListSnapshotsResponse): unknown {
    const obj: any = {};
    if (message.snapshots?.length) {
      obj.snapshots = message.snapshots.map((e) => Snapshot.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListSnapshotsResponse>): ListSnapshotsResponse {
    return ListSnapshotsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListSnapshotsResponse>): ListSnapshotsResponse {
    const message = createBaseListSnapshotsResponse();
    message.snapshots = object.snapshots?.map((e) => Snapshot.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteSnapshotRequest(): DeleteSnapshotRequest {
  return { name: "" };
}

export const DeleteSnapshotRequest: MessageFns<DeleteSnapshotRequest> = {
  encode(message: DeleteSnapshotRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteSnapshotRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteSnapshotRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteSnapshotRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteSnapshotRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteSnapshotRequest>): DeleteSnapshotRequest {
    return DeleteSnapshotRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteSnapshotRequest>): DeleteSnapshotRequest {
    const message = createBaseDeleteSnapshotRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseSnapshotTableMetadata(): SnapshotTableMetadata {
  return { originalRequest: undefined, requestTime: undefined, finishTime: undefined };
}

export const SnapshotTableMetadata: MessageFns<SnapshotTableMetadata> = {
  encode(message: SnapshotTableMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.originalRequest !== undefined) {
      SnapshotTableRequest.encode(message.originalRequest, writer.uint32(10).fork()).join();
    }
    if (message.requestTime !== undefined) {
      Timestamp.encode(toTimestamp(message.requestTime), writer.uint32(18).fork()).join();
    }
    if (message.finishTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finishTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SnapshotTableMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSnapshotTableMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.originalRequest = SnapshotTableRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.finishTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SnapshotTableMetadata {
    return {
      originalRequest: isSet(object.originalRequest)
        ? SnapshotTableRequest.fromJSON(object.originalRequest)
        : undefined,
      requestTime: isSet(object.requestTime) ? fromJsonTimestamp(object.requestTime) : undefined,
      finishTime: isSet(object.finishTime) ? fromJsonTimestamp(object.finishTime) : undefined,
    };
  },

  toJSON(message: SnapshotTableMetadata): unknown {
    const obj: any = {};
    if (message.originalRequest !== undefined) {
      obj.originalRequest = SnapshotTableRequest.toJSON(message.originalRequest);
    }
    if (message.requestTime !== undefined) {
      obj.requestTime = message.requestTime.toISOString();
    }
    if (message.finishTime !== undefined) {
      obj.finishTime = message.finishTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<SnapshotTableMetadata>): SnapshotTableMetadata {
    return SnapshotTableMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SnapshotTableMetadata>): SnapshotTableMetadata {
    const message = createBaseSnapshotTableMetadata();
    message.originalRequest = (object.originalRequest !== undefined && object.originalRequest !== null)
      ? SnapshotTableRequest.fromPartial(object.originalRequest)
      : undefined;
    message.requestTime = object.requestTime ?? undefined;
    message.finishTime = object.finishTime ?? undefined;
    return message;
  },
};

function createBaseCreateTableFromSnapshotMetadata(): CreateTableFromSnapshotMetadata {
  return { originalRequest: undefined, requestTime: undefined, finishTime: undefined };
}

export const CreateTableFromSnapshotMetadata: MessageFns<CreateTableFromSnapshotMetadata> = {
  encode(message: CreateTableFromSnapshotMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.originalRequest !== undefined) {
      CreateTableFromSnapshotRequest.encode(message.originalRequest, writer.uint32(10).fork()).join();
    }
    if (message.requestTime !== undefined) {
      Timestamp.encode(toTimestamp(message.requestTime), writer.uint32(18).fork()).join();
    }
    if (message.finishTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finishTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTableFromSnapshotMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTableFromSnapshotMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.originalRequest = CreateTableFromSnapshotRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.finishTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTableFromSnapshotMetadata {
    return {
      originalRequest: isSet(object.originalRequest)
        ? CreateTableFromSnapshotRequest.fromJSON(object.originalRequest)
        : undefined,
      requestTime: isSet(object.requestTime) ? fromJsonTimestamp(object.requestTime) : undefined,
      finishTime: isSet(object.finishTime) ? fromJsonTimestamp(object.finishTime) : undefined,
    };
  },

  toJSON(message: CreateTableFromSnapshotMetadata): unknown {
    const obj: any = {};
    if (message.originalRequest !== undefined) {
      obj.originalRequest = CreateTableFromSnapshotRequest.toJSON(message.originalRequest);
    }
    if (message.requestTime !== undefined) {
      obj.requestTime = message.requestTime.toISOString();
    }
    if (message.finishTime !== undefined) {
      obj.finishTime = message.finishTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTableFromSnapshotMetadata>): CreateTableFromSnapshotMetadata {
    return CreateTableFromSnapshotMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTableFromSnapshotMetadata>): CreateTableFromSnapshotMetadata {
    const message = createBaseCreateTableFromSnapshotMetadata();
    message.originalRequest = (object.originalRequest !== undefined && object.originalRequest !== null)
      ? CreateTableFromSnapshotRequest.fromPartial(object.originalRequest)
      : undefined;
    message.requestTime = object.requestTime ?? undefined;
    message.finishTime = object.finishTime ?? undefined;
    return message;
  },
};

function createBaseCreateBackupRequest(): CreateBackupRequest {
  return { parent: "", backupId: "", backup: undefined };
}

export const CreateBackupRequest: MessageFns<CreateBackupRequest> = {
  encode(message: CreateBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.backupId !== "") {
      writer.uint32(18).string(message.backupId);
    }
    if (message.backup !== undefined) {
      Backup.encode(message.backup, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backupId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backup = Backup.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBackupRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      backupId: isSet(object.backupId) ? globalThis.String(object.backupId) : "",
      backup: isSet(object.backup) ? Backup.fromJSON(object.backup) : undefined,
    };
  },

  toJSON(message: CreateBackupRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.backupId !== "") {
      obj.backupId = message.backupId;
    }
    if (message.backup !== undefined) {
      obj.backup = Backup.toJSON(message.backup);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBackupRequest>): CreateBackupRequest {
    return CreateBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBackupRequest>): CreateBackupRequest {
    const message = createBaseCreateBackupRequest();
    message.parent = object.parent ?? "";
    message.backupId = object.backupId ?? "";
    message.backup = (object.backup !== undefined && object.backup !== null)
      ? Backup.fromPartial(object.backup)
      : undefined;
    return message;
  },
};

function createBaseCreateBackupMetadata(): CreateBackupMetadata {
  return { name: "", sourceTable: "", startTime: undefined, endTime: undefined };
}

export const CreateBackupMetadata: MessageFns<CreateBackupMetadata> = {
  encode(message: CreateBackupMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sourceTable !== "") {
      writer.uint32(18).string(message.sourceTable);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(26).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBackupMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBackupMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceTable = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBackupMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sourceTable: isSet(object.sourceTable) ? globalThis.String(object.sourceTable) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: CreateBackupMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sourceTable !== "") {
      obj.sourceTable = message.sourceTable;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBackupMetadata>): CreateBackupMetadata {
    return CreateBackupMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBackupMetadata>): CreateBackupMetadata {
    const message = createBaseCreateBackupMetadata();
    message.name = object.name ?? "";
    message.sourceTable = object.sourceTable ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseUpdateBackupRequest(): UpdateBackupRequest {
  return { backup: undefined, updateMask: undefined };
}

export const UpdateBackupRequest: MessageFns<UpdateBackupRequest> = {
  encode(message: UpdateBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backup !== undefined) {
      Backup.encode(message.backup, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backup = Backup.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateBackupRequest {
    return {
      backup: isSet(object.backup) ? Backup.fromJSON(object.backup) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateBackupRequest): unknown {
    const obj: any = {};
    if (message.backup !== undefined) {
      obj.backup = Backup.toJSON(message.backup);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateBackupRequest>): UpdateBackupRequest {
    return UpdateBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateBackupRequest>): UpdateBackupRequest {
    const message = createBaseUpdateBackupRequest();
    message.backup = (object.backup !== undefined && object.backup !== null)
      ? Backup.fromPartial(object.backup)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetBackupRequest(): GetBackupRequest {
  return { name: "" };
}

export const GetBackupRequest: MessageFns<GetBackupRequest> = {
  encode(message: GetBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBackupRequest>): GetBackupRequest {
    return GetBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBackupRequest>): GetBackupRequest {
    const message = createBaseGetBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDeleteBackupRequest(): DeleteBackupRequest {
  return { name: "" };
}

export const DeleteBackupRequest: MessageFns<DeleteBackupRequest> = {
  encode(message: DeleteBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    return DeleteBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    const message = createBaseDeleteBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListBackupsRequest(): ListBackupsRequest {
  return { parent: "", filter: "", orderBy: "", pageSize: 0, pageToken: "" };
}

export const ListBackupsRequest: MessageFns<ListBackupsRequest> = {
  encode(message: ListBackupsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.orderBy !== "") {
      writer.uint32(26).string(message.orderBy);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListBackupsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    return ListBackupsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    const message = createBaseListBackupsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.orderBy = object.orderBy ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListBackupsResponse(): ListBackupsResponse {
  return { backups: [], nextPageToken: "" };
}

export const ListBackupsResponse: MessageFns<ListBackupsResponse> = {
  encode(message: ListBackupsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.backups) {
      Backup.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backups.push(Backup.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsResponse {
    return {
      backups: globalThis.Array.isArray(object?.backups) ? object.backups.map((e: any) => Backup.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListBackupsResponse): unknown {
    const obj: any = {};
    if (message.backups?.length) {
      obj.backups = message.backups.map((e) => Backup.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    return ListBackupsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    const message = createBaseListBackupsResponse();
    message.backups = object.backups?.map((e) => Backup.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCopyBackupRequest(): CopyBackupRequest {
  return { parent: "", backupId: "", sourceBackup: "", expireTime: undefined };
}

export const CopyBackupRequest: MessageFns<CopyBackupRequest> = {
  encode(message: CopyBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.backupId !== "") {
      writer.uint32(18).string(message.backupId);
    }
    if (message.sourceBackup !== "") {
      writer.uint32(26).string(message.sourceBackup);
    }
    if (message.expireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.expireTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CopyBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCopyBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backupId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sourceBackup = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.expireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CopyBackupRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      backupId: isSet(object.backupId) ? globalThis.String(object.backupId) : "",
      sourceBackup: isSet(object.sourceBackup) ? globalThis.String(object.sourceBackup) : "",
      expireTime: isSet(object.expireTime) ? fromJsonTimestamp(object.expireTime) : undefined,
    };
  },

  toJSON(message: CopyBackupRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.backupId !== "") {
      obj.backupId = message.backupId;
    }
    if (message.sourceBackup !== "") {
      obj.sourceBackup = message.sourceBackup;
    }
    if (message.expireTime !== undefined) {
      obj.expireTime = message.expireTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CopyBackupRequest>): CopyBackupRequest {
    return CopyBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CopyBackupRequest>): CopyBackupRequest {
    const message = createBaseCopyBackupRequest();
    message.parent = object.parent ?? "";
    message.backupId = object.backupId ?? "";
    message.sourceBackup = object.sourceBackup ?? "";
    message.expireTime = object.expireTime ?? undefined;
    return message;
  },
};

function createBaseCopyBackupMetadata(): CopyBackupMetadata {
  return { name: "", sourceBackupInfo: undefined, progress: undefined };
}

export const CopyBackupMetadata: MessageFns<CopyBackupMetadata> = {
  encode(message: CopyBackupMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sourceBackupInfo !== undefined) {
      BackupInfo.encode(message.sourceBackupInfo, writer.uint32(18).fork()).join();
    }
    if (message.progress !== undefined) {
      OperationProgress.encode(message.progress, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CopyBackupMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCopyBackupMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceBackupInfo = BackupInfo.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.progress = OperationProgress.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CopyBackupMetadata {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sourceBackupInfo: isSet(object.sourceBackupInfo) ? BackupInfo.fromJSON(object.sourceBackupInfo) : undefined,
      progress: isSet(object.progress) ? OperationProgress.fromJSON(object.progress) : undefined,
    };
  },

  toJSON(message: CopyBackupMetadata): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sourceBackupInfo !== undefined) {
      obj.sourceBackupInfo = BackupInfo.toJSON(message.sourceBackupInfo);
    }
    if (message.progress !== undefined) {
      obj.progress = OperationProgress.toJSON(message.progress);
    }
    return obj;
  },

  create(base?: DeepPartial<CopyBackupMetadata>): CopyBackupMetadata {
    return CopyBackupMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CopyBackupMetadata>): CopyBackupMetadata {
    const message = createBaseCopyBackupMetadata();
    message.name = object.name ?? "";
    message.sourceBackupInfo = (object.sourceBackupInfo !== undefined && object.sourceBackupInfo !== null)
      ? BackupInfo.fromPartial(object.sourceBackupInfo)
      : undefined;
    message.progress = (object.progress !== undefined && object.progress !== null)
      ? OperationProgress.fromPartial(object.progress)
      : undefined;
    return message;
  },
};

function createBaseCreateAuthorizedViewRequest(): CreateAuthorizedViewRequest {
  return { parent: "", authorizedViewId: "", authorizedView: undefined };
}

export const CreateAuthorizedViewRequest: MessageFns<CreateAuthorizedViewRequest> = {
  encode(message: CreateAuthorizedViewRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.authorizedViewId !== "") {
      writer.uint32(18).string(message.authorizedViewId);
    }
    if (message.authorizedView !== undefined) {
      AuthorizedView.encode(message.authorizedView, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateAuthorizedViewRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateAuthorizedViewRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.authorizedViewId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.authorizedView = AuthorizedView.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateAuthorizedViewRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      authorizedViewId: isSet(object.authorizedViewId) ? globalThis.String(object.authorizedViewId) : "",
      authorizedView: isSet(object.authorizedView) ? AuthorizedView.fromJSON(object.authorizedView) : undefined,
    };
  },

  toJSON(message: CreateAuthorizedViewRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.authorizedViewId !== "") {
      obj.authorizedViewId = message.authorizedViewId;
    }
    if (message.authorizedView !== undefined) {
      obj.authorizedView = AuthorizedView.toJSON(message.authorizedView);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateAuthorizedViewRequest>): CreateAuthorizedViewRequest {
    return CreateAuthorizedViewRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateAuthorizedViewRequest>): CreateAuthorizedViewRequest {
    const message = createBaseCreateAuthorizedViewRequest();
    message.parent = object.parent ?? "";
    message.authorizedViewId = object.authorizedViewId ?? "";
    message.authorizedView = (object.authorizedView !== undefined && object.authorizedView !== null)
      ? AuthorizedView.fromPartial(object.authorizedView)
      : undefined;
    return message;
  },
};

function createBaseCreateAuthorizedViewMetadata(): CreateAuthorizedViewMetadata {
  return { originalRequest: undefined, requestTime: undefined, finishTime: undefined };
}

export const CreateAuthorizedViewMetadata: MessageFns<CreateAuthorizedViewMetadata> = {
  encode(message: CreateAuthorizedViewMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.originalRequest !== undefined) {
      CreateAuthorizedViewRequest.encode(message.originalRequest, writer.uint32(10).fork()).join();
    }
    if (message.requestTime !== undefined) {
      Timestamp.encode(toTimestamp(message.requestTime), writer.uint32(18).fork()).join();
    }
    if (message.finishTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finishTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateAuthorizedViewMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateAuthorizedViewMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.originalRequest = CreateAuthorizedViewRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.finishTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateAuthorizedViewMetadata {
    return {
      originalRequest: isSet(object.originalRequest)
        ? CreateAuthorizedViewRequest.fromJSON(object.originalRequest)
        : undefined,
      requestTime: isSet(object.requestTime) ? fromJsonTimestamp(object.requestTime) : undefined,
      finishTime: isSet(object.finishTime) ? fromJsonTimestamp(object.finishTime) : undefined,
    };
  },

  toJSON(message: CreateAuthorizedViewMetadata): unknown {
    const obj: any = {};
    if (message.originalRequest !== undefined) {
      obj.originalRequest = CreateAuthorizedViewRequest.toJSON(message.originalRequest);
    }
    if (message.requestTime !== undefined) {
      obj.requestTime = message.requestTime.toISOString();
    }
    if (message.finishTime !== undefined) {
      obj.finishTime = message.finishTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CreateAuthorizedViewMetadata>): CreateAuthorizedViewMetadata {
    return CreateAuthorizedViewMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateAuthorizedViewMetadata>): CreateAuthorizedViewMetadata {
    const message = createBaseCreateAuthorizedViewMetadata();
    message.originalRequest = (object.originalRequest !== undefined && object.originalRequest !== null)
      ? CreateAuthorizedViewRequest.fromPartial(object.originalRequest)
      : undefined;
    message.requestTime = object.requestTime ?? undefined;
    message.finishTime = object.finishTime ?? undefined;
    return message;
  },
};

function createBaseListAuthorizedViewsRequest(): ListAuthorizedViewsRequest {
  return { parent: "", pageSize: 0, pageToken: "", view: 0 };
}

export const ListAuthorizedViewsRequest: MessageFns<ListAuthorizedViewsRequest> = {
  encode(message: ListAuthorizedViewsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    if (message.view !== 0) {
      writer.uint32(32).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListAuthorizedViewsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListAuthorizedViewsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListAuthorizedViewsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      view: isSet(object.view) ? authorizedView_ResponseViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: ListAuthorizedViewsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.view !== 0) {
      obj.view = authorizedView_ResponseViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<ListAuthorizedViewsRequest>): ListAuthorizedViewsRequest {
    return ListAuthorizedViewsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListAuthorizedViewsRequest>): ListAuthorizedViewsRequest {
    const message = createBaseListAuthorizedViewsRequest();
    message.parent = object.parent ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseListAuthorizedViewsResponse(): ListAuthorizedViewsResponse {
  return { authorizedViews: [], nextPageToken: "" };
}

export const ListAuthorizedViewsResponse: MessageFns<ListAuthorizedViewsResponse> = {
  encode(message: ListAuthorizedViewsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.authorizedViews) {
      AuthorizedView.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListAuthorizedViewsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListAuthorizedViewsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.authorizedViews.push(AuthorizedView.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListAuthorizedViewsResponse {
    return {
      authorizedViews: globalThis.Array.isArray(object?.authorizedViews)
        ? object.authorizedViews.map((e: any) => AuthorizedView.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListAuthorizedViewsResponse): unknown {
    const obj: any = {};
    if (message.authorizedViews?.length) {
      obj.authorizedViews = message.authorizedViews.map((e) => AuthorizedView.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListAuthorizedViewsResponse>): ListAuthorizedViewsResponse {
    return ListAuthorizedViewsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListAuthorizedViewsResponse>): ListAuthorizedViewsResponse {
    const message = createBaseListAuthorizedViewsResponse();
    message.authorizedViews = object.authorizedViews?.map((e) => AuthorizedView.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetAuthorizedViewRequest(): GetAuthorizedViewRequest {
  return { name: "", view: 0 };
}

export const GetAuthorizedViewRequest: MessageFns<GetAuthorizedViewRequest> = {
  encode(message: GetAuthorizedViewRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.view !== 0) {
      writer.uint32(16).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetAuthorizedViewRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetAuthorizedViewRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetAuthorizedViewRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      view: isSet(object.view) ? authorizedView_ResponseViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: GetAuthorizedViewRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.view !== 0) {
      obj.view = authorizedView_ResponseViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<GetAuthorizedViewRequest>): GetAuthorizedViewRequest {
    return GetAuthorizedViewRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetAuthorizedViewRequest>): GetAuthorizedViewRequest {
    const message = createBaseGetAuthorizedViewRequest();
    message.name = object.name ?? "";
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseUpdateAuthorizedViewRequest(): UpdateAuthorizedViewRequest {
  return { authorizedView: undefined, updateMask: undefined, ignoreWarnings: false };
}

export const UpdateAuthorizedViewRequest: MessageFns<UpdateAuthorizedViewRequest> = {
  encode(message: UpdateAuthorizedViewRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.authorizedView !== undefined) {
      AuthorizedView.encode(message.authorizedView, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    if (message.ignoreWarnings !== false) {
      writer.uint32(24).bool(message.ignoreWarnings);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateAuthorizedViewRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateAuthorizedViewRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.authorizedView = AuthorizedView.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.ignoreWarnings = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateAuthorizedViewRequest {
    return {
      authorizedView: isSet(object.authorizedView) ? AuthorizedView.fromJSON(object.authorizedView) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
      ignoreWarnings: isSet(object.ignoreWarnings) ? globalThis.Boolean(object.ignoreWarnings) : false,
    };
  },

  toJSON(message: UpdateAuthorizedViewRequest): unknown {
    const obj: any = {};
    if (message.authorizedView !== undefined) {
      obj.authorizedView = AuthorizedView.toJSON(message.authorizedView);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    if (message.ignoreWarnings !== false) {
      obj.ignoreWarnings = message.ignoreWarnings;
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateAuthorizedViewRequest>): UpdateAuthorizedViewRequest {
    return UpdateAuthorizedViewRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateAuthorizedViewRequest>): UpdateAuthorizedViewRequest {
    const message = createBaseUpdateAuthorizedViewRequest();
    message.authorizedView = (object.authorizedView !== undefined && object.authorizedView !== null)
      ? AuthorizedView.fromPartial(object.authorizedView)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    message.ignoreWarnings = object.ignoreWarnings ?? false;
    return message;
  },
};

function createBaseUpdateAuthorizedViewMetadata(): UpdateAuthorizedViewMetadata {
  return { originalRequest: undefined, requestTime: undefined, finishTime: undefined };
}

export const UpdateAuthorizedViewMetadata: MessageFns<UpdateAuthorizedViewMetadata> = {
  encode(message: UpdateAuthorizedViewMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.originalRequest !== undefined) {
      UpdateAuthorizedViewRequest.encode(message.originalRequest, writer.uint32(10).fork()).join();
    }
    if (message.requestTime !== undefined) {
      Timestamp.encode(toTimestamp(message.requestTime), writer.uint32(18).fork()).join();
    }
    if (message.finishTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finishTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateAuthorizedViewMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateAuthorizedViewMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.originalRequest = UpdateAuthorizedViewRequest.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requestTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.finishTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateAuthorizedViewMetadata {
    return {
      originalRequest: isSet(object.originalRequest)
        ? UpdateAuthorizedViewRequest.fromJSON(object.originalRequest)
        : undefined,
      requestTime: isSet(object.requestTime) ? fromJsonTimestamp(object.requestTime) : undefined,
      finishTime: isSet(object.finishTime) ? fromJsonTimestamp(object.finishTime) : undefined,
    };
  },

  toJSON(message: UpdateAuthorizedViewMetadata): unknown {
    const obj: any = {};
    if (message.originalRequest !== undefined) {
      obj.originalRequest = UpdateAuthorizedViewRequest.toJSON(message.originalRequest);
    }
    if (message.requestTime !== undefined) {
      obj.requestTime = message.requestTime.toISOString();
    }
    if (message.finishTime !== undefined) {
      obj.finishTime = message.finishTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateAuthorizedViewMetadata>): UpdateAuthorizedViewMetadata {
    return UpdateAuthorizedViewMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateAuthorizedViewMetadata>): UpdateAuthorizedViewMetadata {
    const message = createBaseUpdateAuthorizedViewMetadata();
    message.originalRequest = (object.originalRequest !== undefined && object.originalRequest !== null)
      ? UpdateAuthorizedViewRequest.fromPartial(object.originalRequest)
      : undefined;
    message.requestTime = object.requestTime ?? undefined;
    message.finishTime = object.finishTime ?? undefined;
    return message;
  },
};

function createBaseDeleteAuthorizedViewRequest(): DeleteAuthorizedViewRequest {
  return { name: "", etag: "" };
}

export const DeleteAuthorizedViewRequest: MessageFns<DeleteAuthorizedViewRequest> = {
  encode(message: DeleteAuthorizedViewRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.etag !== "") {
      writer.uint32(18).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteAuthorizedViewRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteAuthorizedViewRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteAuthorizedViewRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeleteAuthorizedViewRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteAuthorizedViewRequest>): DeleteAuthorizedViewRequest {
    return DeleteAuthorizedViewRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteAuthorizedViewRequest>): DeleteAuthorizedViewRequest {
    const message = createBaseDeleteAuthorizedViewRequest();
    message.name = object.name ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

/**
 * Service for creating, configuring, and deleting Cloud Bigtable tables.
 *
 * Provides access to the table schemas only, not the data stored within
 * the tables.
 */
export type BigtableTableAdminDefinition = typeof BigtableTableAdminDefinition;
export const BigtableTableAdminDefinition = {
  name: "BigtableTableAdmin",
  fullName: "google.bigtable.admin.v2.BigtableTableAdmin",
  methods: {
    /**
     * Creates a new table in the specified instance.
     * The table can be created with a full set of initial column families,
     * specified in the request.
     */
    createTable: {
      name: "CreateTable",
      requestType: CreateTableRequest,
      requestStream: false,
      responseType: Table,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              21,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              116,
              97,
              98,
              108,
              101,
              95,
              105,
              100,
              44,
              116,
              97,
              98,
              108,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              47,
              58,
              1,
              42,
              34,
              42,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new table from the specified snapshot. The target table must
     * not exist. The snapshot and the table must be in the same instance.
     *
     * Note: This is a private alpha release of Cloud Bigtable snapshots. This
     * feature is not currently available to most Cloud Bigtable customers. This
     * feature might be changed in backward-incompatible ways and is not
     * recommended for production use. It is not subject to any SLA or deprecation
     * policy.
     */
    createTableFromSnapshot: {
      name: "CreateTableFromSnapshot",
      requestType: CreateTableFromSnapshotRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              40,
              10,
              5,
              84,
              97,
              98,
              108,
              101,
              18,
              31,
              67,
              114,
              101,
              97,
              116,
              101,
              84,
              97,
              98,
              108,
              101,
              70,
              114,
              111,
              109,
              83,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              31,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              116,
              97,
              98,
              108,
              101,
              95,
              105,
              100,
              44,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
            ]),
          ],
          578365826: [
            Buffer.from([
              66,
              58,
              1,
              42,
              34,
              61,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              58,
              99,
              114,
              101,
              97,
              116,
              101,
              70,
              114,
              111,
              109,
              83,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
            ]),
          ],
        },
      },
    },
    /** Lists all tables served from a specified instance. */
    listTables: {
      name: "ListTables",
      requestType: ListTablesRequest,
      requestStream: false,
      responseType: ListTablesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              44,
              18,
              42,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets metadata information about the specified table. */
    getTable: {
      name: "GetTable",
      requestType: GetTableRequest,
      requestStream: false,
      responseType: Table,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              44,
              18,
              42,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates a specified table. */
    updateTable: {
      name: "UpdateTable",
      requestType: UpdateTableRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              28,
              10,
              5,
              84,
              97,
              98,
              108,
              101,
              18,
              19,
              85,
              112,
              100,
              97,
              116,
              101,
              84,
              97,
              98,
              108,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([17, 116, 97, 98, 108, 101, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365826: [
            Buffer.from([
              57,
              58,
              5,
              116,
              97,
              98,
              108,
              101,
              50,
              48,
              47,
              118,
              50,
              47,
              123,
              116,
              97,
              98,
              108,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Permanently deletes a specified table and all of its data. */
    deleteTable: {
      name: "DeleteTable",
      requestType: DeleteTableRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              44,
              42,
              42,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Restores a specified table which was accidentally deleted. */
    undeleteTable: {
      name: "UndeleteTable",
      requestType: UndeleteTableRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              30,
              10,
              5,
              84,
              97,
              98,
              108,
              101,
              18,
              21,
              85,
              110,
              100,
              101,
              108,
              101,
              116,
              101,
              84,
              97,
              98,
              108,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              56,
              58,
              1,
              42,
              34,
              51,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              117,
              110,
              100,
              101,
              108,
              101,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /** Creates a new AuthorizedView in a table. */
    createAuthorizedView: {
      name: "CreateAuthorizedView",
      requestType: CreateAuthorizedViewRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              46,
              10,
              14,
              65,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              18,
              28,
              67,
              114,
              101,
              97,
              116,
              101,
              65,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              41,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              44,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              79,
              58,
              15,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              34,
              60,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists all AuthorizedViews from a specific table. */
    listAuthorizedViews: {
      name: "ListAuthorizedViews",
      requestType: ListAuthorizedViewsRequest,
      requestStream: false,
      responseType: ListAuthorizedViewsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              62,
              18,
              60,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets information from a specified AuthorizedView. */
    getAuthorizedView: {
      name: "GetAuthorizedView",
      requestType: GetAuthorizedViewRequest,
      requestStream: false,
      responseType: AuthorizedView,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              62,
              18,
              60,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates an AuthorizedView in a table. */
    updateAuthorizedView: {
      name: "UpdateAuthorizedView",
      requestType: UpdateAuthorizedViewRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              46,
              10,
              14,
              65,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              18,
              28,
              85,
              112,
              100,
              97,
              116,
              101,
              65,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              95,
              58,
              15,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              50,
              76,
              47,
              118,
              50,
              47,
              123,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              95,
              118,
              105,
              101,
              119,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Permanently deletes a specified AuthorizedView. */
    deleteAuthorizedView: {
      name: "DeleteAuthorizedView",
      requestType: DeleteAuthorizedViewRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              62,
              42,
              60,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              47,
              97,
              117,
              116,
              104,
              111,
              114,
              105,
              122,
              101,
              100,
              86,
              105,
              101,
              119,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Performs a series of column family modifications on the specified table.
     * Either all or none of the modifications will occur before this method
     * returns, but data requests received prior to that point may see a table
     * where only some modifications have taken effect.
     */
    modifyColumnFamilies: {
      name: "ModifyColumnFamilies",
      requestType: ModifyColumnFamiliesRequest,
      requestStream: false,
      responseType: Table,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([18, 110, 97, 109, 101, 44, 109, 111, 100, 105, 102, 105, 99, 97, 116, 105, 111, 110, 115]),
          ],
          578365826: [
            Buffer.from([
              68,
              58,
              1,
              42,
              34,
              63,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              109,
              111,
              100,
              105,
              102,
              121,
              67,
              111,
              108,
              117,
              109,
              110,
              70,
              97,
              109,
              105,
              108,
              105,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Permanently drop/delete a row range from a specified table. The request can
     * specify whether to delete all rows in a table, or only those that match a
     * particular prefix.
     */
    dropRowRange: {
      name: "DropRowRange",
      requestType: DropRowRangeRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              60,
              58,
              1,
              42,
              34,
              55,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              100,
              114,
              111,
              112,
              82,
              111,
              119,
              82,
              97,
              110,
              103,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Generates a consistency token for a Table, which can be used in
     * CheckConsistency to check whether mutations to the table that finished
     * before this call started have been replicated. The tokens will be available
     * for 90 days.
     */
    generateConsistencyToken: {
      name: "GenerateConsistencyToken",
      requestType: GenerateConsistencyTokenRequest,
      requestStream: false,
      responseType: GenerateConsistencyTokenResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              72,
              58,
              1,
              42,
              34,
              67,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              110,
              101,
              114,
              97,
              116,
              101,
              67,
              111,
              110,
              115,
              105,
              115,
              116,
              101,
              110,
              99,
              121,
              84,
              111,
              107,
              101,
              110,
            ]),
          ],
        },
      },
    },
    /**
     * Checks replication consistency based on a consistency token, that is, if
     * replication has caught up based on the conditions specified in the token
     * and the check request.
     */
    checkConsistency: {
      name: "CheckConsistency",
      requestType: CheckConsistencyRequest,
      requestStream: false,
      responseType: CheckConsistencyResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              110,
              97,
              109,
              101,
              44,
              99,
              111,
              110,
              115,
              105,
              115,
              116,
              101,
              110,
              99,
              121,
              95,
              116,
              111,
              107,
              101,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              64,
              58,
              1,
              42,
              34,
              59,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              99,
              104,
              101,
              99,
              107,
              67,
              111,
              110,
              115,
              105,
              115,
              116,
              101,
              110,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new snapshot in the specified cluster from the specified
     * source table. The cluster and the table must be in the same instance.
     *
     * Note: This is a private alpha release of Cloud Bigtable snapshots. This
     * feature is not currently available to most Cloud Bigtable customers. This
     * feature might be changed in backward-incompatible ways and is not
     * recommended for production use. It is not subject to any SLA or deprecation
     * policy.
     */
    snapshotTable: {
      name: "SnapshotTable",
      requestType: SnapshotTableRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              33,
              10,
              8,
              83,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              18,
              21,
              83,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              84,
              97,
              98,
              108,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              36,
              110,
              97,
              109,
              101,
              44,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              44,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              95,
              105,
              100,
              44,
              100,
              101,
              115,
              99,
              114,
              105,
              112,
              116,
              105,
              111,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              56,
              58,
              1,
              42,
              34,
              51,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
            ]),
          ],
        },
      },
    },
    /**
     * Gets metadata information about the specified snapshot.
     *
     * Note: This is a private alpha release of Cloud Bigtable snapshots. This
     * feature is not currently available to most Cloud Bigtable customers. This
     * feature might be changed in backward-incompatible ways and is not
     * recommended for production use. It is not subject to any SLA or deprecation
     * policy.
     */
    getSnapshot: {
      name: "GetSnapshot",
      requestType: GetSnapshotRequest,
      requestStream: false,
      responseType: Snapshot,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              58,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists all snapshots associated with the specified cluster.
     *
     * Note: This is a private alpha release of Cloud Bigtable snapshots. This
     * feature is not currently available to most Cloud Bigtable customers. This
     * feature might be changed in backward-incompatible ways and is not
     * recommended for production use. It is not subject to any SLA or deprecation
     * policy.
     */
    listSnapshots: {
      name: "ListSnapshots",
      requestType: ListSnapshotsRequest,
      requestStream: false,
      responseType: ListSnapshotsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              58,
              18,
              56,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              125,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Permanently deletes the specified snapshot.
     *
     * Note: This is a private alpha release of Cloud Bigtable snapshots. This
     * feature is not currently available to most Cloud Bigtable customers. This
     * feature might be changed in backward-incompatible ways and is not
     * recommended for production use. It is not subject to any SLA or deprecation
     * policy.
     */
    deleteSnapshot: {
      name: "DeleteSnapshot",
      requestType: DeleteSnapshotRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              58,
              42,
              56,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              115,
              110,
              97,
              112,
              115,
              104,
              111,
              116,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Starts creating a new Cloud Bigtable Backup.  The returned backup
     * [long-running operation][google.longrunning.Operation] can be used to
     * track creation of the backup. The
     * [metadata][google.longrunning.Operation.metadata] field type is
     * [CreateBackupMetadata][google.bigtable.admin.v2.CreateBackupMetadata]. The
     * [response][google.longrunning.Operation.response] field type is
     * [Backup][google.bigtable.admin.v2.Backup], if successful. Cancelling the
     * returned operation will stop the creation and delete the backup.
     */
    createBackup: {
      name: "CreateBackup",
      requestType: CreateBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              30,
              10,
              6,
              66,
              97,
              99,
              107,
              117,
              112,
              18,
              20,
              67,
              114,
              101,
              97,
              116,
              101,
              66,
              97,
              99,
              107,
              117,
              112,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              23,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              105,
              100,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
            ]),
          ],
          578365826: [
            Buffer.from([
              64,
              58,
              6,
              98,
              97,
              99,
              107,
              117,
              112,
              34,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets metadata on a pending or completed Cloud Bigtable Backup. */
    getBackup: {
      name: "GetBackup",
      requestType: GetBackupRequest,
      requestStream: false,
      responseType: Backup,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Updates a pending or completed Cloud Bigtable Backup. */
    updateBackup: {
      name: "UpdateBackup",
      requestType: UpdateBackupRequest,
      requestStream: false,
      responseType: Backup,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([18, 98, 97, 99, 107, 117, 112, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107])],
          578365826: [
            Buffer.from([
              71,
              58,
              6,
              98,
              97,
              99,
              107,
              117,
              112,
              50,
              61,
              47,
              118,
              50,
              47,
              123,
              98,
              97,
              99,
              107,
              117,
              112,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a pending or completed Cloud Bigtable backup. */
    deleteBackup: {
      name: "DeleteBackup",
      requestType: DeleteBackupRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              56,
              42,
              54,
              47,
              118,
              50,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists Cloud Bigtable backups. Returns both completed and pending
     * backups.
     */
    listBackups: {
      name: "ListBackups",
      requestType: ListBackupsRequest,
      requestStream: false,
      responseType: ListBackupsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Create a new table by restoring from a completed backup.  The
     * returned table [long-running operation][google.longrunning.Operation] can
     * be used to track the progress of the operation, and to cancel it.  The
     * [metadata][google.longrunning.Operation.metadata] field type is
     * [RestoreTableMetadata][google.bigtable.admin.v2.RestoreTableMetadata].  The
     * [response][google.longrunning.Operation.response] type is
     * [Table][google.bigtable.admin.v2.Table], if successful.
     */
    restoreTable: {
      name: "RestoreTable",
      requestType: RestoreTableRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              29,
              10,
              5,
              84,
              97,
              98,
              108,
              101,
              18,
              20,
              82,
              101,
              115,
              116,
              111,
              114,
              101,
              84,
              97,
              98,
              108,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              55,
              58,
              1,
              42,
              34,
              50,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              125,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              58,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Copy a Cloud Bigtable backup to a new backup in the destination cluster
     * located in the destination instance and project.
     */
    copyBackup: {
      name: "CopyBackup",
      requestType: CopyBackupRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              28,
              10,
              6,
              66,
              97,
              99,
              107,
              117,
              112,
              18,
              18,
              67,
              111,
              112,
              121,
              66,
              97,
              99,
              107,
              117,
              112,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              42,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              105,
              100,
              44,
              115,
              111,
              117,
              114,
              99,
              101,
              95,
              98,
              97,
              99,
              107,
              117,
              112,
              44,
              101,
              120,
              112,
              105,
              114,
              101,
              95,
              116,
              105,
              109,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              64,
              58,
              1,
              42,
              34,
              59,
              47,
              118,
              50,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              58,
              99,
              111,
              112,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Gets the access control policy for a Table or Backup resource.
     * Returns an empty policy if the resource exists but does not have a policy
     * set.
     */
    getIamPolicy: {
      name: "GetIamPolicy",
      requestType: GetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([8, 114, 101, 115, 111, 117, 114, 99, 101])],
          578365826: [
            Buffer.from([
              142,
              1,
              58,
              1,
              42,
              90,
              76,
              58,
              1,
              42,
              34,
              71,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              34,
              59,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              103,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Sets the access control policy on a Table or Backup resource.
     * Replaces any existing policy.
     */
    setIamPolicy: {
      name: "SetIamPolicy",
      requestType: SetIamPolicyRequest,
      requestStream: false,
      responseType: Policy,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([15, 114, 101, 115, 111, 117, 114, 99, 101, 44, 112, 111, 108, 105, 99, 121])],
          578365826: [
            Buffer.from([
              142,
              1,
              58,
              1,
              42,
              90,
              76,
              58,
              1,
              42,
              34,
              71,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
              34,
              59,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              115,
              101,
              116,
              73,
              97,
              109,
              80,
              111,
              108,
              105,
              99,
              121,
            ]),
          ],
        },
      },
    },
    /**
     * Returns permissions that the caller has on the specified Table or Backup
     * resource.
     */
    testIamPermissions: {
      name: "TestIamPermissions",
      requestType: TestIamPermissionsRequest,
      requestStream: false,
      responseType: TestIamPermissionsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              44,
              112,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
          578365826: [
            Buffer.from([
              154,
              1,
              58,
              1,
              42,
              90,
              82,
              58,
              1,
              42,
              34,
              77,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              99,
              108,
              117,
              115,
              116,
              101,
              114,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
              34,
              65,
              47,
              118,
              50,
              47,
              123,
              114,
              101,
              115,
              111,
              117,
              114,
              99,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              105,
              110,
              115,
              116,
              97,
              110,
              99,
              101,
              115,
              47,
              42,
              47,
              116,
              97,
              98,
              108,
              101,
              115,
              47,
              42,
              125,
              58,
              116,
              101,
              115,
              116,
              73,
              97,
              109,
              80,
              101,
              114,
              109,
              105,
              115,
              115,
              105,
              111,
              110,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface BigtableTableAdminServiceImplementation<CallContextExt = {}> {
  /**
   * Creates a new table in the specified instance.
   * The table can be created with a full set of initial column families,
   * specified in the request.
   */
  createTable(request: CreateTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Table>>;
  /**
   * Creates a new table from the specified snapshot. The target table must
   * not exist. The snapshot and the table must be in the same instance.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  createTableFromSnapshot(
    request: CreateTableFromSnapshotRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists all tables served from a specified instance. */
  listTables(
    request: ListTablesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTablesResponse>>;
  /** Gets metadata information about the specified table. */
  getTable(request: GetTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Table>>;
  /** Updates a specified table. */
  updateTable(request: UpdateTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Permanently deletes a specified table and all of its data. */
  deleteTable(request: DeleteTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Restores a specified table which was accidentally deleted. */
  undeleteTable(request: UndeleteTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Creates a new AuthorizedView in a table. */
  createAuthorizedView(
    request: CreateAuthorizedViewRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Lists all AuthorizedViews from a specific table. */
  listAuthorizedViews(
    request: ListAuthorizedViewsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListAuthorizedViewsResponse>>;
  /** Gets information from a specified AuthorizedView. */
  getAuthorizedView(
    request: GetAuthorizedViewRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<AuthorizedView>>;
  /** Updates an AuthorizedView in a table. */
  updateAuthorizedView(
    request: UpdateAuthorizedViewRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Permanently deletes a specified AuthorizedView. */
  deleteAuthorizedView(
    request: DeleteAuthorizedViewRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Performs a series of column family modifications on the specified table.
   * Either all or none of the modifications will occur before this method
   * returns, but data requests received prior to that point may see a table
   * where only some modifications have taken effect.
   */
  modifyColumnFamilies(
    request: ModifyColumnFamiliesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Table>>;
  /**
   * Permanently drop/delete a row range from a specified table. The request can
   * specify whether to delete all rows in a table, or only those that match a
   * particular prefix.
   */
  dropRowRange(request: DropRowRangeRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Generates a consistency token for a Table, which can be used in
   * CheckConsistency to check whether mutations to the table that finished
   * before this call started have been replicated. The tokens will be available
   * for 90 days.
   */
  generateConsistencyToken(
    request: GenerateConsistencyTokenRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<GenerateConsistencyTokenResponse>>;
  /**
   * Checks replication consistency based on a consistency token, that is, if
   * replication has caught up based on the conditions specified in the token
   * and the check request.
   */
  checkConsistency(
    request: CheckConsistencyRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<CheckConsistencyResponse>>;
  /**
   * Creates a new snapshot in the specified cluster from the specified
   * source table. The cluster and the table must be in the same instance.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  snapshotTable(request: SnapshotTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Gets metadata information about the specified snapshot.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  getSnapshot(request: GetSnapshotRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Snapshot>>;
  /**
   * Lists all snapshots associated with the specified cluster.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  listSnapshots(
    request: ListSnapshotsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListSnapshotsResponse>>;
  /**
   * Permanently deletes the specified snapshot.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  deleteSnapshot(request: DeleteSnapshotRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Starts creating a new Cloud Bigtable Backup.  The returned backup
   * [long-running operation][google.longrunning.Operation] can be used to
   * track creation of the backup. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [CreateBackupMetadata][google.bigtable.admin.v2.CreateBackupMetadata]. The
   * [response][google.longrunning.Operation.response] field type is
   * [Backup][google.bigtable.admin.v2.Backup], if successful. Cancelling the
   * returned operation will stop the creation and delete the backup.
   */
  createBackup(request: CreateBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Gets metadata on a pending or completed Cloud Bigtable Backup. */
  getBackup(request: GetBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Backup>>;
  /** Updates a pending or completed Cloud Bigtable Backup. */
  updateBackup(request: UpdateBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Backup>>;
  /** Deletes a pending or completed Cloud Bigtable backup. */
  deleteBackup(request: DeleteBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Lists Cloud Bigtable backups. Returns both completed and pending
   * backups.
   */
  listBackups(
    request: ListBackupsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupsResponse>>;
  /**
   * Create a new table by restoring from a completed backup.  The
   * returned table [long-running operation][google.longrunning.Operation] can
   * be used to track the progress of the operation, and to cancel it.  The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [RestoreTableMetadata][google.bigtable.admin.v2.RestoreTableMetadata].  The
   * [response][google.longrunning.Operation.response] type is
   * [Table][google.bigtable.admin.v2.Table], if successful.
   */
  restoreTable(request: RestoreTableRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Copy a Cloud Bigtable backup to a new backup in the destination cluster
   * located in the destination instance and project.
   */
  copyBackup(request: CopyBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Gets the access control policy for a Table or Backup resource.
   * Returns an empty policy if the resource exists but does not have a policy
   * set.
   */
  getIamPolicy(request: GetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Sets the access control policy on a Table or Backup resource.
   * Replaces any existing policy.
   */
  setIamPolicy(request: SetIamPolicyRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Policy>>;
  /**
   * Returns permissions that the caller has on the specified Table or Backup
   * resource.
   */
  testIamPermissions(
    request: TestIamPermissionsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TestIamPermissionsResponse>>;
}

export interface BigtableTableAdminClient<CallOptionsExt = {}> {
  /**
   * Creates a new table in the specified instance.
   * The table can be created with a full set of initial column families,
   * specified in the request.
   */
  createTable(request: DeepPartial<CreateTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Table>;
  /**
   * Creates a new table from the specified snapshot. The target table must
   * not exist. The snapshot and the table must be in the same instance.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  createTableFromSnapshot(
    request: DeepPartial<CreateTableFromSnapshotRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists all tables served from a specified instance. */
  listTables(
    request: DeepPartial<ListTablesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTablesResponse>;
  /** Gets metadata information about the specified table. */
  getTable(request: DeepPartial<GetTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Table>;
  /** Updates a specified table. */
  updateTable(request: DeepPartial<UpdateTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Permanently deletes a specified table and all of its data. */
  deleteTable(request: DeepPartial<DeleteTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Restores a specified table which was accidentally deleted. */
  undeleteTable(request: DeepPartial<UndeleteTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Creates a new AuthorizedView in a table. */
  createAuthorizedView(
    request: DeepPartial<CreateAuthorizedViewRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Lists all AuthorizedViews from a specific table. */
  listAuthorizedViews(
    request: DeepPartial<ListAuthorizedViewsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListAuthorizedViewsResponse>;
  /** Gets information from a specified AuthorizedView. */
  getAuthorizedView(
    request: DeepPartial<GetAuthorizedViewRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<AuthorizedView>;
  /** Updates an AuthorizedView in a table. */
  updateAuthorizedView(
    request: DeepPartial<UpdateAuthorizedViewRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Permanently deletes a specified AuthorizedView. */
  deleteAuthorizedView(
    request: DeepPartial<DeleteAuthorizedViewRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Performs a series of column family modifications on the specified table.
   * Either all or none of the modifications will occur before this method
   * returns, but data requests received prior to that point may see a table
   * where only some modifications have taken effect.
   */
  modifyColumnFamilies(
    request: DeepPartial<ModifyColumnFamiliesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Table>;
  /**
   * Permanently drop/delete a row range from a specified table. The request can
   * specify whether to delete all rows in a table, or only those that match a
   * particular prefix.
   */
  dropRowRange(request: DeepPartial<DropRowRangeRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Generates a consistency token for a Table, which can be used in
   * CheckConsistency to check whether mutations to the table that finished
   * before this call started have been replicated. The tokens will be available
   * for 90 days.
   */
  generateConsistencyToken(
    request: DeepPartial<GenerateConsistencyTokenRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<GenerateConsistencyTokenResponse>;
  /**
   * Checks replication consistency based on a consistency token, that is, if
   * replication has caught up based on the conditions specified in the token
   * and the check request.
   */
  checkConsistency(
    request: DeepPartial<CheckConsistencyRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<CheckConsistencyResponse>;
  /**
   * Creates a new snapshot in the specified cluster from the specified
   * source table. The cluster and the table must be in the same instance.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  snapshotTable(request: DeepPartial<SnapshotTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Gets metadata information about the specified snapshot.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  getSnapshot(request: DeepPartial<GetSnapshotRequest>, options?: CallOptions & CallOptionsExt): Promise<Snapshot>;
  /**
   * Lists all snapshots associated with the specified cluster.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  listSnapshots(
    request: DeepPartial<ListSnapshotsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListSnapshotsResponse>;
  /**
   * Permanently deletes the specified snapshot.
   *
   * Note: This is a private alpha release of Cloud Bigtable snapshots. This
   * feature is not currently available to most Cloud Bigtable customers. This
   * feature might be changed in backward-incompatible ways and is not
   * recommended for production use. It is not subject to any SLA or deprecation
   * policy.
   */
  deleteSnapshot(request: DeepPartial<DeleteSnapshotRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Starts creating a new Cloud Bigtable Backup.  The returned backup
   * [long-running operation][google.longrunning.Operation] can be used to
   * track creation of the backup. The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [CreateBackupMetadata][google.bigtable.admin.v2.CreateBackupMetadata]. The
   * [response][google.longrunning.Operation.response] field type is
   * [Backup][google.bigtable.admin.v2.Backup], if successful. Cancelling the
   * returned operation will stop the creation and delete the backup.
   */
  createBackup(request: DeepPartial<CreateBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Gets metadata on a pending or completed Cloud Bigtable Backup. */
  getBackup(request: DeepPartial<GetBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Backup>;
  /** Updates a pending or completed Cloud Bigtable Backup. */
  updateBackup(request: DeepPartial<UpdateBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Backup>;
  /** Deletes a pending or completed Cloud Bigtable backup. */
  deleteBackup(request: DeepPartial<DeleteBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Lists Cloud Bigtable backups. Returns both completed and pending
   * backups.
   */
  listBackups(
    request: DeepPartial<ListBackupsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupsResponse>;
  /**
   * Create a new table by restoring from a completed backup.  The
   * returned table [long-running operation][google.longrunning.Operation] can
   * be used to track the progress of the operation, and to cancel it.  The
   * [metadata][google.longrunning.Operation.metadata] field type is
   * [RestoreTableMetadata][google.bigtable.admin.v2.RestoreTableMetadata].  The
   * [response][google.longrunning.Operation.response] type is
   * [Table][google.bigtable.admin.v2.Table], if successful.
   */
  restoreTable(request: DeepPartial<RestoreTableRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Copy a Cloud Bigtable backup to a new backup in the destination cluster
   * located in the destination instance and project.
   */
  copyBackup(request: DeepPartial<CopyBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Gets the access control policy for a Table or Backup resource.
   * Returns an empty policy if the resource exists but does not have a policy
   * set.
   */
  getIamPolicy(request: DeepPartial<GetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Sets the access control policy on a Table or Backup resource.
   * Replaces any existing policy.
   */
  setIamPolicy(request: DeepPartial<SetIamPolicyRequest>, options?: CallOptions & CallOptionsExt): Promise<Policy>;
  /**
   * Returns permissions that the caller has on the specified Table or Backup
   * resource.
   */
  testIamPermissions(
    request: DeepPartial<TestIamPermissionsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TestIamPermissionsResponse>;
}

function bytesFromBase64(b64: string): Uint8Array {
  return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
}

function base64FromBytes(arr: Uint8Array): string {
  return globalThis.Buffer.from(arr).toString("base64");
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
