// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/firestore/admin/v1/firestore_admin.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Backup } from "./backup.js";
import { Database, Database_EncryptionConfig } from "./database.js";
import { Field } from "./field.js";
import { Index } from "./index.js";
import { BackupSchedule } from "./schedule.js";

export const protobufPackage = "google.firestore.admin.v1";

/** A request to list the Firestore Databases in all locations for a project. */
export interface ListDatabasesRequest {
  /**
   * Required. A parent name of the form
   * `projects/{project_id}`
   */
  parent: string;
  /** If true, also returns deleted resources. */
  showDeleted: boolean;
}

/**
 * The request for
 * [FirestoreAdmin.CreateDatabase][google.firestore.admin.v1.FirestoreAdmin.CreateDatabase].
 */
export interface CreateDatabaseRequest {
  /**
   * Required. A parent name of the form
   * `projects/{project_id}`
   */
  parent: string;
  /** Required. The Database to create. */
  database:
    | Database
    | undefined;
  /**
   * Required. The ID to use for the database, which will become the final
   * component of the database's resource name.
   *
   * This value should be 4-63 characters. Valid characters are /[a-z][0-9]-/
   * with first character a letter and the last a letter or a number. Must not
   * be UUID-like /[0-9a-f]{8}(-[0-9a-f]{4}){3}-[0-9a-f]{12}/.
   *
   * "(default)" database ID is also valid.
   */
  databaseId: string;
}

/** Metadata related to the create database operation. */
export interface CreateDatabaseMetadata {
}

/** The list of databases for a project. */
export interface ListDatabasesResponse {
  /** The databases in the project. */
  databases: Database[];
  /**
   * In the event that data about individual databases cannot be listed they
   * will be recorded here.
   *
   * An example entry might be: projects/some_project/locations/some_location
   * This can happen if the Cloud Region that the Database resides in is
   * currently unavailable.  In this case we can't fetch all the details about
   * the database. You may be able to get a more detailed error message
   * (or possibly fetch the resource) by sending a 'Get' request for the
   * resource or a 'List' request for the specific location.
   */
  unreachable: string[];
}

/**
 * The request for
 * [FirestoreAdmin.GetDatabase][google.firestore.admin.v1.FirestoreAdmin.GetDatabase].
 */
export interface GetDatabaseRequest {
  /**
   * Required. A name of the form
   * `projects/{project_id}/databases/{database_id}`
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.UpdateDatabase][google.firestore.admin.v1.FirestoreAdmin.UpdateDatabase].
 */
export interface UpdateDatabaseRequest {
  /** Required. The database to update. */
  database:
    | Database
    | undefined;
  /** The list of fields to be updated. */
  updateMask: string[] | undefined;
}

/** Metadata related to the update database operation. */
export interface UpdateDatabaseMetadata {
}

/**
 * The request for
 * [FirestoreAdmin.DeleteDatabase][google.firestore.admin.v1.FirestoreAdmin.DeleteDatabase].
 */
export interface DeleteDatabaseRequest {
  /**
   * Required. A name of the form
   * `projects/{project_id}/databases/{database_id}`
   */
  name: string;
  /**
   * The current etag of the Database.
   * If an etag is provided and does not match the current etag of the database,
   * deletion will be blocked and a FAILED_PRECONDITION error will be returned.
   */
  etag: string;
}

/** Metadata related to the delete database operation. */
export interface DeleteDatabaseMetadata {
}

/**
 * The request for
 * [FirestoreAdmin.CreateBackupSchedule][google.firestore.admin.v1.FirestoreAdmin.CreateBackupSchedule].
 */
export interface CreateBackupScheduleRequest {
  /**
   * Required. The parent database.
   *
   *  Format `projects/{project}/databases/{database}`
   */
  parent: string;
  /** Required. The backup schedule to create. */
  backupSchedule: BackupSchedule | undefined;
}

/**
 * The request for
 * [FirestoreAdmin.GetBackupSchedule][google.firestore.admin.v1.FirestoreAdmin.GetBackupSchedule].
 */
export interface GetBackupScheduleRequest {
  /**
   * Required. The name of the backup schedule.
   *
   * Format
   * `projects/{project}/databases/{database}/backupSchedules/{backup_schedule}`
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.UpdateBackupSchedule][google.firestore.admin.v1.FirestoreAdmin.UpdateBackupSchedule].
 */
export interface UpdateBackupScheduleRequest {
  /** Required. The backup schedule to update. */
  backupSchedule:
    | BackupSchedule
    | undefined;
  /** The list of fields to be updated. */
  updateMask: string[] | undefined;
}

/**
 * The request for
 * [FirestoreAdmin.ListBackupSchedules][google.firestore.admin.v1.FirestoreAdmin.ListBackupSchedules].
 */
export interface ListBackupSchedulesRequest {
  /**
   * Required. The parent database.
   *
   * Format is `projects/{project}/databases/{database}`.
   */
  parent: string;
}

/**
 * The response for
 * [FirestoreAdmin.ListBackupSchedules][google.firestore.admin.v1.FirestoreAdmin.ListBackupSchedules].
 */
export interface ListBackupSchedulesResponse {
  /** List of all backup schedules. */
  backupSchedules: BackupSchedule[];
}

/** The request for [FirestoreAdmin.DeleteBackupSchedules][]. */
export interface DeleteBackupScheduleRequest {
  /**
   * Required. The name of the backup schedule.
   *
   * Format
   * `projects/{project}/databases/{database}/backupSchedules/{backup_schedule}`
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.CreateIndex][google.firestore.admin.v1.FirestoreAdmin.CreateIndex].
 */
export interface CreateIndexRequest {
  /**
   * Required. A parent name of the form
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}`
   */
  parent: string;
  /** Required. The composite index to create. */
  index: Index | undefined;
}

/**
 * The request for
 * [FirestoreAdmin.ListIndexes][google.firestore.admin.v1.FirestoreAdmin.ListIndexes].
 */
export interface ListIndexesRequest {
  /**
   * Required. A parent name of the form
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}`
   */
  parent: string;
  /** The filter to apply to list results. */
  filter: string;
  /** The number of results to return. */
  pageSize: number;
  /**
   * A page token, returned from a previous call to
   * [FirestoreAdmin.ListIndexes][google.firestore.admin.v1.FirestoreAdmin.ListIndexes],
   * that may be used to get the next page of results.
   */
  pageToken: string;
}

/**
 * The response for
 * [FirestoreAdmin.ListIndexes][google.firestore.admin.v1.FirestoreAdmin.ListIndexes].
 */
export interface ListIndexesResponse {
  /** The requested indexes. */
  indexes: Index[];
  /**
   * A page token that may be used to request another page of results. If blank,
   * this is the last page.
   */
  nextPageToken: string;
}

/**
 * The request for
 * [FirestoreAdmin.GetIndex][google.firestore.admin.v1.FirestoreAdmin.GetIndex].
 */
export interface GetIndexRequest {
  /**
   * Required. A name of the form
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}/indexes/{index_id}`
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.DeleteIndex][google.firestore.admin.v1.FirestoreAdmin.DeleteIndex].
 */
export interface DeleteIndexRequest {
  /**
   * Required. A name of the form
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}/indexes/{index_id}`
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.UpdateField][google.firestore.admin.v1.FirestoreAdmin.UpdateField].
 */
export interface UpdateFieldRequest {
  /** Required. The field to be updated. */
  field:
    | Field
    | undefined;
  /**
   * A mask, relative to the field. If specified, only configuration specified
   * by this field_mask will be updated in the field.
   */
  updateMask: string[] | undefined;
}

/**
 * The request for
 * [FirestoreAdmin.GetField][google.firestore.admin.v1.FirestoreAdmin.GetField].
 */
export interface GetFieldRequest {
  /**
   * Required. A name of the form
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}/fields/{field_id}`
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields].
 */
export interface ListFieldsRequest {
  /**
   * Required. A parent name of the form
   * `projects/{project_id}/databases/{database_id}/collectionGroups/{collection_id}`
   */
  parent: string;
  /**
   * The filter to apply to list results. Currently,
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
   * only supports listing fields that have been explicitly overridden. To issue
   * this query, call
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
   * with a filter that includes `indexConfig.usesAncestorConfig:false` or
   * `ttlConfig:*`.
   */
  filter: string;
  /** The number of results to return. */
  pageSize: number;
  /**
   * A page token, returned from a previous call to
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields],
   * that may be used to get the next page of results.
   */
  pageToken: string;
}

/**
 * The response for
 * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields].
 */
export interface ListFieldsResponse {
  /** The requested fields. */
  fields: Field[];
  /**
   * A page token that may be used to request another page of results. If blank,
   * this is the last page.
   */
  nextPageToken: string;
}

/**
 * The request for
 * [FirestoreAdmin.ExportDocuments][google.firestore.admin.v1.FirestoreAdmin.ExportDocuments].
 */
export interface ExportDocumentsRequest {
  /**
   * Required. Database to export. Should be of the form:
   * `projects/{project_id}/databases/{database_id}`.
   */
  name: string;
  /**
   * Which collection IDs to export. Unspecified means all collections. Each
   * collection ID in this list must be unique.
   */
  collectionIds: string[];
  /**
   * The output URI. Currently only supports Google Cloud Storage URIs of the
   * form: `gs://BUCKET_NAME[/NAMESPACE_PATH]`, where `BUCKET_NAME` is the name
   * of the Google Cloud Storage bucket and `NAMESPACE_PATH` is an optional
   * Google Cloud Storage namespace path. When
   * choosing a name, be sure to consider Google Cloud Storage naming
   * guidelines: https://cloud.google.com/storage/docs/naming.
   * If the URI is a bucket (without a namespace path), a prefix will be
   * generated based on the start time.
   */
  outputUriPrefix: string;
  /**
   * An empty list represents all namespaces. This is the preferred
   * usage for databases that don't use namespaces.
   *
   * An empty string element represents the default namespace. This should be
   * used if the database has data in non-default namespaces, but doesn't want
   * to include them. Each namespace in this list must be unique.
   */
  namespaceIds: string[];
  /**
   * The timestamp that corresponds to the version of the database to be
   * exported. The timestamp must be in the past, rounded to the minute and not
   * older than
   * [earliestVersionTime][google.firestore.admin.v1.Database.earliest_version_time].
   * If specified, then the exported documents will represent a consistent view
   * of the database at the provided time. Otherwise, there are no guarantees
   * about the consistency of the exported documents.
   */
  snapshotTime: Date | undefined;
}

/**
 * The request for
 * [FirestoreAdmin.ImportDocuments][google.firestore.admin.v1.FirestoreAdmin.ImportDocuments].
 */
export interface ImportDocumentsRequest {
  /**
   * Required. Database to import into. Should be of the form:
   * `projects/{project_id}/databases/{database_id}`.
   */
  name: string;
  /**
   * Which collection IDs to import. Unspecified means all collections included
   * in the import. Each collection ID in this list must be unique.
   */
  collectionIds: string[];
  /**
   * Location of the exported files.
   * This must match the output_uri_prefix of an ExportDocumentsResponse from
   * an export that has completed successfully.
   * See:
   * [google.firestore.admin.v1.ExportDocumentsResponse.output_uri_prefix][google.firestore.admin.v1.ExportDocumentsResponse.output_uri_prefix].
   */
  inputUriPrefix: string;
  /**
   * An empty list represents all namespaces. This is the preferred
   * usage for databases that don't use namespaces.
   *
   * An empty string element represents the default namespace. This should be
   * used if the database has data in non-default namespaces, but doesn't want
   * to include them. Each namespace in this list must be unique.
   */
  namespaceIds: string[];
}

/**
 * The request for
 * [FirestoreAdmin.BulkDeleteDocuments][google.firestore.admin.v1.FirestoreAdmin.BulkDeleteDocuments].
 *
 * When both collection_ids and namespace_ids are set, only documents satisfying
 * both conditions will be deleted.
 *
 * Requests with namespace_ids and collection_ids both empty will be rejected.
 * Please use
 * [FirestoreAdmin.DeleteDatabase][google.firestore.admin.v1.FirestoreAdmin.DeleteDatabase]
 * instead.
 */
export interface BulkDeleteDocumentsRequest {
  /**
   * Required. Database to operate. Should be of the form:
   * `projects/{project_id}/databases/{database_id}`.
   */
  name: string;
  /**
   * Optional. IDs of the collection groups to delete. Unspecified means all
   * collection groups.
   *
   * Each collection group in this list must be unique.
   */
  collectionIds: string[];
  /**
   * Optional. Namespaces to delete.
   *
   * An empty list means all namespaces. This is the recommended
   * usage for databases that don't use namespaces.
   *
   * An empty string element represents the default namespace. This should be
   * used if the database has data in non-default namespaces, but doesn't want
   * to delete from them.
   *
   * Each namespace in this list must be unique.
   */
  namespaceIds: string[];
}

/**
 * The response for
 * [FirestoreAdmin.BulkDeleteDocuments][google.firestore.admin.v1.FirestoreAdmin.BulkDeleteDocuments].
 */
export interface BulkDeleteDocumentsResponse {
}

/**
 * The request for
 * [FirestoreAdmin.GetBackup][google.firestore.admin.v1.FirestoreAdmin.GetBackup].
 */
export interface GetBackupRequest {
  /**
   * Required. Name of the backup to fetch.
   *
   * Format is `projects/{project}/locations/{location}/backups/{backup}`.
   */
  name: string;
}

/**
 * The request for
 * [FirestoreAdmin.ListBackups][google.firestore.admin.v1.FirestoreAdmin.ListBackups].
 */
export interface ListBackupsRequest {
  /**
   * Required. The location to list backups from.
   *
   * Format is `projects/{project}/locations/{location}`.
   * Use `{location} = '-'` to list backups from all locations for the given
   * project. This allows listing backups from a single location or from all
   * locations.
   */
  parent: string;
}

/**
 * The response for
 * [FirestoreAdmin.ListBackups][google.firestore.admin.v1.FirestoreAdmin.ListBackups].
 */
export interface ListBackupsResponse {
  /** List of all backups for the project. */
  backups: Backup[];
  /**
   * List of locations that existing backups were not able to be fetched from.
   *
   * Instead of failing the entire requests when a single location is
   * unreachable, this response returns a partial result set and list of
   * locations unable to be reached here. The request can be retried against a
   * single location to get a concrete error.
   */
  unreachable: string[];
}

/**
 * The request for
 * [FirestoreAdmin.DeleteBackup][google.firestore.admin.v1.FirestoreAdmin.DeleteBackup].
 */
export interface DeleteBackupRequest {
  /**
   * Required. Name of the backup to delete.
   *
   * format is `projects/{project}/locations/{location}/backups/{backup}`.
   */
  name: string;
}

/**
 * The request message for
 * [FirestoreAdmin.RestoreDatabase][google.firestore.admin.v1.FirestoreAdmin.RestoreDatabase].
 */
export interface RestoreDatabaseRequest {
  /**
   * Required. The project to restore the database in. Format is
   * `projects/{project_id}`.
   */
  parent: string;
  /**
   * Required. The ID to use for the database, which will become the final
   * component of the database's resource name. This database ID must not be
   * associated with an existing database.
   *
   * This value should be 4-63 characters. Valid characters are /[a-z][0-9]-/
   * with first character a letter and the last a letter or a number. Must not
   * be UUID-like /[0-9a-f]{8}(-[0-9a-f]{4}){3}-[0-9a-f]{12}/.
   *
   * "(default)" database ID is also valid.
   */
  databaseId: string;
  /**
   * Required. Backup to restore from. Must be from the same project as the
   * parent.
   *
   * The restored database will be created in the same location as the source
   * backup.
   *
   * Format is: `projects/{project_id}/locations/{location}/backups/{backup}`
   */
  backup: string;
  /**
   * Optional. Encryption configuration for the restored database.
   *
   * If this field is not specified, the restored database will use
   * the same encryption configuration as the backup, namely
   * [use_source_encryption][google.firestore.admin.v1.Database.EncryptionConfig.use_source_encryption].
   */
  encryptionConfig: Database_EncryptionConfig | undefined;
}

function createBaseListDatabasesRequest(): ListDatabasesRequest {
  return { parent: "", showDeleted: false };
}

export const ListDatabasesRequest: MessageFns<ListDatabasesRequest> = {
  encode(message: ListDatabasesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.showDeleted !== false) {
      writer.uint32(32).bool(message.showDeleted);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabasesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabasesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.showDeleted = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabasesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      showDeleted: isSet(object.showDeleted) ? globalThis.Boolean(object.showDeleted) : false,
    };
  },

  toJSON(message: ListDatabasesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.showDeleted !== false) {
      obj.showDeleted = message.showDeleted;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabasesRequest>): ListDatabasesRequest {
    return ListDatabasesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabasesRequest>): ListDatabasesRequest {
    const message = createBaseListDatabasesRequest();
    message.parent = object.parent ?? "";
    message.showDeleted = object.showDeleted ?? false;
    return message;
  },
};

function createBaseCreateDatabaseRequest(): CreateDatabaseRequest {
  return { parent: "", database: undefined, databaseId: "" };
}

export const CreateDatabaseRequest: MessageFns<CreateDatabaseRequest> = {
  encode(message: CreateDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.database !== undefined) {
      Database.encode(message.database, writer.uint32(18).fork()).join();
    }
    if (message.databaseId !== "") {
      writer.uint32(26).string(message.databaseId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.database = Database.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.databaseId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateDatabaseRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      database: isSet(object.database) ? Database.fromJSON(object.database) : undefined,
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
    };
  },

  toJSON(message: CreateDatabaseRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.database !== undefined) {
      obj.database = Database.toJSON(message.database);
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateDatabaseRequest>): CreateDatabaseRequest {
    return CreateDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateDatabaseRequest>): CreateDatabaseRequest {
    const message = createBaseCreateDatabaseRequest();
    message.parent = object.parent ?? "";
    message.database = (object.database !== undefined && object.database !== null)
      ? Database.fromPartial(object.database)
      : undefined;
    message.databaseId = object.databaseId ?? "";
    return message;
  },
};

function createBaseCreateDatabaseMetadata(): CreateDatabaseMetadata {
  return {};
}

export const CreateDatabaseMetadata: MessageFns<CreateDatabaseMetadata> = {
  encode(_: CreateDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CreateDatabaseMetadata {
    return {};
  },

  toJSON(_: CreateDatabaseMetadata): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<CreateDatabaseMetadata>): CreateDatabaseMetadata {
    return CreateDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<CreateDatabaseMetadata>): CreateDatabaseMetadata {
    const message = createBaseCreateDatabaseMetadata();
    return message;
  },
};

function createBaseListDatabasesResponse(): ListDatabasesResponse {
  return { databases: [], unreachable: [] };
}

export const ListDatabasesResponse: MessageFns<ListDatabasesResponse> = {
  encode(message: ListDatabasesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.databases) {
      Database.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatabasesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatabasesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.databases.push(Database.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatabasesResponse {
    return {
      databases: globalThis.Array.isArray(object?.databases)
        ? object.databases.map((e: any) => Database.fromJSON(e))
        : [],
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListDatabasesResponse): unknown {
    const obj: any = {};
    if (message.databases?.length) {
      obj.databases = message.databases.map((e) => Database.toJSON(e));
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListDatabasesResponse>): ListDatabasesResponse {
    return ListDatabasesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListDatabasesResponse>): ListDatabasesResponse {
    const message = createBaseListDatabasesResponse();
    message.databases = object.databases?.map((e) => Database.fromPartial(e)) || [];
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseGetDatabaseRequest(): GetDatabaseRequest {
  return { name: "" };
}

export const GetDatabaseRequest: MessageFns<GetDatabaseRequest> = {
  encode(message: GetDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatabaseRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetDatabaseRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDatabaseRequest>): GetDatabaseRequest {
    return GetDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDatabaseRequest>): GetDatabaseRequest {
    const message = createBaseGetDatabaseRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateDatabaseRequest(): UpdateDatabaseRequest {
  return { database: undefined, updateMask: undefined };
}

export const UpdateDatabaseRequest: MessageFns<UpdateDatabaseRequest> = {
  encode(message: UpdateDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== undefined) {
      Database.encode(message.database, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = Database.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateDatabaseRequest {
    return {
      database: isSet(object.database) ? Database.fromJSON(object.database) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateDatabaseRequest): unknown {
    const obj: any = {};
    if (message.database !== undefined) {
      obj.database = Database.toJSON(message.database);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateDatabaseRequest>): UpdateDatabaseRequest {
    return UpdateDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateDatabaseRequest>): UpdateDatabaseRequest {
    const message = createBaseUpdateDatabaseRequest();
    message.database = (object.database !== undefined && object.database !== null)
      ? Database.fromPartial(object.database)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseUpdateDatabaseMetadata(): UpdateDatabaseMetadata {
  return {};
}

export const UpdateDatabaseMetadata: MessageFns<UpdateDatabaseMetadata> = {
  encode(_: UpdateDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): UpdateDatabaseMetadata {
    return {};
  },

  toJSON(_: UpdateDatabaseMetadata): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<UpdateDatabaseMetadata>): UpdateDatabaseMetadata {
    return UpdateDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<UpdateDatabaseMetadata>): UpdateDatabaseMetadata {
    const message = createBaseUpdateDatabaseMetadata();
    return message;
  },
};

function createBaseDeleteDatabaseRequest(): DeleteDatabaseRequest {
  return { name: "", etag: "" };
}

export const DeleteDatabaseRequest: MessageFns<DeleteDatabaseRequest> = {
  encode(message: DeleteDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.etag !== "") {
      writer.uint32(26).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.etag = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteDatabaseRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DeleteDatabaseRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteDatabaseRequest>): DeleteDatabaseRequest {
    return DeleteDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteDatabaseRequest>): DeleteDatabaseRequest {
    const message = createBaseDeleteDatabaseRequest();
    message.name = object.name ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseDeleteDatabaseMetadata(): DeleteDatabaseMetadata {
  return {};
}

export const DeleteDatabaseMetadata: MessageFns<DeleteDatabaseMetadata> = {
  encode(_: DeleteDatabaseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteDatabaseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteDatabaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DeleteDatabaseMetadata {
    return {};
  },

  toJSON(_: DeleteDatabaseMetadata): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<DeleteDatabaseMetadata>): DeleteDatabaseMetadata {
    return DeleteDatabaseMetadata.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<DeleteDatabaseMetadata>): DeleteDatabaseMetadata {
    const message = createBaseDeleteDatabaseMetadata();
    return message;
  },
};

function createBaseCreateBackupScheduleRequest(): CreateBackupScheduleRequest {
  return { parent: "", backupSchedule: undefined };
}

export const CreateBackupScheduleRequest: MessageFns<CreateBackupScheduleRequest> = {
  encode(message: CreateBackupScheduleRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.backupSchedule !== undefined) {
      BackupSchedule.encode(message.backupSchedule, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateBackupScheduleRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateBackupScheduleRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.backupSchedule = BackupSchedule.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateBackupScheduleRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      backupSchedule: isSet(object.backupSchedule) ? BackupSchedule.fromJSON(object.backupSchedule) : undefined,
    };
  },

  toJSON(message: CreateBackupScheduleRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.backupSchedule !== undefined) {
      obj.backupSchedule = BackupSchedule.toJSON(message.backupSchedule);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateBackupScheduleRequest>): CreateBackupScheduleRequest {
    return CreateBackupScheduleRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateBackupScheduleRequest>): CreateBackupScheduleRequest {
    const message = createBaseCreateBackupScheduleRequest();
    message.parent = object.parent ?? "";
    message.backupSchedule = (object.backupSchedule !== undefined && object.backupSchedule !== null)
      ? BackupSchedule.fromPartial(object.backupSchedule)
      : undefined;
    return message;
  },
};

function createBaseGetBackupScheduleRequest(): GetBackupScheduleRequest {
  return { name: "" };
}

export const GetBackupScheduleRequest: MessageFns<GetBackupScheduleRequest> = {
  encode(message: GetBackupScheduleRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBackupScheduleRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBackupScheduleRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBackupScheduleRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetBackupScheduleRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBackupScheduleRequest>): GetBackupScheduleRequest {
    return GetBackupScheduleRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBackupScheduleRequest>): GetBackupScheduleRequest {
    const message = createBaseGetBackupScheduleRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateBackupScheduleRequest(): UpdateBackupScheduleRequest {
  return { backupSchedule: undefined, updateMask: undefined };
}

export const UpdateBackupScheduleRequest: MessageFns<UpdateBackupScheduleRequest> = {
  encode(message: UpdateBackupScheduleRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backupSchedule !== undefined) {
      BackupSchedule.encode(message.backupSchedule, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateBackupScheduleRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateBackupScheduleRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backupSchedule = BackupSchedule.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateBackupScheduleRequest {
    return {
      backupSchedule: isSet(object.backupSchedule) ? BackupSchedule.fromJSON(object.backupSchedule) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateBackupScheduleRequest): unknown {
    const obj: any = {};
    if (message.backupSchedule !== undefined) {
      obj.backupSchedule = BackupSchedule.toJSON(message.backupSchedule);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateBackupScheduleRequest>): UpdateBackupScheduleRequest {
    return UpdateBackupScheduleRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateBackupScheduleRequest>): UpdateBackupScheduleRequest {
    const message = createBaseUpdateBackupScheduleRequest();
    message.backupSchedule = (object.backupSchedule !== undefined && object.backupSchedule !== null)
      ? BackupSchedule.fromPartial(object.backupSchedule)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseListBackupSchedulesRequest(): ListBackupSchedulesRequest {
  return { parent: "" };
}

export const ListBackupSchedulesRequest: MessageFns<ListBackupSchedulesRequest> = {
  encode(message: ListBackupSchedulesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupSchedulesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupSchedulesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupSchedulesRequest {
    return { parent: isSet(object.parent) ? globalThis.String(object.parent) : "" };
  },

  toJSON(message: ListBackupSchedulesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupSchedulesRequest>): ListBackupSchedulesRequest {
    return ListBackupSchedulesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupSchedulesRequest>): ListBackupSchedulesRequest {
    const message = createBaseListBackupSchedulesRequest();
    message.parent = object.parent ?? "";
    return message;
  },
};

function createBaseListBackupSchedulesResponse(): ListBackupSchedulesResponse {
  return { backupSchedules: [] };
}

export const ListBackupSchedulesResponse: MessageFns<ListBackupSchedulesResponse> = {
  encode(message: ListBackupSchedulesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.backupSchedules) {
      BackupSchedule.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupSchedulesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupSchedulesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backupSchedules.push(BackupSchedule.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupSchedulesResponse {
    return {
      backupSchedules: globalThis.Array.isArray(object?.backupSchedules)
        ? object.backupSchedules.map((e: any) => BackupSchedule.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ListBackupSchedulesResponse): unknown {
    const obj: any = {};
    if (message.backupSchedules?.length) {
      obj.backupSchedules = message.backupSchedules.map((e) => BackupSchedule.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupSchedulesResponse>): ListBackupSchedulesResponse {
    return ListBackupSchedulesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupSchedulesResponse>): ListBackupSchedulesResponse {
    const message = createBaseListBackupSchedulesResponse();
    message.backupSchedules = object.backupSchedules?.map((e) => BackupSchedule.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDeleteBackupScheduleRequest(): DeleteBackupScheduleRequest {
  return { name: "" };
}

export const DeleteBackupScheduleRequest: MessageFns<DeleteBackupScheduleRequest> = {
  encode(message: DeleteBackupScheduleRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBackupScheduleRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBackupScheduleRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBackupScheduleRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteBackupScheduleRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBackupScheduleRequest>): DeleteBackupScheduleRequest {
    return DeleteBackupScheduleRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBackupScheduleRequest>): DeleteBackupScheduleRequest {
    const message = createBaseDeleteBackupScheduleRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateIndexRequest(): CreateIndexRequest {
  return { parent: "", index: undefined };
}

export const CreateIndexRequest: MessageFns<CreateIndexRequest> = {
  encode(message: CreateIndexRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.index !== undefined) {
      Index.encode(message.index, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateIndexRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateIndexRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.index = Index.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateIndexRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      index: isSet(object.index) ? Index.fromJSON(object.index) : undefined,
    };
  },

  toJSON(message: CreateIndexRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.index !== undefined) {
      obj.index = Index.toJSON(message.index);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateIndexRequest>): CreateIndexRequest {
    return CreateIndexRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateIndexRequest>): CreateIndexRequest {
    const message = createBaseCreateIndexRequest();
    message.parent = object.parent ?? "";
    message.index = (object.index !== undefined && object.index !== null) ? Index.fromPartial(object.index) : undefined;
    return message;
  },
};

function createBaseListIndexesRequest(): ListIndexesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "" };
}

export const ListIndexesRequest: MessageFns<ListIndexesRequest> = {
  encode(message: ListIndexesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListIndexesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListIndexesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListIndexesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListIndexesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListIndexesRequest>): ListIndexesRequest {
    return ListIndexesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListIndexesRequest>): ListIndexesRequest {
    const message = createBaseListIndexesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListIndexesResponse(): ListIndexesResponse {
  return { indexes: [], nextPageToken: "" };
}

export const ListIndexesResponse: MessageFns<ListIndexesResponse> = {
  encode(message: ListIndexesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.indexes) {
      Index.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListIndexesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListIndexesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.indexes.push(Index.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListIndexesResponse {
    return {
      indexes: globalThis.Array.isArray(object?.indexes) ? object.indexes.map((e: any) => Index.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListIndexesResponse): unknown {
    const obj: any = {};
    if (message.indexes?.length) {
      obj.indexes = message.indexes.map((e) => Index.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListIndexesResponse>): ListIndexesResponse {
    return ListIndexesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListIndexesResponse>): ListIndexesResponse {
    const message = createBaseListIndexesResponse();
    message.indexes = object.indexes?.map((e) => Index.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetIndexRequest(): GetIndexRequest {
  return { name: "" };
}

export const GetIndexRequest: MessageFns<GetIndexRequest> = {
  encode(message: GetIndexRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetIndexRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetIndexRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetIndexRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetIndexRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetIndexRequest>): GetIndexRequest {
    return GetIndexRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetIndexRequest>): GetIndexRequest {
    const message = createBaseGetIndexRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseDeleteIndexRequest(): DeleteIndexRequest {
  return { name: "" };
}

export const DeleteIndexRequest: MessageFns<DeleteIndexRequest> = {
  encode(message: DeleteIndexRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteIndexRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteIndexRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteIndexRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteIndexRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteIndexRequest>): DeleteIndexRequest {
    return DeleteIndexRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteIndexRequest>): DeleteIndexRequest {
    const message = createBaseDeleteIndexRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseUpdateFieldRequest(): UpdateFieldRequest {
  return { field: undefined, updateMask: undefined };
}

export const UpdateFieldRequest: MessageFns<UpdateFieldRequest> = {
  encode(message: UpdateFieldRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== undefined) {
      Field.encode(message.field, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFieldRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFieldRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.field = Field.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFieldRequest {
    return {
      field: isSet(object.field) ? Field.fromJSON(object.field) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateFieldRequest): unknown {
    const obj: any = {};
    if (message.field !== undefined) {
      obj.field = Field.toJSON(message.field);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFieldRequest>): UpdateFieldRequest {
    return UpdateFieldRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFieldRequest>): UpdateFieldRequest {
    const message = createBaseUpdateFieldRequest();
    message.field = (object.field !== undefined && object.field !== null) ? Field.fromPartial(object.field) : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseGetFieldRequest(): GetFieldRequest {
  return { name: "" };
}

export const GetFieldRequest: MessageFns<GetFieldRequest> = {
  encode(message: GetFieldRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFieldRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFieldRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFieldRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetFieldRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetFieldRequest>): GetFieldRequest {
    return GetFieldRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFieldRequest>): GetFieldRequest {
    const message = createBaseGetFieldRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListFieldsRequest(): ListFieldsRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "" };
}

export const ListFieldsRequest: MessageFns<ListFieldsRequest> = {
  encode(message: ListFieldsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFieldsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFieldsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFieldsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListFieldsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFieldsRequest>): ListFieldsRequest {
    return ListFieldsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFieldsRequest>): ListFieldsRequest {
    const message = createBaseListFieldsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListFieldsResponse(): ListFieldsResponse {
  return { fields: [], nextPageToken: "" };
}

export const ListFieldsResponse: MessageFns<ListFieldsResponse> = {
  encode(message: ListFieldsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fields) {
      Field.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFieldsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFieldsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fields.push(Field.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFieldsResponse {
    return {
      fields: globalThis.Array.isArray(object?.fields) ? object.fields.map((e: any) => Field.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListFieldsResponse): unknown {
    const obj: any = {};
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => Field.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFieldsResponse>): ListFieldsResponse {
    return ListFieldsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFieldsResponse>): ListFieldsResponse {
    const message = createBaseListFieldsResponse();
    message.fields = object.fields?.map((e) => Field.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseExportDocumentsRequest(): ExportDocumentsRequest {
  return { name: "", collectionIds: [], outputUriPrefix: "", namespaceIds: [], snapshotTime: undefined };
}

export const ExportDocumentsRequest: MessageFns<ExportDocumentsRequest> = {
  encode(message: ExportDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.collectionIds) {
      writer.uint32(18).string(v!);
    }
    if (message.outputUriPrefix !== "") {
      writer.uint32(26).string(message.outputUriPrefix);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(34).string(v!);
    }
    if (message.snapshotTime !== undefined) {
      Timestamp.encode(toTimestamp(message.snapshotTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.outputUriPrefix = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.snapshotTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportDocumentsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      outputUriPrefix: isSet(object.outputUriPrefix) ? globalThis.String(object.outputUriPrefix) : "",
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
      snapshotTime: isSet(object.snapshotTime) ? fromJsonTimestamp(object.snapshotTime) : undefined,
    };
  },

  toJSON(message: ExportDocumentsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.outputUriPrefix !== "") {
      obj.outputUriPrefix = message.outputUriPrefix;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    if (message.snapshotTime !== undefined) {
      obj.snapshotTime = message.snapshotTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ExportDocumentsRequest>): ExportDocumentsRequest {
    return ExportDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportDocumentsRequest>): ExportDocumentsRequest {
    const message = createBaseExportDocumentsRequest();
    message.name = object.name ?? "";
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.outputUriPrefix = object.outputUriPrefix ?? "";
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    message.snapshotTime = object.snapshotTime ?? undefined;
    return message;
  },
};

function createBaseImportDocumentsRequest(): ImportDocumentsRequest {
  return { name: "", collectionIds: [], inputUriPrefix: "", namespaceIds: [] };
}

export const ImportDocumentsRequest: MessageFns<ImportDocumentsRequest> = {
  encode(message: ImportDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.collectionIds) {
      writer.uint32(18).string(v!);
    }
    if (message.inputUriPrefix !== "") {
      writer.uint32(26).string(message.inputUriPrefix);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(34).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inputUriPrefix = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportDocumentsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      inputUriPrefix: isSet(object.inputUriPrefix) ? globalThis.String(object.inputUriPrefix) : "",
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ImportDocumentsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.inputUriPrefix !== "") {
      obj.inputUriPrefix = message.inputUriPrefix;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportDocumentsRequest>): ImportDocumentsRequest {
    return ImportDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportDocumentsRequest>): ImportDocumentsRequest {
    const message = createBaseImportDocumentsRequest();
    message.name = object.name ?? "";
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.inputUriPrefix = object.inputUriPrefix ?? "";
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseBulkDeleteDocumentsRequest(): BulkDeleteDocumentsRequest {
  return { name: "", collectionIds: [], namespaceIds: [] };
}

export const BulkDeleteDocumentsRequest: MessageFns<BulkDeleteDocumentsRequest> = {
  encode(message: BulkDeleteDocumentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.collectionIds) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.namespaceIds) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BulkDeleteDocumentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBulkDeleteDocumentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.collectionIds.push(reader.string());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.namespaceIds.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BulkDeleteDocumentsRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      collectionIds: globalThis.Array.isArray(object?.collectionIds)
        ? object.collectionIds.map((e: any) => globalThis.String(e))
        : [],
      namespaceIds: globalThis.Array.isArray(object?.namespaceIds)
        ? object.namespaceIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: BulkDeleteDocumentsRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.collectionIds?.length) {
      obj.collectionIds = message.collectionIds;
    }
    if (message.namespaceIds?.length) {
      obj.namespaceIds = message.namespaceIds;
    }
    return obj;
  },

  create(base?: DeepPartial<BulkDeleteDocumentsRequest>): BulkDeleteDocumentsRequest {
    return BulkDeleteDocumentsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BulkDeleteDocumentsRequest>): BulkDeleteDocumentsRequest {
    const message = createBaseBulkDeleteDocumentsRequest();
    message.name = object.name ?? "";
    message.collectionIds = object.collectionIds?.map((e) => e) || [];
    message.namespaceIds = object.namespaceIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseBulkDeleteDocumentsResponse(): BulkDeleteDocumentsResponse {
  return {};
}

export const BulkDeleteDocumentsResponse: MessageFns<BulkDeleteDocumentsResponse> = {
  encode(_: BulkDeleteDocumentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BulkDeleteDocumentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBulkDeleteDocumentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): BulkDeleteDocumentsResponse {
    return {};
  },

  toJSON(_: BulkDeleteDocumentsResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<BulkDeleteDocumentsResponse>): BulkDeleteDocumentsResponse {
    return BulkDeleteDocumentsResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<BulkDeleteDocumentsResponse>): BulkDeleteDocumentsResponse {
    const message = createBaseBulkDeleteDocumentsResponse();
    return message;
  },
};

function createBaseGetBackupRequest(): GetBackupRequest {
  return { name: "" };
}

export const GetBackupRequest: MessageFns<GetBackupRequest> = {
  encode(message: GetBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetBackupRequest>): GetBackupRequest {
    return GetBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetBackupRequest>): GetBackupRequest {
    const message = createBaseGetBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListBackupsRequest(): ListBackupsRequest {
  return { parent: "" };
}

export const ListBackupsRequest: MessageFns<ListBackupsRequest> = {
  encode(message: ListBackupsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsRequest {
    return { parent: isSet(object.parent) ? globalThis.String(object.parent) : "" };
  },

  toJSON(message: ListBackupsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    return ListBackupsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsRequest>): ListBackupsRequest {
    const message = createBaseListBackupsRequest();
    message.parent = object.parent ?? "";
    return message;
  },
};

function createBaseListBackupsResponse(): ListBackupsResponse {
  return { backups: [], unreachable: [] };
}

export const ListBackupsResponse: MessageFns<ListBackupsResponse> = {
  encode(message: ListBackupsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.backups) {
      Backup.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.unreachable) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListBackupsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListBackupsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.backups.push(Backup.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.unreachable.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListBackupsResponse {
    return {
      backups: globalThis.Array.isArray(object?.backups) ? object.backups.map((e: any) => Backup.fromJSON(e)) : [],
      unreachable: globalThis.Array.isArray(object?.unreachable)
        ? object.unreachable.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: ListBackupsResponse): unknown {
    const obj: any = {};
    if (message.backups?.length) {
      obj.backups = message.backups.map((e) => Backup.toJSON(e));
    }
    if (message.unreachable?.length) {
      obj.unreachable = message.unreachable;
    }
    return obj;
  },

  create(base?: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    return ListBackupsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListBackupsResponse>): ListBackupsResponse {
    const message = createBaseListBackupsResponse();
    message.backups = object.backups?.map((e) => Backup.fromPartial(e)) || [];
    message.unreachable = object.unreachable?.map((e) => e) || [];
    return message;
  },
};

function createBaseDeleteBackupRequest(): DeleteBackupRequest {
  return { name: "" };
}

export const DeleteBackupRequest: MessageFns<DeleteBackupRequest> = {
  encode(message: DeleteBackupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteBackupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteBackupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteBackupRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteBackupRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    return DeleteBackupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteBackupRequest>): DeleteBackupRequest {
    const message = createBaseDeleteBackupRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseRestoreDatabaseRequest(): RestoreDatabaseRequest {
  return { parent: "", databaseId: "", backup: "", encryptionConfig: undefined };
}

export const RestoreDatabaseRequest: MessageFns<RestoreDatabaseRequest> = {
  encode(message: RestoreDatabaseRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.databaseId !== "") {
      writer.uint32(18).string(message.databaseId);
    }
    if (message.backup !== "") {
      writer.uint32(26).string(message.backup);
    }
    if (message.encryptionConfig !== undefined) {
      Database_EncryptionConfig.encode(message.encryptionConfig, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreDatabaseRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreDatabaseRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.databaseId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.backup = reader.string();
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.encryptionConfig = Database_EncryptionConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreDatabaseRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      databaseId: isSet(object.databaseId) ? globalThis.String(object.databaseId) : "",
      backup: isSet(object.backup) ? globalThis.String(object.backup) : "",
      encryptionConfig: isSet(object.encryptionConfig)
        ? Database_EncryptionConfig.fromJSON(object.encryptionConfig)
        : undefined,
    };
  },

  toJSON(message: RestoreDatabaseRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.databaseId !== "") {
      obj.databaseId = message.databaseId;
    }
    if (message.backup !== "") {
      obj.backup = message.backup;
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = Database_EncryptionConfig.toJSON(message.encryptionConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<RestoreDatabaseRequest>): RestoreDatabaseRequest {
    return RestoreDatabaseRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<RestoreDatabaseRequest>): RestoreDatabaseRequest {
    const message = createBaseRestoreDatabaseRequest();
    message.parent = object.parent ?? "";
    message.databaseId = object.databaseId ?? "";
    message.backup = object.backup ?? "";
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? Database_EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    return message;
  },
};

/**
 * The Cloud Firestore Admin API.
 *
 * This API provides several administrative services for Cloud Firestore.
 *
 * Project, Database, Namespace, Collection, Collection Group, and Document are
 * used as defined in the Google Cloud Firestore API.
 *
 * Operation: An Operation represents work being performed in the background.
 *
 * The index service manages Cloud Firestore indexes.
 *
 * Index creation is performed asynchronously.
 * An Operation resource is created for each such asynchronous operation.
 * The state of the operation (including any errors encountered)
 * may be queried via the Operation resource.
 *
 * The Operations collection provides a record of actions performed for the
 * specified Project (including any Operations in progress). Operations are not
 * created directly but through calls on other collections or resources.
 *
 * An Operation that is done may be deleted so that it is no longer listed as
 * part of the Operation collection. Operations are garbage collected after
 * 30 days. By default, ListOperations will only return in progress and failed
 * operations. To list completed operation, issue a ListOperations request with
 * the filter `done: true`.
 *
 * Operations are created by service `FirestoreAdmin`, but are accessed via
 * service `google.longrunning.Operations`.
 */
export type FirestoreAdminDefinition = typeof FirestoreAdminDefinition;
export const FirestoreAdminDefinition = {
  name: "FirestoreAdmin",
  fullName: "google.firestore.admin.v1.FirestoreAdmin",
  methods: {
    /**
     * Creates a composite index. This returns a
     * [google.longrunning.Operation][google.longrunning.Operation] which may be
     * used to track the status of the creation. The metadata for the operation
     * will be the type
     * [IndexOperationMetadata][google.firestore.admin.v1.IndexOperationMetadata].
     */
    createIndex: {
      name: "CreateIndex",
      requestType: CreateIndexRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              5,
              73,
              110,
              100,
              101,
              120,
              18,
              22,
              73,
              110,
              100,
              101,
              120,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([12, 112, 97, 114, 101, 110, 116, 44, 105, 110, 100, 101, 120])],
          578365826: [
            Buffer.from([
              71,
              58,
              5,
              105,
              110,
              100,
              101,
              120,
              34,
              62,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Lists composite indexes. */
    listIndexes: {
      name: "ListIndexes",
      requestType: ListIndexesRequest,
      requestStream: false,
      responseType: ListIndexesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              64,
              18,
              62,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              125,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets a composite index. */
    getIndex: {
      name: "GetIndex",
      requestType: GetIndexRequest,
      requestStream: false,
      responseType: Index,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              64,
              18,
              62,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a composite index. */
    deleteIndex: {
      name: "DeleteIndex",
      requestType: DeleteIndexRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              64,
              42,
              62,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              47,
              105,
              110,
              100,
              101,
              120,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets the metadata and configuration for a Field. */
    getField: {
      name: "GetField",
      requestType: GetFieldRequest,
      requestStream: false,
      responseType: Field,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              63,
              18,
              61,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              47,
              102,
              105,
              101,
              108,
              100,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Updates a field configuration. Currently, field updates apply only to
     * single field index configuration. However, calls to
     * [FirestoreAdmin.UpdateField][google.firestore.admin.v1.FirestoreAdmin.UpdateField]
     * should provide a field mask to avoid changing any configuration that the
     * caller isn't aware of. The field mask should be specified as: `{ paths:
     * "index_config" }`.
     *
     * This call returns a
     * [google.longrunning.Operation][google.longrunning.Operation] which may be
     * used to track the status of the field update. The metadata for the
     * operation will be the type
     * [FieldOperationMetadata][google.firestore.admin.v1.FieldOperationMetadata].
     *
     * To configure the default field settings for the database, use
     * the special `Field` with resource name:
     * `projects/{project_id}/databases/{database_id}/collectionGroups/__default__/fields/*`.
     */
    updateField: {
      name: "UpdateField",
      requestType: UpdateFieldRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              31,
              10,
              5,
              70,
              105,
              101,
              108,
              100,
              18,
              22,
              70,
              105,
              101,
              108,
              100,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([5, 102, 105, 101, 108, 100])],
          578365826: [
            Buffer.from([
              76,
              58,
              5,
              102,
              105,
              101,
              108,
              100,
              50,
              67,
              47,
              118,
              49,
              47,
              123,
              102,
              105,
              101,
              108,
              100,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              47,
              102,
              105,
              101,
              108,
              100,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Lists the field configuration and metadata for this database.
     *
     * Currently,
     * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
     * only supports listing fields that have been explicitly overridden. To issue
     * this query, call
     * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
     * with the filter set to `indexConfig.usesAncestorConfig:false` or
     * `ttlConfig:*`.
     */
    listFields: {
      name: "ListFields",
      requestType: ListFieldsRequest,
      requestStream: false,
      responseType: ListFieldsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              63,
              18,
              61,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              99,
              111,
              108,
              108,
              101,
              99,
              116,
              105,
              111,
              110,
              71,
              114,
              111,
              117,
              112,
              115,
              47,
              42,
              125,
              47,
              102,
              105,
              101,
              108,
              100,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Exports a copy of all or a subset of documents from Google Cloud Firestore
     * to another storage system, such as Google Cloud Storage. Recent updates to
     * documents may not be reflected in the export. The export occurs in the
     * background and its progress can be monitored and managed via the
     * Operation resource that is created. The output of an export may only be
     * used once the associated operation is done. If an export operation is
     * cancelled before completion it may leave partial data behind in Google
     * Cloud Storage.
     *
     * For more details on export behavior and output format, refer to:
     * https://cloud.google.com/firestore/docs/manage-data/export-import
     */
    exportDocuments: {
      name: "ExportDocuments",
      requestType: ExportDocumentsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              50,
              10,
              23,
              69,
              120,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              23,
              69,
              120,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              54,
              58,
              1,
              42,
              34,
              49,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Imports documents into Google Cloud Firestore. Existing documents with the
     * same name are overwritten. The import occurs in the background and its
     * progress can be monitored and managed via the Operation resource that is
     * created. If an ImportDocuments operation is cancelled, it is possible
     * that a subset of the data has already been imported to Cloud Firestore.
     */
    importDocuments: {
      name: "ImportDocuments",
      requestType: ImportDocumentsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              73,
              109,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              54,
              58,
              1,
              42,
              34,
              49,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Bulk deletes a subset of documents from Google Cloud Firestore.
     * Documents created or updated after the underlying system starts to process
     * the request will not be deleted. The bulk delete occurs in the background
     * and its progress can be monitored and managed via the Operation resource
     * that is created.
     *
     * For more details on bulk delete behavior, refer to:
     * https://cloud.google.com/firestore/docs/manage-data/bulk-delete
     */
    bulkDeleteDocuments: {
      name: "BulkDeleteDocuments",
      requestType: BulkDeleteDocumentsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              58,
              10,
              27,
              66,
              117,
              108,
              107,
              68,
              101,
              108,
              101,
              116,
              101,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              27,
              66,
              117,
              108,
              107,
              68,
              101,
              108,
              101,
              116,
              101,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              58,
              58,
              1,
              42,
              34,
              53,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              58,
              98,
              117,
              108,
              107,
              68,
              101,
              108,
              101,
              116,
              101,
              68,
              111,
              99,
              117,
              109,
              101,
              110,
              116,
              115,
            ]),
          ],
        },
      },
    },
    /** Create a database. */
    createDatabase: {
      name: "CreateDatabase",
      requestType: CreateDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              34,
              10,
              8,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              22,
              67,
              114,
              101,
              97,
              116,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              27,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              44,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              45,
              58,
              8,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              34,
              33,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets information about a database. */
    getDatabase: {
      name: "GetDatabase",
      requestType: GetDatabaseRequest,
      requestStream: false,
      responseType: Database,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              35,
              18,
              33,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** List all the databases in the project. */
    listDatabases: {
      name: "ListDatabases",
      requestType: ListDatabasesRequest,
      requestStream: false,
      responseType: ListDatabasesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              35,
              18,
              33,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a database. */
    updateDatabase: {
      name: "UpdateDatabase",
      requestType: UpdateDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              34,
              10,
              8,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              22,
              85,
              112,
              100,
              97,
              116,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              20,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              54,
              58,
              8,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              50,
              42,
              47,
              118,
              49,
              47,
              123,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a database. */
    deleteDatabase: {
      name: "DeleteDatabase",
      requestType: DeleteDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              34,
              10,
              8,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              22,
              68,
              101,
              108,
              101,
              116,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              35,
              42,
              33,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Gets information about a backup. */
    getBackup: {
      name: "GetBackup",
      requestType: GetBackupRequest,
      requestStream: false,
      responseType: Backup,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              45,
              18,
              43,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists all the backups. */
    listBackups: {
      name: "ListBackups",
      requestType: ListBackupsRequest,
      requestStream: false,
      responseType: ListBackupsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              45,
              18,
              43,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a backup. */
    deleteBackup: {
      name: "DeleteBackup",
      requestType: DeleteBackupRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              45,
              42,
              43,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a new database by restoring from an existing backup.
     *
     * The new database must be in the same cloud region or multi-region location
     * as the existing backup. This behaves similar to
     * [FirestoreAdmin.CreateDatabase][google.firestore.admin.v1.FirestoreAdmin.CreateDatabase]
     * except instead of creating a new empty database, a new database is created
     * with the database type, index configuration, and documents from an existing
     * backup.
     *
     * The [long-running operation][google.longrunning.Operation] can be used to
     * track the progress of the restore, with the Operation's
     * [metadata][google.longrunning.Operation.metadata] field type being the
     * [RestoreDatabaseMetadata][google.firestore.admin.v1.RestoreDatabaseMetadata].
     * The [response][google.longrunning.Operation.response] type is the
     * [Database][google.firestore.admin.v1.Database] if the restore was
     * successful. The new database is not readable or writeable until the LRO has
     * completed.
     */
    restoreDatabase: {
      name: "RestoreDatabase",
      requestType: RestoreDatabaseRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              35,
              10,
              8,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              18,
              23,
              82,
              101,
              115,
              116,
              111,
              114,
              101,
              68,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          578365826: [
            Buffer.from([
              46,
              58,
              1,
              42,
              34,
              41,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              125,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              58,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a backup schedule on a database.
     * At most two backup schedules can be configured on a database, one daily
     * backup schedule and one weekly backup schedule.
     */
    createBackupSchedule: {
      name: "CreateBackupSchedule",
      requestType: CreateBackupScheduleRequest,
      requestStream: false,
      responseType: BackupSchedule,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              22,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              70,
              58,
              15,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              34,
              51,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets information about a backup schedule. */
    getBackupSchedule: {
      name: "GetBackupSchedule",
      requestType: GetBackupScheduleRequest,
      requestStream: false,
      responseType: BackupSchedule,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              53,
              18,
              51,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** List backup schedules. */
    listBackupSchedules: {
      name: "ListBackupSchedules",
      requestType: ListBackupSchedulesRequest,
      requestStream: false,
      responseType: ListBackupSchedulesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              53,
              18,
              51,
              47,
              118,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              125,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a backup schedule. */
    updateBackupSchedule: {
      name: "UpdateBackupSchedule",
      requestType: UpdateBackupScheduleRequest,
      requestStream: false,
      responseType: BackupSchedule,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              27,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              86,
              58,
              15,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              50,
              67,
              47,
              118,
              49,
              47,
              123,
              98,
              97,
              99,
              107,
              117,
              112,
              95,
              115,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a backup schedule. */
    deleteBackupSchedule: {
      name: "DeleteBackupSchedule",
      requestType: DeleteBackupScheduleRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              53,
              42,
              51,
              47,
              118,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              100,
              97,
              116,
              97,
              98,
              97,
              115,
              101,
              115,
              47,
              42,
              47,
              98,
              97,
              99,
              107,
              117,
              112,
              83,
              99,
              104,
              101,
              100,
              117,
              108,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface FirestoreAdminServiceImplementation<CallContextExt = {}> {
  /**
   * Creates a composite index. This returns a
   * [google.longrunning.Operation][google.longrunning.Operation] which may be
   * used to track the status of the creation. The metadata for the operation
   * will be the type
   * [IndexOperationMetadata][google.firestore.admin.v1.IndexOperationMetadata].
   */
  createIndex(request: CreateIndexRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Lists composite indexes. */
  listIndexes(
    request: ListIndexesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListIndexesResponse>>;
  /** Gets a composite index. */
  getIndex(request: GetIndexRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Index>>;
  /** Deletes a composite index. */
  deleteIndex(request: DeleteIndexRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /** Gets the metadata and configuration for a Field. */
  getField(request: GetFieldRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Field>>;
  /**
   * Updates a field configuration. Currently, field updates apply only to
   * single field index configuration. However, calls to
   * [FirestoreAdmin.UpdateField][google.firestore.admin.v1.FirestoreAdmin.UpdateField]
   * should provide a field mask to avoid changing any configuration that the
   * caller isn't aware of. The field mask should be specified as: `{ paths:
   * "index_config" }`.
   *
   * This call returns a
   * [google.longrunning.Operation][google.longrunning.Operation] which may be
   * used to track the status of the field update. The metadata for the
   * operation will be the type
   * [FieldOperationMetadata][google.firestore.admin.v1.FieldOperationMetadata].
   *
   * To configure the default field settings for the database, use
   * the special `Field` with resource name:
   * `projects/{project_id}/databases/{database_id}/collectionGroups/__default__/fields/*`.
   */
  updateField(request: UpdateFieldRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Lists the field configuration and metadata for this database.
   *
   * Currently,
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
   * only supports listing fields that have been explicitly overridden. To issue
   * this query, call
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
   * with the filter set to `indexConfig.usesAncestorConfig:false` or
   * `ttlConfig:*`.
   */
  listFields(
    request: ListFieldsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListFieldsResponse>>;
  /**
   * Exports a copy of all or a subset of documents from Google Cloud Firestore
   * to another storage system, such as Google Cloud Storage. Recent updates to
   * documents may not be reflected in the export. The export occurs in the
   * background and its progress can be monitored and managed via the
   * Operation resource that is created. The output of an export may only be
   * used once the associated operation is done. If an export operation is
   * cancelled before completion it may leave partial data behind in Google
   * Cloud Storage.
   *
   * For more details on export behavior and output format, refer to:
   * https://cloud.google.com/firestore/docs/manage-data/export-import
   */
  exportDocuments(
    request: ExportDocumentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Imports documents into Google Cloud Firestore. Existing documents with the
   * same name are overwritten. The import occurs in the background and its
   * progress can be monitored and managed via the Operation resource that is
   * created. If an ImportDocuments operation is cancelled, it is possible
   * that a subset of the data has already been imported to Cloud Firestore.
   */
  importDocuments(
    request: ImportDocumentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Bulk deletes a subset of documents from Google Cloud Firestore.
   * Documents created or updated after the underlying system starts to process
   * the request will not be deleted. The bulk delete occurs in the background
   * and its progress can be monitored and managed via the Operation resource
   * that is created.
   *
   * For more details on bulk delete behavior, refer to:
   * https://cloud.google.com/firestore/docs/manage-data/bulk-delete
   */
  bulkDeleteDocuments(
    request: BulkDeleteDocumentsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Create a database. */
  createDatabase(
    request: CreateDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets information about a database. */
  getDatabase(request: GetDatabaseRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Database>>;
  /** List all the databases in the project. */
  listDatabases(
    request: ListDatabasesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListDatabasesResponse>>;
  /** Updates a database. */
  updateDatabase(
    request: UpdateDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Deletes a database. */
  deleteDatabase(
    request: DeleteDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets information about a backup. */
  getBackup(request: GetBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Backup>>;
  /** Lists all the backups. */
  listBackups(
    request: ListBackupsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupsResponse>>;
  /** Deletes a backup. */
  deleteBackup(request: DeleteBackupRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Empty>>;
  /**
   * Creates a new database by restoring from an existing backup.
   *
   * The new database must be in the same cloud region or multi-region location
   * as the existing backup. This behaves similar to
   * [FirestoreAdmin.CreateDatabase][google.firestore.admin.v1.FirestoreAdmin.CreateDatabase]
   * except instead of creating a new empty database, a new database is created
   * with the database type, index configuration, and documents from an existing
   * backup.
   *
   * The [long-running operation][google.longrunning.Operation] can be used to
   * track the progress of the restore, with the Operation's
   * [metadata][google.longrunning.Operation.metadata] field type being the
   * [RestoreDatabaseMetadata][google.firestore.admin.v1.RestoreDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] type is the
   * [Database][google.firestore.admin.v1.Database] if the restore was
   * successful. The new database is not readable or writeable until the LRO has
   * completed.
   */
  restoreDatabase(
    request: RestoreDatabaseRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Creates a backup schedule on a database.
   * At most two backup schedules can be configured on a database, one daily
   * backup schedule and one weekly backup schedule.
   */
  createBackupSchedule(
    request: CreateBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BackupSchedule>>;
  /** Gets information about a backup schedule. */
  getBackupSchedule(
    request: GetBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BackupSchedule>>;
  /** List backup schedules. */
  listBackupSchedules(
    request: ListBackupSchedulesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListBackupSchedulesResponse>>;
  /** Updates a backup schedule. */
  updateBackupSchedule(
    request: UpdateBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<BackupSchedule>>;
  /** Deletes a backup schedule. */
  deleteBackupSchedule(
    request: DeleteBackupScheduleRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
}

export interface FirestoreAdminClient<CallOptionsExt = {}> {
  /**
   * Creates a composite index. This returns a
   * [google.longrunning.Operation][google.longrunning.Operation] which may be
   * used to track the status of the creation. The metadata for the operation
   * will be the type
   * [IndexOperationMetadata][google.firestore.admin.v1.IndexOperationMetadata].
   */
  createIndex(request: DeepPartial<CreateIndexRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Lists composite indexes. */
  listIndexes(
    request: DeepPartial<ListIndexesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListIndexesResponse>;
  /** Gets a composite index. */
  getIndex(request: DeepPartial<GetIndexRequest>, options?: CallOptions & CallOptionsExt): Promise<Index>;
  /** Deletes a composite index. */
  deleteIndex(request: DeepPartial<DeleteIndexRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /** Gets the metadata and configuration for a Field. */
  getField(request: DeepPartial<GetFieldRequest>, options?: CallOptions & CallOptionsExt): Promise<Field>;
  /**
   * Updates a field configuration. Currently, field updates apply only to
   * single field index configuration. However, calls to
   * [FirestoreAdmin.UpdateField][google.firestore.admin.v1.FirestoreAdmin.UpdateField]
   * should provide a field mask to avoid changing any configuration that the
   * caller isn't aware of. The field mask should be specified as: `{ paths:
   * "index_config" }`.
   *
   * This call returns a
   * [google.longrunning.Operation][google.longrunning.Operation] which may be
   * used to track the status of the field update. The metadata for the
   * operation will be the type
   * [FieldOperationMetadata][google.firestore.admin.v1.FieldOperationMetadata].
   *
   * To configure the default field settings for the database, use
   * the special `Field` with resource name:
   * `projects/{project_id}/databases/{database_id}/collectionGroups/__default__/fields/*`.
   */
  updateField(request: DeepPartial<UpdateFieldRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Lists the field configuration and metadata for this database.
   *
   * Currently,
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
   * only supports listing fields that have been explicitly overridden. To issue
   * this query, call
   * [FirestoreAdmin.ListFields][google.firestore.admin.v1.FirestoreAdmin.ListFields]
   * with the filter set to `indexConfig.usesAncestorConfig:false` or
   * `ttlConfig:*`.
   */
  listFields(
    request: DeepPartial<ListFieldsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListFieldsResponse>;
  /**
   * Exports a copy of all or a subset of documents from Google Cloud Firestore
   * to another storage system, such as Google Cloud Storage. Recent updates to
   * documents may not be reflected in the export. The export occurs in the
   * background and its progress can be monitored and managed via the
   * Operation resource that is created. The output of an export may only be
   * used once the associated operation is done. If an export operation is
   * cancelled before completion it may leave partial data behind in Google
   * Cloud Storage.
   *
   * For more details on export behavior and output format, refer to:
   * https://cloud.google.com/firestore/docs/manage-data/export-import
   */
  exportDocuments(
    request: DeepPartial<ExportDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Imports documents into Google Cloud Firestore. Existing documents with the
   * same name are overwritten. The import occurs in the background and its
   * progress can be monitored and managed via the Operation resource that is
   * created. If an ImportDocuments operation is cancelled, it is possible
   * that a subset of the data has already been imported to Cloud Firestore.
   */
  importDocuments(
    request: DeepPartial<ImportDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Bulk deletes a subset of documents from Google Cloud Firestore.
   * Documents created or updated after the underlying system starts to process
   * the request will not be deleted. The bulk delete occurs in the background
   * and its progress can be monitored and managed via the Operation resource
   * that is created.
   *
   * For more details on bulk delete behavior, refer to:
   * https://cloud.google.com/firestore/docs/manage-data/bulk-delete
   */
  bulkDeleteDocuments(
    request: DeepPartial<BulkDeleteDocumentsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Create a database. */
  createDatabase(
    request: DeepPartial<CreateDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets information about a database. */
  getDatabase(request: DeepPartial<GetDatabaseRequest>, options?: CallOptions & CallOptionsExt): Promise<Database>;
  /** List all the databases in the project. */
  listDatabases(
    request: DeepPartial<ListDatabasesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListDatabasesResponse>;
  /** Updates a database. */
  updateDatabase(
    request: DeepPartial<UpdateDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Deletes a database. */
  deleteDatabase(
    request: DeepPartial<DeleteDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets information about a backup. */
  getBackup(request: DeepPartial<GetBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Backup>;
  /** Lists all the backups. */
  listBackups(
    request: DeepPartial<ListBackupsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupsResponse>;
  /** Deletes a backup. */
  deleteBackup(request: DeepPartial<DeleteBackupRequest>, options?: CallOptions & CallOptionsExt): Promise<Empty>;
  /**
   * Creates a new database by restoring from an existing backup.
   *
   * The new database must be in the same cloud region or multi-region location
   * as the existing backup. This behaves similar to
   * [FirestoreAdmin.CreateDatabase][google.firestore.admin.v1.FirestoreAdmin.CreateDatabase]
   * except instead of creating a new empty database, a new database is created
   * with the database type, index configuration, and documents from an existing
   * backup.
   *
   * The [long-running operation][google.longrunning.Operation] can be used to
   * track the progress of the restore, with the Operation's
   * [metadata][google.longrunning.Operation.metadata] field type being the
   * [RestoreDatabaseMetadata][google.firestore.admin.v1.RestoreDatabaseMetadata].
   * The [response][google.longrunning.Operation.response] type is the
   * [Database][google.firestore.admin.v1.Database] if the restore was
   * successful. The new database is not readable or writeable until the LRO has
   * completed.
   */
  restoreDatabase(
    request: DeepPartial<RestoreDatabaseRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Creates a backup schedule on a database.
   * At most two backup schedules can be configured on a database, one daily
   * backup schedule and one weekly backup schedule.
   */
  createBackupSchedule(
    request: DeepPartial<CreateBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BackupSchedule>;
  /** Gets information about a backup schedule. */
  getBackupSchedule(
    request: DeepPartial<GetBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BackupSchedule>;
  /** List backup schedules. */
  listBackupSchedules(
    request: DeepPartial<ListBackupSchedulesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListBackupSchedulesResponse>;
  /** Updates a backup schedule. */
  updateBackupSchedule(
    request: DeepPartial<UpdateBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<BackupSchedule>;
  /** Deletes a backup schedule. */
  deleteBackupSchedule(
    request: DeepPartial<DeleteBackupScheduleRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
