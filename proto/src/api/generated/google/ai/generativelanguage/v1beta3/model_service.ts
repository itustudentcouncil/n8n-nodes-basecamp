// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/ai/generativelanguage/v1beta3/model_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Model } from "./model.js";
import { TunedModel, TuningSnapshot } from "./tuned_model.js";

export const protobufPackage = "google.ai.generativelanguage.v1beta3";

/** Request for getting information about a specific Model. */
export interface GetModelRequest {
  /**
   * Required. The resource name of the model.
   *
   * This name should match a model name returned by the `ListModels` method.
   *
   * Format: `models/{model}`
   */
  name: string;
}

/** Request for listing all Models. */
export interface ListModelsRequest {
  /**
   * The maximum number of `Models` to return (per page).
   *
   * The service may return fewer models.
   * If unspecified, at most 50 models will be returned per page.
   * This method returns at most 1000 models per page, even if you pass a larger
   * page_size.
   */
  pageSize: number;
  /**
   * A page token, received from a previous `ListModels` call.
   *
   * Provide the `page_token` returned by one request as an argument to the next
   * request to retrieve the next page.
   *
   * When paginating, all other parameters provided to `ListModels` must match
   * the call that provided the page token.
   */
  pageToken: string;
}

/** Response from `ListModel` containing a paginated list of Models. */
export interface ListModelsResponse {
  /** The returned Models. */
  models: Model[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   *
   * If this field is omitted, there are no more pages.
   */
  nextPageToken: string;
}

/** Request for getting information about a specific Model. */
export interface GetTunedModelRequest {
  /**
   * Required. The resource name of the model.
   *
   * Format: `tunedModels/my-model-id`
   */
  name: string;
}

/** Request for listing TunedModels. */
export interface ListTunedModelsRequest {
  /**
   * Optional. The maximum number of `TunedModels` to return (per page).
   * The service may return fewer tuned models.
   *
   * If unspecified, at most 10 tuned models will be returned.
   * This method returns at most 1000 models per page, even if you pass a larger
   * page_size.
   */
  pageSize: number;
  /**
   * Optional. A page token, received from a previous `ListTunedModels` call.
   *
   * Provide the `page_token` returned by one request as an argument to the next
   * request to retrieve the next page.
   *
   * When paginating, all other parameters provided to `ListTunedModels`
   * must match the call that provided the page token.
   */
  pageToken: string;
}

/** Response from `ListTunedModels` containing a paginated list of Models. */
export interface ListTunedModelsResponse {
  /** The returned Models. */
  tunedModels: TunedModel[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page.
   *
   * If this field is omitted, there are no more pages.
   */
  nextPageToken: string;
}

/** Request to create a TunedModel. */
export interface CreateTunedModelRequest {
  /**
   * Optional. The unique id for the tuned model if specified.
   * This value should be up to 40 characters, the first character must be a
   * letter, the last could be a letter or a number. The id must match the
   * regular expression: [a-z]([a-z0-9-]{0,38}[a-z0-9])?.
   */
  tunedModelId?:
    | string
    | undefined;
  /** Required. The tuned model to create. */
  tunedModel: TunedModel | undefined;
}

/**
 * Metadata about the state and progress of creating a tuned model returned from
 * the long-running operation
 */
export interface CreateTunedModelMetadata {
  /** Name of the tuned model associated with the tuning operation. */
  tunedModel: string;
  /** The total number of tuning steps. */
  totalSteps: number;
  /** The number of steps completed. */
  completedSteps: number;
  /** The completed percentage for the tuning operation. */
  completedPercent: number;
  /** Metrics collected during tuning. */
  snapshots: TuningSnapshot[];
}

/** Request to update a TunedModel. */
export interface UpdateTunedModelRequest {
  /** Required. The tuned model to update. */
  tunedModel:
    | TunedModel
    | undefined;
  /** Required. The list of fields to update. */
  updateMask: string[] | undefined;
}

/** Request to delete a TunedModel. */
export interface DeleteTunedModelRequest {
  /**
   * Required. The resource name of the model.
   * Format: `tunedModels/my-model-id`
   */
  name: string;
}

function createBaseGetModelRequest(): GetModelRequest {
  return { name: "" };
}

export const GetModelRequest: MessageFns<GetModelRequest> = {
  encode(message: GetModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetModelRequest>): GetModelRequest {
    return GetModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetModelRequest>): GetModelRequest {
    const message = createBaseGetModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListModelsRequest(): ListModelsRequest {
  return { pageSize: 0, pageToken: "" };
}

export const ListModelsRequest: MessageFns<ListModelsRequest> = {
  encode(message: ListModelsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pageSize !== 0) {
      writer.uint32(16).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(26).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 16) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelsRequest {
    return {
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListModelsRequest): unknown {
    const obj: any = {};
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelsRequest>): ListModelsRequest {
    return ListModelsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelsRequest>): ListModelsRequest {
    const message = createBaseListModelsRequest();
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListModelsResponse(): ListModelsResponse {
  return { models: [], nextPageToken: "" };
}

export const ListModelsResponse: MessageFns<ListModelsResponse> = {
  encode(message: ListModelsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.models) {
      Model.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListModelsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListModelsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.models.push(Model.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListModelsResponse {
    return {
      models: globalThis.Array.isArray(object?.models) ? object.models.map((e: any) => Model.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListModelsResponse): unknown {
    const obj: any = {};
    if (message.models?.length) {
      obj.models = message.models.map((e) => Model.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListModelsResponse>): ListModelsResponse {
    return ListModelsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListModelsResponse>): ListModelsResponse {
    const message = createBaseListModelsResponse();
    message.models = object.models?.map((e) => Model.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseGetTunedModelRequest(): GetTunedModelRequest {
  return { name: "" };
}

export const GetTunedModelRequest: MessageFns<GetTunedModelRequest> = {
  encode(message: GetTunedModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTunedModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTunedModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetTunedModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetTunedModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetTunedModelRequest>): GetTunedModelRequest {
    return GetTunedModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetTunedModelRequest>): GetTunedModelRequest {
    const message = createBaseGetTunedModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListTunedModelsRequest(): ListTunedModelsRequest {
  return { pageSize: 0, pageToken: "" };
}

export const ListTunedModelsRequest: MessageFns<ListTunedModelsRequest> = {
  encode(message: ListTunedModelsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pageSize !== 0) {
      writer.uint32(8).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(18).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTunedModelsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTunedModelsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTunedModelsRequest {
    return {
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: ListTunedModelsRequest): unknown {
    const obj: any = {};
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTunedModelsRequest>): ListTunedModelsRequest {
    return ListTunedModelsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTunedModelsRequest>): ListTunedModelsRequest {
    const message = createBaseListTunedModelsRequest();
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseListTunedModelsResponse(): ListTunedModelsResponse {
  return { tunedModels: [], nextPageToken: "" };
}

export const ListTunedModelsResponse: MessageFns<ListTunedModelsResponse> = {
  encode(message: ListTunedModelsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tunedModels) {
      TunedModel.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTunedModelsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTunedModelsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tunedModels.push(TunedModel.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTunedModelsResponse {
    return {
      tunedModels: globalThis.Array.isArray(object?.tunedModels)
        ? object.tunedModels.map((e: any) => TunedModel.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTunedModelsResponse): unknown {
    const obj: any = {};
    if (message.tunedModels?.length) {
      obj.tunedModels = message.tunedModels.map((e) => TunedModel.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTunedModelsResponse>): ListTunedModelsResponse {
    return ListTunedModelsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTunedModelsResponse>): ListTunedModelsResponse {
    const message = createBaseListTunedModelsResponse();
    message.tunedModels = object.tunedModels?.map((e) => TunedModel.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseCreateTunedModelRequest(): CreateTunedModelRequest {
  return { tunedModelId: undefined, tunedModel: undefined };
}

export const CreateTunedModelRequest: MessageFns<CreateTunedModelRequest> = {
  encode(message: CreateTunedModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tunedModelId !== undefined) {
      writer.uint32(10).string(message.tunedModelId);
    }
    if (message.tunedModel !== undefined) {
      TunedModel.encode(message.tunedModel, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTunedModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTunedModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tunedModelId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tunedModel = TunedModel.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTunedModelRequest {
    return {
      tunedModelId: isSet(object.tunedModelId) ? globalThis.String(object.tunedModelId) : undefined,
      tunedModel: isSet(object.tunedModel) ? TunedModel.fromJSON(object.tunedModel) : undefined,
    };
  },

  toJSON(message: CreateTunedModelRequest): unknown {
    const obj: any = {};
    if (message.tunedModelId !== undefined) {
      obj.tunedModelId = message.tunedModelId;
    }
    if (message.tunedModel !== undefined) {
      obj.tunedModel = TunedModel.toJSON(message.tunedModel);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTunedModelRequest>): CreateTunedModelRequest {
    return CreateTunedModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTunedModelRequest>): CreateTunedModelRequest {
    const message = createBaseCreateTunedModelRequest();
    message.tunedModelId = object.tunedModelId ?? undefined;
    message.tunedModel = (object.tunedModel !== undefined && object.tunedModel !== null)
      ? TunedModel.fromPartial(object.tunedModel)
      : undefined;
    return message;
  },
};

function createBaseCreateTunedModelMetadata(): CreateTunedModelMetadata {
  return { tunedModel: "", totalSteps: 0, completedSteps: 0, completedPercent: 0, snapshots: [] };
}

export const CreateTunedModelMetadata: MessageFns<CreateTunedModelMetadata> = {
  encode(message: CreateTunedModelMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tunedModel !== "") {
      writer.uint32(42).string(message.tunedModel);
    }
    if (message.totalSteps !== 0) {
      writer.uint32(8).int32(message.totalSteps);
    }
    if (message.completedSteps !== 0) {
      writer.uint32(16).int32(message.completedSteps);
    }
    if (message.completedPercent !== 0) {
      writer.uint32(29).float(message.completedPercent);
    }
    for (const v of message.snapshots) {
      TuningSnapshot.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTunedModelMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTunedModelMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5:
          if (tag !== 42) {
            break;
          }

          message.tunedModel = reader.string();
          continue;
        case 1:
          if (tag !== 8) {
            break;
          }

          message.totalSteps = reader.int32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.completedSteps = reader.int32();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.completedPercent = reader.float();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.snapshots.push(TuningSnapshot.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTunedModelMetadata {
    return {
      tunedModel: isSet(object.tunedModel) ? globalThis.String(object.tunedModel) : "",
      totalSteps: isSet(object.totalSteps) ? globalThis.Number(object.totalSteps) : 0,
      completedSteps: isSet(object.completedSteps) ? globalThis.Number(object.completedSteps) : 0,
      completedPercent: isSet(object.completedPercent) ? globalThis.Number(object.completedPercent) : 0,
      snapshots: globalThis.Array.isArray(object?.snapshots)
        ? object.snapshots.map((e: any) => TuningSnapshot.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CreateTunedModelMetadata): unknown {
    const obj: any = {};
    if (message.tunedModel !== "") {
      obj.tunedModel = message.tunedModel;
    }
    if (message.totalSteps !== 0) {
      obj.totalSteps = Math.round(message.totalSteps);
    }
    if (message.completedSteps !== 0) {
      obj.completedSteps = Math.round(message.completedSteps);
    }
    if (message.completedPercent !== 0) {
      obj.completedPercent = message.completedPercent;
    }
    if (message.snapshots?.length) {
      obj.snapshots = message.snapshots.map((e) => TuningSnapshot.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTunedModelMetadata>): CreateTunedModelMetadata {
    return CreateTunedModelMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTunedModelMetadata>): CreateTunedModelMetadata {
    const message = createBaseCreateTunedModelMetadata();
    message.tunedModel = object.tunedModel ?? "";
    message.totalSteps = object.totalSteps ?? 0;
    message.completedSteps = object.completedSteps ?? 0;
    message.completedPercent = object.completedPercent ?? 0;
    message.snapshots = object.snapshots?.map((e) => TuningSnapshot.fromPartial(e)) || [];
    return message;
  },
};

function createBaseUpdateTunedModelRequest(): UpdateTunedModelRequest {
  return { tunedModel: undefined, updateMask: undefined };
}

export const UpdateTunedModelRequest: MessageFns<UpdateTunedModelRequest> = {
  encode(message: UpdateTunedModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tunedModel !== undefined) {
      TunedModel.encode(message.tunedModel, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateTunedModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateTunedModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tunedModel = TunedModel.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateTunedModelRequest {
    return {
      tunedModel: isSet(object.tunedModel) ? TunedModel.fromJSON(object.tunedModel) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateTunedModelRequest): unknown {
    const obj: any = {};
    if (message.tunedModel !== undefined) {
      obj.tunedModel = TunedModel.toJSON(message.tunedModel);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateTunedModelRequest>): UpdateTunedModelRequest {
    return UpdateTunedModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateTunedModelRequest>): UpdateTunedModelRequest {
    const message = createBaseUpdateTunedModelRequest();
    message.tunedModel = (object.tunedModel !== undefined && object.tunedModel !== null)
      ? TunedModel.fromPartial(object.tunedModel)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteTunedModelRequest(): DeleteTunedModelRequest {
  return { name: "" };
}

export const DeleteTunedModelRequest: MessageFns<DeleteTunedModelRequest> = {
  encode(message: DeleteTunedModelRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteTunedModelRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteTunedModelRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteTunedModelRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteTunedModelRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteTunedModelRequest>): DeleteTunedModelRequest {
    return DeleteTunedModelRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteTunedModelRequest>): DeleteTunedModelRequest {
    const message = createBaseDeleteTunedModelRequest();
    message.name = object.name ?? "";
    return message;
  },
};

/** Provides methods for getting metadata information about Generative Models. */
export type ModelServiceDefinition = typeof ModelServiceDefinition;
export const ModelServiceDefinition = {
  name: "ModelService",
  fullName: "google.ai.generativelanguage.v1beta3.ModelService",
  methods: {
    /** Gets information about a specific Model. */
    getModel: {
      name: "GetModel",
      requestType: GetModelRequest,
      requestStream: false,
      responseType: Model,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              26,
              18,
              24,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              51,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              109,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists models available through the API. */
    listModels: {
      name: "ListModels",
      requestType: ListModelsRequest,
      requestStream: false,
      responseType: ListModelsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              112,
              97,
              103,
              101,
              95,
              115,
              105,
              122,
              101,
              44,
              112,
              97,
              103,
              101,
              95,
              116,
              111,
              107,
              101,
              110,
            ]),
          ],
          578365826: [Buffer.from([17, 18, 15, 47, 118, 49, 98, 101, 116, 97, 51, 47, 109, 111, 100, 101, 108, 115])],
        },
      },
    },
    /** Gets information about a specific TunedModel. */
    getTunedModel: {
      name: "GetTunedModel",
      requestType: GetTunedModelRequest,
      requestStream: false,
      responseType: TunedModel,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              31,
              18,
              29,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              51,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              116,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists tuned models owned by the user. */
    listTunedModels: {
      name: "ListTunedModels",
      requestType: ListTunedModelsRequest,
      requestStream: false,
      responseType: ListTunedModelsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              20,
              112,
              97,
              103,
              101,
              95,
              115,
              105,
              122,
              101,
              44,
              112,
              97,
              103,
              101,
              95,
              116,
              111,
              107,
              101,
              110,
            ]),
          ],
          578365826: [
            Buffer.from([
              22,
              18,
              20,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              51,
              47,
              116,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Creates a tuned model.
     * Intermediate tuning progress (if any) is accessed through the
     * [google.longrunning.Operations] service.
     *
     * Status and results can be accessed through the Operations service.
     * Example:
     *   GET /v1/tunedModels/az2mb0bpw6i/operations/000-111-222
     */
    createTunedModel: {
      name: "CreateTunedModel",
      requestType: CreateTunedModelRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              38,
              10,
              10,
              84,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              18,
              24,
              67,
              114,
              101,
              97,
              116,
              101,
              84,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([11, 116, 117, 110, 101, 100, 95, 109, 111, 100, 101, 108]),
            Buffer.from([
              26,
              116,
              117,
              110,
              101,
              100,
              95,
              109,
              111,
              100,
              101,
              108,
              95,
              105,
              100,
              44,
              116,
              117,
              110,
              101,
              100,
              95,
              109,
              111,
              100,
              101,
              108,
            ]),
          ],
          578365826: [
            Buffer.from([
              35,
              58,
              11,
              116,
              117,
              110,
              101,
              100,
              95,
              109,
              111,
              100,
              101,
              108,
              34,
              20,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              51,
              47,
              116,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates a tuned model. */
    updateTunedModel: {
      name: "UpdateTunedModel",
      requestType: UpdateTunedModelRequest,
      requestStream: false,
      responseType: TunedModel,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              116,
              117,
              110,
              101,
              100,
              95,
              109,
              111,
              100,
              101,
              108,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              56,
              58,
              11,
              116,
              117,
              110,
              101,
              100,
              95,
              109,
              111,
              100,
              101,
              108,
              50,
              41,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              51,
              47,
              123,
              116,
              117,
              110,
              101,
              100,
              95,
              109,
              111,
              100,
              101,
              108,
              46,
              110,
              97,
              109,
              101,
              61,
              116,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a tuned model. */
    deleteTunedModel: {
      name: "DeleteTunedModel",
      requestType: DeleteTunedModelRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              31,
              42,
              29,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              51,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              116,
              117,
              110,
              101,
              100,
              77,
              111,
              100,
              101,
              108,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface ModelServiceImplementation<CallContextExt = {}> {
  /** Gets information about a specific Model. */
  getModel(request: GetModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Model>>;
  /** Lists models available through the API. */
  listModels(
    request: ListModelsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListModelsResponse>>;
  /** Gets information about a specific TunedModel. */
  getTunedModel(request: GetTunedModelRequest, context: CallContext & CallContextExt): Promise<DeepPartial<TunedModel>>;
  /** Lists tuned models owned by the user. */
  listTunedModels(
    request: ListTunedModelsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTunedModelsResponse>>;
  /**
   * Creates a tuned model.
   * Intermediate tuning progress (if any) is accessed through the
   * [google.longrunning.Operations] service.
   *
   * Status and results can be accessed through the Operations service.
   * Example:
   *   GET /v1/tunedModels/az2mb0bpw6i/operations/000-111-222
   */
  createTunedModel(
    request: CreateTunedModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Updates a tuned model. */
  updateTunedModel(
    request: UpdateTunedModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TunedModel>>;
  /** Deletes a tuned model. */
  deleteTunedModel(
    request: DeleteTunedModelRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
}

export interface ModelServiceClient<CallOptionsExt = {}> {
  /** Gets information about a specific Model. */
  getModel(request: DeepPartial<GetModelRequest>, options?: CallOptions & CallOptionsExt): Promise<Model>;
  /** Lists models available through the API. */
  listModels(
    request: DeepPartial<ListModelsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListModelsResponse>;
  /** Gets information about a specific TunedModel. */
  getTunedModel(
    request: DeepPartial<GetTunedModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TunedModel>;
  /** Lists tuned models owned by the user. */
  listTunedModels(
    request: DeepPartial<ListTunedModelsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTunedModelsResponse>;
  /**
   * Creates a tuned model.
   * Intermediate tuning progress (if any) is accessed through the
   * [google.longrunning.Operations] service.
   *
   * Status and results can be accessed through the Operations service.
   * Example:
   *   GET /v1/tunedModels/az2mb0bpw6i/operations/000-111-222
   */
  createTunedModel(
    request: DeepPartial<CreateTunedModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Updates a tuned model. */
  updateTunedModel(
    request: DeepPartial<UpdateTunedModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TunedModel>;
  /** Deletes a tuned model. */
  deleteTunedModel(
    request: DeepPartial<DeleteTunedModelRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
