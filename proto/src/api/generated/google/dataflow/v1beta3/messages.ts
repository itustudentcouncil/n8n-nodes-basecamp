// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/dataflow/v1beta3/messages.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Value } from "../../protobuf/struct.js";
import { Timestamp } from "../../protobuf/timestamp.js";

export const protobufPackage = "google.dataflow.v1beta3";

/** Indicates the importance of the message. */
export enum JobMessageImportance {
  /** JOB_MESSAGE_IMPORTANCE_UNKNOWN - The message importance isn't specified, or is unknown. */
  JOB_MESSAGE_IMPORTANCE_UNKNOWN = 0,
  /**
   * JOB_MESSAGE_DEBUG - The message is at the 'debug' level: typically only useful for
   * software engineers working on the code the job is running.
   * Typically, Dataflow pipeline runners do not display log messages
   * at this level by default.
   */
  JOB_MESSAGE_DEBUG = 1,
  /**
   * JOB_MESSAGE_DETAILED - The message is at the 'detailed' level: somewhat verbose, but
   * potentially useful to users.  Typically, Dataflow pipeline
   * runners do not display log messages at this level by default.
   * These messages are displayed by default in the Dataflow
   * monitoring UI.
   */
  JOB_MESSAGE_DETAILED = 2,
  /**
   * JOB_MESSAGE_BASIC - The message is at the 'basic' level: useful for keeping
   * track of the execution of a Dataflow pipeline.  Typically,
   * Dataflow pipeline runners display log messages at this level by
   * default, and these messages are displayed by default in the
   * Dataflow monitoring UI.
   */
  JOB_MESSAGE_BASIC = 5,
  /**
   * JOB_MESSAGE_WARNING - The message is at the 'warning' level: indicating a condition
   * pertaining to a job which may require human intervention.
   * Typically, Dataflow pipeline runners display log messages at this
   * level by default, and these messages are displayed by default in
   * the Dataflow monitoring UI.
   */
  JOB_MESSAGE_WARNING = 3,
  /**
   * JOB_MESSAGE_ERROR - The message is at the 'error' level: indicating a condition
   * preventing a job from succeeding.  Typically, Dataflow pipeline
   * runners display log messages at this level by default, and these
   * messages are displayed by default in the Dataflow monitoring UI.
   */
  JOB_MESSAGE_ERROR = 4,
  UNRECOGNIZED = -1,
}

export function jobMessageImportanceFromJSON(object: any): JobMessageImportance {
  switch (object) {
    case 0:
    case "JOB_MESSAGE_IMPORTANCE_UNKNOWN":
      return JobMessageImportance.JOB_MESSAGE_IMPORTANCE_UNKNOWN;
    case 1:
    case "JOB_MESSAGE_DEBUG":
      return JobMessageImportance.JOB_MESSAGE_DEBUG;
    case 2:
    case "JOB_MESSAGE_DETAILED":
      return JobMessageImportance.JOB_MESSAGE_DETAILED;
    case 5:
    case "JOB_MESSAGE_BASIC":
      return JobMessageImportance.JOB_MESSAGE_BASIC;
    case 3:
    case "JOB_MESSAGE_WARNING":
      return JobMessageImportance.JOB_MESSAGE_WARNING;
    case 4:
    case "JOB_MESSAGE_ERROR":
      return JobMessageImportance.JOB_MESSAGE_ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobMessageImportance.UNRECOGNIZED;
  }
}

export function jobMessageImportanceToJSON(object: JobMessageImportance): string {
  switch (object) {
    case JobMessageImportance.JOB_MESSAGE_IMPORTANCE_UNKNOWN:
      return "JOB_MESSAGE_IMPORTANCE_UNKNOWN";
    case JobMessageImportance.JOB_MESSAGE_DEBUG:
      return "JOB_MESSAGE_DEBUG";
    case JobMessageImportance.JOB_MESSAGE_DETAILED:
      return "JOB_MESSAGE_DETAILED";
    case JobMessageImportance.JOB_MESSAGE_BASIC:
      return "JOB_MESSAGE_BASIC";
    case JobMessageImportance.JOB_MESSAGE_WARNING:
      return "JOB_MESSAGE_WARNING";
    case JobMessageImportance.JOB_MESSAGE_ERROR:
      return "JOB_MESSAGE_ERROR";
    case JobMessageImportance.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A particular message pertaining to a Dataflow job. */
export interface JobMessage {
  /** Deprecated. */
  id: string;
  /** The timestamp of the message. */
  time:
    | Date
    | undefined;
  /** The text of the message. */
  messageText: string;
  /** Importance level of the message. */
  messageImportance: JobMessageImportance;
}

/**
 * A rich message format, including a human readable string, a key for
 * identifying the message, and structured data associated with the message for
 * programmatic consumption.
 */
export interface StructuredMessage {
  /** Human-readable version of message. */
  messageText: string;
  /**
   * Identifier for this message type.  Used by external systems to
   * internationalize or personalize message.
   */
  messageKey: string;
  /** The structured data associated with this message. */
  parameters: StructuredMessage_Parameter[];
}

/** Structured data associated with this message. */
export interface StructuredMessage_Parameter {
  /** Key or name for this parameter. */
  key: string;
  /** Value for this parameter. */
  value: any | undefined;
}

/**
 * A structured message reporting an autoscaling decision made by the Dataflow
 * service.
 */
export interface AutoscalingEvent {
  /** The current number of workers the job has. */
  currentNumWorkers: Long;
  /** The target number of workers the worker pool wants to resize to use. */
  targetNumWorkers: Long;
  /** The type of autoscaling event to report. */
  eventType: AutoscalingEvent_AutoscalingEventType;
  /**
   * A message describing why the system decided to adjust the current
   * number of workers, why it failed, or why the system decided to
   * not make any changes to the number of workers.
   */
  description:
    | StructuredMessage
    | undefined;
  /**
   * The time this event was emitted to indicate a new target or current
   * num_workers value.
   */
  time:
    | Date
    | undefined;
  /** A short and friendly name for the worker pool this event refers to. */
  workerPool: string;
}

/** Indicates the type of autoscaling event. */
export enum AutoscalingEvent_AutoscalingEventType {
  /** TYPE_UNKNOWN - Default type for the enum.  Value should never be returned. */
  TYPE_UNKNOWN = 0,
  /**
   * TARGET_NUM_WORKERS_CHANGED - The TARGET_NUM_WORKERS_CHANGED type should be used when the target
   * worker pool size has changed at the start of an actuation. An event
   * should always be specified as TARGET_NUM_WORKERS_CHANGED if it reflects
   * a change in the target_num_workers.
   */
  TARGET_NUM_WORKERS_CHANGED = 1,
  /**
   * CURRENT_NUM_WORKERS_CHANGED - The CURRENT_NUM_WORKERS_CHANGED type should be used when actual worker
   * pool size has been changed, but the target_num_workers has not changed.
   */
  CURRENT_NUM_WORKERS_CHANGED = 2,
  /**
   * ACTUATION_FAILURE - The ACTUATION_FAILURE type should be used when we want to report
   * an error to the user indicating why the current number of workers
   * in the pool could not be changed.
   * Displayed in the current status and history widgets.
   */
  ACTUATION_FAILURE = 3,
  /**
   * NO_CHANGE - Used when we want to report to the user a reason why we are
   * not currently adjusting the number of workers.
   * Should specify both target_num_workers, current_num_workers and a
   * decision_message.
   */
  NO_CHANGE = 4,
  UNRECOGNIZED = -1,
}

export function autoscalingEvent_AutoscalingEventTypeFromJSON(object: any): AutoscalingEvent_AutoscalingEventType {
  switch (object) {
    case 0:
    case "TYPE_UNKNOWN":
      return AutoscalingEvent_AutoscalingEventType.TYPE_UNKNOWN;
    case 1:
    case "TARGET_NUM_WORKERS_CHANGED":
      return AutoscalingEvent_AutoscalingEventType.TARGET_NUM_WORKERS_CHANGED;
    case 2:
    case "CURRENT_NUM_WORKERS_CHANGED":
      return AutoscalingEvent_AutoscalingEventType.CURRENT_NUM_WORKERS_CHANGED;
    case 3:
    case "ACTUATION_FAILURE":
      return AutoscalingEvent_AutoscalingEventType.ACTUATION_FAILURE;
    case 4:
    case "NO_CHANGE":
      return AutoscalingEvent_AutoscalingEventType.NO_CHANGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AutoscalingEvent_AutoscalingEventType.UNRECOGNIZED;
  }
}

export function autoscalingEvent_AutoscalingEventTypeToJSON(object: AutoscalingEvent_AutoscalingEventType): string {
  switch (object) {
    case AutoscalingEvent_AutoscalingEventType.TYPE_UNKNOWN:
      return "TYPE_UNKNOWN";
    case AutoscalingEvent_AutoscalingEventType.TARGET_NUM_WORKERS_CHANGED:
      return "TARGET_NUM_WORKERS_CHANGED";
    case AutoscalingEvent_AutoscalingEventType.CURRENT_NUM_WORKERS_CHANGED:
      return "CURRENT_NUM_WORKERS_CHANGED";
    case AutoscalingEvent_AutoscalingEventType.ACTUATION_FAILURE:
      return "ACTUATION_FAILURE";
    case AutoscalingEvent_AutoscalingEventType.NO_CHANGE:
      return "NO_CHANGE";
    case AutoscalingEvent_AutoscalingEventType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Request to list job messages.
 * Up to max_results messages will be returned in the time range specified
 * starting with the oldest messages first. If no time range is specified
 * the results with start with the oldest message.
 */
export interface ListJobMessagesRequest {
  /** A project id. */
  projectId: string;
  /** The job to get messages about. */
  jobId: string;
  /** Filter to only get messages with importance >= level */
  minimumImportance: JobMessageImportance;
  /**
   * If specified, determines the maximum number of messages to
   * return.  If unspecified, the service may choose an appropriate
   * default, or may return an arbitrarily large number of results.
   */
  pageSize: number;
  /**
   * If supplied, this should be the value of next_page_token returned
   * by an earlier call. This will cause the next page of results to
   * be returned.
   */
  pageToken: string;
  /**
   * If specified, return only messages with timestamps >= start_time.
   * The default is the job creation time (i.e. beginning of messages).
   */
  startTime:
    | Date
    | undefined;
  /**
   * Return only messages with timestamps < end_time. The default is now
   * (i.e. return up to the latest messages available).
   */
  endTime:
    | Date
    | undefined;
  /**
   * The [regional endpoint]
   * (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
   * contains the job specified by job_id.
   */
  location: string;
}

/** Response to a request to list job messages. */
export interface ListJobMessagesResponse {
  /** Messages in ascending timestamp order. */
  jobMessages: JobMessage[];
  /** The token to obtain the next page of results if there are more. */
  nextPageToken: string;
  /** Autoscaling events in ascending timestamp order. */
  autoscalingEvents: AutoscalingEvent[];
}

function createBaseJobMessage(): JobMessage {
  return { id: "", time: undefined, messageText: "", messageImportance: 0 };
}

export const JobMessage: MessageFns<JobMessage> = {
  encode(message: JobMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.time !== undefined) {
      Timestamp.encode(toTimestamp(message.time), writer.uint32(18).fork()).join();
    }
    if (message.messageText !== "") {
      writer.uint32(26).string(message.messageText);
    }
    if (message.messageImportance !== 0) {
      writer.uint32(32).int32(message.messageImportance);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.time = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.messageText = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.messageImportance = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobMessage {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      time: isSet(object.time) ? fromJsonTimestamp(object.time) : undefined,
      messageText: isSet(object.messageText) ? globalThis.String(object.messageText) : "",
      messageImportance: isSet(object.messageImportance) ? jobMessageImportanceFromJSON(object.messageImportance) : 0,
    };
  },

  toJSON(message: JobMessage): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.time !== undefined) {
      obj.time = message.time.toISOString();
    }
    if (message.messageText !== "") {
      obj.messageText = message.messageText;
    }
    if (message.messageImportance !== 0) {
      obj.messageImportance = jobMessageImportanceToJSON(message.messageImportance);
    }
    return obj;
  },

  create(base?: DeepPartial<JobMessage>): JobMessage {
    return JobMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobMessage>): JobMessage {
    const message = createBaseJobMessage();
    message.id = object.id ?? "";
    message.time = object.time ?? undefined;
    message.messageText = object.messageText ?? "";
    message.messageImportance = object.messageImportance ?? 0;
    return message;
  },
};

function createBaseStructuredMessage(): StructuredMessage {
  return { messageText: "", messageKey: "", parameters: [] };
}

export const StructuredMessage: MessageFns<StructuredMessage> = {
  encode(message: StructuredMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.messageText !== "") {
      writer.uint32(10).string(message.messageText);
    }
    if (message.messageKey !== "") {
      writer.uint32(18).string(message.messageKey);
    }
    for (const v of message.parameters) {
      StructuredMessage_Parameter.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StructuredMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStructuredMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.messageText = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.messageKey = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.parameters.push(StructuredMessage_Parameter.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StructuredMessage {
    return {
      messageText: isSet(object.messageText) ? globalThis.String(object.messageText) : "",
      messageKey: isSet(object.messageKey) ? globalThis.String(object.messageKey) : "",
      parameters: globalThis.Array.isArray(object?.parameters)
        ? object.parameters.map((e: any) => StructuredMessage_Parameter.fromJSON(e))
        : [],
    };
  },

  toJSON(message: StructuredMessage): unknown {
    const obj: any = {};
    if (message.messageText !== "") {
      obj.messageText = message.messageText;
    }
    if (message.messageKey !== "") {
      obj.messageKey = message.messageKey;
    }
    if (message.parameters?.length) {
      obj.parameters = message.parameters.map((e) => StructuredMessage_Parameter.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<StructuredMessage>): StructuredMessage {
    return StructuredMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StructuredMessage>): StructuredMessage {
    const message = createBaseStructuredMessage();
    message.messageText = object.messageText ?? "";
    message.messageKey = object.messageKey ?? "";
    message.parameters = object.parameters?.map((e) => StructuredMessage_Parameter.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStructuredMessage_Parameter(): StructuredMessage_Parameter {
  return { key: "", value: undefined };
}

export const StructuredMessage_Parameter: MessageFns<StructuredMessage_Parameter> = {
  encode(message: StructuredMessage_Parameter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Value.encode(Value.wrap(message.value), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StructuredMessage_Parameter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStructuredMessage_Parameter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StructuredMessage_Parameter {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object?.value) ? object.value : undefined,
    };
  },

  toJSON(message: StructuredMessage_Parameter): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<StructuredMessage_Parameter>): StructuredMessage_Parameter {
    return StructuredMessage_Parameter.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StructuredMessage_Parameter>): StructuredMessage_Parameter {
    const message = createBaseStructuredMessage_Parameter();
    message.key = object.key ?? "";
    message.value = object.value ?? undefined;
    return message;
  },
};

function createBaseAutoscalingEvent(): AutoscalingEvent {
  return {
    currentNumWorkers: Long.ZERO,
    targetNumWorkers: Long.ZERO,
    eventType: 0,
    description: undefined,
    time: undefined,
    workerPool: "",
  };
}

export const AutoscalingEvent: MessageFns<AutoscalingEvent> = {
  encode(message: AutoscalingEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.currentNumWorkers.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.currentNumWorkers.toString());
    }
    if (!message.targetNumWorkers.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.targetNumWorkers.toString());
    }
    if (message.eventType !== 0) {
      writer.uint32(24).int32(message.eventType);
    }
    if (message.description !== undefined) {
      StructuredMessage.encode(message.description, writer.uint32(34).fork()).join();
    }
    if (message.time !== undefined) {
      Timestamp.encode(toTimestamp(message.time), writer.uint32(42).fork()).join();
    }
    if (message.workerPool !== "") {
      writer.uint32(58).string(message.workerPool);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutoscalingEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutoscalingEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.currentNumWorkers = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.targetNumWorkers = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.eventType = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.description = StructuredMessage.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.time = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.workerPool = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AutoscalingEvent {
    return {
      currentNumWorkers: isSet(object.currentNumWorkers) ? Long.fromValue(object.currentNumWorkers) : Long.ZERO,
      targetNumWorkers: isSet(object.targetNumWorkers) ? Long.fromValue(object.targetNumWorkers) : Long.ZERO,
      eventType: isSet(object.eventType) ? autoscalingEvent_AutoscalingEventTypeFromJSON(object.eventType) : 0,
      description: isSet(object.description) ? StructuredMessage.fromJSON(object.description) : undefined,
      time: isSet(object.time) ? fromJsonTimestamp(object.time) : undefined,
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
    };
  },

  toJSON(message: AutoscalingEvent): unknown {
    const obj: any = {};
    if (!message.currentNumWorkers.equals(Long.ZERO)) {
      obj.currentNumWorkers = (message.currentNumWorkers || Long.ZERO).toString();
    }
    if (!message.targetNumWorkers.equals(Long.ZERO)) {
      obj.targetNumWorkers = (message.targetNumWorkers || Long.ZERO).toString();
    }
    if (message.eventType !== 0) {
      obj.eventType = autoscalingEvent_AutoscalingEventTypeToJSON(message.eventType);
    }
    if (message.description !== undefined) {
      obj.description = StructuredMessage.toJSON(message.description);
    }
    if (message.time !== undefined) {
      obj.time = message.time.toISOString();
    }
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    return obj;
  },

  create(base?: DeepPartial<AutoscalingEvent>): AutoscalingEvent {
    return AutoscalingEvent.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<AutoscalingEvent>): AutoscalingEvent {
    const message = createBaseAutoscalingEvent();
    message.currentNumWorkers = (object.currentNumWorkers !== undefined && object.currentNumWorkers !== null)
      ? Long.fromValue(object.currentNumWorkers)
      : Long.ZERO;
    message.targetNumWorkers = (object.targetNumWorkers !== undefined && object.targetNumWorkers !== null)
      ? Long.fromValue(object.targetNumWorkers)
      : Long.ZERO;
    message.eventType = object.eventType ?? 0;
    message.description = (object.description !== undefined && object.description !== null)
      ? StructuredMessage.fromPartial(object.description)
      : undefined;
    message.time = object.time ?? undefined;
    message.workerPool = object.workerPool ?? "";
    return message;
  },
};

function createBaseListJobMessagesRequest(): ListJobMessagesRequest {
  return {
    projectId: "",
    jobId: "",
    minimumImportance: 0,
    pageSize: 0,
    pageToken: "",
    startTime: undefined,
    endTime: undefined,
    location: "",
  };
}

export const ListJobMessagesRequest: MessageFns<ListJobMessagesRequest> = {
  encode(message: ListJobMessagesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.jobId !== "") {
      writer.uint32(18).string(message.jobId);
    }
    if (message.minimumImportance !== 0) {
      writer.uint32(24).int32(message.minimumImportance);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(50).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(58).fork()).join();
    }
    if (message.location !== "") {
      writer.uint32(66).string(message.location);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListJobMessagesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListJobMessagesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.jobId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.minimumImportance = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.location = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListJobMessagesRequest {
    return {
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      jobId: isSet(object.jobId) ? globalThis.String(object.jobId) : "",
      minimumImportance: isSet(object.minimumImportance) ? jobMessageImportanceFromJSON(object.minimumImportance) : 0,
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      location: isSet(object.location) ? globalThis.String(object.location) : "",
    };
  },

  toJSON(message: ListJobMessagesRequest): unknown {
    const obj: any = {};
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.jobId !== "") {
      obj.jobId = message.jobId;
    }
    if (message.minimumImportance !== 0) {
      obj.minimumImportance = jobMessageImportanceToJSON(message.minimumImportance);
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.location !== "") {
      obj.location = message.location;
    }
    return obj;
  },

  create(base?: DeepPartial<ListJobMessagesRequest>): ListJobMessagesRequest {
    return ListJobMessagesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListJobMessagesRequest>): ListJobMessagesRequest {
    const message = createBaseListJobMessagesRequest();
    message.projectId = object.projectId ?? "";
    message.jobId = object.jobId ?? "";
    message.minimumImportance = object.minimumImportance ?? 0;
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.location = object.location ?? "";
    return message;
  },
};

function createBaseListJobMessagesResponse(): ListJobMessagesResponse {
  return { jobMessages: [], nextPageToken: "", autoscalingEvents: [] };
}

export const ListJobMessagesResponse: MessageFns<ListJobMessagesResponse> = {
  encode(message: ListJobMessagesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.jobMessages) {
      JobMessage.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    for (const v of message.autoscalingEvents) {
      AutoscalingEvent.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListJobMessagesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListJobMessagesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.jobMessages.push(JobMessage.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.autoscalingEvents.push(AutoscalingEvent.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListJobMessagesResponse {
    return {
      jobMessages: globalThis.Array.isArray(object?.jobMessages)
        ? object.jobMessages.map((e: any) => JobMessage.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
      autoscalingEvents: globalThis.Array.isArray(object?.autoscalingEvents)
        ? object.autoscalingEvents.map((e: any) => AutoscalingEvent.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ListJobMessagesResponse): unknown {
    const obj: any = {};
    if (message.jobMessages?.length) {
      obj.jobMessages = message.jobMessages.map((e) => JobMessage.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    if (message.autoscalingEvents?.length) {
      obj.autoscalingEvents = message.autoscalingEvents.map((e) => AutoscalingEvent.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ListJobMessagesResponse>): ListJobMessagesResponse {
    return ListJobMessagesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListJobMessagesResponse>): ListJobMessagesResponse {
    const message = createBaseListJobMessagesResponse();
    message.jobMessages = object.jobMessages?.map((e) => JobMessage.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    message.autoscalingEvents = object.autoscalingEvents?.map((e) => AutoscalingEvent.fromPartial(e)) || [];
    return message;
  },
};

/**
 * The Dataflow Messages API is used for monitoring the progress of
 * Dataflow jobs.
 */
export type MessagesV1Beta3Definition = typeof MessagesV1Beta3Definition;
export const MessagesV1Beta3Definition = {
  name: "MessagesV1Beta3",
  fullName: "google.dataflow.v1beta3.MessagesV1Beta3",
  methods: {
    /**
     * Request the job status.
     *
     * To request the status of a job, we recommend using
     * `projects.locations.jobs.messages.list` with a [regional endpoint]
     * (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using
     * `projects.jobs.messages.list` is not recommended, as you can only request
     * the status of jobs that are running in `us-central1`.
     */
    listJobMessages: {
      name: "ListJobMessages",
      requestType: ListJobMessagesRequest,
      requestStream: false,
      responseType: ListJobMessagesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          578365826: [
            Buffer.from([
              127,
              90,
              52,
              18,
              50,
              47,
              118,
              49,
              98,
              51,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              106,
              111,
              98,
              115,
              47,
              123,
              106,
              111,
              98,
              95,
              105,
              100,
              125,
              47,
              109,
              101,
              115,
              115,
              97,
              103,
              101,
              115,
              18,
              71,
              47,
              118,
              49,
              98,
              51,
              47,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              123,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              95,
              105,
              100,
              125,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              125,
              47,
              106,
              111,
              98,
              115,
              47,
              123,
              106,
              111,
              98,
              95,
              105,
              100,
              125,
              47,
              109,
              101,
              115,
              115,
              97,
              103,
              101,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface MessagesV1Beta3ServiceImplementation<CallContextExt = {}> {
  /**
   * Request the job status.
   *
   * To request the status of a job, we recommend using
   * `projects.locations.jobs.messages.list` with a [regional endpoint]
   * (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using
   * `projects.jobs.messages.list` is not recommended, as you can only request
   * the status of jobs that are running in `us-central1`.
   */
  listJobMessages(
    request: ListJobMessagesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListJobMessagesResponse>>;
}

export interface MessagesV1Beta3Client<CallOptionsExt = {}> {
  /**
   * Request the job status.
   *
   * To request the status of a job, we recommend using
   * `projects.locations.jobs.messages.list` with a [regional endpoint]
   * (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using
   * `projects.jobs.messages.list` is not recommended, as you can only request
   * the status of jobs that are running in `us-central1`.
   */
  listJobMessages(
    request: DeepPartial<ListJobMessagesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListJobMessagesResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
