// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/dataflow/v1beta3/streaming.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.dataflow.v1beta3";

/**
 * Global topology of the streaming Dataflow job, including all
 * computations and their sharded locations.
 */
export interface TopologyConfig {
  /** The computations associated with a streaming Dataflow job. */
  computations: ComputationTopology[];
  /** The disks assigned to a streaming Dataflow job. */
  dataDiskAssignments: DataDiskAssignment[];
  /** Maps user stage names to stable computation names. */
  userStageToComputationNameMap: { [key: string]: string };
  /** The size (in bits) of keys that will be assigned to source messages. */
  forwardingKeyBits: number;
  /** Version number for persistent state. */
  persistentStateVersion: number;
}

export interface TopologyConfig_UserStageToComputationNameMapEntry {
  key: string;
  value: string;
}

/**
 * Identifies a pubsub location to use for transferring data into or
 * out of a streaming Dataflow job.
 */
export interface PubsubLocation {
  /**
   * A pubsub topic, in the form of
   * "pubsub.googleapis.com/topics/<project-id>/<topic-name>"
   */
  topic: string;
  /**
   * A pubsub subscription, in the form of
   * "pubsub.googleapis.com/subscriptions/<project-id>/<subscription-name>"
   */
  subscription: string;
  /**
   * If set, contains a pubsub label from which to extract record timestamps.
   * If left empty, record timestamps will be generated upon arrival.
   */
  timestampLabel: string;
  /**
   * If set, contains a pubsub label from which to extract record ids.
   * If left empty, record deduplication will be strictly best effort.
   */
  idLabel: string;
  /** Indicates whether the pipeline allows late-arriving data. */
  dropLateData: boolean;
  /**
   * If set, specifies the pubsub subscription that will be used for tracking
   * custom time timestamps for watermark estimation.
   */
  trackingSubscription: string;
  /** If true, then the client has requested to get pubsub attributes. */
  withAttributes: boolean;
}

/**
 * Identifies the location of a streaming computation stage, for
 * stage-to-stage communication.
 */
export interface StreamingStageLocation {
  /**
   * Identifies the particular stream within the streaming Dataflow
   * job.
   */
  streamId: string;
}

/** Identifies the location of a streaming side input. */
export interface StreamingSideInputLocation {
  /** Identifies the particular side input within the streaming Dataflow job. */
  tag: string;
  /** Identifies the state family where this side input is stored. */
  stateFamily: string;
}

/** Identifies the location of a custom souce. */
export interface CustomSourceLocation {
  /** Whether this source is stateful. */
  stateful: boolean;
}

/**
 * Describes a stream of data, either as input to be processed or as
 * output of a streaming Dataflow job.
 */
export interface StreamLocation {
  /**
   * The stream is part of another computation within the current
   * streaming Dataflow job.
   */
  streamingStageLocation?:
    | StreamingStageLocation
    | undefined;
  /** The stream is a pubsub stream. */
  pubsubLocation?:
    | PubsubLocation
    | undefined;
  /** The stream is a streaming side input. */
  sideInputLocation?:
    | StreamingSideInputLocation
    | undefined;
  /** The stream is a custom source. */
  customSourceLocation?: CustomSourceLocation | undefined;
}

/** State family configuration. */
export interface StateFamilyConfig {
  /** The state family value. */
  stateFamily: string;
  /** If true, this family corresponds to a read operation. */
  isRead: boolean;
}

/** All configuration data for a particular Computation. */
export interface ComputationTopology {
  /** The system stage name. */
  systemStageName: string;
  /** The ID of the computation. */
  computationId: string;
  /** The key ranges processed by the computation. */
  keyRanges: KeyRangeLocation[];
  /** The inputs to the computation. */
  inputs: StreamLocation[];
  /** The outputs from the computation. */
  outputs: StreamLocation[];
  /** The state family values. */
  stateFamilies: StateFamilyConfig[];
}

/**
 * Location information for a specific key-range of a sharded computation.
 * Currently we only support UTF-8 character splits to simplify encoding into
 * JSON.
 */
export interface KeyRangeLocation {
  /** The start (inclusive) of the key range. */
  start: string;
  /** The end (exclusive) of the key range. */
  end: string;
  /**
   * The physical location of this range assignment to be used for
   * streaming computation cross-worker message delivery.
   */
  deliveryEndpoint: string;
  /**
   * The name of the data disk where data for this range is stored.
   * This name is local to the Google Cloud Platform project and uniquely
   * identifies the disk within that project, for example
   * "myproject-1014-104817-4c2-harness-0-disk-1".
   */
  dataDisk: string;
  /**
   * DEPRECATED. The location of the persistent state for this range, as a
   * persistent directory in the worker local filesystem.
   *
   * @deprecated
   */
  deprecatedPersistentDirectory: string;
}

/** Describes mounted data disk. */
export interface MountedDataDisk {
  /**
   * The name of the data disk.
   * This name is local to the Google Cloud Platform project and uniquely
   * identifies the disk within that project, for example
   * "myproject-1014-104817-4c2-harness-0-disk-1".
   */
  dataDisk: string;
}

/** Data disk assignment for a given VM instance. */
export interface DataDiskAssignment {
  /**
   * VM instance name the data disks mounted to, for example
   * "myproject-1014-104817-4c2-harness-0".
   */
  vmInstance: string;
  /**
   * Mounted data disks. The order is important a data disk's 0-based index in
   * this list defines which persistent directory the disk is mounted to, for
   * example the list of { "myproject-1014-104817-4c2-harness-0-disk-0" },
   * { "myproject-1014-104817-4c2-harness-0-disk-1" }.
   */
  dataDisks: string[];
}

/**
 * Data disk assignment information for a specific key-range of a sharded
 * computation.
 * Currently we only support UTF-8 character splits to simplify encoding into
 * JSON.
 */
export interface KeyRangeDataDiskAssignment {
  /** The start (inclusive) of the key range. */
  start: string;
  /** The end (exclusive) of the key range. */
  end: string;
  /**
   * The name of the data disk where data for this range is stored.
   * This name is local to the Google Cloud Platform project and uniquely
   * identifies the disk within that project, for example
   * "myproject-1014-104817-4c2-harness-0-disk-1".
   */
  dataDisk: string;
}

/**
 * Describes full or partial data disk assignment information of the computation
 * ranges.
 */
export interface StreamingComputationRanges {
  /** The ID of the computation. */
  computationId: string;
  /** Data disk assignments for ranges from this computation. */
  rangeAssignments: KeyRangeDataDiskAssignment[];
}

/** Streaming appliance snapshot configuration. */
export interface StreamingApplianceSnapshotConfig {
  /** If set, indicates the snapshot id for the snapshot being performed. */
  snapshotId: string;
  /** Indicates which endpoint is used to import appliance state. */
  importStateEndpoint: string;
}

function createBaseTopologyConfig(): TopologyConfig {
  return {
    computations: [],
    dataDiskAssignments: [],
    userStageToComputationNameMap: {},
    forwardingKeyBits: 0,
    persistentStateVersion: 0,
  };
}

export const TopologyConfig: MessageFns<TopologyConfig> = {
  encode(message: TopologyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.computations) {
      ComputationTopology.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.dataDiskAssignments) {
      DataDiskAssignment.encode(v!, writer.uint32(18).fork()).join();
    }
    Object.entries(message.userStageToComputationNameMap).forEach(([key, value]) => {
      TopologyConfig_UserStageToComputationNameMapEntry.encode({ key: key as any, value }, writer.uint32(26).fork())
        .join();
    });
    if (message.forwardingKeyBits !== 0) {
      writer.uint32(32).int32(message.forwardingKeyBits);
    }
    if (message.persistentStateVersion !== 0) {
      writer.uint32(40).int32(message.persistentStateVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TopologyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTopologyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.computations.push(ComputationTopology.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataDiskAssignments.push(DataDiskAssignment.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = TopologyConfig_UserStageToComputationNameMapEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.userStageToComputationNameMap[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.forwardingKeyBits = reader.int32();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.persistentStateVersion = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TopologyConfig {
    return {
      computations: globalThis.Array.isArray(object?.computations)
        ? object.computations.map((e: any) => ComputationTopology.fromJSON(e))
        : [],
      dataDiskAssignments: globalThis.Array.isArray(object?.dataDiskAssignments)
        ? object.dataDiskAssignments.map((e: any) => DataDiskAssignment.fromJSON(e))
        : [],
      userStageToComputationNameMap: isObject(object.userStageToComputationNameMap)
        ? Object.entries(object.userStageToComputationNameMap).reduce<{ [key: string]: string }>(
          (acc, [key, value]) => {
            acc[key] = String(value);
            return acc;
          },
          {},
        )
        : {},
      forwardingKeyBits: isSet(object.forwardingKeyBits) ? globalThis.Number(object.forwardingKeyBits) : 0,
      persistentStateVersion: isSet(object.persistentStateVersion)
        ? globalThis.Number(object.persistentStateVersion)
        : 0,
    };
  },

  toJSON(message: TopologyConfig): unknown {
    const obj: any = {};
    if (message.computations?.length) {
      obj.computations = message.computations.map((e) => ComputationTopology.toJSON(e));
    }
    if (message.dataDiskAssignments?.length) {
      obj.dataDiskAssignments = message.dataDiskAssignments.map((e) => DataDiskAssignment.toJSON(e));
    }
    if (message.userStageToComputationNameMap) {
      const entries = Object.entries(message.userStageToComputationNameMap);
      if (entries.length > 0) {
        obj.userStageToComputationNameMap = {};
        entries.forEach(([k, v]) => {
          obj.userStageToComputationNameMap[k] = v;
        });
      }
    }
    if (message.forwardingKeyBits !== 0) {
      obj.forwardingKeyBits = Math.round(message.forwardingKeyBits);
    }
    if (message.persistentStateVersion !== 0) {
      obj.persistentStateVersion = Math.round(message.persistentStateVersion);
    }
    return obj;
  },

  create(base?: DeepPartial<TopologyConfig>): TopologyConfig {
    return TopologyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TopologyConfig>): TopologyConfig {
    const message = createBaseTopologyConfig();
    message.computations = object.computations?.map((e) => ComputationTopology.fromPartial(e)) || [];
    message.dataDiskAssignments = object.dataDiskAssignments?.map((e) => DataDiskAssignment.fromPartial(e)) || [];
    message.userStageToComputationNameMap = Object.entries(object.userStageToComputationNameMap ?? {}).reduce<
      { [key: string]: string }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.forwardingKeyBits = object.forwardingKeyBits ?? 0;
    message.persistentStateVersion = object.persistentStateVersion ?? 0;
    return message;
  },
};

function createBaseTopologyConfig_UserStageToComputationNameMapEntry(): TopologyConfig_UserStageToComputationNameMapEntry {
  return { key: "", value: "" };
}

export const TopologyConfig_UserStageToComputationNameMapEntry: MessageFns<
  TopologyConfig_UserStageToComputationNameMapEntry
> = {
  encode(
    message: TopologyConfig_UserStageToComputationNameMapEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TopologyConfig_UserStageToComputationNameMapEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTopologyConfig_UserStageToComputationNameMapEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TopologyConfig_UserStageToComputationNameMapEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: TopologyConfig_UserStageToComputationNameMapEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(
    base?: DeepPartial<TopologyConfig_UserStageToComputationNameMapEntry>,
  ): TopologyConfig_UserStageToComputationNameMapEntry {
    return TopologyConfig_UserStageToComputationNameMapEntry.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<TopologyConfig_UserStageToComputationNameMapEntry>,
  ): TopologyConfig_UserStageToComputationNameMapEntry {
    const message = createBaseTopologyConfig_UserStageToComputationNameMapEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePubsubLocation(): PubsubLocation {
  return {
    topic: "",
    subscription: "",
    timestampLabel: "",
    idLabel: "",
    dropLateData: false,
    trackingSubscription: "",
    withAttributes: false,
  };
}

export const PubsubLocation: MessageFns<PubsubLocation> = {
  encode(message: PubsubLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topic !== "") {
      writer.uint32(10).string(message.topic);
    }
    if (message.subscription !== "") {
      writer.uint32(18).string(message.subscription);
    }
    if (message.timestampLabel !== "") {
      writer.uint32(26).string(message.timestampLabel);
    }
    if (message.idLabel !== "") {
      writer.uint32(34).string(message.idLabel);
    }
    if (message.dropLateData !== false) {
      writer.uint32(40).bool(message.dropLateData);
    }
    if (message.trackingSubscription !== "") {
      writer.uint32(50).string(message.trackingSubscription);
    }
    if (message.withAttributes !== false) {
      writer.uint32(56).bool(message.withAttributes);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PubsubLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePubsubLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subscription = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestampLabel = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.idLabel = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.dropLateData = reader.bool();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.trackingSubscription = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.withAttributes = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PubsubLocation {
    return {
      topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
      subscription: isSet(object.subscription) ? globalThis.String(object.subscription) : "",
      timestampLabel: isSet(object.timestampLabel) ? globalThis.String(object.timestampLabel) : "",
      idLabel: isSet(object.idLabel) ? globalThis.String(object.idLabel) : "",
      dropLateData: isSet(object.dropLateData) ? globalThis.Boolean(object.dropLateData) : false,
      trackingSubscription: isSet(object.trackingSubscription) ? globalThis.String(object.trackingSubscription) : "",
      withAttributes: isSet(object.withAttributes) ? globalThis.Boolean(object.withAttributes) : false,
    };
  },

  toJSON(message: PubsubLocation): unknown {
    const obj: any = {};
    if (message.topic !== "") {
      obj.topic = message.topic;
    }
    if (message.subscription !== "") {
      obj.subscription = message.subscription;
    }
    if (message.timestampLabel !== "") {
      obj.timestampLabel = message.timestampLabel;
    }
    if (message.idLabel !== "") {
      obj.idLabel = message.idLabel;
    }
    if (message.dropLateData !== false) {
      obj.dropLateData = message.dropLateData;
    }
    if (message.trackingSubscription !== "") {
      obj.trackingSubscription = message.trackingSubscription;
    }
    if (message.withAttributes !== false) {
      obj.withAttributes = message.withAttributes;
    }
    return obj;
  },

  create(base?: DeepPartial<PubsubLocation>): PubsubLocation {
    return PubsubLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PubsubLocation>): PubsubLocation {
    const message = createBasePubsubLocation();
    message.topic = object.topic ?? "";
    message.subscription = object.subscription ?? "";
    message.timestampLabel = object.timestampLabel ?? "";
    message.idLabel = object.idLabel ?? "";
    message.dropLateData = object.dropLateData ?? false;
    message.trackingSubscription = object.trackingSubscription ?? "";
    message.withAttributes = object.withAttributes ?? false;
    return message;
  },
};

function createBaseStreamingStageLocation(): StreamingStageLocation {
  return { streamId: "" };
}

export const StreamingStageLocation: MessageFns<StreamingStageLocation> = {
  encode(message: StreamingStageLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.streamId !== "") {
      writer.uint32(10).string(message.streamId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingStageLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingStageLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.streamId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingStageLocation {
    return { streamId: isSet(object.streamId) ? globalThis.String(object.streamId) : "" };
  },

  toJSON(message: StreamingStageLocation): unknown {
    const obj: any = {};
    if (message.streamId !== "") {
      obj.streamId = message.streamId;
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingStageLocation>): StreamingStageLocation {
    return StreamingStageLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingStageLocation>): StreamingStageLocation {
    const message = createBaseStreamingStageLocation();
    message.streamId = object.streamId ?? "";
    return message;
  },
};

function createBaseStreamingSideInputLocation(): StreamingSideInputLocation {
  return { tag: "", stateFamily: "" };
}

export const StreamingSideInputLocation: MessageFns<StreamingSideInputLocation> = {
  encode(message: StreamingSideInputLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tag !== "") {
      writer.uint32(10).string(message.tag);
    }
    if (message.stateFamily !== "") {
      writer.uint32(18).string(message.stateFamily);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingSideInputLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingSideInputLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.tag = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.stateFamily = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingSideInputLocation {
    return {
      tag: isSet(object.tag) ? globalThis.String(object.tag) : "",
      stateFamily: isSet(object.stateFamily) ? globalThis.String(object.stateFamily) : "",
    };
  },

  toJSON(message: StreamingSideInputLocation): unknown {
    const obj: any = {};
    if (message.tag !== "") {
      obj.tag = message.tag;
    }
    if (message.stateFamily !== "") {
      obj.stateFamily = message.stateFamily;
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingSideInputLocation>): StreamingSideInputLocation {
    return StreamingSideInputLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingSideInputLocation>): StreamingSideInputLocation {
    const message = createBaseStreamingSideInputLocation();
    message.tag = object.tag ?? "";
    message.stateFamily = object.stateFamily ?? "";
    return message;
  },
};

function createBaseCustomSourceLocation(): CustomSourceLocation {
  return { stateful: false };
}

export const CustomSourceLocation: MessageFns<CustomSourceLocation> = {
  encode(message: CustomSourceLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stateful !== false) {
      writer.uint32(8).bool(message.stateful);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomSourceLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomSourceLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.stateful = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomSourceLocation {
    return { stateful: isSet(object.stateful) ? globalThis.Boolean(object.stateful) : false };
  },

  toJSON(message: CustomSourceLocation): unknown {
    const obj: any = {};
    if (message.stateful !== false) {
      obj.stateful = message.stateful;
    }
    return obj;
  },

  create(base?: DeepPartial<CustomSourceLocation>): CustomSourceLocation {
    return CustomSourceLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CustomSourceLocation>): CustomSourceLocation {
    const message = createBaseCustomSourceLocation();
    message.stateful = object.stateful ?? false;
    return message;
  },
};

function createBaseStreamLocation(): StreamLocation {
  return {
    streamingStageLocation: undefined,
    pubsubLocation: undefined,
    sideInputLocation: undefined,
    customSourceLocation: undefined,
  };
}

export const StreamLocation: MessageFns<StreamLocation> = {
  encode(message: StreamLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.streamingStageLocation !== undefined) {
      StreamingStageLocation.encode(message.streamingStageLocation, writer.uint32(10).fork()).join();
    }
    if (message.pubsubLocation !== undefined) {
      PubsubLocation.encode(message.pubsubLocation, writer.uint32(18).fork()).join();
    }
    if (message.sideInputLocation !== undefined) {
      StreamingSideInputLocation.encode(message.sideInputLocation, writer.uint32(26).fork()).join();
    }
    if (message.customSourceLocation !== undefined) {
      CustomSourceLocation.encode(message.customSourceLocation, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.streamingStageLocation = StreamingStageLocation.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pubsubLocation = PubsubLocation.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.sideInputLocation = StreamingSideInputLocation.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.customSourceLocation = CustomSourceLocation.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamLocation {
    return {
      streamingStageLocation: isSet(object.streamingStageLocation)
        ? StreamingStageLocation.fromJSON(object.streamingStageLocation)
        : undefined,
      pubsubLocation: isSet(object.pubsubLocation) ? PubsubLocation.fromJSON(object.pubsubLocation) : undefined,
      sideInputLocation: isSet(object.sideInputLocation)
        ? StreamingSideInputLocation.fromJSON(object.sideInputLocation)
        : undefined,
      customSourceLocation: isSet(object.customSourceLocation)
        ? CustomSourceLocation.fromJSON(object.customSourceLocation)
        : undefined,
    };
  },

  toJSON(message: StreamLocation): unknown {
    const obj: any = {};
    if (message.streamingStageLocation !== undefined) {
      obj.streamingStageLocation = StreamingStageLocation.toJSON(message.streamingStageLocation);
    }
    if (message.pubsubLocation !== undefined) {
      obj.pubsubLocation = PubsubLocation.toJSON(message.pubsubLocation);
    }
    if (message.sideInputLocation !== undefined) {
      obj.sideInputLocation = StreamingSideInputLocation.toJSON(message.sideInputLocation);
    }
    if (message.customSourceLocation !== undefined) {
      obj.customSourceLocation = CustomSourceLocation.toJSON(message.customSourceLocation);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamLocation>): StreamLocation {
    return StreamLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamLocation>): StreamLocation {
    const message = createBaseStreamLocation();
    message.streamingStageLocation =
      (object.streamingStageLocation !== undefined && object.streamingStageLocation !== null)
        ? StreamingStageLocation.fromPartial(object.streamingStageLocation)
        : undefined;
    message.pubsubLocation = (object.pubsubLocation !== undefined && object.pubsubLocation !== null)
      ? PubsubLocation.fromPartial(object.pubsubLocation)
      : undefined;
    message.sideInputLocation = (object.sideInputLocation !== undefined && object.sideInputLocation !== null)
      ? StreamingSideInputLocation.fromPartial(object.sideInputLocation)
      : undefined;
    message.customSourceLocation = (object.customSourceLocation !== undefined && object.customSourceLocation !== null)
      ? CustomSourceLocation.fromPartial(object.customSourceLocation)
      : undefined;
    return message;
  },
};

function createBaseStateFamilyConfig(): StateFamilyConfig {
  return { stateFamily: "", isRead: false };
}

export const StateFamilyConfig: MessageFns<StateFamilyConfig> = {
  encode(message: StateFamilyConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stateFamily !== "") {
      writer.uint32(10).string(message.stateFamily);
    }
    if (message.isRead !== false) {
      writer.uint32(16).bool(message.isRead);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StateFamilyConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStateFamilyConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.stateFamily = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.isRead = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StateFamilyConfig {
    return {
      stateFamily: isSet(object.stateFamily) ? globalThis.String(object.stateFamily) : "",
      isRead: isSet(object.isRead) ? globalThis.Boolean(object.isRead) : false,
    };
  },

  toJSON(message: StateFamilyConfig): unknown {
    const obj: any = {};
    if (message.stateFamily !== "") {
      obj.stateFamily = message.stateFamily;
    }
    if (message.isRead !== false) {
      obj.isRead = message.isRead;
    }
    return obj;
  },

  create(base?: DeepPartial<StateFamilyConfig>): StateFamilyConfig {
    return StateFamilyConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StateFamilyConfig>): StateFamilyConfig {
    const message = createBaseStateFamilyConfig();
    message.stateFamily = object.stateFamily ?? "";
    message.isRead = object.isRead ?? false;
    return message;
  },
};

function createBaseComputationTopology(): ComputationTopology {
  return { systemStageName: "", computationId: "", keyRanges: [], inputs: [], outputs: [], stateFamilies: [] };
}

export const ComputationTopology: MessageFns<ComputationTopology> = {
  encode(message: ComputationTopology, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.systemStageName !== "") {
      writer.uint32(10).string(message.systemStageName);
    }
    if (message.computationId !== "") {
      writer.uint32(42).string(message.computationId);
    }
    for (const v of message.keyRanges) {
      KeyRangeLocation.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.inputs) {
      StreamLocation.encode(v!, writer.uint32(26).fork()).join();
    }
    for (const v of message.outputs) {
      StreamLocation.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.stateFamilies) {
      StateFamilyConfig.encode(v!, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputationTopology {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputationTopology();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.systemStageName = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.computationId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.keyRanges.push(KeyRangeLocation.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.inputs.push(StreamLocation.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.outputs.push(StreamLocation.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.stateFamilies.push(StateFamilyConfig.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputationTopology {
    return {
      systemStageName: isSet(object.systemStageName) ? globalThis.String(object.systemStageName) : "",
      computationId: isSet(object.computationId) ? globalThis.String(object.computationId) : "",
      keyRanges: globalThis.Array.isArray(object?.keyRanges)
        ? object.keyRanges.map((e: any) => KeyRangeLocation.fromJSON(e))
        : [],
      inputs: globalThis.Array.isArray(object?.inputs) ? object.inputs.map((e: any) => StreamLocation.fromJSON(e)) : [],
      outputs: globalThis.Array.isArray(object?.outputs)
        ? object.outputs.map((e: any) => StreamLocation.fromJSON(e))
        : [],
      stateFamilies: globalThis.Array.isArray(object?.stateFamilies)
        ? object.stateFamilies.map((e: any) => StateFamilyConfig.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ComputationTopology): unknown {
    const obj: any = {};
    if (message.systemStageName !== "") {
      obj.systemStageName = message.systemStageName;
    }
    if (message.computationId !== "") {
      obj.computationId = message.computationId;
    }
    if (message.keyRanges?.length) {
      obj.keyRanges = message.keyRanges.map((e) => KeyRangeLocation.toJSON(e));
    }
    if (message.inputs?.length) {
      obj.inputs = message.inputs.map((e) => StreamLocation.toJSON(e));
    }
    if (message.outputs?.length) {
      obj.outputs = message.outputs.map((e) => StreamLocation.toJSON(e));
    }
    if (message.stateFamilies?.length) {
      obj.stateFamilies = message.stateFamilies.map((e) => StateFamilyConfig.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ComputationTopology>): ComputationTopology {
    return ComputationTopology.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ComputationTopology>): ComputationTopology {
    const message = createBaseComputationTopology();
    message.systemStageName = object.systemStageName ?? "";
    message.computationId = object.computationId ?? "";
    message.keyRanges = object.keyRanges?.map((e) => KeyRangeLocation.fromPartial(e)) || [];
    message.inputs = object.inputs?.map((e) => StreamLocation.fromPartial(e)) || [];
    message.outputs = object.outputs?.map((e) => StreamLocation.fromPartial(e)) || [];
    message.stateFamilies = object.stateFamilies?.map((e) => StateFamilyConfig.fromPartial(e)) || [];
    return message;
  },
};

function createBaseKeyRangeLocation(): KeyRangeLocation {
  return { start: "", end: "", deliveryEndpoint: "", dataDisk: "", deprecatedPersistentDirectory: "" };
}

export const KeyRangeLocation: MessageFns<KeyRangeLocation> = {
  encode(message: KeyRangeLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.start !== "") {
      writer.uint32(10).string(message.start);
    }
    if (message.end !== "") {
      writer.uint32(18).string(message.end);
    }
    if (message.deliveryEndpoint !== "") {
      writer.uint32(26).string(message.deliveryEndpoint);
    }
    if (message.dataDisk !== "") {
      writer.uint32(42).string(message.dataDisk);
    }
    if (message.deprecatedPersistentDirectory !== "") {
      writer.uint32(34).string(message.deprecatedPersistentDirectory);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KeyRangeLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKeyRangeLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.start = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.end = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.deliveryEndpoint = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.dataDisk = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.deprecatedPersistentDirectory = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KeyRangeLocation {
    return {
      start: isSet(object.start) ? globalThis.String(object.start) : "",
      end: isSet(object.end) ? globalThis.String(object.end) : "",
      deliveryEndpoint: isSet(object.deliveryEndpoint) ? globalThis.String(object.deliveryEndpoint) : "",
      dataDisk: isSet(object.dataDisk) ? globalThis.String(object.dataDisk) : "",
      deprecatedPersistentDirectory: isSet(object.deprecatedPersistentDirectory)
        ? globalThis.String(object.deprecatedPersistentDirectory)
        : "",
    };
  },

  toJSON(message: KeyRangeLocation): unknown {
    const obj: any = {};
    if (message.start !== "") {
      obj.start = message.start;
    }
    if (message.end !== "") {
      obj.end = message.end;
    }
    if (message.deliveryEndpoint !== "") {
      obj.deliveryEndpoint = message.deliveryEndpoint;
    }
    if (message.dataDisk !== "") {
      obj.dataDisk = message.dataDisk;
    }
    if (message.deprecatedPersistentDirectory !== "") {
      obj.deprecatedPersistentDirectory = message.deprecatedPersistentDirectory;
    }
    return obj;
  },

  create(base?: DeepPartial<KeyRangeLocation>): KeyRangeLocation {
    return KeyRangeLocation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<KeyRangeLocation>): KeyRangeLocation {
    const message = createBaseKeyRangeLocation();
    message.start = object.start ?? "";
    message.end = object.end ?? "";
    message.deliveryEndpoint = object.deliveryEndpoint ?? "";
    message.dataDisk = object.dataDisk ?? "";
    message.deprecatedPersistentDirectory = object.deprecatedPersistentDirectory ?? "";
    return message;
  },
};

function createBaseMountedDataDisk(): MountedDataDisk {
  return { dataDisk: "" };
}

export const MountedDataDisk: MessageFns<MountedDataDisk> = {
  encode(message: MountedDataDisk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataDisk !== "") {
      writer.uint32(10).string(message.dataDisk);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MountedDataDisk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMountedDataDisk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.dataDisk = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MountedDataDisk {
    return { dataDisk: isSet(object.dataDisk) ? globalThis.String(object.dataDisk) : "" };
  },

  toJSON(message: MountedDataDisk): unknown {
    const obj: any = {};
    if (message.dataDisk !== "") {
      obj.dataDisk = message.dataDisk;
    }
    return obj;
  },

  create(base?: DeepPartial<MountedDataDisk>): MountedDataDisk {
    return MountedDataDisk.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MountedDataDisk>): MountedDataDisk {
    const message = createBaseMountedDataDisk();
    message.dataDisk = object.dataDisk ?? "";
    return message;
  },
};

function createBaseDataDiskAssignment(): DataDiskAssignment {
  return { vmInstance: "", dataDisks: [] };
}

export const DataDiskAssignment: MessageFns<DataDiskAssignment> = {
  encode(message: DataDiskAssignment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmInstance !== "") {
      writer.uint32(10).string(message.vmInstance);
    }
    for (const v of message.dataDisks) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataDiskAssignment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataDiskAssignment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vmInstance = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataDisks.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataDiskAssignment {
    return {
      vmInstance: isSet(object.vmInstance) ? globalThis.String(object.vmInstance) : "",
      dataDisks: globalThis.Array.isArray(object?.dataDisks)
        ? object.dataDisks.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: DataDiskAssignment): unknown {
    const obj: any = {};
    if (message.vmInstance !== "") {
      obj.vmInstance = message.vmInstance;
    }
    if (message.dataDisks?.length) {
      obj.dataDisks = message.dataDisks;
    }
    return obj;
  },

  create(base?: DeepPartial<DataDiskAssignment>): DataDiskAssignment {
    return DataDiskAssignment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DataDiskAssignment>): DataDiskAssignment {
    const message = createBaseDataDiskAssignment();
    message.vmInstance = object.vmInstance ?? "";
    message.dataDisks = object.dataDisks?.map((e) => e) || [];
    return message;
  },
};

function createBaseKeyRangeDataDiskAssignment(): KeyRangeDataDiskAssignment {
  return { start: "", end: "", dataDisk: "" };
}

export const KeyRangeDataDiskAssignment: MessageFns<KeyRangeDataDiskAssignment> = {
  encode(message: KeyRangeDataDiskAssignment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.start !== "") {
      writer.uint32(10).string(message.start);
    }
    if (message.end !== "") {
      writer.uint32(18).string(message.end);
    }
    if (message.dataDisk !== "") {
      writer.uint32(26).string(message.dataDisk);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KeyRangeDataDiskAssignment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKeyRangeDataDiskAssignment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.start = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.end = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.dataDisk = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KeyRangeDataDiskAssignment {
    return {
      start: isSet(object.start) ? globalThis.String(object.start) : "",
      end: isSet(object.end) ? globalThis.String(object.end) : "",
      dataDisk: isSet(object.dataDisk) ? globalThis.String(object.dataDisk) : "",
    };
  },

  toJSON(message: KeyRangeDataDiskAssignment): unknown {
    const obj: any = {};
    if (message.start !== "") {
      obj.start = message.start;
    }
    if (message.end !== "") {
      obj.end = message.end;
    }
    if (message.dataDisk !== "") {
      obj.dataDisk = message.dataDisk;
    }
    return obj;
  },

  create(base?: DeepPartial<KeyRangeDataDiskAssignment>): KeyRangeDataDiskAssignment {
    return KeyRangeDataDiskAssignment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<KeyRangeDataDiskAssignment>): KeyRangeDataDiskAssignment {
    const message = createBaseKeyRangeDataDiskAssignment();
    message.start = object.start ?? "";
    message.end = object.end ?? "";
    message.dataDisk = object.dataDisk ?? "";
    return message;
  },
};

function createBaseStreamingComputationRanges(): StreamingComputationRanges {
  return { computationId: "", rangeAssignments: [] };
}

export const StreamingComputationRanges: MessageFns<StreamingComputationRanges> = {
  encode(message: StreamingComputationRanges, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.computationId !== "") {
      writer.uint32(10).string(message.computationId);
    }
    for (const v of message.rangeAssignments) {
      KeyRangeDataDiskAssignment.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingComputationRanges {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingComputationRanges();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.computationId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rangeAssignments.push(KeyRangeDataDiskAssignment.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingComputationRanges {
    return {
      computationId: isSet(object.computationId) ? globalThis.String(object.computationId) : "",
      rangeAssignments: globalThis.Array.isArray(object?.rangeAssignments)
        ? object.rangeAssignments.map((e: any) => KeyRangeDataDiskAssignment.fromJSON(e))
        : [],
    };
  },

  toJSON(message: StreamingComputationRanges): unknown {
    const obj: any = {};
    if (message.computationId !== "") {
      obj.computationId = message.computationId;
    }
    if (message.rangeAssignments?.length) {
      obj.rangeAssignments = message.rangeAssignments.map((e) => KeyRangeDataDiskAssignment.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingComputationRanges>): StreamingComputationRanges {
    return StreamingComputationRanges.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingComputationRanges>): StreamingComputationRanges {
    const message = createBaseStreamingComputationRanges();
    message.computationId = object.computationId ?? "";
    message.rangeAssignments = object.rangeAssignments?.map((e) => KeyRangeDataDiskAssignment.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStreamingApplianceSnapshotConfig(): StreamingApplianceSnapshotConfig {
  return { snapshotId: "", importStateEndpoint: "" };
}

export const StreamingApplianceSnapshotConfig: MessageFns<StreamingApplianceSnapshotConfig> = {
  encode(message: StreamingApplianceSnapshotConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshotId !== "") {
      writer.uint32(10).string(message.snapshotId);
    }
    if (message.importStateEndpoint !== "") {
      writer.uint32(18).string(message.importStateEndpoint);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingApplianceSnapshotConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingApplianceSnapshotConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshotId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.importStateEndpoint = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingApplianceSnapshotConfig {
    return {
      snapshotId: isSet(object.snapshotId) ? globalThis.String(object.snapshotId) : "",
      importStateEndpoint: isSet(object.importStateEndpoint) ? globalThis.String(object.importStateEndpoint) : "",
    };
  },

  toJSON(message: StreamingApplianceSnapshotConfig): unknown {
    const obj: any = {};
    if (message.snapshotId !== "") {
      obj.snapshotId = message.snapshotId;
    }
    if (message.importStateEndpoint !== "") {
      obj.importStateEndpoint = message.importStateEndpoint;
    }
    return obj;
  },

  create(base?: DeepPartial<StreamingApplianceSnapshotConfig>): StreamingApplianceSnapshotConfig {
    return StreamingApplianceSnapshotConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamingApplianceSnapshotConfig>): StreamingApplianceSnapshotConfig {
    const message = createBaseStreamingApplianceSnapshotConfig();
    message.snapshotId = object.snapshotId ?? "";
    message.importStateEndpoint = object.importStateEndpoint ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
