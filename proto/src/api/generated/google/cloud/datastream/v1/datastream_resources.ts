// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/datastream/v1/datastream_resources.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.datastream.v1";

/** Oracle database profile. */
export interface OracleProfile {
  /** Required. Hostname for the Oracle connection. */
  hostname: string;
  /** Port for the Oracle connection, default value is 1521. */
  port: number;
  /** Required. Username for the Oracle connection. */
  username: string;
  /** Required. Password for the Oracle connection. */
  password: string;
  /** Required. Database for the Oracle connection. */
  databaseService: string;
  /** Connection string attributes */
  connectionAttributes: { [key: string]: string };
}

export interface OracleProfile_ConnectionAttributesEntry {
  key: string;
  value: string;
}

/** MySQL database profile. */
export interface MysqlProfile {
  /** Required. Hostname for the MySQL connection. */
  hostname: string;
  /** Port for the MySQL connection, default value is 3306. */
  port: number;
  /** Required. Username for the MySQL connection. */
  username: string;
  /** Required. Input only. Password for the MySQL connection. */
  password: string;
  /** SSL configuration for the MySQL connection. */
  sslConfig: MysqlSslConfig | undefined;
}

/** PostgreSQL database profile. */
export interface PostgresqlProfile {
  /** Required. Hostname for the PostgreSQL connection. */
  hostname: string;
  /** Port for the PostgreSQL connection, default value is 5432. */
  port: number;
  /** Required. Username for the PostgreSQL connection. */
  username: string;
  /** Required. Password for the PostgreSQL connection. */
  password: string;
  /** Required. Database for the PostgreSQL connection. */
  database: string;
}

/** Cloud Storage bucket profile. */
export interface GcsProfile {
  /** Required. The Cloud Storage bucket name. */
  bucket: string;
  /** The root path inside the Cloud Storage bucket. */
  rootPath: string;
}

/** BigQuery warehouse profile. */
export interface BigQueryProfile {
}

/**
 * Static IP address connectivity. Used when the source database is configured
 * to allow incoming connections from the Datastream public IP addresses
 * for the region specified in the connection profile.
 */
export interface StaticServiceIpConnectivity {
}

/** Forward SSH Tunnel connectivity. */
export interface ForwardSshTunnelConnectivity {
  /** Required. Hostname for the SSH tunnel. */
  hostname: string;
  /** Required. Username for the SSH tunnel. */
  username: string;
  /** Port for the SSH tunnel, default value is 22. */
  port: number;
  /** Input only. SSH password. */
  password?:
    | string
    | undefined;
  /** Input only. SSH private key. */
  privateKey?: string | undefined;
}

/**
 * The VPC Peering configuration is used to create VPC peering between
 * Datastream and the consumer's VPC.
 */
export interface VpcPeeringConfig {
  /**
   * Required. Fully qualified name of the VPC that Datastream will peer to.
   * Format: `projects/{project}/global/{networks}/{name}`
   */
  vpc: string;
  /** Required. A free subnet for peering. (CIDR of /29) */
  subnet: string;
}

/**
 * The PrivateConnection resource is used to establish private connectivity
 * between Datastream and a customer's network.
 */
export interface PrivateConnection {
  /** Output only. The resource's name. */
  name: string;
  /** Output only. The create time of the resource. */
  createTime:
    | Date
    | undefined;
  /** Output only. The update time of the resource. */
  updateTime:
    | Date
    | undefined;
  /** Labels. */
  labels: { [key: string]: string };
  /** Required. Display name. */
  displayName: string;
  /** Output only. The state of the Private Connection. */
  state: PrivateConnection_State;
  /**
   * Output only. In case of error, the details of the error in a user-friendly
   * format.
   */
  error:
    | Error
    | undefined;
  /** VPC Peering Config. */
  vpcPeeringConfig: VpcPeeringConfig | undefined;
}

/** Private Connection state. */
export enum PrivateConnection_State {
  /** STATE_UNSPECIFIED - Unspecified state. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The private connection is in creation state - creating resources. */
  CREATING = 1,
  /** CREATED - The private connection has been created with all of its resources. */
  CREATED = 2,
  /** FAILED - The private connection creation has failed. */
  FAILED = 3,
  /** DELETING - The private connection is being deleted. */
  DELETING = 4,
  /** FAILED_TO_DELETE - Delete request has failed, resource is in invalid state. */
  FAILED_TO_DELETE = 5,
  UNRECOGNIZED = -1,
}

export function privateConnection_StateFromJSON(object: any): PrivateConnection_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return PrivateConnection_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return PrivateConnection_State.CREATING;
    case 2:
    case "CREATED":
      return PrivateConnection_State.CREATED;
    case 3:
    case "FAILED":
      return PrivateConnection_State.FAILED;
    case 4:
    case "DELETING":
      return PrivateConnection_State.DELETING;
    case 5:
    case "FAILED_TO_DELETE":
      return PrivateConnection_State.FAILED_TO_DELETE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PrivateConnection_State.UNRECOGNIZED;
  }
}

export function privateConnection_StateToJSON(object: PrivateConnection_State): string {
  switch (object) {
    case PrivateConnection_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case PrivateConnection_State.CREATING:
      return "CREATING";
    case PrivateConnection_State.CREATED:
      return "CREATED";
    case PrivateConnection_State.FAILED:
      return "FAILED";
    case PrivateConnection_State.DELETING:
      return "DELETING";
    case PrivateConnection_State.FAILED_TO_DELETE:
      return "FAILED_TO_DELETE";
    case PrivateConnection_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface PrivateConnection_LabelsEntry {
  key: string;
  value: string;
}

/** Private Connectivity */
export interface PrivateConnectivity {
  /**
   * Required. A reference to a private connection resource.
   * Format: `projects/{project}/locations/{location}/privateConnections/{name}`
   */
  privateConnection: string;
}

/**
 * The route resource is the child of the private connection resource,
 * used for defining a route for a private connection.
 */
export interface Route {
  /** Output only. The resource's name. */
  name: string;
  /** Output only. The create time of the resource. */
  createTime:
    | Date
    | undefined;
  /** Output only. The update time of the resource. */
  updateTime:
    | Date
    | undefined;
  /** Labels. */
  labels: { [key: string]: string };
  /** Required. Display name. */
  displayName: string;
  /** Required. Destination address for connection */
  destinationAddress: string;
  /** Destination port for connection */
  destinationPort: number;
}

export interface Route_LabelsEntry {
  key: string;
  value: string;
}

/** MySQL SSL configuration information. */
export interface MysqlSslConfig {
  /**
   * Input only. PEM-encoded private key associated with the Client Certificate.
   * If this field is used then the 'client_certificate' and the
   * 'ca_certificate' fields are mandatory.
   */
  clientKey: string;
  /** Output only. Indicates whether the client_key field is set. */
  clientKeySet: boolean;
  /**
   * Input only. PEM-encoded certificate that will be used by the replica to
   * authenticate against the source database server. If this field is used
   * then the 'client_key' and the 'ca_certificate' fields are mandatory.
   */
  clientCertificate: string;
  /** Output only. Indicates whether the client_certificate field is set. */
  clientCertificateSet: boolean;
  /**
   * Input only. PEM-encoded certificate of the CA that signed the source
   * database server's certificate.
   */
  caCertificate: string;
  /** Output only. Indicates whether the ca_certificate field is set. */
  caCertificateSet: boolean;
}

/**
 * A set of reusable connection configurations to be used as a source or
 * destination for a stream.
 */
export interface ConnectionProfile {
  /** Output only. The resource's name. */
  name: string;
  /** Output only. The create time of the resource. */
  createTime:
    | Date
    | undefined;
  /** Output only. The update time of the resource. */
  updateTime:
    | Date
    | undefined;
  /** Labels. */
  labels: { [key: string]: string };
  /** Required. Display name. */
  displayName: string;
  /** Oracle ConnectionProfile configuration. */
  oracleProfile?:
    | OracleProfile
    | undefined;
  /** Cloud Storage ConnectionProfile configuration. */
  gcsProfile?:
    | GcsProfile
    | undefined;
  /** MySQL ConnectionProfile configuration. */
  mysqlProfile?:
    | MysqlProfile
    | undefined;
  /** BigQuery Connection Profile configuration. */
  bigqueryProfile?:
    | BigQueryProfile
    | undefined;
  /** PostgreSQL Connection Profile configuration. */
  postgresqlProfile?:
    | PostgresqlProfile
    | undefined;
  /** Static Service IP connectivity. */
  staticServiceIpConnectivity?:
    | StaticServiceIpConnectivity
    | undefined;
  /** Forward SSH tunnel connectivity. */
  forwardSshConnectivity?:
    | ForwardSshTunnelConnectivity
    | undefined;
  /** Private connectivity. */
  privateConnectivity?: PrivateConnectivity | undefined;
}

export interface ConnectionProfile_LabelsEntry {
  key: string;
  value: string;
}

/** Oracle Column. */
export interface OracleColumn {
  /** Column name. */
  column: string;
  /** The Oracle data type. */
  dataType: string;
  /** Column length. */
  length: number;
  /** Column precision. */
  precision: number;
  /** Column scale. */
  scale: number;
  /** Column encoding. */
  encoding: string;
  /** Whether or not the column represents a primary key. */
  primaryKey: boolean;
  /** Whether or not the column can accept a null value. */
  nullable: boolean;
  /** The ordinal position of the column in the table. */
  ordinalPosition: number;
}

/** Oracle table. */
export interface OracleTable {
  /** Table name. */
  table: string;
  /**
   * Oracle columns in the schema.
   * When unspecified as part of include/exclude objects, includes/excludes
   * everything.
   */
  oracleColumns: OracleColumn[];
}

/** Oracle schema. */
export interface OracleSchema {
  /** Schema name. */
  schema: string;
  /** Tables in the schema. */
  oracleTables: OracleTable[];
}

/** Oracle database structure. */
export interface OracleRdbms {
  /** Oracle schemas/databases in the database server. */
  oracleSchemas: OracleSchema[];
}

/** Oracle data source configuration */
export interface OracleSourceConfig {
  /** Oracle objects to include in the stream. */
  includeObjects:
    | OracleRdbms
    | undefined;
  /** Oracle objects to exclude from the stream. */
  excludeObjects:
    | OracleRdbms
    | undefined;
  /**
   * Maximum number of concurrent CDC tasks. The number should be non-negative.
   * If not set (or set to 0), the system's default value is used.
   */
  maxConcurrentCdcTasks: number;
  /**
   * Maximum number of concurrent backfill tasks. The number should be
   * non-negative. If not set (or set to 0), the system's default value is used.
   */
  maxConcurrentBackfillTasks: number;
  /** Drop large object values. */
  dropLargeObjects?:
    | OracleSourceConfig_DropLargeObjects
    | undefined;
  /** Stream large object values. NOTE: This feature is currently experimental. */
  streamLargeObjects?: OracleSourceConfig_StreamLargeObjects | undefined;
}

/** Configuration to drop large object values. */
export interface OracleSourceConfig_DropLargeObjects {
}

/** Configuration to stream large object values. */
export interface OracleSourceConfig_StreamLargeObjects {
}

/** PostgreSQL Column. */
export interface PostgresqlColumn {
  /** Column name. */
  column: string;
  /** The PostgreSQL data type. */
  dataType: string;
  /** Column length. */
  length: number;
  /** Column precision. */
  precision: number;
  /** Column scale. */
  scale: number;
  /** Whether or not the column represents a primary key. */
  primaryKey: boolean;
  /** Whether or not the column can accept a null value. */
  nullable: boolean;
  /** The ordinal position of the column in the table. */
  ordinalPosition: number;
}

/** PostgreSQL table. */
export interface PostgresqlTable {
  /** Table name. */
  table: string;
  /**
   * PostgreSQL columns in the schema.
   * When unspecified as part of include/exclude objects,
   * includes/excludes everything.
   */
  postgresqlColumns: PostgresqlColumn[];
}

/** PostgreSQL schema. */
export interface PostgresqlSchema {
  /** Schema name. */
  schema: string;
  /** Tables in the schema. */
  postgresqlTables: PostgresqlTable[];
}

/** PostgreSQL database structure. */
export interface PostgresqlRdbms {
  /** PostgreSQL schemas in the database server. */
  postgresqlSchemas: PostgresqlSchema[];
}

/** PostgreSQL data source configuration */
export interface PostgresqlSourceConfig {
  /** PostgreSQL objects to include in the stream. */
  includeObjects:
    | PostgresqlRdbms
    | undefined;
  /** PostgreSQL objects to exclude from the stream. */
  excludeObjects:
    | PostgresqlRdbms
    | undefined;
  /**
   * Required. Immutable. The name of the logical replication slot that's
   * configured with the pgoutput plugin.
   */
  replicationSlot: string;
  /**
   * Required. The name of the publication that includes the set of all tables
   * that are defined in the stream's include_objects.
   */
  publication: string;
  /**
   * Maximum number of concurrent backfill tasks. The number should be non
   * negative. If not set (or set to 0), the system's default value will be
   * used.
   */
  maxConcurrentBackfillTasks: number;
}

/** MySQL Column. */
export interface MysqlColumn {
  /** Column name. */
  column: string;
  /**
   * The MySQL data type. Full data types list can be found here:
   * https://dev.mysql.com/doc/refman/8.0/en/data-types.html
   */
  dataType: string;
  /** Column length. */
  length: number;
  /** Column collation. */
  collation: string;
  /** Whether or not the column represents a primary key. */
  primaryKey: boolean;
  /** Whether or not the column can accept a null value. */
  nullable: boolean;
  /** The ordinal position of the column in the table. */
  ordinalPosition: number;
  /** Column precision. */
  precision: number;
  /** Column scale. */
  scale: number;
}

/** MySQL table. */
export interface MysqlTable {
  /** Table name. */
  table: string;
  /**
   * MySQL columns in the database.
   * When unspecified as part of include/exclude objects, includes/excludes
   * everything.
   */
  mysqlColumns: MysqlColumn[];
}

/** MySQL database. */
export interface MysqlDatabase {
  /** Database name. */
  database: string;
  /** Tables in the database. */
  mysqlTables: MysqlTable[];
}

/** MySQL database structure */
export interface MysqlRdbms {
  /** Mysql databases on the server */
  mysqlDatabases: MysqlDatabase[];
}

/** MySQL source configuration */
export interface MysqlSourceConfig {
  /** MySQL objects to retrieve from the source. */
  includeObjects:
    | MysqlRdbms
    | undefined;
  /** MySQL objects to exclude from the stream. */
  excludeObjects:
    | MysqlRdbms
    | undefined;
  /**
   * Maximum number of concurrent CDC tasks. The number should be non negative.
   * If not set (or set to 0), the system's default value will be used.
   */
  maxConcurrentCdcTasks: number;
  /**
   * Maximum number of concurrent backfill tasks. The number should be non
   * negative. If not set (or set to 0), the system's default value will be
   * used.
   */
  maxConcurrentBackfillTasks: number;
}

/** The configuration of the stream source. */
export interface SourceConfig {
  /**
   * Required. Source connection profile resoource.
   * Format: `projects/{project}/locations/{location}/connectionProfiles/{name}`
   */
  sourceConnectionProfile: string;
  /** Oracle data source configuration. */
  oracleSourceConfig?:
    | OracleSourceConfig
    | undefined;
  /** MySQL data source configuration. */
  mysqlSourceConfig?:
    | MysqlSourceConfig
    | undefined;
  /** PostgreSQL data source configuration. */
  postgresqlSourceConfig?: PostgresqlSourceConfig | undefined;
}

/** AVRO file format configuration. */
export interface AvroFileFormat {
}

/** JSON file format configuration. */
export interface JsonFileFormat {
  /** The schema file format along JSON data files. */
  schemaFileFormat: JsonFileFormat_SchemaFileFormat;
  /** Compression of the loaded JSON file. */
  compression: JsonFileFormat_JsonCompression;
}

/** Schema file format. */
export enum JsonFileFormat_SchemaFileFormat {
  /** SCHEMA_FILE_FORMAT_UNSPECIFIED - Unspecified schema file format. */
  SCHEMA_FILE_FORMAT_UNSPECIFIED = 0,
  /** NO_SCHEMA_FILE - Do not attach schema file. */
  NO_SCHEMA_FILE = 1,
  /** AVRO_SCHEMA_FILE - Avro schema format. */
  AVRO_SCHEMA_FILE = 2,
  UNRECOGNIZED = -1,
}

export function jsonFileFormat_SchemaFileFormatFromJSON(object: any): JsonFileFormat_SchemaFileFormat {
  switch (object) {
    case 0:
    case "SCHEMA_FILE_FORMAT_UNSPECIFIED":
      return JsonFileFormat_SchemaFileFormat.SCHEMA_FILE_FORMAT_UNSPECIFIED;
    case 1:
    case "NO_SCHEMA_FILE":
      return JsonFileFormat_SchemaFileFormat.NO_SCHEMA_FILE;
    case 2:
    case "AVRO_SCHEMA_FILE":
      return JsonFileFormat_SchemaFileFormat.AVRO_SCHEMA_FILE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JsonFileFormat_SchemaFileFormat.UNRECOGNIZED;
  }
}

export function jsonFileFormat_SchemaFileFormatToJSON(object: JsonFileFormat_SchemaFileFormat): string {
  switch (object) {
    case JsonFileFormat_SchemaFileFormat.SCHEMA_FILE_FORMAT_UNSPECIFIED:
      return "SCHEMA_FILE_FORMAT_UNSPECIFIED";
    case JsonFileFormat_SchemaFileFormat.NO_SCHEMA_FILE:
      return "NO_SCHEMA_FILE";
    case JsonFileFormat_SchemaFileFormat.AVRO_SCHEMA_FILE:
      return "AVRO_SCHEMA_FILE";
    case JsonFileFormat_SchemaFileFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Json file compression. */
export enum JsonFileFormat_JsonCompression {
  /** JSON_COMPRESSION_UNSPECIFIED - Unspecified json file compression. */
  JSON_COMPRESSION_UNSPECIFIED = 0,
  /** NO_COMPRESSION - Do not compress JSON file. */
  NO_COMPRESSION = 1,
  /** GZIP - Gzip compression. */
  GZIP = 2,
  UNRECOGNIZED = -1,
}

export function jsonFileFormat_JsonCompressionFromJSON(object: any): JsonFileFormat_JsonCompression {
  switch (object) {
    case 0:
    case "JSON_COMPRESSION_UNSPECIFIED":
      return JsonFileFormat_JsonCompression.JSON_COMPRESSION_UNSPECIFIED;
    case 1:
    case "NO_COMPRESSION":
      return JsonFileFormat_JsonCompression.NO_COMPRESSION;
    case 2:
    case "GZIP":
      return JsonFileFormat_JsonCompression.GZIP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JsonFileFormat_JsonCompression.UNRECOGNIZED;
  }
}

export function jsonFileFormat_JsonCompressionToJSON(object: JsonFileFormat_JsonCompression): string {
  switch (object) {
    case JsonFileFormat_JsonCompression.JSON_COMPRESSION_UNSPECIFIED:
      return "JSON_COMPRESSION_UNSPECIFIED";
    case JsonFileFormat_JsonCompression.NO_COMPRESSION:
      return "NO_COMPRESSION";
    case JsonFileFormat_JsonCompression.GZIP:
      return "GZIP";
    case JsonFileFormat_JsonCompression.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Google Cloud Storage destination configuration */
export interface GcsDestinationConfig {
  /** Path inside the Cloud Storage bucket to write data to. */
  path: string;
  /** The maximum file size to be saved in the bucket. */
  fileRotationMb: number;
  /**
   * The maximum duration for which new events are added before a file is
   * closed and a new file is created. Values within the range of 15-60 seconds
   * are allowed.
   */
  fileRotationInterval:
    | Duration
    | undefined;
  /** AVRO file format configuration. */
  avroFileFormat?:
    | AvroFileFormat
    | undefined;
  /** JSON file format configuration. */
  jsonFileFormat?: JsonFileFormat | undefined;
}

/** BigQuery destination configuration */
export interface BigQueryDestinationConfig {
  /** Single destination dataset. */
  singleTargetDataset?:
    | BigQueryDestinationConfig_SingleTargetDataset
    | undefined;
  /** Source hierarchy datasets. */
  sourceHierarchyDatasets?:
    | BigQueryDestinationConfig_SourceHierarchyDatasets
    | undefined;
  /**
   * The guaranteed data freshness (in seconds) when querying tables created by
   * the stream. Editing this field will only affect new tables created in the
   * future, but existing tables will not be impacted. Lower values mean that
   * queries will return fresher data, but may result in higher cost.
   */
  dataFreshness: Duration | undefined;
}

/** A single target dataset to which all data will be streamed. */
export interface BigQueryDestinationConfig_SingleTargetDataset {
  /** The dataset ID of the target dataset. */
  datasetId: string;
}

/**
 * Destination datasets are created so that hierarchy of the destination data
 * objects matches the source hierarchy.
 */
export interface BigQueryDestinationConfig_SourceHierarchyDatasets {
  /** The dataset template to use for dynamic dataset creation. */
  datasetTemplate: BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate | undefined;
}

/** Dataset template used for dynamic dataset creation. */
export interface BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate {
  /**
   * Required. The geographic location where the dataset should reside. See
   * https://cloud.google.com/bigquery/docs/locations for supported
   * locations.
   */
  location: string;
  /**
   * If supplied, every created dataset will have its name prefixed by the
   * provided value. The prefix and name will be separated by an underscore.
   * i.e. <prefix>_<dataset_name>.
   */
  datasetIdPrefix: string;
  /**
   * Describes the Cloud KMS encryption key that will be used to
   * protect destination BigQuery table. The BigQuery Service Account
   * associated with your project requires access to this encryption key.
   * i.e.
   * projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{cryptoKey}.
   * See https://cloud.google.com/bigquery/docs/customer-managed-encryption
   * for more information.
   */
  kmsKeyName: string;
}

/** The configuration of the stream destination. */
export interface DestinationConfig {
  /**
   * Required. Destination connection profile resource.
   * Format: `projects/{project}/locations/{location}/connectionProfiles/{name}`
   */
  destinationConnectionProfile: string;
  /** A configuration for how data should be loaded to Cloud Storage. */
  gcsDestinationConfig?:
    | GcsDestinationConfig
    | undefined;
  /** BigQuery destination configuration. */
  bigqueryDestinationConfig?: BigQueryDestinationConfig | undefined;
}

/** A resource representing streaming data from a source to a destination. */
export interface Stream {
  /** Output only. The stream's name. */
  name: string;
  /** Output only. The creation time of the stream. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update time of the stream. */
  updateTime:
    | Date
    | undefined;
  /** Labels. */
  labels: { [key: string]: string };
  /** Required. Display name. */
  displayName: string;
  /** Required. Source connection profile configuration. */
  sourceConfig:
    | SourceConfig
    | undefined;
  /** Required. Destination connection profile configuration. */
  destinationConfig:
    | DestinationConfig
    | undefined;
  /** The state of the stream. */
  state: Stream_State;
  /**
   * Automatically backfill objects included in the stream source
   * configuration. Specific objects can be excluded.
   */
  backfillAll?:
    | Stream_BackfillAllStrategy
    | undefined;
  /** Do not automatically backfill any objects. */
  backfillNone?:
    | Stream_BackfillNoneStrategy
    | undefined;
  /** Output only. Errors on the Stream. */
  errors: Error[];
  /**
   * Immutable. A reference to a KMS encryption key.
   * If provided, it will be used to encrypt the data.
   * If left blank, data will be encrypted using an internal Stream-specific
   * encryption key provisioned through KMS.
   */
  customerManagedEncryptionKey?: string | undefined;
}

/** Stream state. */
export enum Stream_State {
  /** STATE_UNSPECIFIED - Unspecified stream state. */
  STATE_UNSPECIFIED = 0,
  /** NOT_STARTED - The stream has been created but has not yet started streaming data. */
  NOT_STARTED = 1,
  /** RUNNING - The stream is running. */
  RUNNING = 2,
  /** PAUSED - The stream is paused. */
  PAUSED = 3,
  /**
   * MAINTENANCE - The stream is in maintenance mode.
   *
   * Updates are rejected on the resource in this state.
   */
  MAINTENANCE = 4,
  /**
   * FAILED - The stream is experiencing an error that is preventing data from being
   * streamed.
   */
  FAILED = 5,
  /** FAILED_PERMANENTLY - The stream has experienced a terminal failure. */
  FAILED_PERMANENTLY = 6,
  /** STARTING - The stream is starting, but not yet running. */
  STARTING = 7,
  /**
   * DRAINING - The Stream is no longer reading new events, but still writing events in
   * the buffer.
   */
  DRAINING = 8,
  UNRECOGNIZED = -1,
}

export function stream_StateFromJSON(object: any): Stream_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Stream_State.STATE_UNSPECIFIED;
    case 1:
    case "NOT_STARTED":
      return Stream_State.NOT_STARTED;
    case 2:
    case "RUNNING":
      return Stream_State.RUNNING;
    case 3:
    case "PAUSED":
      return Stream_State.PAUSED;
    case 4:
    case "MAINTENANCE":
      return Stream_State.MAINTENANCE;
    case 5:
    case "FAILED":
      return Stream_State.FAILED;
    case 6:
    case "FAILED_PERMANENTLY":
      return Stream_State.FAILED_PERMANENTLY;
    case 7:
    case "STARTING":
      return Stream_State.STARTING;
    case 8:
    case "DRAINING":
      return Stream_State.DRAINING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Stream_State.UNRECOGNIZED;
  }
}

export function stream_StateToJSON(object: Stream_State): string {
  switch (object) {
    case Stream_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Stream_State.NOT_STARTED:
      return "NOT_STARTED";
    case Stream_State.RUNNING:
      return "RUNNING";
    case Stream_State.PAUSED:
      return "PAUSED";
    case Stream_State.MAINTENANCE:
      return "MAINTENANCE";
    case Stream_State.FAILED:
      return "FAILED";
    case Stream_State.FAILED_PERMANENTLY:
      return "FAILED_PERMANENTLY";
    case Stream_State.STARTING:
      return "STARTING";
    case Stream_State.DRAINING:
      return "DRAINING";
    case Stream_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Backfill strategy to automatically backfill the Stream's objects.
 * Specific objects can be excluded.
 */
export interface Stream_BackfillAllStrategy {
  /** Oracle data source objects to avoid backfilling. */
  oracleExcludedObjects?:
    | OracleRdbms
    | undefined;
  /** MySQL data source objects to avoid backfilling. */
  mysqlExcludedObjects?:
    | MysqlRdbms
    | undefined;
  /** PostgreSQL data source objects to avoid backfilling. */
  postgresqlExcludedObjects?: PostgresqlRdbms | undefined;
}

/** Backfill strategy to disable automatic backfill for the Stream's objects. */
export interface Stream_BackfillNoneStrategy {
}

export interface Stream_LabelsEntry {
  key: string;
  value: string;
}

/** A specific stream object (e.g a specific DB table). */
export interface StreamObject {
  /** Output only. The object resource's name. */
  name: string;
  /** Output only. The creation time of the object. */
  createTime:
    | Date
    | undefined;
  /** Output only. The last update time of the object. */
  updateTime:
    | Date
    | undefined;
  /** Required. Display name. */
  displayName: string;
  /** Output only. Active errors on the object. */
  errors: Error[];
  /** The latest backfill job that was initiated for the stream object. */
  backfillJob:
    | BackfillJob
    | undefined;
  /** The object identifier in the data source. */
  sourceObject: SourceObjectIdentifier | undefined;
}

/** Represents an identifier of an object in the data source. */
export interface SourceObjectIdentifier {
  /** Oracle data source object identifier. */
  oracleIdentifier?:
    | SourceObjectIdentifier_OracleObjectIdentifier
    | undefined;
  /** Mysql data source object identifier. */
  mysqlIdentifier?:
    | SourceObjectIdentifier_MysqlObjectIdentifier
    | undefined;
  /** PostgreSQL data source object identifier. */
  postgresqlIdentifier?: SourceObjectIdentifier_PostgresqlObjectIdentifier | undefined;
}

/** Oracle data source object identifier. */
export interface SourceObjectIdentifier_OracleObjectIdentifier {
  /** Required. The schema name. */
  schema: string;
  /** Required. The table name. */
  table: string;
}

/** PostgreSQL data source object identifier. */
export interface SourceObjectIdentifier_PostgresqlObjectIdentifier {
  /** Required. The schema name. */
  schema: string;
  /** Required. The table name. */
  table: string;
}

/** Mysql data source object identifier. */
export interface SourceObjectIdentifier_MysqlObjectIdentifier {
  /** Required. The database name. */
  database: string;
  /** Required. The table name. */
  table: string;
}

/** Represents a backfill job on a specific stream object. */
export interface BackfillJob {
  /** Backfill job state. */
  state: BackfillJob_State;
  /** Backfill job's triggering reason. */
  trigger: BackfillJob_Trigger;
  /** Output only. Backfill job's start time. */
  lastStartTime:
    | Date
    | undefined;
  /** Output only. Backfill job's end time. */
  lastEndTime:
    | Date
    | undefined;
  /** Output only. Errors which caused the backfill job to fail. */
  errors: Error[];
}

/** State of the stream object's backfill job. */
export enum BackfillJob_State {
  /** STATE_UNSPECIFIED - Default value. */
  STATE_UNSPECIFIED = 0,
  /**
   * NOT_STARTED - Backfill job was never started for the stream object (stream has backfill
   * strategy defined as manual or object was explicitly excluded from
   * automatic backfill).
   */
  NOT_STARTED = 1,
  /** PENDING - Backfill job will start pending available resources. */
  PENDING = 2,
  /** ACTIVE - Backfill job is running. */
  ACTIVE = 3,
  /** STOPPED - Backfill job stopped (next job run will start from beginning). */
  STOPPED = 4,
  /** FAILED - Backfill job failed (due to an error). */
  FAILED = 5,
  /** COMPLETED - Backfill completed successfully. */
  COMPLETED = 6,
  /**
   * UNSUPPORTED - Backfill job failed since the table structure is currently unsupported
   * for backfill.
   */
  UNSUPPORTED = 7,
  UNRECOGNIZED = -1,
}

export function backfillJob_StateFromJSON(object: any): BackfillJob_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return BackfillJob_State.STATE_UNSPECIFIED;
    case 1:
    case "NOT_STARTED":
      return BackfillJob_State.NOT_STARTED;
    case 2:
    case "PENDING":
      return BackfillJob_State.PENDING;
    case 3:
    case "ACTIVE":
      return BackfillJob_State.ACTIVE;
    case 4:
    case "STOPPED":
      return BackfillJob_State.STOPPED;
    case 5:
    case "FAILED":
      return BackfillJob_State.FAILED;
    case 6:
    case "COMPLETED":
      return BackfillJob_State.COMPLETED;
    case 7:
    case "UNSUPPORTED":
      return BackfillJob_State.UNSUPPORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BackfillJob_State.UNRECOGNIZED;
  }
}

export function backfillJob_StateToJSON(object: BackfillJob_State): string {
  switch (object) {
    case BackfillJob_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case BackfillJob_State.NOT_STARTED:
      return "NOT_STARTED";
    case BackfillJob_State.PENDING:
      return "PENDING";
    case BackfillJob_State.ACTIVE:
      return "ACTIVE";
    case BackfillJob_State.STOPPED:
      return "STOPPED";
    case BackfillJob_State.FAILED:
      return "FAILED";
    case BackfillJob_State.COMPLETED:
      return "COMPLETED";
    case BackfillJob_State.UNSUPPORTED:
      return "UNSUPPORTED";
    case BackfillJob_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Triggering reason for a backfill job. */
export enum BackfillJob_Trigger {
  /** TRIGGER_UNSPECIFIED - Default value. */
  TRIGGER_UNSPECIFIED = 0,
  /**
   * AUTOMATIC - Object backfill job was triggered automatically according to the stream's
   * backfill strategy.
   */
  AUTOMATIC = 1,
  /** MANUAL - Object backfill job was triggered manually using the dedicated API. */
  MANUAL = 2,
  UNRECOGNIZED = -1,
}

export function backfillJob_TriggerFromJSON(object: any): BackfillJob_Trigger {
  switch (object) {
    case 0:
    case "TRIGGER_UNSPECIFIED":
      return BackfillJob_Trigger.TRIGGER_UNSPECIFIED;
    case 1:
    case "AUTOMATIC":
      return BackfillJob_Trigger.AUTOMATIC;
    case 2:
    case "MANUAL":
      return BackfillJob_Trigger.MANUAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BackfillJob_Trigger.UNRECOGNIZED;
  }
}

export function backfillJob_TriggerToJSON(object: BackfillJob_Trigger): string {
  switch (object) {
    case BackfillJob_Trigger.TRIGGER_UNSPECIFIED:
      return "TRIGGER_UNSPECIFIED";
    case BackfillJob_Trigger.AUTOMATIC:
      return "AUTOMATIC";
    case BackfillJob_Trigger.MANUAL:
      return "MANUAL";
    case BackfillJob_Trigger.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represent a user-facing Error. */
export interface Error {
  /** A title that explains the reason for the error. */
  reason: string;
  /**
   * A unique identifier for this specific error,
   * allowing it to be traced throughout the system in logs and API responses.
   */
  errorUuid: string;
  /** A message containing more information about the error that occurred. */
  message: string;
  /** The time when the error occurred. */
  errorTime:
    | Date
    | undefined;
  /** Additional information about the error. */
  details: { [key: string]: string };
}

export interface Error_DetailsEntry {
  key: string;
  value: string;
}

/** Contains the current validation results. */
export interface ValidationResult {
  /**
   * A list of validations (includes both executed as well as not executed
   * validations).
   */
  validations: Validation[];
}

/** A validation to perform on a stream. */
export interface Validation {
  /** A short description of the validation. */
  description: string;
  /** Validation execution status. */
  state: Validation_State;
  /** Messages reflecting the validation results. */
  message: ValidationMessage[];
  /** A custom code identifying this validation. */
  code: string;
}

/** Validation execution state. */
export enum Validation_State {
  /** STATE_UNSPECIFIED - Unspecified state. */
  STATE_UNSPECIFIED = 0,
  /** NOT_EXECUTED - Validation did not execute. */
  NOT_EXECUTED = 1,
  /** FAILED - Validation failed. */
  FAILED = 2,
  /** PASSED - Validation passed. */
  PASSED = 3,
  UNRECOGNIZED = -1,
}

export function validation_StateFromJSON(object: any): Validation_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Validation_State.STATE_UNSPECIFIED;
    case 1:
    case "NOT_EXECUTED":
      return Validation_State.NOT_EXECUTED;
    case 2:
    case "FAILED":
      return Validation_State.FAILED;
    case 3:
    case "PASSED":
      return Validation_State.PASSED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Validation_State.UNRECOGNIZED;
  }
}

export function validation_StateToJSON(object: Validation_State): string {
  switch (object) {
    case Validation_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Validation_State.NOT_EXECUTED:
      return "NOT_EXECUTED";
    case Validation_State.FAILED:
      return "FAILED";
    case Validation_State.PASSED:
      return "PASSED";
    case Validation_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represent user-facing validation result message. */
export interface ValidationMessage {
  /** The result of the validation. */
  message: string;
  /** Message severity level (warning or error). */
  level: ValidationMessage_Level;
  /** Additional metadata related to the result. */
  metadata: { [key: string]: string };
  /** A custom code identifying this specific message. */
  code: string;
}

/** Validation message level. */
export enum ValidationMessage_Level {
  /** LEVEL_UNSPECIFIED - Unspecified level. */
  LEVEL_UNSPECIFIED = 0,
  /** WARNING - Potentially cause issues with the Stream. */
  WARNING = 1,
  /** ERROR - Definitely cause issues with the Stream. */
  ERROR = 2,
  UNRECOGNIZED = -1,
}

export function validationMessage_LevelFromJSON(object: any): ValidationMessage_Level {
  switch (object) {
    case 0:
    case "LEVEL_UNSPECIFIED":
      return ValidationMessage_Level.LEVEL_UNSPECIFIED;
    case 1:
    case "WARNING":
      return ValidationMessage_Level.WARNING;
    case 2:
    case "ERROR":
      return ValidationMessage_Level.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ValidationMessage_Level.UNRECOGNIZED;
  }
}

export function validationMessage_LevelToJSON(object: ValidationMessage_Level): string {
  switch (object) {
    case ValidationMessage_Level.LEVEL_UNSPECIFIED:
      return "LEVEL_UNSPECIFIED";
    case ValidationMessage_Level.WARNING:
      return "WARNING";
    case ValidationMessage_Level.ERROR:
      return "ERROR";
    case ValidationMessage_Level.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface ValidationMessage_MetadataEntry {
  key: string;
  value: string;
}

function createBaseOracleProfile(): OracleProfile {
  return { hostname: "", port: 0, username: "", password: "", databaseService: "", connectionAttributes: {} };
}

export const OracleProfile: MessageFns<OracleProfile> = {
  encode(message: OracleProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hostname !== "") {
      writer.uint32(10).string(message.hostname);
    }
    if (message.port !== 0) {
      writer.uint32(16).int32(message.port);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.databaseService !== "") {
      writer.uint32(42).string(message.databaseService);
    }
    Object.entries(message.connectionAttributes).forEach(([key, value]) => {
      OracleProfile_ConnectionAttributesEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hostname = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.databaseService = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          const entry6 = OracleProfile_ConnectionAttributesEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.connectionAttributes[entry6.key] = entry6.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleProfile {
    return {
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      databaseService: isSet(object.databaseService) ? globalThis.String(object.databaseService) : "",
      connectionAttributes: isObject(object.connectionAttributes)
        ? Object.entries(object.connectionAttributes).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: OracleProfile): unknown {
    const obj: any = {};
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.databaseService !== "") {
      obj.databaseService = message.databaseService;
    }
    if (message.connectionAttributes) {
      const entries = Object.entries(message.connectionAttributes);
      if (entries.length > 0) {
        obj.connectionAttributes = {};
        entries.forEach(([k, v]) => {
          obj.connectionAttributes[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<OracleProfile>): OracleProfile {
    return OracleProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleProfile>): OracleProfile {
    const message = createBaseOracleProfile();
    message.hostname = object.hostname ?? "";
    message.port = object.port ?? 0;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.databaseService = object.databaseService ?? "";
    message.connectionAttributes = Object.entries(object.connectionAttributes ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseOracleProfile_ConnectionAttributesEntry(): OracleProfile_ConnectionAttributesEntry {
  return { key: "", value: "" };
}

export const OracleProfile_ConnectionAttributesEntry: MessageFns<OracleProfile_ConnectionAttributesEntry> = {
  encode(message: OracleProfile_ConnectionAttributesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleProfile_ConnectionAttributesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleProfile_ConnectionAttributesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleProfile_ConnectionAttributesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: OracleProfile_ConnectionAttributesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<OracleProfile_ConnectionAttributesEntry>): OracleProfile_ConnectionAttributesEntry {
    return OracleProfile_ConnectionAttributesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleProfile_ConnectionAttributesEntry>): OracleProfile_ConnectionAttributesEntry {
    const message = createBaseOracleProfile_ConnectionAttributesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMysqlProfile(): MysqlProfile {
  return { hostname: "", port: 0, username: "", password: "", sslConfig: undefined };
}

export const MysqlProfile: MessageFns<MysqlProfile> = {
  encode(message: MysqlProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hostname !== "") {
      writer.uint32(10).string(message.hostname);
    }
    if (message.port !== 0) {
      writer.uint32(16).int32(message.port);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.sslConfig !== undefined) {
      MysqlSslConfig.encode(message.sslConfig, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hostname = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.sslConfig = MysqlSslConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlProfile {
    return {
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      sslConfig: isSet(object.sslConfig) ? MysqlSslConfig.fromJSON(object.sslConfig) : undefined,
    };
  },

  toJSON(message: MysqlProfile): unknown {
    const obj: any = {};
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.sslConfig !== undefined) {
      obj.sslConfig = MysqlSslConfig.toJSON(message.sslConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlProfile>): MysqlProfile {
    return MysqlProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlProfile>): MysqlProfile {
    const message = createBaseMysqlProfile();
    message.hostname = object.hostname ?? "";
    message.port = object.port ?? 0;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.sslConfig = (object.sslConfig !== undefined && object.sslConfig !== null)
      ? MysqlSslConfig.fromPartial(object.sslConfig)
      : undefined;
    return message;
  },
};

function createBasePostgresqlProfile(): PostgresqlProfile {
  return { hostname: "", port: 0, username: "", password: "", database: "" };
}

export const PostgresqlProfile: MessageFns<PostgresqlProfile> = {
  encode(message: PostgresqlProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hostname !== "") {
      writer.uint32(10).string(message.hostname);
    }
    if (message.port !== 0) {
      writer.uint32(16).int32(message.port);
    }
    if (message.username !== "") {
      writer.uint32(26).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(34).string(message.password);
    }
    if (message.database !== "") {
      writer.uint32(42).string(message.database);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgresqlProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgresqlProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hostname = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.username = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.password = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.database = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgresqlProfile {
    return {
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
      database: isSet(object.database) ? globalThis.String(object.database) : "",
    };
  },

  toJSON(message: PostgresqlProfile): unknown {
    const obj: any = {};
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    if (message.database !== "") {
      obj.database = message.database;
    }
    return obj;
  },

  create(base?: DeepPartial<PostgresqlProfile>): PostgresqlProfile {
    return PostgresqlProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgresqlProfile>): PostgresqlProfile {
    const message = createBasePostgresqlProfile();
    message.hostname = object.hostname ?? "";
    message.port = object.port ?? 0;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    message.database = object.database ?? "";
    return message;
  },
};

function createBaseGcsProfile(): GcsProfile {
  return { bucket: "", rootPath: "" };
}

export const GcsProfile: MessageFns<GcsProfile> = {
  encode(message: GcsProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.rootPath !== "") {
      writer.uint32(18).string(message.rootPath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.rootPath = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsProfile {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      rootPath: isSet(object.rootPath) ? globalThis.String(object.rootPath) : "",
    };
  },

  toJSON(message: GcsProfile): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.rootPath !== "") {
      obj.rootPath = message.rootPath;
    }
    return obj;
  },

  create(base?: DeepPartial<GcsProfile>): GcsProfile {
    return GcsProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsProfile>): GcsProfile {
    const message = createBaseGcsProfile();
    message.bucket = object.bucket ?? "";
    message.rootPath = object.rootPath ?? "";
    return message;
  },
};

function createBaseBigQueryProfile(): BigQueryProfile {
  return {};
}

export const BigQueryProfile: MessageFns<BigQueryProfile> = {
  encode(_: BigQueryProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): BigQueryProfile {
    return {};
  },

  toJSON(_: BigQueryProfile): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<BigQueryProfile>): BigQueryProfile {
    return BigQueryProfile.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<BigQueryProfile>): BigQueryProfile {
    const message = createBaseBigQueryProfile();
    return message;
  },
};

function createBaseStaticServiceIpConnectivity(): StaticServiceIpConnectivity {
  return {};
}

export const StaticServiceIpConnectivity: MessageFns<StaticServiceIpConnectivity> = {
  encode(_: StaticServiceIpConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StaticServiceIpConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStaticServiceIpConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): StaticServiceIpConnectivity {
    return {};
  },

  toJSON(_: StaticServiceIpConnectivity): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<StaticServiceIpConnectivity>): StaticServiceIpConnectivity {
    return StaticServiceIpConnectivity.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<StaticServiceIpConnectivity>): StaticServiceIpConnectivity {
    const message = createBaseStaticServiceIpConnectivity();
    return message;
  },
};

function createBaseForwardSshTunnelConnectivity(): ForwardSshTunnelConnectivity {
  return { hostname: "", username: "", port: 0, password: undefined, privateKey: undefined };
}

export const ForwardSshTunnelConnectivity: MessageFns<ForwardSshTunnelConnectivity> = {
  encode(message: ForwardSshTunnelConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hostname !== "") {
      writer.uint32(10).string(message.hostname);
    }
    if (message.username !== "") {
      writer.uint32(18).string(message.username);
    }
    if (message.port !== 0) {
      writer.uint32(24).int32(message.port);
    }
    if (message.password !== undefined) {
      writer.uint32(802).string(message.password);
    }
    if (message.privateKey !== undefined) {
      writer.uint32(810).string(message.privateKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ForwardSshTunnelConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseForwardSshTunnelConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.hostname = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.username = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.port = reader.int32();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.password = reader.string();
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.privateKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ForwardSshTunnelConnectivity {
    return {
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      password: isSet(object.password) ? globalThis.String(object.password) : undefined,
      privateKey: isSet(object.privateKey) ? globalThis.String(object.privateKey) : undefined,
    };
  },

  toJSON(message: ForwardSshTunnelConnectivity): unknown {
    const obj: any = {};
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.password !== undefined) {
      obj.password = message.password;
    }
    if (message.privateKey !== undefined) {
      obj.privateKey = message.privateKey;
    }
    return obj;
  },

  create(base?: DeepPartial<ForwardSshTunnelConnectivity>): ForwardSshTunnelConnectivity {
    return ForwardSshTunnelConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ForwardSshTunnelConnectivity>): ForwardSshTunnelConnectivity {
    const message = createBaseForwardSshTunnelConnectivity();
    message.hostname = object.hostname ?? "";
    message.username = object.username ?? "";
    message.port = object.port ?? 0;
    message.password = object.password ?? undefined;
    message.privateKey = object.privateKey ?? undefined;
    return message;
  },
};

function createBaseVpcPeeringConfig(): VpcPeeringConfig {
  return { vpc: "", subnet: "" };
}

export const VpcPeeringConfig: MessageFns<VpcPeeringConfig> = {
  encode(message: VpcPeeringConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vpc !== "") {
      writer.uint32(10).string(message.vpc);
    }
    if (message.subnet !== "") {
      writer.uint32(18).string(message.subnet);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VpcPeeringConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVpcPeeringConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.vpc = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.subnet = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VpcPeeringConfig {
    return {
      vpc: isSet(object.vpc) ? globalThis.String(object.vpc) : "",
      subnet: isSet(object.subnet) ? globalThis.String(object.subnet) : "",
    };
  },

  toJSON(message: VpcPeeringConfig): unknown {
    const obj: any = {};
    if (message.vpc !== "") {
      obj.vpc = message.vpc;
    }
    if (message.subnet !== "") {
      obj.subnet = message.subnet;
    }
    return obj;
  },

  create(base?: DeepPartial<VpcPeeringConfig>): VpcPeeringConfig {
    return VpcPeeringConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<VpcPeeringConfig>): VpcPeeringConfig {
    const message = createBaseVpcPeeringConfig();
    message.vpc = object.vpc ?? "";
    message.subnet = object.subnet ?? "";
    return message;
  },
};

function createBasePrivateConnection(): PrivateConnection {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    displayName: "",
    state: 0,
    error: undefined,
    vpcPeeringConfig: undefined,
  };
}

export const PrivateConnection: MessageFns<PrivateConnection> = {
  encode(message: PrivateConnection, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      PrivateConnection_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.error !== undefined) {
      Error.encode(message.error, writer.uint32(58).fork()).join();
    }
    if (message.vpcPeeringConfig !== undefined) {
      VpcPeeringConfig.encode(message.vpcPeeringConfig, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateConnection {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateConnection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = PrivateConnection_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.error = Error.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.vpcPeeringConfig = VpcPeeringConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateConnection {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? privateConnection_StateFromJSON(object.state) : 0,
      error: isSet(object.error) ? Error.fromJSON(object.error) : undefined,
      vpcPeeringConfig: isSet(object.vpcPeeringConfig) ? VpcPeeringConfig.fromJSON(object.vpcPeeringConfig) : undefined,
    };
  },

  toJSON(message: PrivateConnection): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = privateConnection_StateToJSON(message.state);
    }
    if (message.error !== undefined) {
      obj.error = Error.toJSON(message.error);
    }
    if (message.vpcPeeringConfig !== undefined) {
      obj.vpcPeeringConfig = VpcPeeringConfig.toJSON(message.vpcPeeringConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateConnection>): PrivateConnection {
    return PrivateConnection.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateConnection>): PrivateConnection {
    const message = createBasePrivateConnection();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.error = (object.error !== undefined && object.error !== null) ? Error.fromPartial(object.error) : undefined;
    message.vpcPeeringConfig = (object.vpcPeeringConfig !== undefined && object.vpcPeeringConfig !== null)
      ? VpcPeeringConfig.fromPartial(object.vpcPeeringConfig)
      : undefined;
    return message;
  },
};

function createBasePrivateConnection_LabelsEntry(): PrivateConnection_LabelsEntry {
  return { key: "", value: "" };
}

export const PrivateConnection_LabelsEntry: MessageFns<PrivateConnection_LabelsEntry> = {
  encode(message: PrivateConnection_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateConnection_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateConnection_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateConnection_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PrivateConnection_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateConnection_LabelsEntry>): PrivateConnection_LabelsEntry {
    return PrivateConnection_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateConnection_LabelsEntry>): PrivateConnection_LabelsEntry {
    const message = createBasePrivateConnection_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePrivateConnectivity(): PrivateConnectivity {
  return { privateConnection: "" };
}

export const PrivateConnectivity: MessageFns<PrivateConnectivity> = {
  encode(message: PrivateConnectivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.privateConnection !== "") {
      writer.uint32(10).string(message.privateConnection);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivateConnectivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivateConnectivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.privateConnection = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivateConnectivity {
    return { privateConnection: isSet(object.privateConnection) ? globalThis.String(object.privateConnection) : "" };
  },

  toJSON(message: PrivateConnectivity): unknown {
    const obj: any = {};
    if (message.privateConnection !== "") {
      obj.privateConnection = message.privateConnection;
    }
    return obj;
  },

  create(base?: DeepPartial<PrivateConnectivity>): PrivateConnectivity {
    return PrivateConnectivity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PrivateConnectivity>): PrivateConnectivity {
    const message = createBasePrivateConnectivity();
    message.privateConnection = object.privateConnection ?? "";
    return message;
  },
};

function createBaseRoute(): Route {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    displayName: "",
    destinationAddress: "",
    destinationPort: 0,
  };
}

export const Route: MessageFns<Route> = {
  encode(message: Route, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Route_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.destinationAddress !== "") {
      writer.uint32(50).string(message.destinationAddress);
    }
    if (message.destinationPort !== 0) {
      writer.uint32(56).int32(message.destinationPort);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Route {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRoute();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = Route_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.destinationAddress = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.destinationPort = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Route {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      destinationAddress: isSet(object.destinationAddress) ? globalThis.String(object.destinationAddress) : "",
      destinationPort: isSet(object.destinationPort) ? globalThis.Number(object.destinationPort) : 0,
    };
  },

  toJSON(message: Route): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.destinationAddress !== "") {
      obj.destinationAddress = message.destinationAddress;
    }
    if (message.destinationPort !== 0) {
      obj.destinationPort = Math.round(message.destinationPort);
    }
    return obj;
  },

  create(base?: DeepPartial<Route>): Route {
    return Route.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Route>): Route {
    const message = createBaseRoute();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.displayName = object.displayName ?? "";
    message.destinationAddress = object.destinationAddress ?? "";
    message.destinationPort = object.destinationPort ?? 0;
    return message;
  },
};

function createBaseRoute_LabelsEntry(): Route_LabelsEntry {
  return { key: "", value: "" };
}

export const Route_LabelsEntry: MessageFns<Route_LabelsEntry> = {
  encode(message: Route_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Route_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRoute_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Route_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Route_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Route_LabelsEntry>): Route_LabelsEntry {
    return Route_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Route_LabelsEntry>): Route_LabelsEntry {
    const message = createBaseRoute_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMysqlSslConfig(): MysqlSslConfig {
  return {
    clientKey: "",
    clientKeySet: false,
    clientCertificate: "",
    clientCertificateSet: false,
    caCertificate: "",
    caCertificateSet: false,
  };
}

export const MysqlSslConfig: MessageFns<MysqlSslConfig> = {
  encode(message: MysqlSslConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.clientKey !== "") {
      writer.uint32(10).string(message.clientKey);
    }
    if (message.clientKeySet !== false) {
      writer.uint32(16).bool(message.clientKeySet);
    }
    if (message.clientCertificate !== "") {
      writer.uint32(26).string(message.clientCertificate);
    }
    if (message.clientCertificateSet !== false) {
      writer.uint32(32).bool(message.clientCertificateSet);
    }
    if (message.caCertificate !== "") {
      writer.uint32(42).string(message.caCertificate);
    }
    if (message.caCertificateSet !== false) {
      writer.uint32(48).bool(message.caCertificateSet);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlSslConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlSslConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.clientKey = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.clientKeySet = reader.bool();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.clientCertificate = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.clientCertificateSet = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.caCertificate = reader.string();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.caCertificateSet = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlSslConfig {
    return {
      clientKey: isSet(object.clientKey) ? globalThis.String(object.clientKey) : "",
      clientKeySet: isSet(object.clientKeySet) ? globalThis.Boolean(object.clientKeySet) : false,
      clientCertificate: isSet(object.clientCertificate) ? globalThis.String(object.clientCertificate) : "",
      clientCertificateSet: isSet(object.clientCertificateSet)
        ? globalThis.Boolean(object.clientCertificateSet)
        : false,
      caCertificate: isSet(object.caCertificate) ? globalThis.String(object.caCertificate) : "",
      caCertificateSet: isSet(object.caCertificateSet) ? globalThis.Boolean(object.caCertificateSet) : false,
    };
  },

  toJSON(message: MysqlSslConfig): unknown {
    const obj: any = {};
    if (message.clientKey !== "") {
      obj.clientKey = message.clientKey;
    }
    if (message.clientKeySet !== false) {
      obj.clientKeySet = message.clientKeySet;
    }
    if (message.clientCertificate !== "") {
      obj.clientCertificate = message.clientCertificate;
    }
    if (message.clientCertificateSet !== false) {
      obj.clientCertificateSet = message.clientCertificateSet;
    }
    if (message.caCertificate !== "") {
      obj.caCertificate = message.caCertificate;
    }
    if (message.caCertificateSet !== false) {
      obj.caCertificateSet = message.caCertificateSet;
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlSslConfig>): MysqlSslConfig {
    return MysqlSslConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlSslConfig>): MysqlSslConfig {
    const message = createBaseMysqlSslConfig();
    message.clientKey = object.clientKey ?? "";
    message.clientKeySet = object.clientKeySet ?? false;
    message.clientCertificate = object.clientCertificate ?? "";
    message.clientCertificateSet = object.clientCertificateSet ?? false;
    message.caCertificate = object.caCertificate ?? "";
    message.caCertificateSet = object.caCertificateSet ?? false;
    return message;
  },
};

function createBaseConnectionProfile(): ConnectionProfile {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    displayName: "",
    oracleProfile: undefined,
    gcsProfile: undefined,
    mysqlProfile: undefined,
    bigqueryProfile: undefined,
    postgresqlProfile: undefined,
    staticServiceIpConnectivity: undefined,
    forwardSshConnectivity: undefined,
    privateConnectivity: undefined,
  };
}

export const ConnectionProfile: MessageFns<ConnectionProfile> = {
  encode(message: ConnectionProfile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ConnectionProfile_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.oracleProfile !== undefined) {
      OracleProfile.encode(message.oracleProfile, writer.uint32(802).fork()).join();
    }
    if (message.gcsProfile !== undefined) {
      GcsProfile.encode(message.gcsProfile, writer.uint32(810).fork()).join();
    }
    if (message.mysqlProfile !== undefined) {
      MysqlProfile.encode(message.mysqlProfile, writer.uint32(818).fork()).join();
    }
    if (message.bigqueryProfile !== undefined) {
      BigQueryProfile.encode(message.bigqueryProfile, writer.uint32(826).fork()).join();
    }
    if (message.postgresqlProfile !== undefined) {
      PostgresqlProfile.encode(message.postgresqlProfile, writer.uint32(834).fork()).join();
    }
    if (message.staticServiceIpConnectivity !== undefined) {
      StaticServiceIpConnectivity.encode(message.staticServiceIpConnectivity, writer.uint32(1602).fork()).join();
    }
    if (message.forwardSshConnectivity !== undefined) {
      ForwardSshTunnelConnectivity.encode(message.forwardSshConnectivity, writer.uint32(1610).fork()).join();
    }
    if (message.privateConnectivity !== undefined) {
      PrivateConnectivity.encode(message.privateConnectivity, writer.uint32(1618).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConnectionProfile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnectionProfile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = ConnectionProfile_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.oracleProfile = OracleProfile.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.gcsProfile = GcsProfile.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.mysqlProfile = MysqlProfile.decode(reader, reader.uint32());
          continue;
        case 103:
          if (tag !== 826) {
            break;
          }

          message.bigqueryProfile = BigQueryProfile.decode(reader, reader.uint32());
          continue;
        case 104:
          if (tag !== 834) {
            break;
          }

          message.postgresqlProfile = PostgresqlProfile.decode(reader, reader.uint32());
          continue;
        case 200:
          if (tag !== 1602) {
            break;
          }

          message.staticServiceIpConnectivity = StaticServiceIpConnectivity.decode(reader, reader.uint32());
          continue;
        case 201:
          if (tag !== 1610) {
            break;
          }

          message.forwardSshConnectivity = ForwardSshTunnelConnectivity.decode(reader, reader.uint32());
          continue;
        case 202:
          if (tag !== 1618) {
            break;
          }

          message.privateConnectivity = PrivateConnectivity.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConnectionProfile {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      oracleProfile: isSet(object.oracleProfile) ? OracleProfile.fromJSON(object.oracleProfile) : undefined,
      gcsProfile: isSet(object.gcsProfile) ? GcsProfile.fromJSON(object.gcsProfile) : undefined,
      mysqlProfile: isSet(object.mysqlProfile) ? MysqlProfile.fromJSON(object.mysqlProfile) : undefined,
      bigqueryProfile: isSet(object.bigqueryProfile) ? BigQueryProfile.fromJSON(object.bigqueryProfile) : undefined,
      postgresqlProfile: isSet(object.postgresqlProfile)
        ? PostgresqlProfile.fromJSON(object.postgresqlProfile)
        : undefined,
      staticServiceIpConnectivity: isSet(object.staticServiceIpConnectivity)
        ? StaticServiceIpConnectivity.fromJSON(object.staticServiceIpConnectivity)
        : undefined,
      forwardSshConnectivity: isSet(object.forwardSshConnectivity)
        ? ForwardSshTunnelConnectivity.fromJSON(object.forwardSshConnectivity)
        : undefined,
      privateConnectivity: isSet(object.privateConnectivity)
        ? PrivateConnectivity.fromJSON(object.privateConnectivity)
        : undefined,
    };
  },

  toJSON(message: ConnectionProfile): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.oracleProfile !== undefined) {
      obj.oracleProfile = OracleProfile.toJSON(message.oracleProfile);
    }
    if (message.gcsProfile !== undefined) {
      obj.gcsProfile = GcsProfile.toJSON(message.gcsProfile);
    }
    if (message.mysqlProfile !== undefined) {
      obj.mysqlProfile = MysqlProfile.toJSON(message.mysqlProfile);
    }
    if (message.bigqueryProfile !== undefined) {
      obj.bigqueryProfile = BigQueryProfile.toJSON(message.bigqueryProfile);
    }
    if (message.postgresqlProfile !== undefined) {
      obj.postgresqlProfile = PostgresqlProfile.toJSON(message.postgresqlProfile);
    }
    if (message.staticServiceIpConnectivity !== undefined) {
      obj.staticServiceIpConnectivity = StaticServiceIpConnectivity.toJSON(message.staticServiceIpConnectivity);
    }
    if (message.forwardSshConnectivity !== undefined) {
      obj.forwardSshConnectivity = ForwardSshTunnelConnectivity.toJSON(message.forwardSshConnectivity);
    }
    if (message.privateConnectivity !== undefined) {
      obj.privateConnectivity = PrivateConnectivity.toJSON(message.privateConnectivity);
    }
    return obj;
  },

  create(base?: DeepPartial<ConnectionProfile>): ConnectionProfile {
    return ConnectionProfile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConnectionProfile>): ConnectionProfile {
    const message = createBaseConnectionProfile();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.displayName = object.displayName ?? "";
    message.oracleProfile = (object.oracleProfile !== undefined && object.oracleProfile !== null)
      ? OracleProfile.fromPartial(object.oracleProfile)
      : undefined;
    message.gcsProfile = (object.gcsProfile !== undefined && object.gcsProfile !== null)
      ? GcsProfile.fromPartial(object.gcsProfile)
      : undefined;
    message.mysqlProfile = (object.mysqlProfile !== undefined && object.mysqlProfile !== null)
      ? MysqlProfile.fromPartial(object.mysqlProfile)
      : undefined;
    message.bigqueryProfile = (object.bigqueryProfile !== undefined && object.bigqueryProfile !== null)
      ? BigQueryProfile.fromPartial(object.bigqueryProfile)
      : undefined;
    message.postgresqlProfile = (object.postgresqlProfile !== undefined && object.postgresqlProfile !== null)
      ? PostgresqlProfile.fromPartial(object.postgresqlProfile)
      : undefined;
    message.staticServiceIpConnectivity =
      (object.staticServiceIpConnectivity !== undefined && object.staticServiceIpConnectivity !== null)
        ? StaticServiceIpConnectivity.fromPartial(object.staticServiceIpConnectivity)
        : undefined;
    message.forwardSshConnectivity =
      (object.forwardSshConnectivity !== undefined && object.forwardSshConnectivity !== null)
        ? ForwardSshTunnelConnectivity.fromPartial(object.forwardSshConnectivity)
        : undefined;
    message.privateConnectivity = (object.privateConnectivity !== undefined && object.privateConnectivity !== null)
      ? PrivateConnectivity.fromPartial(object.privateConnectivity)
      : undefined;
    return message;
  },
};

function createBaseConnectionProfile_LabelsEntry(): ConnectionProfile_LabelsEntry {
  return { key: "", value: "" };
}

export const ConnectionProfile_LabelsEntry: MessageFns<ConnectionProfile_LabelsEntry> = {
  encode(message: ConnectionProfile_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConnectionProfile_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnectionProfile_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConnectionProfile_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ConnectionProfile_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ConnectionProfile_LabelsEntry>): ConnectionProfile_LabelsEntry {
    return ConnectionProfile_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ConnectionProfile_LabelsEntry>): ConnectionProfile_LabelsEntry {
    const message = createBaseConnectionProfile_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseOracleColumn(): OracleColumn {
  return {
    column: "",
    dataType: "",
    length: 0,
    precision: 0,
    scale: 0,
    encoding: "",
    primaryKey: false,
    nullable: false,
    ordinalPosition: 0,
  };
}

export const OracleColumn: MessageFns<OracleColumn> = {
  encode(message: OracleColumn, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.column !== "") {
      writer.uint32(10).string(message.column);
    }
    if (message.dataType !== "") {
      writer.uint32(18).string(message.dataType);
    }
    if (message.length !== 0) {
      writer.uint32(24).int32(message.length);
    }
    if (message.precision !== 0) {
      writer.uint32(32).int32(message.precision);
    }
    if (message.scale !== 0) {
      writer.uint32(40).int32(message.scale);
    }
    if (message.encoding !== "") {
      writer.uint32(50).string(message.encoding);
    }
    if (message.primaryKey !== false) {
      writer.uint32(56).bool(message.primaryKey);
    }
    if (message.nullable !== false) {
      writer.uint32(64).bool(message.nullable);
    }
    if (message.ordinalPosition !== 0) {
      writer.uint32(72).int32(message.ordinalPosition);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleColumn {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleColumn();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.column = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataType = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.length = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.precision = reader.int32();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.scale = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.encoding = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.primaryKey = reader.bool();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.nullable = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.ordinalPosition = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleColumn {
    return {
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      dataType: isSet(object.dataType) ? globalThis.String(object.dataType) : "",
      length: isSet(object.length) ? globalThis.Number(object.length) : 0,
      precision: isSet(object.precision) ? globalThis.Number(object.precision) : 0,
      scale: isSet(object.scale) ? globalThis.Number(object.scale) : 0,
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      primaryKey: isSet(object.primaryKey) ? globalThis.Boolean(object.primaryKey) : false,
      nullable: isSet(object.nullable) ? globalThis.Boolean(object.nullable) : false,
      ordinalPosition: isSet(object.ordinalPosition) ? globalThis.Number(object.ordinalPosition) : 0,
    };
  },

  toJSON(message: OracleColumn): unknown {
    const obj: any = {};
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.dataType !== "") {
      obj.dataType = message.dataType;
    }
    if (message.length !== 0) {
      obj.length = Math.round(message.length);
    }
    if (message.precision !== 0) {
      obj.precision = Math.round(message.precision);
    }
    if (message.scale !== 0) {
      obj.scale = Math.round(message.scale);
    }
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.primaryKey !== false) {
      obj.primaryKey = message.primaryKey;
    }
    if (message.nullable !== false) {
      obj.nullable = message.nullable;
    }
    if (message.ordinalPosition !== 0) {
      obj.ordinalPosition = Math.round(message.ordinalPosition);
    }
    return obj;
  },

  create(base?: DeepPartial<OracleColumn>): OracleColumn {
    return OracleColumn.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleColumn>): OracleColumn {
    const message = createBaseOracleColumn();
    message.column = object.column ?? "";
    message.dataType = object.dataType ?? "";
    message.length = object.length ?? 0;
    message.precision = object.precision ?? 0;
    message.scale = object.scale ?? 0;
    message.encoding = object.encoding ?? "";
    message.primaryKey = object.primaryKey ?? false;
    message.nullable = object.nullable ?? false;
    message.ordinalPosition = object.ordinalPosition ?? 0;
    return message;
  },
};

function createBaseOracleTable(): OracleTable {
  return { table: "", oracleColumns: [] };
}

export const OracleTable: MessageFns<OracleTable> = {
  encode(message: OracleTable, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== "") {
      writer.uint32(10).string(message.table);
    }
    for (const v of message.oracleColumns) {
      OracleColumn.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleTable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.oracleColumns.push(OracleColumn.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleTable {
    return {
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      oracleColumns: globalThis.Array.isArray(object?.oracleColumns)
        ? object.oracleColumns.map((e: any) => OracleColumn.fromJSON(e))
        : [],
    };
  },

  toJSON(message: OracleTable): unknown {
    const obj: any = {};
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.oracleColumns?.length) {
      obj.oracleColumns = message.oracleColumns.map((e) => OracleColumn.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<OracleTable>): OracleTable {
    return OracleTable.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleTable>): OracleTable {
    const message = createBaseOracleTable();
    message.table = object.table ?? "";
    message.oracleColumns = object.oracleColumns?.map((e) => OracleColumn.fromPartial(e)) || [];
    return message;
  },
};

function createBaseOracleSchema(): OracleSchema {
  return { schema: "", oracleTables: [] };
}

export const OracleSchema: MessageFns<OracleSchema> = {
  encode(message: OracleSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schema !== "") {
      writer.uint32(10).string(message.schema);
    }
    for (const v of message.oracleTables) {
      OracleTable.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schema = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.oracleTables.push(OracleTable.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleSchema {
    return {
      schema: isSet(object.schema) ? globalThis.String(object.schema) : "",
      oracleTables: globalThis.Array.isArray(object?.oracleTables)
        ? object.oracleTables.map((e: any) => OracleTable.fromJSON(e))
        : [],
    };
  },

  toJSON(message: OracleSchema): unknown {
    const obj: any = {};
    if (message.schema !== "") {
      obj.schema = message.schema;
    }
    if (message.oracleTables?.length) {
      obj.oracleTables = message.oracleTables.map((e) => OracleTable.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<OracleSchema>): OracleSchema {
    return OracleSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleSchema>): OracleSchema {
    const message = createBaseOracleSchema();
    message.schema = object.schema ?? "";
    message.oracleTables = object.oracleTables?.map((e) => OracleTable.fromPartial(e)) || [];
    return message;
  },
};

function createBaseOracleRdbms(): OracleRdbms {
  return { oracleSchemas: [] };
}

export const OracleRdbms: MessageFns<OracleRdbms> = {
  encode(message: OracleRdbms, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.oracleSchemas) {
      OracleSchema.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleRdbms {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleRdbms();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.oracleSchemas.push(OracleSchema.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleRdbms {
    return {
      oracleSchemas: globalThis.Array.isArray(object?.oracleSchemas)
        ? object.oracleSchemas.map((e: any) => OracleSchema.fromJSON(e))
        : [],
    };
  },

  toJSON(message: OracleRdbms): unknown {
    const obj: any = {};
    if (message.oracleSchemas?.length) {
      obj.oracleSchemas = message.oracleSchemas.map((e) => OracleSchema.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<OracleRdbms>): OracleRdbms {
    return OracleRdbms.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleRdbms>): OracleRdbms {
    const message = createBaseOracleRdbms();
    message.oracleSchemas = object.oracleSchemas?.map((e) => OracleSchema.fromPartial(e)) || [];
    return message;
  },
};

function createBaseOracleSourceConfig(): OracleSourceConfig {
  return {
    includeObjects: undefined,
    excludeObjects: undefined,
    maxConcurrentCdcTasks: 0,
    maxConcurrentBackfillTasks: 0,
    dropLargeObjects: undefined,
    streamLargeObjects: undefined,
  };
}

export const OracleSourceConfig: MessageFns<OracleSourceConfig> = {
  encode(message: OracleSourceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeObjects !== undefined) {
      OracleRdbms.encode(message.includeObjects, writer.uint32(10).fork()).join();
    }
    if (message.excludeObjects !== undefined) {
      OracleRdbms.encode(message.excludeObjects, writer.uint32(18).fork()).join();
    }
    if (message.maxConcurrentCdcTasks !== 0) {
      writer.uint32(24).int32(message.maxConcurrentCdcTasks);
    }
    if (message.maxConcurrentBackfillTasks !== 0) {
      writer.uint32(32).int32(message.maxConcurrentBackfillTasks);
    }
    if (message.dropLargeObjects !== undefined) {
      OracleSourceConfig_DropLargeObjects.encode(message.dropLargeObjects, writer.uint32(802).fork()).join();
    }
    if (message.streamLargeObjects !== undefined) {
      OracleSourceConfig_StreamLargeObjects.encode(message.streamLargeObjects, writer.uint32(818).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleSourceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleSourceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeObjects = OracleRdbms.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.excludeObjects = OracleRdbms.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.maxConcurrentCdcTasks = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.maxConcurrentBackfillTasks = reader.int32();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.dropLargeObjects = OracleSourceConfig_DropLargeObjects.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.streamLargeObjects = OracleSourceConfig_StreamLargeObjects.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OracleSourceConfig {
    return {
      includeObjects: isSet(object.includeObjects) ? OracleRdbms.fromJSON(object.includeObjects) : undefined,
      excludeObjects: isSet(object.excludeObjects) ? OracleRdbms.fromJSON(object.excludeObjects) : undefined,
      maxConcurrentCdcTasks: isSet(object.maxConcurrentCdcTasks) ? globalThis.Number(object.maxConcurrentCdcTasks) : 0,
      maxConcurrentBackfillTasks: isSet(object.maxConcurrentBackfillTasks)
        ? globalThis.Number(object.maxConcurrentBackfillTasks)
        : 0,
      dropLargeObjects: isSet(object.dropLargeObjects)
        ? OracleSourceConfig_DropLargeObjects.fromJSON(object.dropLargeObjects)
        : undefined,
      streamLargeObjects: isSet(object.streamLargeObjects)
        ? OracleSourceConfig_StreamLargeObjects.fromJSON(object.streamLargeObjects)
        : undefined,
    };
  },

  toJSON(message: OracleSourceConfig): unknown {
    const obj: any = {};
    if (message.includeObjects !== undefined) {
      obj.includeObjects = OracleRdbms.toJSON(message.includeObjects);
    }
    if (message.excludeObjects !== undefined) {
      obj.excludeObjects = OracleRdbms.toJSON(message.excludeObjects);
    }
    if (message.maxConcurrentCdcTasks !== 0) {
      obj.maxConcurrentCdcTasks = Math.round(message.maxConcurrentCdcTasks);
    }
    if (message.maxConcurrentBackfillTasks !== 0) {
      obj.maxConcurrentBackfillTasks = Math.round(message.maxConcurrentBackfillTasks);
    }
    if (message.dropLargeObjects !== undefined) {
      obj.dropLargeObjects = OracleSourceConfig_DropLargeObjects.toJSON(message.dropLargeObjects);
    }
    if (message.streamLargeObjects !== undefined) {
      obj.streamLargeObjects = OracleSourceConfig_StreamLargeObjects.toJSON(message.streamLargeObjects);
    }
    return obj;
  },

  create(base?: DeepPartial<OracleSourceConfig>): OracleSourceConfig {
    return OracleSourceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OracleSourceConfig>): OracleSourceConfig {
    const message = createBaseOracleSourceConfig();
    message.includeObjects = (object.includeObjects !== undefined && object.includeObjects !== null)
      ? OracleRdbms.fromPartial(object.includeObjects)
      : undefined;
    message.excludeObjects = (object.excludeObjects !== undefined && object.excludeObjects !== null)
      ? OracleRdbms.fromPartial(object.excludeObjects)
      : undefined;
    message.maxConcurrentCdcTasks = object.maxConcurrentCdcTasks ?? 0;
    message.maxConcurrentBackfillTasks = object.maxConcurrentBackfillTasks ?? 0;
    message.dropLargeObjects = (object.dropLargeObjects !== undefined && object.dropLargeObjects !== null)
      ? OracleSourceConfig_DropLargeObjects.fromPartial(object.dropLargeObjects)
      : undefined;
    message.streamLargeObjects = (object.streamLargeObjects !== undefined && object.streamLargeObjects !== null)
      ? OracleSourceConfig_StreamLargeObjects.fromPartial(object.streamLargeObjects)
      : undefined;
    return message;
  },
};

function createBaseOracleSourceConfig_DropLargeObjects(): OracleSourceConfig_DropLargeObjects {
  return {};
}

export const OracleSourceConfig_DropLargeObjects: MessageFns<OracleSourceConfig_DropLargeObjects> = {
  encode(_: OracleSourceConfig_DropLargeObjects, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleSourceConfig_DropLargeObjects {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleSourceConfig_DropLargeObjects();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): OracleSourceConfig_DropLargeObjects {
    return {};
  },

  toJSON(_: OracleSourceConfig_DropLargeObjects): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<OracleSourceConfig_DropLargeObjects>): OracleSourceConfig_DropLargeObjects {
    return OracleSourceConfig_DropLargeObjects.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<OracleSourceConfig_DropLargeObjects>): OracleSourceConfig_DropLargeObjects {
    const message = createBaseOracleSourceConfig_DropLargeObjects();
    return message;
  },
};

function createBaseOracleSourceConfig_StreamLargeObjects(): OracleSourceConfig_StreamLargeObjects {
  return {};
}

export const OracleSourceConfig_StreamLargeObjects: MessageFns<OracleSourceConfig_StreamLargeObjects> = {
  encode(_: OracleSourceConfig_StreamLargeObjects, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OracleSourceConfig_StreamLargeObjects {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOracleSourceConfig_StreamLargeObjects();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): OracleSourceConfig_StreamLargeObjects {
    return {};
  },

  toJSON(_: OracleSourceConfig_StreamLargeObjects): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<OracleSourceConfig_StreamLargeObjects>): OracleSourceConfig_StreamLargeObjects {
    return OracleSourceConfig_StreamLargeObjects.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<OracleSourceConfig_StreamLargeObjects>): OracleSourceConfig_StreamLargeObjects {
    const message = createBaseOracleSourceConfig_StreamLargeObjects();
    return message;
  },
};

function createBasePostgresqlColumn(): PostgresqlColumn {
  return {
    column: "",
    dataType: "",
    length: 0,
    precision: 0,
    scale: 0,
    primaryKey: false,
    nullable: false,
    ordinalPosition: 0,
  };
}

export const PostgresqlColumn: MessageFns<PostgresqlColumn> = {
  encode(message: PostgresqlColumn, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.column !== "") {
      writer.uint32(10).string(message.column);
    }
    if (message.dataType !== "") {
      writer.uint32(18).string(message.dataType);
    }
    if (message.length !== 0) {
      writer.uint32(24).int32(message.length);
    }
    if (message.precision !== 0) {
      writer.uint32(32).int32(message.precision);
    }
    if (message.scale !== 0) {
      writer.uint32(40).int32(message.scale);
    }
    if (message.primaryKey !== false) {
      writer.uint32(56).bool(message.primaryKey);
    }
    if (message.nullable !== false) {
      writer.uint32(64).bool(message.nullable);
    }
    if (message.ordinalPosition !== 0) {
      writer.uint32(72).int32(message.ordinalPosition);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgresqlColumn {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgresqlColumn();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.column = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataType = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.length = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.precision = reader.int32();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.scale = reader.int32();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.primaryKey = reader.bool();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.nullable = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.ordinalPosition = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgresqlColumn {
    return {
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      dataType: isSet(object.dataType) ? globalThis.String(object.dataType) : "",
      length: isSet(object.length) ? globalThis.Number(object.length) : 0,
      precision: isSet(object.precision) ? globalThis.Number(object.precision) : 0,
      scale: isSet(object.scale) ? globalThis.Number(object.scale) : 0,
      primaryKey: isSet(object.primaryKey) ? globalThis.Boolean(object.primaryKey) : false,
      nullable: isSet(object.nullable) ? globalThis.Boolean(object.nullable) : false,
      ordinalPosition: isSet(object.ordinalPosition) ? globalThis.Number(object.ordinalPosition) : 0,
    };
  },

  toJSON(message: PostgresqlColumn): unknown {
    const obj: any = {};
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.dataType !== "") {
      obj.dataType = message.dataType;
    }
    if (message.length !== 0) {
      obj.length = Math.round(message.length);
    }
    if (message.precision !== 0) {
      obj.precision = Math.round(message.precision);
    }
    if (message.scale !== 0) {
      obj.scale = Math.round(message.scale);
    }
    if (message.primaryKey !== false) {
      obj.primaryKey = message.primaryKey;
    }
    if (message.nullable !== false) {
      obj.nullable = message.nullable;
    }
    if (message.ordinalPosition !== 0) {
      obj.ordinalPosition = Math.round(message.ordinalPosition);
    }
    return obj;
  },

  create(base?: DeepPartial<PostgresqlColumn>): PostgresqlColumn {
    return PostgresqlColumn.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgresqlColumn>): PostgresqlColumn {
    const message = createBasePostgresqlColumn();
    message.column = object.column ?? "";
    message.dataType = object.dataType ?? "";
    message.length = object.length ?? 0;
    message.precision = object.precision ?? 0;
    message.scale = object.scale ?? 0;
    message.primaryKey = object.primaryKey ?? false;
    message.nullable = object.nullable ?? false;
    message.ordinalPosition = object.ordinalPosition ?? 0;
    return message;
  },
};

function createBasePostgresqlTable(): PostgresqlTable {
  return { table: "", postgresqlColumns: [] };
}

export const PostgresqlTable: MessageFns<PostgresqlTable> = {
  encode(message: PostgresqlTable, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== "") {
      writer.uint32(10).string(message.table);
    }
    for (const v of message.postgresqlColumns) {
      PostgresqlColumn.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgresqlTable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgresqlTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.postgresqlColumns.push(PostgresqlColumn.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgresqlTable {
    return {
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      postgresqlColumns: globalThis.Array.isArray(object?.postgresqlColumns)
        ? object.postgresqlColumns.map((e: any) => PostgresqlColumn.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PostgresqlTable): unknown {
    const obj: any = {};
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.postgresqlColumns?.length) {
      obj.postgresqlColumns = message.postgresqlColumns.map((e) => PostgresqlColumn.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PostgresqlTable>): PostgresqlTable {
    return PostgresqlTable.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgresqlTable>): PostgresqlTable {
    const message = createBasePostgresqlTable();
    message.table = object.table ?? "";
    message.postgresqlColumns = object.postgresqlColumns?.map((e) => PostgresqlColumn.fromPartial(e)) || [];
    return message;
  },
};

function createBasePostgresqlSchema(): PostgresqlSchema {
  return { schema: "", postgresqlTables: [] };
}

export const PostgresqlSchema: MessageFns<PostgresqlSchema> = {
  encode(message: PostgresqlSchema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schema !== "") {
      writer.uint32(10).string(message.schema);
    }
    for (const v of message.postgresqlTables) {
      PostgresqlTable.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgresqlSchema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgresqlSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schema = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.postgresqlTables.push(PostgresqlTable.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgresqlSchema {
    return {
      schema: isSet(object.schema) ? globalThis.String(object.schema) : "",
      postgresqlTables: globalThis.Array.isArray(object?.postgresqlTables)
        ? object.postgresqlTables.map((e: any) => PostgresqlTable.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PostgresqlSchema): unknown {
    const obj: any = {};
    if (message.schema !== "") {
      obj.schema = message.schema;
    }
    if (message.postgresqlTables?.length) {
      obj.postgresqlTables = message.postgresqlTables.map((e) => PostgresqlTable.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PostgresqlSchema>): PostgresqlSchema {
    return PostgresqlSchema.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgresqlSchema>): PostgresqlSchema {
    const message = createBasePostgresqlSchema();
    message.schema = object.schema ?? "";
    message.postgresqlTables = object.postgresqlTables?.map((e) => PostgresqlTable.fromPartial(e)) || [];
    return message;
  },
};

function createBasePostgresqlRdbms(): PostgresqlRdbms {
  return { postgresqlSchemas: [] };
}

export const PostgresqlRdbms: MessageFns<PostgresqlRdbms> = {
  encode(message: PostgresqlRdbms, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.postgresqlSchemas) {
      PostgresqlSchema.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgresqlRdbms {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgresqlRdbms();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.postgresqlSchemas.push(PostgresqlSchema.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgresqlRdbms {
    return {
      postgresqlSchemas: globalThis.Array.isArray(object?.postgresqlSchemas)
        ? object.postgresqlSchemas.map((e: any) => PostgresqlSchema.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PostgresqlRdbms): unknown {
    const obj: any = {};
    if (message.postgresqlSchemas?.length) {
      obj.postgresqlSchemas = message.postgresqlSchemas.map((e) => PostgresqlSchema.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<PostgresqlRdbms>): PostgresqlRdbms {
    return PostgresqlRdbms.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgresqlRdbms>): PostgresqlRdbms {
    const message = createBasePostgresqlRdbms();
    message.postgresqlSchemas = object.postgresqlSchemas?.map((e) => PostgresqlSchema.fromPartial(e)) || [];
    return message;
  },
};

function createBasePostgresqlSourceConfig(): PostgresqlSourceConfig {
  return {
    includeObjects: undefined,
    excludeObjects: undefined,
    replicationSlot: "",
    publication: "",
    maxConcurrentBackfillTasks: 0,
  };
}

export const PostgresqlSourceConfig: MessageFns<PostgresqlSourceConfig> = {
  encode(message: PostgresqlSourceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeObjects !== undefined) {
      PostgresqlRdbms.encode(message.includeObjects, writer.uint32(10).fork()).join();
    }
    if (message.excludeObjects !== undefined) {
      PostgresqlRdbms.encode(message.excludeObjects, writer.uint32(18).fork()).join();
    }
    if (message.replicationSlot !== "") {
      writer.uint32(26).string(message.replicationSlot);
    }
    if (message.publication !== "") {
      writer.uint32(34).string(message.publication);
    }
    if (message.maxConcurrentBackfillTasks !== 0) {
      writer.uint32(40).int32(message.maxConcurrentBackfillTasks);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgresqlSourceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgresqlSourceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeObjects = PostgresqlRdbms.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.excludeObjects = PostgresqlRdbms.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.replicationSlot = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.publication = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.maxConcurrentBackfillTasks = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgresqlSourceConfig {
    return {
      includeObjects: isSet(object.includeObjects) ? PostgresqlRdbms.fromJSON(object.includeObjects) : undefined,
      excludeObjects: isSet(object.excludeObjects) ? PostgresqlRdbms.fromJSON(object.excludeObjects) : undefined,
      replicationSlot: isSet(object.replicationSlot) ? globalThis.String(object.replicationSlot) : "",
      publication: isSet(object.publication) ? globalThis.String(object.publication) : "",
      maxConcurrentBackfillTasks: isSet(object.maxConcurrentBackfillTasks)
        ? globalThis.Number(object.maxConcurrentBackfillTasks)
        : 0,
    };
  },

  toJSON(message: PostgresqlSourceConfig): unknown {
    const obj: any = {};
    if (message.includeObjects !== undefined) {
      obj.includeObjects = PostgresqlRdbms.toJSON(message.includeObjects);
    }
    if (message.excludeObjects !== undefined) {
      obj.excludeObjects = PostgresqlRdbms.toJSON(message.excludeObjects);
    }
    if (message.replicationSlot !== "") {
      obj.replicationSlot = message.replicationSlot;
    }
    if (message.publication !== "") {
      obj.publication = message.publication;
    }
    if (message.maxConcurrentBackfillTasks !== 0) {
      obj.maxConcurrentBackfillTasks = Math.round(message.maxConcurrentBackfillTasks);
    }
    return obj;
  },

  create(base?: DeepPartial<PostgresqlSourceConfig>): PostgresqlSourceConfig {
    return PostgresqlSourceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PostgresqlSourceConfig>): PostgresqlSourceConfig {
    const message = createBasePostgresqlSourceConfig();
    message.includeObjects = (object.includeObjects !== undefined && object.includeObjects !== null)
      ? PostgresqlRdbms.fromPartial(object.includeObjects)
      : undefined;
    message.excludeObjects = (object.excludeObjects !== undefined && object.excludeObjects !== null)
      ? PostgresqlRdbms.fromPartial(object.excludeObjects)
      : undefined;
    message.replicationSlot = object.replicationSlot ?? "";
    message.publication = object.publication ?? "";
    message.maxConcurrentBackfillTasks = object.maxConcurrentBackfillTasks ?? 0;
    return message;
  },
};

function createBaseMysqlColumn(): MysqlColumn {
  return {
    column: "",
    dataType: "",
    length: 0,
    collation: "",
    primaryKey: false,
    nullable: false,
    ordinalPosition: 0,
    precision: 0,
    scale: 0,
  };
}

export const MysqlColumn: MessageFns<MysqlColumn> = {
  encode(message: MysqlColumn, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.column !== "") {
      writer.uint32(10).string(message.column);
    }
    if (message.dataType !== "") {
      writer.uint32(18).string(message.dataType);
    }
    if (message.length !== 0) {
      writer.uint32(24).int32(message.length);
    }
    if (message.collation !== "") {
      writer.uint32(34).string(message.collation);
    }
    if (message.primaryKey !== false) {
      writer.uint32(40).bool(message.primaryKey);
    }
    if (message.nullable !== false) {
      writer.uint32(48).bool(message.nullable);
    }
    if (message.ordinalPosition !== 0) {
      writer.uint32(56).int32(message.ordinalPosition);
    }
    if (message.precision !== 0) {
      writer.uint32(64).int32(message.precision);
    }
    if (message.scale !== 0) {
      writer.uint32(72).int32(message.scale);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlColumn {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlColumn();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.column = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataType = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.length = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.collation = reader.string();
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.primaryKey = reader.bool();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.nullable = reader.bool();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.ordinalPosition = reader.int32();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.precision = reader.int32();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.scale = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlColumn {
    return {
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      dataType: isSet(object.dataType) ? globalThis.String(object.dataType) : "",
      length: isSet(object.length) ? globalThis.Number(object.length) : 0,
      collation: isSet(object.collation) ? globalThis.String(object.collation) : "",
      primaryKey: isSet(object.primaryKey) ? globalThis.Boolean(object.primaryKey) : false,
      nullable: isSet(object.nullable) ? globalThis.Boolean(object.nullable) : false,
      ordinalPosition: isSet(object.ordinalPosition) ? globalThis.Number(object.ordinalPosition) : 0,
      precision: isSet(object.precision) ? globalThis.Number(object.precision) : 0,
      scale: isSet(object.scale) ? globalThis.Number(object.scale) : 0,
    };
  },

  toJSON(message: MysqlColumn): unknown {
    const obj: any = {};
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.dataType !== "") {
      obj.dataType = message.dataType;
    }
    if (message.length !== 0) {
      obj.length = Math.round(message.length);
    }
    if (message.collation !== "") {
      obj.collation = message.collation;
    }
    if (message.primaryKey !== false) {
      obj.primaryKey = message.primaryKey;
    }
    if (message.nullable !== false) {
      obj.nullable = message.nullable;
    }
    if (message.ordinalPosition !== 0) {
      obj.ordinalPosition = Math.round(message.ordinalPosition);
    }
    if (message.precision !== 0) {
      obj.precision = Math.round(message.precision);
    }
    if (message.scale !== 0) {
      obj.scale = Math.round(message.scale);
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlColumn>): MysqlColumn {
    return MysqlColumn.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlColumn>): MysqlColumn {
    const message = createBaseMysqlColumn();
    message.column = object.column ?? "";
    message.dataType = object.dataType ?? "";
    message.length = object.length ?? 0;
    message.collation = object.collation ?? "";
    message.primaryKey = object.primaryKey ?? false;
    message.nullable = object.nullable ?? false;
    message.ordinalPosition = object.ordinalPosition ?? 0;
    message.precision = object.precision ?? 0;
    message.scale = object.scale ?? 0;
    return message;
  },
};

function createBaseMysqlTable(): MysqlTable {
  return { table: "", mysqlColumns: [] };
}

export const MysqlTable: MessageFns<MysqlTable> = {
  encode(message: MysqlTable, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.table !== "") {
      writer.uint32(10).string(message.table);
    }
    for (const v of message.mysqlColumns) {
      MysqlColumn.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlTable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.table = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mysqlColumns.push(MysqlColumn.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlTable {
    return {
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      mysqlColumns: globalThis.Array.isArray(object?.mysqlColumns)
        ? object.mysqlColumns.map((e: any) => MysqlColumn.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MysqlTable): unknown {
    const obj: any = {};
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.mysqlColumns?.length) {
      obj.mysqlColumns = message.mysqlColumns.map((e) => MysqlColumn.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlTable>): MysqlTable {
    return MysqlTable.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlTable>): MysqlTable {
    const message = createBaseMysqlTable();
    message.table = object.table ?? "";
    message.mysqlColumns = object.mysqlColumns?.map((e) => MysqlColumn.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMysqlDatabase(): MysqlDatabase {
  return { database: "", mysqlTables: [] };
}

export const MysqlDatabase: MessageFns<MysqlDatabase> = {
  encode(message: MysqlDatabase, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    for (const v of message.mysqlTables) {
      MysqlTable.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlDatabase {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlDatabase();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mysqlTables.push(MysqlTable.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlDatabase {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      mysqlTables: globalThis.Array.isArray(object?.mysqlTables)
        ? object.mysqlTables.map((e: any) => MysqlTable.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MysqlDatabase): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.mysqlTables?.length) {
      obj.mysqlTables = message.mysqlTables.map((e) => MysqlTable.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlDatabase>): MysqlDatabase {
    return MysqlDatabase.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlDatabase>): MysqlDatabase {
    const message = createBaseMysqlDatabase();
    message.database = object.database ?? "";
    message.mysqlTables = object.mysqlTables?.map((e) => MysqlTable.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMysqlRdbms(): MysqlRdbms {
  return { mysqlDatabases: [] };
}

export const MysqlRdbms: MessageFns<MysqlRdbms> = {
  encode(message: MysqlRdbms, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.mysqlDatabases) {
      MysqlDatabase.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlRdbms {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlRdbms();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.mysqlDatabases.push(MysqlDatabase.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlRdbms {
    return {
      mysqlDatabases: globalThis.Array.isArray(object?.mysqlDatabases)
        ? object.mysqlDatabases.map((e: any) => MysqlDatabase.fromJSON(e))
        : [],
    };
  },

  toJSON(message: MysqlRdbms): unknown {
    const obj: any = {};
    if (message.mysqlDatabases?.length) {
      obj.mysqlDatabases = message.mysqlDatabases.map((e) => MysqlDatabase.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlRdbms>): MysqlRdbms {
    return MysqlRdbms.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlRdbms>): MysqlRdbms {
    const message = createBaseMysqlRdbms();
    message.mysqlDatabases = object.mysqlDatabases?.map((e) => MysqlDatabase.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMysqlSourceConfig(): MysqlSourceConfig {
  return {
    includeObjects: undefined,
    excludeObjects: undefined,
    maxConcurrentCdcTasks: 0,
    maxConcurrentBackfillTasks: 0,
  };
}

export const MysqlSourceConfig: MessageFns<MysqlSourceConfig> = {
  encode(message: MysqlSourceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeObjects !== undefined) {
      MysqlRdbms.encode(message.includeObjects, writer.uint32(10).fork()).join();
    }
    if (message.excludeObjects !== undefined) {
      MysqlRdbms.encode(message.excludeObjects, writer.uint32(18).fork()).join();
    }
    if (message.maxConcurrentCdcTasks !== 0) {
      writer.uint32(24).int32(message.maxConcurrentCdcTasks);
    }
    if (message.maxConcurrentBackfillTasks !== 0) {
      writer.uint32(32).int32(message.maxConcurrentBackfillTasks);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MysqlSourceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMysqlSourceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.includeObjects = MysqlRdbms.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.excludeObjects = MysqlRdbms.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.maxConcurrentCdcTasks = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.maxConcurrentBackfillTasks = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MysqlSourceConfig {
    return {
      includeObjects: isSet(object.includeObjects) ? MysqlRdbms.fromJSON(object.includeObjects) : undefined,
      excludeObjects: isSet(object.excludeObjects) ? MysqlRdbms.fromJSON(object.excludeObjects) : undefined,
      maxConcurrentCdcTasks: isSet(object.maxConcurrentCdcTasks) ? globalThis.Number(object.maxConcurrentCdcTasks) : 0,
      maxConcurrentBackfillTasks: isSet(object.maxConcurrentBackfillTasks)
        ? globalThis.Number(object.maxConcurrentBackfillTasks)
        : 0,
    };
  },

  toJSON(message: MysqlSourceConfig): unknown {
    const obj: any = {};
    if (message.includeObjects !== undefined) {
      obj.includeObjects = MysqlRdbms.toJSON(message.includeObjects);
    }
    if (message.excludeObjects !== undefined) {
      obj.excludeObjects = MysqlRdbms.toJSON(message.excludeObjects);
    }
    if (message.maxConcurrentCdcTasks !== 0) {
      obj.maxConcurrentCdcTasks = Math.round(message.maxConcurrentCdcTasks);
    }
    if (message.maxConcurrentBackfillTasks !== 0) {
      obj.maxConcurrentBackfillTasks = Math.round(message.maxConcurrentBackfillTasks);
    }
    return obj;
  },

  create(base?: DeepPartial<MysqlSourceConfig>): MysqlSourceConfig {
    return MysqlSourceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<MysqlSourceConfig>): MysqlSourceConfig {
    const message = createBaseMysqlSourceConfig();
    message.includeObjects = (object.includeObjects !== undefined && object.includeObjects !== null)
      ? MysqlRdbms.fromPartial(object.includeObjects)
      : undefined;
    message.excludeObjects = (object.excludeObjects !== undefined && object.excludeObjects !== null)
      ? MysqlRdbms.fromPartial(object.excludeObjects)
      : undefined;
    message.maxConcurrentCdcTasks = object.maxConcurrentCdcTasks ?? 0;
    message.maxConcurrentBackfillTasks = object.maxConcurrentBackfillTasks ?? 0;
    return message;
  },
};

function createBaseSourceConfig(): SourceConfig {
  return {
    sourceConnectionProfile: "",
    oracleSourceConfig: undefined,
    mysqlSourceConfig: undefined,
    postgresqlSourceConfig: undefined,
  };
}

export const SourceConfig: MessageFns<SourceConfig> = {
  encode(message: SourceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sourceConnectionProfile !== "") {
      writer.uint32(10).string(message.sourceConnectionProfile);
    }
    if (message.oracleSourceConfig !== undefined) {
      OracleSourceConfig.encode(message.oracleSourceConfig, writer.uint32(802).fork()).join();
    }
    if (message.mysqlSourceConfig !== undefined) {
      MysqlSourceConfig.encode(message.mysqlSourceConfig, writer.uint32(810).fork()).join();
    }
    if (message.postgresqlSourceConfig !== undefined) {
      PostgresqlSourceConfig.encode(message.postgresqlSourceConfig, writer.uint32(818).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sourceConnectionProfile = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.oracleSourceConfig = OracleSourceConfig.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.mysqlSourceConfig = MysqlSourceConfig.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.postgresqlSourceConfig = PostgresqlSourceConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceConfig {
    return {
      sourceConnectionProfile: isSet(object.sourceConnectionProfile)
        ? globalThis.String(object.sourceConnectionProfile)
        : "",
      oracleSourceConfig: isSet(object.oracleSourceConfig)
        ? OracleSourceConfig.fromJSON(object.oracleSourceConfig)
        : undefined,
      mysqlSourceConfig: isSet(object.mysqlSourceConfig)
        ? MysqlSourceConfig.fromJSON(object.mysqlSourceConfig)
        : undefined,
      postgresqlSourceConfig: isSet(object.postgresqlSourceConfig)
        ? PostgresqlSourceConfig.fromJSON(object.postgresqlSourceConfig)
        : undefined,
    };
  },

  toJSON(message: SourceConfig): unknown {
    const obj: any = {};
    if (message.sourceConnectionProfile !== "") {
      obj.sourceConnectionProfile = message.sourceConnectionProfile;
    }
    if (message.oracleSourceConfig !== undefined) {
      obj.oracleSourceConfig = OracleSourceConfig.toJSON(message.oracleSourceConfig);
    }
    if (message.mysqlSourceConfig !== undefined) {
      obj.mysqlSourceConfig = MysqlSourceConfig.toJSON(message.mysqlSourceConfig);
    }
    if (message.postgresqlSourceConfig !== undefined) {
      obj.postgresqlSourceConfig = PostgresqlSourceConfig.toJSON(message.postgresqlSourceConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<SourceConfig>): SourceConfig {
    return SourceConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceConfig>): SourceConfig {
    const message = createBaseSourceConfig();
    message.sourceConnectionProfile = object.sourceConnectionProfile ?? "";
    message.oracleSourceConfig = (object.oracleSourceConfig !== undefined && object.oracleSourceConfig !== null)
      ? OracleSourceConfig.fromPartial(object.oracleSourceConfig)
      : undefined;
    message.mysqlSourceConfig = (object.mysqlSourceConfig !== undefined && object.mysqlSourceConfig !== null)
      ? MysqlSourceConfig.fromPartial(object.mysqlSourceConfig)
      : undefined;
    message.postgresqlSourceConfig =
      (object.postgresqlSourceConfig !== undefined && object.postgresqlSourceConfig !== null)
        ? PostgresqlSourceConfig.fromPartial(object.postgresqlSourceConfig)
        : undefined;
    return message;
  },
};

function createBaseAvroFileFormat(): AvroFileFormat {
  return {};
}

export const AvroFileFormat: MessageFns<AvroFileFormat> = {
  encode(_: AvroFileFormat, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AvroFileFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAvroFileFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AvroFileFormat {
    return {};
  },

  toJSON(_: AvroFileFormat): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<AvroFileFormat>): AvroFileFormat {
    return AvroFileFormat.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<AvroFileFormat>): AvroFileFormat {
    const message = createBaseAvroFileFormat();
    return message;
  },
};

function createBaseJsonFileFormat(): JsonFileFormat {
  return { schemaFileFormat: 0, compression: 0 };
}

export const JsonFileFormat: MessageFns<JsonFileFormat> = {
  encode(message: JsonFileFormat, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schemaFileFormat !== 0) {
      writer.uint32(8).int32(message.schemaFileFormat);
    }
    if (message.compression !== 0) {
      writer.uint32(16).int32(message.compression);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JsonFileFormat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJsonFileFormat();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.schemaFileFormat = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.compression = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JsonFileFormat {
    return {
      schemaFileFormat: isSet(object.schemaFileFormat)
        ? jsonFileFormat_SchemaFileFormatFromJSON(object.schemaFileFormat)
        : 0,
      compression: isSet(object.compression) ? jsonFileFormat_JsonCompressionFromJSON(object.compression) : 0,
    };
  },

  toJSON(message: JsonFileFormat): unknown {
    const obj: any = {};
    if (message.schemaFileFormat !== 0) {
      obj.schemaFileFormat = jsonFileFormat_SchemaFileFormatToJSON(message.schemaFileFormat);
    }
    if (message.compression !== 0) {
      obj.compression = jsonFileFormat_JsonCompressionToJSON(message.compression);
    }
    return obj;
  },

  create(base?: DeepPartial<JsonFileFormat>): JsonFileFormat {
    return JsonFileFormat.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JsonFileFormat>): JsonFileFormat {
    const message = createBaseJsonFileFormat();
    message.schemaFileFormat = object.schemaFileFormat ?? 0;
    message.compression = object.compression ?? 0;
    return message;
  },
};

function createBaseGcsDestinationConfig(): GcsDestinationConfig {
  return {
    path: "",
    fileRotationMb: 0,
    fileRotationInterval: undefined,
    avroFileFormat: undefined,
    jsonFileFormat: undefined,
  };
}

export const GcsDestinationConfig: MessageFns<GcsDestinationConfig> = {
  encode(message: GcsDestinationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    if (message.fileRotationMb !== 0) {
      writer.uint32(16).int32(message.fileRotationMb);
    }
    if (message.fileRotationInterval !== undefined) {
      Duration.encode(message.fileRotationInterval, writer.uint32(26).fork()).join();
    }
    if (message.avroFileFormat !== undefined) {
      AvroFileFormat.encode(message.avroFileFormat, writer.uint32(802).fork()).join();
    }
    if (message.jsonFileFormat !== undefined) {
      JsonFileFormat.encode(message.jsonFileFormat, writer.uint32(810).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GcsDestinationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGcsDestinationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.fileRotationMb = reader.int32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.fileRotationInterval = Duration.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.avroFileFormat = AvroFileFormat.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.jsonFileFormat = JsonFileFormat.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GcsDestinationConfig {
    return {
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      fileRotationMb: isSet(object.fileRotationMb) ? globalThis.Number(object.fileRotationMb) : 0,
      fileRotationInterval: isSet(object.fileRotationInterval)
        ? Duration.fromJSON(object.fileRotationInterval)
        : undefined,
      avroFileFormat: isSet(object.avroFileFormat) ? AvroFileFormat.fromJSON(object.avroFileFormat) : undefined,
      jsonFileFormat: isSet(object.jsonFileFormat) ? JsonFileFormat.fromJSON(object.jsonFileFormat) : undefined,
    };
  },

  toJSON(message: GcsDestinationConfig): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.fileRotationMb !== 0) {
      obj.fileRotationMb = Math.round(message.fileRotationMb);
    }
    if (message.fileRotationInterval !== undefined) {
      obj.fileRotationInterval = Duration.toJSON(message.fileRotationInterval);
    }
    if (message.avroFileFormat !== undefined) {
      obj.avroFileFormat = AvroFileFormat.toJSON(message.avroFileFormat);
    }
    if (message.jsonFileFormat !== undefined) {
      obj.jsonFileFormat = JsonFileFormat.toJSON(message.jsonFileFormat);
    }
    return obj;
  },

  create(base?: DeepPartial<GcsDestinationConfig>): GcsDestinationConfig {
    return GcsDestinationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GcsDestinationConfig>): GcsDestinationConfig {
    const message = createBaseGcsDestinationConfig();
    message.path = object.path ?? "";
    message.fileRotationMb = object.fileRotationMb ?? 0;
    message.fileRotationInterval = (object.fileRotationInterval !== undefined && object.fileRotationInterval !== null)
      ? Duration.fromPartial(object.fileRotationInterval)
      : undefined;
    message.avroFileFormat = (object.avroFileFormat !== undefined && object.avroFileFormat !== null)
      ? AvroFileFormat.fromPartial(object.avroFileFormat)
      : undefined;
    message.jsonFileFormat = (object.jsonFileFormat !== undefined && object.jsonFileFormat !== null)
      ? JsonFileFormat.fromPartial(object.jsonFileFormat)
      : undefined;
    return message;
  },
};

function createBaseBigQueryDestinationConfig(): BigQueryDestinationConfig {
  return { singleTargetDataset: undefined, sourceHierarchyDatasets: undefined, dataFreshness: undefined };
}

export const BigQueryDestinationConfig: MessageFns<BigQueryDestinationConfig> = {
  encode(message: BigQueryDestinationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.singleTargetDataset !== undefined) {
      BigQueryDestinationConfig_SingleTargetDataset.encode(message.singleTargetDataset, writer.uint32(1610).fork())
        .join();
    }
    if (message.sourceHierarchyDatasets !== undefined) {
      BigQueryDestinationConfig_SourceHierarchyDatasets.encode(
        message.sourceHierarchyDatasets,
        writer.uint32(1618).fork(),
      ).join();
    }
    if (message.dataFreshness !== undefined) {
      Duration.encode(message.dataFreshness, writer.uint32(2402).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDestinationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDestinationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 201:
          if (tag !== 1610) {
            break;
          }

          message.singleTargetDataset = BigQueryDestinationConfig_SingleTargetDataset.decode(reader, reader.uint32());
          continue;
        case 202:
          if (tag !== 1618) {
            break;
          }

          message.sourceHierarchyDatasets = BigQueryDestinationConfig_SourceHierarchyDatasets.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 300:
          if (tag !== 2402) {
            break;
          }

          message.dataFreshness = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDestinationConfig {
    return {
      singleTargetDataset: isSet(object.singleTargetDataset)
        ? BigQueryDestinationConfig_SingleTargetDataset.fromJSON(object.singleTargetDataset)
        : undefined,
      sourceHierarchyDatasets: isSet(object.sourceHierarchyDatasets)
        ? BigQueryDestinationConfig_SourceHierarchyDatasets.fromJSON(object.sourceHierarchyDatasets)
        : undefined,
      dataFreshness: isSet(object.dataFreshness) ? Duration.fromJSON(object.dataFreshness) : undefined,
    };
  },

  toJSON(message: BigQueryDestinationConfig): unknown {
    const obj: any = {};
    if (message.singleTargetDataset !== undefined) {
      obj.singleTargetDataset = BigQueryDestinationConfig_SingleTargetDataset.toJSON(message.singleTargetDataset);
    }
    if (message.sourceHierarchyDatasets !== undefined) {
      obj.sourceHierarchyDatasets = BigQueryDestinationConfig_SourceHierarchyDatasets.toJSON(
        message.sourceHierarchyDatasets,
      );
    }
    if (message.dataFreshness !== undefined) {
      obj.dataFreshness = Duration.toJSON(message.dataFreshness);
    }
    return obj;
  },

  create(base?: DeepPartial<BigQueryDestinationConfig>): BigQueryDestinationConfig {
    return BigQueryDestinationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BigQueryDestinationConfig>): BigQueryDestinationConfig {
    const message = createBaseBigQueryDestinationConfig();
    message.singleTargetDataset = (object.singleTargetDataset !== undefined && object.singleTargetDataset !== null)
      ? BigQueryDestinationConfig_SingleTargetDataset.fromPartial(object.singleTargetDataset)
      : undefined;
    message.sourceHierarchyDatasets =
      (object.sourceHierarchyDatasets !== undefined && object.sourceHierarchyDatasets !== null)
        ? BigQueryDestinationConfig_SourceHierarchyDatasets.fromPartial(object.sourceHierarchyDatasets)
        : undefined;
    message.dataFreshness = (object.dataFreshness !== undefined && object.dataFreshness !== null)
      ? Duration.fromPartial(object.dataFreshness)
      : undefined;
    return message;
  },
};

function createBaseBigQueryDestinationConfig_SingleTargetDataset(): BigQueryDestinationConfig_SingleTargetDataset {
  return { datasetId: "" };
}

export const BigQueryDestinationConfig_SingleTargetDataset: MessageFns<BigQueryDestinationConfig_SingleTargetDataset> =
  {
    encode(
      message: BigQueryDestinationConfig_SingleTargetDataset,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.datasetId !== "") {
        writer.uint32(10).string(message.datasetId);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDestinationConfig_SingleTargetDataset {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseBigQueryDestinationConfig_SingleTargetDataset();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.datasetId = reader.string();
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): BigQueryDestinationConfig_SingleTargetDataset {
      return { datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "" };
    },

    toJSON(message: BigQueryDestinationConfig_SingleTargetDataset): unknown {
      const obj: any = {};
      if (message.datasetId !== "") {
        obj.datasetId = message.datasetId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<BigQueryDestinationConfig_SingleTargetDataset>,
    ): BigQueryDestinationConfig_SingleTargetDataset {
      return BigQueryDestinationConfig_SingleTargetDataset.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<BigQueryDestinationConfig_SingleTargetDataset>,
    ): BigQueryDestinationConfig_SingleTargetDataset {
      const message = createBaseBigQueryDestinationConfig_SingleTargetDataset();
      message.datasetId = object.datasetId ?? "";
      return message;
    },
  };

function createBaseBigQueryDestinationConfig_SourceHierarchyDatasets(): BigQueryDestinationConfig_SourceHierarchyDatasets {
  return { datasetTemplate: undefined };
}

export const BigQueryDestinationConfig_SourceHierarchyDatasets: MessageFns<
  BigQueryDestinationConfig_SourceHierarchyDatasets
> = {
  encode(
    message: BigQueryDestinationConfig_SourceHierarchyDatasets,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetTemplate !== undefined) {
      BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate.encode(
        message.datasetTemplate,
        writer.uint32(18).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BigQueryDestinationConfig_SourceHierarchyDatasets {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDestinationConfig_SourceHierarchyDatasets();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetTemplate = BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDestinationConfig_SourceHierarchyDatasets {
    return {
      datasetTemplate: isSet(object.datasetTemplate)
        ? BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate.fromJSON(object.datasetTemplate)
        : undefined,
    };
  },

  toJSON(message: BigQueryDestinationConfig_SourceHierarchyDatasets): unknown {
    const obj: any = {};
    if (message.datasetTemplate !== undefined) {
      obj.datasetTemplate = BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate.toJSON(
        message.datasetTemplate,
      );
    }
    return obj;
  },

  create(
    base?: DeepPartial<BigQueryDestinationConfig_SourceHierarchyDatasets>,
  ): BigQueryDestinationConfig_SourceHierarchyDatasets {
    return BigQueryDestinationConfig_SourceHierarchyDatasets.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BigQueryDestinationConfig_SourceHierarchyDatasets>,
  ): BigQueryDestinationConfig_SourceHierarchyDatasets {
    const message = createBaseBigQueryDestinationConfig_SourceHierarchyDatasets();
    message.datasetTemplate = (object.datasetTemplate !== undefined && object.datasetTemplate !== null)
      ? BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate.fromPartial(object.datasetTemplate)
      : undefined;
    return message;
  },
};

function createBaseBigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate(): BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate {
  return { location: "", datasetIdPrefix: "", kmsKeyName: "" };
}

export const BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate: MessageFns<
  BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate
> = {
  encode(
    message: BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.location !== "") {
      writer.uint32(10).string(message.location);
    }
    if (message.datasetIdPrefix !== "") {
      writer.uint32(18).string(message.datasetIdPrefix);
    }
    if (message.kmsKeyName !== "") {
      writer.uint32(26).string(message.kmsKeyName);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.datasetIdPrefix = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.kmsKeyName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate {
    return {
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      datasetIdPrefix: isSet(object.datasetIdPrefix) ? globalThis.String(object.datasetIdPrefix) : "",
      kmsKeyName: isSet(object.kmsKeyName) ? globalThis.String(object.kmsKeyName) : "",
    };
  },

  toJSON(message: BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate): unknown {
    const obj: any = {};
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.datasetIdPrefix !== "") {
      obj.datasetIdPrefix = message.datasetIdPrefix;
    }
    if (message.kmsKeyName !== "") {
      obj.kmsKeyName = message.kmsKeyName;
    }
    return obj;
  },

  create(
    base?: DeepPartial<BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate>,
  ): BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate {
    return BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate>,
  ): BigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate {
    const message = createBaseBigQueryDestinationConfig_SourceHierarchyDatasets_DatasetTemplate();
    message.location = object.location ?? "";
    message.datasetIdPrefix = object.datasetIdPrefix ?? "";
    message.kmsKeyName = object.kmsKeyName ?? "";
    return message;
  },
};

function createBaseDestinationConfig(): DestinationConfig {
  return { destinationConnectionProfile: "", gcsDestinationConfig: undefined, bigqueryDestinationConfig: undefined };
}

export const DestinationConfig: MessageFns<DestinationConfig> = {
  encode(message: DestinationConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destinationConnectionProfile !== "") {
      writer.uint32(10).string(message.destinationConnectionProfile);
    }
    if (message.gcsDestinationConfig !== undefined) {
      GcsDestinationConfig.encode(message.gcsDestinationConfig, writer.uint32(802).fork()).join();
    }
    if (message.bigqueryDestinationConfig !== undefined) {
      BigQueryDestinationConfig.encode(message.bigqueryDestinationConfig, writer.uint32(810).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DestinationConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDestinationConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.destinationConnectionProfile = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.gcsDestinationConfig = GcsDestinationConfig.decode(reader, reader.uint32());
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.bigqueryDestinationConfig = BigQueryDestinationConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DestinationConfig {
    return {
      destinationConnectionProfile: isSet(object.destinationConnectionProfile)
        ? globalThis.String(object.destinationConnectionProfile)
        : "",
      gcsDestinationConfig: isSet(object.gcsDestinationConfig)
        ? GcsDestinationConfig.fromJSON(object.gcsDestinationConfig)
        : undefined,
      bigqueryDestinationConfig: isSet(object.bigqueryDestinationConfig)
        ? BigQueryDestinationConfig.fromJSON(object.bigqueryDestinationConfig)
        : undefined,
    };
  },

  toJSON(message: DestinationConfig): unknown {
    const obj: any = {};
    if (message.destinationConnectionProfile !== "") {
      obj.destinationConnectionProfile = message.destinationConnectionProfile;
    }
    if (message.gcsDestinationConfig !== undefined) {
      obj.gcsDestinationConfig = GcsDestinationConfig.toJSON(message.gcsDestinationConfig);
    }
    if (message.bigqueryDestinationConfig !== undefined) {
      obj.bigqueryDestinationConfig = BigQueryDestinationConfig.toJSON(message.bigqueryDestinationConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<DestinationConfig>): DestinationConfig {
    return DestinationConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DestinationConfig>): DestinationConfig {
    const message = createBaseDestinationConfig();
    message.destinationConnectionProfile = object.destinationConnectionProfile ?? "";
    message.gcsDestinationConfig = (object.gcsDestinationConfig !== undefined && object.gcsDestinationConfig !== null)
      ? GcsDestinationConfig.fromPartial(object.gcsDestinationConfig)
      : undefined;
    message.bigqueryDestinationConfig =
      (object.bigqueryDestinationConfig !== undefined && object.bigqueryDestinationConfig !== null)
        ? BigQueryDestinationConfig.fromPartial(object.bigqueryDestinationConfig)
        : undefined;
    return message;
  },
};

function createBaseStream(): Stream {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    displayName: "",
    sourceConfig: undefined,
    destinationConfig: undefined,
    state: 0,
    backfillAll: undefined,
    backfillNone: undefined,
    errors: [],
    customerManagedEncryptionKey: undefined,
  };
}

export const Stream: MessageFns<Stream> = {
  encode(message: Stream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Stream_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.sourceConfig !== undefined) {
      SourceConfig.encode(message.sourceConfig, writer.uint32(50).fork()).join();
    }
    if (message.destinationConfig !== undefined) {
      DestinationConfig.encode(message.destinationConfig, writer.uint32(58).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.backfillAll !== undefined) {
      Stream_BackfillAllStrategy.encode(message.backfillAll, writer.uint32(810).fork()).join();
    }
    if (message.backfillNone !== undefined) {
      Stream_BackfillNoneStrategy.encode(message.backfillNone, writer.uint32(818).fork()).join();
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.customerManagedEncryptionKey !== undefined) {
      writer.uint32(82).string(message.customerManagedEncryptionKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          const entry4 = Stream_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.sourceConfig = SourceConfig.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.destinationConfig = DestinationConfig.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 101:
          if (tag !== 810) {
            break;
          }

          message.backfillAll = Stream_BackfillAllStrategy.decode(reader, reader.uint32());
          continue;
        case 102:
          if (tag !== 818) {
            break;
          }

          message.backfillNone = Stream_BackfillNoneStrategy.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.customerManagedEncryptionKey = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stream {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      sourceConfig: isSet(object.sourceConfig) ? SourceConfig.fromJSON(object.sourceConfig) : undefined,
      destinationConfig: isSet(object.destinationConfig)
        ? DestinationConfig.fromJSON(object.destinationConfig)
        : undefined,
      state: isSet(object.state) ? stream_StateFromJSON(object.state) : 0,
      backfillAll: isSet(object.backfillAll) ? Stream_BackfillAllStrategy.fromJSON(object.backfillAll) : undefined,
      backfillNone: isSet(object.backfillNone) ? Stream_BackfillNoneStrategy.fromJSON(object.backfillNone) : undefined,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      customerManagedEncryptionKey: isSet(object.customerManagedEncryptionKey)
        ? globalThis.String(object.customerManagedEncryptionKey)
        : undefined,
    };
  },

  toJSON(message: Stream): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.sourceConfig !== undefined) {
      obj.sourceConfig = SourceConfig.toJSON(message.sourceConfig);
    }
    if (message.destinationConfig !== undefined) {
      obj.destinationConfig = DestinationConfig.toJSON(message.destinationConfig);
    }
    if (message.state !== 0) {
      obj.state = stream_StateToJSON(message.state);
    }
    if (message.backfillAll !== undefined) {
      obj.backfillAll = Stream_BackfillAllStrategy.toJSON(message.backfillAll);
    }
    if (message.backfillNone !== undefined) {
      obj.backfillNone = Stream_BackfillNoneStrategy.toJSON(message.backfillNone);
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.customerManagedEncryptionKey !== undefined) {
      obj.customerManagedEncryptionKey = message.customerManagedEncryptionKey;
    }
    return obj;
  },

  create(base?: DeepPartial<Stream>): Stream {
    return Stream.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stream>): Stream {
    const message = createBaseStream();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.displayName = object.displayName ?? "";
    message.sourceConfig = (object.sourceConfig !== undefined && object.sourceConfig !== null)
      ? SourceConfig.fromPartial(object.sourceConfig)
      : undefined;
    message.destinationConfig = (object.destinationConfig !== undefined && object.destinationConfig !== null)
      ? DestinationConfig.fromPartial(object.destinationConfig)
      : undefined;
    message.state = object.state ?? 0;
    message.backfillAll = (object.backfillAll !== undefined && object.backfillAll !== null)
      ? Stream_BackfillAllStrategy.fromPartial(object.backfillAll)
      : undefined;
    message.backfillNone = (object.backfillNone !== undefined && object.backfillNone !== null)
      ? Stream_BackfillNoneStrategy.fromPartial(object.backfillNone)
      : undefined;
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.customerManagedEncryptionKey = object.customerManagedEncryptionKey ?? undefined;
    return message;
  },
};

function createBaseStream_BackfillAllStrategy(): Stream_BackfillAllStrategy {
  return { oracleExcludedObjects: undefined, mysqlExcludedObjects: undefined, postgresqlExcludedObjects: undefined };
}

export const Stream_BackfillAllStrategy: MessageFns<Stream_BackfillAllStrategy> = {
  encode(message: Stream_BackfillAllStrategy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.oracleExcludedObjects !== undefined) {
      OracleRdbms.encode(message.oracleExcludedObjects, writer.uint32(10).fork()).join();
    }
    if (message.mysqlExcludedObjects !== undefined) {
      MysqlRdbms.encode(message.mysqlExcludedObjects, writer.uint32(18).fork()).join();
    }
    if (message.postgresqlExcludedObjects !== undefined) {
      PostgresqlRdbms.encode(message.postgresqlExcludedObjects, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stream_BackfillAllStrategy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStream_BackfillAllStrategy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.oracleExcludedObjects = OracleRdbms.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mysqlExcludedObjects = MysqlRdbms.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.postgresqlExcludedObjects = PostgresqlRdbms.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stream_BackfillAllStrategy {
    return {
      oracleExcludedObjects: isSet(object.oracleExcludedObjects)
        ? OracleRdbms.fromJSON(object.oracleExcludedObjects)
        : undefined,
      mysqlExcludedObjects: isSet(object.mysqlExcludedObjects)
        ? MysqlRdbms.fromJSON(object.mysqlExcludedObjects)
        : undefined,
      postgresqlExcludedObjects: isSet(object.postgresqlExcludedObjects)
        ? PostgresqlRdbms.fromJSON(object.postgresqlExcludedObjects)
        : undefined,
    };
  },

  toJSON(message: Stream_BackfillAllStrategy): unknown {
    const obj: any = {};
    if (message.oracleExcludedObjects !== undefined) {
      obj.oracleExcludedObjects = OracleRdbms.toJSON(message.oracleExcludedObjects);
    }
    if (message.mysqlExcludedObjects !== undefined) {
      obj.mysqlExcludedObjects = MysqlRdbms.toJSON(message.mysqlExcludedObjects);
    }
    if (message.postgresqlExcludedObjects !== undefined) {
      obj.postgresqlExcludedObjects = PostgresqlRdbms.toJSON(message.postgresqlExcludedObjects);
    }
    return obj;
  },

  create(base?: DeepPartial<Stream_BackfillAllStrategy>): Stream_BackfillAllStrategy {
    return Stream_BackfillAllStrategy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stream_BackfillAllStrategy>): Stream_BackfillAllStrategy {
    const message = createBaseStream_BackfillAllStrategy();
    message.oracleExcludedObjects =
      (object.oracleExcludedObjects !== undefined && object.oracleExcludedObjects !== null)
        ? OracleRdbms.fromPartial(object.oracleExcludedObjects)
        : undefined;
    message.mysqlExcludedObjects = (object.mysqlExcludedObjects !== undefined && object.mysqlExcludedObjects !== null)
      ? MysqlRdbms.fromPartial(object.mysqlExcludedObjects)
      : undefined;
    message.postgresqlExcludedObjects =
      (object.postgresqlExcludedObjects !== undefined && object.postgresqlExcludedObjects !== null)
        ? PostgresqlRdbms.fromPartial(object.postgresqlExcludedObjects)
        : undefined;
    return message;
  },
};

function createBaseStream_BackfillNoneStrategy(): Stream_BackfillNoneStrategy {
  return {};
}

export const Stream_BackfillNoneStrategy: MessageFns<Stream_BackfillNoneStrategy> = {
  encode(_: Stream_BackfillNoneStrategy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stream_BackfillNoneStrategy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStream_BackfillNoneStrategy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Stream_BackfillNoneStrategy {
    return {};
  },

  toJSON(_: Stream_BackfillNoneStrategy): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Stream_BackfillNoneStrategy>): Stream_BackfillNoneStrategy {
    return Stream_BackfillNoneStrategy.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Stream_BackfillNoneStrategy>): Stream_BackfillNoneStrategy {
    const message = createBaseStream_BackfillNoneStrategy();
    return message;
  },
};

function createBaseStream_LabelsEntry(): Stream_LabelsEntry {
  return { key: "", value: "" };
}

export const Stream_LabelsEntry: MessageFns<Stream_LabelsEntry> = {
  encode(message: Stream_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stream_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStream_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stream_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Stream_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Stream_LabelsEntry>): Stream_LabelsEntry {
    return Stream_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stream_LabelsEntry>): Stream_LabelsEntry {
    const message = createBaseStream_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseStreamObject(): StreamObject {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    displayName: "",
    errors: [],
    backfillJob: undefined,
    sourceObject: undefined,
  };
}

export const StreamObject: MessageFns<StreamObject> = {
  encode(message: StreamObject, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.backfillJob !== undefined) {
      BackfillJob.encode(message.backfillJob, writer.uint32(58).fork()).join();
    }
    if (message.sourceObject !== undefined) {
      SourceObjectIdentifier.encode(message.sourceObject, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamObject {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamObject();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.backfillJob = BackfillJob.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.sourceObject = SourceObjectIdentifier.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamObject {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
      backfillJob: isSet(object.backfillJob) ? BackfillJob.fromJSON(object.backfillJob) : undefined,
      sourceObject: isSet(object.sourceObject) ? SourceObjectIdentifier.fromJSON(object.sourceObject) : undefined,
    };
  },

  toJSON(message: StreamObject): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    if (message.backfillJob !== undefined) {
      obj.backfillJob = BackfillJob.toJSON(message.backfillJob);
    }
    if (message.sourceObject !== undefined) {
      obj.sourceObject = SourceObjectIdentifier.toJSON(message.sourceObject);
    }
    return obj;
  },

  create(base?: DeepPartial<StreamObject>): StreamObject {
    return StreamObject.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StreamObject>): StreamObject {
    const message = createBaseStreamObject();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.displayName = object.displayName ?? "";
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    message.backfillJob = (object.backfillJob !== undefined && object.backfillJob !== null)
      ? BackfillJob.fromPartial(object.backfillJob)
      : undefined;
    message.sourceObject = (object.sourceObject !== undefined && object.sourceObject !== null)
      ? SourceObjectIdentifier.fromPartial(object.sourceObject)
      : undefined;
    return message;
  },
};

function createBaseSourceObjectIdentifier(): SourceObjectIdentifier {
  return { oracleIdentifier: undefined, mysqlIdentifier: undefined, postgresqlIdentifier: undefined };
}

export const SourceObjectIdentifier: MessageFns<SourceObjectIdentifier> = {
  encode(message: SourceObjectIdentifier, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.oracleIdentifier !== undefined) {
      SourceObjectIdentifier_OracleObjectIdentifier.encode(message.oracleIdentifier, writer.uint32(10).fork()).join();
    }
    if (message.mysqlIdentifier !== undefined) {
      SourceObjectIdentifier_MysqlObjectIdentifier.encode(message.mysqlIdentifier, writer.uint32(18).fork()).join();
    }
    if (message.postgresqlIdentifier !== undefined) {
      SourceObjectIdentifier_PostgresqlObjectIdentifier.encode(message.postgresqlIdentifier, writer.uint32(26).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceObjectIdentifier {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceObjectIdentifier();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.oracleIdentifier = SourceObjectIdentifier_OracleObjectIdentifier.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.mysqlIdentifier = SourceObjectIdentifier_MysqlObjectIdentifier.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.postgresqlIdentifier = SourceObjectIdentifier_PostgresqlObjectIdentifier.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceObjectIdentifier {
    return {
      oracleIdentifier: isSet(object.oracleIdentifier)
        ? SourceObjectIdentifier_OracleObjectIdentifier.fromJSON(object.oracleIdentifier)
        : undefined,
      mysqlIdentifier: isSet(object.mysqlIdentifier)
        ? SourceObjectIdentifier_MysqlObjectIdentifier.fromJSON(object.mysqlIdentifier)
        : undefined,
      postgresqlIdentifier: isSet(object.postgresqlIdentifier)
        ? SourceObjectIdentifier_PostgresqlObjectIdentifier.fromJSON(object.postgresqlIdentifier)
        : undefined,
    };
  },

  toJSON(message: SourceObjectIdentifier): unknown {
    const obj: any = {};
    if (message.oracleIdentifier !== undefined) {
      obj.oracleIdentifier = SourceObjectIdentifier_OracleObjectIdentifier.toJSON(message.oracleIdentifier);
    }
    if (message.mysqlIdentifier !== undefined) {
      obj.mysqlIdentifier = SourceObjectIdentifier_MysqlObjectIdentifier.toJSON(message.mysqlIdentifier);
    }
    if (message.postgresqlIdentifier !== undefined) {
      obj.postgresqlIdentifier = SourceObjectIdentifier_PostgresqlObjectIdentifier.toJSON(message.postgresqlIdentifier);
    }
    return obj;
  },

  create(base?: DeepPartial<SourceObjectIdentifier>): SourceObjectIdentifier {
    return SourceObjectIdentifier.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SourceObjectIdentifier>): SourceObjectIdentifier {
    const message = createBaseSourceObjectIdentifier();
    message.oracleIdentifier = (object.oracleIdentifier !== undefined && object.oracleIdentifier !== null)
      ? SourceObjectIdentifier_OracleObjectIdentifier.fromPartial(object.oracleIdentifier)
      : undefined;
    message.mysqlIdentifier = (object.mysqlIdentifier !== undefined && object.mysqlIdentifier !== null)
      ? SourceObjectIdentifier_MysqlObjectIdentifier.fromPartial(object.mysqlIdentifier)
      : undefined;
    message.postgresqlIdentifier = (object.postgresqlIdentifier !== undefined && object.postgresqlIdentifier !== null)
      ? SourceObjectIdentifier_PostgresqlObjectIdentifier.fromPartial(object.postgresqlIdentifier)
      : undefined;
    return message;
  },
};

function createBaseSourceObjectIdentifier_OracleObjectIdentifier(): SourceObjectIdentifier_OracleObjectIdentifier {
  return { schema: "", table: "" };
}

export const SourceObjectIdentifier_OracleObjectIdentifier: MessageFns<SourceObjectIdentifier_OracleObjectIdentifier> =
  {
    encode(
      message: SourceObjectIdentifier_OracleObjectIdentifier,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.schema !== "") {
        writer.uint32(10).string(message.schema);
      }
      if (message.table !== "") {
        writer.uint32(18).string(message.table);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): SourceObjectIdentifier_OracleObjectIdentifier {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseSourceObjectIdentifier_OracleObjectIdentifier();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1:
            if (tag !== 10) {
              break;
            }

            message.schema = reader.string();
            continue;
          case 2:
            if (tag !== 18) {
              break;
            }

            message.table = reader.string();
            continue;
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): SourceObjectIdentifier_OracleObjectIdentifier {
      return {
        schema: isSet(object.schema) ? globalThis.String(object.schema) : "",
        table: isSet(object.table) ? globalThis.String(object.table) : "",
      };
    },

    toJSON(message: SourceObjectIdentifier_OracleObjectIdentifier): unknown {
      const obj: any = {};
      if (message.schema !== "") {
        obj.schema = message.schema;
      }
      if (message.table !== "") {
        obj.table = message.table;
      }
      return obj;
    },

    create(
      base?: DeepPartial<SourceObjectIdentifier_OracleObjectIdentifier>,
    ): SourceObjectIdentifier_OracleObjectIdentifier {
      return SourceObjectIdentifier_OracleObjectIdentifier.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<SourceObjectIdentifier_OracleObjectIdentifier>,
    ): SourceObjectIdentifier_OracleObjectIdentifier {
      const message = createBaseSourceObjectIdentifier_OracleObjectIdentifier();
      message.schema = object.schema ?? "";
      message.table = object.table ?? "";
      return message;
    },
  };

function createBaseSourceObjectIdentifier_PostgresqlObjectIdentifier(): SourceObjectIdentifier_PostgresqlObjectIdentifier {
  return { schema: "", table: "" };
}

export const SourceObjectIdentifier_PostgresqlObjectIdentifier: MessageFns<
  SourceObjectIdentifier_PostgresqlObjectIdentifier
> = {
  encode(
    message: SourceObjectIdentifier_PostgresqlObjectIdentifier,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.schema !== "") {
      writer.uint32(10).string(message.schema);
    }
    if (message.table !== "") {
      writer.uint32(18).string(message.table);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceObjectIdentifier_PostgresqlObjectIdentifier {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceObjectIdentifier_PostgresqlObjectIdentifier();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.schema = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.table = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceObjectIdentifier_PostgresqlObjectIdentifier {
    return {
      schema: isSet(object.schema) ? globalThis.String(object.schema) : "",
      table: isSet(object.table) ? globalThis.String(object.table) : "",
    };
  },

  toJSON(message: SourceObjectIdentifier_PostgresqlObjectIdentifier): unknown {
    const obj: any = {};
    if (message.schema !== "") {
      obj.schema = message.schema;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    return obj;
  },

  create(
    base?: DeepPartial<SourceObjectIdentifier_PostgresqlObjectIdentifier>,
  ): SourceObjectIdentifier_PostgresqlObjectIdentifier {
    return SourceObjectIdentifier_PostgresqlObjectIdentifier.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<SourceObjectIdentifier_PostgresqlObjectIdentifier>,
  ): SourceObjectIdentifier_PostgresqlObjectIdentifier {
    const message = createBaseSourceObjectIdentifier_PostgresqlObjectIdentifier();
    message.schema = object.schema ?? "";
    message.table = object.table ?? "";
    return message;
  },
};

function createBaseSourceObjectIdentifier_MysqlObjectIdentifier(): SourceObjectIdentifier_MysqlObjectIdentifier {
  return { database: "", table: "" };
}

export const SourceObjectIdentifier_MysqlObjectIdentifier: MessageFns<SourceObjectIdentifier_MysqlObjectIdentifier> = {
  encode(
    message: SourceObjectIdentifier_MysqlObjectIdentifier,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    if (message.table !== "") {
      writer.uint32(18).string(message.table);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceObjectIdentifier_MysqlObjectIdentifier {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceObjectIdentifier_MysqlObjectIdentifier();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.table = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceObjectIdentifier_MysqlObjectIdentifier {
    return {
      database: isSet(object.database) ? globalThis.String(object.database) : "",
      table: isSet(object.table) ? globalThis.String(object.table) : "",
    };
  },

  toJSON(message: SourceObjectIdentifier_MysqlObjectIdentifier): unknown {
    const obj: any = {};
    if (message.database !== "") {
      obj.database = message.database;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    return obj;
  },

  create(
    base?: DeepPartial<SourceObjectIdentifier_MysqlObjectIdentifier>,
  ): SourceObjectIdentifier_MysqlObjectIdentifier {
    return SourceObjectIdentifier_MysqlObjectIdentifier.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<SourceObjectIdentifier_MysqlObjectIdentifier>,
  ): SourceObjectIdentifier_MysqlObjectIdentifier {
    const message = createBaseSourceObjectIdentifier_MysqlObjectIdentifier();
    message.database = object.database ?? "";
    message.table = object.table ?? "";
    return message;
  },
};

function createBaseBackfillJob(): BackfillJob {
  return { state: 0, trigger: 0, lastStartTime: undefined, lastEndTime: undefined, errors: [] };
}

export const BackfillJob: MessageFns<BackfillJob> = {
  encode(message: BackfillJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.trigger !== 0) {
      writer.uint32(16).int32(message.trigger);
    }
    if (message.lastStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastStartTime), writer.uint32(26).fork()).join();
    }
    if (message.lastEndTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastEndTime), writer.uint32(34).fork()).join();
    }
    for (const v of message.errors) {
      Error.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackfillJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackfillJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.trigger = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.lastStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lastEndTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.errors.push(Error.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackfillJob {
    return {
      state: isSet(object.state) ? backfillJob_StateFromJSON(object.state) : 0,
      trigger: isSet(object.trigger) ? backfillJob_TriggerFromJSON(object.trigger) : 0,
      lastStartTime: isSet(object.lastStartTime) ? fromJsonTimestamp(object.lastStartTime) : undefined,
      lastEndTime: isSet(object.lastEndTime) ? fromJsonTimestamp(object.lastEndTime) : undefined,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => Error.fromJSON(e)) : [],
    };
  },

  toJSON(message: BackfillJob): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = backfillJob_StateToJSON(message.state);
    }
    if (message.trigger !== 0) {
      obj.trigger = backfillJob_TriggerToJSON(message.trigger);
    }
    if (message.lastStartTime !== undefined) {
      obj.lastStartTime = message.lastStartTime.toISOString();
    }
    if (message.lastEndTime !== undefined) {
      obj.lastEndTime = message.lastEndTime.toISOString();
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => Error.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BackfillJob>): BackfillJob {
    return BackfillJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BackfillJob>): BackfillJob {
    const message = createBaseBackfillJob();
    message.state = object.state ?? 0;
    message.trigger = object.trigger ?? 0;
    message.lastStartTime = object.lastStartTime ?? undefined;
    message.lastEndTime = object.lastEndTime ?? undefined;
    message.errors = object.errors?.map((e) => Error.fromPartial(e)) || [];
    return message;
  },
};

function createBaseError(): Error {
  return { reason: "", errorUuid: "", message: "", errorTime: undefined, details: {} };
}

export const Error: MessageFns<Error> = {
  encode(message: Error, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.reason !== "") {
      writer.uint32(10).string(message.reason);
    }
    if (message.errorUuid !== "") {
      writer.uint32(18).string(message.errorUuid);
    }
    if (message.message !== "") {
      writer.uint32(26).string(message.message);
    }
    if (message.errorTime !== undefined) {
      Timestamp.encode(toTimestamp(message.errorTime), writer.uint32(34).fork()).join();
    }
    Object.entries(message.details).forEach(([key, value]) => {
      Error_DetailsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Error {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.reason = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.errorUuid = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.message = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.errorTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          const entry5 = Error_DetailsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.details[entry5.key] = entry5.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Error {
    return {
      reason: isSet(object.reason) ? globalThis.String(object.reason) : "",
      errorUuid: isSet(object.errorUuid) ? globalThis.String(object.errorUuid) : "",
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      errorTime: isSet(object.errorTime) ? fromJsonTimestamp(object.errorTime) : undefined,
      details: isObject(object.details)
        ? Object.entries(object.details).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Error): unknown {
    const obj: any = {};
    if (message.reason !== "") {
      obj.reason = message.reason;
    }
    if (message.errorUuid !== "") {
      obj.errorUuid = message.errorUuid;
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.errorTime !== undefined) {
      obj.errorTime = message.errorTime.toISOString();
    }
    if (message.details) {
      const entries = Object.entries(message.details);
      if (entries.length > 0) {
        obj.details = {};
        entries.forEach(([k, v]) => {
          obj.details[k] = v;
        });
      }
    }
    return obj;
  },

  create(base?: DeepPartial<Error>): Error {
    return Error.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Error>): Error {
    const message = createBaseError();
    message.reason = object.reason ?? "";
    message.errorUuid = object.errorUuid ?? "";
    message.message = object.message ?? "";
    message.errorTime = object.errorTime ?? undefined;
    message.details = Object.entries(object.details ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseError_DetailsEntry(): Error_DetailsEntry {
  return { key: "", value: "" };
}

export const Error_DetailsEntry: MessageFns<Error_DetailsEntry> = {
  encode(message: Error_DetailsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Error_DetailsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseError_DetailsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Error_DetailsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Error_DetailsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<Error_DetailsEntry>): Error_DetailsEntry {
    return Error_DetailsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Error_DetailsEntry>): Error_DetailsEntry {
    const message = createBaseError_DetailsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseValidationResult(): ValidationResult {
  return { validations: [] };
}

export const ValidationResult: MessageFns<ValidationResult> = {
  encode(message: ValidationResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.validations) {
      Validation.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ValidationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValidationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.validations.push(Validation.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ValidationResult {
    return {
      validations: globalThis.Array.isArray(object?.validations)
        ? object.validations.map((e: any) => Validation.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ValidationResult): unknown {
    const obj: any = {};
    if (message.validations?.length) {
      obj.validations = message.validations.map((e) => Validation.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ValidationResult>): ValidationResult {
    return ValidationResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ValidationResult>): ValidationResult {
    const message = createBaseValidationResult();
    message.validations = object.validations?.map((e) => Validation.fromPartial(e)) || [];
    return message;
  },
};

function createBaseValidation(): Validation {
  return { description: "", state: 0, message: [], code: "" };
}

export const Validation: MessageFns<Validation> = {
  encode(message: Validation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.description !== "") {
      writer.uint32(10).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    for (const v of message.message) {
      ValidationMessage.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.code !== "") {
      writer.uint32(34).string(message.code);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Validation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValidation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.description = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.message.push(ValidationMessage.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.code = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Validation {
    return {
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? validation_StateFromJSON(object.state) : 0,
      message: globalThis.Array.isArray(object?.message)
        ? object.message.map((e: any) => ValidationMessage.fromJSON(e))
        : [],
      code: isSet(object.code) ? globalThis.String(object.code) : "",
    };
  },

  toJSON(message: Validation): unknown {
    const obj: any = {};
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = validation_StateToJSON(message.state);
    }
    if (message.message?.length) {
      obj.message = message.message.map((e) => ValidationMessage.toJSON(e));
    }
    if (message.code !== "") {
      obj.code = message.code;
    }
    return obj;
  },

  create(base?: DeepPartial<Validation>): Validation {
    return Validation.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Validation>): Validation {
    const message = createBaseValidation();
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.message = object.message?.map((e) => ValidationMessage.fromPartial(e)) || [];
    message.code = object.code ?? "";
    return message;
  },
};

function createBaseValidationMessage(): ValidationMessage {
  return { message: "", level: 0, metadata: {}, code: "" };
}

export const ValidationMessage: MessageFns<ValidationMessage> = {
  encode(message: ValidationMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    if (message.level !== 0) {
      writer.uint32(16).int32(message.level);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      ValidationMessage_MetadataEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.code !== "") {
      writer.uint32(34).string(message.code);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ValidationMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValidationMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.level = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = ValidationMessage_MetadataEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.metadata[entry3.key] = entry3.value;
          }
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.code = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ValidationMessage {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      level: isSet(object.level) ? validationMessage_LevelFromJSON(object.level) : 0,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      code: isSet(object.code) ? globalThis.String(object.code) : "",
    };
  },

  toJSON(message: ValidationMessage): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.level !== 0) {
      obj.level = validationMessage_LevelToJSON(message.level);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    if (message.code !== "") {
      obj.code = message.code;
    }
    return obj;
  },

  create(base?: DeepPartial<ValidationMessage>): ValidationMessage {
    return ValidationMessage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ValidationMessage>): ValidationMessage {
    const message = createBaseValidationMessage();
    message.message = object.message ?? "";
    message.level = object.level ?? 0;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.code = object.code ?? "";
    return message;
  },
};

function createBaseValidationMessage_MetadataEntry(): ValidationMessage_MetadataEntry {
  return { key: "", value: "" };
}

export const ValidationMessage_MetadataEntry: MessageFns<ValidationMessage_MetadataEntry> = {
  encode(message: ValidationMessage_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ValidationMessage_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseValidationMessage_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ValidationMessage_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ValidationMessage_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ValidationMessage_MetadataEntry>): ValidationMessage_MetadataEntry {
    return ValidationMessage_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ValidationMessage_MetadataEntry>): ValidationMessage_MetadataEntry {
    const message = createBaseValidationMessage_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
