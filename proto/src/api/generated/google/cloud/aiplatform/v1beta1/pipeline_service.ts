// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/pipeline_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { Empty } from "../../../protobuf/empty.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { GenericOperationMetadata } from "./operation.js";
import { PipelineJob } from "./pipeline_job.js";
import { TrainingPipeline } from "./training_pipeline.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/**
 * Runtime operation information for
 * [PipelineService.BatchCancelPipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.BatchCancelPipelineJobs].
 */
export interface BatchCancelPipelineJobsOperationMetadata {
  /** The common part of the operation metadata. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/**
 * Request message for
 * [PipelineService.CreateTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.CreateTrainingPipeline].
 */
export interface CreateTrainingPipelineRequest {
  /**
   * Required. The resource name of the Location to create the TrainingPipeline
   * in. Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. The TrainingPipeline to create. */
  trainingPipeline: TrainingPipeline | undefined;
}

/**
 * Request message for
 * [PipelineService.GetTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.GetTrainingPipeline].
 */
export interface GetTrainingPipelineRequest {
  /**
   * Required. The name of the TrainingPipeline resource.
   * Format:
   * `projects/{project}/locations/{location}/trainingPipelines/{training_pipeline}`
   */
  name: string;
}

/**
 * Request message for
 * [PipelineService.ListTrainingPipelines][google.cloud.aiplatform.v1beta1.PipelineService.ListTrainingPipelines].
 */
export interface ListTrainingPipelinesRequest {
  /**
   * Required. The resource name of the Location to list the TrainingPipelines
   * from. Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * The standard list filter.
   *
   * Supported fields:
   *
   *   * `display_name` supports `=`, `!=` comparisons, and `:` wildcard.
   *   * `state` supports `=`, `!=` comparisons.
   *   * `training_task_definition` `=`, `!=` comparisons, and `:` wildcard.
   *   * `create_time` supports `=`, `!=`,`<`, `<=`,`>`, `>=` comparisons.
   *     `create_time` must be in RFC 3339 format.
   *   * `labels` supports general map functions that is:
   *     `labels.key=value` - key:value equality
   *     `labels.key:* - key existence
   *
   * Some examples of using the filter are:
   *
   *   * `state="PIPELINE_STATE_SUCCEEDED" AND display_name:"my_pipeline_*"`
   *   * `state!="PIPELINE_STATE_FAILED" OR display_name="my_pipeline"`
   *   * `NOT display_name="my_pipeline"`
   *   * `create_time>"2021-05-18T00:00:00Z"`
   *   * `training_task_definition:"*automl_text_classification*"`
   */
  filter: string;
  /** The standard list page size. */
  pageSize: number;
  /**
   * The standard list page token.
   * Typically obtained via
   * [ListTrainingPipelinesResponse.next_page_token][google.cloud.aiplatform.v1beta1.ListTrainingPipelinesResponse.next_page_token]
   * of the previous
   * [PipelineService.ListTrainingPipelines][google.cloud.aiplatform.v1beta1.PipelineService.ListTrainingPipelines]
   * call.
   */
  pageToken: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [PipelineService.ListTrainingPipelines][google.cloud.aiplatform.v1beta1.PipelineService.ListTrainingPipelines]
 */
export interface ListTrainingPipelinesResponse {
  /** List of TrainingPipelines in the requested page. */
  trainingPipelines: TrainingPipeline[];
  /**
   * A token to retrieve the next page of results.
   * Pass to
   * [ListTrainingPipelinesRequest.page_token][google.cloud.aiplatform.v1beta1.ListTrainingPipelinesRequest.page_token]
   * to obtain that page.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [PipelineService.DeleteTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.DeleteTrainingPipeline].
 */
export interface DeleteTrainingPipelineRequest {
  /**
   * Required. The name of the TrainingPipeline resource to be deleted.
   * Format:
   * `projects/{project}/locations/{location}/trainingPipelines/{training_pipeline}`
   */
  name: string;
}

/**
 * Request message for
 * [PipelineService.CancelTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.CancelTrainingPipeline].
 */
export interface CancelTrainingPipelineRequest {
  /**
   * Required. The name of the TrainingPipeline to cancel.
   * Format:
   * `projects/{project}/locations/{location}/trainingPipelines/{training_pipeline}`
   */
  name: string;
}

/**
 * Request message for
 * [PipelineService.CreatePipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.CreatePipelineJob].
 */
export interface CreatePipelineJobRequest {
  /**
   * Required. The resource name of the Location to create the PipelineJob in.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. The PipelineJob to create. */
  pipelineJob:
    | PipelineJob
    | undefined;
  /**
   * The ID to use for the PipelineJob, which will become the final component of
   * the PipelineJob name. If not provided, an ID will be automatically
   * generated.
   *
   * This value should be less than 128 characters, and valid characters
   * are `/[a-z][0-9]-/`.
   */
  pipelineJobId: string;
}

/**
 * Request message for
 * [PipelineService.GetPipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.GetPipelineJob].
 */
export interface GetPipelineJobRequest {
  /**
   * Required. The name of the PipelineJob resource.
   * Format:
   * `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`
   */
  name: string;
}

/**
 * Request message for
 * [PipelineService.ListPipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.ListPipelineJobs].
 */
export interface ListPipelineJobsRequest {
  /**
   * Required. The resource name of the Location to list the PipelineJobs from.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * Lists the PipelineJobs that match the filter expression. The following
   * fields are supported:
   *
   * * `pipeline_name`: Supports `=` and `!=` comparisons.
   * * `display_name`: Supports `=`, `!=` comparisons, and `:` wildcard.
   * * `pipeline_job_user_id`: Supports `=`, `!=` comparisons, and `:` wildcard.
   *   for example, can check if pipeline's display_name contains *step* by
   *   doing display_name:\"*step*\"
   * * `state`: Supports `=` and `!=` comparisons.
   * * `create_time`: Supports `=`, `!=`, `<`, `>`, `<=`, and `>=` comparisons.
   *   Values must be in RFC 3339 format.
   * * `update_time`: Supports `=`, `!=`, `<`, `>`, `<=`, and `>=` comparisons.
   *   Values must be in RFC 3339 format.
   * * `end_time`: Supports `=`, `!=`, `<`, `>`, `<=`, and `>=` comparisons.
   *   Values must be in RFC 3339 format.
   * * `labels`: Supports key-value equality and key presence.
   * * `template_uri`: Supports `=`, `!=` comparisons, and `:` wildcard.
   * * `template_metadata.version`: Supports `=`, `!=` comparisons, and `:`
   *   wildcard.
   *
   * Filter expressions can be combined together using logical operators
   * (`AND` & `OR`).
   * For example: `pipeline_name="test" AND create_time>"2020-05-18T13:30:00Z"`.
   *
   * The syntax to define filter expression is based on
   * https://google.aip.dev/160.
   *
   * Examples:
   *
   * * `create_time>"2021-05-18T00:00:00Z" OR
   *   update_time>"2020-05-18T00:00:00Z"` PipelineJobs created or updated
   *   after 2020-05-18 00:00:00 UTC.
   * * `labels.env = "prod"`
   *   PipelineJobs with label "env" set to "prod".
   */
  filter: string;
  /** The standard list page size. */
  pageSize: number;
  /**
   * The standard list page token.
   * Typically obtained via
   * [ListPipelineJobsResponse.next_page_token][google.cloud.aiplatform.v1beta1.ListPipelineJobsResponse.next_page_token]
   * of the previous
   * [PipelineService.ListPipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.ListPipelineJobs]
   * call.
   */
  pageToken: string;
  /**
   * A comma-separated list of fields to order by. The default sort order is in
   * ascending order. Use "desc" after a field name for descending. You can have
   * multiple order_by fields provided e.g. "create_time desc, end_time",
   * "end_time, start_time, update_time" For example, using "create_time desc,
   * end_time" will order results by create time in descending order, and if
   * there are multiple jobs having the same create time, order them by the end
   * time in ascending order. if order_by is not specified, it will order by
   * default order is create time in descending order. Supported fields:
   *
   *   * `create_time`
   *   * `update_time`
   *   * `end_time`
   *   * `start_time`
   */
  orderBy: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [PipelineService.ListPipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.ListPipelineJobs]
 */
export interface ListPipelineJobsResponse {
  /** List of PipelineJobs in the requested page. */
  pipelineJobs: PipelineJob[];
  /**
   * A token to retrieve the next page of results.
   * Pass to
   * [ListPipelineJobsRequest.page_token][google.cloud.aiplatform.v1beta1.ListPipelineJobsRequest.page_token]
   * to obtain that page.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [PipelineService.DeletePipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.DeletePipelineJob].
 */
export interface DeletePipelineJobRequest {
  /**
   * Required. The name of the PipelineJob resource to be deleted.
   * Format:
   * `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`
   */
  name: string;
}

/**
 * Request message for
 * [PipelineService.BatchDeletePipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.BatchDeletePipelineJobs].
 */
export interface BatchDeletePipelineJobsRequest {
  /**
   * Required. The name of the PipelineJobs' parent resource.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * Required. The names of the PipelineJobs to delete.
   * A maximum of 32 PipelineJobs can be deleted in a batch.
   * Format:
   * `projects/{project}/locations/{location}/pipelineJobs/{pipelineJob}`
   */
  names: string[];
}

/**
 * Response message for
 * [PipelineService.BatchDeletePipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.BatchDeletePipelineJobs].
 */
export interface BatchDeletePipelineJobsResponse {
  /** PipelineJobs deleted. */
  pipelineJobs: PipelineJob[];
}

/**
 * Request message for
 * [PipelineService.CancelPipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.CancelPipelineJob].
 */
export interface CancelPipelineJobRequest {
  /**
   * Required. The name of the PipelineJob to cancel.
   * Format:
   * `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`
   */
  name: string;
}

/**
 * Request message for
 * [PipelineService.BatchCancelPipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.BatchCancelPipelineJobs].
 */
export interface BatchCancelPipelineJobsRequest {
  /**
   * Required. The name of the PipelineJobs' parent resource.
   * Format: `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * Required. The names of the PipelineJobs to cancel.
   * A maximum of 32 PipelineJobs can be cancelled in a batch.
   * Format:
   * `projects/{project}/locations/{location}/pipelineJobs/{pipelineJob}`
   */
  names: string[];
}

/**
 * Response message for
 * [PipelineService.BatchCancelPipelineJobs][google.cloud.aiplatform.v1beta1.PipelineService.BatchCancelPipelineJobs].
 */
export interface BatchCancelPipelineJobsResponse {
  /** PipelineJobs cancelled. */
  pipelineJobs: PipelineJob[];
}

function createBaseBatchCancelPipelineJobsOperationMetadata(): BatchCancelPipelineJobsOperationMetadata {
  return { genericMetadata: undefined };
}

export const BatchCancelPipelineJobsOperationMetadata: MessageFns<BatchCancelPipelineJobsOperationMetadata> = {
  encode(message: BatchCancelPipelineJobsOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchCancelPipelineJobsOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchCancelPipelineJobsOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchCancelPipelineJobsOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: BatchCancelPipelineJobsOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchCancelPipelineJobsOperationMetadata>): BatchCancelPipelineJobsOperationMetadata {
    return BatchCancelPipelineJobsOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchCancelPipelineJobsOperationMetadata>): BatchCancelPipelineJobsOperationMetadata {
    const message = createBaseBatchCancelPipelineJobsOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseCreateTrainingPipelineRequest(): CreateTrainingPipelineRequest {
  return { parent: "", trainingPipeline: undefined };
}

export const CreateTrainingPipelineRequest: MessageFns<CreateTrainingPipelineRequest> = {
  encode(message: CreateTrainingPipelineRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.trainingPipeline !== undefined) {
      TrainingPipeline.encode(message.trainingPipeline, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateTrainingPipelineRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateTrainingPipelineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.trainingPipeline = TrainingPipeline.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateTrainingPipelineRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      trainingPipeline: isSet(object.trainingPipeline) ? TrainingPipeline.fromJSON(object.trainingPipeline) : undefined,
    };
  },

  toJSON(message: CreateTrainingPipelineRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.trainingPipeline !== undefined) {
      obj.trainingPipeline = TrainingPipeline.toJSON(message.trainingPipeline);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateTrainingPipelineRequest>): CreateTrainingPipelineRequest {
    return CreateTrainingPipelineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateTrainingPipelineRequest>): CreateTrainingPipelineRequest {
    const message = createBaseCreateTrainingPipelineRequest();
    message.parent = object.parent ?? "";
    message.trainingPipeline = (object.trainingPipeline !== undefined && object.trainingPipeline !== null)
      ? TrainingPipeline.fromPartial(object.trainingPipeline)
      : undefined;
    return message;
  },
};

function createBaseGetTrainingPipelineRequest(): GetTrainingPipelineRequest {
  return { name: "" };
}

export const GetTrainingPipelineRequest: MessageFns<GetTrainingPipelineRequest> = {
  encode(message: GetTrainingPipelineRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTrainingPipelineRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTrainingPipelineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetTrainingPipelineRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetTrainingPipelineRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetTrainingPipelineRequest>): GetTrainingPipelineRequest {
    return GetTrainingPipelineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetTrainingPipelineRequest>): GetTrainingPipelineRequest {
    const message = createBaseGetTrainingPipelineRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListTrainingPipelinesRequest(): ListTrainingPipelinesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", readMask: undefined };
}

export const ListTrainingPipelinesRequest: MessageFns<ListTrainingPipelinesRequest> = {
  encode(message: ListTrainingPipelinesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTrainingPipelinesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTrainingPipelinesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTrainingPipelinesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListTrainingPipelinesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListTrainingPipelinesRequest>): ListTrainingPipelinesRequest {
    return ListTrainingPipelinesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTrainingPipelinesRequest>): ListTrainingPipelinesRequest {
    const message = createBaseListTrainingPipelinesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListTrainingPipelinesResponse(): ListTrainingPipelinesResponse {
  return { trainingPipelines: [], nextPageToken: "" };
}

export const ListTrainingPipelinesResponse: MessageFns<ListTrainingPipelinesResponse> = {
  encode(message: ListTrainingPipelinesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.trainingPipelines) {
      TrainingPipeline.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListTrainingPipelinesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListTrainingPipelinesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.trainingPipelines.push(TrainingPipeline.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListTrainingPipelinesResponse {
    return {
      trainingPipelines: globalThis.Array.isArray(object?.trainingPipelines)
        ? object.trainingPipelines.map((e: any) => TrainingPipeline.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListTrainingPipelinesResponse): unknown {
    const obj: any = {};
    if (message.trainingPipelines?.length) {
      obj.trainingPipelines = message.trainingPipelines.map((e) => TrainingPipeline.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListTrainingPipelinesResponse>): ListTrainingPipelinesResponse {
    return ListTrainingPipelinesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListTrainingPipelinesResponse>): ListTrainingPipelinesResponse {
    const message = createBaseListTrainingPipelinesResponse();
    message.trainingPipelines = object.trainingPipelines?.map((e) => TrainingPipeline.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeleteTrainingPipelineRequest(): DeleteTrainingPipelineRequest {
  return { name: "" };
}

export const DeleteTrainingPipelineRequest: MessageFns<DeleteTrainingPipelineRequest> = {
  encode(message: DeleteTrainingPipelineRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteTrainingPipelineRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteTrainingPipelineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteTrainingPipelineRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteTrainingPipelineRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteTrainingPipelineRequest>): DeleteTrainingPipelineRequest {
    return DeleteTrainingPipelineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteTrainingPipelineRequest>): DeleteTrainingPipelineRequest {
    const message = createBaseDeleteTrainingPipelineRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCancelTrainingPipelineRequest(): CancelTrainingPipelineRequest {
  return { name: "" };
}

export const CancelTrainingPipelineRequest: MessageFns<CancelTrainingPipelineRequest> = {
  encode(message: CancelTrainingPipelineRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelTrainingPipelineRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelTrainingPipelineRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelTrainingPipelineRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: CancelTrainingPipelineRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelTrainingPipelineRequest>): CancelTrainingPipelineRequest {
    return CancelTrainingPipelineRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelTrainingPipelineRequest>): CancelTrainingPipelineRequest {
    const message = createBaseCancelTrainingPipelineRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreatePipelineJobRequest(): CreatePipelineJobRequest {
  return { parent: "", pipelineJob: undefined, pipelineJobId: "" };
}

export const CreatePipelineJobRequest: MessageFns<CreatePipelineJobRequest> = {
  encode(message: CreatePipelineJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.pipelineJob !== undefined) {
      PipelineJob.encode(message.pipelineJob, writer.uint32(18).fork()).join();
    }
    if (message.pipelineJobId !== "") {
      writer.uint32(26).string(message.pipelineJobId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreatePipelineJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreatePipelineJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.pipelineJob = PipelineJob.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pipelineJobId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreatePipelineJobRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      pipelineJob: isSet(object.pipelineJob) ? PipelineJob.fromJSON(object.pipelineJob) : undefined,
      pipelineJobId: isSet(object.pipelineJobId) ? globalThis.String(object.pipelineJobId) : "",
    };
  },

  toJSON(message: CreatePipelineJobRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.pipelineJob !== undefined) {
      obj.pipelineJob = PipelineJob.toJSON(message.pipelineJob);
    }
    if (message.pipelineJobId !== "") {
      obj.pipelineJobId = message.pipelineJobId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreatePipelineJobRequest>): CreatePipelineJobRequest {
    return CreatePipelineJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreatePipelineJobRequest>): CreatePipelineJobRequest {
    const message = createBaseCreatePipelineJobRequest();
    message.parent = object.parent ?? "";
    message.pipelineJob = (object.pipelineJob !== undefined && object.pipelineJob !== null)
      ? PipelineJob.fromPartial(object.pipelineJob)
      : undefined;
    message.pipelineJobId = object.pipelineJobId ?? "";
    return message;
  },
};

function createBaseGetPipelineJobRequest(): GetPipelineJobRequest {
  return { name: "" };
}

export const GetPipelineJobRequest: MessageFns<GetPipelineJobRequest> = {
  encode(message: GetPipelineJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetPipelineJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetPipelineJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetPipelineJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetPipelineJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetPipelineJobRequest>): GetPipelineJobRequest {
    return GetPipelineJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetPipelineJobRequest>): GetPipelineJobRequest {
    const message = createBaseGetPipelineJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListPipelineJobsRequest(): ListPipelineJobsRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", orderBy: "", readMask: undefined };
}

export const ListPipelineJobsRequest: MessageFns<ListPipelineJobsRequest> = {
  encode(message: ListPipelineJobsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(50).string(message.orderBy);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListPipelineJobsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListPipelineJobsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListPipelineJobsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListPipelineJobsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListPipelineJobsRequest>): ListPipelineJobsRequest {
    return ListPipelineJobsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListPipelineJobsRequest>): ListPipelineJobsRequest {
    const message = createBaseListPipelineJobsRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListPipelineJobsResponse(): ListPipelineJobsResponse {
  return { pipelineJobs: [], nextPageToken: "" };
}

export const ListPipelineJobsResponse: MessageFns<ListPipelineJobsResponse> = {
  encode(message: ListPipelineJobsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.pipelineJobs) {
      PipelineJob.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListPipelineJobsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListPipelineJobsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipelineJobs.push(PipelineJob.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListPipelineJobsResponse {
    return {
      pipelineJobs: globalThis.Array.isArray(object?.pipelineJobs)
        ? object.pipelineJobs.map((e: any) => PipelineJob.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListPipelineJobsResponse): unknown {
    const obj: any = {};
    if (message.pipelineJobs?.length) {
      obj.pipelineJobs = message.pipelineJobs.map((e) => PipelineJob.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListPipelineJobsResponse>): ListPipelineJobsResponse {
    return ListPipelineJobsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListPipelineJobsResponse>): ListPipelineJobsResponse {
    const message = createBaseListPipelineJobsResponse();
    message.pipelineJobs = object.pipelineJobs?.map((e) => PipelineJob.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseDeletePipelineJobRequest(): DeletePipelineJobRequest {
  return { name: "" };
}

export const DeletePipelineJobRequest: MessageFns<DeletePipelineJobRequest> = {
  encode(message: DeletePipelineJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeletePipelineJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeletePipelineJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeletePipelineJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeletePipelineJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeletePipelineJobRequest>): DeletePipelineJobRequest {
    return DeletePipelineJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeletePipelineJobRequest>): DeletePipelineJobRequest {
    const message = createBaseDeletePipelineJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseBatchDeletePipelineJobsRequest(): BatchDeletePipelineJobsRequest {
  return { parent: "", names: [] };
}

export const BatchDeletePipelineJobsRequest: MessageFns<BatchDeletePipelineJobsRequest> = {
  encode(message: BatchDeletePipelineJobsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.names) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchDeletePipelineJobsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchDeletePipelineJobsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.names.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchDeletePipelineJobsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      names: globalThis.Array.isArray(object?.names) ? object.names.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: BatchDeletePipelineJobsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.names?.length) {
      obj.names = message.names;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchDeletePipelineJobsRequest>): BatchDeletePipelineJobsRequest {
    return BatchDeletePipelineJobsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchDeletePipelineJobsRequest>): BatchDeletePipelineJobsRequest {
    const message = createBaseBatchDeletePipelineJobsRequest();
    message.parent = object.parent ?? "";
    message.names = object.names?.map((e) => e) || [];
    return message;
  },
};

function createBaseBatchDeletePipelineJobsResponse(): BatchDeletePipelineJobsResponse {
  return { pipelineJobs: [] };
}

export const BatchDeletePipelineJobsResponse: MessageFns<BatchDeletePipelineJobsResponse> = {
  encode(message: BatchDeletePipelineJobsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.pipelineJobs) {
      PipelineJob.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchDeletePipelineJobsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchDeletePipelineJobsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipelineJobs.push(PipelineJob.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchDeletePipelineJobsResponse {
    return {
      pipelineJobs: globalThis.Array.isArray(object?.pipelineJobs)
        ? object.pipelineJobs.map((e: any) => PipelineJob.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchDeletePipelineJobsResponse): unknown {
    const obj: any = {};
    if (message.pipelineJobs?.length) {
      obj.pipelineJobs = message.pipelineJobs.map((e) => PipelineJob.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchDeletePipelineJobsResponse>): BatchDeletePipelineJobsResponse {
    return BatchDeletePipelineJobsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchDeletePipelineJobsResponse>): BatchDeletePipelineJobsResponse {
    const message = createBaseBatchDeletePipelineJobsResponse();
    message.pipelineJobs = object.pipelineJobs?.map((e) => PipelineJob.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCancelPipelineJobRequest(): CancelPipelineJobRequest {
  return { name: "" };
}

export const CancelPipelineJobRequest: MessageFns<CancelPipelineJobRequest> = {
  encode(message: CancelPipelineJobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CancelPipelineJobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelPipelineJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelPipelineJobRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: CancelPipelineJobRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelPipelineJobRequest>): CancelPipelineJobRequest {
    return CancelPipelineJobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelPipelineJobRequest>): CancelPipelineJobRequest {
    const message = createBaseCancelPipelineJobRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseBatchCancelPipelineJobsRequest(): BatchCancelPipelineJobsRequest {
  return { parent: "", names: [] };
}

export const BatchCancelPipelineJobsRequest: MessageFns<BatchCancelPipelineJobsRequest> = {
  encode(message: BatchCancelPipelineJobsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.names) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchCancelPipelineJobsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchCancelPipelineJobsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.names.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchCancelPipelineJobsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      names: globalThis.Array.isArray(object?.names) ? object.names.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: BatchCancelPipelineJobsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.names?.length) {
      obj.names = message.names;
    }
    return obj;
  },

  create(base?: DeepPartial<BatchCancelPipelineJobsRequest>): BatchCancelPipelineJobsRequest {
    return BatchCancelPipelineJobsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchCancelPipelineJobsRequest>): BatchCancelPipelineJobsRequest {
    const message = createBaseBatchCancelPipelineJobsRequest();
    message.parent = object.parent ?? "";
    message.names = object.names?.map((e) => e) || [];
    return message;
  },
};

function createBaseBatchCancelPipelineJobsResponse(): BatchCancelPipelineJobsResponse {
  return { pipelineJobs: [] };
}

export const BatchCancelPipelineJobsResponse: MessageFns<BatchCancelPipelineJobsResponse> = {
  encode(message: BatchCancelPipelineJobsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.pipelineJobs) {
      PipelineJob.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchCancelPipelineJobsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchCancelPipelineJobsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.pipelineJobs.push(PipelineJob.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchCancelPipelineJobsResponse {
    return {
      pipelineJobs: globalThis.Array.isArray(object?.pipelineJobs)
        ? object.pipelineJobs.map((e: any) => PipelineJob.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchCancelPipelineJobsResponse): unknown {
    const obj: any = {};
    if (message.pipelineJobs?.length) {
      obj.pipelineJobs = message.pipelineJobs.map((e) => PipelineJob.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchCancelPipelineJobsResponse>): BatchCancelPipelineJobsResponse {
    return BatchCancelPipelineJobsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchCancelPipelineJobsResponse>): BatchCancelPipelineJobsResponse {
    const message = createBaseBatchCancelPipelineJobsResponse();
    message.pipelineJobs = object.pipelineJobs?.map((e) => PipelineJob.fromPartial(e)) || [];
    return message;
  },
};

/**
 * A service for creating and managing Vertex AI's pipelines. This includes both
 * `TrainingPipeline` resources (used for AutoML and custom training) and
 * `PipelineJob` resources (used for Vertex AI Pipelines).
 */
export type PipelineServiceDefinition = typeof PipelineServiceDefinition;
export const PipelineServiceDefinition = {
  name: "PipelineService",
  fullName: "google.cloud.aiplatform.v1beta1.PipelineService",
  methods: {
    /**
     * Creates a TrainingPipeline. A created TrainingPipeline right away will be
     * attempted to be run.
     */
    createTrainingPipeline: {
      name: "CreateTrainingPipeline",
      requestType: CreateTrainingPipelineRequest,
      requestStream: false,
      responseType: TrainingPipeline,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              24,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              95,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
            ]),
          ],
          578365826: [
            Buffer.from([
              79,
              58,
              17,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              95,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              34,
              58,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets a TrainingPipeline. */
    getTrainingPipeline: {
      name: "GetTrainingPipeline",
      requestType: GetTrainingPipelineRequest,
      requestStream: false,
      responseType: TrainingPipeline,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              60,
              18,
              58,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists TrainingPipelines in a Location. */
    listTrainingPipelines: {
      name: "ListTrainingPipelines",
      requestType: ListTrainingPipelinesRequest,
      requestStream: false,
      responseType: ListTrainingPipelinesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              60,
              18,
              58,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a TrainingPipeline. */
    deleteTrainingPipeline: {
      name: "DeleteTrainingPipeline",
      requestType: DeleteTrainingPipelineRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              60,
              42,
              58,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Cancels a TrainingPipeline.
     * Starts asynchronous cancellation on the TrainingPipeline. The server
     * makes a best effort to cancel the pipeline, but success is not
     * guaranteed. Clients can use
     * [PipelineService.GetTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.GetTrainingPipeline]
     * or other methods to check whether the cancellation succeeded or whether the
     * pipeline completed despite cancellation. On successful cancellation,
     * the TrainingPipeline is not deleted; instead it becomes a pipeline with
     * a
     * [TrainingPipeline.error][google.cloud.aiplatform.v1beta1.TrainingPipeline.error]
     * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
     * corresponding to `Code.CANCELLED`, and
     * [TrainingPipeline.state][google.cloud.aiplatform.v1beta1.TrainingPipeline.state]
     * is set to `CANCELLED`.
     */
    cancelTrainingPipeline: {
      name: "CancelTrainingPipeline",
      requestType: CancelTrainingPipelineRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              70,
              58,
              1,
              42,
              34,
              65,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              116,
              114,
              97,
              105,
              110,
              105,
              110,
              103,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
        },
      },
    },
    /** Creates a PipelineJob. A PipelineJob will run immediately when created. */
    createPipelineJob: {
      name: "CreatePipelineJob",
      requestType: CreatePipelineJobRequest,
      requestStream: false,
      responseType: PipelineJob,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              35,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              95,
              106,
              111,
              98,
              44,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              95,
              106,
              111,
              98,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              69,
              58,
              12,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              95,
              106,
              111,
              98,
              34,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets a PipelineJob. */
    getPipelineJob: {
      name: "GetPipelineJob",
      requestType: GetPipelineJobRequest,
      requestStream: false,
      responseType: PipelineJob,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              55,
              18,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists PipelineJobs in a Location. */
    listPipelineJobs: {
      name: "ListPipelineJobs",
      requestType: ListPipelineJobsRequest,
      requestStream: false,
      responseType: ListPipelineJobsResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              55,
              18,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
            ]),
          ],
        },
      },
    },
    /** Deletes a PipelineJob. */
    deletePipelineJob: {
      name: "DeletePipelineJob",
      requestType: DeletePipelineJobRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              55,
              42,
              53,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Batch deletes PipelineJobs
     * The Operation is atomic. If it fails, none of the PipelineJobs are deleted.
     * If it succeeds, all of the PipelineJobs are deleted.
     */
    batchDeletePipelineJobs: {
      name: "BatchDeletePipelineJobs",
      requestType: BatchDeletePipelineJobsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              58,
              10,
              31,
              66,
              97,
              116,
              99,
              104,
              68,
              101,
              108,
              101,
              116,
              101,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([12, 112, 97, 114, 101, 110, 116, 44, 110, 97, 109, 101, 115])],
          578365826: [
            Buffer.from([
              70,
              58,
              1,
              42,
              34,
              65,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              68,
              101,
              108,
              101,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /**
     * Cancels a PipelineJob.
     * Starts asynchronous cancellation on the PipelineJob. The server
     * makes a best effort to cancel the pipeline, but success is not
     * guaranteed. Clients can use
     * [PipelineService.GetPipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.GetPipelineJob]
     * or other methods to check whether the cancellation succeeded or whether the
     * pipeline completed despite cancellation. On successful cancellation,
     * the PipelineJob is not deleted; instead it becomes a pipeline with
     * a [PipelineJob.error][google.cloud.aiplatform.v1beta1.PipelineJob.error]
     * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
     * corresponding to `Code.CANCELLED`, and
     * [PipelineJob.state][google.cloud.aiplatform.v1beta1.PipelineJob.state] is
     * set to `CANCELLED`.
     */
    cancelPipelineJob: {
      name: "CancelPipelineJob",
      requestType: CancelPipelineJobRequest,
      requestStream: false,
      responseType: Empty,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              65,
              58,
              1,
              42,
              34,
              60,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              47,
              42,
              125,
              58,
              99,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
        },
      },
    },
    /**
     * Batch cancel PipelineJobs.
     * Firstly the server will check if all the jobs are in non-terminal states,
     * and skip the jobs that are already terminated.
     * If the operation failed, none of the pipeline jobs are cancelled.
     * The server will poll the states of all the pipeline jobs periodically
     * to check the cancellation status.
     * This operation will return an LRO.
     */
    batchCancelPipelineJobs: {
      name: "BatchCancelPipelineJobs",
      requestType: BatchCancelPipelineJobsRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              75,
              10,
              31,
              66,
              97,
              116,
              99,
              104,
              67,
              97,
              110,
              99,
              101,
              108,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              40,
              66,
              97,
              116,
              99,
              104,
              67,
              97,
              110,
              99,
              101,
              108,
              80,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([12, 112, 97, 114, 101, 110, 116, 44, 110, 97, 109, 101, 115])],
          578365826: [
            Buffer.from([
              70,
              58,
              1,
              42,
              34,
              65,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              112,
              105,
              112,
              101,
              108,
              105,
              110,
              101,
              74,
              111,
              98,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              67,
              97,
              110,
              99,
              101,
              108,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface PipelineServiceImplementation<CallContextExt = {}> {
  /**
   * Creates a TrainingPipeline. A created TrainingPipeline right away will be
   * attempted to be run.
   */
  createTrainingPipeline(
    request: CreateTrainingPipelineRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TrainingPipeline>>;
  /** Gets a TrainingPipeline. */
  getTrainingPipeline(
    request: GetTrainingPipelineRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<TrainingPipeline>>;
  /** Lists TrainingPipelines in a Location. */
  listTrainingPipelines(
    request: ListTrainingPipelinesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListTrainingPipelinesResponse>>;
  /** Deletes a TrainingPipeline. */
  deleteTrainingPipeline(
    request: DeleteTrainingPipelineRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Cancels a TrainingPipeline.
   * Starts asynchronous cancellation on the TrainingPipeline. The server
   * makes a best effort to cancel the pipeline, but success is not
   * guaranteed. Clients can use
   * [PipelineService.GetTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.GetTrainingPipeline]
   * or other methods to check whether the cancellation succeeded or whether the
   * pipeline completed despite cancellation. On successful cancellation,
   * the TrainingPipeline is not deleted; instead it becomes a pipeline with
   * a
   * [TrainingPipeline.error][google.cloud.aiplatform.v1beta1.TrainingPipeline.error]
   * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
   * corresponding to `Code.CANCELLED`, and
   * [TrainingPipeline.state][google.cloud.aiplatform.v1beta1.TrainingPipeline.state]
   * is set to `CANCELLED`.
   */
  cancelTrainingPipeline(
    request: CancelTrainingPipelineRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /** Creates a PipelineJob. A PipelineJob will run immediately when created. */
  createPipelineJob(
    request: CreatePipelineJobRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<PipelineJob>>;
  /** Gets a PipelineJob. */
  getPipelineJob(
    request: GetPipelineJobRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<PipelineJob>>;
  /** Lists PipelineJobs in a Location. */
  listPipelineJobs(
    request: ListPipelineJobsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListPipelineJobsResponse>>;
  /** Deletes a PipelineJob. */
  deletePipelineJob(
    request: DeletePipelineJobRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Batch deletes PipelineJobs
   * The Operation is atomic. If it fails, none of the PipelineJobs are deleted.
   * If it succeeds, all of the PipelineJobs are deleted.
   */
  batchDeletePipelineJobs(
    request: BatchDeletePipelineJobsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Cancels a PipelineJob.
   * Starts asynchronous cancellation on the PipelineJob. The server
   * makes a best effort to cancel the pipeline, but success is not
   * guaranteed. Clients can use
   * [PipelineService.GetPipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.GetPipelineJob]
   * or other methods to check whether the cancellation succeeded or whether the
   * pipeline completed despite cancellation. On successful cancellation,
   * the PipelineJob is not deleted; instead it becomes a pipeline with
   * a [PipelineJob.error][google.cloud.aiplatform.v1beta1.PipelineJob.error]
   * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
   * corresponding to `Code.CANCELLED`, and
   * [PipelineJob.state][google.cloud.aiplatform.v1beta1.PipelineJob.state] is
   * set to `CANCELLED`.
   */
  cancelPipelineJob(
    request: CancelPipelineJobRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Empty>>;
  /**
   * Batch cancel PipelineJobs.
   * Firstly the server will check if all the jobs are in non-terminal states,
   * and skip the jobs that are already terminated.
   * If the operation failed, none of the pipeline jobs are cancelled.
   * The server will poll the states of all the pipeline jobs periodically
   * to check the cancellation status.
   * This operation will return an LRO.
   */
  batchCancelPipelineJobs(
    request: BatchCancelPipelineJobsRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
}

export interface PipelineServiceClient<CallOptionsExt = {}> {
  /**
   * Creates a TrainingPipeline. A created TrainingPipeline right away will be
   * attempted to be run.
   */
  createTrainingPipeline(
    request: DeepPartial<CreateTrainingPipelineRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TrainingPipeline>;
  /** Gets a TrainingPipeline. */
  getTrainingPipeline(
    request: DeepPartial<GetTrainingPipelineRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<TrainingPipeline>;
  /** Lists TrainingPipelines in a Location. */
  listTrainingPipelines(
    request: DeepPartial<ListTrainingPipelinesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListTrainingPipelinesResponse>;
  /** Deletes a TrainingPipeline. */
  deleteTrainingPipeline(
    request: DeepPartial<DeleteTrainingPipelineRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Cancels a TrainingPipeline.
   * Starts asynchronous cancellation on the TrainingPipeline. The server
   * makes a best effort to cancel the pipeline, but success is not
   * guaranteed. Clients can use
   * [PipelineService.GetTrainingPipeline][google.cloud.aiplatform.v1beta1.PipelineService.GetTrainingPipeline]
   * or other methods to check whether the cancellation succeeded or whether the
   * pipeline completed despite cancellation. On successful cancellation,
   * the TrainingPipeline is not deleted; instead it becomes a pipeline with
   * a
   * [TrainingPipeline.error][google.cloud.aiplatform.v1beta1.TrainingPipeline.error]
   * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
   * corresponding to `Code.CANCELLED`, and
   * [TrainingPipeline.state][google.cloud.aiplatform.v1beta1.TrainingPipeline.state]
   * is set to `CANCELLED`.
   */
  cancelTrainingPipeline(
    request: DeepPartial<CancelTrainingPipelineRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /** Creates a PipelineJob. A PipelineJob will run immediately when created. */
  createPipelineJob(
    request: DeepPartial<CreatePipelineJobRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<PipelineJob>;
  /** Gets a PipelineJob. */
  getPipelineJob(
    request: DeepPartial<GetPipelineJobRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<PipelineJob>;
  /** Lists PipelineJobs in a Location. */
  listPipelineJobs(
    request: DeepPartial<ListPipelineJobsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListPipelineJobsResponse>;
  /** Deletes a PipelineJob. */
  deletePipelineJob(
    request: DeepPartial<DeletePipelineJobRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Batch deletes PipelineJobs
   * The Operation is atomic. If it fails, none of the PipelineJobs are deleted.
   * If it succeeds, all of the PipelineJobs are deleted.
   */
  batchDeletePipelineJobs(
    request: DeepPartial<BatchDeletePipelineJobsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Cancels a PipelineJob.
   * Starts asynchronous cancellation on the PipelineJob. The server
   * makes a best effort to cancel the pipeline, but success is not
   * guaranteed. Clients can use
   * [PipelineService.GetPipelineJob][google.cloud.aiplatform.v1beta1.PipelineService.GetPipelineJob]
   * or other methods to check whether the cancellation succeeded or whether the
   * pipeline completed despite cancellation. On successful cancellation,
   * the PipelineJob is not deleted; instead it becomes a pipeline with
   * a [PipelineJob.error][google.cloud.aiplatform.v1beta1.PipelineJob.error]
   * value with a [google.rpc.Status.code][google.rpc.Status.code] of 1,
   * corresponding to `Code.CANCELLED`, and
   * [PipelineJob.state][google.cloud.aiplatform.v1beta1.PipelineJob.state] is
   * set to `CANCELLED`.
   */
  cancelPipelineJob(
    request: DeepPartial<CancelPipelineJobRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Empty>;
  /**
   * Batch cancel PipelineJobs.
   * Firstly the server will check if all the jobs are in non-terminal states,
   * and skip the jobs that are already terminated.
   * If the operation failed, none of the pipeline jobs are cancelled.
   * The server will poll the states of all the pipeline jobs periodically
   * to check the cancellation status.
   * This operation will return an LRO.
   */
  batchCancelPipelineJobs(
    request: DeepPartial<BatchCancelPipelineJobsRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
