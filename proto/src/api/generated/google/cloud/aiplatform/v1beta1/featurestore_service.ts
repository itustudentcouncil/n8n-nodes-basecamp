// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/featurestore_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { type CallContext, type CallOptions } from "nice-grpc-common";
import { Operation } from "../../../longrunning/operations.js";
import { FieldMask } from "../../../protobuf/field_mask.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Interval } from "../../../type/interval.js";
import { EntityType } from "./entity_type.js";
import { Feature } from "./feature.js";
import { FeatureSelector } from "./feature_selector.js";
import { Featurestore } from "./featurestore.js";
import {
  AvroSource,
  BigQueryDestination,
  BigQuerySource,
  CsvDestination,
  CsvSource,
  TFRecordDestination,
} from "./io.js";
import { GenericOperationMetadata } from "./operation.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/**
 * Request message for
 * [FeaturestoreService.CreateFeaturestore][google.cloud.aiplatform.v1beta1.FeaturestoreService.CreateFeaturestore].
 */
export interface CreateFeaturestoreRequest {
  /**
   * Required. The resource name of the Location to create Featurestores.
   * Format:
   * `projects/{project}/locations/{location}`
   */
  parent: string;
  /** Required. The Featurestore to create. */
  featurestore:
    | Featurestore
    | undefined;
  /**
   * Required. The ID to use for this Featurestore, which will become the final
   * component of the Featurestore's resource name.
   *
   * This value may be up to 60 characters, and valid characters are
   * `[a-z0-9_]`. The first character cannot be a number.
   *
   * The value must be unique within the project and location.
   */
  featurestoreId: string;
}

/**
 * Request message for
 * [FeaturestoreService.GetFeaturestore][google.cloud.aiplatform.v1beta1.FeaturestoreService.GetFeaturestore].
 */
export interface GetFeaturestoreRequest {
  /** Required. The name of the Featurestore resource. */
  name: string;
}

/**
 * Request message for
 * [FeaturestoreService.ListFeaturestores][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeaturestores].
 */
export interface ListFeaturestoresRequest {
  /**
   * Required. The resource name of the Location to list Featurestores.
   * Format:
   * `projects/{project}/locations/{location}`
   */
  parent: string;
  /**
   * Lists the featurestores that match the filter expression. The following
   * fields are supported:
   *
   * * `create_time`: Supports `=`, `!=`, `<`, `>`, `<=`, and `>=` comparisons.
   * Values must be
   *   in RFC 3339 format.
   * * `update_time`: Supports `=`, `!=`, `<`, `>`, `<=`, and `>=` comparisons.
   * Values must be
   *   in RFC 3339 format.
   * * `online_serving_config.fixed_node_count`: Supports `=`, `!=`, `<`, `>`,
   * `<=`, and `>=` comparisons.
   * * `labels`: Supports key-value equality and key presence.
   *
   * Examples:
   *
   * * `create_time > "2020-01-01" OR update_time > "2020-01-01"`
   *    Featurestores created or updated after 2020-01-01.
   * * `labels.env = "prod"`
   *    Featurestores with label "env" set to "prod".
   */
  filter: string;
  /**
   * The maximum number of Featurestores to return. The service may return fewer
   * than this value. If unspecified, at most 100 Featurestores will be
   * returned. The maximum value is 100; any value greater than 100 will be
   * coerced to 100.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [FeaturestoreService.ListFeaturestores][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeaturestores]
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [FeaturestoreService.ListFeaturestores][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeaturestores]
   * must match the call that provided the page token.
   */
  pageToken: string;
  /**
   * A comma-separated list of fields to order by, sorted in ascending order.
   * Use "desc" after a field name for descending.
   * Supported Fields:
   *
   *   * `create_time`
   *   * `update_time`
   *   * `online_serving_config.fixed_node_count`
   */
  orderBy: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [FeaturestoreService.ListFeaturestores][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeaturestores].
 */
export interface ListFeaturestoresResponse {
  /** The Featurestores matching the request. */
  featurestores: Featurestore[];
  /**
   * A token, which can be sent as
   * [ListFeaturestoresRequest.page_token][google.cloud.aiplatform.v1beta1.ListFeaturestoresRequest.page_token]
   * to retrieve the next page. If this field is omitted, there are no
   * subsequent pages.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [FeaturestoreService.UpdateFeaturestore][google.cloud.aiplatform.v1beta1.FeaturestoreService.UpdateFeaturestore].
 */
export interface UpdateFeaturestoreRequest {
  /**
   * Required. The Featurestore's `name` field is used to identify the
   * Featurestore to be updated. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}`
   */
  featurestore:
    | Featurestore
    | undefined;
  /**
   * Field mask is used to specify the fields to be overwritten in the
   * Featurestore resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then only the non-empty fields present in the
   * request will be overwritten. Set the update_mask to `*` to override all
   * fields.
   *
   * Updatable fields:
   *
   *   * `labels`
   *   * `online_serving_config.fixed_node_count`
   *   * `online_serving_config.scaling`
   *   * `online_storage_ttl_days`
   */
  updateMask: string[] | undefined;
}

/**
 * Request message for
 * [FeaturestoreService.DeleteFeaturestore][google.cloud.aiplatform.v1beta1.FeaturestoreService.DeleteFeaturestore].
 */
export interface DeleteFeaturestoreRequest {
  /**
   * Required. The name of the Featurestore to be deleted.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}`
   */
  name: string;
  /**
   * If set to true, any EntityTypes and Features for this Featurestore will
   * also be deleted. (Otherwise, the request will only work if the Featurestore
   * has no EntityTypes.)
   */
  force: boolean;
}

/**
 * Request message for
 * [FeaturestoreService.ImportFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.ImportFeatureValues].
 */
export interface ImportFeatureValuesRequest {
  avroSource?: AvroSource | undefined;
  bigquerySource?: BigQuerySource | undefined;
  csvSource?:
    | CsvSource
    | undefined;
  /**
   * Source column that holds the Feature timestamp for all Feature
   * values in each entity.
   */
  featureTimeField?:
    | string
    | undefined;
  /**
   * Single Feature timestamp for all entities being imported. The
   * timestamp must not have higher than millisecond precision.
   */
  featureTime?:
    | Date
    | undefined;
  /**
   * Required. The resource name of the EntityType grouping the Features for
   * which values are being imported. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entityType}`
   */
  entityType: string;
  /**
   * Source column that holds entity IDs. If not provided, entity IDs are
   * extracted from the column named entity_id.
   */
  entityIdField: string;
  /**
   * Required. Specifications defining which Feature values to import from the
   * entity. The request fails if no feature_specs are provided, and having
   * multiple feature_specs for one Feature is not allowed.
   */
  featureSpecs: ImportFeatureValuesRequest_FeatureSpec[];
  /**
   * If set, data will not be imported for online serving. This
   * is typically used for backfilling, where Feature generation timestamps are
   * not in the timestamp range needed for online serving.
   */
  disableOnlineServing: boolean;
  /**
   * Specifies the number of workers that are used to write data to the
   * Featurestore. Consider the online serving capacity that you require to
   * achieve the desired import throughput without interfering with online
   * serving. The value must be positive, and less than or equal to 100.
   * If not set, defaults to using 1 worker. The low count ensures minimal
   * impact on online serving performance.
   */
  workerCount: number;
  /** If true, API doesn't start ingestion analysis pipeline. */
  disableIngestionAnalysis: boolean;
}

/** Defines the Feature value(s) to import. */
export interface ImportFeatureValuesRequest_FeatureSpec {
  /**
   * Required. ID of the Feature to import values of. This Feature must exist
   * in the target EntityType, or the request will fail.
   */
  id: string;
  /**
   * Source column to get the Feature values from. If not set, uses the column
   * with the same name as the Feature ID.
   */
  sourceField: string;
}

/**
 * Response message for
 * [FeaturestoreService.ImportFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.ImportFeatureValues].
 */
export interface ImportFeatureValuesResponse {
  /** Number of entities that have been imported by the operation. */
  importedEntityCount: Long;
  /** Number of Feature values that have been imported by the operation. */
  importedFeatureValueCount: Long;
  /**
   * The number of rows in input source that weren't imported due to either
   * * Not having any featureValues.
   * * Having a null entityId.
   * * Having a null timestamp.
   * * Not being parsable (applicable for CSV sources).
   */
  invalidRowCount: Long;
  /**
   * The number rows that weren't ingested due to having feature timestamps
   * outside the retention boundary.
   */
  timestampOutsideRetentionRowsCount: Long;
}

/**
 * Request message for
 * [FeaturestoreService.BatchReadFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.BatchReadFeatureValues].
 */
export interface BatchReadFeatureValuesRequest {
  /**
   * Each read instance consists of exactly one read timestamp and one or more
   * entity IDs identifying entities of the corresponding EntityTypes whose
   * Features are requested.
   *
   * Each output instance contains Feature values of requested entities
   * concatenated together as of the read time.
   *
   * An example read instance may be `foo_entity_id, bar_entity_id,
   * 2020-01-01T10:00:00.123Z`.
   *
   * An example output instance may be `foo_entity_id, bar_entity_id,
   * 2020-01-01T10:00:00.123Z, foo_entity_feature1_value,
   * bar_entity_feature2_value`.
   *
   * Timestamp in each read instance must be millisecond-aligned.
   *
   * `csv_read_instances` are read instances stored in a plain-text CSV file.
   * The header should be:
   *     [ENTITY_TYPE_ID1], [ENTITY_TYPE_ID2], ..., timestamp
   *
   * The columns can be in any order.
   *
   * Values in the timestamp column must use the RFC 3339 format, e.g.
   * `2012-07-30T10:43:17.123Z`.
   */
  csvReadInstances?:
    | CsvSource
    | undefined;
  /** Similar to csv_read_instances, but from BigQuery source. */
  bigqueryReadInstances?:
    | BigQuerySource
    | undefined;
  /**
   * Required. The resource name of the Featurestore from which to query Feature
   * values. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}`
   */
  featurestore: string;
  /** Required. Specifies output location and format. */
  destination:
    | FeatureValueDestination
    | undefined;
  /**
   * When not empty, the specified fields in the *_read_instances source will be
   * joined as-is in the output, in addition to those fields from the
   * Featurestore Entity.
   *
   * For BigQuery source, the type of the pass-through values will be
   * automatically inferred. For CSV source, the pass-through values will be
   * passed as opaque bytes.
   */
  passThroughFields: BatchReadFeatureValuesRequest_PassThroughField[];
  /**
   * Required. Specifies EntityType grouping Features to read values of and
   * settings.
   */
  entityTypeSpecs: BatchReadFeatureValuesRequest_EntityTypeSpec[];
  /**
   * Optional. Excludes Feature values with feature generation timestamp before
   * this timestamp. If not set, retrieve oldest values kept in Feature Store.
   * Timestamp, if present, must not have higher than millisecond precision.
   */
  startTime: Date | undefined;
}

/** Describe pass-through fields in read_instance source. */
export interface BatchReadFeatureValuesRequest_PassThroughField {
  /**
   * Required. The name of the field in the CSV header or the name of the
   * column in BigQuery table. The naming restriction is the same as
   * [Feature.name][google.cloud.aiplatform.v1beta1.Feature.name].
   */
  fieldName: string;
}

/**
 * Selects Features of an EntityType to read values of and specifies read
 * settings.
 */
export interface BatchReadFeatureValuesRequest_EntityTypeSpec {
  /**
   * Required. ID of the EntityType to select Features. The EntityType id is
   * the
   * [entity_type_id][google.cloud.aiplatform.v1beta1.CreateEntityTypeRequest.entity_type_id]
   * specified during EntityType creation.
   */
  entityTypeId: string;
  /**
   * Required. Selectors choosing which Feature values to read from the
   * EntityType.
   */
  featureSelector:
    | FeatureSelector
    | undefined;
  /** Per-Feature settings for the batch read. */
  settings: DestinationFeatureSetting[];
}

/**
 * Request message for
 * [FeaturestoreService.ExportFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.ExportFeatureValues].
 */
export interface ExportFeatureValuesRequest {
  /**
   * Exports the latest Feature values of all entities of the EntityType
   * within a time range.
   */
  snapshotExport?:
    | ExportFeatureValuesRequest_SnapshotExport
    | undefined;
  /**
   * Exports all historical values of all entities of the EntityType within a
   * time range
   */
  fullExport?:
    | ExportFeatureValuesRequest_FullExport
    | undefined;
  /**
   * Required. The resource name of the EntityType from which to export Feature
   * values. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   */
  entityType: string;
  /** Required. Specifies destination location and format. */
  destination:
    | FeatureValueDestination
    | undefined;
  /** Required. Selects Features to export values of. */
  featureSelector:
    | FeatureSelector
    | undefined;
  /** Per-Feature export settings. */
  settings: DestinationFeatureSetting[];
}

/**
 * Describes exporting the latest Feature values of all entities of the
 * EntityType between [start_time, snapshot_time].
 */
export interface ExportFeatureValuesRequest_SnapshotExport {
  /**
   * Exports Feature values as of this timestamp. If not set,
   * retrieve values as of now. Timestamp, if present, must not have higher
   * than millisecond precision.
   */
  snapshotTime:
    | Date
    | undefined;
  /**
   * Excludes Feature values with feature generation timestamp before this
   * timestamp. If not set, retrieve oldest values kept in Feature Store.
   * Timestamp, if present, must not have higher than millisecond precision.
   */
  startTime: Date | undefined;
}

/**
 * Describes exporting all historical Feature values of all entities of the
 * EntityType between [start_time, end_time].
 */
export interface ExportFeatureValuesRequest_FullExport {
  /**
   * Excludes Feature values with feature generation timestamp before this
   * timestamp. If not set, retrieve oldest values kept in Feature Store.
   * Timestamp, if present, must not have higher than millisecond precision.
   */
  startTime:
    | Date
    | undefined;
  /**
   * Exports Feature values as of this timestamp. If not set,
   * retrieve values as of now. Timestamp, if present, must not have higher
   * than millisecond precision.
   */
  endTime: Date | undefined;
}

export interface DestinationFeatureSetting {
  /** Required. The ID of the Feature to apply the setting to. */
  featureId: string;
  /**
   * Specify the field name in the export destination. If not specified,
   * Feature ID is used.
   */
  destinationField: string;
}

/** A destination location for Feature values and format. */
export interface FeatureValueDestination {
  /**
   * Output in BigQuery format.
   * [BigQueryDestination.output_uri][google.cloud.aiplatform.v1beta1.BigQueryDestination.output_uri]
   * in
   * [FeatureValueDestination.bigquery_destination][google.cloud.aiplatform.v1beta1.FeatureValueDestination.bigquery_destination]
   * must refer to a table.
   */
  bigqueryDestination?:
    | BigQueryDestination
    | undefined;
  /**
   * Output in TFRecord format.
   *
   * Below are the mapping from Feature value type
   * in Featurestore to Feature value type in TFRecord:
   *
   *     Value type in Featurestore                 | Value type in TFRecord
   *     DOUBLE, DOUBLE_ARRAY                       | FLOAT_LIST
   *     INT64, INT64_ARRAY                         | INT64_LIST
   *     STRING, STRING_ARRAY, BYTES                | BYTES_LIST
   *     true -> byte_string("true"), false -> byte_string("false")
   *     BOOL, BOOL_ARRAY (true, false)             | BYTES_LIST
   */
  tfrecordDestination?:
    | TFRecordDestination
    | undefined;
  /**
   * Output in CSV format. Array Feature value types are not allowed in CSV
   * format.
   */
  csvDestination?: CsvDestination | undefined;
}

/**
 * Response message for
 * [FeaturestoreService.ExportFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.ExportFeatureValues].
 */
export interface ExportFeatureValuesResponse {
}

/**
 * Response message for
 * [FeaturestoreService.BatchReadFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.BatchReadFeatureValues].
 */
export interface BatchReadFeatureValuesResponse {
}

/**
 * Request message for
 * [FeaturestoreService.CreateEntityType][google.cloud.aiplatform.v1beta1.FeaturestoreService.CreateEntityType].
 */
export interface CreateEntityTypeRequest {
  /**
   * Required. The resource name of the Featurestore to create EntityTypes.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}`
   */
  parent: string;
  /** The EntityType to create. */
  entityType:
    | EntityType
    | undefined;
  /**
   * Required. The ID to use for the EntityType, which will become the final
   * component of the EntityType's resource name.
   *
   * This value may be up to 60 characters, and valid characters are
   * `[a-z0-9_]`. The first character cannot be a number.
   *
   * The value must be unique within a featurestore.
   */
  entityTypeId: string;
}

/**
 * Request message for
 * [FeaturestoreService.GetEntityType][google.cloud.aiplatform.v1beta1.FeaturestoreService.GetEntityType].
 */
export interface GetEntityTypeRequest {
  /**
   * Required. The name of the EntityType resource.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   */
  name: string;
}

/**
 * Request message for
 * [FeaturestoreService.ListEntityTypes][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListEntityTypes].
 */
export interface ListEntityTypesRequest {
  /**
   * Required. The resource name of the Featurestore to list EntityTypes.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}`
   */
  parent: string;
  /**
   * Lists the EntityTypes that match the filter expression. The following
   * filters are supported:
   *
   * * `create_time`: Supports `=`, `!=`, `<`, `>`, `>=`, and `<=` comparisons.
   * Values must be in RFC 3339 format.
   * * `update_time`: Supports `=`, `!=`, `<`, `>`, `>=`, and `<=` comparisons.
   * Values must be in RFC 3339 format.
   * * `labels`: Supports key-value equality as well as key presence.
   *
   * Examples:
   *
   * * `create_time > \"2020-01-31T15:30:00.000000Z\" OR
   *      update_time > \"2020-01-31T15:30:00.000000Z\"` --> EntityTypes created
   *      or updated after 2020-01-31T15:30:00.000000Z.
   * * `labels.active = yes AND labels.env = prod` --> EntityTypes having both
   *     (active: yes) and (env: prod) labels.
   * * `labels.env: *` --> Any EntityType which has a label with 'env' as the
   *   key.
   */
  filter: string;
  /**
   * The maximum number of EntityTypes to return. The service may return fewer
   * than this value. If unspecified, at most 1000 EntityTypes will be returned.
   * The maximum value is 1000; any value greater than 1000 will be coerced to
   * 1000.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [FeaturestoreService.ListEntityTypes][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListEntityTypes]
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [FeaturestoreService.ListEntityTypes][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListEntityTypes]
   * must match the call that provided the page token.
   */
  pageToken: string;
  /**
   * A comma-separated list of fields to order by, sorted in ascending order.
   * Use "desc" after a field name for descending.
   *
   * Supported fields:
   *
   *   * `entity_type_id`
   *   * `create_time`
   *   * `update_time`
   */
  orderBy: string;
  /** Mask specifying which fields to read. */
  readMask: string[] | undefined;
}

/**
 * Response message for
 * [FeaturestoreService.ListEntityTypes][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListEntityTypes].
 */
export interface ListEntityTypesResponse {
  /** The EntityTypes matching the request. */
  entityTypes: EntityType[];
  /**
   * A token, which can be sent as
   * [ListEntityTypesRequest.page_token][google.cloud.aiplatform.v1beta1.ListEntityTypesRequest.page_token]
   * to retrieve the next page. If this field is omitted, there are no
   * subsequent pages.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [FeaturestoreService.UpdateEntityType][google.cloud.aiplatform.v1beta1.FeaturestoreService.UpdateEntityType].
 */
export interface UpdateEntityTypeRequest {
  /**
   * Required. The EntityType's `name` field is used to identify the EntityType
   * to be updated. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   */
  entityType:
    | EntityType
    | undefined;
  /**
   * Field mask is used to specify the fields to be overwritten in the
   * EntityType resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then only the non-empty fields present in the
   * request will be overwritten. Set the update_mask to `*` to override all
   * fields.
   *
   * Updatable fields:
   *
   *   * `description`
   *   * `labels`
   *   * `monitoring_config.snapshot_analysis.disabled`
   *   * `monitoring_config.snapshot_analysis.monitoring_interval_days`
   *   * `monitoring_config.snapshot_analysis.staleness_days`
   *   * `monitoring_config.import_features_analysis.state`
   *   * `monitoring_config.import_features_analysis.anomaly_detection_baseline`
   *   * `monitoring_config.numerical_threshold_config.value`
   *   * `monitoring_config.categorical_threshold_config.value`
   *   * `offline_storage_ttl_days`
   */
  updateMask: string[] | undefined;
}

/** Request message for [FeaturestoreService.DeleteEntityTypes][]. */
export interface DeleteEntityTypeRequest {
  /**
   * Required. The name of the EntityType to be deleted.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   */
  name: string;
  /**
   * If set to true, any Features for this EntityType will also be deleted.
   * (Otherwise, the request will only work if the EntityType has no Features.)
   */
  force: boolean;
}

/**
 * Request message for
 * [FeaturestoreService.CreateFeature][google.cloud.aiplatform.v1beta1.FeaturestoreService.CreateFeature].
 * Request message for
 * [FeatureRegistryService.CreateFeature][google.cloud.aiplatform.v1beta1.FeatureRegistryService.CreateFeature].
 */
export interface CreateFeatureRequest {
  /**
   * Required. The resource name of the EntityType or FeatureGroup to create a
   * Feature. Format for entity_type as parent:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   * Format for feature_group as parent:
   * `projects/{project}/locations/{location}/featureGroups/{feature_group}`
   */
  parent: string;
  /** Required. The Feature to create. */
  feature:
    | Feature
    | undefined;
  /**
   * Required. The ID to use for the Feature, which will become the final
   * component of the Feature's resource name.
   *
   * This value may be up to 128 characters, and valid characters are
   * `[a-z0-9_]`. The first character cannot be a number.
   *
   * The value must be unique within an EntityType/FeatureGroup.
   */
  featureId: string;
}

/**
 * Request message for
 * [FeaturestoreService.BatchCreateFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.BatchCreateFeatures].
 */
export interface BatchCreateFeaturesRequest {
  /**
   * Required. The resource name of the EntityType to create the batch of
   * Features under. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   */
  parent: string;
  /**
   * Required. The request message specifying the Features to create. All
   * Features must be created under the same parent EntityType. The `parent`
   * field in each child request message can be omitted. If `parent` is set in a
   * child request, then the value must match the `parent` value in this request
   * message.
   */
  requests: CreateFeatureRequest[];
}

/**
 * Response message for
 * [FeaturestoreService.BatchCreateFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.BatchCreateFeatures].
 */
export interface BatchCreateFeaturesResponse {
  /** The Features created. */
  features: Feature[];
}

/**
 * Request message for
 * [FeaturestoreService.GetFeature][google.cloud.aiplatform.v1beta1.FeaturestoreService.GetFeature].
 * Request message for
 * [FeatureRegistryService.GetFeature][google.cloud.aiplatform.v1beta1.FeatureRegistryService.GetFeature].
 */
export interface GetFeatureRequest {
  /**
   * Required. The name of the Feature resource.
   * Format for entity_type as parent:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   * Format for feature_group as parent:
   * `projects/{project}/locations/{location}/featureGroups/{feature_group}`
   */
  name: string;
}

/**
 * Request message for
 * [FeaturestoreService.ListFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeatures].
 * Request message for
 * [FeatureRegistryService.ListFeatures][google.cloud.aiplatform.v1beta1.FeatureRegistryService.ListFeatures].
 */
export interface ListFeaturesRequest {
  /**
   * Required. The resource name of the Location to list Features.
   * Format for entity_type as parent:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}`
   * Format for feature_group as parent:
   * `projects/{project}/locations/{location}/featureGroups/{feature_group}`
   */
  parent: string;
  /**
   * Lists the Features that match the filter expression. The following
   * filters are supported:
   *
   * * `value_type`: Supports = and != comparisons.
   * * `create_time`: Supports =, !=, <, >, >=, and <= comparisons. Values must
   * be in RFC 3339 format.
   * * `update_time`: Supports =, !=, <, >, >=, and <= comparisons. Values must
   * be in RFC 3339 format.
   * * `labels`: Supports key-value equality as well as key presence.
   *
   * Examples:
   *
   * * `value_type = DOUBLE` --> Features whose type is DOUBLE.
   * * `create_time > \"2020-01-31T15:30:00.000000Z\" OR
   *      update_time > \"2020-01-31T15:30:00.000000Z\"` --> EntityTypes created
   *      or updated after 2020-01-31T15:30:00.000000Z.
   * * `labels.active = yes AND labels.env = prod` --> Features having both
   *     (active: yes) and (env: prod) labels.
   * * `labels.env: *` --> Any Feature which has a label with 'env' as the
   *   key.
   */
  filter: string;
  /**
   * The maximum number of Features to return. The service may return fewer
   * than this value. If unspecified, at most 1000 Features will be returned.
   * The maximum value is 1000; any value greater than 1000 will be coerced to
   * 1000.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [FeaturestoreService.ListFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeatures]
   * call or
   * [FeatureRegistryService.ListFeatures][google.cloud.aiplatform.v1beta1.FeatureRegistryService.ListFeatures]
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [FeaturestoreService.ListFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeatures]
   * or
   * [FeatureRegistryService.ListFeatures][google.cloud.aiplatform.v1beta1.FeatureRegistryService.ListFeatures]
   * must match the call that provided the page token.
   */
  pageToken: string;
  /**
   * A comma-separated list of fields to order by, sorted in ascending order.
   * Use "desc" after a field name for descending.
   * Supported fields:
   *
   *   * `feature_id`
   *   * `value_type` (Not supported for FeatureRegistry Feature)
   *   * `create_time`
   *   * `update_time`
   */
  orderBy: string;
  /** Mask specifying which fields to read. */
  readMask:
    | string[]
    | undefined;
  /**
   * Only applicable for Vertex AI Feature Store (Legacy).
   * If set, return the most recent
   * [ListFeaturesRequest.latest_stats_count][google.cloud.aiplatform.v1beta1.ListFeaturesRequest.latest_stats_count]
   * of stats for each Feature in response. Valid value is [0, 10]. If number of
   * stats exists <
   * [ListFeaturesRequest.latest_stats_count][google.cloud.aiplatform.v1beta1.ListFeaturesRequest.latest_stats_count],
   * return all existing stats.
   */
  latestStatsCount: number;
}

/**
 * Response message for
 * [FeaturestoreService.ListFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeatures].
 * Response message for
 * [FeatureRegistryService.ListFeatures][google.cloud.aiplatform.v1beta1.FeatureRegistryService.ListFeatures].
 */
export interface ListFeaturesResponse {
  /** The Features matching the request. */
  features: Feature[];
  /**
   * A token, which can be sent as
   * [ListFeaturesRequest.page_token][google.cloud.aiplatform.v1beta1.ListFeaturesRequest.page_token]
   * to retrieve the next page. If this field is omitted, there are no
   * subsequent pages.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [FeaturestoreService.SearchFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.SearchFeatures].
 */
export interface SearchFeaturesRequest {
  /**
   * Required. The resource name of the Location to search Features.
   * Format:
   * `projects/{project}/locations/{location}`
   */
  location: string;
  /**
   * Query string that is a conjunction of field-restricted queries and/or
   * field-restricted filters.  Field-restricted queries and filters can be
   * combined using `AND` to form a conjunction.
   *
   * A field query is in the form FIELD:QUERY. This implicitly checks if QUERY
   * exists as a substring within Feature's FIELD. The QUERY
   * and the FIELD are converted to a sequence of words (i.e. tokens) for
   * comparison. This is done by:
   *
   *   * Removing leading/trailing whitespace and tokenizing the search value.
   *   Characters that are not one of alphanumeric `[a-zA-Z0-9]`, underscore
   *   `_`, or asterisk `*` are treated as delimiters for tokens. `*` is treated
   *   as a wildcard that matches characters within a token.
   *   * Ignoring case.
   *   * Prepending an asterisk to the first and appending an asterisk to the
   *   last token in QUERY.
   *
   * A QUERY must be either a singular token or a phrase. A phrase is one or
   * multiple words enclosed in double quotation marks ("). With phrases, the
   * order of the words is important. Words in the phrase must be matching in
   * order and consecutively.
   *
   * Supported FIELDs for field-restricted queries:
   *
   * * `feature_id`
   * * `description`
   * * `entity_type_id`
   *
   * Examples:
   *
   * * `feature_id: foo` --> Matches a Feature with ID containing the substring
   * `foo` (eg. `foo`, `foofeature`, `barfoo`).
   * * `feature_id: foo*feature` --> Matches a Feature with ID containing the
   * substring `foo*feature` (eg. `foobarfeature`).
   * * `feature_id: foo AND description: bar` --> Matches a Feature with ID
   * containing the substring `foo` and description containing the substring
   * `bar`.
   *
   * Besides field queries, the following exact-match filters are
   * supported. The exact-match filters do not support wildcards. Unlike
   * field-restricted queries, exact-match filters are case-sensitive.
   *
   * * `feature_id`: Supports = comparisons.
   * * `description`: Supports = comparisons. Multi-token filters should be
   * enclosed in quotes.
   * * `entity_type_id`: Supports = comparisons.
   * * `value_type`: Supports = and != comparisons.
   * * `labels`: Supports key-value equality as well as key presence.
   * * `featurestore_id`: Supports = comparisons.
   *
   * Examples:
   *
   * * `description = "foo bar"` --> Any Feature with description exactly equal
   * to `foo bar`
   * * `value_type = DOUBLE` --> Features whose type is DOUBLE.
   * * `labels.active = yes AND labels.env = prod` --> Features having both
   *     (active: yes) and (env: prod) labels.
   * * `labels.env: *` --> Any Feature which has a label with `env` as the
   *   key.
   */
  query: string;
  /**
   * The maximum number of Features to return. The service may return fewer
   * than this value. If unspecified, at most 100 Features will be returned.
   * The maximum value is 100; any value greater than 100 will be coerced to
   * 100.
   */
  pageSize: number;
  /**
   * A page token, received from a previous
   * [FeaturestoreService.SearchFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.SearchFeatures]
   * call. Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [FeaturestoreService.SearchFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.SearchFeatures],
   * except `page_size`, must match the call that provided the page token.
   */
  pageToken: string;
}

/**
 * Response message for
 * [FeaturestoreService.SearchFeatures][google.cloud.aiplatform.v1beta1.FeaturestoreService.SearchFeatures].
 */
export interface SearchFeaturesResponse {
  /**
   * The Features matching the request.
   *
   * Fields returned:
   *
   *  * `name`
   *  * `description`
   *  * `labels`
   *  * `create_time`
   *  * `update_time`
   */
  features: Feature[];
  /**
   * A token, which can be sent as
   * [SearchFeaturesRequest.page_token][google.cloud.aiplatform.v1beta1.SearchFeaturesRequest.page_token]
   * to retrieve the next page. If this field is omitted, there are no
   * subsequent pages.
   */
  nextPageToken: string;
}

/**
 * Request message for
 * [FeaturestoreService.UpdateFeature][google.cloud.aiplatform.v1beta1.FeaturestoreService.UpdateFeature].
 * Request message for
 * [FeatureRegistryService.UpdateFeature][google.cloud.aiplatform.v1beta1.FeatureRegistryService.UpdateFeature].
 */
export interface UpdateFeatureRequest {
  /**
   * Required. The Feature's `name` field is used to identify the Feature to be
   * updated.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}/features/{feature}`
   * `projects/{project}/locations/{location}/featureGroups/{feature_group}/features/{feature}`
   */
  feature:
    | Feature
    | undefined;
  /**
   * Field mask is used to specify the fields to be overwritten in the
   * Features resource by the update.
   * The fields specified in the update_mask are relative to the resource, not
   * the full request. A field will be overwritten if it is in the mask. If the
   * user does not provide a mask then only the non-empty fields present in the
   * request will be overwritten. Set the update_mask to `*` to override all
   * fields.
   *
   * Updatable fields:
   *
   *   * `description`
   *   * `labels`
   *   * `disable_monitoring` (Not supported for FeatureRegistryService Feature)
   *   * `point_of_contact` (Not supported for FeaturestoreService FeatureStore)
   */
  updateMask: string[] | undefined;
}

/**
 * Request message for
 * [FeaturestoreService.DeleteFeature][google.cloud.aiplatform.v1beta1.FeaturestoreService.DeleteFeature].
 * Request message for
 * [FeatureRegistryService.DeleteFeature][google.cloud.aiplatform.v1beta1.FeatureRegistryService.DeleteFeature].
 */
export interface DeleteFeatureRequest {
  /**
   * Required. The name of the Features to be deleted.
   * Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entity_type}/features/{feature}`
   * `projects/{project}/locations/{location}/featureGroups/{feature_group}/features/{feature}`
   */
  name: string;
}

/** Details of operations that perform create Featurestore. */
export interface CreateFeaturestoreOperationMetadata {
  /** Operation metadata for Featurestore. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that perform update Featurestore. */
export interface UpdateFeaturestoreOperationMetadata {
  /** Operation metadata for Featurestore. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that perform import Feature values. */
export interface ImportFeatureValuesOperationMetadata {
  /** Operation metadata for Featurestore import Feature values. */
  genericMetadata:
    | GenericOperationMetadata
    | undefined;
  /** Number of entities that have been imported by the operation. */
  importedEntityCount: Long;
  /** Number of Feature values that have been imported by the operation. */
  importedFeatureValueCount: Long;
  /** The source URI from where Feature values are imported. */
  sourceUris: string[];
  /**
   * The number of rows in input source that weren't imported due to either
   * * Not having any featureValues.
   * * Having a null entityId.
   * * Having a null timestamp.
   * * Not being parsable (applicable for CSV sources).
   */
  invalidRowCount: Long;
  /**
   * The number rows that weren't ingested due to having timestamps outside the
   * retention boundary.
   */
  timestampOutsideRetentionRowsCount: Long;
  /**
   * List of ImportFeatureValues operations running under a single EntityType
   * that are blocking this operation.
   */
  blockingOperationIds: Long[];
}

/** Details of operations that exports Features values. */
export interface ExportFeatureValuesOperationMetadata {
  /** Operation metadata for Featurestore export Feature values. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that batch reads Feature values. */
export interface BatchReadFeatureValuesOperationMetadata {
  /** Operation metadata for Featurestore batch read Features values. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that delete Feature values. */
export interface DeleteFeatureValuesOperationMetadata {
  /** Operation metadata for Featurestore delete Features values. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that perform create EntityType. */
export interface CreateEntityTypeOperationMetadata {
  /** Operation metadata for EntityType. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that perform create Feature. */
export interface CreateFeatureOperationMetadata {
  /** Operation metadata for Feature. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/** Details of operations that perform batch create Features. */
export interface BatchCreateFeaturesOperationMetadata {
  /** Operation metadata for Feature. */
  genericMetadata: GenericOperationMetadata | undefined;
}

/**
 * Request message for
 * [FeaturestoreService.DeleteFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.DeleteFeatureValues].
 */
export interface DeleteFeatureValuesRequest {
  /** Select feature values to be deleted by specifying entities. */
  selectEntity?:
    | DeleteFeatureValuesRequest_SelectEntity
    | undefined;
  /**
   * Select feature values to be deleted by specifying time range and
   * features.
   */
  selectTimeRangeAndFeature?:
    | DeleteFeatureValuesRequest_SelectTimeRangeAndFeature
    | undefined;
  /**
   * Required. The resource name of the EntityType grouping the Features for
   * which values are being deleted from. Format:
   * `projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entityType}`
   */
  entityType: string;
}

/**
 * Message to select entity.
 * If an entity id is selected, all the feature values corresponding to the
 * entity id will be deleted, including the entityId.
 */
export interface DeleteFeatureValuesRequest_SelectEntity {
  /**
   * Required. Selectors choosing feature values of which entity id to be
   * deleted from the EntityType.
   */
  entityIdSelector: EntityIdSelector | undefined;
}

/**
 * Message to select time range and feature.
 * Values of the selected feature generated within an inclusive time range
 * will be deleted. Using this option permanently deletes the feature values
 * from the specified feature IDs within the specified time range.
 * This might include data from the online storage. If you want to retain
 * any deleted historical data in the online storage, you must re-ingest it.
 */
export interface DeleteFeatureValuesRequest_SelectTimeRangeAndFeature {
  /**
   * Required. Select feature generated within a half-inclusive time range.
   * The time range is lower inclusive and upper exclusive.
   */
  timeRange:
    | Interval
    | undefined;
  /**
   * Required. Selectors choosing which feature values to be deleted from the
   * EntityType.
   */
  featureSelector:
    | FeatureSelector
    | undefined;
  /**
   * If set, data will not be deleted from online storage.
   * When time range is older than the data in online storage, setting this to
   * be true will make the deletion have no impact on online serving.
   */
  skipOnlineStorageDelete: boolean;
}

/**
 * Response message for
 * [FeaturestoreService.DeleteFeatureValues][google.cloud.aiplatform.v1beta1.FeaturestoreService.DeleteFeatureValues].
 */
export interface DeleteFeatureValuesResponse {
  /** Response for request specifying the entities to delete */
  selectEntity?:
    | DeleteFeatureValuesResponse_SelectEntity
    | undefined;
  /** Response for request specifying time range and feature */
  selectTimeRangeAndFeature?: DeleteFeatureValuesResponse_SelectTimeRangeAndFeature | undefined;
}

/** Response message if the request uses the SelectEntity option. */
export interface DeleteFeatureValuesResponse_SelectEntity {
  /**
   * The count of deleted entity rows in the offline storage.
   * Each row corresponds to the combination of an entity ID and a timestamp.
   * One entity ID can have multiple rows in the offline storage.
   */
  offlineStorageDeletedEntityRowCount: Long;
  /**
   * The count of deleted entities in the online storage.
   * Each entity ID corresponds to one entity.
   */
  onlineStorageDeletedEntityCount: Long;
}

/** Response message if the request uses the SelectTimeRangeAndFeature option. */
export interface DeleteFeatureValuesResponse_SelectTimeRangeAndFeature {
  /**
   * The count of the features or columns impacted.
   * This is the same as the feature count in the request.
   */
  impactedFeatureCount: Long;
  /**
   * The count of modified entity rows in the offline storage.
   * Each row corresponds to the combination of an entity ID and a timestamp.
   * One entity ID can have multiple rows in the offline storage.
   * Within each row, only the features specified in the request are
   * deleted.
   */
  offlineStorageModifiedEntityRowCount: Long;
  /**
   * The count of modified entities in the online storage.
   * Each entity ID corresponds to one entity.
   * Within each entity, only the features specified in the request are
   * deleted.
   */
  onlineStorageModifiedEntityCount: Long;
}

/** Selector for entityId. Getting ids from the given source. */
export interface EntityIdSelector {
  /** Source of Csv */
  csvSource?:
    | CsvSource
    | undefined;
  /**
   * Source column that holds entity IDs. If not provided, entity IDs are
   * extracted from the column named entity_id.
   */
  entityIdField: string;
}

function createBaseCreateFeaturestoreRequest(): CreateFeaturestoreRequest {
  return { parent: "", featurestore: undefined, featurestoreId: "" };
}

export const CreateFeaturestoreRequest: MessageFns<CreateFeaturestoreRequest> = {
  encode(message: CreateFeaturestoreRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.featurestore !== undefined) {
      Featurestore.encode(message.featurestore, writer.uint32(18).fork()).join();
    }
    if (message.featurestoreId !== "") {
      writer.uint32(26).string(message.featurestoreId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFeaturestoreRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFeaturestoreRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.featurestore = Featurestore.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.featurestoreId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFeaturestoreRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      featurestore: isSet(object.featurestore) ? Featurestore.fromJSON(object.featurestore) : undefined,
      featurestoreId: isSet(object.featurestoreId) ? globalThis.String(object.featurestoreId) : "",
    };
  },

  toJSON(message: CreateFeaturestoreRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.featurestore !== undefined) {
      obj.featurestore = Featurestore.toJSON(message.featurestore);
    }
    if (message.featurestoreId !== "") {
      obj.featurestoreId = message.featurestoreId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFeaturestoreRequest>): CreateFeaturestoreRequest {
    return CreateFeaturestoreRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFeaturestoreRequest>): CreateFeaturestoreRequest {
    const message = createBaseCreateFeaturestoreRequest();
    message.parent = object.parent ?? "";
    message.featurestore = (object.featurestore !== undefined && object.featurestore !== null)
      ? Featurestore.fromPartial(object.featurestore)
      : undefined;
    message.featurestoreId = object.featurestoreId ?? "";
    return message;
  },
};

function createBaseGetFeaturestoreRequest(): GetFeaturestoreRequest {
  return { name: "" };
}

export const GetFeaturestoreRequest: MessageFns<GetFeaturestoreRequest> = {
  encode(message: GetFeaturestoreRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFeaturestoreRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFeaturestoreRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFeaturestoreRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetFeaturestoreRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetFeaturestoreRequest>): GetFeaturestoreRequest {
    return GetFeaturestoreRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFeaturestoreRequest>): GetFeaturestoreRequest {
    const message = createBaseGetFeaturestoreRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListFeaturestoresRequest(): ListFeaturestoresRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", orderBy: "", readMask: undefined };
}

export const ListFeaturestoresRequest: MessageFns<ListFeaturestoresRequest> = {
  encode(message: ListFeaturestoresRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFeaturestoresRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFeaturestoresRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFeaturestoresRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListFeaturestoresRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListFeaturestoresRequest>): ListFeaturestoresRequest {
    return ListFeaturestoresRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFeaturestoresRequest>): ListFeaturestoresRequest {
    const message = createBaseListFeaturestoresRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListFeaturestoresResponse(): ListFeaturestoresResponse {
  return { featurestores: [], nextPageToken: "" };
}

export const ListFeaturestoresResponse: MessageFns<ListFeaturestoresResponse> = {
  encode(message: ListFeaturestoresResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.featurestores) {
      Featurestore.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFeaturestoresResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFeaturestoresResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featurestores.push(Featurestore.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFeaturestoresResponse {
    return {
      featurestores: globalThis.Array.isArray(object?.featurestores)
        ? object.featurestores.map((e: any) => Featurestore.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListFeaturestoresResponse): unknown {
    const obj: any = {};
    if (message.featurestores?.length) {
      obj.featurestores = message.featurestores.map((e) => Featurestore.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFeaturestoresResponse>): ListFeaturestoresResponse {
    return ListFeaturestoresResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFeaturestoresResponse>): ListFeaturestoresResponse {
    const message = createBaseListFeaturestoresResponse();
    message.featurestores = object.featurestores?.map((e) => Featurestore.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateFeaturestoreRequest(): UpdateFeaturestoreRequest {
  return { featurestore: undefined, updateMask: undefined };
}

export const UpdateFeaturestoreRequest: MessageFns<UpdateFeaturestoreRequest> = {
  encode(message: UpdateFeaturestoreRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.featurestore !== undefined) {
      Featurestore.encode(message.featurestore, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFeaturestoreRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFeaturestoreRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featurestore = Featurestore.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFeaturestoreRequest {
    return {
      featurestore: isSet(object.featurestore) ? Featurestore.fromJSON(object.featurestore) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateFeaturestoreRequest): unknown {
    const obj: any = {};
    if (message.featurestore !== undefined) {
      obj.featurestore = Featurestore.toJSON(message.featurestore);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFeaturestoreRequest>): UpdateFeaturestoreRequest {
    return UpdateFeaturestoreRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFeaturestoreRequest>): UpdateFeaturestoreRequest {
    const message = createBaseUpdateFeaturestoreRequest();
    message.featurestore = (object.featurestore !== undefined && object.featurestore !== null)
      ? Featurestore.fromPartial(object.featurestore)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteFeaturestoreRequest(): DeleteFeaturestoreRequest {
  return { name: "", force: false };
}

export const DeleteFeaturestoreRequest: MessageFns<DeleteFeaturestoreRequest> = {
  encode(message: DeleteFeaturestoreRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.force !== false) {
      writer.uint32(16).bool(message.force);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeaturestoreRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeaturestoreRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.force = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeaturestoreRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      force: isSet(object.force) ? globalThis.Boolean(object.force) : false,
    };
  },

  toJSON(message: DeleteFeaturestoreRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.force !== false) {
      obj.force = message.force;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeaturestoreRequest>): DeleteFeaturestoreRequest {
    return DeleteFeaturestoreRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeaturestoreRequest>): DeleteFeaturestoreRequest {
    const message = createBaseDeleteFeaturestoreRequest();
    message.name = object.name ?? "";
    message.force = object.force ?? false;
    return message;
  },
};

function createBaseImportFeatureValuesRequest(): ImportFeatureValuesRequest {
  return {
    avroSource: undefined,
    bigquerySource: undefined,
    csvSource: undefined,
    featureTimeField: undefined,
    featureTime: undefined,
    entityType: "",
    entityIdField: "",
    featureSpecs: [],
    disableOnlineServing: false,
    workerCount: 0,
    disableIngestionAnalysis: false,
  };
}

export const ImportFeatureValuesRequest: MessageFns<ImportFeatureValuesRequest> = {
  encode(message: ImportFeatureValuesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.avroSource !== undefined) {
      AvroSource.encode(message.avroSource, writer.uint32(18).fork()).join();
    }
    if (message.bigquerySource !== undefined) {
      BigQuerySource.encode(message.bigquerySource, writer.uint32(26).fork()).join();
    }
    if (message.csvSource !== undefined) {
      CsvSource.encode(message.csvSource, writer.uint32(34).fork()).join();
    }
    if (message.featureTimeField !== undefined) {
      writer.uint32(50).string(message.featureTimeField);
    }
    if (message.featureTime !== undefined) {
      Timestamp.encode(toTimestamp(message.featureTime), writer.uint32(58).fork()).join();
    }
    if (message.entityType !== "") {
      writer.uint32(10).string(message.entityType);
    }
    if (message.entityIdField !== "") {
      writer.uint32(42).string(message.entityIdField);
    }
    for (const v of message.featureSpecs) {
      ImportFeatureValuesRequest_FeatureSpec.encode(v!, writer.uint32(66).fork()).join();
    }
    if (message.disableOnlineServing !== false) {
      writer.uint32(72).bool(message.disableOnlineServing);
    }
    if (message.workerCount !== 0) {
      writer.uint32(88).int32(message.workerCount);
    }
    if (message.disableIngestionAnalysis !== false) {
      writer.uint32(96).bool(message.disableIngestionAnalysis);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportFeatureValuesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportFeatureValuesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.avroSource = AvroSource.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.bigquerySource = BigQuerySource.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.csvSource = CsvSource.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.featureTimeField = reader.string();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.featureTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityType = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.entityIdField = reader.string();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.featureSpecs.push(ImportFeatureValuesRequest_FeatureSpec.decode(reader, reader.uint32()));
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.disableOnlineServing = reader.bool();
          continue;
        case 11:
          if (tag !== 88) {
            break;
          }

          message.workerCount = reader.int32();
          continue;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.disableIngestionAnalysis = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportFeatureValuesRequest {
    return {
      avroSource: isSet(object.avroSource) ? AvroSource.fromJSON(object.avroSource) : undefined,
      bigquerySource: isSet(object.bigquerySource) ? BigQuerySource.fromJSON(object.bigquerySource) : undefined,
      csvSource: isSet(object.csvSource) ? CsvSource.fromJSON(object.csvSource) : undefined,
      featureTimeField: isSet(object.featureTimeField) ? globalThis.String(object.featureTimeField) : undefined,
      featureTime: isSet(object.featureTime) ? fromJsonTimestamp(object.featureTime) : undefined,
      entityType: isSet(object.entityType) ? globalThis.String(object.entityType) : "",
      entityIdField: isSet(object.entityIdField) ? globalThis.String(object.entityIdField) : "",
      featureSpecs: globalThis.Array.isArray(object?.featureSpecs)
        ? object.featureSpecs.map((e: any) => ImportFeatureValuesRequest_FeatureSpec.fromJSON(e))
        : [],
      disableOnlineServing: isSet(object.disableOnlineServing)
        ? globalThis.Boolean(object.disableOnlineServing)
        : false,
      workerCount: isSet(object.workerCount) ? globalThis.Number(object.workerCount) : 0,
      disableIngestionAnalysis: isSet(object.disableIngestionAnalysis)
        ? globalThis.Boolean(object.disableIngestionAnalysis)
        : false,
    };
  },

  toJSON(message: ImportFeatureValuesRequest): unknown {
    const obj: any = {};
    if (message.avroSource !== undefined) {
      obj.avroSource = AvroSource.toJSON(message.avroSource);
    }
    if (message.bigquerySource !== undefined) {
      obj.bigquerySource = BigQuerySource.toJSON(message.bigquerySource);
    }
    if (message.csvSource !== undefined) {
      obj.csvSource = CsvSource.toJSON(message.csvSource);
    }
    if (message.featureTimeField !== undefined) {
      obj.featureTimeField = message.featureTimeField;
    }
    if (message.featureTime !== undefined) {
      obj.featureTime = message.featureTime.toISOString();
    }
    if (message.entityType !== "") {
      obj.entityType = message.entityType;
    }
    if (message.entityIdField !== "") {
      obj.entityIdField = message.entityIdField;
    }
    if (message.featureSpecs?.length) {
      obj.featureSpecs = message.featureSpecs.map((e) => ImportFeatureValuesRequest_FeatureSpec.toJSON(e));
    }
    if (message.disableOnlineServing !== false) {
      obj.disableOnlineServing = message.disableOnlineServing;
    }
    if (message.workerCount !== 0) {
      obj.workerCount = Math.round(message.workerCount);
    }
    if (message.disableIngestionAnalysis !== false) {
      obj.disableIngestionAnalysis = message.disableIngestionAnalysis;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportFeatureValuesRequest>): ImportFeatureValuesRequest {
    return ImportFeatureValuesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportFeatureValuesRequest>): ImportFeatureValuesRequest {
    const message = createBaseImportFeatureValuesRequest();
    message.avroSource = (object.avroSource !== undefined && object.avroSource !== null)
      ? AvroSource.fromPartial(object.avroSource)
      : undefined;
    message.bigquerySource = (object.bigquerySource !== undefined && object.bigquerySource !== null)
      ? BigQuerySource.fromPartial(object.bigquerySource)
      : undefined;
    message.csvSource = (object.csvSource !== undefined && object.csvSource !== null)
      ? CsvSource.fromPartial(object.csvSource)
      : undefined;
    message.featureTimeField = object.featureTimeField ?? undefined;
    message.featureTime = object.featureTime ?? undefined;
    message.entityType = object.entityType ?? "";
    message.entityIdField = object.entityIdField ?? "";
    message.featureSpecs = object.featureSpecs?.map((e) => ImportFeatureValuesRequest_FeatureSpec.fromPartial(e)) || [];
    message.disableOnlineServing = object.disableOnlineServing ?? false;
    message.workerCount = object.workerCount ?? 0;
    message.disableIngestionAnalysis = object.disableIngestionAnalysis ?? false;
    return message;
  },
};

function createBaseImportFeatureValuesRequest_FeatureSpec(): ImportFeatureValuesRequest_FeatureSpec {
  return { id: "", sourceField: "" };
}

export const ImportFeatureValuesRequest_FeatureSpec: MessageFns<ImportFeatureValuesRequest_FeatureSpec> = {
  encode(message: ImportFeatureValuesRequest_FeatureSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.sourceField !== "") {
      writer.uint32(18).string(message.sourceField);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportFeatureValuesRequest_FeatureSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportFeatureValuesRequest_FeatureSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.sourceField = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportFeatureValuesRequest_FeatureSpec {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      sourceField: isSet(object.sourceField) ? globalThis.String(object.sourceField) : "",
    };
  },

  toJSON(message: ImportFeatureValuesRequest_FeatureSpec): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.sourceField !== "") {
      obj.sourceField = message.sourceField;
    }
    return obj;
  },

  create(base?: DeepPartial<ImportFeatureValuesRequest_FeatureSpec>): ImportFeatureValuesRequest_FeatureSpec {
    return ImportFeatureValuesRequest_FeatureSpec.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportFeatureValuesRequest_FeatureSpec>): ImportFeatureValuesRequest_FeatureSpec {
    const message = createBaseImportFeatureValuesRequest_FeatureSpec();
    message.id = object.id ?? "";
    message.sourceField = object.sourceField ?? "";
    return message;
  },
};

function createBaseImportFeatureValuesResponse(): ImportFeatureValuesResponse {
  return {
    importedEntityCount: Long.ZERO,
    importedFeatureValueCount: Long.ZERO,
    invalidRowCount: Long.ZERO,
    timestampOutsideRetentionRowsCount: Long.ZERO,
  };
}

export const ImportFeatureValuesResponse: MessageFns<ImportFeatureValuesResponse> = {
  encode(message: ImportFeatureValuesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.importedEntityCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.importedEntityCount.toString());
    }
    if (!message.importedFeatureValueCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.importedFeatureValueCount.toString());
    }
    if (!message.invalidRowCount.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.invalidRowCount.toString());
    }
    if (!message.timestampOutsideRetentionRowsCount.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.timestampOutsideRetentionRowsCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportFeatureValuesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportFeatureValuesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.importedEntityCount = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.importedFeatureValueCount = Long.fromString(reader.int64().toString());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.invalidRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.timestampOutsideRetentionRowsCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportFeatureValuesResponse {
    return {
      importedEntityCount: isSet(object.importedEntityCount) ? Long.fromValue(object.importedEntityCount) : Long.ZERO,
      importedFeatureValueCount: isSet(object.importedFeatureValueCount)
        ? Long.fromValue(object.importedFeatureValueCount)
        : Long.ZERO,
      invalidRowCount: isSet(object.invalidRowCount) ? Long.fromValue(object.invalidRowCount) : Long.ZERO,
      timestampOutsideRetentionRowsCount: isSet(object.timestampOutsideRetentionRowsCount)
        ? Long.fromValue(object.timestampOutsideRetentionRowsCount)
        : Long.ZERO,
    };
  },

  toJSON(message: ImportFeatureValuesResponse): unknown {
    const obj: any = {};
    if (!message.importedEntityCount.equals(Long.ZERO)) {
      obj.importedEntityCount = (message.importedEntityCount || Long.ZERO).toString();
    }
    if (!message.importedFeatureValueCount.equals(Long.ZERO)) {
      obj.importedFeatureValueCount = (message.importedFeatureValueCount || Long.ZERO).toString();
    }
    if (!message.invalidRowCount.equals(Long.ZERO)) {
      obj.invalidRowCount = (message.invalidRowCount || Long.ZERO).toString();
    }
    if (!message.timestampOutsideRetentionRowsCount.equals(Long.ZERO)) {
      obj.timestampOutsideRetentionRowsCount = (message.timestampOutsideRetentionRowsCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<ImportFeatureValuesResponse>): ImportFeatureValuesResponse {
    return ImportFeatureValuesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportFeatureValuesResponse>): ImportFeatureValuesResponse {
    const message = createBaseImportFeatureValuesResponse();
    message.importedEntityCount = (object.importedEntityCount !== undefined && object.importedEntityCount !== null)
      ? Long.fromValue(object.importedEntityCount)
      : Long.ZERO;
    message.importedFeatureValueCount =
      (object.importedFeatureValueCount !== undefined && object.importedFeatureValueCount !== null)
        ? Long.fromValue(object.importedFeatureValueCount)
        : Long.ZERO;
    message.invalidRowCount = (object.invalidRowCount !== undefined && object.invalidRowCount !== null)
      ? Long.fromValue(object.invalidRowCount)
      : Long.ZERO;
    message.timestampOutsideRetentionRowsCount =
      (object.timestampOutsideRetentionRowsCount !== undefined && object.timestampOutsideRetentionRowsCount !== null)
        ? Long.fromValue(object.timestampOutsideRetentionRowsCount)
        : Long.ZERO;
    return message;
  },
};

function createBaseBatchReadFeatureValuesRequest(): BatchReadFeatureValuesRequest {
  return {
    csvReadInstances: undefined,
    bigqueryReadInstances: undefined,
    featurestore: "",
    destination: undefined,
    passThroughFields: [],
    entityTypeSpecs: [],
    startTime: undefined,
  };
}

export const BatchReadFeatureValuesRequest: MessageFns<BatchReadFeatureValuesRequest> = {
  encode(message: BatchReadFeatureValuesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.csvReadInstances !== undefined) {
      CsvSource.encode(message.csvReadInstances, writer.uint32(26).fork()).join();
    }
    if (message.bigqueryReadInstances !== undefined) {
      BigQuerySource.encode(message.bigqueryReadInstances, writer.uint32(42).fork()).join();
    }
    if (message.featurestore !== "") {
      writer.uint32(10).string(message.featurestore);
    }
    if (message.destination !== undefined) {
      FeatureValueDestination.encode(message.destination, writer.uint32(34).fork()).join();
    }
    for (const v of message.passThroughFields) {
      BatchReadFeatureValuesRequest_PassThroughField.encode(v!, writer.uint32(66).fork()).join();
    }
    for (const v of message.entityTypeSpecs) {
      BatchReadFeatureValuesRequest_EntityTypeSpec.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchReadFeatureValuesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchReadFeatureValuesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.csvReadInstances = CsvSource.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.bigqueryReadInstances = BigQuerySource.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featurestore = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.destination = FeatureValueDestination.decode(reader, reader.uint32());
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.passThroughFields.push(
            BatchReadFeatureValuesRequest_PassThroughField.decode(reader, reader.uint32()),
          );
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.entityTypeSpecs.push(BatchReadFeatureValuesRequest_EntityTypeSpec.decode(reader, reader.uint32()));
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchReadFeatureValuesRequest {
    return {
      csvReadInstances: isSet(object.csvReadInstances) ? CsvSource.fromJSON(object.csvReadInstances) : undefined,
      bigqueryReadInstances: isSet(object.bigqueryReadInstances)
        ? BigQuerySource.fromJSON(object.bigqueryReadInstances)
        : undefined,
      featurestore: isSet(object.featurestore) ? globalThis.String(object.featurestore) : "",
      destination: isSet(object.destination) ? FeatureValueDestination.fromJSON(object.destination) : undefined,
      passThroughFields: globalThis.Array.isArray(object?.passThroughFields)
        ? object.passThroughFields.map((e: any) => BatchReadFeatureValuesRequest_PassThroughField.fromJSON(e))
        : [],
      entityTypeSpecs: globalThis.Array.isArray(object?.entityTypeSpecs)
        ? object.entityTypeSpecs.map((e: any) => BatchReadFeatureValuesRequest_EntityTypeSpec.fromJSON(e))
        : [],
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
    };
  },

  toJSON(message: BatchReadFeatureValuesRequest): unknown {
    const obj: any = {};
    if (message.csvReadInstances !== undefined) {
      obj.csvReadInstances = CsvSource.toJSON(message.csvReadInstances);
    }
    if (message.bigqueryReadInstances !== undefined) {
      obj.bigqueryReadInstances = BigQuerySource.toJSON(message.bigqueryReadInstances);
    }
    if (message.featurestore !== "") {
      obj.featurestore = message.featurestore;
    }
    if (message.destination !== undefined) {
      obj.destination = FeatureValueDestination.toJSON(message.destination);
    }
    if (message.passThroughFields?.length) {
      obj.passThroughFields = message.passThroughFields.map((e) =>
        BatchReadFeatureValuesRequest_PassThroughField.toJSON(e)
      );
    }
    if (message.entityTypeSpecs?.length) {
      obj.entityTypeSpecs = message.entityTypeSpecs.map((e) => BatchReadFeatureValuesRequest_EntityTypeSpec.toJSON(e));
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<BatchReadFeatureValuesRequest>): BatchReadFeatureValuesRequest {
    return BatchReadFeatureValuesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchReadFeatureValuesRequest>): BatchReadFeatureValuesRequest {
    const message = createBaseBatchReadFeatureValuesRequest();
    message.csvReadInstances = (object.csvReadInstances !== undefined && object.csvReadInstances !== null)
      ? CsvSource.fromPartial(object.csvReadInstances)
      : undefined;
    message.bigqueryReadInstances =
      (object.bigqueryReadInstances !== undefined && object.bigqueryReadInstances !== null)
        ? BigQuerySource.fromPartial(object.bigqueryReadInstances)
        : undefined;
    message.featurestore = object.featurestore ?? "";
    message.destination = (object.destination !== undefined && object.destination !== null)
      ? FeatureValueDestination.fromPartial(object.destination)
      : undefined;
    message.passThroughFields =
      object.passThroughFields?.map((e) => BatchReadFeatureValuesRequest_PassThroughField.fromPartial(e)) || [];
    message.entityTypeSpecs =
      object.entityTypeSpecs?.map((e) => BatchReadFeatureValuesRequest_EntityTypeSpec.fromPartial(e)) || [];
    message.startTime = object.startTime ?? undefined;
    return message;
  },
};

function createBaseBatchReadFeatureValuesRequest_PassThroughField(): BatchReadFeatureValuesRequest_PassThroughField {
  return { fieldName: "" };
}

export const BatchReadFeatureValuesRequest_PassThroughField: MessageFns<
  BatchReadFeatureValuesRequest_PassThroughField
> = {
  encode(
    message: BatchReadFeatureValuesRequest_PassThroughField,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.fieldName !== "") {
      writer.uint32(10).string(message.fieldName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchReadFeatureValuesRequest_PassThroughField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchReadFeatureValuesRequest_PassThroughField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.fieldName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchReadFeatureValuesRequest_PassThroughField {
    return { fieldName: isSet(object.fieldName) ? globalThis.String(object.fieldName) : "" };
  },

  toJSON(message: BatchReadFeatureValuesRequest_PassThroughField): unknown {
    const obj: any = {};
    if (message.fieldName !== "") {
      obj.fieldName = message.fieldName;
    }
    return obj;
  },

  create(
    base?: DeepPartial<BatchReadFeatureValuesRequest_PassThroughField>,
  ): BatchReadFeatureValuesRequest_PassThroughField {
    return BatchReadFeatureValuesRequest_PassThroughField.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BatchReadFeatureValuesRequest_PassThroughField>,
  ): BatchReadFeatureValuesRequest_PassThroughField {
    const message = createBaseBatchReadFeatureValuesRequest_PassThroughField();
    message.fieldName = object.fieldName ?? "";
    return message;
  },
};

function createBaseBatchReadFeatureValuesRequest_EntityTypeSpec(): BatchReadFeatureValuesRequest_EntityTypeSpec {
  return { entityTypeId: "", featureSelector: undefined, settings: [] };
}

export const BatchReadFeatureValuesRequest_EntityTypeSpec: MessageFns<BatchReadFeatureValuesRequest_EntityTypeSpec> = {
  encode(
    message: BatchReadFeatureValuesRequest_EntityTypeSpec,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.entityTypeId !== "") {
      writer.uint32(10).string(message.entityTypeId);
    }
    if (message.featureSelector !== undefined) {
      FeatureSelector.encode(message.featureSelector, writer.uint32(18).fork()).join();
    }
    for (const v of message.settings) {
      DestinationFeatureSetting.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchReadFeatureValuesRequest_EntityTypeSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchReadFeatureValuesRequest_EntityTypeSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityTypeId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.featureSelector = FeatureSelector.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.settings.push(DestinationFeatureSetting.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchReadFeatureValuesRequest_EntityTypeSpec {
    return {
      entityTypeId: isSet(object.entityTypeId) ? globalThis.String(object.entityTypeId) : "",
      featureSelector: isSet(object.featureSelector) ? FeatureSelector.fromJSON(object.featureSelector) : undefined,
      settings: globalThis.Array.isArray(object?.settings)
        ? object.settings.map((e: any) => DestinationFeatureSetting.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchReadFeatureValuesRequest_EntityTypeSpec): unknown {
    const obj: any = {};
    if (message.entityTypeId !== "") {
      obj.entityTypeId = message.entityTypeId;
    }
    if (message.featureSelector !== undefined) {
      obj.featureSelector = FeatureSelector.toJSON(message.featureSelector);
    }
    if (message.settings?.length) {
      obj.settings = message.settings.map((e) => DestinationFeatureSetting.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<BatchReadFeatureValuesRequest_EntityTypeSpec>,
  ): BatchReadFeatureValuesRequest_EntityTypeSpec {
    return BatchReadFeatureValuesRequest_EntityTypeSpec.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BatchReadFeatureValuesRequest_EntityTypeSpec>,
  ): BatchReadFeatureValuesRequest_EntityTypeSpec {
    const message = createBaseBatchReadFeatureValuesRequest_EntityTypeSpec();
    message.entityTypeId = object.entityTypeId ?? "";
    message.featureSelector = (object.featureSelector !== undefined && object.featureSelector !== null)
      ? FeatureSelector.fromPartial(object.featureSelector)
      : undefined;
    message.settings = object.settings?.map((e) => DestinationFeatureSetting.fromPartial(e)) || [];
    return message;
  },
};

function createBaseExportFeatureValuesRequest(): ExportFeatureValuesRequest {
  return {
    snapshotExport: undefined,
    fullExport: undefined,
    entityType: "",
    destination: undefined,
    featureSelector: undefined,
    settings: [],
  };
}

export const ExportFeatureValuesRequest: MessageFns<ExportFeatureValuesRequest> = {
  encode(message: ExportFeatureValuesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshotExport !== undefined) {
      ExportFeatureValuesRequest_SnapshotExport.encode(message.snapshotExport, writer.uint32(26).fork()).join();
    }
    if (message.fullExport !== undefined) {
      ExportFeatureValuesRequest_FullExport.encode(message.fullExport, writer.uint32(58).fork()).join();
    }
    if (message.entityType !== "") {
      writer.uint32(10).string(message.entityType);
    }
    if (message.destination !== undefined) {
      FeatureValueDestination.encode(message.destination, writer.uint32(34).fork()).join();
    }
    if (message.featureSelector !== undefined) {
      FeatureSelector.encode(message.featureSelector, writer.uint32(42).fork()).join();
    }
    for (const v of message.settings) {
      DestinationFeatureSetting.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportFeatureValuesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportFeatureValuesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.snapshotExport = ExportFeatureValuesRequest_SnapshotExport.decode(reader, reader.uint32());
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.fullExport = ExportFeatureValuesRequest_FullExport.decode(reader, reader.uint32());
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityType = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.destination = FeatureValueDestination.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.featureSelector = FeatureSelector.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.settings.push(DestinationFeatureSetting.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportFeatureValuesRequest {
    return {
      snapshotExport: isSet(object.snapshotExport)
        ? ExportFeatureValuesRequest_SnapshotExport.fromJSON(object.snapshotExport)
        : undefined,
      fullExport: isSet(object.fullExport)
        ? ExportFeatureValuesRequest_FullExport.fromJSON(object.fullExport)
        : undefined,
      entityType: isSet(object.entityType) ? globalThis.String(object.entityType) : "",
      destination: isSet(object.destination) ? FeatureValueDestination.fromJSON(object.destination) : undefined,
      featureSelector: isSet(object.featureSelector) ? FeatureSelector.fromJSON(object.featureSelector) : undefined,
      settings: globalThis.Array.isArray(object?.settings)
        ? object.settings.map((e: any) => DestinationFeatureSetting.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ExportFeatureValuesRequest): unknown {
    const obj: any = {};
    if (message.snapshotExport !== undefined) {
      obj.snapshotExport = ExportFeatureValuesRequest_SnapshotExport.toJSON(message.snapshotExport);
    }
    if (message.fullExport !== undefined) {
      obj.fullExport = ExportFeatureValuesRequest_FullExport.toJSON(message.fullExport);
    }
    if (message.entityType !== "") {
      obj.entityType = message.entityType;
    }
    if (message.destination !== undefined) {
      obj.destination = FeatureValueDestination.toJSON(message.destination);
    }
    if (message.featureSelector !== undefined) {
      obj.featureSelector = FeatureSelector.toJSON(message.featureSelector);
    }
    if (message.settings?.length) {
      obj.settings = message.settings.map((e) => DestinationFeatureSetting.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<ExportFeatureValuesRequest>): ExportFeatureValuesRequest {
    return ExportFeatureValuesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportFeatureValuesRequest>): ExportFeatureValuesRequest {
    const message = createBaseExportFeatureValuesRequest();
    message.snapshotExport = (object.snapshotExport !== undefined && object.snapshotExport !== null)
      ? ExportFeatureValuesRequest_SnapshotExport.fromPartial(object.snapshotExport)
      : undefined;
    message.fullExport = (object.fullExport !== undefined && object.fullExport !== null)
      ? ExportFeatureValuesRequest_FullExport.fromPartial(object.fullExport)
      : undefined;
    message.entityType = object.entityType ?? "";
    message.destination = (object.destination !== undefined && object.destination !== null)
      ? FeatureValueDestination.fromPartial(object.destination)
      : undefined;
    message.featureSelector = (object.featureSelector !== undefined && object.featureSelector !== null)
      ? FeatureSelector.fromPartial(object.featureSelector)
      : undefined;
    message.settings = object.settings?.map((e) => DestinationFeatureSetting.fromPartial(e)) || [];
    return message;
  },
};

function createBaseExportFeatureValuesRequest_SnapshotExport(): ExportFeatureValuesRequest_SnapshotExport {
  return { snapshotTime: undefined, startTime: undefined };
}

export const ExportFeatureValuesRequest_SnapshotExport: MessageFns<ExportFeatureValuesRequest_SnapshotExport> = {
  encode(message: ExportFeatureValuesRequest_SnapshotExport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.snapshotTime !== undefined) {
      Timestamp.encode(toTimestamp(message.snapshotTime), writer.uint32(10).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportFeatureValuesRequest_SnapshotExport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportFeatureValuesRequest_SnapshotExport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.snapshotTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportFeatureValuesRequest_SnapshotExport {
    return {
      snapshotTime: isSet(object.snapshotTime) ? fromJsonTimestamp(object.snapshotTime) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
    };
  },

  toJSON(message: ExportFeatureValuesRequest_SnapshotExport): unknown {
    const obj: any = {};
    if (message.snapshotTime !== undefined) {
      obj.snapshotTime = message.snapshotTime.toISOString();
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ExportFeatureValuesRequest_SnapshotExport>): ExportFeatureValuesRequest_SnapshotExport {
    return ExportFeatureValuesRequest_SnapshotExport.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ExportFeatureValuesRequest_SnapshotExport>,
  ): ExportFeatureValuesRequest_SnapshotExport {
    const message = createBaseExportFeatureValuesRequest_SnapshotExport();
    message.snapshotTime = object.snapshotTime ?? undefined;
    message.startTime = object.startTime ?? undefined;
    return message;
  },
};

function createBaseExportFeatureValuesRequest_FullExport(): ExportFeatureValuesRequest_FullExport {
  return { startTime: undefined, endTime: undefined };
}

export const ExportFeatureValuesRequest_FullExport: MessageFns<ExportFeatureValuesRequest_FullExport> = {
  encode(message: ExportFeatureValuesRequest_FullExport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportFeatureValuesRequest_FullExport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportFeatureValuesRequest_FullExport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportFeatureValuesRequest_FullExport {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: ExportFeatureValuesRequest_FullExport): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<ExportFeatureValuesRequest_FullExport>): ExportFeatureValuesRequest_FullExport {
    return ExportFeatureValuesRequest_FullExport.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportFeatureValuesRequest_FullExport>): ExportFeatureValuesRequest_FullExport {
    const message = createBaseExportFeatureValuesRequest_FullExport();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseDestinationFeatureSetting(): DestinationFeatureSetting {
  return { featureId: "", destinationField: "" };
}

export const DestinationFeatureSetting: MessageFns<DestinationFeatureSetting> = {
  encode(message: DestinationFeatureSetting, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.featureId !== "") {
      writer.uint32(10).string(message.featureId);
    }
    if (message.destinationField !== "") {
      writer.uint32(18).string(message.destinationField);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DestinationFeatureSetting {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDestinationFeatureSetting();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featureId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.destinationField = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DestinationFeatureSetting {
    return {
      featureId: isSet(object.featureId) ? globalThis.String(object.featureId) : "",
      destinationField: isSet(object.destinationField) ? globalThis.String(object.destinationField) : "",
    };
  },

  toJSON(message: DestinationFeatureSetting): unknown {
    const obj: any = {};
    if (message.featureId !== "") {
      obj.featureId = message.featureId;
    }
    if (message.destinationField !== "") {
      obj.destinationField = message.destinationField;
    }
    return obj;
  },

  create(base?: DeepPartial<DestinationFeatureSetting>): DestinationFeatureSetting {
    return DestinationFeatureSetting.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DestinationFeatureSetting>): DestinationFeatureSetting {
    const message = createBaseDestinationFeatureSetting();
    message.featureId = object.featureId ?? "";
    message.destinationField = object.destinationField ?? "";
    return message;
  },
};

function createBaseFeatureValueDestination(): FeatureValueDestination {
  return { bigqueryDestination: undefined, tfrecordDestination: undefined, csvDestination: undefined };
}

export const FeatureValueDestination: MessageFns<FeatureValueDestination> = {
  encode(message: FeatureValueDestination, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bigqueryDestination !== undefined) {
      BigQueryDestination.encode(message.bigqueryDestination, writer.uint32(10).fork()).join();
    }
    if (message.tfrecordDestination !== undefined) {
      TFRecordDestination.encode(message.tfrecordDestination, writer.uint32(18).fork()).join();
    }
    if (message.csvDestination !== undefined) {
      CsvDestination.encode(message.csvDestination, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FeatureValueDestination {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeatureValueDestination();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.bigqueryDestination = BigQueryDestination.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.tfrecordDestination = TFRecordDestination.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.csvDestination = CsvDestination.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FeatureValueDestination {
    return {
      bigqueryDestination: isSet(object.bigqueryDestination)
        ? BigQueryDestination.fromJSON(object.bigqueryDestination)
        : undefined,
      tfrecordDestination: isSet(object.tfrecordDestination)
        ? TFRecordDestination.fromJSON(object.tfrecordDestination)
        : undefined,
      csvDestination: isSet(object.csvDestination) ? CsvDestination.fromJSON(object.csvDestination) : undefined,
    };
  },

  toJSON(message: FeatureValueDestination): unknown {
    const obj: any = {};
    if (message.bigqueryDestination !== undefined) {
      obj.bigqueryDestination = BigQueryDestination.toJSON(message.bigqueryDestination);
    }
    if (message.tfrecordDestination !== undefined) {
      obj.tfrecordDestination = TFRecordDestination.toJSON(message.tfrecordDestination);
    }
    if (message.csvDestination !== undefined) {
      obj.csvDestination = CsvDestination.toJSON(message.csvDestination);
    }
    return obj;
  },

  create(base?: DeepPartial<FeatureValueDestination>): FeatureValueDestination {
    return FeatureValueDestination.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FeatureValueDestination>): FeatureValueDestination {
    const message = createBaseFeatureValueDestination();
    message.bigqueryDestination = (object.bigqueryDestination !== undefined && object.bigqueryDestination !== null)
      ? BigQueryDestination.fromPartial(object.bigqueryDestination)
      : undefined;
    message.tfrecordDestination = (object.tfrecordDestination !== undefined && object.tfrecordDestination !== null)
      ? TFRecordDestination.fromPartial(object.tfrecordDestination)
      : undefined;
    message.csvDestination = (object.csvDestination !== undefined && object.csvDestination !== null)
      ? CsvDestination.fromPartial(object.csvDestination)
      : undefined;
    return message;
  },
};

function createBaseExportFeatureValuesResponse(): ExportFeatureValuesResponse {
  return {};
}

export const ExportFeatureValuesResponse: MessageFns<ExportFeatureValuesResponse> = {
  encode(_: ExportFeatureValuesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportFeatureValuesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportFeatureValuesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ExportFeatureValuesResponse {
    return {};
  },

  toJSON(_: ExportFeatureValuesResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<ExportFeatureValuesResponse>): ExportFeatureValuesResponse {
    return ExportFeatureValuesResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<ExportFeatureValuesResponse>): ExportFeatureValuesResponse {
    const message = createBaseExportFeatureValuesResponse();
    return message;
  },
};

function createBaseBatchReadFeatureValuesResponse(): BatchReadFeatureValuesResponse {
  return {};
}

export const BatchReadFeatureValuesResponse: MessageFns<BatchReadFeatureValuesResponse> = {
  encode(_: BatchReadFeatureValuesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchReadFeatureValuesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchReadFeatureValuesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): BatchReadFeatureValuesResponse {
    return {};
  },

  toJSON(_: BatchReadFeatureValuesResponse): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<BatchReadFeatureValuesResponse>): BatchReadFeatureValuesResponse {
    return BatchReadFeatureValuesResponse.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<BatchReadFeatureValuesResponse>): BatchReadFeatureValuesResponse {
    const message = createBaseBatchReadFeatureValuesResponse();
    return message;
  },
};

function createBaseCreateEntityTypeRequest(): CreateEntityTypeRequest {
  return { parent: "", entityType: undefined, entityTypeId: "" };
}

export const CreateEntityTypeRequest: MessageFns<CreateEntityTypeRequest> = {
  encode(message: CreateEntityTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.entityType !== undefined) {
      EntityType.encode(message.entityType, writer.uint32(18).fork()).join();
    }
    if (message.entityTypeId !== "") {
      writer.uint32(26).string(message.entityTypeId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateEntityTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateEntityTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.entityType = EntityType.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.entityTypeId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateEntityTypeRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      entityType: isSet(object.entityType) ? EntityType.fromJSON(object.entityType) : undefined,
      entityTypeId: isSet(object.entityTypeId) ? globalThis.String(object.entityTypeId) : "",
    };
  },

  toJSON(message: CreateEntityTypeRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.entityType !== undefined) {
      obj.entityType = EntityType.toJSON(message.entityType);
    }
    if (message.entityTypeId !== "") {
      obj.entityTypeId = message.entityTypeId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateEntityTypeRequest>): CreateEntityTypeRequest {
    return CreateEntityTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateEntityTypeRequest>): CreateEntityTypeRequest {
    const message = createBaseCreateEntityTypeRequest();
    message.parent = object.parent ?? "";
    message.entityType = (object.entityType !== undefined && object.entityType !== null)
      ? EntityType.fromPartial(object.entityType)
      : undefined;
    message.entityTypeId = object.entityTypeId ?? "";
    return message;
  },
};

function createBaseGetEntityTypeRequest(): GetEntityTypeRequest {
  return { name: "" };
}

export const GetEntityTypeRequest: MessageFns<GetEntityTypeRequest> = {
  encode(message: GetEntityTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetEntityTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetEntityTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetEntityTypeRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetEntityTypeRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetEntityTypeRequest>): GetEntityTypeRequest {
    return GetEntityTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetEntityTypeRequest>): GetEntityTypeRequest {
    const message = createBaseGetEntityTypeRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListEntityTypesRequest(): ListEntityTypesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", orderBy: "", readMask: undefined };
}

export const ListEntityTypesRequest: MessageFns<ListEntityTypesRequest> = {
  encode(message: ListEntityTypesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListEntityTypesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListEntityTypesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListEntityTypesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
    };
  },

  toJSON(message: ListEntityTypesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    return obj;
  },

  create(base?: DeepPartial<ListEntityTypesRequest>): ListEntityTypesRequest {
    return ListEntityTypesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListEntityTypesRequest>): ListEntityTypesRequest {
    const message = createBaseListEntityTypesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.readMask = object.readMask ?? undefined;
    return message;
  },
};

function createBaseListEntityTypesResponse(): ListEntityTypesResponse {
  return { entityTypes: [], nextPageToken: "" };
}

export const ListEntityTypesResponse: MessageFns<ListEntityTypesResponse> = {
  encode(message: ListEntityTypesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.entityTypes) {
      EntityType.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListEntityTypesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListEntityTypesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityTypes.push(EntityType.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListEntityTypesResponse {
    return {
      entityTypes: globalThis.Array.isArray(object?.entityTypes)
        ? object.entityTypes.map((e: any) => EntityType.fromJSON(e))
        : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListEntityTypesResponse): unknown {
    const obj: any = {};
    if (message.entityTypes?.length) {
      obj.entityTypes = message.entityTypes.map((e) => EntityType.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListEntityTypesResponse>): ListEntityTypesResponse {
    return ListEntityTypesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListEntityTypesResponse>): ListEntityTypesResponse {
    const message = createBaseListEntityTypesResponse();
    message.entityTypes = object.entityTypes?.map((e) => EntityType.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateEntityTypeRequest(): UpdateEntityTypeRequest {
  return { entityType: undefined, updateMask: undefined };
}

export const UpdateEntityTypeRequest: MessageFns<UpdateEntityTypeRequest> = {
  encode(message: UpdateEntityTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entityType !== undefined) {
      EntityType.encode(message.entityType, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateEntityTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateEntityTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityType = EntityType.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateEntityTypeRequest {
    return {
      entityType: isSet(object.entityType) ? EntityType.fromJSON(object.entityType) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateEntityTypeRequest): unknown {
    const obj: any = {};
    if (message.entityType !== undefined) {
      obj.entityType = EntityType.toJSON(message.entityType);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateEntityTypeRequest>): UpdateEntityTypeRequest {
    return UpdateEntityTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateEntityTypeRequest>): UpdateEntityTypeRequest {
    const message = createBaseUpdateEntityTypeRequest();
    message.entityType = (object.entityType !== undefined && object.entityType !== null)
      ? EntityType.fromPartial(object.entityType)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteEntityTypeRequest(): DeleteEntityTypeRequest {
  return { name: "", force: false };
}

export const DeleteEntityTypeRequest: MessageFns<DeleteEntityTypeRequest> = {
  encode(message: DeleteEntityTypeRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.force !== false) {
      writer.uint32(16).bool(message.force);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteEntityTypeRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteEntityTypeRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.force = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteEntityTypeRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      force: isSet(object.force) ? globalThis.Boolean(object.force) : false,
    };
  },

  toJSON(message: DeleteEntityTypeRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.force !== false) {
      obj.force = message.force;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteEntityTypeRequest>): DeleteEntityTypeRequest {
    return DeleteEntityTypeRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteEntityTypeRequest>): DeleteEntityTypeRequest {
    const message = createBaseDeleteEntityTypeRequest();
    message.name = object.name ?? "";
    message.force = object.force ?? false;
    return message;
  },
};

function createBaseCreateFeatureRequest(): CreateFeatureRequest {
  return { parent: "", feature: undefined, featureId: "" };
}

export const CreateFeatureRequest: MessageFns<CreateFeatureRequest> = {
  encode(message: CreateFeatureRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.feature !== undefined) {
      Feature.encode(message.feature, writer.uint32(18).fork()).join();
    }
    if (message.featureId !== "") {
      writer.uint32(26).string(message.featureId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFeatureRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFeatureRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.feature = Feature.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.featureId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFeatureRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      feature: isSet(object.feature) ? Feature.fromJSON(object.feature) : undefined,
      featureId: isSet(object.featureId) ? globalThis.String(object.featureId) : "",
    };
  },

  toJSON(message: CreateFeatureRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.feature !== undefined) {
      obj.feature = Feature.toJSON(message.feature);
    }
    if (message.featureId !== "") {
      obj.featureId = message.featureId;
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFeatureRequest>): CreateFeatureRequest {
    return CreateFeatureRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFeatureRequest>): CreateFeatureRequest {
    const message = createBaseCreateFeatureRequest();
    message.parent = object.parent ?? "";
    message.feature = (object.feature !== undefined && object.feature !== null)
      ? Feature.fromPartial(object.feature)
      : undefined;
    message.featureId = object.featureId ?? "";
    return message;
  },
};

function createBaseBatchCreateFeaturesRequest(): BatchCreateFeaturesRequest {
  return { parent: "", requests: [] };
}

export const BatchCreateFeaturesRequest: MessageFns<BatchCreateFeaturesRequest> = {
  encode(message: BatchCreateFeaturesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.requests) {
      CreateFeatureRequest.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchCreateFeaturesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchCreateFeaturesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.requests.push(CreateFeatureRequest.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchCreateFeaturesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      requests: globalThis.Array.isArray(object?.requests)
        ? object.requests.map((e: any) => CreateFeatureRequest.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchCreateFeaturesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.requests?.length) {
      obj.requests = message.requests.map((e) => CreateFeatureRequest.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchCreateFeaturesRequest>): BatchCreateFeaturesRequest {
    return BatchCreateFeaturesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchCreateFeaturesRequest>): BatchCreateFeaturesRequest {
    const message = createBaseBatchCreateFeaturesRequest();
    message.parent = object.parent ?? "";
    message.requests = object.requests?.map((e) => CreateFeatureRequest.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBatchCreateFeaturesResponse(): BatchCreateFeaturesResponse {
  return { features: [] };
}

export const BatchCreateFeaturesResponse: MessageFns<BatchCreateFeaturesResponse> = {
  encode(message: BatchCreateFeaturesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.features) {
      Feature.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchCreateFeaturesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchCreateFeaturesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.features.push(Feature.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchCreateFeaturesResponse {
    return {
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => Feature.fromJSON(e)) : [],
    };
  },

  toJSON(message: BatchCreateFeaturesResponse): unknown {
    const obj: any = {};
    if (message.features?.length) {
      obj.features = message.features.map((e) => Feature.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchCreateFeaturesResponse>): BatchCreateFeaturesResponse {
    return BatchCreateFeaturesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchCreateFeaturesResponse>): BatchCreateFeaturesResponse {
    const message = createBaseBatchCreateFeaturesResponse();
    message.features = object.features?.map((e) => Feature.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGetFeatureRequest(): GetFeatureRequest {
  return { name: "" };
}

export const GetFeatureRequest: MessageFns<GetFeatureRequest> = {
  encode(message: GetFeatureRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetFeatureRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetFeatureRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetFeatureRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: GetFeatureRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<GetFeatureRequest>): GetFeatureRequest {
    return GetFeatureRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetFeatureRequest>): GetFeatureRequest {
    const message = createBaseGetFeatureRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseListFeaturesRequest(): ListFeaturesRequest {
  return { parent: "", filter: "", pageSize: 0, pageToken: "", orderBy: "", readMask: undefined, latestStatsCount: 0 };
}

export const ListFeaturesRequest: MessageFns<ListFeaturesRequest> = {
  encode(message: ListFeaturesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.filter !== "") {
      writer.uint32(18).string(message.filter);
    }
    if (message.pageSize !== 0) {
      writer.uint32(24).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(34).string(message.pageToken);
    }
    if (message.orderBy !== "") {
      writer.uint32(42).string(message.orderBy);
    }
    if (message.readMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.readMask), writer.uint32(50).fork()).join();
    }
    if (message.latestStatsCount !== 0) {
      writer.uint32(56).int32(message.latestStatsCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFeaturesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFeaturesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.filter = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.pageToken = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.orderBy = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.readMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.latestStatsCount = reader.int32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFeaturesRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      filter: isSet(object.filter) ? globalThis.String(object.filter) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
      orderBy: isSet(object.orderBy) ? globalThis.String(object.orderBy) : "",
      readMask: isSet(object.readMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.readMask)) : undefined,
      latestStatsCount: isSet(object.latestStatsCount) ? globalThis.Number(object.latestStatsCount) : 0,
    };
  },

  toJSON(message: ListFeaturesRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.filter !== "") {
      obj.filter = message.filter;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    if (message.orderBy !== "") {
      obj.orderBy = message.orderBy;
    }
    if (message.readMask !== undefined) {
      obj.readMask = FieldMask.toJSON(FieldMask.wrap(message.readMask));
    }
    if (message.latestStatsCount !== 0) {
      obj.latestStatsCount = Math.round(message.latestStatsCount);
    }
    return obj;
  },

  create(base?: DeepPartial<ListFeaturesRequest>): ListFeaturesRequest {
    return ListFeaturesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFeaturesRequest>): ListFeaturesRequest {
    const message = createBaseListFeaturesRequest();
    message.parent = object.parent ?? "";
    message.filter = object.filter ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    message.orderBy = object.orderBy ?? "";
    message.readMask = object.readMask ?? undefined;
    message.latestStatsCount = object.latestStatsCount ?? 0;
    return message;
  },
};

function createBaseListFeaturesResponse(): ListFeaturesResponse {
  return { features: [], nextPageToken: "" };
}

export const ListFeaturesResponse: MessageFns<ListFeaturesResponse> = {
  encode(message: ListFeaturesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.features) {
      Feature.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListFeaturesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListFeaturesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.features.push(Feature.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListFeaturesResponse {
    return {
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => Feature.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: ListFeaturesResponse): unknown {
    const obj: any = {};
    if (message.features?.length) {
      obj.features = message.features.map((e) => Feature.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<ListFeaturesResponse>): ListFeaturesResponse {
    return ListFeaturesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ListFeaturesResponse>): ListFeaturesResponse {
    const message = createBaseListFeaturesResponse();
    message.features = object.features?.map((e) => Feature.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseSearchFeaturesRequest(): SearchFeaturesRequest {
  return { location: "", query: "", pageSize: 0, pageToken: "" };
}

export const SearchFeaturesRequest: MessageFns<SearchFeaturesRequest> = {
  encode(message: SearchFeaturesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== "") {
      writer.uint32(10).string(message.location);
    }
    if (message.query !== "") {
      writer.uint32(26).string(message.query);
    }
    if (message.pageSize !== 0) {
      writer.uint32(32).int32(message.pageSize);
    }
    if (message.pageToken !== "") {
      writer.uint32(42).string(message.pageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchFeaturesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchFeaturesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.location = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.query = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.pageSize = reader.int32();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchFeaturesRequest {
    return {
      location: isSet(object.location) ? globalThis.String(object.location) : "",
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      pageSize: isSet(object.pageSize) ? globalThis.Number(object.pageSize) : 0,
      pageToken: isSet(object.pageToken) ? globalThis.String(object.pageToken) : "",
    };
  },

  toJSON(message: SearchFeaturesRequest): unknown {
    const obj: any = {};
    if (message.location !== "") {
      obj.location = message.location;
    }
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.pageSize !== 0) {
      obj.pageSize = Math.round(message.pageSize);
    }
    if (message.pageToken !== "") {
      obj.pageToken = message.pageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchFeaturesRequest>): SearchFeaturesRequest {
    return SearchFeaturesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchFeaturesRequest>): SearchFeaturesRequest {
    const message = createBaseSearchFeaturesRequest();
    message.location = object.location ?? "";
    message.query = object.query ?? "";
    message.pageSize = object.pageSize ?? 0;
    message.pageToken = object.pageToken ?? "";
    return message;
  },
};

function createBaseSearchFeaturesResponse(): SearchFeaturesResponse {
  return { features: [], nextPageToken: "" };
}

export const SearchFeaturesResponse: MessageFns<SearchFeaturesResponse> = {
  encode(message: SearchFeaturesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.features) {
      Feature.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.nextPageToken !== "") {
      writer.uint32(18).string(message.nextPageToken);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SearchFeaturesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSearchFeaturesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.features.push(Feature.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.nextPageToken = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SearchFeaturesResponse {
    return {
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => Feature.fromJSON(e)) : [],
      nextPageToken: isSet(object.nextPageToken) ? globalThis.String(object.nextPageToken) : "",
    };
  },

  toJSON(message: SearchFeaturesResponse): unknown {
    const obj: any = {};
    if (message.features?.length) {
      obj.features = message.features.map((e) => Feature.toJSON(e));
    }
    if (message.nextPageToken !== "") {
      obj.nextPageToken = message.nextPageToken;
    }
    return obj;
  },

  create(base?: DeepPartial<SearchFeaturesResponse>): SearchFeaturesResponse {
    return SearchFeaturesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<SearchFeaturesResponse>): SearchFeaturesResponse {
    const message = createBaseSearchFeaturesResponse();
    message.features = object.features?.map((e) => Feature.fromPartial(e)) || [];
    message.nextPageToken = object.nextPageToken ?? "";
    return message;
  },
};

function createBaseUpdateFeatureRequest(): UpdateFeatureRequest {
  return { feature: undefined, updateMask: undefined };
}

export const UpdateFeatureRequest: MessageFns<UpdateFeatureRequest> = {
  encode(message: UpdateFeatureRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.feature !== undefined) {
      Feature.encode(message.feature, writer.uint32(10).fork()).join();
    }
    if (message.updateMask !== undefined) {
      FieldMask.encode(FieldMask.wrap(message.updateMask), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFeatureRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFeatureRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.feature = Feature.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.updateMask = FieldMask.unwrap(FieldMask.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFeatureRequest {
    return {
      feature: isSet(object.feature) ? Feature.fromJSON(object.feature) : undefined,
      updateMask: isSet(object.updateMask) ? FieldMask.unwrap(FieldMask.fromJSON(object.updateMask)) : undefined,
    };
  },

  toJSON(message: UpdateFeatureRequest): unknown {
    const obj: any = {};
    if (message.feature !== undefined) {
      obj.feature = Feature.toJSON(message.feature);
    }
    if (message.updateMask !== undefined) {
      obj.updateMask = FieldMask.toJSON(FieldMask.wrap(message.updateMask));
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFeatureRequest>): UpdateFeatureRequest {
    return UpdateFeatureRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFeatureRequest>): UpdateFeatureRequest {
    const message = createBaseUpdateFeatureRequest();
    message.feature = (object.feature !== undefined && object.feature !== null)
      ? Feature.fromPartial(object.feature)
      : undefined;
    message.updateMask = object.updateMask ?? undefined;
    return message;
  },
};

function createBaseDeleteFeatureRequest(): DeleteFeatureRequest {
  return { name: "" };
}

export const DeleteFeatureRequest: MessageFns<DeleteFeatureRequest> = {
  encode(message: DeleteFeatureRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteFeatureRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeatureRequest>): DeleteFeatureRequest {
    return DeleteFeatureRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeatureRequest>): DeleteFeatureRequest {
    const message = createBaseDeleteFeatureRequest();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseCreateFeaturestoreOperationMetadata(): CreateFeaturestoreOperationMetadata {
  return { genericMetadata: undefined };
}

export const CreateFeaturestoreOperationMetadata: MessageFns<CreateFeaturestoreOperationMetadata> = {
  encode(message: CreateFeaturestoreOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFeaturestoreOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFeaturestoreOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFeaturestoreOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: CreateFeaturestoreOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFeaturestoreOperationMetadata>): CreateFeaturestoreOperationMetadata {
    return CreateFeaturestoreOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFeaturestoreOperationMetadata>): CreateFeaturestoreOperationMetadata {
    const message = createBaseCreateFeaturestoreOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseUpdateFeaturestoreOperationMetadata(): UpdateFeaturestoreOperationMetadata {
  return { genericMetadata: undefined };
}

export const UpdateFeaturestoreOperationMetadata: MessageFns<UpdateFeaturestoreOperationMetadata> = {
  encode(message: UpdateFeaturestoreOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateFeaturestoreOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateFeaturestoreOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateFeaturestoreOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: UpdateFeaturestoreOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<UpdateFeaturestoreOperationMetadata>): UpdateFeaturestoreOperationMetadata {
    return UpdateFeaturestoreOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpdateFeaturestoreOperationMetadata>): UpdateFeaturestoreOperationMetadata {
    const message = createBaseUpdateFeaturestoreOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseImportFeatureValuesOperationMetadata(): ImportFeatureValuesOperationMetadata {
  return {
    genericMetadata: undefined,
    importedEntityCount: Long.ZERO,
    importedFeatureValueCount: Long.ZERO,
    sourceUris: [],
    invalidRowCount: Long.ZERO,
    timestampOutsideRetentionRowsCount: Long.ZERO,
    blockingOperationIds: [],
  };
}

export const ImportFeatureValuesOperationMetadata: MessageFns<ImportFeatureValuesOperationMetadata> = {
  encode(message: ImportFeatureValuesOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    if (!message.importedEntityCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.importedEntityCount.toString());
    }
    if (!message.importedFeatureValueCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.importedFeatureValueCount.toString());
    }
    for (const v of message.sourceUris) {
      writer.uint32(34).string(v!);
    }
    if (!message.invalidRowCount.equals(Long.ZERO)) {
      writer.uint32(48).int64(message.invalidRowCount.toString());
    }
    if (!message.timestampOutsideRetentionRowsCount.equals(Long.ZERO)) {
      writer.uint32(56).int64(message.timestampOutsideRetentionRowsCount.toString());
    }
    writer.uint32(66).fork();
    for (const v of message.blockingOperationIds) {
      writer.int64(v.toString());
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ImportFeatureValuesOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseImportFeatureValuesOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.importedEntityCount = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.importedFeatureValueCount = Long.fromString(reader.int64().toString());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.sourceUris.push(reader.string());
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.invalidRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.timestampOutsideRetentionRowsCount = Long.fromString(reader.int64().toString());
          continue;
        case 8:
          if (tag === 64) {
            message.blockingOperationIds.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 66) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.blockingOperationIds.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ImportFeatureValuesOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
      importedEntityCount: isSet(object.importedEntityCount) ? Long.fromValue(object.importedEntityCount) : Long.ZERO,
      importedFeatureValueCount: isSet(object.importedFeatureValueCount)
        ? Long.fromValue(object.importedFeatureValueCount)
        : Long.ZERO,
      sourceUris: globalThis.Array.isArray(object?.sourceUris)
        ? object.sourceUris.map((e: any) => globalThis.String(e))
        : [],
      invalidRowCount: isSet(object.invalidRowCount) ? Long.fromValue(object.invalidRowCount) : Long.ZERO,
      timestampOutsideRetentionRowsCount: isSet(object.timestampOutsideRetentionRowsCount)
        ? Long.fromValue(object.timestampOutsideRetentionRowsCount)
        : Long.ZERO,
      blockingOperationIds: globalThis.Array.isArray(object?.blockingOperationIds)
        ? object.blockingOperationIds.map((e: any) => Long.fromValue(e))
        : [],
    };
  },

  toJSON(message: ImportFeatureValuesOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    if (!message.importedEntityCount.equals(Long.ZERO)) {
      obj.importedEntityCount = (message.importedEntityCount || Long.ZERO).toString();
    }
    if (!message.importedFeatureValueCount.equals(Long.ZERO)) {
      obj.importedFeatureValueCount = (message.importedFeatureValueCount || Long.ZERO).toString();
    }
    if (message.sourceUris?.length) {
      obj.sourceUris = message.sourceUris;
    }
    if (!message.invalidRowCount.equals(Long.ZERO)) {
      obj.invalidRowCount = (message.invalidRowCount || Long.ZERO).toString();
    }
    if (!message.timestampOutsideRetentionRowsCount.equals(Long.ZERO)) {
      obj.timestampOutsideRetentionRowsCount = (message.timestampOutsideRetentionRowsCount || Long.ZERO).toString();
    }
    if (message.blockingOperationIds?.length) {
      obj.blockingOperationIds = message.blockingOperationIds.map((e) => (e || Long.ZERO).toString());
    }
    return obj;
  },

  create(base?: DeepPartial<ImportFeatureValuesOperationMetadata>): ImportFeatureValuesOperationMetadata {
    return ImportFeatureValuesOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ImportFeatureValuesOperationMetadata>): ImportFeatureValuesOperationMetadata {
    const message = createBaseImportFeatureValuesOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    message.importedEntityCount = (object.importedEntityCount !== undefined && object.importedEntityCount !== null)
      ? Long.fromValue(object.importedEntityCount)
      : Long.ZERO;
    message.importedFeatureValueCount =
      (object.importedFeatureValueCount !== undefined && object.importedFeatureValueCount !== null)
        ? Long.fromValue(object.importedFeatureValueCount)
        : Long.ZERO;
    message.sourceUris = object.sourceUris?.map((e) => e) || [];
    message.invalidRowCount = (object.invalidRowCount !== undefined && object.invalidRowCount !== null)
      ? Long.fromValue(object.invalidRowCount)
      : Long.ZERO;
    message.timestampOutsideRetentionRowsCount =
      (object.timestampOutsideRetentionRowsCount !== undefined && object.timestampOutsideRetentionRowsCount !== null)
        ? Long.fromValue(object.timestampOutsideRetentionRowsCount)
        : Long.ZERO;
    message.blockingOperationIds = object.blockingOperationIds?.map((e) => Long.fromValue(e)) || [];
    return message;
  },
};

function createBaseExportFeatureValuesOperationMetadata(): ExportFeatureValuesOperationMetadata {
  return { genericMetadata: undefined };
}

export const ExportFeatureValuesOperationMetadata: MessageFns<ExportFeatureValuesOperationMetadata> = {
  encode(message: ExportFeatureValuesOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExportFeatureValuesOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExportFeatureValuesOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExportFeatureValuesOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: ExportFeatureValuesOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<ExportFeatureValuesOperationMetadata>): ExportFeatureValuesOperationMetadata {
    return ExportFeatureValuesOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExportFeatureValuesOperationMetadata>): ExportFeatureValuesOperationMetadata {
    const message = createBaseExportFeatureValuesOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseBatchReadFeatureValuesOperationMetadata(): BatchReadFeatureValuesOperationMetadata {
  return { genericMetadata: undefined };
}

export const BatchReadFeatureValuesOperationMetadata: MessageFns<BatchReadFeatureValuesOperationMetadata> = {
  encode(message: BatchReadFeatureValuesOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchReadFeatureValuesOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchReadFeatureValuesOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchReadFeatureValuesOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: BatchReadFeatureValuesOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchReadFeatureValuesOperationMetadata>): BatchReadFeatureValuesOperationMetadata {
    return BatchReadFeatureValuesOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchReadFeatureValuesOperationMetadata>): BatchReadFeatureValuesOperationMetadata {
    const message = createBaseBatchReadFeatureValuesOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseDeleteFeatureValuesOperationMetadata(): DeleteFeatureValuesOperationMetadata {
  return { genericMetadata: undefined };
}

export const DeleteFeatureValuesOperationMetadata: MessageFns<DeleteFeatureValuesOperationMetadata> = {
  encode(message: DeleteFeatureValuesOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: DeleteFeatureValuesOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeatureValuesOperationMetadata>): DeleteFeatureValuesOperationMetadata {
    return DeleteFeatureValuesOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeatureValuesOperationMetadata>): DeleteFeatureValuesOperationMetadata {
    const message = createBaseDeleteFeatureValuesOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseCreateEntityTypeOperationMetadata(): CreateEntityTypeOperationMetadata {
  return { genericMetadata: undefined };
}

export const CreateEntityTypeOperationMetadata: MessageFns<CreateEntityTypeOperationMetadata> = {
  encode(message: CreateEntityTypeOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateEntityTypeOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateEntityTypeOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateEntityTypeOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: CreateEntityTypeOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateEntityTypeOperationMetadata>): CreateEntityTypeOperationMetadata {
    return CreateEntityTypeOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateEntityTypeOperationMetadata>): CreateEntityTypeOperationMetadata {
    const message = createBaseCreateEntityTypeOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseCreateFeatureOperationMetadata(): CreateFeatureOperationMetadata {
  return { genericMetadata: undefined };
}

export const CreateFeatureOperationMetadata: MessageFns<CreateFeatureOperationMetadata> = {
  encode(message: CreateFeatureOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateFeatureOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateFeatureOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateFeatureOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: CreateFeatureOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<CreateFeatureOperationMetadata>): CreateFeatureOperationMetadata {
    return CreateFeatureOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateFeatureOperationMetadata>): CreateFeatureOperationMetadata {
    const message = createBaseCreateFeatureOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseBatchCreateFeaturesOperationMetadata(): BatchCreateFeaturesOperationMetadata {
  return { genericMetadata: undefined };
}

export const BatchCreateFeaturesOperationMetadata: MessageFns<BatchCreateFeaturesOperationMetadata> = {
  encode(message: BatchCreateFeaturesOperationMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.genericMetadata !== undefined) {
      GenericOperationMetadata.encode(message.genericMetadata, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchCreateFeaturesOperationMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchCreateFeaturesOperationMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.genericMetadata = GenericOperationMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchCreateFeaturesOperationMetadata {
    return {
      genericMetadata: isSet(object.genericMetadata)
        ? GenericOperationMetadata.fromJSON(object.genericMetadata)
        : undefined,
    };
  },

  toJSON(message: BatchCreateFeaturesOperationMetadata): unknown {
    const obj: any = {};
    if (message.genericMetadata !== undefined) {
      obj.genericMetadata = GenericOperationMetadata.toJSON(message.genericMetadata);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchCreateFeaturesOperationMetadata>): BatchCreateFeaturesOperationMetadata {
    return BatchCreateFeaturesOperationMetadata.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchCreateFeaturesOperationMetadata>): BatchCreateFeaturesOperationMetadata {
    const message = createBaseBatchCreateFeaturesOperationMetadata();
    message.genericMetadata = (object.genericMetadata !== undefined && object.genericMetadata !== null)
      ? GenericOperationMetadata.fromPartial(object.genericMetadata)
      : undefined;
    return message;
  },
};

function createBaseDeleteFeatureValuesRequest(): DeleteFeatureValuesRequest {
  return { selectEntity: undefined, selectTimeRangeAndFeature: undefined, entityType: "" };
}

export const DeleteFeatureValuesRequest: MessageFns<DeleteFeatureValuesRequest> = {
  encode(message: DeleteFeatureValuesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.selectEntity !== undefined) {
      DeleteFeatureValuesRequest_SelectEntity.encode(message.selectEntity, writer.uint32(18).fork()).join();
    }
    if (message.selectTimeRangeAndFeature !== undefined) {
      DeleteFeatureValuesRequest_SelectTimeRangeAndFeature.encode(
        message.selectTimeRangeAndFeature,
        writer.uint32(26).fork(),
      ).join();
    }
    if (message.entityType !== "") {
      writer.uint32(10).string(message.entityType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2:
          if (tag !== 18) {
            break;
          }

          message.selectEntity = DeleteFeatureValuesRequest_SelectEntity.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.selectTimeRangeAndFeature = DeleteFeatureValuesRequest_SelectTimeRangeAndFeature.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityType = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesRequest {
    return {
      selectEntity: isSet(object.selectEntity)
        ? DeleteFeatureValuesRequest_SelectEntity.fromJSON(object.selectEntity)
        : undefined,
      selectTimeRangeAndFeature: isSet(object.selectTimeRangeAndFeature)
        ? DeleteFeatureValuesRequest_SelectTimeRangeAndFeature.fromJSON(object.selectTimeRangeAndFeature)
        : undefined,
      entityType: isSet(object.entityType) ? globalThis.String(object.entityType) : "",
    };
  },

  toJSON(message: DeleteFeatureValuesRequest): unknown {
    const obj: any = {};
    if (message.selectEntity !== undefined) {
      obj.selectEntity = DeleteFeatureValuesRequest_SelectEntity.toJSON(message.selectEntity);
    }
    if (message.selectTimeRangeAndFeature !== undefined) {
      obj.selectTimeRangeAndFeature = DeleteFeatureValuesRequest_SelectTimeRangeAndFeature.toJSON(
        message.selectTimeRangeAndFeature,
      );
    }
    if (message.entityType !== "") {
      obj.entityType = message.entityType;
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeatureValuesRequest>): DeleteFeatureValuesRequest {
    return DeleteFeatureValuesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeatureValuesRequest>): DeleteFeatureValuesRequest {
    const message = createBaseDeleteFeatureValuesRequest();
    message.selectEntity = (object.selectEntity !== undefined && object.selectEntity !== null)
      ? DeleteFeatureValuesRequest_SelectEntity.fromPartial(object.selectEntity)
      : undefined;
    message.selectTimeRangeAndFeature =
      (object.selectTimeRangeAndFeature !== undefined && object.selectTimeRangeAndFeature !== null)
        ? DeleteFeatureValuesRequest_SelectTimeRangeAndFeature.fromPartial(object.selectTimeRangeAndFeature)
        : undefined;
    message.entityType = object.entityType ?? "";
    return message;
  },
};

function createBaseDeleteFeatureValuesRequest_SelectEntity(): DeleteFeatureValuesRequest_SelectEntity {
  return { entityIdSelector: undefined };
}

export const DeleteFeatureValuesRequest_SelectEntity: MessageFns<DeleteFeatureValuesRequest_SelectEntity> = {
  encode(message: DeleteFeatureValuesRequest_SelectEntity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entityIdSelector !== undefined) {
      EntityIdSelector.encode(message.entityIdSelector, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesRequest_SelectEntity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesRequest_SelectEntity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.entityIdSelector = EntityIdSelector.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesRequest_SelectEntity {
    return {
      entityIdSelector: isSet(object.entityIdSelector) ? EntityIdSelector.fromJSON(object.entityIdSelector) : undefined,
    };
  },

  toJSON(message: DeleteFeatureValuesRequest_SelectEntity): unknown {
    const obj: any = {};
    if (message.entityIdSelector !== undefined) {
      obj.entityIdSelector = EntityIdSelector.toJSON(message.entityIdSelector);
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeatureValuesRequest_SelectEntity>): DeleteFeatureValuesRequest_SelectEntity {
    return DeleteFeatureValuesRequest_SelectEntity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeatureValuesRequest_SelectEntity>): DeleteFeatureValuesRequest_SelectEntity {
    const message = createBaseDeleteFeatureValuesRequest_SelectEntity();
    message.entityIdSelector = (object.entityIdSelector !== undefined && object.entityIdSelector !== null)
      ? EntityIdSelector.fromPartial(object.entityIdSelector)
      : undefined;
    return message;
  },
};

function createBaseDeleteFeatureValuesRequest_SelectTimeRangeAndFeature(): DeleteFeatureValuesRequest_SelectTimeRangeAndFeature {
  return { timeRange: undefined, featureSelector: undefined, skipOnlineStorageDelete: false };
}

export const DeleteFeatureValuesRequest_SelectTimeRangeAndFeature: MessageFns<
  DeleteFeatureValuesRequest_SelectTimeRangeAndFeature
> = {
  encode(
    message: DeleteFeatureValuesRequest_SelectTimeRangeAndFeature,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.timeRange !== undefined) {
      Interval.encode(message.timeRange, writer.uint32(10).fork()).join();
    }
    if (message.featureSelector !== undefined) {
      FeatureSelector.encode(message.featureSelector, writer.uint32(18).fork()).join();
    }
    if (message.skipOnlineStorageDelete !== false) {
      writer.uint32(24).bool(message.skipOnlineStorageDelete);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesRequest_SelectTimeRangeAndFeature {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesRequest_SelectTimeRangeAndFeature();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.timeRange = Interval.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.featureSelector = FeatureSelector.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.skipOnlineStorageDelete = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesRequest_SelectTimeRangeAndFeature {
    return {
      timeRange: isSet(object.timeRange) ? Interval.fromJSON(object.timeRange) : undefined,
      featureSelector: isSet(object.featureSelector) ? FeatureSelector.fromJSON(object.featureSelector) : undefined,
      skipOnlineStorageDelete: isSet(object.skipOnlineStorageDelete)
        ? globalThis.Boolean(object.skipOnlineStorageDelete)
        : false,
    };
  },

  toJSON(message: DeleteFeatureValuesRequest_SelectTimeRangeAndFeature): unknown {
    const obj: any = {};
    if (message.timeRange !== undefined) {
      obj.timeRange = Interval.toJSON(message.timeRange);
    }
    if (message.featureSelector !== undefined) {
      obj.featureSelector = FeatureSelector.toJSON(message.featureSelector);
    }
    if (message.skipOnlineStorageDelete !== false) {
      obj.skipOnlineStorageDelete = message.skipOnlineStorageDelete;
    }
    return obj;
  },

  create(
    base?: DeepPartial<DeleteFeatureValuesRequest_SelectTimeRangeAndFeature>,
  ): DeleteFeatureValuesRequest_SelectTimeRangeAndFeature {
    return DeleteFeatureValuesRequest_SelectTimeRangeAndFeature.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DeleteFeatureValuesRequest_SelectTimeRangeAndFeature>,
  ): DeleteFeatureValuesRequest_SelectTimeRangeAndFeature {
    const message = createBaseDeleteFeatureValuesRequest_SelectTimeRangeAndFeature();
    message.timeRange = (object.timeRange !== undefined && object.timeRange !== null)
      ? Interval.fromPartial(object.timeRange)
      : undefined;
    message.featureSelector = (object.featureSelector !== undefined && object.featureSelector !== null)
      ? FeatureSelector.fromPartial(object.featureSelector)
      : undefined;
    message.skipOnlineStorageDelete = object.skipOnlineStorageDelete ?? false;
    return message;
  },
};

function createBaseDeleteFeatureValuesResponse(): DeleteFeatureValuesResponse {
  return { selectEntity: undefined, selectTimeRangeAndFeature: undefined };
}

export const DeleteFeatureValuesResponse: MessageFns<DeleteFeatureValuesResponse> = {
  encode(message: DeleteFeatureValuesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.selectEntity !== undefined) {
      DeleteFeatureValuesResponse_SelectEntity.encode(message.selectEntity, writer.uint32(10).fork()).join();
    }
    if (message.selectTimeRangeAndFeature !== undefined) {
      DeleteFeatureValuesResponse_SelectTimeRangeAndFeature.encode(
        message.selectTimeRangeAndFeature,
        writer.uint32(18).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.selectEntity = DeleteFeatureValuesResponse_SelectEntity.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.selectTimeRangeAndFeature = DeleteFeatureValuesResponse_SelectTimeRangeAndFeature.decode(
            reader,
            reader.uint32(),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesResponse {
    return {
      selectEntity: isSet(object.selectEntity)
        ? DeleteFeatureValuesResponse_SelectEntity.fromJSON(object.selectEntity)
        : undefined,
      selectTimeRangeAndFeature: isSet(object.selectTimeRangeAndFeature)
        ? DeleteFeatureValuesResponse_SelectTimeRangeAndFeature.fromJSON(object.selectTimeRangeAndFeature)
        : undefined,
    };
  },

  toJSON(message: DeleteFeatureValuesResponse): unknown {
    const obj: any = {};
    if (message.selectEntity !== undefined) {
      obj.selectEntity = DeleteFeatureValuesResponse_SelectEntity.toJSON(message.selectEntity);
    }
    if (message.selectTimeRangeAndFeature !== undefined) {
      obj.selectTimeRangeAndFeature = DeleteFeatureValuesResponse_SelectTimeRangeAndFeature.toJSON(
        message.selectTimeRangeAndFeature,
      );
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeatureValuesResponse>): DeleteFeatureValuesResponse {
    return DeleteFeatureValuesResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeatureValuesResponse>): DeleteFeatureValuesResponse {
    const message = createBaseDeleteFeatureValuesResponse();
    message.selectEntity = (object.selectEntity !== undefined && object.selectEntity !== null)
      ? DeleteFeatureValuesResponse_SelectEntity.fromPartial(object.selectEntity)
      : undefined;
    message.selectTimeRangeAndFeature =
      (object.selectTimeRangeAndFeature !== undefined && object.selectTimeRangeAndFeature !== null)
        ? DeleteFeatureValuesResponse_SelectTimeRangeAndFeature.fromPartial(object.selectTimeRangeAndFeature)
        : undefined;
    return message;
  },
};

function createBaseDeleteFeatureValuesResponse_SelectEntity(): DeleteFeatureValuesResponse_SelectEntity {
  return { offlineStorageDeletedEntityRowCount: Long.ZERO, onlineStorageDeletedEntityCount: Long.ZERO };
}

export const DeleteFeatureValuesResponse_SelectEntity: MessageFns<DeleteFeatureValuesResponse_SelectEntity> = {
  encode(message: DeleteFeatureValuesResponse_SelectEntity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.offlineStorageDeletedEntityRowCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.offlineStorageDeletedEntityRowCount.toString());
    }
    if (!message.onlineStorageDeletedEntityCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.onlineStorageDeletedEntityCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesResponse_SelectEntity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesResponse_SelectEntity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.offlineStorageDeletedEntityRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.onlineStorageDeletedEntityCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesResponse_SelectEntity {
    return {
      offlineStorageDeletedEntityRowCount: isSet(object.offlineStorageDeletedEntityRowCount)
        ? Long.fromValue(object.offlineStorageDeletedEntityRowCount)
        : Long.ZERO,
      onlineStorageDeletedEntityCount: isSet(object.onlineStorageDeletedEntityCount)
        ? Long.fromValue(object.onlineStorageDeletedEntityCount)
        : Long.ZERO,
    };
  },

  toJSON(message: DeleteFeatureValuesResponse_SelectEntity): unknown {
    const obj: any = {};
    if (!message.offlineStorageDeletedEntityRowCount.equals(Long.ZERO)) {
      obj.offlineStorageDeletedEntityRowCount = (message.offlineStorageDeletedEntityRowCount || Long.ZERO).toString();
    }
    if (!message.onlineStorageDeletedEntityCount.equals(Long.ZERO)) {
      obj.onlineStorageDeletedEntityCount = (message.onlineStorageDeletedEntityCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(base?: DeepPartial<DeleteFeatureValuesResponse_SelectEntity>): DeleteFeatureValuesResponse_SelectEntity {
    return DeleteFeatureValuesResponse_SelectEntity.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DeleteFeatureValuesResponse_SelectEntity>): DeleteFeatureValuesResponse_SelectEntity {
    const message = createBaseDeleteFeatureValuesResponse_SelectEntity();
    message.offlineStorageDeletedEntityRowCount =
      (object.offlineStorageDeletedEntityRowCount !== undefined && object.offlineStorageDeletedEntityRowCount !== null)
        ? Long.fromValue(object.offlineStorageDeletedEntityRowCount)
        : Long.ZERO;
    message.onlineStorageDeletedEntityCount =
      (object.onlineStorageDeletedEntityCount !== undefined && object.onlineStorageDeletedEntityCount !== null)
        ? Long.fromValue(object.onlineStorageDeletedEntityCount)
        : Long.ZERO;
    return message;
  },
};

function createBaseDeleteFeatureValuesResponse_SelectTimeRangeAndFeature(): DeleteFeatureValuesResponse_SelectTimeRangeAndFeature {
  return {
    impactedFeatureCount: Long.ZERO,
    offlineStorageModifiedEntityRowCount: Long.ZERO,
    onlineStorageModifiedEntityCount: Long.ZERO,
  };
}

export const DeleteFeatureValuesResponse_SelectTimeRangeAndFeature: MessageFns<
  DeleteFeatureValuesResponse_SelectTimeRangeAndFeature
> = {
  encode(
    message: DeleteFeatureValuesResponse_SelectTimeRangeAndFeature,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (!message.impactedFeatureCount.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.impactedFeatureCount.toString());
    }
    if (!message.offlineStorageModifiedEntityRowCount.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.offlineStorageModifiedEntityRowCount.toString());
    }
    if (!message.onlineStorageModifiedEntityCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.onlineStorageModifiedEntityCount.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteFeatureValuesResponse_SelectTimeRangeAndFeature {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteFeatureValuesResponse_SelectTimeRangeAndFeature();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.impactedFeatureCount = Long.fromString(reader.int64().toString());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.offlineStorageModifiedEntityRowCount = Long.fromString(reader.int64().toString());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.onlineStorageModifiedEntityCount = Long.fromString(reader.int64().toString());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteFeatureValuesResponse_SelectTimeRangeAndFeature {
    return {
      impactedFeatureCount: isSet(object.impactedFeatureCount)
        ? Long.fromValue(object.impactedFeatureCount)
        : Long.ZERO,
      offlineStorageModifiedEntityRowCount: isSet(object.offlineStorageModifiedEntityRowCount)
        ? Long.fromValue(object.offlineStorageModifiedEntityRowCount)
        : Long.ZERO,
      onlineStorageModifiedEntityCount: isSet(object.onlineStorageModifiedEntityCount)
        ? Long.fromValue(object.onlineStorageModifiedEntityCount)
        : Long.ZERO,
    };
  },

  toJSON(message: DeleteFeatureValuesResponse_SelectTimeRangeAndFeature): unknown {
    const obj: any = {};
    if (!message.impactedFeatureCount.equals(Long.ZERO)) {
      obj.impactedFeatureCount = (message.impactedFeatureCount || Long.ZERO).toString();
    }
    if (!message.offlineStorageModifiedEntityRowCount.equals(Long.ZERO)) {
      obj.offlineStorageModifiedEntityRowCount = (message.offlineStorageModifiedEntityRowCount || Long.ZERO).toString();
    }
    if (!message.onlineStorageModifiedEntityCount.equals(Long.ZERO)) {
      obj.onlineStorageModifiedEntityCount = (message.onlineStorageModifiedEntityCount || Long.ZERO).toString();
    }
    return obj;
  },

  create(
    base?: DeepPartial<DeleteFeatureValuesResponse_SelectTimeRangeAndFeature>,
  ): DeleteFeatureValuesResponse_SelectTimeRangeAndFeature {
    return DeleteFeatureValuesResponse_SelectTimeRangeAndFeature.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<DeleteFeatureValuesResponse_SelectTimeRangeAndFeature>,
  ): DeleteFeatureValuesResponse_SelectTimeRangeAndFeature {
    const message = createBaseDeleteFeatureValuesResponse_SelectTimeRangeAndFeature();
    message.impactedFeatureCount = (object.impactedFeatureCount !== undefined && object.impactedFeatureCount !== null)
      ? Long.fromValue(object.impactedFeatureCount)
      : Long.ZERO;
    message.offlineStorageModifiedEntityRowCount =
      (object.offlineStorageModifiedEntityRowCount !== undefined &&
          object.offlineStorageModifiedEntityRowCount !== null)
        ? Long.fromValue(object.offlineStorageModifiedEntityRowCount)
        : Long.ZERO;
    message.onlineStorageModifiedEntityCount =
      (object.onlineStorageModifiedEntityCount !== undefined && object.onlineStorageModifiedEntityCount !== null)
        ? Long.fromValue(object.onlineStorageModifiedEntityCount)
        : Long.ZERO;
    return message;
  },
};

function createBaseEntityIdSelector(): EntityIdSelector {
  return { csvSource: undefined, entityIdField: "" };
}

export const EntityIdSelector: MessageFns<EntityIdSelector> = {
  encode(message: EntityIdSelector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.csvSource !== undefined) {
      CsvSource.encode(message.csvSource, writer.uint32(26).fork()).join();
    }
    if (message.entityIdField !== "") {
      writer.uint32(42).string(message.entityIdField);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EntityIdSelector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEntityIdSelector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3:
          if (tag !== 26) {
            break;
          }

          message.csvSource = CsvSource.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.entityIdField = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EntityIdSelector {
    return {
      csvSource: isSet(object.csvSource) ? CsvSource.fromJSON(object.csvSource) : undefined,
      entityIdField: isSet(object.entityIdField) ? globalThis.String(object.entityIdField) : "",
    };
  },

  toJSON(message: EntityIdSelector): unknown {
    const obj: any = {};
    if (message.csvSource !== undefined) {
      obj.csvSource = CsvSource.toJSON(message.csvSource);
    }
    if (message.entityIdField !== "") {
      obj.entityIdField = message.entityIdField;
    }
    return obj;
  },

  create(base?: DeepPartial<EntityIdSelector>): EntityIdSelector {
    return EntityIdSelector.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<EntityIdSelector>): EntityIdSelector {
    const message = createBaseEntityIdSelector();
    message.csvSource = (object.csvSource !== undefined && object.csvSource !== null)
      ? CsvSource.fromPartial(object.csvSource)
      : undefined;
    message.entityIdField = object.entityIdField ?? "";
    return message;
  },
};

/** The service that handles CRUD and List for resources for Featurestore. */
export type FeaturestoreServiceDefinition = typeof FeaturestoreServiceDefinition;
export const FeaturestoreServiceDefinition = {
  name: "FeaturestoreService",
  fullName: "google.cloud.aiplatform.v1beta1.FeaturestoreService",
  methods: {
    /** Creates a new Featurestore in a given project and location. */
    createFeaturestore: {
      name: "CreateFeaturestore",
      requestType: CreateFeaturestoreRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              51,
              10,
              12,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              18,
              35,
              67,
              114,
              101,
              97,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              19,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
            ]),
            Buffer.from([
              35,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              70,
              58,
              12,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              34,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details of a single Featurestore. */
    getFeaturestore: {
      name: "GetFeaturestore",
      requestType: GetFeaturestoreRequest,
      requestStream: false,
      responseType: Featurestore,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists Featurestores in a given project and location. */
    listFeaturestores: {
      name: "ListFeaturestores",
      requestType: ListFeaturestoresRequest,
      requestStream: false,
      responseType: ListFeaturestoresResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              56,
              18,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates the parameters of a single Featurestore. */
    updateFeaturestore: {
      name: "UpdateFeaturestore",
      requestType: UpdateFeaturestoreRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              51,
              10,
              12,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              18,
              35,
              85,
              112,
              100,
              97,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([
              24,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              83,
              58,
              12,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              50,
              67,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a single Featurestore. The Featurestore must not contain any
     * EntityTypes or `force` must be set to true for the request to succeed.
     */
    deleteFeaturestore: {
      name: "DeleteFeaturestore",
      requestType: DeleteFeaturestoreRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101]), Buffer.from([10, 110, 97, 109, 101, 44, 102, 111, 114, 99, 101])],
          578365826: [
            Buffer.from([
              56,
              42,
              54,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new EntityType in a given Featurestore. */
    createEntityType: {
      name: "CreateEntityType",
      requestType: CreateEntityTypeRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              47,
              10,
              10,
              69,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              18,
              33,
              67,
              114,
              101,
              97,
              116,
              101,
              69,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([18, 112, 97, 114, 101, 110, 116, 44, 101, 110, 116, 105, 116, 121, 95, 116, 121, 112, 101]),
            Buffer.from([
              33,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              44,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              83,
              58,
              11,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              34,
              68,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              125,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Gets details of a single EntityType. */
    getEntityType: {
      name: "GetEntityType",
      requestType: GetEntityTypeRequest,
      requestStream: false,
      responseType: EntityType,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              70,
              18,
              68,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists EntityTypes in a given Featurestore. */
    listEntityTypes: {
      name: "ListEntityTypes",
      requestType: ListEntityTypesRequest,
      requestStream: false,
      responseType: ListEntityTypesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              70,
              18,
              68,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              125,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates the parameters of a single EntityType. */
    updateEntityType: {
      name: "UpdateEntityType",
      requestType: UpdateEntityTypeRequest,
      requestStream: false,
      responseType: EntityType,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([
              23,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              44,
              117,
              112,
              100,
              97,
              116,
              101,
              95,
              109,
              97,
              115,
              107,
            ]),
          ],
          578365826: [
            Buffer.from([
              95,
              58,
              11,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              50,
              80,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Deletes a single EntityType. The EntityType must not have any Features
     * or `force` must be set to true for the request to succeed.
     */
    deleteEntityType: {
      name: "DeleteEntityType",
      requestType: DeleteEntityTypeRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101]), Buffer.from([10, 110, 97, 109, 101, 44, 102, 111, 114, 99, 101])],
          578365826: [
            Buffer.from([
              70,
              42,
              68,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Creates a new Feature in a given EntityType. */
    createFeature: {
      name: "CreateFeature",
      requestType: CreateFeatureRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              41,
              10,
              7,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              18,
              30,
              67,
              114,
              101,
              97,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [
            Buffer.from([14, 112, 97, 114, 101, 110, 116, 44, 102, 101, 97, 116, 117, 114, 101]),
            Buffer.from([
              25,
              112,
              97,
              114,
              101,
              110,
              116,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              44,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              95,
              105,
              100,
            ]),
          ],
          578365826: [
            Buffer.from([
              90,
              58,
              7,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              34,
              79,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Creates a batch of Features in a given EntityType. */
    batchCreateFeatures: {
      name: "BatchCreateFeatures",
      requestType: BatchCreateFeaturesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              67,
              10,
              27,
              66,
              97,
              116,
              99,
              104,
              67,
              114,
              101,
              97,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              36,
              66,
              97,
              116,
              99,
              104,
              67,
              114,
              101,
              97,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([15, 112, 97, 114, 101, 110, 116, 44, 114, 101, 113, 117, 101, 115, 116, 115])],
          578365826: [
            Buffer.from([
              96,
              58,
              1,
              42,
              34,
              91,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              58,
              98,
              97,
              116,
              99,
              104,
              67,
              114,
              101,
              97,
              116,
              101,
            ]),
          ],
        },
      },
    },
    /** Gets details of a single Feature. */
    getFeature: {
      name: "GetFeature",
      requestType: GetFeatureRequest,
      requestStream: false,
      responseType: Feature,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              81,
              18,
              79,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Lists Features in a given EntityType. */
    listFeatures: {
      name: "ListFeatures",
      requestType: ListFeaturesRequest,
      requestStream: false,
      responseType: ListFeaturesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [Buffer.from([6, 112, 97, 114, 101, 110, 116])],
          578365826: [
            Buffer.from([
              81,
              18,
              79,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              112,
              97,
              114,
              101,
              110,
              116,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Updates the parameters of a single Feature. */
    updateFeature: {
      name: "UpdateFeature",
      requestType: UpdateFeatureRequest,
      requestStream: false,
      responseType: Feature,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([19, 102, 101, 97, 116, 117, 114, 101, 44, 117, 112, 100, 97, 116, 101, 95, 109, 97, 115, 107]),
          ],
          578365826: [
            Buffer.from([
              98,
              58,
              7,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              50,
              87,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              46,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /** Deletes a single Feature. */
    deleteFeature: {
      name: "DeleteFeature",
      requestType: DeleteFeatureRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              48,
              10,
              21,
              103,
              111,
              111,
              103,
              108,
              101,
              46,
              112,
              114,
              111,
              116,
              111,
              98,
              117,
              102,
              46,
              69,
              109,
              112,
              116,
              121,
              18,
              23,
              68,
              101,
              108,
              101,
              116,
              101,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([4, 110, 97, 109, 101])],
          578365826: [
            Buffer.from([
              81,
              42,
              79,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              110,
              97,
              109,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              47,
              42,
              125,
            ]),
          ],
        },
      },
    },
    /**
     * Imports Feature values into the Featurestore from a source storage.
     *
     * The progress of the import is tracked by the returned operation. The
     * imported features are guaranteed to be visible to subsequent read
     * operations after the operation is marked as successfully done.
     *
     * If an import operation fails, the Feature values returned from
     * reads and exports may be inconsistent. If consistency is
     * required, the caller must retry the same import request again and wait till
     * the new operation returned is marked as successfully done.
     *
     * There are also scenarios where the caller can cause inconsistency.
     *
     *  - Source data for import contains multiple distinct Feature values for
     *    the same entity ID and timestamp.
     *  - Source is modified during an import. This includes adding, updating, or
     *  removing source data and/or metadata. Examples of updating metadata
     *  include but are not limited to changing storage location, storage class,
     *  or retention policy.
     *  - Online serving cluster is under-provisioned.
     */
    importFeatureValues: {
      name: "ImportFeatureValues",
      requestType: ImportFeatureValuesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              67,
              10,
              27,
              73,
              109,
              112,
              111,
              114,
              116,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              36,
              73,
              109,
              112,
              111,
              114,
              116,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([11, 101, 110, 116, 105, 116, 121, 95, 116, 121, 112, 101])],
          578365826: [
            Buffer.from([
              100,
              58,
              1,
              42,
              34,
              95,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              58,
              105,
              109,
              112,
              111,
              114,
              116,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Batch reads Feature values from a Featurestore.
     *
     * This API enables batch reading Feature values, where each read
     * instance in the batch may read Feature values of entities from one or
     * more EntityTypes. Point-in-time correctness is guaranteed for Feature
     * values of each read instance as of each instance's read timestamp.
     */
    batchReadFeatureValues: {
      name: "BatchReadFeatureValues",
      requestType: BatchReadFeatureValuesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              73,
              10,
              30,
              66,
              97,
              116,
              99,
              104,
              82,
              101,
              97,
              100,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              39,
              66,
              97,
              116,
              99,
              104,
              82,
              101,
              97,
              100,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([12, 102, 101, 97, 116, 117, 114, 101, 115, 116, 111, 114, 101])],
          578365826: [
            Buffer.from([
              90,
              58,
              1,
              42,
              34,
              85,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              125,
              58,
              98,
              97,
              116,
              99,
              104,
              82,
              101,
              97,
              100,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Exports Feature values from all the entities of a target EntityType. */
    exportFeatureValues: {
      name: "ExportFeatureValues",
      requestType: ExportFeatureValuesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              67,
              10,
              27,
              69,
              120,
              112,
              111,
              114,
              116,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              36,
              69,
              120,
              112,
              111,
              114,
              116,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([11, 101, 110, 116, 105, 116, 121, 95, 116, 121, 112, 101])],
          578365826: [
            Buffer.from([
              100,
              58,
              1,
              42,
              34,
              95,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              58,
              101,
              120,
              112,
              111,
              114,
              116,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /**
     * Delete Feature values from Featurestore.
     *
     * The progress of the deletion is tracked by the returned operation. The
     * deleted feature values are guaranteed to be invisible to subsequent read
     * operations after the operation is marked as successfully done.
     *
     * If a delete feature values operation fails, the feature values
     * returned from reads and exports may be inconsistent. If consistency is
     * required, the caller must retry the same delete request again and wait till
     * the new operation returned is marked as successfully done.
     */
    deleteFeatureValues: {
      name: "DeleteFeatureValues",
      requestType: DeleteFeatureValuesRequest,
      requestStream: false,
      responseType: Operation,
      responseStream: false,
      options: {
        _unknownFields: {
          8394: [
            Buffer.from([
              67,
              10,
              27,
              68,
              101,
              108,
              101,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              82,
              101,
              115,
              112,
              111,
              110,
              115,
              101,
              18,
              36,
              68,
              101,
              108,
              101,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
              79,
              112,
              101,
              114,
              97,
              116,
              105,
              111,
              110,
              77,
              101,
              116,
              97,
              100,
              97,
              116,
              97,
            ]),
          ],
          8410: [Buffer.from([11, 101, 110, 116, 105, 116, 121, 95, 116, 121, 112, 101])],
          578365826: [
            Buffer.from([
              100,
              58,
              1,
              42,
              34,
              95,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              101,
              110,
              116,
              105,
              116,
              121,
              95,
              116,
              121,
              112,
              101,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              47,
              42,
              47,
              101,
              110,
              116,
              105,
              116,
              121,
              84,
              121,
              112,
              101,
              115,
              47,
              42,
              125,
              58,
              100,
              101,
              108,
              101,
              116,
              101,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              86,
              97,
              108,
              117,
              101,
              115,
            ]),
          ],
        },
      },
    },
    /** Searches Features matching a query in a given project. */
    searchFeatures: {
      name: "SearchFeatures",
      requestType: SearchFeaturesRequest,
      requestStream: false,
      responseType: SearchFeaturesResponse,
      responseStream: false,
      options: {
        _unknownFields: {
          8410: [
            Buffer.from([8, 108, 111, 99, 97, 116, 105, 111, 110]),
            Buffer.from([14, 108, 111, 99, 97, 116, 105, 111, 110, 44, 113, 117, 101, 114, 121]),
          ],
          578365826: [
            Buffer.from([
              73,
              18,
              71,
              47,
              118,
              49,
              98,
              101,
              116,
              97,
              49,
              47,
              123,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              61,
              112,
              114,
              111,
              106,
              101,
              99,
              116,
              115,
              47,
              42,
              47,
              108,
              111,
              99,
              97,
              116,
              105,
              111,
              110,
              115,
              47,
              42,
              125,
              47,
              102,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
              116,
              111,
              114,
              101,
              115,
              58,
              115,
              101,
              97,
              114,
              99,
              104,
              70,
              101,
              97,
              116,
              117,
              114,
              101,
              115,
            ]),
          ],
        },
      },
    },
  },
} as const;

export interface FeaturestoreServiceImplementation<CallContextExt = {}> {
  /** Creates a new Featurestore in a given project and location. */
  createFeaturestore(
    request: CreateFeaturestoreRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets details of a single Featurestore. */
  getFeaturestore(
    request: GetFeaturestoreRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Featurestore>>;
  /** Lists Featurestores in a given project and location. */
  listFeaturestores(
    request: ListFeaturestoresRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListFeaturestoresResponse>>;
  /** Updates the parameters of a single Featurestore. */
  updateFeaturestore(
    request: UpdateFeaturestoreRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Deletes a single Featurestore. The Featurestore must not contain any
   * EntityTypes or `force` must be set to true for the request to succeed.
   */
  deleteFeaturestore(
    request: DeleteFeaturestoreRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Creates a new EntityType in a given Featurestore. */
  createEntityType(
    request: CreateEntityTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets details of a single EntityType. */
  getEntityType(request: GetEntityTypeRequest, context: CallContext & CallContextExt): Promise<DeepPartial<EntityType>>;
  /** Lists EntityTypes in a given Featurestore. */
  listEntityTypes(
    request: ListEntityTypesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListEntityTypesResponse>>;
  /** Updates the parameters of a single EntityType. */
  updateEntityType(
    request: UpdateEntityTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<EntityType>>;
  /**
   * Deletes a single EntityType. The EntityType must not have any Features
   * or `force` must be set to true for the request to succeed.
   */
  deleteEntityType(
    request: DeleteEntityTypeRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Creates a new Feature in a given EntityType. */
  createFeature(request: CreateFeatureRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /** Creates a batch of Features in a given EntityType. */
  batchCreateFeatures(
    request: BatchCreateFeaturesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Gets details of a single Feature. */
  getFeature(request: GetFeatureRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Feature>>;
  /** Lists Features in a given EntityType. */
  listFeatures(
    request: ListFeaturesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<ListFeaturesResponse>>;
  /** Updates the parameters of a single Feature. */
  updateFeature(request: UpdateFeatureRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Feature>>;
  /** Deletes a single Feature. */
  deleteFeature(request: DeleteFeatureRequest, context: CallContext & CallContextExt): Promise<DeepPartial<Operation>>;
  /**
   * Imports Feature values into the Featurestore from a source storage.
   *
   * The progress of the import is tracked by the returned operation. The
   * imported features are guaranteed to be visible to subsequent read
   * operations after the operation is marked as successfully done.
   *
   * If an import operation fails, the Feature values returned from
   * reads and exports may be inconsistent. If consistency is
   * required, the caller must retry the same import request again and wait till
   * the new operation returned is marked as successfully done.
   *
   * There are also scenarios where the caller can cause inconsistency.
   *
   *  - Source data for import contains multiple distinct Feature values for
   *    the same entity ID and timestamp.
   *  - Source is modified during an import. This includes adding, updating, or
   *  removing source data and/or metadata. Examples of updating metadata
   *  include but are not limited to changing storage location, storage class,
   *  or retention policy.
   *  - Online serving cluster is under-provisioned.
   */
  importFeatureValues(
    request: ImportFeatureValuesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Batch reads Feature values from a Featurestore.
   *
   * This API enables batch reading Feature values, where each read
   * instance in the batch may read Feature values of entities from one or
   * more EntityTypes. Point-in-time correctness is guaranteed for Feature
   * values of each read instance as of each instance's read timestamp.
   */
  batchReadFeatureValues(
    request: BatchReadFeatureValuesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Exports Feature values from all the entities of a target EntityType. */
  exportFeatureValues(
    request: ExportFeatureValuesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /**
   * Delete Feature values from Featurestore.
   *
   * The progress of the deletion is tracked by the returned operation. The
   * deleted feature values are guaranteed to be invisible to subsequent read
   * operations after the operation is marked as successfully done.
   *
   * If a delete feature values operation fails, the feature values
   * returned from reads and exports may be inconsistent. If consistency is
   * required, the caller must retry the same delete request again and wait till
   * the new operation returned is marked as successfully done.
   */
  deleteFeatureValues(
    request: DeleteFeatureValuesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<Operation>>;
  /** Searches Features matching a query in a given project. */
  searchFeatures(
    request: SearchFeaturesRequest,
    context: CallContext & CallContextExt,
  ): Promise<DeepPartial<SearchFeaturesResponse>>;
}

export interface FeaturestoreServiceClient<CallOptionsExt = {}> {
  /** Creates a new Featurestore in a given project and location. */
  createFeaturestore(
    request: DeepPartial<CreateFeaturestoreRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets details of a single Featurestore. */
  getFeaturestore(
    request: DeepPartial<GetFeaturestoreRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Featurestore>;
  /** Lists Featurestores in a given project and location. */
  listFeaturestores(
    request: DeepPartial<ListFeaturestoresRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListFeaturestoresResponse>;
  /** Updates the parameters of a single Featurestore. */
  updateFeaturestore(
    request: DeepPartial<UpdateFeaturestoreRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Deletes a single Featurestore. The Featurestore must not contain any
   * EntityTypes or `force` must be set to true for the request to succeed.
   */
  deleteFeaturestore(
    request: DeepPartial<DeleteFeaturestoreRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Creates a new EntityType in a given Featurestore. */
  createEntityType(
    request: DeepPartial<CreateEntityTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets details of a single EntityType. */
  getEntityType(
    request: DeepPartial<GetEntityTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<EntityType>;
  /** Lists EntityTypes in a given Featurestore. */
  listEntityTypes(
    request: DeepPartial<ListEntityTypesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListEntityTypesResponse>;
  /** Updates the parameters of a single EntityType. */
  updateEntityType(
    request: DeepPartial<UpdateEntityTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<EntityType>;
  /**
   * Deletes a single EntityType. The EntityType must not have any Features
   * or `force` must be set to true for the request to succeed.
   */
  deleteEntityType(
    request: DeepPartial<DeleteEntityTypeRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Creates a new Feature in a given EntityType. */
  createFeature(request: DeepPartial<CreateFeatureRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /** Creates a batch of Features in a given EntityType. */
  batchCreateFeatures(
    request: DeepPartial<BatchCreateFeaturesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Gets details of a single Feature. */
  getFeature(request: DeepPartial<GetFeatureRequest>, options?: CallOptions & CallOptionsExt): Promise<Feature>;
  /** Lists Features in a given EntityType. */
  listFeatures(
    request: DeepPartial<ListFeaturesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<ListFeaturesResponse>;
  /** Updates the parameters of a single Feature. */
  updateFeature(request: DeepPartial<UpdateFeatureRequest>, options?: CallOptions & CallOptionsExt): Promise<Feature>;
  /** Deletes a single Feature. */
  deleteFeature(request: DeepPartial<DeleteFeatureRequest>, options?: CallOptions & CallOptionsExt): Promise<Operation>;
  /**
   * Imports Feature values into the Featurestore from a source storage.
   *
   * The progress of the import is tracked by the returned operation. The
   * imported features are guaranteed to be visible to subsequent read
   * operations after the operation is marked as successfully done.
   *
   * If an import operation fails, the Feature values returned from
   * reads and exports may be inconsistent. If consistency is
   * required, the caller must retry the same import request again and wait till
   * the new operation returned is marked as successfully done.
   *
   * There are also scenarios where the caller can cause inconsistency.
   *
   *  - Source data for import contains multiple distinct Feature values for
   *    the same entity ID and timestamp.
   *  - Source is modified during an import. This includes adding, updating, or
   *  removing source data and/or metadata. Examples of updating metadata
   *  include but are not limited to changing storage location, storage class,
   *  or retention policy.
   *  - Online serving cluster is under-provisioned.
   */
  importFeatureValues(
    request: DeepPartial<ImportFeatureValuesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Batch reads Feature values from a Featurestore.
   *
   * This API enables batch reading Feature values, where each read
   * instance in the batch may read Feature values of entities from one or
   * more EntityTypes. Point-in-time correctness is guaranteed for Feature
   * values of each read instance as of each instance's read timestamp.
   */
  batchReadFeatureValues(
    request: DeepPartial<BatchReadFeatureValuesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Exports Feature values from all the entities of a target EntityType. */
  exportFeatureValues(
    request: DeepPartial<ExportFeatureValuesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /**
   * Delete Feature values from Featurestore.
   *
   * The progress of the deletion is tracked by the returned operation. The
   * deleted feature values are guaranteed to be invisible to subsequent read
   * operations after the operation is marked as successfully done.
   *
   * If a delete feature values operation fails, the feature values
   * returned from reads and exports may be inconsistent. If consistency is
   * required, the caller must retry the same delete request again and wait till
   * the new operation returned is marked as successfully done.
   */
  deleteFeatureValues(
    request: DeepPartial<DeleteFeatureValuesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<Operation>;
  /** Searches Features matching a query in a given project. */
  searchFeatures(
    request: DeepPartial<SearchFeaturesRequest>,
    options?: CallOptions & CallOptionsExt,
  ): Promise<SearchFeaturesResponse>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
