// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/schema/predict/prediction/text_extraction.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";

export const protobufPackage = "google.cloud.aiplatform.v1beta1.schema.predict.prediction";

/** Prediction output format for Text Extraction. */
export interface TextExtractionPredictionResult {
  /**
   * The resource IDs of the AnnotationSpecs that had been identified,
   * ordered by the confidence score descendingly.
   */
  ids: Long[];
  /**
   * The display names of the AnnotationSpecs that had been identified,
   * order matches the IDs.
   */
  displayNames: string[];
  /**
   * The start offsets, inclusive, of the text segment in which the
   * AnnotationSpec has been identified. Expressed as a zero-based number
   * of characters as measured from the start of the text snippet.
   */
  textSegmentStartOffsets: Long[];
  /**
   * The end offsets, inclusive, of the text segment in which the
   * AnnotationSpec has been identified. Expressed as a zero-based number
   * of characters as measured from the start of the text snippet.
   */
  textSegmentEndOffsets: Long[];
  /**
   * The Model's confidences in correctness of the predicted IDs, higher
   * value means higher confidence. Order matches the Ids.
   */
  confidences: number[];
}

function createBaseTextExtractionPredictionResult(): TextExtractionPredictionResult {
  return { ids: [], displayNames: [], textSegmentStartOffsets: [], textSegmentEndOffsets: [], confidences: [] };
}

export const TextExtractionPredictionResult: MessageFns<TextExtractionPredictionResult> = {
  encode(message: TextExtractionPredictionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.ids) {
      writer.int64(v.toString());
    }
    writer.join();
    for (const v of message.displayNames) {
      writer.uint32(18).string(v!);
    }
    writer.uint32(26).fork();
    for (const v of message.textSegmentStartOffsets) {
      writer.int64(v.toString());
    }
    writer.join();
    writer.uint32(34).fork();
    for (const v of message.textSegmentEndOffsets) {
      writer.int64(v.toString());
    }
    writer.join();
    writer.uint32(42).fork();
    for (const v of message.confidences) {
      writer.float(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextExtractionPredictionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextExtractionPredictionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag === 8) {
            message.ids.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.ids.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayNames.push(reader.string());
          continue;
        case 3:
          if (tag === 24) {
            message.textSegmentStartOffsets.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 26) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.textSegmentStartOffsets.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
        case 4:
          if (tag === 32) {
            message.textSegmentEndOffsets.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 34) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.textSegmentEndOffsets.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
        case 5:
          if (tag === 45) {
            message.confidences.push(reader.float());

            continue;
          }

          if (tag === 42) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.confidences.push(reader.float());
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextExtractionPredictionResult {
    return {
      ids: globalThis.Array.isArray(object?.ids) ? object.ids.map((e: any) => Long.fromValue(e)) : [],
      displayNames: globalThis.Array.isArray(object?.displayNames)
        ? object.displayNames.map((e: any) => globalThis.String(e))
        : [],
      textSegmentStartOffsets: globalThis.Array.isArray(object?.textSegmentStartOffsets)
        ? object.textSegmentStartOffsets.map((e: any) => Long.fromValue(e))
        : [],
      textSegmentEndOffsets: globalThis.Array.isArray(object?.textSegmentEndOffsets)
        ? object.textSegmentEndOffsets.map((e: any) => Long.fromValue(e))
        : [],
      confidences: globalThis.Array.isArray(object?.confidences)
        ? object.confidences.map((e: any) => globalThis.Number(e))
        : [],
    };
  },

  toJSON(message: TextExtractionPredictionResult): unknown {
    const obj: any = {};
    if (message.ids?.length) {
      obj.ids = message.ids.map((e) => (e || Long.ZERO).toString());
    }
    if (message.displayNames?.length) {
      obj.displayNames = message.displayNames;
    }
    if (message.textSegmentStartOffsets?.length) {
      obj.textSegmentStartOffsets = message.textSegmentStartOffsets.map((e) => (e || Long.ZERO).toString());
    }
    if (message.textSegmentEndOffsets?.length) {
      obj.textSegmentEndOffsets = message.textSegmentEndOffsets.map((e) => (e || Long.ZERO).toString());
    }
    if (message.confidences?.length) {
      obj.confidences = message.confidences;
    }
    return obj;
  },

  create(base?: DeepPartial<TextExtractionPredictionResult>): TextExtractionPredictionResult {
    return TextExtractionPredictionResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<TextExtractionPredictionResult>): TextExtractionPredictionResult {
    const message = createBaseTextExtractionPredictionResult();
    message.ids = object.ids?.map((e) => Long.fromValue(e)) || [];
    message.displayNames = object.displayNames?.map((e) => e) || [];
    message.textSegmentStartOffsets = object.textSegmentStartOffsets?.map((e) => Long.fromValue(e)) || [];
    message.textSegmentEndOffsets = object.textSegmentEndOffsets?.map((e) => Long.fromValue(e)) || [];
    message.confidences = object.confidences?.map((e) => e) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
