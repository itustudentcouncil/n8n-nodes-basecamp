// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/model_deployment_monitoring_job.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../protobuf/duration.js";
import { Value } from "../../../protobuf/struct.js";
import { Timestamp } from "../../../protobuf/timestamp.js";
import { Status } from "../../../rpc/status.js";
import { EncryptionSpec } from "./encryption_spec.js";
import { FeatureStatsAnomaly } from "./feature_monitoring_stats.js";
import { GcsDestination } from "./io.js";
import { JobState, jobStateFromJSON, jobStateToJSON } from "./job_state.js";
import {
  ModelMonitoringAlertConfig,
  ModelMonitoringObjectiveConfig,
  SamplingStrategy,
  ThresholdConfig,
} from "./model_monitoring.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/** The Model Monitoring Objective types. */
export enum ModelDeploymentMonitoringObjectiveType {
  /** MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED - Default value, should not be set. */
  MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED = 0,
  /**
   * RAW_FEATURE_SKEW - Raw feature values' stats to detect skew between Training-Prediction
   * datasets.
   */
  RAW_FEATURE_SKEW = 1,
  /**
   * RAW_FEATURE_DRIFT - Raw feature values' stats to detect drift between Serving-Prediction
   * datasets.
   */
  RAW_FEATURE_DRIFT = 2,
  /**
   * FEATURE_ATTRIBUTION_SKEW - Feature attribution scores to detect skew between Training-Prediction
   * datasets.
   */
  FEATURE_ATTRIBUTION_SKEW = 3,
  /**
   * FEATURE_ATTRIBUTION_DRIFT - Feature attribution scores to detect skew between Prediction datasets
   * collected within different time windows.
   */
  FEATURE_ATTRIBUTION_DRIFT = 4,
  UNRECOGNIZED = -1,
}

export function modelDeploymentMonitoringObjectiveTypeFromJSON(object: any): ModelDeploymentMonitoringObjectiveType {
  switch (object) {
    case 0:
    case "MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED":
      return ModelDeploymentMonitoringObjectiveType.MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED;
    case 1:
    case "RAW_FEATURE_SKEW":
      return ModelDeploymentMonitoringObjectiveType.RAW_FEATURE_SKEW;
    case 2:
    case "RAW_FEATURE_DRIFT":
      return ModelDeploymentMonitoringObjectiveType.RAW_FEATURE_DRIFT;
    case 3:
    case "FEATURE_ATTRIBUTION_SKEW":
      return ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW;
    case 4:
    case "FEATURE_ATTRIBUTION_DRIFT":
      return ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ModelDeploymentMonitoringObjectiveType.UNRECOGNIZED;
  }
}

export function modelDeploymentMonitoringObjectiveTypeToJSON(object: ModelDeploymentMonitoringObjectiveType): string {
  switch (object) {
    case ModelDeploymentMonitoringObjectiveType.MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED:
      return "MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED";
    case ModelDeploymentMonitoringObjectiveType.RAW_FEATURE_SKEW:
      return "RAW_FEATURE_SKEW";
    case ModelDeploymentMonitoringObjectiveType.RAW_FEATURE_DRIFT:
      return "RAW_FEATURE_DRIFT";
    case ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW:
      return "FEATURE_ATTRIBUTION_SKEW";
    case ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT:
      return "FEATURE_ATTRIBUTION_DRIFT";
    case ModelDeploymentMonitoringObjectiveType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Represents a job that runs periodically to monitor the deployed models in an
 * endpoint. It will analyze the logged training & prediction data to detect any
 * abnormal behaviors.
 */
export interface ModelDeploymentMonitoringJob {
  /** Output only. Resource name of a ModelDeploymentMonitoringJob. */
  name: string;
  /**
   * Required. The user-defined name of the ModelDeploymentMonitoringJob.
   * The name can be up to 128 characters long and can consist of any UTF-8
   * characters.
   * Display name of a ModelDeploymentMonitoringJob.
   */
  displayName: string;
  /**
   * Required. Endpoint resource name.
   * Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
   */
  endpoint: string;
  /**
   * Output only. The detailed state of the monitoring job.
   * When the job is still creating, the state will be 'PENDING'.
   * Once the job is successfully created, the state will be 'RUNNING'.
   * Pause the job, the state will be 'PAUSED'.
   * Resume the job, the state will return to 'RUNNING'.
   */
  state: JobState;
  /** Output only. Schedule state when the monitoring job is in Running state. */
  scheduleState: ModelDeploymentMonitoringJob_MonitoringScheduleState;
  /** Output only. Latest triggered monitoring pipeline metadata. */
  latestMonitoringPipelineMetadata:
    | ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata
    | undefined;
  /**
   * Required. The config for monitoring objectives. This is a per DeployedModel
   * config. Each DeployedModel needs to be configured separately.
   */
  modelDeploymentMonitoringObjectiveConfigs: ModelDeploymentMonitoringObjectiveConfig[];
  /** Required. Schedule config for running the monitoring job. */
  modelDeploymentMonitoringScheduleConfig:
    | ModelDeploymentMonitoringScheduleConfig
    | undefined;
  /** Required. Sample Strategy for logging. */
  loggingSamplingStrategy:
    | SamplingStrategy
    | undefined;
  /** Alert config for model monitoring. */
  modelMonitoringAlertConfig:
    | ModelMonitoringAlertConfig
    | undefined;
  /**
   * YAML schema file uri describing the format of a single instance,
   * which are given to format this Endpoint's prediction (and explanation).
   * If not set, we will generate predict schema from collected predict
   * requests.
   */
  predictInstanceSchemaUri: string;
  /**
   * Sample Predict instance, same format as
   * [PredictRequest.instances][google.cloud.aiplatform.v1beta1.PredictRequest.instances],
   * this can be set as a replacement of
   * [ModelDeploymentMonitoringJob.predict_instance_schema_uri][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringJob.predict_instance_schema_uri].
   * If not set, we will generate predict schema from collected predict
   * requests.
   */
  samplePredictInstance:
    | any
    | undefined;
  /**
   * YAML schema file uri describing the format of a single instance that you
   * want Tensorflow Data Validation (TFDV) to analyze.
   *
   * If this field is empty, all the feature data types are inferred from
   * [predict_instance_schema_uri][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringJob.predict_instance_schema_uri],
   * meaning that TFDV will use the data in the exact format(data type) as
   * prediction request/response.
   * If there are any data type differences between predict instance and TFDV
   * instance, this field can be used to override the schema.
   * For models trained with Vertex AI, this field must be set as all the
   * fields in predict instance formatted as string.
   */
  analysisInstanceSchemaUri: string;
  /**
   * Output only. The created bigquery tables for the job under customer
   * project. Customer could do their own query & analysis. There could be 4 log
   * tables in maximum:
   * 1. Training data logging predict request/response
   * 2. Serving data logging predict request/response
   */
  bigqueryTables: ModelDeploymentMonitoringBigQueryTable[];
  /**
   * The TTL of BigQuery tables in user projects which stores logs.
   * A day is the basic unit of the TTL and we take the ceil of TTL/86400(a
   * day). e.g. { second: 3600} indicates ttl = 1 day.
   */
  logTtl:
    | Duration
    | undefined;
  /**
   * The labels with user-defined metadata to organize your
   * ModelDeploymentMonitoringJob.
   *
   * Label keys and values can be no longer than 64 characters
   * (Unicode codepoints), can only contain lowercase letters, numeric
   * characters, underscores and dashes. International characters are allowed.
   *
   * See https://goo.gl/xmQnxf for more information and examples of labels.
   */
  labels: { [key: string]: string };
  /** Output only. Timestamp when this ModelDeploymentMonitoringJob was created. */
  createTime:
    | Date
    | undefined;
  /**
   * Output only. Timestamp when this ModelDeploymentMonitoringJob was updated
   * most recently.
   */
  updateTime:
    | Date
    | undefined;
  /**
   * Output only. Timestamp when this monitoring pipeline will be scheduled to
   * run for the next round.
   */
  nextScheduleTime:
    | Date
    | undefined;
  /** Stats anomalies base folder path. */
  statsAnomaliesBaseDirectory:
    | GcsDestination
    | undefined;
  /**
   * Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If
   * set, this ModelDeploymentMonitoringJob and all sub-resources of this
   * ModelDeploymentMonitoringJob will be secured by this key.
   */
  encryptionSpec:
    | EncryptionSpec
    | undefined;
  /**
   * If true, the scheduled monitoring pipeline logs are sent to
   * Google Cloud Logging, including pipeline status and anomalies detected.
   * Please note the logs incur cost, which are subject to [Cloud Logging
   * pricing](https://cloud.google.com/logging#pricing).
   */
  enableMonitoringPipelineLogs: boolean;
  /**
   * Output only. Only populated when the job's state is `JOB_STATE_FAILED` or
   * `JOB_STATE_CANCELLED`.
   */
  error:
    | Status
    | undefined;
  /** Output only. Reserved for future use. */
  satisfiesPzs: boolean;
  /** Output only. Reserved for future use. */
  satisfiesPzi: boolean;
}

/** The state to Specify the monitoring pipeline. */
export enum ModelDeploymentMonitoringJob_MonitoringScheduleState {
  /** MONITORING_SCHEDULE_STATE_UNSPECIFIED - Unspecified state. */
  MONITORING_SCHEDULE_STATE_UNSPECIFIED = 0,
  /** PENDING - The pipeline is picked up and wait to run. */
  PENDING = 1,
  /** OFFLINE - The pipeline is offline and will be scheduled for next run. */
  OFFLINE = 2,
  /** RUNNING - The pipeline is running. */
  RUNNING = 3,
  UNRECOGNIZED = -1,
}

export function modelDeploymentMonitoringJob_MonitoringScheduleStateFromJSON(
  object: any,
): ModelDeploymentMonitoringJob_MonitoringScheduleState {
  switch (object) {
    case 0:
    case "MONITORING_SCHEDULE_STATE_UNSPECIFIED":
      return ModelDeploymentMonitoringJob_MonitoringScheduleState.MONITORING_SCHEDULE_STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return ModelDeploymentMonitoringJob_MonitoringScheduleState.PENDING;
    case 2:
    case "OFFLINE":
      return ModelDeploymentMonitoringJob_MonitoringScheduleState.OFFLINE;
    case 3:
    case "RUNNING":
      return ModelDeploymentMonitoringJob_MonitoringScheduleState.RUNNING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ModelDeploymentMonitoringJob_MonitoringScheduleState.UNRECOGNIZED;
  }
}

export function modelDeploymentMonitoringJob_MonitoringScheduleStateToJSON(
  object: ModelDeploymentMonitoringJob_MonitoringScheduleState,
): string {
  switch (object) {
    case ModelDeploymentMonitoringJob_MonitoringScheduleState.MONITORING_SCHEDULE_STATE_UNSPECIFIED:
      return "MONITORING_SCHEDULE_STATE_UNSPECIFIED";
    case ModelDeploymentMonitoringJob_MonitoringScheduleState.PENDING:
      return "PENDING";
    case ModelDeploymentMonitoringJob_MonitoringScheduleState.OFFLINE:
      return "OFFLINE";
    case ModelDeploymentMonitoringJob_MonitoringScheduleState.RUNNING:
      return "RUNNING";
    case ModelDeploymentMonitoringJob_MonitoringScheduleState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** All metadata of most recent monitoring pipelines. */
export interface ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata {
  /**
   * The time that most recent monitoring pipelines that is related to this
   * run.
   */
  runTime:
    | Date
    | undefined;
  /** The status of the most recent monitoring pipeline. */
  status: Status | undefined;
}

export interface ModelDeploymentMonitoringJob_LabelsEntry {
  key: string;
  value: string;
}

/**
 * ModelDeploymentMonitoringBigQueryTable specifies the BigQuery table name
 * as well as some information of the logs stored in this table.
 */
export interface ModelDeploymentMonitoringBigQueryTable {
  /** The source of log. */
  logSource: ModelDeploymentMonitoringBigQueryTable_LogSource;
  /** The type of log. */
  logType: ModelDeploymentMonitoringBigQueryTable_LogType;
  /**
   * The created BigQuery table to store logs. Customer could do their own query
   * & analysis. Format:
   * `bq://<project_id>.model_deployment_monitoring_<endpoint_id>.<tolower(log_source)>_<tolower(log_type)>`
   */
  bigqueryTablePath: string;
  /**
   * Output only. The schema version of the request/response logging BigQuery
   * table. Default to v1 if unset.
   */
  requestResponseLoggingSchemaVersion: string;
}

/** Indicates where does the log come from. */
export enum ModelDeploymentMonitoringBigQueryTable_LogSource {
  /** LOG_SOURCE_UNSPECIFIED - Unspecified source. */
  LOG_SOURCE_UNSPECIFIED = 0,
  /** TRAINING - Logs coming from Training dataset. */
  TRAINING = 1,
  /** SERVING - Logs coming from Serving traffic. */
  SERVING = 2,
  UNRECOGNIZED = -1,
}

export function modelDeploymentMonitoringBigQueryTable_LogSourceFromJSON(
  object: any,
): ModelDeploymentMonitoringBigQueryTable_LogSource {
  switch (object) {
    case 0:
    case "LOG_SOURCE_UNSPECIFIED":
      return ModelDeploymentMonitoringBigQueryTable_LogSource.LOG_SOURCE_UNSPECIFIED;
    case 1:
    case "TRAINING":
      return ModelDeploymentMonitoringBigQueryTable_LogSource.TRAINING;
    case 2:
    case "SERVING":
      return ModelDeploymentMonitoringBigQueryTable_LogSource.SERVING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ModelDeploymentMonitoringBigQueryTable_LogSource.UNRECOGNIZED;
  }
}

export function modelDeploymentMonitoringBigQueryTable_LogSourceToJSON(
  object: ModelDeploymentMonitoringBigQueryTable_LogSource,
): string {
  switch (object) {
    case ModelDeploymentMonitoringBigQueryTable_LogSource.LOG_SOURCE_UNSPECIFIED:
      return "LOG_SOURCE_UNSPECIFIED";
    case ModelDeploymentMonitoringBigQueryTable_LogSource.TRAINING:
      return "TRAINING";
    case ModelDeploymentMonitoringBigQueryTable_LogSource.SERVING:
      return "SERVING";
    case ModelDeploymentMonitoringBigQueryTable_LogSource.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Indicates what type of traffic does the log belong to. */
export enum ModelDeploymentMonitoringBigQueryTable_LogType {
  /** LOG_TYPE_UNSPECIFIED - Unspecified type. */
  LOG_TYPE_UNSPECIFIED = 0,
  /** PREDICT - Predict logs. */
  PREDICT = 1,
  /** EXPLAIN - Explain logs. */
  EXPLAIN = 2,
  UNRECOGNIZED = -1,
}

export function modelDeploymentMonitoringBigQueryTable_LogTypeFromJSON(
  object: any,
): ModelDeploymentMonitoringBigQueryTable_LogType {
  switch (object) {
    case 0:
    case "LOG_TYPE_UNSPECIFIED":
      return ModelDeploymentMonitoringBigQueryTable_LogType.LOG_TYPE_UNSPECIFIED;
    case 1:
    case "PREDICT":
      return ModelDeploymentMonitoringBigQueryTable_LogType.PREDICT;
    case 2:
    case "EXPLAIN":
      return ModelDeploymentMonitoringBigQueryTable_LogType.EXPLAIN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ModelDeploymentMonitoringBigQueryTable_LogType.UNRECOGNIZED;
  }
}

export function modelDeploymentMonitoringBigQueryTable_LogTypeToJSON(
  object: ModelDeploymentMonitoringBigQueryTable_LogType,
): string {
  switch (object) {
    case ModelDeploymentMonitoringBigQueryTable_LogType.LOG_TYPE_UNSPECIFIED:
      return "LOG_TYPE_UNSPECIFIED";
    case ModelDeploymentMonitoringBigQueryTable_LogType.PREDICT:
      return "PREDICT";
    case ModelDeploymentMonitoringBigQueryTable_LogType.EXPLAIN:
      return "EXPLAIN";
    case ModelDeploymentMonitoringBigQueryTable_LogType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * ModelDeploymentMonitoringObjectiveConfig contains the pair of
 * deployed_model_id to ModelMonitoringObjectiveConfig.
 */
export interface ModelDeploymentMonitoringObjectiveConfig {
  /** The DeployedModel ID of the objective config. */
  deployedModelId: string;
  /** The objective config of for the modelmonitoring job of this deployed model. */
  objectiveConfig: ModelMonitoringObjectiveConfig | undefined;
}

/** The config for scheduling monitoring job. */
export interface ModelDeploymentMonitoringScheduleConfig {
  /**
   * Required. The model monitoring job scheduling interval. It will be rounded
   * up to next full hour. This defines how often the monitoring jobs are
   * triggered.
   */
  monitorInterval:
    | Duration
    | undefined;
  /**
   * The time window of the prediction data being included in each prediction
   * dataset. This window specifies how long the data should be collected from
   * historical model results for each run. If not set,
   * [ModelDeploymentMonitoringScheduleConfig.monitor_interval][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringScheduleConfig.monitor_interval]
   * will be used. e.g. If currently the cutoff time is 2022-01-08 14:30:00 and
   * the monitor_window is set to be 3600, then data from 2022-01-08 13:30:00 to
   * 2022-01-08 14:30:00 will be retrieved and aggregated to calculate the
   * monitoring statistics.
   */
  monitorWindow: Duration | undefined;
}

/** Statistics and anomalies generated by Model Monitoring. */
export interface ModelMonitoringStatsAnomalies {
  /** Model Monitoring Objective those stats and anomalies belonging to. */
  objective: ModelDeploymentMonitoringObjectiveType;
  /** Deployed Model ID. */
  deployedModelId: string;
  /** Number of anomalies within all stats. */
  anomalyCount: number;
  /** A list of historical Stats and Anomalies generated for all Features. */
  featureStats: ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies[];
}

/** Historical Stats (and Anomalies) for a specific Feature. */
export interface ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies {
  /** Display Name of the Feature. */
  featureDisplayName: string;
  /** Threshold for anomaly detection. */
  threshold:
    | ThresholdConfig
    | undefined;
  /** Stats calculated for the Training Dataset. */
  trainingStats:
    | FeatureStatsAnomaly
    | undefined;
  /**
   * A list of historical stats generated by different time window's
   * Prediction Dataset.
   */
  predictionStats: FeatureStatsAnomaly[];
}

function createBaseModelDeploymentMonitoringJob(): ModelDeploymentMonitoringJob {
  return {
    name: "",
    displayName: "",
    endpoint: "",
    state: 0,
    scheduleState: 0,
    latestMonitoringPipelineMetadata: undefined,
    modelDeploymentMonitoringObjectiveConfigs: [],
    modelDeploymentMonitoringScheduleConfig: undefined,
    loggingSamplingStrategy: undefined,
    modelMonitoringAlertConfig: undefined,
    predictInstanceSchemaUri: "",
    samplePredictInstance: undefined,
    analysisInstanceSchemaUri: "",
    bigqueryTables: [],
    logTtl: undefined,
    labels: {},
    createTime: undefined,
    updateTime: undefined,
    nextScheduleTime: undefined,
    statsAnomaliesBaseDirectory: undefined,
    encryptionSpec: undefined,
    enableMonitoringPipelineLogs: false,
    error: undefined,
    satisfiesPzs: false,
    satisfiesPzi: false,
  };
}

export const ModelDeploymentMonitoringJob: MessageFns<ModelDeploymentMonitoringJob> = {
  encode(message: ModelDeploymentMonitoringJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.endpoint !== "") {
      writer.uint32(26).string(message.endpoint);
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.scheduleState !== 0) {
      writer.uint32(40).int32(message.scheduleState);
    }
    if (message.latestMonitoringPipelineMetadata !== undefined) {
      ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata.encode(
        message.latestMonitoringPipelineMetadata,
        writer.uint32(202).fork(),
      ).join();
    }
    for (const v of message.modelDeploymentMonitoringObjectiveConfigs) {
      ModelDeploymentMonitoringObjectiveConfig.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.modelDeploymentMonitoringScheduleConfig !== undefined) {
      ModelDeploymentMonitoringScheduleConfig.encode(
        message.modelDeploymentMonitoringScheduleConfig,
        writer.uint32(58).fork(),
      ).join();
    }
    if (message.loggingSamplingStrategy !== undefined) {
      SamplingStrategy.encode(message.loggingSamplingStrategy, writer.uint32(66).fork()).join();
    }
    if (message.modelMonitoringAlertConfig !== undefined) {
      ModelMonitoringAlertConfig.encode(message.modelMonitoringAlertConfig, writer.uint32(122).fork()).join();
    }
    if (message.predictInstanceSchemaUri !== "") {
      writer.uint32(74).string(message.predictInstanceSchemaUri);
    }
    if (message.samplePredictInstance !== undefined) {
      Value.encode(Value.wrap(message.samplePredictInstance), writer.uint32(154).fork()).join();
    }
    if (message.analysisInstanceSchemaUri !== "") {
      writer.uint32(130).string(message.analysisInstanceSchemaUri);
    }
    for (const v of message.bigqueryTables) {
      ModelDeploymentMonitoringBigQueryTable.encode(v!, writer.uint32(82).fork()).join();
    }
    if (message.logTtl !== undefined) {
      Duration.encode(message.logTtl, writer.uint32(138).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ModelDeploymentMonitoringJob_LabelsEntry.encode({ key: key as any, value }, writer.uint32(90).fork()).join();
    });
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(98).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(106).fork()).join();
    }
    if (message.nextScheduleTime !== undefined) {
      Timestamp.encode(toTimestamp(message.nextScheduleTime), writer.uint32(114).fork()).join();
    }
    if (message.statsAnomaliesBaseDirectory !== undefined) {
      GcsDestination.encode(message.statsAnomaliesBaseDirectory, writer.uint32(162).fork()).join();
    }
    if (message.encryptionSpec !== undefined) {
      EncryptionSpec.encode(message.encryptionSpec, writer.uint32(170).fork()).join();
    }
    if (message.enableMonitoringPipelineLogs !== false) {
      writer.uint32(176).bool(message.enableMonitoringPipelineLogs);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(186).fork()).join();
    }
    if (message.satisfiesPzs !== false) {
      writer.uint32(208).bool(message.satisfiesPzs);
    }
    if (message.satisfiesPzi !== false) {
      writer.uint32(216).bool(message.satisfiesPzi);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelDeploymentMonitoringJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelDeploymentMonitoringJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.endpoint = reader.string();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.scheduleState = reader.int32() as any;
          continue;
        case 25:
          if (tag !== 202) {
            break;
          }

          message.latestMonitoringPipelineMetadata = ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata
            .decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.modelDeploymentMonitoringObjectiveConfigs.push(
            ModelDeploymentMonitoringObjectiveConfig.decode(reader, reader.uint32()),
          );
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.modelDeploymentMonitoringScheduleConfig = ModelDeploymentMonitoringScheduleConfig.decode(
            reader,
            reader.uint32(),
          );
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.loggingSamplingStrategy = SamplingStrategy.decode(reader, reader.uint32());
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.modelMonitoringAlertConfig = ModelMonitoringAlertConfig.decode(reader, reader.uint32());
          continue;
        case 9:
          if (tag !== 74) {
            break;
          }

          message.predictInstanceSchemaUri = reader.string();
          continue;
        case 19:
          if (tag !== 154) {
            break;
          }

          message.samplePredictInstance = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.analysisInstanceSchemaUri = reader.string();
          continue;
        case 10:
          if (tag !== 82) {
            break;
          }

          message.bigqueryTables.push(ModelDeploymentMonitoringBigQueryTable.decode(reader, reader.uint32()));
          continue;
        case 17:
          if (tag !== 138) {
            break;
          }

          message.logTtl = Duration.decode(reader, reader.uint32());
          continue;
        case 11:
          if (tag !== 90) {
            break;
          }

          const entry11 = ModelDeploymentMonitoringJob_LabelsEntry.decode(reader, reader.uint32());
          if (entry11.value !== undefined) {
            message.labels[entry11.key] = entry11.value;
          }
          continue;
        case 12:
          if (tag !== 98) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 13:
          if (tag !== 106) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 14:
          if (tag !== 114) {
            break;
          }

          message.nextScheduleTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 20:
          if (tag !== 162) {
            break;
          }

          message.statsAnomaliesBaseDirectory = GcsDestination.decode(reader, reader.uint32());
          continue;
        case 21:
          if (tag !== 170) {
            break;
          }

          message.encryptionSpec = EncryptionSpec.decode(reader, reader.uint32());
          continue;
        case 22:
          if (tag !== 176) {
            break;
          }

          message.enableMonitoringPipelineLogs = reader.bool();
          continue;
        case 23:
          if (tag !== 186) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        case 26:
          if (tag !== 208) {
            break;
          }

          message.satisfiesPzs = reader.bool();
          continue;
        case 27:
          if (tag !== 216) {
            break;
          }

          message.satisfiesPzi = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelDeploymentMonitoringJob {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : "",
      state: isSet(object.state) ? jobStateFromJSON(object.state) : 0,
      scheduleState: isSet(object.scheduleState)
        ? modelDeploymentMonitoringJob_MonitoringScheduleStateFromJSON(object.scheduleState)
        : 0,
      latestMonitoringPipelineMetadata: isSet(object.latestMonitoringPipelineMetadata)
        ? ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata.fromJSON(
          object.latestMonitoringPipelineMetadata,
        )
        : undefined,
      modelDeploymentMonitoringObjectiveConfigs:
        globalThis.Array.isArray(object?.modelDeploymentMonitoringObjectiveConfigs)
          ? object.modelDeploymentMonitoringObjectiveConfigs.map((e: any) =>
            ModelDeploymentMonitoringObjectiveConfig.fromJSON(e)
          )
          : [],
      modelDeploymentMonitoringScheduleConfig: isSet(object.modelDeploymentMonitoringScheduleConfig)
        ? ModelDeploymentMonitoringScheduleConfig.fromJSON(object.modelDeploymentMonitoringScheduleConfig)
        : undefined,
      loggingSamplingStrategy: isSet(object.loggingSamplingStrategy)
        ? SamplingStrategy.fromJSON(object.loggingSamplingStrategy)
        : undefined,
      modelMonitoringAlertConfig: isSet(object.modelMonitoringAlertConfig)
        ? ModelMonitoringAlertConfig.fromJSON(object.modelMonitoringAlertConfig)
        : undefined,
      predictInstanceSchemaUri: isSet(object.predictInstanceSchemaUri)
        ? globalThis.String(object.predictInstanceSchemaUri)
        : "",
      samplePredictInstance: isSet(object?.samplePredictInstance) ? object.samplePredictInstance : undefined,
      analysisInstanceSchemaUri: isSet(object.analysisInstanceSchemaUri)
        ? globalThis.String(object.analysisInstanceSchemaUri)
        : "",
      bigqueryTables: globalThis.Array.isArray(object?.bigqueryTables)
        ? object.bigqueryTables.map((e: any) => ModelDeploymentMonitoringBigQueryTable.fromJSON(e))
        : [],
      logTtl: isSet(object.logTtl) ? Duration.fromJSON(object.logTtl) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      nextScheduleTime: isSet(object.nextScheduleTime) ? fromJsonTimestamp(object.nextScheduleTime) : undefined,
      statsAnomaliesBaseDirectory: isSet(object.statsAnomaliesBaseDirectory)
        ? GcsDestination.fromJSON(object.statsAnomaliesBaseDirectory)
        : undefined,
      encryptionSpec: isSet(object.encryptionSpec) ? EncryptionSpec.fromJSON(object.encryptionSpec) : undefined,
      enableMonitoringPipelineLogs: isSet(object.enableMonitoringPipelineLogs)
        ? globalThis.Boolean(object.enableMonitoringPipelineLogs)
        : false,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      satisfiesPzs: isSet(object.satisfiesPzs) ? globalThis.Boolean(object.satisfiesPzs) : false,
      satisfiesPzi: isSet(object.satisfiesPzi) ? globalThis.Boolean(object.satisfiesPzi) : false,
    };
  },

  toJSON(message: ModelDeploymentMonitoringJob): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.endpoint !== "") {
      obj.endpoint = message.endpoint;
    }
    if (message.state !== 0) {
      obj.state = jobStateToJSON(message.state);
    }
    if (message.scheduleState !== 0) {
      obj.scheduleState = modelDeploymentMonitoringJob_MonitoringScheduleStateToJSON(message.scheduleState);
    }
    if (message.latestMonitoringPipelineMetadata !== undefined) {
      obj.latestMonitoringPipelineMetadata = ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata.toJSON(
        message.latestMonitoringPipelineMetadata,
      );
    }
    if (message.modelDeploymentMonitoringObjectiveConfigs?.length) {
      obj.modelDeploymentMonitoringObjectiveConfigs = message.modelDeploymentMonitoringObjectiveConfigs.map((e) =>
        ModelDeploymentMonitoringObjectiveConfig.toJSON(e)
      );
    }
    if (message.modelDeploymentMonitoringScheduleConfig !== undefined) {
      obj.modelDeploymentMonitoringScheduleConfig = ModelDeploymentMonitoringScheduleConfig.toJSON(
        message.modelDeploymentMonitoringScheduleConfig,
      );
    }
    if (message.loggingSamplingStrategy !== undefined) {
      obj.loggingSamplingStrategy = SamplingStrategy.toJSON(message.loggingSamplingStrategy);
    }
    if (message.modelMonitoringAlertConfig !== undefined) {
      obj.modelMonitoringAlertConfig = ModelMonitoringAlertConfig.toJSON(message.modelMonitoringAlertConfig);
    }
    if (message.predictInstanceSchemaUri !== "") {
      obj.predictInstanceSchemaUri = message.predictInstanceSchemaUri;
    }
    if (message.samplePredictInstance !== undefined) {
      obj.samplePredictInstance = message.samplePredictInstance;
    }
    if (message.analysisInstanceSchemaUri !== "") {
      obj.analysisInstanceSchemaUri = message.analysisInstanceSchemaUri;
    }
    if (message.bigqueryTables?.length) {
      obj.bigqueryTables = message.bigqueryTables.map((e) => ModelDeploymentMonitoringBigQueryTable.toJSON(e));
    }
    if (message.logTtl !== undefined) {
      obj.logTtl = Duration.toJSON(message.logTtl);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.nextScheduleTime !== undefined) {
      obj.nextScheduleTime = message.nextScheduleTime.toISOString();
    }
    if (message.statsAnomaliesBaseDirectory !== undefined) {
      obj.statsAnomaliesBaseDirectory = GcsDestination.toJSON(message.statsAnomaliesBaseDirectory);
    }
    if (message.encryptionSpec !== undefined) {
      obj.encryptionSpec = EncryptionSpec.toJSON(message.encryptionSpec);
    }
    if (message.enableMonitoringPipelineLogs !== false) {
      obj.enableMonitoringPipelineLogs = message.enableMonitoringPipelineLogs;
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.satisfiesPzs !== false) {
      obj.satisfiesPzs = message.satisfiesPzs;
    }
    if (message.satisfiesPzi !== false) {
      obj.satisfiesPzi = message.satisfiesPzi;
    }
    return obj;
  },

  create(base?: DeepPartial<ModelDeploymentMonitoringJob>): ModelDeploymentMonitoringJob {
    return ModelDeploymentMonitoringJob.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelDeploymentMonitoringJob>): ModelDeploymentMonitoringJob {
    const message = createBaseModelDeploymentMonitoringJob();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.endpoint = object.endpoint ?? "";
    message.state = object.state ?? 0;
    message.scheduleState = object.scheduleState ?? 0;
    message.latestMonitoringPipelineMetadata =
      (object.latestMonitoringPipelineMetadata !== undefined && object.latestMonitoringPipelineMetadata !== null)
        ? ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata.fromPartial(
          object.latestMonitoringPipelineMetadata,
        )
        : undefined;
    message.modelDeploymentMonitoringObjectiveConfigs =
      object.modelDeploymentMonitoringObjectiveConfigs?.map((e) =>
        ModelDeploymentMonitoringObjectiveConfig.fromPartial(e)
      ) || [];
    message.modelDeploymentMonitoringScheduleConfig =
      (object.modelDeploymentMonitoringScheduleConfig !== undefined &&
          object.modelDeploymentMonitoringScheduleConfig !== null)
        ? ModelDeploymentMonitoringScheduleConfig.fromPartial(object.modelDeploymentMonitoringScheduleConfig)
        : undefined;
    message.loggingSamplingStrategy =
      (object.loggingSamplingStrategy !== undefined && object.loggingSamplingStrategy !== null)
        ? SamplingStrategy.fromPartial(object.loggingSamplingStrategy)
        : undefined;
    message.modelMonitoringAlertConfig =
      (object.modelMonitoringAlertConfig !== undefined && object.modelMonitoringAlertConfig !== null)
        ? ModelMonitoringAlertConfig.fromPartial(object.modelMonitoringAlertConfig)
        : undefined;
    message.predictInstanceSchemaUri = object.predictInstanceSchemaUri ?? "";
    message.samplePredictInstance = object.samplePredictInstance ?? undefined;
    message.analysisInstanceSchemaUri = object.analysisInstanceSchemaUri ?? "";
    message.bigqueryTables = object.bigqueryTables?.map((e) => ModelDeploymentMonitoringBigQueryTable.fromPartial(e)) ||
      [];
    message.logTtl = (object.logTtl !== undefined && object.logTtl !== null)
      ? Duration.fromPartial(object.logTtl)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.nextScheduleTime = object.nextScheduleTime ?? undefined;
    message.statsAnomaliesBaseDirectory =
      (object.statsAnomaliesBaseDirectory !== undefined && object.statsAnomaliesBaseDirectory !== null)
        ? GcsDestination.fromPartial(object.statsAnomaliesBaseDirectory)
        : undefined;
    message.encryptionSpec = (object.encryptionSpec !== undefined && object.encryptionSpec !== null)
      ? EncryptionSpec.fromPartial(object.encryptionSpec)
      : undefined;
    message.enableMonitoringPipelineLogs = object.enableMonitoringPipelineLogs ?? false;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.satisfiesPzs = object.satisfiesPzs ?? false;
    message.satisfiesPzi = object.satisfiesPzi ?? false;
    return message;
  },
};

function createBaseModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata(): ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata {
  return { runTime: undefined, status: undefined };
}

export const ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata: MessageFns<
  ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata
> = {
  encode(
    message: ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.runTime !== undefined) {
      Timestamp.encode(toTimestamp(message.runTime), writer.uint32(10).fork()).join();
    }
    if (message.status !== undefined) {
      Status.encode(message.status, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.runTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.status = Status.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata {
    return {
      runTime: isSet(object.runTime) ? fromJsonTimestamp(object.runTime) : undefined,
      status: isSet(object.status) ? Status.fromJSON(object.status) : undefined,
    };
  },

  toJSON(message: ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata): unknown {
    const obj: any = {};
    if (message.runTime !== undefined) {
      obj.runTime = message.runTime.toISOString();
    }
    if (message.status !== undefined) {
      obj.status = Status.toJSON(message.status);
    }
    return obj;
  },

  create(
    base?: DeepPartial<ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata>,
  ): ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata {
    return ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata>,
  ): ModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata {
    const message = createBaseModelDeploymentMonitoringJob_LatestMonitoringPipelineMetadata();
    message.runTime = object.runTime ?? undefined;
    message.status = (object.status !== undefined && object.status !== null)
      ? Status.fromPartial(object.status)
      : undefined;
    return message;
  },
};

function createBaseModelDeploymentMonitoringJob_LabelsEntry(): ModelDeploymentMonitoringJob_LabelsEntry {
  return { key: "", value: "" };
}

export const ModelDeploymentMonitoringJob_LabelsEntry: MessageFns<ModelDeploymentMonitoringJob_LabelsEntry> = {
  encode(message: ModelDeploymentMonitoringJob_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelDeploymentMonitoringJob_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelDeploymentMonitoringJob_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelDeploymentMonitoringJob_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ModelDeploymentMonitoringJob_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<ModelDeploymentMonitoringJob_LabelsEntry>): ModelDeploymentMonitoringJob_LabelsEntry {
    return ModelDeploymentMonitoringJob_LabelsEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelDeploymentMonitoringJob_LabelsEntry>): ModelDeploymentMonitoringJob_LabelsEntry {
    const message = createBaseModelDeploymentMonitoringJob_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseModelDeploymentMonitoringBigQueryTable(): ModelDeploymentMonitoringBigQueryTable {
  return { logSource: 0, logType: 0, bigqueryTablePath: "", requestResponseLoggingSchemaVersion: "" };
}

export const ModelDeploymentMonitoringBigQueryTable: MessageFns<ModelDeploymentMonitoringBigQueryTable> = {
  encode(message: ModelDeploymentMonitoringBigQueryTable, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.logSource !== 0) {
      writer.uint32(8).int32(message.logSource);
    }
    if (message.logType !== 0) {
      writer.uint32(16).int32(message.logType);
    }
    if (message.bigqueryTablePath !== "") {
      writer.uint32(26).string(message.bigqueryTablePath);
    }
    if (message.requestResponseLoggingSchemaVersion !== "") {
      writer.uint32(34).string(message.requestResponseLoggingSchemaVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelDeploymentMonitoringBigQueryTable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelDeploymentMonitoringBigQueryTable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.logSource = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.logType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.bigqueryTablePath = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.requestResponseLoggingSchemaVersion = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelDeploymentMonitoringBigQueryTable {
    return {
      logSource: isSet(object.logSource)
        ? modelDeploymentMonitoringBigQueryTable_LogSourceFromJSON(object.logSource)
        : 0,
      logType: isSet(object.logType) ? modelDeploymentMonitoringBigQueryTable_LogTypeFromJSON(object.logType) : 0,
      bigqueryTablePath: isSet(object.bigqueryTablePath) ? globalThis.String(object.bigqueryTablePath) : "",
      requestResponseLoggingSchemaVersion: isSet(object.requestResponseLoggingSchemaVersion)
        ? globalThis.String(object.requestResponseLoggingSchemaVersion)
        : "",
    };
  },

  toJSON(message: ModelDeploymentMonitoringBigQueryTable): unknown {
    const obj: any = {};
    if (message.logSource !== 0) {
      obj.logSource = modelDeploymentMonitoringBigQueryTable_LogSourceToJSON(message.logSource);
    }
    if (message.logType !== 0) {
      obj.logType = modelDeploymentMonitoringBigQueryTable_LogTypeToJSON(message.logType);
    }
    if (message.bigqueryTablePath !== "") {
      obj.bigqueryTablePath = message.bigqueryTablePath;
    }
    if (message.requestResponseLoggingSchemaVersion !== "") {
      obj.requestResponseLoggingSchemaVersion = message.requestResponseLoggingSchemaVersion;
    }
    return obj;
  },

  create(base?: DeepPartial<ModelDeploymentMonitoringBigQueryTable>): ModelDeploymentMonitoringBigQueryTable {
    return ModelDeploymentMonitoringBigQueryTable.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelDeploymentMonitoringBigQueryTable>): ModelDeploymentMonitoringBigQueryTable {
    const message = createBaseModelDeploymentMonitoringBigQueryTable();
    message.logSource = object.logSource ?? 0;
    message.logType = object.logType ?? 0;
    message.bigqueryTablePath = object.bigqueryTablePath ?? "";
    message.requestResponseLoggingSchemaVersion = object.requestResponseLoggingSchemaVersion ?? "";
    return message;
  },
};

function createBaseModelDeploymentMonitoringObjectiveConfig(): ModelDeploymentMonitoringObjectiveConfig {
  return { deployedModelId: "", objectiveConfig: undefined };
}

export const ModelDeploymentMonitoringObjectiveConfig: MessageFns<ModelDeploymentMonitoringObjectiveConfig> = {
  encode(message: ModelDeploymentMonitoringObjectiveConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deployedModelId !== "") {
      writer.uint32(10).string(message.deployedModelId);
    }
    if (message.objectiveConfig !== undefined) {
      ModelMonitoringObjectiveConfig.encode(message.objectiveConfig, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelDeploymentMonitoringObjectiveConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelDeploymentMonitoringObjectiveConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.deployedModelId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.objectiveConfig = ModelMonitoringObjectiveConfig.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelDeploymentMonitoringObjectiveConfig {
    return {
      deployedModelId: isSet(object.deployedModelId) ? globalThis.String(object.deployedModelId) : "",
      objectiveConfig: isSet(object.objectiveConfig)
        ? ModelMonitoringObjectiveConfig.fromJSON(object.objectiveConfig)
        : undefined,
    };
  },

  toJSON(message: ModelDeploymentMonitoringObjectiveConfig): unknown {
    const obj: any = {};
    if (message.deployedModelId !== "") {
      obj.deployedModelId = message.deployedModelId;
    }
    if (message.objectiveConfig !== undefined) {
      obj.objectiveConfig = ModelMonitoringObjectiveConfig.toJSON(message.objectiveConfig);
    }
    return obj;
  },

  create(base?: DeepPartial<ModelDeploymentMonitoringObjectiveConfig>): ModelDeploymentMonitoringObjectiveConfig {
    return ModelDeploymentMonitoringObjectiveConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelDeploymentMonitoringObjectiveConfig>): ModelDeploymentMonitoringObjectiveConfig {
    const message = createBaseModelDeploymentMonitoringObjectiveConfig();
    message.deployedModelId = object.deployedModelId ?? "";
    message.objectiveConfig = (object.objectiveConfig !== undefined && object.objectiveConfig !== null)
      ? ModelMonitoringObjectiveConfig.fromPartial(object.objectiveConfig)
      : undefined;
    return message;
  },
};

function createBaseModelDeploymentMonitoringScheduleConfig(): ModelDeploymentMonitoringScheduleConfig {
  return { monitorInterval: undefined, monitorWindow: undefined };
}

export const ModelDeploymentMonitoringScheduleConfig: MessageFns<ModelDeploymentMonitoringScheduleConfig> = {
  encode(message: ModelDeploymentMonitoringScheduleConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.monitorInterval !== undefined) {
      Duration.encode(message.monitorInterval, writer.uint32(10).fork()).join();
    }
    if (message.monitorWindow !== undefined) {
      Duration.encode(message.monitorWindow, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelDeploymentMonitoringScheduleConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelDeploymentMonitoringScheduleConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.monitorInterval = Duration.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.monitorWindow = Duration.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelDeploymentMonitoringScheduleConfig {
    return {
      monitorInterval: isSet(object.monitorInterval) ? Duration.fromJSON(object.monitorInterval) : undefined,
      monitorWindow: isSet(object.monitorWindow) ? Duration.fromJSON(object.monitorWindow) : undefined,
    };
  },

  toJSON(message: ModelDeploymentMonitoringScheduleConfig): unknown {
    const obj: any = {};
    if (message.monitorInterval !== undefined) {
      obj.monitorInterval = Duration.toJSON(message.monitorInterval);
    }
    if (message.monitorWindow !== undefined) {
      obj.monitorWindow = Duration.toJSON(message.monitorWindow);
    }
    return obj;
  },

  create(base?: DeepPartial<ModelDeploymentMonitoringScheduleConfig>): ModelDeploymentMonitoringScheduleConfig {
    return ModelDeploymentMonitoringScheduleConfig.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelDeploymentMonitoringScheduleConfig>): ModelDeploymentMonitoringScheduleConfig {
    const message = createBaseModelDeploymentMonitoringScheduleConfig();
    message.monitorInterval = (object.monitorInterval !== undefined && object.monitorInterval !== null)
      ? Duration.fromPartial(object.monitorInterval)
      : undefined;
    message.monitorWindow = (object.monitorWindow !== undefined && object.monitorWindow !== null)
      ? Duration.fromPartial(object.monitorWindow)
      : undefined;
    return message;
  },
};

function createBaseModelMonitoringStatsAnomalies(): ModelMonitoringStatsAnomalies {
  return { objective: 0, deployedModelId: "", anomalyCount: 0, featureStats: [] };
}

export const ModelMonitoringStatsAnomalies: MessageFns<ModelMonitoringStatsAnomalies> = {
  encode(message: ModelMonitoringStatsAnomalies, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.objective !== 0) {
      writer.uint32(8).int32(message.objective);
    }
    if (message.deployedModelId !== "") {
      writer.uint32(18).string(message.deployedModelId);
    }
    if (message.anomalyCount !== 0) {
      writer.uint32(24).int32(message.anomalyCount);
    }
    for (const v of message.featureStats) {
      ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelMonitoringStatsAnomalies {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelMonitoringStatsAnomalies();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.objective = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.deployedModelId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.anomalyCount = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.featureStats.push(
            ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies.decode(reader, reader.uint32()),
          );
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelMonitoringStatsAnomalies {
    return {
      objective: isSet(object.objective) ? modelDeploymentMonitoringObjectiveTypeFromJSON(object.objective) : 0,
      deployedModelId: isSet(object.deployedModelId) ? globalThis.String(object.deployedModelId) : "",
      anomalyCount: isSet(object.anomalyCount) ? globalThis.Number(object.anomalyCount) : 0,
      featureStats: globalThis.Array.isArray(object?.featureStats)
        ? object.featureStats.map((e: any) => ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ModelMonitoringStatsAnomalies): unknown {
    const obj: any = {};
    if (message.objective !== 0) {
      obj.objective = modelDeploymentMonitoringObjectiveTypeToJSON(message.objective);
    }
    if (message.deployedModelId !== "") {
      obj.deployedModelId = message.deployedModelId;
    }
    if (message.anomalyCount !== 0) {
      obj.anomalyCount = Math.round(message.anomalyCount);
    }
    if (message.featureStats?.length) {
      obj.featureStats = message.featureStats.map((e) =>
        ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies.toJSON(e)
      );
    }
    return obj;
  },

  create(base?: DeepPartial<ModelMonitoringStatsAnomalies>): ModelMonitoringStatsAnomalies {
    return ModelMonitoringStatsAnomalies.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ModelMonitoringStatsAnomalies>): ModelMonitoringStatsAnomalies {
    const message = createBaseModelMonitoringStatsAnomalies();
    message.objective = object.objective ?? 0;
    message.deployedModelId = object.deployedModelId ?? "";
    message.anomalyCount = object.anomalyCount ?? 0;
    message.featureStats =
      object.featureStats?.map((e) => ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies(): ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies {
  return { featureDisplayName: "", threshold: undefined, trainingStats: undefined, predictionStats: [] };
}

export const ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies: MessageFns<
  ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies
> = {
  encode(
    message: ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.featureDisplayName !== "") {
      writer.uint32(10).string(message.featureDisplayName);
    }
    if (message.threshold !== undefined) {
      ThresholdConfig.encode(message.threshold, writer.uint32(26).fork()).join();
    }
    if (message.trainingStats !== undefined) {
      FeatureStatsAnomaly.encode(message.trainingStats, writer.uint32(34).fork()).join();
    }
    for (const v of message.predictionStats) {
      FeatureStatsAnomaly.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.featureDisplayName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.threshold = ThresholdConfig.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.trainingStats = FeatureStatsAnomaly.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.predictionStats.push(FeatureStatsAnomaly.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies {
    return {
      featureDisplayName: isSet(object.featureDisplayName) ? globalThis.String(object.featureDisplayName) : "",
      threshold: isSet(object.threshold) ? ThresholdConfig.fromJSON(object.threshold) : undefined,
      trainingStats: isSet(object.trainingStats) ? FeatureStatsAnomaly.fromJSON(object.trainingStats) : undefined,
      predictionStats: globalThis.Array.isArray(object?.predictionStats)
        ? object.predictionStats.map((e: any) => FeatureStatsAnomaly.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies): unknown {
    const obj: any = {};
    if (message.featureDisplayName !== "") {
      obj.featureDisplayName = message.featureDisplayName;
    }
    if (message.threshold !== undefined) {
      obj.threshold = ThresholdConfig.toJSON(message.threshold);
    }
    if (message.trainingStats !== undefined) {
      obj.trainingStats = FeatureStatsAnomaly.toJSON(message.trainingStats);
    }
    if (message.predictionStats?.length) {
      obj.predictionStats = message.predictionStats.map((e) => FeatureStatsAnomaly.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies>,
  ): ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies {
    return ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies>,
  ): ModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies {
    const message = createBaseModelMonitoringStatsAnomalies_FeatureHistoricStatsAnomalies();
    message.featureDisplayName = object.featureDisplayName ?? "";
    message.threshold = (object.threshold !== undefined && object.threshold !== null)
      ? ThresholdConfig.fromPartial(object.threshold)
      : undefined;
    message.trainingStats = (object.trainingStats !== undefined && object.trainingStats !== null)
      ? FeatureStatsAnomaly.fromPartial(object.trainingStats)
      : undefined;
    message.predictionStats = object.predictionStats?.map((e) => FeatureStatsAnomaly.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
