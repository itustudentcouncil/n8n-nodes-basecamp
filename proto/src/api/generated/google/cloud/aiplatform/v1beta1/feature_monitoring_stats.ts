// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: google/cloud/aiplatform/v1beta1/feature_monitoring_stats.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../protobuf/timestamp.js";

export const protobufPackage = "google.cloud.aiplatform.v1beta1";

/**
 * Stats and Anomaly generated at specific timestamp for specific Feature.
 * The start_time and end_time are used to define the time range of the dataset
 * that current stats belongs to, e.g. prediction traffic is bucketed into
 * prediction datasets by time window. If the Dataset is not defined by time
 * window, start_time = end_time. Timestamp of the stats and anomalies always
 * refers to end_time. Raw stats and anomalies are stored in stats_uri or
 * anomaly_uri in the tensorflow defined protos. Field data_stats contains
 * almost identical information with the raw stats in Vertex AI
 * defined proto, for UI to display.
 */
export interface FeatureStatsAnomaly {
  /**
   * Feature importance score, only populated when cross-feature monitoring is
   * enabled. For now only used to represent feature attribution score within
   * range [0, 1] for
   * [ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW]
   * and
   * [ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT].
   */
  score: number;
  /**
   * Path of the stats file for current feature values in Cloud Storage bucket.
   * Format: gs://<bucket_name>/<object_name>/stats.
   * Example: gs://monitoring_bucket/feature_name/stats.
   * Stats are stored as binary format with Protobuf message
   * [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
   */
  statsUri: string;
  /**
   * Path of the anomaly file for current feature values in Cloud Storage
   * bucket.
   * Format: gs://<bucket_name>/<object_name>/anomalies.
   * Example: gs://monitoring_bucket/feature_name/anomalies.
   * Stats are stored as binary format with Protobuf message
   * Anoamlies are stored as binary format with Protobuf message
   * [tensorflow.metadata.v0.AnomalyInfo]
   * (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
   */
  anomalyUri: string;
  /**
   * Deviation from the current stats to baseline stats.
   *   1. For categorical feature, the distribution distance is calculated by
   *      L-inifinity norm.
   *   2. For numerical feature, the distribution distance is calculated by
   *      Jensenâ€“Shannon divergence.
   */
  distributionDeviation: number;
  /**
   * This is the threshold used when detecting anomalies.
   * The threshold can be changed by user, so this one might be different from
   * [ThresholdConfig.value][google.cloud.aiplatform.v1beta1.ThresholdConfig.value].
   */
  anomalyDetectionThreshold: number;
  /**
   * The start timestamp of window where stats were generated.
   * For objectives where time window doesn't make sense (e.g. Featurestore
   * Snapshot Monitoring), start_time is only used to indicate the monitoring
   * intervals, so it always equals to (end_time - monitoring_interval).
   */
  startTime:
    | Date
    | undefined;
  /**
   * The end timestamp of window where stats were generated.
   * For objectives where time window doesn't make sense (e.g. Featurestore
   * Snapshot Monitoring), end_time indicates the timestamp of the data used to
   * generate stats (e.g. timestamp we take snapshots for feature values).
   */
  endTime: Date | undefined;
}

function createBaseFeatureStatsAnomaly(): FeatureStatsAnomaly {
  return {
    score: 0,
    statsUri: "",
    anomalyUri: "",
    distributionDeviation: 0,
    anomalyDetectionThreshold: 0,
    startTime: undefined,
    endTime: undefined,
  };
}

export const FeatureStatsAnomaly: MessageFns<FeatureStatsAnomaly> = {
  encode(message: FeatureStatsAnomaly, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.score !== 0) {
      writer.uint32(9).double(message.score);
    }
    if (message.statsUri !== "") {
      writer.uint32(26).string(message.statsUri);
    }
    if (message.anomalyUri !== "") {
      writer.uint32(34).string(message.anomalyUri);
    }
    if (message.distributionDeviation !== 0) {
      writer.uint32(41).double(message.distributionDeviation);
    }
    if (message.anomalyDetectionThreshold !== 0) {
      writer.uint32(73).double(message.anomalyDetectionThreshold);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(58).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FeatureStatsAnomaly {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFeatureStatsAnomaly();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 9) {
            break;
          }

          message.score = reader.double();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.statsUri = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.anomalyUri = reader.string();
          continue;
        case 5:
          if (tag !== 41) {
            break;
          }

          message.distributionDeviation = reader.double();
          continue;
        case 9:
          if (tag !== 73) {
            break;
          }

          message.anomalyDetectionThreshold = reader.double();
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FeatureStatsAnomaly {
    return {
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
      statsUri: isSet(object.statsUri) ? globalThis.String(object.statsUri) : "",
      anomalyUri: isSet(object.anomalyUri) ? globalThis.String(object.anomalyUri) : "",
      distributionDeviation: isSet(object.distributionDeviation) ? globalThis.Number(object.distributionDeviation) : 0,
      anomalyDetectionThreshold: isSet(object.anomalyDetectionThreshold)
        ? globalThis.Number(object.anomalyDetectionThreshold)
        : 0,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: FeatureStatsAnomaly): unknown {
    const obj: any = {};
    if (message.score !== 0) {
      obj.score = message.score;
    }
    if (message.statsUri !== "") {
      obj.statsUri = message.statsUri;
    }
    if (message.anomalyUri !== "") {
      obj.anomalyUri = message.anomalyUri;
    }
    if (message.distributionDeviation !== 0) {
      obj.distributionDeviation = message.distributionDeviation;
    }
    if (message.anomalyDetectionThreshold !== 0) {
      obj.anomalyDetectionThreshold = message.anomalyDetectionThreshold;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<FeatureStatsAnomaly>): FeatureStatsAnomaly {
    return FeatureStatsAnomaly.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FeatureStatsAnomaly>): FeatureStatsAnomaly {
    const message = createBaseFeatureStatsAnomaly();
    message.score = object.score ?? 0;
    message.statsUri = object.statsUri ?? "";
    message.anomalyUri = object.anomalyUri ?? "";
    message.distributionDeviation = object.distributionDeviation ?? 0;
    message.anomalyDetectionThreshold = object.anomalyDetectionThreshold ?? 0;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
